
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522.log
2022-11-04 01:05:22.386354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 01:05:22.522014: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 01:05:22.918675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 01:05:22.918724: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 01:05:22.918731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/tb_runs
Files already downloaded and verified
hello
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
INFO - Inserted quantizers into the original model
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Validation [   20/   40]   Loss 0.412269   Top1 90.351562   Top5 99.511719   BatchTime 0.172718
INFO - Validation [   40/   40]   Loss 0.402214   Top1 90.500000   Top5 99.590000   BatchTime 0.114749
INFO - ==> Top1: 90.500    Top5: 99.590    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.029285   Top1 98.945312   Top5 100.000000   BatchTime 0.261288   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.031289   Top1 98.857422   Top5 100.000000   BatchTime 0.206241   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.034107   Top1 98.769531   Top5 100.000000   BatchTime 0.187710   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.035260   Top1 98.740234   Top5 100.000000   BatchTime 0.178372   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.036265   Top1 98.722656   Top5 100.000000   BatchTime 0.172812   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.036477   Top1 98.694661   Top5 100.000000   BatchTime 0.169069   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.037272   Top1 98.663504   Top5 100.000000   BatchTime 0.166444   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.038279   Top1 98.623047   Top5 99.997559   BatchTime 0.164343   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.039104   Top1 98.582899   Top5 99.997830   BatchTime 0.162714   LR 0.010000
INFO - ==> Top1: 98.606    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.430218   Top1 90.019531   Top5 99.570312   BatchTime 0.139322
INFO - Validation [0][   40/   40]   Loss 0.415012   Top1 90.290000   Top5 99.630000   BatchTime 0.094873
INFO - ==> Top1: 90.290    Top5: 99.630    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.044071   Top1 98.574219   Top5 100.000000   BatchTime 0.240453   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.044024   Top1 98.583984   Top5 100.000000   BatchTime 0.195704   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.046415   Top1 98.509115   Top5 100.000000   BatchTime 0.180761   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.044021   Top1 98.549805   Top5 100.000000   BatchTime 0.173222   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.043364   Top1 98.558594   Top5 100.000000   BatchTime 0.168838   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.043097   Top1 98.531901   Top5 100.000000   BatchTime 0.166649   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.041560   Top1 98.568638   Top5 100.000000   BatchTime 0.164300   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.041151   Top1 98.596191   Top5 100.000000   BatchTime 0.162484   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.041284   Top1 98.598090   Top5 100.000000   BatchTime 0.161076   LR 0.010000
INFO - ==> Top1: 98.598    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.433011   Top1 90.000000   Top5 99.648438   BatchTime 0.132660
INFO - Validation [1][   40/   40]   Loss 0.420769   Top1 90.180000   Top5 99.650000   BatchTime 0.091583
INFO - ==> Top1: 90.180    Top5: 99.650    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 90.180   Top5: 99.650] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.031670   Top1 99.023438   Top5 100.000000   BatchTime 0.241216   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.032693   Top1 98.964844   Top5 100.000000   BatchTime 0.196473   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.034533   Top1 98.841146   Top5 100.000000   BatchTime 0.181559   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.034845   Top1 98.793945   Top5 100.000000   BatchTime 0.174104   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.034493   Top1 98.804688   Top5 100.000000   BatchTime 0.169625   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.035439   Top1 98.723958   Top5 100.000000   BatchTime 0.166617   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.036971   Top1 98.669085   Top5 100.000000   BatchTime 0.164436   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.037564   Top1 98.657227   Top5 100.000000   BatchTime 0.162636   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.038951   Top1 98.608941   Top5 99.997830   BatchTime 0.161260   LR 0.010000
INFO - ==> Top1: 98.612    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.435636   Top1 90.234375   Top5 99.511719   BatchTime 0.130153
INFO - Validation [2][   40/   40]   Loss 0.423086   Top1 90.550000   Top5 99.560000   BatchTime 0.091139
INFO - ==> Top1: 90.550    Top5: 99.560    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.036699   Top1 98.691406   Top5 100.000000   BatchTime 0.217774   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.039743   Top1 98.593750   Top5 100.000000   BatchTime 0.184635   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.039968   Top1 98.574219   Top5 100.000000   BatchTime 0.173430   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.038580   Top1 98.642578   Top5 100.000000   BatchTime 0.167966   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.037863   Top1 98.679688   Top5 100.000000   BatchTime 0.164543   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.038440   Top1 98.652344   Top5 100.000000   BatchTime 0.162490   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.039490   Top1 98.627232   Top5 100.000000   BatchTime 0.160859   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.038956   Top1 98.666992   Top5 100.000000   BatchTime 0.159451   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.039735   Top1 98.628472   Top5 100.000000   BatchTime 0.158403   LR 0.010000
INFO - ==> Top1: 98.636    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.441783   Top1 90.097656   Top5 99.453125   BatchTime 0.124763
INFO - Validation [3][   40/   40]   Loss 0.429969   Top1 90.280000   Top5 99.560000   BatchTime 0.084106
INFO - ==> Top1: 90.280    Top5: 99.560    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.036828   Top1 98.730469   Top5 100.000000   BatchTime 0.201353   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.032848   Top1 98.867188   Top5 100.000000   BatchTime 0.175420   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.034444   Top1 98.841146   Top5 100.000000   BatchTime 0.167343   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.035752   Top1 98.740234   Top5 100.000000   BatchTime 0.163395   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.036376   Top1 98.703125   Top5 100.000000   BatchTime 0.160967   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.037333   Top1 98.655599   Top5 100.000000   BatchTime 0.159355   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.038002   Top1 98.607701   Top5 100.000000   BatchTime 0.158084   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.038385   Top1 98.598633   Top5 100.000000   BatchTime 0.157059   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.038903   Top1 98.602431   Top5 100.000000   BatchTime 0.156234   LR 0.010000
INFO - ==> Top1: 98.580    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.429817   Top1 90.527344   Top5 99.531250   BatchTime 0.126299
INFO - Validation [4][   40/   40]   Loss 0.425634   Top1 90.600000   Top5 99.590000   BatchTime 0.080295
INFO - ==> Top1: 90.600    Top5: 99.590    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.037389   Top1 98.671875   Top5 100.000000   BatchTime 0.193726   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.037689   Top1 98.642578   Top5 100.000000   BatchTime 0.173409   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.036665   Top1 98.678385   Top5 100.000000   BatchTime 0.165991   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.035769   Top1 98.701172   Top5 99.995117   BatchTime 0.162305   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.035578   Top1 98.726562   Top5 99.996094   BatchTime 0.160059   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.036666   Top1 98.704427   Top5 99.996745   BatchTime 0.159194   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.037059   Top1 98.705357   Top5 99.997210   BatchTime 0.158013   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.037045   Top1 98.696289   Top5 99.997559   BatchTime 0.156993   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.037289   Top1 98.656684   Top5 99.997830   BatchTime 0.156185   LR 0.010000
INFO - ==> Top1: 98.646    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.441704   Top1 90.566406   Top5 99.511719   BatchTime 0.126328
INFO - Validation [5][   40/   40]   Loss 0.428170   Top1 90.520000   Top5 99.590000   BatchTime 0.080379
INFO - ==> Top1: 90.520    Top5: 99.590    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.033900   Top1 98.808594   Top5 100.000000   BatchTime 0.191655   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.036099   Top1 98.671875   Top5 100.000000   BatchTime 0.171352   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.037066   Top1 98.691406   Top5 100.000000   BatchTime 0.164761   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.034513   Top1 98.813477   Top5 100.000000   BatchTime 0.161479   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.035028   Top1 98.789062   Top5 100.000000   BatchTime 0.159431   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.035112   Top1 98.795573   Top5 100.000000   BatchTime 0.158151   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.035079   Top1 98.789062   Top5 100.000000   BatchTime 0.157266   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.035336   Top1 98.776855   Top5 100.000000   BatchTime 0.156387   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.035394   Top1 98.771701   Top5 100.000000   BatchTime 0.155639   LR 0.010000
INFO - ==> Top1: 98.770    Top5: 100.000    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.448127   Top1 90.214844   Top5 99.550781   BatchTime 0.130854
INFO - Validation [6][   40/   40]   Loss 0.430425   Top1 90.410000   Top5 99.590000   BatchTime 0.082618
INFO - ==> Top1: 90.410    Top5: 99.590    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.027297   Top1 99.082031   Top5 100.000000   BatchTime 0.190377   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.029878   Top1 99.013672   Top5 100.000000   BatchTime 0.157610   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.030339   Top1 99.016927   Top5 100.000000   BatchTime 0.155401   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.031888   Top1 98.955078   Top5 100.000000   BatchTime 0.154272   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.031826   Top1 98.929688   Top5 100.000000   BatchTime 0.153698   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.032100   Top1 98.909505   Top5 100.000000   BatchTime 0.153222   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.033251   Top1 98.856027   Top5 100.000000   BatchTime 0.152904   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.034229   Top1 98.825684   Top5 100.000000   BatchTime 0.152605   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.034142   Top1 98.836806   Top5 100.000000   BatchTime 0.152308   LR 0.010000
INFO - ==> Top1: 98.830    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.439483   Top1 90.039062   Top5 99.667969   BatchTime 0.151241
INFO - Validation [7][   40/   40]   Loss 0.427296   Top1 90.420000   Top5 99.710000   BatchTime 0.093681
INFO - ==> Top1: 90.420    Top5: 99.710    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.031072   Top1 98.964844   Top5 100.000000   BatchTime 0.201209   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.029871   Top1 99.033203   Top5 100.000000   BatchTime 0.152566   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.028948   Top1 99.042969   Top5 100.000000   BatchTime 0.152046   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.030877   Top1 98.994141   Top5 100.000000   BatchTime 0.152078   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.030424   Top1 98.980469   Top5 100.000000   BatchTime 0.151719   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.030521   Top1 99.003906   Top5 100.000000   BatchTime 0.151768   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.030413   Top1 98.995536   Top5 100.000000   BatchTime 0.151604   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.031868   Top1 98.942871   Top5 100.000000   BatchTime 0.151523   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.031853   Top1 98.934462   Top5 100.000000   BatchTime 0.151338   LR 0.010000
INFO - ==> Top1: 98.938    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.446328   Top1 90.429688   Top5 99.433594   BatchTime 0.158140
INFO - Validation [8][   40/   40]   Loss 0.435362   Top1 90.450000   Top5 99.550000   BatchTime 0.102085
INFO - ==> Top1: 90.450    Top5: 99.550    Loss: 0.435
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.026089   Top1 99.121094   Top5 99.980469   BatchTime 0.208390   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.029548   Top1 98.935547   Top5 99.990234   BatchTime 0.147655   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.029710   Top1 98.886719   Top5 99.993490   BatchTime 0.145294   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.030891   Top1 98.847656   Top5 99.995117   BatchTime 0.146905   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.030760   Top1 98.855469   Top5 99.996094   BatchTime 0.147710   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.029913   Top1 98.886719   Top5 99.996745   BatchTime 0.148327   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.030519   Top1 98.869978   Top5 99.997210   BatchTime 0.148614   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.030706   Top1 98.852539   Top5 99.997559   BatchTime 0.148780   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.030511   Top1 98.858507   Top5 99.997830   BatchTime 0.149495   LR 0.010000
INFO - ==> Top1: 98.850    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.456671   Top1 90.214844   Top5 99.628906   BatchTime 0.158478
INFO - Validation [9][   40/   40]   Loss 0.436166   Top1 90.580000   Top5 99.670000   BatchTime 0.113634
INFO - ==> Top1: 90.580    Top5: 99.670    Loss: 0.436
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.029550   Top1 99.042969   Top5 100.000000   BatchTime 0.217122   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.030677   Top1 98.925781   Top5 100.000000   BatchTime 0.157855   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.032102   Top1 98.834635   Top5 100.000000   BatchTime 0.147459   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.032421   Top1 98.862305   Top5 100.000000   BatchTime 0.148441   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.032942   Top1 98.839844   Top5 100.000000   BatchTime 0.149048   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.033058   Top1 98.824870   Top5 100.000000   BatchTime 0.149385   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.032185   Top1 98.839286   Top5 100.000000   BatchTime 0.149681   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.031758   Top1 98.859863   Top5 100.000000   BatchTime 0.149741   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.031385   Top1 98.865017   Top5 100.000000   BatchTime 0.149889   LR 0.010000
INFO - ==> Top1: 98.864    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.443440   Top1 90.332031   Top5 99.589844   BatchTime 0.159167
INFO - Validation [10][   40/   40]   Loss 0.429766   Top1 90.480000   Top5 99.630000   BatchTime 0.116634
INFO - ==> Top1: 90.480    Top5: 99.630    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.030170   Top1 98.945312   Top5 100.000000   BatchTime 0.213057   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.031098   Top1 98.916016   Top5 100.000000   BatchTime 0.157241   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.032182   Top1 98.847656   Top5 100.000000   BatchTime 0.140182   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.033318   Top1 98.808594   Top5 100.000000   BatchTime 0.142726   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.034545   Top1 98.785156   Top5 100.000000   BatchTime 0.144509   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.034155   Top1 98.792318   Top5 100.000000   BatchTime 0.145691   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.033752   Top1 98.830915   Top5 100.000000   BatchTime 0.146436   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.032886   Top1 98.864746   Top5 100.000000   BatchTime 0.146960   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.033084   Top1 98.862847   Top5 100.000000   BatchTime 0.147341   LR 0.010000
INFO - ==> Top1: 98.842    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.458660   Top1 90.429688   Top5 99.414062   BatchTime 0.158205
INFO - Validation [11][   40/   40]   Loss 0.443853   Top1 90.500000   Top5 99.510000   BatchTime 0.117008
INFO - ==> Top1: 90.500    Top5: 99.510    Loss: 0.444
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.034780   Top1 98.691406   Top5 100.000000   BatchTime 0.203418   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.029905   Top1 98.847656   Top5 100.000000   BatchTime 0.158239   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.031059   Top1 98.802083   Top5 100.000000   BatchTime 0.137277   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.031909   Top1 98.818359   Top5 100.000000   BatchTime 0.141017   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.030992   Top1 98.847656   Top5 100.000000   BatchTime 0.142973   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.031315   Top1 98.860677   Top5 100.000000   BatchTime 0.144301   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.032427   Top1 98.842076   Top5 100.000000   BatchTime 0.145322   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.032002   Top1 98.845215   Top5 100.000000   BatchTime 0.145910   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.031556   Top1 98.884549   Top5 100.000000   BatchTime 0.146402   LR 0.010000
INFO - ==> Top1: 98.886    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.458137   Top1 90.527344   Top5 99.570312   BatchTime 0.158872
INFO - Validation [12][   40/   40]   Loss 0.440626   Top1 90.570000   Top5 99.580000   BatchTime 0.116128
INFO - ==> Top1: 90.570    Top5: 99.580    Loss: 0.441
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.026587   Top1 98.925781   Top5 100.000000   BatchTime 0.198420   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.028188   Top1 98.955078   Top5 100.000000   BatchTime 0.156712   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.027774   Top1 98.990885   Top5 100.000000   BatchTime 0.133110   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.028434   Top1 98.950195   Top5 100.000000   BatchTime 0.137563   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.029311   Top1 98.949219   Top5 100.000000   BatchTime 0.140353   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.029030   Top1 98.974609   Top5 100.000000   BatchTime 0.142107   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.029165   Top1 98.962054   Top5 100.000000   BatchTime 0.143402   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.029758   Top1 98.935547   Top5 100.000000   BatchTime 0.144297   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.030281   Top1 98.910590   Top5 100.000000   BatchTime 0.144966   LR 0.010000
INFO - ==> Top1: 98.900    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.459975   Top1 90.390625   Top5 99.687500   BatchTime 0.158447
INFO - Validation [13][   40/   40]   Loss 0.436822   Top1 90.490000   Top5 99.680000   BatchTime 0.116103
INFO - ==> Top1: 90.490    Top5: 99.680    Loss: 0.437
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.025494   Top1 99.082031   Top5 100.000000   BatchTime 0.208090   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.028973   Top1 98.857422   Top5 100.000000   BatchTime 0.161714   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.030741   Top1 98.847656   Top5 100.000000   BatchTime 0.136708   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.030260   Top1 98.886719   Top5 100.000000   BatchTime 0.140096   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.029074   Top1 98.960938   Top5 100.000000   BatchTime 0.142329   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.028791   Top1 98.971354   Top5 100.000000   BatchTime 0.143093   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.028749   Top1 98.962054   Top5 100.000000   BatchTime 0.144299   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.029128   Top1 98.959961   Top5 100.000000   BatchTime 0.145007   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.029933   Top1 98.943142   Top5 100.000000   BatchTime 0.145522   LR 0.010000
INFO - ==> Top1: 98.940    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.453526   Top1 90.292969   Top5 99.492188   BatchTime 0.157691
INFO - Validation [14][   40/   40]   Loss 0.438445   Top1 90.480000   Top5 99.570000   BatchTime 0.116453
INFO - ==> Top1: 90.480    Top5: 99.570    Loss: 0.438
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.026282   Top1 99.062500   Top5 100.000000   BatchTime 0.195801   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.026688   Top1 99.111328   Top5 100.000000   BatchTime 0.154930   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.027384   Top1 99.075521   Top5 100.000000   BatchTime 0.134514   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.027687   Top1 99.067383   Top5 100.000000   BatchTime 0.135524   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.027618   Top1 99.046875   Top5 100.000000   BatchTime 0.138670   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.028269   Top1 99.023438   Top5 100.000000   BatchTime 0.140761   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.028472   Top1 99.015067   Top5 100.000000   BatchTime 0.142105   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.028892   Top1 99.003906   Top5 100.000000   BatchTime 0.143188   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.029495   Top1 98.990885   Top5 100.000000   BatchTime 0.144009   LR 0.010000
INFO - ==> Top1: 98.994    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.453889   Top1 90.312500   Top5 99.628906   BatchTime 0.158902
INFO - Validation [15][   40/   40]   Loss 0.441252   Top1 90.420000   Top5 99.680000   BatchTime 0.117056
INFO - ==> Top1: 90.420    Top5: 99.680    Loss: 0.441
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.026293   Top1 98.964844   Top5 100.000000   BatchTime 0.192214   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.027217   Top1 98.964844   Top5 100.000000   BatchTime 0.152775   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.028179   Top1 98.932292   Top5 100.000000   BatchTime 0.134520   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.027769   Top1 98.955078   Top5 100.000000   BatchTime 0.135002   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.027964   Top1 98.949219   Top5 100.000000   BatchTime 0.138314   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.027353   Top1 98.997396   Top5 100.000000   BatchTime 0.140366   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.027626   Top1 99.003906   Top5 100.000000   BatchTime 0.141673   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.028390   Top1 98.974609   Top5 100.000000   BatchTime 0.142777   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.028488   Top1 98.973524   Top5 100.000000   BatchTime 0.143639   LR 0.010000
INFO - ==> Top1: 98.980    Top5: 100.000    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.464504   Top1 90.625000   Top5 99.511719   BatchTime 0.158003
INFO - Validation [16][   40/   40]   Loss 0.449164   Top1 90.670000   Top5 99.640000   BatchTime 0.116249
INFO - ==> Top1: 90.670    Top5: 99.640    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.029159   Top1 99.082031   Top5 100.000000   BatchTime 0.190941   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.026081   Top1 99.169922   Top5 100.000000   BatchTime 0.152199   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.025835   Top1 99.166667   Top5 100.000000   BatchTime 0.132553   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.027195   Top1 99.082031   Top5 100.000000   BatchTime 0.132326   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.026392   Top1 99.132812   Top5 100.000000   BatchTime 0.136114   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.026575   Top1 99.134115   Top5 100.000000   BatchTime 0.138589   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.026584   Top1 99.118304   Top5 100.000000   BatchTime 0.140281   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.026665   Top1 99.108887   Top5 100.000000   BatchTime 0.141466   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.026871   Top1 99.097222   Top5 100.000000   BatchTime 0.142493   LR 0.010000
INFO - ==> Top1: 99.106    Top5: 100.000    Loss: 0.027
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.453575   Top1 90.468750   Top5 99.335938   BatchTime 0.159823
INFO - Validation [17][   40/   40]   Loss 0.441660   Top1 90.560000   Top5 99.540000   BatchTime 0.117102
INFO - ==> Top1: 90.560    Top5: 99.540    Loss: 0.442
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.027062   Top1 99.121094   Top5 100.000000   BatchTime 0.189818   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.024962   Top1 99.169922   Top5 100.000000   BatchTime 0.151371   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.025863   Top1 99.121094   Top5 100.000000   BatchTime 0.135426   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.025546   Top1 99.140625   Top5 100.000000   BatchTime 0.132119   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.026277   Top1 99.093750   Top5 99.996094   BatchTime 0.135975   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.027577   Top1 99.055990   Top5 99.996745   BatchTime 0.138370   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.027836   Top1 99.059710   Top5 99.997210   BatchTime 0.140185   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.027533   Top1 99.067383   Top5 99.995117   BatchTime 0.141401   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.028192   Top1 99.060330   Top5 99.995660   BatchTime 0.142024   LR 0.010000
INFO - ==> Top1: 99.068    Top5: 99.996    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.459623   Top1 90.664062   Top5 99.375000   BatchTime 0.159648
INFO - Validation [18][   40/   40]   Loss 0.448657   Top1 90.630000   Top5 99.540000   BatchTime 0.116793
INFO - ==> Top1: 90.630    Top5: 99.540    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.021685   Top1 99.355469   Top5 100.000000   BatchTime 0.184967   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.022089   Top1 99.267578   Top5 100.000000   BatchTime 0.148048   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.023411   Top1 99.205729   Top5 100.000000   BatchTime 0.132756   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.023164   Top1 99.204102   Top5 100.000000   BatchTime 0.126747   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.023543   Top1 99.171875   Top5 100.000000   BatchTime 0.132130   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.024153   Top1 99.153646   Top5 100.000000   BatchTime 0.135302   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.024553   Top1 99.154576   Top5 100.000000   BatchTime 0.137451   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.024875   Top1 99.150391   Top5 100.000000   BatchTime 0.139146   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.025442   Top1 99.118924   Top5 100.000000   BatchTime 0.140368   LR 0.010000
INFO - ==> Top1: 99.124    Top5: 100.000    Loss: 0.025
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.466178   Top1 90.429688   Top5 99.414062   BatchTime 0.161039
INFO - Validation [19][   40/   40]   Loss 0.445522   Top1 90.570000   Top5 99.530000   BatchTime 0.117493
INFO - ==> Top1: 90.570    Top5: 99.530    Loss: 0.446
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.024721   Top1 99.121094   Top5 100.000000   BatchTime 0.195816   LR 0.010000
INFO - Training [20][   40/  196]   Loss 0.026047   Top1 99.042969   Top5 100.000000   BatchTime 0.150702   LR 0.010000
INFO - Training [20][   60/  196]   Loss 0.028737   Top1 98.990885   Top5 100.000000   BatchTime 0.136461   LR 0.010000
INFO - Training [20][   80/  196]   Loss 0.028376   Top1 99.023438   Top5 100.000000   BatchTime 0.125893   LR 0.010000
INFO - Training [20][  100/  196]   Loss 0.027918   Top1 99.023438   Top5 100.000000   BatchTime 0.130979   LR 0.010000
INFO - Training [20][  120/  196]   Loss 0.027641   Top1 99.049479   Top5 100.000000   BatchTime 0.134420   LR 0.010000
INFO - Training [20][  140/  196]   Loss 0.027383   Top1 99.059710   Top5 100.000000   BatchTime 0.136760   LR 0.010000
INFO - Training [20][  160/  196]   Loss 0.027788   Top1 99.057617   Top5 100.000000   BatchTime 0.138368   LR 0.010000
INFO - Training [20][  180/  196]   Loss 0.028319   Top1 99.058160   Top5 100.000000   BatchTime 0.139620   LR 0.010000
INFO - ==> Top1: 99.050    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.462125   Top1 90.585938   Top5 99.394531   BatchTime 0.160539
INFO - Validation [20][   40/   40]   Loss 0.448622   Top1 90.650000   Top5 99.530000   BatchTime 0.117197
INFO - ==> Top1: 90.650    Top5: 99.530    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.019054   Top1 99.257812   Top5 100.000000   BatchTime 0.210234   LR 0.010000
INFO - Training [21][   40/  196]   Loss 0.022475   Top1 99.150391   Top5 100.000000   BatchTime 0.155396   LR 0.010000
INFO - Training [21][   60/  196]   Loss 0.024051   Top1 99.114583   Top5 100.000000   BatchTime 0.142805   LR 0.010000
INFO - Training [21][   80/  196]   Loss 0.025666   Top1 99.091797   Top5 100.000000   BatchTime 0.128488   LR 0.010000
INFO - Training [21][  100/  196]   Loss 0.025807   Top1 99.082031   Top5 100.000000   BatchTime 0.132731   LR 0.010000
INFO - Training [21][  120/  196]   Loss 0.025527   Top1 99.091797   Top5 100.000000   BatchTime 0.135751   LR 0.010000
INFO - Training [21][  140/  196]   Loss 0.025405   Top1 99.095982   Top5 100.000000   BatchTime 0.137909   LR 0.010000
INFO - Training [21][  160/  196]   Loss 0.025655   Top1 99.094238   Top5 100.000000   BatchTime 0.139436   LR 0.010000
INFO - Training [21][  180/  196]   Loss 0.025905   Top1 99.092882   Top5 100.000000   BatchTime 0.140587   LR 0.010000
INFO - ==> Top1: 99.094    Top5: 100.000    Loss: 0.026
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.470151   Top1 90.175781   Top5 99.531250   BatchTime 0.158635
INFO - Validation [21][   40/   40]   Loss 0.461824   Top1 90.320000   Top5 99.620000   BatchTime 0.116092
INFO - ==> Top1: 90.320    Top5: 99.620    Loss: 0.462
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.031012   Top1 98.984375   Top5 100.000000   BatchTime 0.221345   LR 0.010000
INFO - Training [22][   40/  196]   Loss 0.027211   Top1 99.072266   Top5 100.000000   BatchTime 0.158771   LR 0.010000
INFO - Training [22][   60/  196]   Loss 0.026342   Top1 99.108073   Top5 100.000000   BatchTime 0.143760   LR 0.010000
INFO - Training [22][   80/  196]   Loss 0.025922   Top1 99.130859   Top5 100.000000   BatchTime 0.132687   LR 0.010000
INFO - Training [22][  100/  196]   Loss 0.025907   Top1 99.109375   Top5 100.000000   BatchTime 0.135974   LR 0.010000
INFO - Training [22][  120/  196]   Loss 0.025793   Top1 99.114583   Top5 100.000000   BatchTime 0.138577   LR 0.010000
INFO - Training [22][  140/  196]   Loss 0.026109   Top1 99.109933   Top5 100.000000   BatchTime 0.140326   LR 0.010000
INFO - Training [22][  160/  196]   Loss 0.025917   Top1 99.118652   Top5 100.000000   BatchTime 0.141492   LR 0.010000
INFO - Training [22][  180/  196]   Loss 0.026007   Top1 99.092882   Top5 100.000000   BatchTime 0.142462   LR 0.010000
INFO - ==> Top1: 99.084    Top5: 100.000    Loss: 0.026
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.446938   Top1 90.703125   Top5 99.550781   BatchTime 0.152260
INFO - Validation [22][   40/   40]   Loss 0.442373   Top1 90.730000   Top5 99.620000   BatchTime 0.113169
INFO - ==> Top1: 90.730    Top5: 99.620    Loss: 0.442
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.021535   Top1 99.140625   Top5 100.000000   BatchTime 0.219033   LR 0.010000
INFO - Training [23][   40/  196]   Loss 0.022148   Top1 99.169922   Top5 100.000000   BatchTime 0.158032   LR 0.010000
INFO - Training [23][   60/  196]   Loss 0.022438   Top1 99.166667   Top5 100.000000   BatchTime 0.143078   LR 0.010000
INFO - Training [23][   80/  196]   Loss 0.023715   Top1 99.179688   Top5 100.000000   BatchTime 0.130137   LR 0.010000
INFO - Training [23][  100/  196]   Loss 0.023731   Top1 99.171875   Top5 100.000000   BatchTime 0.130712   LR 0.010000
INFO - Training [23][  120/  196]   Loss 0.023910   Top1 99.169922   Top5 100.000000   BatchTime 0.134167   LR 0.010000
INFO - Training [23][  140/  196]   Loss 0.023722   Top1 99.182478   Top5 100.000000   BatchTime 0.136581   LR 0.010000
INFO - Training [23][  160/  196]   Loss 0.024197   Top1 99.174805   Top5 100.000000   BatchTime 0.138363   LR 0.010000
INFO - Training [23][  180/  196]   Loss 0.024297   Top1 99.175347   Top5 100.000000   BatchTime 0.139652   LR 0.010000
INFO - ==> Top1: 99.168    Top5: 100.000    Loss: 0.025
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.475016   Top1 90.156250   Top5 99.414062   BatchTime 0.159565
INFO - Validation [23][   40/   40]   Loss 0.461854   Top1 90.430000   Top5 99.530000   BatchTime 0.116576
INFO - ==> Top1: 90.430    Top5: 99.530    Loss: 0.462
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.021320   Top1 99.238281   Top5 100.000000   BatchTime 0.235508   LR 0.010000
INFO - Training [24][   40/  196]   Loss 0.021694   Top1 99.218750   Top5 100.000000   BatchTime 0.163196   LR 0.010000
INFO - Training [24][   60/  196]   Loss 0.022401   Top1 99.205729   Top5 100.000000   BatchTime 0.146828   LR 0.010000
INFO - Training [24][   80/  196]   Loss 0.023406   Top1 99.174805   Top5 100.000000   BatchTime 0.134872   LR 0.010000
INFO - Training [24][  100/  196]   Loss 0.024022   Top1 99.171875   Top5 100.000000   BatchTime 0.133328   LR 0.010000
INFO - Training [24][  120/  196]   Loss 0.023774   Top1 99.189453   Top5 100.000000   BatchTime 0.136278   LR 0.010000
INFO - Training [24][  140/  196]   Loss 0.023617   Top1 99.204799   Top5 100.000000   BatchTime 0.138292   LR 0.010000
INFO - Training [24][  160/  196]   Loss 0.023606   Top1 99.201660   Top5 100.000000   BatchTime 0.139856   LR 0.010000
INFO - Training [24][  180/  196]   Loss 0.024906   Top1 99.160156   Top5 100.000000   BatchTime 0.140934   LR 0.010000
INFO - ==> Top1: 99.156    Top5: 100.000    Loss: 0.025
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.478948   Top1 90.742188   Top5 99.375000   BatchTime 0.159820
INFO - Validation [24][   40/   40]   Loss 0.464886   Top1 90.770000   Top5 99.550000   BatchTime 0.117816
INFO - ==> Top1: 90.770    Top5: 99.550    Loss: 0.465
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.023247   Top1 99.335938   Top5 100.000000   BatchTime 0.227800   LR 0.010000
INFO - Training [25][   40/  196]   Loss 0.021155   Top1 99.384766   Top5 100.000000   BatchTime 0.160387   LR 0.010000
INFO - Training [25][   60/  196]   Loss 0.022309   Top1 99.309896   Top5 100.000000   BatchTime 0.144920   LR 0.010000
INFO - Training [25][   80/  196]   Loss 0.024198   Top1 99.213867   Top5 100.000000   BatchTime 0.132594   LR 0.010000
INFO - Training [25][  100/  196]   Loss 0.025176   Top1 99.175781   Top5 100.000000   BatchTime 0.132196   LR 0.010000
INFO - Training [25][  120/  196]   Loss 0.024908   Top1 99.166667   Top5 100.000000   BatchTime 0.135333   LR 0.010000
INFO - Training [25][  140/  196]   Loss 0.024575   Top1 99.174107   Top5 100.000000   BatchTime 0.137569   LR 0.010000
INFO - Training [25][  160/  196]   Loss 0.024800   Top1 99.162598   Top5 100.000000   BatchTime 0.139086   LR 0.010000
INFO - Training [25][  180/  196]   Loss 0.024424   Top1 99.175347   Top5 100.000000   BatchTime 0.140378   LR 0.010000
INFO - ==> Top1: 99.158    Top5: 100.000    Loss: 0.025
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.480095   Top1 90.292969   Top5 99.394531   BatchTime 0.160291
INFO - Validation [25][   40/   40]   Loss 0.458020   Top1 90.580000   Top5 99.510000   BatchTime 0.117152
INFO - ==> Top1: 90.580    Top5: 99.510    Loss: 0.458
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.015810   Top1 99.492188   Top5 100.000000   BatchTime 0.241413   LR 0.010000
INFO - Training [26][   40/  196]   Loss 0.018963   Top1 99.375000   Top5 100.000000   BatchTime 0.163840   LR 0.010000
INFO - Training [26][   60/  196]   Loss 0.020569   Top1 99.316406   Top5 100.000000   BatchTime 0.149336   LR 0.010000
INFO - Training [26][   80/  196]   Loss 0.021436   Top1 99.287109   Top5 99.995117   BatchTime 0.136573   LR 0.010000
INFO - Training [26][  100/  196]   Loss 0.021943   Top1 99.257812   Top5 99.996094   BatchTime 0.133663   LR 0.010000
INFO - Training [26][  120/  196]   Loss 0.022908   Top1 99.225260   Top5 99.996745   BatchTime 0.136655   LR 0.010000
INFO - Training [26][  140/  196]   Loss 0.022554   Top1 99.241071   Top5 99.994420   BatchTime 0.138624   LR 0.010000
INFO - Training [26][  160/  196]   Loss 0.023021   Top1 99.238281   Top5 99.995117   BatchTime 0.140061   LR 0.010000
INFO - Training [26][  180/  196]   Loss 0.023479   Top1 99.227431   Top5 99.995660   BatchTime 0.141245   LR 0.010000
INFO - ==> Top1: 99.226    Top5: 99.996    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.484872   Top1 90.156250   Top5 99.550781   BatchTime 0.160661
INFO - Validation [26][   40/   40]   Loss 0.466915   Top1 90.540000   Top5 99.610000   BatchTime 0.117260
INFO - ==> Top1: 90.540    Top5: 99.610    Loss: 0.467
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.024780   Top1 99.238281   Top5 100.000000   BatchTime 0.235765   LR 0.010000
INFO - Training [27][   40/  196]   Loss 0.023580   Top1 99.189453   Top5 100.000000   BatchTime 0.166870   LR 0.010000
INFO - Training [27][   60/  196]   Loss 0.024683   Top1 99.147135   Top5 100.000000   BatchTime 0.147781   LR 0.010000
INFO - Training [27][   80/  196]   Loss 0.024910   Top1 99.101562   Top5 100.000000   BatchTime 0.136932   LR 0.010000
INFO - Training [27][  100/  196]   Loss 0.025063   Top1 99.101562   Top5 100.000000   BatchTime 0.130489   LR 0.010000
INFO - Training [27][  120/  196]   Loss 0.024079   Top1 99.127604   Top5 100.000000   BatchTime 0.133742   LR 0.010000
INFO - Training [27][  140/  196]   Loss 0.023486   Top1 99.143415   Top5 100.000000   BatchTime 0.136146   LR 0.010000
INFO - Training [27][  160/  196]   Loss 0.023529   Top1 99.145508   Top5 100.000000   BatchTime 0.138011   LR 0.010000
INFO - Training [27][  180/  196]   Loss 0.023436   Top1 99.149306   Top5 100.000000   BatchTime 0.139403   LR 0.010000
INFO - ==> Top1: 99.148    Top5: 100.000    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.483721   Top1 90.292969   Top5 99.335938   BatchTime 0.161473
INFO - Validation [27][   40/   40]   Loss 0.459833   Top1 90.520000   Top5 99.500000   BatchTime 0.118105
INFO - ==> Top1: 90.520    Top5: 99.500    Loss: 0.460
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.020933   Top1 99.199219   Top5 100.000000   BatchTime 0.239280   LR 0.010000
INFO - Training [28][   40/  196]   Loss 0.022064   Top1 99.238281   Top5 100.000000   BatchTime 0.175422   LR 0.010000
INFO - Training [28][   60/  196]   Loss 0.020483   Top1 99.290365   Top5 100.000000   BatchTime 0.152227   LR 0.010000
INFO - Training [28][   80/  196]   Loss 0.020979   Top1 99.257812   Top5 100.000000   BatchTime 0.141315   LR 0.010000
INFO - Training [28][  100/  196]   Loss 0.020492   Top1 99.269531   Top5 100.000000   BatchTime 0.131959   LR 0.010000
INFO - Training [28][  120/  196]   Loss 0.021051   Top1 99.225260   Top5 100.000000   BatchTime 0.134754   LR 0.010000
INFO - Training [28][  140/  196]   Loss 0.021196   Top1 99.221540   Top5 100.000000   BatchTime 0.137033   LR 0.010000
INFO - Training [28][  160/  196]   Loss 0.020845   Top1 99.250488   Top5 100.000000   BatchTime 0.138799   LR 0.010000
INFO - Training [28][  180/  196]   Loss 0.021303   Top1 99.238281   Top5 100.000000   BatchTime 0.140023   LR 0.010000
INFO - ==> Top1: 99.216    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.478783   Top1 90.664062   Top5 99.414062   BatchTime 0.160268
INFO - Validation [28][   40/   40]   Loss 0.461122   Top1 90.830000   Top5 99.560000   BatchTime 0.117982
INFO - ==> Top1: 90.830    Top5: 99.560    Loss: 0.461
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.015748   Top1 99.414062   Top5 100.000000   BatchTime 0.241432   LR 0.010000
INFO - Training [29][   40/  196]   Loss 0.016529   Top1 99.443359   Top5 100.000000   BatchTime 0.178411   LR 0.010000
INFO - Training [29][   60/  196]   Loss 0.017521   Top1 99.420573   Top5 100.000000   BatchTime 0.153213   LR 0.010000
INFO - Training [29][   80/  196]   Loss 0.018740   Top1 99.316406   Top5 100.000000   BatchTime 0.143887   LR 0.010000
INFO - Training [29][  100/  196]   Loss 0.019234   Top1 99.316406   Top5 100.000000   BatchTime 0.132438   LR 0.010000
INFO - Training [29][  120/  196]   Loss 0.020057   Top1 99.303385   Top5 100.000000   BatchTime 0.136436   LR 0.010000
INFO - Training [29][  140/  196]   Loss 0.020898   Top1 99.291295   Top5 100.000000   BatchTime 0.138403   LR 0.010000
INFO - Training [29][  160/  196]   Loss 0.021241   Top1 99.287109   Top5 100.000000   BatchTime 0.139873   LR 0.010000
INFO - Training [29][  180/  196]   Loss 0.021520   Top1 99.279514   Top5 100.000000   BatchTime 0.140925   LR 0.010000
INFO - ==> Top1: 99.274    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.483510   Top1 90.058594   Top5 99.375000   BatchTime 0.159791
INFO - Validation [29][   40/   40]   Loss 0.467497   Top1 90.250000   Top5 99.510000   BatchTime 0.117851
INFO - ==> Top1: 90.250    Top5: 99.510    Loss: 0.467
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.022003   Top1 99.238281   Top5 100.000000   BatchTime 0.243083   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.021288   Top1 99.218750   Top5 100.000000   BatchTime 0.183186   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.021903   Top1 99.218750   Top5 100.000000   BatchTime 0.155450   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.021262   Top1 99.218750   Top5 100.000000   BatchTime 0.145327   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.022189   Top1 99.238281   Top5 100.000000   BatchTime 0.134965   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.022057   Top1 99.241536   Top5 100.000000   BatchTime 0.136886   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.021572   Top1 99.260603   Top5 100.000000   BatchTime 0.138755   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.021168   Top1 99.274902   Top5 100.000000   BatchTime 0.140278   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.021314   Top1 99.281684   Top5 100.000000   BatchTime 0.141380   LR 0.001000
INFO - ==> Top1: 99.288    Top5: 100.000    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.454868   Top1 91.210938   Top5 99.433594   BatchTime 0.159978
INFO - Validation [30][   40/   40]   Loss 0.442234   Top1 91.150000   Top5 99.570000   BatchTime 0.116847
INFO - ==> Top1: 91.150    Top5: 99.570    Loss: 0.442
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.018348   Top1 99.472656   Top5 100.000000   BatchTime 0.242171   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.018527   Top1 99.472656   Top5 100.000000   BatchTime 0.179799   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.017263   Top1 99.505208   Top5 100.000000   BatchTime 0.154519   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.017390   Top1 99.443359   Top5 100.000000   BatchTime 0.143829   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.017678   Top1 99.429688   Top5 100.000000   BatchTime 0.132449   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.017474   Top1 99.430339   Top5 100.000000   BatchTime 0.136334   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.018070   Top1 99.400112   Top5 100.000000   BatchTime 0.138542   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.017894   Top1 99.416504   Top5 100.000000   BatchTime 0.139611   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.018213   Top1 99.398872   Top5 100.000000   BatchTime 0.140831   LR 0.001000
INFO - ==> Top1: 99.384    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.457074   Top1 90.546875   Top5 99.375000   BatchTime 0.160645
INFO - Validation [31][   40/   40]   Loss 0.444738   Top1 90.680000   Top5 99.510000   BatchTime 0.117283
INFO - ==> Top1: 90.680    Top5: 99.510    Loss: 0.445
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.018004   Top1 99.316406   Top5 100.000000   BatchTime 0.242569   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.017755   Top1 99.423828   Top5 100.000000   BatchTime 0.184224   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.018482   Top1 99.414062   Top5 100.000000   BatchTime 0.155490   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.018443   Top1 99.394531   Top5 100.000000   BatchTime 0.145052   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.018416   Top1 99.386719   Top5 100.000000   BatchTime 0.133838   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.018754   Top1 99.394531   Top5 100.000000   BatchTime 0.135476   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.018894   Top1 99.391741   Top5 100.000000   BatchTime 0.137639   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.018914   Top1 99.387207   Top5 100.000000   BatchTime 0.139172   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.018415   Top1 99.418403   Top5 100.000000   BatchTime 0.140362   LR 0.001000
INFO - ==> Top1: 99.430    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.454368   Top1 90.585938   Top5 99.453125   BatchTime 0.160040
INFO - Validation [32][   40/   40]   Loss 0.444571   Top1 90.790000   Top5 99.560000   BatchTime 0.117022
INFO - ==> Top1: 90.790    Top5: 99.560    Loss: 0.445
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.790   Top5: 99.560] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.017976   Top1 99.453125   Top5 99.980469   BatchTime 0.239858   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.017599   Top1 99.453125   Top5 99.990234   BatchTime 0.189634   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.018022   Top1 99.414062   Top5 99.993490   BatchTime 0.157842   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.017950   Top1 99.409180   Top5 99.995117   BatchTime 0.146818   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.017312   Top1 99.437500   Top5 99.996094   BatchTime 0.137136   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.017450   Top1 99.430339   Top5 99.996745   BatchTime 0.136482   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.017946   Top1 99.411272   Top5 99.997210   BatchTime 0.138567   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.018039   Top1 99.396973   Top5 99.997559   BatchTime 0.140011   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.018150   Top1 99.405382   Top5 99.997830   BatchTime 0.141154   LR 0.001000
INFO - ==> Top1: 99.400    Top5: 99.998    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.460219   Top1 90.820312   Top5 99.375000   BatchTime 0.160181
INFO - Validation [33][   40/   40]   Loss 0.445093   Top1 90.800000   Top5 99.550000   BatchTime 0.117378
INFO - ==> Top1: 90.800    Top5: 99.550    Loss: 0.445
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.800   Top5: 99.550] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.017246   Top1 99.433594   Top5 100.000000   BatchTime 0.240067   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.016494   Top1 99.404297   Top5 100.000000   BatchTime 0.194033   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.016340   Top1 99.440104   Top5 100.000000   BatchTime 0.157643   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.016506   Top1 99.428711   Top5 100.000000   BatchTime 0.146972   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.016593   Top1 99.433594   Top5 100.000000   BatchTime 0.138014   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.016479   Top1 99.420573   Top5 100.000000   BatchTime 0.136183   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.016525   Top1 99.439174   Top5 100.000000   BatchTime 0.138333   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.016640   Top1 99.436035   Top5 100.000000   BatchTime 0.139886   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.017009   Top1 99.422743   Top5 100.000000   BatchTime 0.141079   LR 0.001000
INFO - ==> Top1: 99.416    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.459479   Top1 90.800781   Top5 99.414062   BatchTime 0.159835
INFO - Validation [34][   40/   40]   Loss 0.446821   Top1 90.850000   Top5 99.520000   BatchTime 0.116950
INFO - ==> Top1: 90.850    Top5: 99.520    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.020794   Top1 99.296875   Top5 100.000000   BatchTime 0.242936   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.019741   Top1 99.355469   Top5 100.000000   BatchTime 0.196603   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.018824   Top1 99.394531   Top5 100.000000   BatchTime 0.162697   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.018290   Top1 99.404297   Top5 100.000000   BatchTime 0.149459   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.017892   Top1 99.417969   Top5 100.000000   BatchTime 0.141358   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.017921   Top1 99.414062   Top5 100.000000   BatchTime 0.135585   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.017587   Top1 99.428013   Top5 100.000000   BatchTime 0.137682   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.017403   Top1 99.421387   Top5 100.000000   BatchTime 0.139280   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.017143   Top1 99.435764   Top5 100.000000   BatchTime 0.140553   LR 0.001000
INFO - ==> Top1: 99.438    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.463526   Top1 90.605469   Top5 99.394531   BatchTime 0.159630
INFO - Validation [35][   40/   40]   Loss 0.446073   Top1 90.860000   Top5 99.570000   BatchTime 0.117241
INFO - ==> Top1: 90.860    Top5: 99.570    Loss: 0.446
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.019334   Top1 99.316406   Top5 100.000000   BatchTime 0.238182   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.017901   Top1 99.375000   Top5 100.000000   BatchTime 0.193902   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.017613   Top1 99.401042   Top5 100.000000   BatchTime 0.165411   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.016996   Top1 99.418945   Top5 100.000000   BatchTime 0.150694   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.016726   Top1 99.453125   Top5 100.000000   BatchTime 0.142616   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.016582   Top1 99.462891   Top5 100.000000   BatchTime 0.133272   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.016818   Top1 99.455915   Top5 100.000000   BatchTime 0.136681   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.016870   Top1 99.458008   Top5 100.000000   BatchTime 0.138417   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.017055   Top1 99.457465   Top5 100.000000   BatchTime 0.139735   LR 0.001000
INFO - ==> Top1: 99.444    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.469121   Top1 90.566406   Top5 99.394531   BatchTime 0.161553
INFO - Validation [36][   40/   40]   Loss 0.453467   Top1 90.810000   Top5 99.550000   BatchTime 0.116739
INFO - ==> Top1: 90.810    Top5: 99.550    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.016945   Top1 99.316406   Top5 100.000000   BatchTime 0.240843   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.017321   Top1 99.404297   Top5 99.990234   BatchTime 0.195758   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.017538   Top1 99.420573   Top5 99.993490   BatchTime 0.171703   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.017361   Top1 99.404297   Top5 99.995117   BatchTime 0.153417   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.016861   Top1 99.402344   Top5 99.996094   BatchTime 0.145212   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.017655   Top1 99.361979   Top5 99.996745   BatchTime 0.136620   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.017605   Top1 99.358259   Top5 99.997210   BatchTime 0.137646   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.016971   Top1 99.384766   Top5 99.997559   BatchTime 0.139282   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.016554   Top1 99.401042   Top5 99.997830   BatchTime 0.140517   LR 0.001000
INFO - ==> Top1: 99.402    Top5: 99.998    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.463041   Top1 90.605469   Top5 99.433594   BatchTime 0.161254
INFO - Validation [37][   40/   40]   Loss 0.455363   Top1 90.750000   Top5 99.590000   BatchTime 0.118271
INFO - ==> Top1: 90.750    Top5: 99.590    Loss: 0.455
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.013153   Top1 99.472656   Top5 100.000000   BatchTime 0.240247   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.014253   Top1 99.462891   Top5 100.000000   BatchTime 0.195315   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.014417   Top1 99.531250   Top5 100.000000   BatchTime 0.177209   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.014727   Top1 99.487305   Top5 100.000000   BatchTime 0.155690   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.015306   Top1 99.500000   Top5 100.000000   BatchTime 0.148510   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.015049   Top1 99.514974   Top5 100.000000   BatchTime 0.139546   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.015130   Top1 99.517299   Top5 100.000000   BatchTime 0.138505   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.014891   Top1 99.521484   Top5 100.000000   BatchTime 0.140010   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.014929   Top1 99.520399   Top5 100.000000   BatchTime 0.141163   LR 0.001000
INFO - ==> Top1: 99.506    Top5: 100.000    Loss: 0.015
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.466985   Top1 90.781250   Top5 99.453125   BatchTime 0.160031
INFO - Validation [38][   40/   40]   Loss 0.449936   Top1 91.000000   Top5 99.590000   BatchTime 0.116819
INFO - ==> Top1: 91.000    Top5: 99.590    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.016221   Top1 99.414062   Top5 100.000000   BatchTime 0.240103   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.017495   Top1 99.414062   Top5 100.000000   BatchTime 0.195201   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.016531   Top1 99.414062   Top5 100.000000   BatchTime 0.180870   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.016156   Top1 99.423828   Top5 100.000000   BatchTime 0.157927   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.016348   Top1 99.414062   Top5 100.000000   BatchTime 0.149038   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.016390   Top1 99.401042   Top5 100.000000   BatchTime 0.140949   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.016309   Top1 99.425223   Top5 100.000000   BatchTime 0.138066   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.016069   Top1 99.426270   Top5 100.000000   BatchTime 0.139565   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.016159   Top1 99.422743   Top5 100.000000   BatchTime 0.140725   LR 0.001000
INFO - ==> Top1: 99.424    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.464393   Top1 90.683594   Top5 99.375000   BatchTime 0.158699
INFO - Validation [39][   40/   40]   Loss 0.452542   Top1 90.820000   Top5 99.530000   BatchTime 0.117521
INFO - ==> Top1: 90.820    Top5: 99.530    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.013843   Top1 99.550781   Top5 100.000000   BatchTime 0.241433   LR 0.001000
INFO - Training [40][   40/  196]   Loss 0.016022   Top1 99.531250   Top5 100.000000   BatchTime 0.196084   LR 0.001000
INFO - Training [40][   60/  196]   Loss 0.016445   Top1 99.518229   Top5 100.000000   BatchTime 0.179733   LR 0.001000
INFO - Training [40][   80/  196]   Loss 0.016109   Top1 99.511719   Top5 100.000000   BatchTime 0.159731   LR 0.001000
INFO - Training [40][  100/  196]   Loss 0.016580   Top1 99.519531   Top5 100.000000   BatchTime 0.149786   LR 0.001000
INFO - Training [40][  120/  196]   Loss 0.016678   Top1 99.505208   Top5 100.000000   BatchTime 0.142924   LR 0.001000
INFO - Training [40][  140/  196]   Loss 0.016938   Top1 99.481027   Top5 100.000000   BatchTime 0.136149   LR 0.001000
INFO - Training [40][  160/  196]   Loss 0.016547   Top1 99.484863   Top5 100.000000   BatchTime 0.133228   LR 0.001000
INFO - Training [40][  180/  196]   Loss 0.016154   Top1 99.496528   Top5 100.000000   BatchTime 0.128475   LR 0.001000
INFO - ==> Top1: 99.506    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.456160   Top1 90.996094   Top5 99.433594   BatchTime 0.118546
INFO - Validation [40][   40/   40]   Loss 0.444209   Top1 91.090000   Top5 99.550000   BatchTime 0.076508
INFO - ==> Top1: 91.090    Top5: 99.550    Loss: 0.444
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.015437   Top1 99.453125   Top5 100.000000   BatchTime 0.179093   LR 0.001000
INFO - Training [41][   40/  196]   Loss 0.015045   Top1 99.453125   Top5 100.000000   BatchTime 0.132002   LR 0.001000
INFO - Training [41][   60/  196]   Loss 0.014992   Top1 99.440104   Top5 100.000000   BatchTime 0.117077   LR 0.001000
INFO - Training [41][   80/  196]   Loss 0.014637   Top1 99.453125   Top5 100.000000   BatchTime 0.109397   LR 0.001000
INFO - Training [41][  100/  196]   Loss 0.015170   Top1 99.449219   Top5 100.000000   BatchTime 0.104551   LR 0.001000
INFO - Training [41][  120/  196]   Loss 0.014871   Top1 99.462891   Top5 100.000000   BatchTime 0.101358   LR 0.001000
INFO - Training [41][  140/  196]   Loss 0.014522   Top1 99.478237   Top5 100.000000   BatchTime 0.098807   LR 0.001000
INFO - Training [41][  160/  196]   Loss 0.014752   Top1 99.467773   Top5 100.000000   BatchTime 0.096743   LR 0.001000
INFO - Training [41][  180/  196]   Loss 0.015212   Top1 99.466146   Top5 100.000000   BatchTime 0.095191   LR 0.001000
INFO - ==> Top1: 99.482    Top5: 100.000    Loss: 0.015
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.468601   Top1 90.742188   Top5 99.414062   BatchTime 0.119067
INFO - Validation [41][   40/   40]   Loss 0.452327   Top1 90.910000   Top5 99.560000   BatchTime 0.076668
INFO - ==> Top1: 90.910    Top5: 99.560    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.012867   Top1 99.511719   Top5 100.000000   BatchTime 0.177480   LR 0.001000
INFO - Training [42][   40/  196]   Loss 0.014564   Top1 99.501953   Top5 100.000000   BatchTime 0.131174   LR 0.001000
INFO - Training [42][   60/  196]   Loss 0.014028   Top1 99.557292   Top5 100.000000   BatchTime 0.115750   LR 0.001000
INFO - Training [42][   80/  196]   Loss 0.014234   Top1 99.550781   Top5 100.000000   BatchTime 0.107879   LR 0.001000
INFO - Training [42][  100/  196]   Loss 0.014253   Top1 99.562500   Top5 100.000000   BatchTime 0.103056   LR 0.001000
INFO - Training [42][  120/  196]   Loss 0.014354   Top1 99.544271   Top5 100.000000   BatchTime 0.100039   LR 0.001000
INFO - Training [42][  140/  196]   Loss 0.014466   Top1 99.525670   Top5 100.000000   BatchTime 0.098498   LR 0.001000
INFO - Training [42][  160/  196]   Loss 0.014457   Top1 99.531250   Top5 100.000000   BatchTime 0.096454   LR 0.001000
INFO - Training [42][  180/  196]   Loss 0.014039   Top1 99.548611   Top5 100.000000   BatchTime 0.094892   LR 0.001000
INFO - ==> Top1: 99.540    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.462023   Top1 90.957031   Top5 99.453125   BatchTime 0.118644
INFO - Validation [42][   40/   40]   Loss 0.449277   Top1 90.860000   Top5 99.580000   BatchTime 0.076468
INFO - ==> Top1: 90.860    Top5: 99.580    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.018755   Top1 99.335938   Top5 100.000000   BatchTime 0.177327   LR 0.001000
INFO - Training [43][   40/  196]   Loss 0.015992   Top1 99.414062   Top5 100.000000   BatchTime 0.130785   LR 0.001000
INFO - Training [43][   60/  196]   Loss 0.015837   Top1 99.427083   Top5 100.000000   BatchTime 0.115500   LR 0.001000
INFO - Training [43][   80/  196]   Loss 0.014897   Top1 99.477539   Top5 100.000000   BatchTime 0.107754   LR 0.001000
INFO - Training [43][  100/  196]   Loss 0.015182   Top1 99.476562   Top5 100.000000   BatchTime 0.103072   LR 0.001000
INFO - Training [43][  120/  196]   Loss 0.014669   Top1 99.495443   Top5 100.000000   BatchTime 0.099827   LR 0.001000
INFO - Training [43][  140/  196]   Loss 0.014809   Top1 99.492188   Top5 100.000000   BatchTime 0.097605   LR 0.001000
INFO - Training [43][  160/  196]   Loss 0.014855   Top1 99.497070   Top5 100.000000   BatchTime 0.096004   LR 0.001000
INFO - Training [43][  180/  196]   Loss 0.015020   Top1 99.494358   Top5 100.000000   BatchTime 0.094620   LR 0.001000
INFO - ==> Top1: 99.500    Top5: 100.000    Loss: 0.015
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.462392   Top1 90.937500   Top5 99.472656   BatchTime 0.119162
INFO - Validation [43][   40/   40]   Loss 0.449188   Top1 90.970000   Top5 99.580000   BatchTime 0.076731
INFO - ==> Top1: 90.970    Top5: 99.580    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.014705   Top1 99.414062   Top5 100.000000   BatchTime 0.177200   LR 0.001000
INFO - Training [44][   40/  196]   Loss 0.013397   Top1 99.501953   Top5 100.000000   BatchTime 0.130523   LR 0.001000
INFO - Training [44][   60/  196]   Loss 0.013751   Top1 99.479167   Top5 100.000000   BatchTime 0.115413   LR 0.001000
INFO - Training [44][   80/  196]   Loss 0.014020   Top1 99.492188   Top5 100.000000   BatchTime 0.107681   LR 0.001000
INFO - Training [44][  100/  196]   Loss 0.014386   Top1 99.476562   Top5 100.000000   BatchTime 0.103005   LR 0.001000
INFO - Training [44][  120/  196]   Loss 0.014144   Top1 99.488932   Top5 100.000000   BatchTime 0.099714   LR 0.001000
INFO - Training [44][  140/  196]   Loss 0.014124   Top1 99.497768   Top5 100.000000   BatchTime 0.097422   LR 0.001000
INFO - Training [44][  160/  196]   Loss 0.013998   Top1 99.511719   Top5 100.000000   BatchTime 0.095596   LR 0.001000
INFO - Training [44][  180/  196]   Loss 0.013964   Top1 99.505208   Top5 100.000000   BatchTime 0.094180   LR 0.001000
INFO - ==> Top1: 99.492    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.461794   Top1 90.820312   Top5 99.394531   BatchTime 0.118680
INFO - Validation [44][   40/   40]   Loss 0.447922   Top1 91.020000   Top5 99.580000   BatchTime 0.076422
INFO - ==> Top1: 91.020    Top5: 99.580    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.013351   Top1 99.570312   Top5 100.000000   BatchTime 0.177093   LR 0.001000
INFO - Training [45][   40/  196]   Loss 0.014152   Top1 99.443359   Top5 100.000000   BatchTime 0.130615   LR 0.001000
INFO - Training [45][   60/  196]   Loss 0.013362   Top1 99.531250   Top5 100.000000   BatchTime 0.115145   LR 0.001000
INFO - Training [45][   80/  196]   Loss 0.012784   Top1 99.580078   Top5 100.000000   BatchTime 0.107626   LR 0.001000
INFO - Training [45][  100/  196]   Loss 0.012867   Top1 99.574219   Top5 100.000000   BatchTime 0.102820   LR 0.001000
INFO - Training [45][  120/  196]   Loss 0.012773   Top1 99.570312   Top5 100.000000   BatchTime 0.099916   LR 0.001000
INFO - Training [45][  140/  196]   Loss 0.013105   Top1 99.564732   Top5 100.000000   BatchTime 0.097501   LR 0.001000
INFO - Training [45][  160/  196]   Loss 0.013331   Top1 99.567871   Top5 100.000000   BatchTime 0.095621   LR 0.001000
INFO - Training [45][  180/  196]   Loss 0.013395   Top1 99.574653   Top5 100.000000   BatchTime 0.094180   LR 0.001000
INFO - ==> Top1: 99.574    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.459615   Top1 90.800781   Top5 99.394531   BatchTime 0.118560
INFO - Validation [45][   40/   40]   Loss 0.446250   Top1 91.000000   Top5 99.530000   BatchTime 0.076395
INFO - ==> Top1: 91.000    Top5: 99.530    Loss: 0.446
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.013866   Top1 99.472656   Top5 100.000000   BatchTime 0.176724   LR 0.001000
INFO - Training [46][   40/  196]   Loss 0.014250   Top1 99.443359   Top5 100.000000   BatchTime 0.131075   LR 0.001000
INFO - Training [46][   60/  196]   Loss 0.014464   Top1 99.479167   Top5 100.000000   BatchTime 0.115145   LR 0.001000
INFO - Training [46][   80/  196]   Loss 0.013338   Top1 99.541016   Top5 100.000000   BatchTime 0.107396   LR 0.001000
INFO - Training [46][  100/  196]   Loss 0.013303   Top1 99.531250   Top5 100.000000   BatchTime 0.102542   LR 0.001000
INFO - Training [46][  120/  196]   Loss 0.013368   Top1 99.527995   Top5 100.000000   BatchTime 0.099419   LR 0.001000
INFO - Training [46][  140/  196]   Loss 0.013546   Top1 99.525670   Top5 100.000000   BatchTime 0.097121   LR 0.001000
INFO - Training [46][  160/  196]   Loss 0.013935   Top1 99.514160   Top5 100.000000   BatchTime 0.096068   LR 0.001000
INFO - Training [46][  180/  196]   Loss 0.014022   Top1 99.520399   Top5 100.000000   BatchTime 0.094529   LR 0.001000
INFO - ==> Top1: 99.520    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.462690   Top1 91.054688   Top5 99.433594   BatchTime 0.118694
INFO - Validation [46][   40/   40]   Loss 0.448832   Top1 91.020000   Top5 99.550000   BatchTime 0.076430
INFO - ==> Top1: 91.020    Top5: 99.550    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.011959   Top1 99.570312   Top5 100.000000   BatchTime 0.174419   LR 0.001000
INFO - Training [47][   40/  196]   Loss 0.012558   Top1 99.589844   Top5 100.000000   BatchTime 0.129388   LR 0.001000
INFO - Training [47][   60/  196]   Loss 0.013014   Top1 99.583333   Top5 100.000000   BatchTime 0.113863   LR 0.001000
INFO - Training [47][   80/  196]   Loss 0.012695   Top1 99.604492   Top5 100.000000   BatchTime 0.106618   LR 0.001000
INFO - Training [47][  100/  196]   Loss 0.013367   Top1 99.570312   Top5 100.000000   BatchTime 0.102335   LR 0.001000
INFO - Training [47][  120/  196]   Loss 0.012949   Top1 99.583333   Top5 100.000000   BatchTime 0.099213   LR 0.001000
INFO - Training [47][  140/  196]   Loss 0.013324   Top1 99.570312   Top5 100.000000   BatchTime 0.097113   LR 0.001000
INFO - Training [47][  160/  196]   Loss 0.013493   Top1 99.548340   Top5 100.000000   BatchTime 0.095355   LR 0.001000
INFO - Training [47][  180/  196]   Loss 0.013859   Top1 99.531250   Top5 100.000000   BatchTime 0.093956   LR 0.001000
INFO - ==> Top1: 99.526    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.464906   Top1 90.976562   Top5 99.472656   BatchTime 0.117998
INFO - Validation [47][   40/   40]   Loss 0.451248   Top1 90.970000   Top5 99.560000   BatchTime 0.076000
INFO - ==> Top1: 90.970    Top5: 99.560    Loss: 0.451
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.014115   Top1 99.511719   Top5 100.000000   BatchTime 0.176445   LR 0.001000
INFO - Training [48][   40/  196]   Loss 0.014753   Top1 99.482422   Top5 100.000000   BatchTime 0.130033   LR 0.001000
INFO - Training [48][   60/  196]   Loss 0.014316   Top1 99.518229   Top5 100.000000   BatchTime 0.114508   LR 0.001000
INFO - Training [48][   80/  196]   Loss 0.014647   Top1 99.492188   Top5 100.000000   BatchTime 0.106754   LR 0.001000
INFO - Training [48][  100/  196]   Loss 0.014667   Top1 99.503906   Top5 100.000000   BatchTime 0.102109   LR 0.001000
INFO - Training [48][  120/  196]   Loss 0.014101   Top1 99.531250   Top5 100.000000   BatchTime 0.098981   LR 0.001000
INFO - Training [48][  140/  196]   Loss 0.014622   Top1 99.503348   Top5 100.000000   BatchTime 0.096732   LR 0.001000
INFO - Training [48][  160/  196]   Loss 0.014297   Top1 99.519043   Top5 100.000000   BatchTime 0.094896   LR 0.001000
INFO - Training [48][  180/  196]   Loss 0.013979   Top1 99.535590   Top5 100.000000   BatchTime 0.093512   LR 0.001000
INFO - ==> Top1: 99.544    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.471396   Top1 90.937500   Top5 99.394531   BatchTime 0.118485
INFO - Validation [48][   40/   40]   Loss 0.452010   Top1 91.010000   Top5 99.560000   BatchTime 0.076207
INFO - ==> Top1: 91.010    Top5: 99.560    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.013178   Top1 99.570312   Top5 100.000000   BatchTime 0.174413   LR 0.001000
INFO - Training [49][   40/  196]   Loss 0.013957   Top1 99.482422   Top5 100.000000   BatchTime 0.128956   LR 0.001000
INFO - Training [49][   60/  196]   Loss 0.013736   Top1 99.518229   Top5 100.000000   BatchTime 0.113481   LR 0.001000
INFO - Training [49][   80/  196]   Loss 0.013411   Top1 99.536133   Top5 100.000000   BatchTime 0.105891   LR 0.001000
INFO - Training [49][  100/  196]   Loss 0.012971   Top1 99.554688   Top5 100.000000   BatchTime 0.101302   LR 0.001000
INFO - Training [49][  120/  196]   Loss 0.013493   Top1 99.527995   Top5 100.000000   BatchTime 0.098334   LR 0.001000
INFO - Training [49][  140/  196]   Loss 0.013976   Top1 99.517299   Top5 100.000000   BatchTime 0.096327   LR 0.001000
INFO - Training [49][  160/  196]   Loss 0.014032   Top1 99.536133   Top5 100.000000   BatchTime 0.094809   LR 0.001000
INFO - Training [49][  180/  196]   Loss 0.014265   Top1 99.520399   Top5 100.000000   BatchTime 0.093553   LR 0.001000
INFO - ==> Top1: 99.526    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.471677   Top1 90.898438   Top5 99.355469   BatchTime 0.118752
INFO - Validation [49][   40/   40]   Loss 0.451127   Top1 91.180000   Top5 99.520000   BatchTime 0.076353
INFO - ==> Top1: 91.180    Top5: 99.520    Loss: 0.451
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.013394   Top1 99.550781   Top5 100.000000   BatchTime 0.177143   LR 0.001000
INFO - Training [50][   40/  196]   Loss 0.014186   Top1 99.433594   Top5 100.000000   BatchTime 0.130297   LR 0.001000
INFO - Training [50][   60/  196]   Loss 0.014539   Top1 99.466146   Top5 100.000000   BatchTime 0.114738   LR 0.001000
INFO - Training [50][   80/  196]   Loss 0.014799   Top1 99.472656   Top5 100.000000   BatchTime 0.106783   LR 0.001000
INFO - Training [50][  100/  196]   Loss 0.014962   Top1 99.468750   Top5 100.000000   BatchTime 0.102031   LR 0.001000
INFO - Training [50][  120/  196]   Loss 0.014636   Top1 99.488932   Top5 100.000000   BatchTime 0.099221   LR 0.001000
INFO - Training [50][  140/  196]   Loss 0.014387   Top1 99.486607   Top5 100.000000   BatchTime 0.097014   LR 0.001000
INFO - Training [50][  160/  196]   Loss 0.014387   Top1 99.487305   Top5 100.000000   BatchTime 0.095939   LR 0.001000
INFO - Training [50][  180/  196]   Loss 0.014510   Top1 99.472656   Top5 100.000000   BatchTime 0.094472   LR 0.001000
INFO - ==> Top1: 99.476    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.464092   Top1 90.976562   Top5 99.375000   BatchTime 0.118858
INFO - Validation [50][   40/   40]   Loss 0.451559   Top1 91.120000   Top5 99.540000   BatchTime 0.076435
INFO - ==> Top1: 91.120    Top5: 99.540    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.015710   Top1 99.511719   Top5 100.000000   BatchTime 0.177656   LR 0.001000
INFO - Training [51][   40/  196]   Loss 0.013766   Top1 99.589844   Top5 100.000000   BatchTime 0.131089   LR 0.001000
INFO - Training [51][   60/  196]   Loss 0.013989   Top1 99.537760   Top5 100.000000   BatchTime 0.115862   LR 0.001000
INFO - Training [51][   80/  196]   Loss 0.013584   Top1 99.575195   Top5 100.000000   BatchTime 0.108175   LR 0.001000
INFO - Training [51][  100/  196]   Loss 0.013397   Top1 99.570312   Top5 100.000000   BatchTime 0.103441   LR 0.001000
INFO - Training [51][  120/  196]   Loss 0.013960   Top1 99.547526   Top5 100.000000   BatchTime 0.100335   LR 0.001000
INFO - Training [51][  140/  196]   Loss 0.014075   Top1 99.553571   Top5 100.000000   BatchTime 0.097880   LR 0.001000
INFO - Training [51][  160/  196]   Loss 0.013932   Top1 99.555664   Top5 100.000000   BatchTime 0.095920   LR 0.001000
INFO - Training [51][  180/  196]   Loss 0.013896   Top1 99.563802   Top5 100.000000   BatchTime 0.094497   LR 0.001000
INFO - ==> Top1: 99.552    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.470930   Top1 90.703125   Top5 99.414062   BatchTime 0.118586
INFO - Validation [51][   40/   40]   Loss 0.455807   Top1 90.930000   Top5 99.550000   BatchTime 0.076425
INFO - ==> Top1: 90.930    Top5: 99.550    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.012543   Top1 99.531250   Top5 100.000000   BatchTime 0.175746   LR 0.001000
INFO - Training [52][   40/  196]   Loss 0.013032   Top1 99.531250   Top5 100.000000   BatchTime 0.130723   LR 0.001000
INFO - Training [52][   60/  196]   Loss 0.013422   Top1 99.550781   Top5 100.000000   BatchTime 0.115455   LR 0.001000
INFO - Training [52][   80/  196]   Loss 0.012981   Top1 99.565430   Top5 100.000000   BatchTime 0.107668   LR 0.001000
INFO - Training [52][  100/  196]   Loss 0.013946   Top1 99.539062   Top5 100.000000   BatchTime 0.102880   LR 0.001000
INFO - Training [52][  120/  196]   Loss 0.013691   Top1 99.554036   Top5 100.000000   BatchTime 0.099858   LR 0.001000
INFO - Training [52][  140/  196]   Loss 0.013111   Top1 99.587054   Top5 100.000000   BatchTime 0.097470   LR 0.001000
INFO - Training [52][  160/  196]   Loss 0.013681   Top1 99.560547   Top5 100.000000   BatchTime 0.095615   LR 0.001000
INFO - Training [52][  180/  196]   Loss 0.014187   Top1 99.533420   Top5 100.000000   BatchTime 0.094135   LR 0.001000
INFO - ==> Top1: 99.538    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.466332   Top1 90.820312   Top5 99.492188   BatchTime 0.118727
INFO - Validation [52][   40/   40]   Loss 0.448765   Top1 90.930000   Top5 99.620000   BatchTime 0.076310
INFO - ==> Top1: 90.930    Top5: 99.620    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.015889   Top1 99.394531   Top5 100.000000   BatchTime 0.177477   LR 0.001000
INFO - Training [53][   40/  196]   Loss 0.013203   Top1 99.560547   Top5 100.000000   BatchTime 0.130675   LR 0.001000
INFO - Training [53][   60/  196]   Loss 0.012840   Top1 99.576823   Top5 100.000000   BatchTime 0.114842   LR 0.001000
INFO - Training [53][   80/  196]   Loss 0.012867   Top1 99.570312   Top5 100.000000   BatchTime 0.107077   LR 0.001000
INFO - Training [53][  100/  196]   Loss 0.013127   Top1 99.566406   Top5 100.000000   BatchTime 0.102577   LR 0.001000
INFO - Training [53][  120/  196]   Loss 0.013439   Top1 99.544271   Top5 100.000000   BatchTime 0.099556   LR 0.001000
INFO - Training [53][  140/  196]   Loss 0.013159   Top1 99.559152   Top5 100.000000   BatchTime 0.097575   LR 0.001000
INFO - Training [53][  160/  196]   Loss 0.013034   Top1 99.575195   Top5 100.000000   BatchTime 0.095799   LR 0.001000
INFO - Training [53][  180/  196]   Loss 0.012926   Top1 99.578993   Top5 100.000000   BatchTime 0.094382   LR 0.001000
INFO - ==> Top1: 99.570    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.470453   Top1 90.878906   Top5 99.394531   BatchTime 0.118166
INFO - Validation [53][   40/   40]   Loss 0.454776   Top1 90.890000   Top5 99.560000   BatchTime 0.076150
INFO - ==> Top1: 90.890    Top5: 99.560    Loss: 0.455
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.014506   Top1 99.531250   Top5 100.000000   BatchTime 0.175561   LR 0.001000
INFO - Training [54][   40/  196]   Loss 0.015927   Top1 99.501953   Top5 100.000000   BatchTime 0.129315   LR 0.001000
INFO - Training [54][   60/  196]   Loss 0.014103   Top1 99.557292   Top5 100.000000   BatchTime 0.114702   LR 0.001000
INFO - Training [54][   80/  196]   Loss 0.014086   Top1 99.555664   Top5 100.000000   BatchTime 0.106933   LR 0.001000
INFO - Training [54][  100/  196]   Loss 0.014351   Top1 99.531250   Top5 100.000000   BatchTime 0.102188   LR 0.001000
INFO - Training [54][  120/  196]   Loss 0.014036   Top1 99.567057   Top5 100.000000   BatchTime 0.099306   LR 0.001000
INFO - Training [54][  140/  196]   Loss 0.013660   Top1 99.575893   Top5 100.000000   BatchTime 0.096989   LR 0.001000
INFO - Training [54][  160/  196]   Loss 0.013075   Top1 99.594727   Top5 100.000000   BatchTime 0.095891   LR 0.001000
INFO - Training [54][  180/  196]   Loss 0.013027   Top1 99.585503   Top5 100.000000   BatchTime 0.094473   LR 0.001000
INFO - ==> Top1: 99.584    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.468519   Top1 90.898438   Top5 99.472656   BatchTime 0.121843
INFO - Validation [54][   40/   40]   Loss 0.454295   Top1 90.950000   Top5 99.570000   BatchTime 0.078290
INFO - ==> Top1: 90.950    Top5: 99.570    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.011485   Top1 99.648438   Top5 100.000000   BatchTime 0.181133   LR 0.001000
INFO - Training [55][   40/  196]   Loss 0.011612   Top1 99.609375   Top5 100.000000   BatchTime 0.134572   LR 0.001000
INFO - Training [55][   60/  196]   Loss 0.011565   Top1 99.609375   Top5 100.000000   BatchTime 0.118851   LR 0.001000
INFO - Training [55][   80/  196]   Loss 0.011807   Top1 99.594727   Top5 100.000000   BatchTime 0.110355   LR 0.001000
INFO - Training [55][  100/  196]   Loss 0.012232   Top1 99.582031   Top5 100.000000   BatchTime 0.105294   LR 0.001000
INFO - Training [55][  120/  196]   Loss 0.012252   Top1 99.589844   Top5 100.000000   BatchTime 0.101798   LR 0.001000
INFO - Training [55][  140/  196]   Loss 0.013109   Top1 99.547991   Top5 100.000000   BatchTime 0.099684   LR 0.001000
INFO - Training [55][  160/  196]   Loss 0.013018   Top1 99.570312   Top5 100.000000   BatchTime 0.097783   LR 0.001000
INFO - Training [55][  180/  196]   Loss 0.012954   Top1 99.583333   Top5 100.000000   BatchTime 0.096192   LR 0.001000
INFO - ==> Top1: 99.590    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.468102   Top1 90.781250   Top5 99.433594   BatchTime 0.122494
INFO - Validation [55][   40/   40]   Loss 0.450338   Top1 91.040000   Top5 99.570000   BatchTime 0.079309
INFO - ==> Top1: 91.040    Top5: 99.570    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.012289   Top1 99.667969   Top5 100.000000   BatchTime 0.178773   LR 0.001000
INFO - Training [56][   40/  196]   Loss 0.012641   Top1 99.667969   Top5 100.000000   BatchTime 0.130995   LR 0.001000
INFO - Training [56][   60/  196]   Loss 0.012305   Top1 99.667969   Top5 100.000000   BatchTime 0.115456   LR 0.001000
INFO - Training [56][   80/  196]   Loss 0.012349   Top1 99.643555   Top5 100.000000   BatchTime 0.108229   LR 0.001000
INFO - Training [56][  100/  196]   Loss 0.013067   Top1 99.625000   Top5 100.000000   BatchTime 0.103656   LR 0.001000
INFO - Training [56][  120/  196]   Loss 0.013126   Top1 99.632161   Top5 100.000000   BatchTime 0.100300   LR 0.001000
INFO - Training [56][  140/  196]   Loss 0.012835   Top1 99.623326   Top5 100.000000   BatchTime 0.097908   LR 0.001000
INFO - Training [56][  160/  196]   Loss 0.013365   Top1 99.599609   Top5 100.000000   BatchTime 0.096014   LR 0.001000
INFO - Training [56][  180/  196]   Loss 0.013299   Top1 99.600694   Top5 100.000000   BatchTime 0.094526   LR 0.001000
INFO - ==> Top1: 99.606    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.475249   Top1 90.976562   Top5 99.414062   BatchTime 0.119244
INFO - Validation [56][   40/   40]   Loss 0.456045   Top1 91.130000   Top5 99.560000   BatchTime 0.076851
INFO - ==> Top1: 91.130    Top5: 99.560    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 91.130   Top5: 99.560] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.012318   Top1 99.609375   Top5 100.000000   BatchTime 0.176276   LR 0.001000
INFO - Training [57][   40/  196]   Loss 0.012280   Top1 99.609375   Top5 100.000000   BatchTime 0.130445   LR 0.001000
INFO - Training [57][   60/  196]   Loss 0.012022   Top1 99.615885   Top5 100.000000   BatchTime 0.115232   LR 0.001000
INFO - Training [57][   80/  196]   Loss 0.012501   Top1 99.614258   Top5 100.000000   BatchTime 0.107876   LR 0.001000
INFO - Training [57][  100/  196]   Loss 0.012792   Top1 99.609375   Top5 100.000000   BatchTime 0.103145   LR 0.001000
INFO - Training [57][  120/  196]   Loss 0.012750   Top1 99.606120   Top5 100.000000   BatchTime 0.099854   LR 0.001000
INFO - Training [57][  140/  196]   Loss 0.012627   Top1 99.601004   Top5 100.000000   BatchTime 0.097474   LR 0.001000
INFO - Training [57][  160/  196]   Loss 0.012507   Top1 99.602051   Top5 100.000000   BatchTime 0.095585   LR 0.001000
INFO - Training [57][  180/  196]   Loss 0.012457   Top1 99.602865   Top5 100.000000   BatchTime 0.094117   LR 0.001000
INFO - ==> Top1: 99.596    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.469736   Top1 91.093750   Top5 99.433594   BatchTime 0.117954
INFO - Validation [57][   40/   40]   Loss 0.454394   Top1 91.160000   Top5 99.550000   BatchTime 0.076096
INFO - ==> Top1: 91.160    Top5: 99.550    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.012857   Top1 99.609375   Top5 100.000000   BatchTime 0.178040   LR 0.001000
INFO - Training [58][   40/  196]   Loss 0.013789   Top1 99.580078   Top5 100.000000   BatchTime 0.130709   LR 0.001000
INFO - Training [58][   60/  196]   Loss 0.013936   Top1 99.563802   Top5 100.000000   BatchTime 0.115191   LR 0.001000
INFO - Training [58][   80/  196]   Loss 0.013075   Top1 99.599609   Top5 100.000000   BatchTime 0.107996   LR 0.001000
INFO - Training [58][  100/  196]   Loss 0.012832   Top1 99.609375   Top5 100.000000   BatchTime 0.103544   LR 0.001000
INFO - Training [58][  120/  196]   Loss 0.012446   Top1 99.609375   Top5 100.000000   BatchTime 0.100826   LR 0.001000
INFO - Training [58][  140/  196]   Loss 0.012988   Top1 99.561942   Top5 100.000000   BatchTime 0.098783   LR 0.001000
INFO - Training [58][  160/  196]   Loss 0.013562   Top1 99.541016   Top5 100.000000   BatchTime 0.097226   LR 0.001000
INFO - Training [58][  180/  196]   Loss 0.013651   Top1 99.537760   Top5 100.000000   BatchTime 0.096180   LR 0.001000
INFO - ==> Top1: 99.544    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.479641   Top1 90.761719   Top5 99.453125   BatchTime 0.126767
INFO - Validation [58][   40/   40]   Loss 0.460857   Top1 90.850000   Top5 99.580000   BatchTime 0.083399
INFO - ==> Top1: 90.850    Top5: 99.580    Loss: 0.461
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.010925   Top1 99.667969   Top5 100.000000   BatchTime 0.194155   LR 0.001000
INFO - Training [59][   40/  196]   Loss 0.012298   Top1 99.638672   Top5 100.000000   BatchTime 0.157128   LR 0.001000
INFO - Training [59][   60/  196]   Loss 0.012701   Top1 99.570312   Top5 100.000000   BatchTime 0.146055   LR 0.001000
INFO - Training [59][   80/  196]   Loss 0.012550   Top1 99.570312   Top5 100.000000   BatchTime 0.140425   LR 0.001000
INFO - Training [59][  100/  196]   Loss 0.013122   Top1 99.558594   Top5 100.000000   BatchTime 0.137329   LR 0.001000
INFO - Training [59][  120/  196]   Loss 0.013060   Top1 99.567057   Top5 100.000000   BatchTime 0.135157   LR 0.001000
INFO - Training [59][  140/  196]   Loss 0.013008   Top1 99.567522   Top5 100.000000   BatchTime 0.133759   LR 0.001000
INFO - Training [59][  160/  196]   Loss 0.013688   Top1 99.553223   Top5 100.000000   BatchTime 0.132462   LR 0.001000
INFO - Training [59][  180/  196]   Loss 0.013456   Top1 99.557292   Top5 100.000000   BatchTime 0.131441   LR 0.001000
INFO - ==> Top1: 99.560    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.479521   Top1 90.566406   Top5 99.433594   BatchTime 0.143033
INFO - Validation [59][   40/   40]   Loss 0.460271   Top1 90.860000   Top5 99.610000   BatchTime 0.099298
INFO - ==> Top1: 90.860    Top5: 99.610    Loss: 0.460
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [60][   20/  196]   Loss 0.011517   Top1 99.628906   Top5 100.000000   BatchTime 0.217670   LR 0.000100
INFO - Training [60][   40/  196]   Loss 0.011288   Top1 99.667969   Top5 100.000000   BatchTime 0.171044   LR 0.000100
INFO - Training [60][   60/  196]   Loss 0.011946   Top1 99.654948   Top5 100.000000   BatchTime 0.155312   LR 0.000100
INFO - Training [60][   80/  196]   Loss 0.012874   Top1 99.628906   Top5 100.000000   BatchTime 0.147569   LR 0.000100
INFO - Training [60][  100/  196]   Loss 0.012323   Top1 99.656250   Top5 100.000000   BatchTime 0.142706   LR 0.000100
INFO - Training [60][  120/  196]   Loss 0.012091   Top1 99.645182   Top5 100.000000   BatchTime 0.139555   LR 0.000100
INFO - Training [60][  140/  196]   Loss 0.012071   Top1 99.640067   Top5 100.000000   BatchTime 0.137016   LR 0.000100
INFO - Training [60][  160/  196]   Loss 0.012142   Top1 99.641113   Top5 100.000000   BatchTime 0.133007   LR 0.000100
INFO - Training [60][  180/  196]   Loss 0.012409   Top1 99.626736   Top5 100.000000   BatchTime 0.128650   LR 0.000100
INFO - ==> Top1: 99.622    Top5: 100.000    Loss: 0.012
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 0.472325   Top1 90.664062   Top5 99.375000   BatchTime 0.125779
INFO - Validation [60][   40/   40]   Loss 0.459797   Top1 90.930000   Top5 99.530000   BatchTime 0.083315
INFO - ==> Top1: 90.930    Top5: 99.530    Loss: 0.460
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [61][   20/  196]   Loss 0.013573   Top1 99.550781   Top5 100.000000   BatchTime 0.217732   LR 0.000100
INFO - Training [61][   40/  196]   Loss 0.012485   Top1 99.599609   Top5 100.000000   BatchTime 0.170736   LR 0.000100
INFO - Training [61][   60/  196]   Loss 0.012203   Top1 99.576823   Top5 100.000000   BatchTime 0.155248   LR 0.000100
INFO - Training [61][   80/  196]   Loss 0.011575   Top1 99.599609   Top5 100.000000   BatchTime 0.147516   LR 0.000100
INFO - Training [61][  100/  196]   Loss 0.012017   Top1 99.601562   Top5 100.000000   BatchTime 0.142808   LR 0.000100
INFO - Training [61][  120/  196]   Loss 0.012333   Top1 99.606120   Top5 100.000000   BatchTime 0.139831   LR 0.000100
INFO - Training [61][  140/  196]   Loss 0.012592   Top1 99.606585   Top5 100.000000   BatchTime 0.137495   LR 0.000100
INFO - Training [61][  160/  196]   Loss 0.012984   Top1 99.594727   Top5 100.000000   BatchTime 0.135728   LR 0.000100
INFO - Training [61][  180/  196]   Loss 0.012958   Top1 99.600694   Top5 100.000000   BatchTime 0.134320   LR 0.000100
INFO - ==> Top1: 99.598    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 0.473589   Top1 90.957031   Top5 99.453125   BatchTime 0.142358
INFO - Validation [61][   40/   40]   Loss 0.457938   Top1 91.040000   Top5 99.570000   BatchTime 0.098942
INFO - ==> Top1: 91.040    Top5: 99.570    Loss: 0.458
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [62][   20/  196]   Loss 0.014780   Top1 99.531250   Top5 100.000000   BatchTime 0.217003   LR 0.000100
INFO - Training [62][   40/  196]   Loss 0.013556   Top1 99.560547   Top5 100.000000   BatchTime 0.170542   LR 0.000100
INFO - Training [62][   60/  196]   Loss 0.013363   Top1 99.557292   Top5 100.000000   BatchTime 0.154956   LR 0.000100
INFO - Training [62][   80/  196]   Loss 0.013205   Top1 99.575195   Top5 100.000000   BatchTime 0.147054   LR 0.000100
INFO - Training [62][  100/  196]   Loss 0.014054   Top1 99.542969   Top5 100.000000   BatchTime 0.141679   LR 0.000100
INFO - Training [62][  120/  196]   Loss 0.014218   Top1 99.531250   Top5 100.000000   BatchTime 0.133110   LR 0.000100
INFO - Training [62][  140/  196]   Loss 0.013929   Top1 99.550781   Top5 100.000000   BatchTime 0.128670   LR 0.000100
INFO - Training [62][  160/  196]   Loss 0.014030   Top1 99.536133   Top5 100.000000   BatchTime 0.125103   LR 0.000100
INFO - Training [62][  180/  196]   Loss 0.013527   Top1 99.552951   Top5 100.000000   BatchTime 0.121567   LR 0.000100
INFO - ==> Top1: 99.564    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 0.477251   Top1 90.820312   Top5 99.394531   BatchTime 0.141602
INFO - Validation [62][   40/   40]   Loss 0.457427   Top1 91.030000   Top5 99.540000   BatchTime 0.098882
INFO - ==> Top1: 91.030    Top5: 99.540    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 0.011248   Top1 99.667969   Top5 100.000000   BatchTime 0.216541   LR 0.000100
INFO - Training [63][   40/  196]   Loss 0.011811   Top1 99.638672   Top5 100.000000   BatchTime 0.172414   LR 0.000100
INFO - Training [63][   60/  196]   Loss 0.012578   Top1 99.622396   Top5 100.000000   BatchTime 0.156182   LR 0.000100
INFO - Training [63][   80/  196]   Loss 0.012203   Top1 99.638672   Top5 100.000000   BatchTime 0.148178   LR 0.000100
INFO - Training [63][  100/  196]   Loss 0.012502   Top1 99.609375   Top5 100.000000   BatchTime 0.143235   LR 0.000100
INFO - Training [63][  120/  196]   Loss 0.012606   Top1 99.599609   Top5 100.000000   BatchTime 0.139954   LR 0.000100
INFO - Training [63][  140/  196]   Loss 0.012803   Top1 99.595424   Top5 100.000000   BatchTime 0.137591   LR 0.000100
INFO - Training [63][  160/  196]   Loss 0.012965   Top1 99.584961   Top5 100.000000   BatchTime 0.135796   LR 0.000100
INFO - Training [63][  180/  196]   Loss 0.013048   Top1 99.578993   Top5 100.000000   BatchTime 0.134471   LR 0.000100
INFO - ==> Top1: 99.592    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 0.476097   Top1 90.859375   Top5 99.375000   BatchTime 0.140617
INFO - Validation [63][   40/   40]   Loss 0.455674   Top1 91.090000   Top5 99.570000   BatchTime 0.098289
INFO - ==> Top1: 91.090    Top5: 99.570    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 0.011097   Top1 99.628906   Top5 100.000000   BatchTime 0.214036   LR 0.000100
INFO - Training [64][   40/  196]   Loss 0.012189   Top1 99.580078   Top5 100.000000   BatchTime 0.168886   LR 0.000100
INFO - Training [64][   60/  196]   Loss 0.012193   Top1 99.589844   Top5 100.000000   BatchTime 0.146149   LR 0.000100
INFO - Training [64][   80/  196]   Loss 0.011950   Top1 99.594727   Top5 100.000000   BatchTime 0.134205   LR 0.000100
INFO - Training [64][  100/  196]   Loss 0.011424   Top1 99.628906   Top5 100.000000   BatchTime 0.127707   LR 0.000100
INFO - Training [64][  120/  196]   Loss 0.011817   Top1 99.596354   Top5 100.000000   BatchTime 0.124179   LR 0.000100
INFO - Training [64][  140/  196]   Loss 0.012098   Top1 99.589844   Top5 100.000000   BatchTime 0.118757   LR 0.000100
INFO - Training [64][  160/  196]   Loss 0.012039   Top1 99.597168   Top5 100.000000   BatchTime 0.120415   LR 0.000100
INFO - Training [64][  180/  196]   Loss 0.012686   Top1 99.581163   Top5 100.000000   BatchTime 0.120760   LR 0.000100
INFO - ==> Top1: 99.580    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [64][   20/   40]   Loss 0.480072   Top1 90.683594   Top5 99.472656   BatchTime 0.141545
INFO - Validation [64][   40/   40]   Loss 0.461412   Top1 90.930000   Top5 99.610000   BatchTime 0.099040
INFO - ==> Top1: 90.930    Top5: 99.610    Loss: 0.461
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [65][   20/  196]   Loss 0.011061   Top1 99.687500   Top5 100.000000   BatchTime 0.217773   LR 0.000100
INFO - Training [65][   40/  196]   Loss 0.012394   Top1 99.619141   Top5 100.000000   BatchTime 0.171031   LR 0.000100
INFO - Training [65][   60/  196]   Loss 0.012890   Top1 99.583333   Top5 100.000000   BatchTime 0.155288   LR 0.000100
INFO - Training [65][   80/  196]   Loss 0.012546   Top1 99.614258   Top5 100.000000   BatchTime 0.147412   LR 0.000100
INFO - Training [65][  100/  196]   Loss 0.013300   Top1 99.558594   Top5 100.000000   BatchTime 0.142915   LR 0.000100
INFO - Training [65][  120/  196]   Loss 0.013651   Top1 99.541016   Top5 100.000000   BatchTime 0.139907   LR 0.000100
INFO - Training [65][  140/  196]   Loss 0.013624   Top1 99.547991   Top5 100.000000   BatchTime 0.137579   LR 0.000100
INFO - Training [65][  160/  196]   Loss 0.013547   Top1 99.560547   Top5 100.000000   BatchTime 0.135722   LR 0.000100
INFO - Training [65][  180/  196]   Loss 0.013463   Top1 99.568142   Top5 100.000000   BatchTime 0.134372   LR 0.000100
INFO - ==> Top1: 99.566    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 0.476754   Top1 90.976562   Top5 99.453125   BatchTime 0.141576
INFO - Validation [65][   40/   40]   Loss 0.460958   Top1 91.050000   Top5 99.590000   BatchTime 0.098994
INFO - ==> Top1: 91.050    Top5: 99.590    Loss: 0.461
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [66][   20/  196]   Loss 0.013305   Top1 99.628906   Top5 100.000000   BatchTime 0.195785   LR 0.000100
INFO - Training [66][   40/  196]   Loss 0.015619   Top1 99.570312   Top5 100.000000   BatchTime 0.148632   LR 0.000100
INFO - Training [66][   60/  196]   Loss 0.014310   Top1 99.583333   Top5 100.000000   BatchTime 0.132962   LR 0.000100
INFO - Training [66][   80/  196]   Loss 0.015071   Top1 99.536133   Top5 100.000000   BatchTime 0.123846   LR 0.000100
INFO - Training [66][  100/  196]   Loss 0.014162   Top1 99.558594   Top5 100.000000   BatchTime 0.120343   LR 0.000100
INFO - Training [66][  120/  196]   Loss 0.014151   Top1 99.541016   Top5 100.000000   BatchTime 0.120968   LR 0.000100
INFO - Training [66][  140/  196]   Loss 0.013847   Top1 99.547991   Top5 100.000000   BatchTime 0.121364   LR 0.000100
INFO - Training [66][  160/  196]   Loss 0.013560   Top1 99.560547   Top5 100.000000   BatchTime 0.121601   LR 0.000100
INFO - Training [66][  180/  196]   Loss 0.013735   Top1 99.548611   Top5 100.000000   BatchTime 0.121761   LR 0.000100
INFO - ==> Top1: 99.558    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 0.469738   Top1 90.664062   Top5 99.375000   BatchTime 0.141130
INFO - Validation [66][   40/   40]   Loss 0.454138   Top1 90.790000   Top5 99.550000   BatchTime 0.097624
INFO - ==> Top1: 90.790    Top5: 99.550    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 0.010840   Top1 99.648438   Top5 100.000000   BatchTime 0.217514   LR 0.000100
INFO - Training [67][   40/  196]   Loss 0.010050   Top1 99.697266   Top5 100.000000   BatchTime 0.174090   LR 0.000100
INFO - Training [67][   60/  196]   Loss 0.011567   Top1 99.648438   Top5 100.000000   BatchTime 0.157315   LR 0.000100
INFO - Training [67][   80/  196]   Loss 0.012427   Top1 99.594727   Top5 100.000000   BatchTime 0.148886   LR 0.000100
INFO - Training [67][  100/  196]   Loss 0.012536   Top1 99.589844   Top5 100.000000   BatchTime 0.143744   LR 0.000100
INFO - Training [67][  120/  196]   Loss 0.013285   Top1 99.560547   Top5 100.000000   BatchTime 0.140453   LR 0.000100
INFO - Training [67][  140/  196]   Loss 0.013370   Top1 99.573103   Top5 100.000000   BatchTime 0.138155   LR 0.000100
INFO - Training [67][  160/  196]   Loss 0.013421   Top1 99.572754   Top5 100.000000   BatchTime 0.136206   LR 0.000100
INFO - Training [67][  180/  196]   Loss 0.013263   Top1 99.572483   Top5 100.000000   BatchTime 0.134704   LR 0.000100
INFO - ==> Top1: 99.574    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 0.474352   Top1 91.015625   Top5 99.375000   BatchTime 0.126782
INFO - Validation [67][   40/   40]   Loss 0.461017   Top1 90.990000   Top5 99.550000   BatchTime 0.082896
INFO - ==> Top1: 90.990    Top5: 99.550    Loss: 0.461
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 0.010739   Top1 99.707031   Top5 100.000000   BatchTime 0.182866   LR 0.000100
INFO - Training [68][   40/  196]   Loss 0.012480   Top1 99.677734   Top5 100.000000   BatchTime 0.148749   LR 0.000100
INFO - Training [68][   60/  196]   Loss 0.012863   Top1 99.641927   Top5 100.000000   BatchTime 0.139766   LR 0.000100
INFO - Training [68][   80/  196]   Loss 0.012686   Top1 99.628906   Top5 100.000000   BatchTime 0.135699   LR 0.000100
INFO - Training [68][  100/  196]   Loss 0.012939   Top1 99.613281   Top5 100.000000   BatchTime 0.133317   LR 0.000100
INFO - Training [68][  120/  196]   Loss 0.013342   Top1 99.580078   Top5 100.000000   BatchTime 0.131871   LR 0.000100
INFO - Training [68][  140/  196]   Loss 0.013635   Top1 99.564732   Top5 100.000000   BatchTime 0.130767   LR 0.000100
INFO - Training [68][  160/  196]   Loss 0.013806   Top1 99.558105   Top5 100.000000   BatchTime 0.129795   LR 0.000100
INFO - Training [68][  180/  196]   Loss 0.013986   Top1 99.548611   Top5 100.000000   BatchTime 0.129081   LR 0.000100
INFO - ==> Top1: 99.556    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.470692   Top1 91.074219   Top5 99.550781   BatchTime 0.142056
INFO - Validation [68][   40/   40]   Loss 0.453757   Top1 91.140000   Top5 99.670000   BatchTime 0.099165
INFO - ==> Top1: 91.140    Top5: 99.670    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 0.015797   Top1 99.414062   Top5 100.000000   BatchTime 0.219869   LR 0.000100
INFO - Training [69][   40/  196]   Loss 0.015028   Top1 99.501953   Top5 100.000000   BatchTime 0.172086   LR 0.000100
INFO - Training [69][   60/  196]   Loss 0.014352   Top1 99.524740   Top5 100.000000   BatchTime 0.155980   LR 0.000100
INFO - Training [69][   80/  196]   Loss 0.012824   Top1 99.580078   Top5 100.000000   BatchTime 0.147980   LR 0.000100
INFO - Training [69][  100/  196]   Loss 0.012330   Top1 99.597656   Top5 100.000000   BatchTime 0.143075   LR 0.000100
INFO - Training [69][  120/  196]   Loss 0.012891   Top1 99.570312   Top5 100.000000   BatchTime 0.139819   LR 0.000100
INFO - Training [69][  140/  196]   Loss 0.013027   Top1 99.570312   Top5 100.000000   BatchTime 0.137482   LR 0.000100
INFO - Training [69][  160/  196]   Loss 0.012977   Top1 99.570312   Top5 100.000000   BatchTime 0.133123   LR 0.000100
INFO - Training [69][  180/  196]   Loss 0.012960   Top1 99.572483   Top5 100.000000   BatchTime 0.128817   LR 0.000100
INFO - ==> Top1: 99.570    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [69][   20/   40]   Loss 0.472391   Top1 90.722656   Top5 99.375000   BatchTime 0.126107
INFO - Validation [69][   40/   40]   Loss 0.456229   Top1 90.990000   Top5 99.510000   BatchTime 0.081180
INFO - ==> Top1: 90.990    Top5: 99.510    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  70
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [70][   20/  196]   Loss 0.012627   Top1 99.531250   Top5 100.000000   BatchTime 0.215862   LR 0.000010
INFO - Training [70][   40/  196]   Loss 0.012420   Top1 99.599609   Top5 100.000000   BatchTime 0.170030   LR 0.000010
INFO - Training [70][   60/  196]   Loss 0.011858   Top1 99.615885   Top5 100.000000   BatchTime 0.154979   LR 0.000010
INFO - Training [70][   80/  196]   Loss 0.012496   Top1 99.580078   Top5 100.000000   BatchTime 0.147361   LR 0.000010
INFO - Training [70][  100/  196]   Loss 0.013099   Top1 99.558594   Top5 100.000000   BatchTime 0.142765   LR 0.000010
INFO - Training [70][  120/  196]   Loss 0.012755   Top1 99.573568   Top5 100.000000   BatchTime 0.139734   LR 0.000010
INFO - Training [70][  140/  196]   Loss 0.012384   Top1 99.595424   Top5 100.000000   BatchTime 0.137432   LR 0.000010
INFO - Training [70][  160/  196]   Loss 0.012270   Top1 99.592285   Top5 100.000000   BatchTime 0.135728   LR 0.000010
INFO - Training [70][  180/  196]   Loss 0.012215   Top1 99.594184   Top5 100.000000   BatchTime 0.134330   LR 0.000010
INFO - ==> Top1: 99.586    Top5: 100.000    Loss: 0.012
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [70][   20/   40]   Loss 0.470100   Top1 90.839844   Top5 99.394531   BatchTime 0.141608
INFO - Validation [70][   40/   40]   Loss 0.453894   Top1 91.110000   Top5 99.560000   BatchTime 0.098833
INFO - ==> Top1: 91.110    Top5: 99.560    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  71
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [71][   20/  196]   Loss 0.015272   Top1 99.531250   Top5 100.000000   BatchTime 0.217519   LR 0.000010
INFO - Training [71][   40/  196]   Loss 0.013452   Top1 99.599609   Top5 100.000000   BatchTime 0.170715   LR 0.000010
INFO - Training [71][   60/  196]   Loss 0.012212   Top1 99.635417   Top5 100.000000   BatchTime 0.155241   LR 0.000010
INFO - Training [71][   80/  196]   Loss 0.012044   Top1 99.633789   Top5 100.000000   BatchTime 0.147259   LR 0.000010
INFO - Training [71][  100/  196]   Loss 0.011719   Top1 99.632812   Top5 100.000000   BatchTime 0.143879   LR 0.000010
INFO - Training [71][  120/  196]   Loss 0.012667   Top1 99.609375   Top5 100.000000   BatchTime 0.134920   LR 0.000010
INFO - Training [71][  140/  196]   Loss 0.012702   Top1 99.598214   Top5 100.000000   BatchTime 0.130305   LR 0.000010
INFO - Training [71][  160/  196]   Loss 0.012437   Top1 99.611816   Top5 100.000000   BatchTime 0.126610   LR 0.000010
INFO - Training [71][  180/  196]   Loss 0.012492   Top1 99.607205   Top5 100.000000   BatchTime 0.122966   LR 0.000010
INFO - ==> Top1: 99.590    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [71][   20/   40]   Loss 0.475168   Top1 90.722656   Top5 99.433594   BatchTime 0.141265
INFO - Validation [71][   40/   40]   Loss 0.459020   Top1 90.890000   Top5 99.570000   BatchTime 0.098176
INFO - ==> Top1: 90.890    Top5: 99.570    Loss: 0.459
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  72
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [72][   20/  196]   Loss 0.012625   Top1 99.628906   Top5 100.000000   BatchTime 0.214654   LR 0.000010
INFO - Training [72][   40/  196]   Loss 0.012352   Top1 99.580078   Top5 100.000000   BatchTime 0.169580   LR 0.000010
INFO - Training [72][   60/  196]   Loss 0.014047   Top1 99.537760   Top5 100.000000   BatchTime 0.154342   LR 0.000010
INFO - Training [72][   80/  196]   Loss 0.014282   Top1 99.536133   Top5 100.000000   BatchTime 0.146645   LR 0.000010
INFO - Training [72][  100/  196]   Loss 0.014726   Top1 99.511719   Top5 100.000000   BatchTime 0.142074   LR 0.000010
INFO - Training [72][  120/  196]   Loss 0.014168   Top1 99.524740   Top5 100.000000   BatchTime 0.139098   LR 0.000010
INFO - Training [72][  140/  196]   Loss 0.014001   Top1 99.536830   Top5 100.000000   BatchTime 0.136964   LR 0.000010
INFO - Training [72][  160/  196]   Loss 0.014178   Top1 99.531250   Top5 100.000000   BatchTime 0.135233   LR 0.000010
INFO - Training [72][  180/  196]   Loss 0.013981   Top1 99.535590   Top5 100.000000   BatchTime 0.133877   LR 0.000010
INFO - ==> Top1: 99.540    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [72][   20/   40]   Loss 0.472666   Top1 90.917969   Top5 99.453125   BatchTime 0.145263
INFO - Validation [72][   40/   40]   Loss 0.453520   Top1 90.910000   Top5 99.590000   BatchTime 0.100832
INFO - ==> Top1: 90.910    Top5: 99.590    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  73
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [73][   20/  196]   Loss 0.011612   Top1 99.570312   Top5 100.000000   BatchTime 0.215363   LR 0.000010
INFO - Training [73][   40/  196]   Loss 0.013433   Top1 99.580078   Top5 100.000000   BatchTime 0.169271   LR 0.000010
INFO - Training [73][   60/  196]   Loss 0.013351   Top1 99.570312   Top5 100.000000   BatchTime 0.145307   LR 0.000010
INFO - Training [73][   80/  196]   Loss 0.014464   Top1 99.521484   Top5 100.000000   BatchTime 0.134478   LR 0.000010
INFO - Training [73][  100/  196]   Loss 0.014879   Top1 99.507812   Top5 100.000000   BatchTime 0.128169   LR 0.000010
INFO - Training [73][  120/  196]   Loss 0.015034   Top1 99.518229   Top5 100.000000   BatchTime 0.123411   LR 0.000010
INFO - Training [73][  140/  196]   Loss 0.014664   Top1 99.534040   Top5 100.000000   BatchTime 0.119064   LR 0.000010
INFO - Training [73][  160/  196]   Loss 0.014102   Top1 99.560547   Top5 100.000000   BatchTime 0.119633   LR 0.000010
INFO - Training [73][  180/  196]   Loss 0.013444   Top1 99.585503   Top5 100.000000   BatchTime 0.120076   LR 0.000010
INFO - ==> Top1: 99.566    Top5: 100.000    Loss: 0.014
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [73][   20/   40]   Loss 0.477458   Top1 90.664062   Top5 99.375000   BatchTime 0.141309
INFO - Validation [73][   40/   40]   Loss 0.461009   Top1 90.930000   Top5 99.540000   BatchTime 0.098913
INFO - ==> Top1: 90.930    Top5: 99.540    Loss: 0.461
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  74
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [74][   20/  196]   Loss 0.013757   Top1 99.648438   Top5 100.000000   BatchTime 0.216338   LR 0.000010
INFO - Training [74][   40/  196]   Loss 0.012842   Top1 99.687500   Top5 100.000000   BatchTime 0.170093   LR 0.000010
INFO - Training [74][   60/  196]   Loss 0.012229   Top1 99.674479   Top5 100.000000   BatchTime 0.154812   LR 0.000010
INFO - Training [74][   80/  196]   Loss 0.011184   Top1 99.707031   Top5 100.000000   BatchTime 0.147103   LR 0.000010
INFO - Training [74][  100/  196]   Loss 0.012069   Top1 99.683594   Top5 100.000000   BatchTime 0.142421   LR 0.000010
INFO - Training [74][  120/  196]   Loss 0.011996   Top1 99.677734   Top5 100.000000   BatchTime 0.139354   LR 0.000010
INFO - Training [74][  140/  196]   Loss 0.012156   Top1 99.659598   Top5 100.000000   BatchTime 0.137124   LR 0.000010
INFO - Training [74][  160/  196]   Loss 0.012310   Top1 99.628906   Top5 100.000000   BatchTime 0.135371   LR 0.000010
INFO - Training [74][  180/  196]   Loss 0.012360   Top1 99.626736   Top5 100.000000   BatchTime 0.134015   LR 0.000010
INFO - ==> Top1: 99.618    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [74][   20/   40]   Loss 0.467562   Top1 90.996094   Top5 99.414062   BatchTime 0.142028
INFO - Validation [74][   40/   40]   Loss 0.453970   Top1 91.030000   Top5 99.570000   BatchTime 0.099017
INFO - ==> Top1: 91.030    Top5: 99.570    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  75
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [75][   20/  196]   Loss 0.014632   Top1 99.531250   Top5 100.000000   BatchTime 0.199556   LR 0.000010
INFO - Training [75][   40/  196]   Loss 0.014150   Top1 99.511719   Top5 100.000000   BatchTime 0.151146   LR 0.000010
INFO - Training [75][   60/  196]   Loss 0.014277   Top1 99.492188   Top5 100.000000   BatchTime 0.135286   LR 0.000010
INFO - Training [75][   80/  196]   Loss 0.013391   Top1 99.536133   Top5 100.000000   BatchTime 0.123333   LR 0.000010
INFO - Training [75][  100/  196]   Loss 0.013124   Top1 99.535156   Top5 100.000000   BatchTime 0.122530   LR 0.000010
INFO - Training [75][  120/  196]   Loss 0.012675   Top1 99.560547   Top5 100.000000   BatchTime 0.122814   LR 0.000010
INFO - Training [75][  140/  196]   Loss 0.012842   Top1 99.556362   Top5 100.000000   BatchTime 0.123633   LR 0.000010
INFO - Training [75][  160/  196]   Loss 0.012744   Top1 99.572754   Top5 100.000000   BatchTime 0.123626   LR 0.000010
INFO - Training [75][  180/  196]   Loss 0.012664   Top1 99.565972   Top5 100.000000   BatchTime 0.123635   LR 0.000010
INFO - ==> Top1: 99.566    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [75][   20/   40]   Loss 0.471413   Top1 90.859375   Top5 99.492188   BatchTime 0.142763
INFO - Validation [75][   40/   40]   Loss 0.457189   Top1 90.990000   Top5 99.600000   BatchTime 0.099138
INFO - ==> Top1: 90.990    Top5: 99.600    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  76
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [76][   20/  196]   Loss 0.014349   Top1 99.550781   Top5 100.000000   BatchTime 0.214907   LR 0.000010
INFO - Training [76][   40/  196]   Loss 0.013025   Top1 99.589844   Top5 100.000000   BatchTime 0.169490   LR 0.000010
INFO - Training [76][   60/  196]   Loss 0.011894   Top1 99.628906   Top5 100.000000   BatchTime 0.154604   LR 0.000010
INFO - Training [76][   80/  196]   Loss 0.012073   Top1 99.624023   Top5 100.000000   BatchTime 0.146926   LR 0.000010
INFO - Training [76][  100/  196]   Loss 0.011983   Top1 99.625000   Top5 100.000000   BatchTime 0.142374   LR 0.000010
INFO - Training [76][  120/  196]   Loss 0.012477   Top1 99.586589   Top5 100.000000   BatchTime 0.139433   LR 0.000010
INFO - Training [76][  140/  196]   Loss 0.012089   Top1 99.620536   Top5 100.000000   BatchTime 0.137167   LR 0.000010
INFO - Training [76][  160/  196]   Loss 0.012689   Top1 99.609375   Top5 100.000000   BatchTime 0.135393   LR 0.000010
INFO - Training [76][  180/  196]   Loss 0.012619   Top1 99.615885   Top5 100.000000   BatchTime 0.133971   LR 0.000010
INFO - ==> Top1: 99.608    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [76][   20/   40]   Loss 0.471384   Top1 90.878906   Top5 99.375000   BatchTime 0.127876
INFO - Validation [76][   40/   40]   Loss 0.456607   Top1 90.960000   Top5 99.540000   BatchTime 0.085493
INFO - ==> Top1: 90.960    Top5: 99.540    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  77
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [77][   20/  196]   Loss 0.011230   Top1 99.550781   Top5 100.000000   BatchTime 0.195420   LR 0.000010
INFO - Training [77][   40/  196]   Loss 0.012052   Top1 99.580078   Top5 100.000000   BatchTime 0.160027   LR 0.000010
INFO - Training [77][   60/  196]   Loss 0.011790   Top1 99.596354   Top5 100.000000   BatchTime 0.148217   LR 0.000010
INFO - Training [77][   80/  196]   Loss 0.011745   Top1 99.614258   Top5 100.000000   BatchTime 0.142079   LR 0.000010
INFO - Training [77][  100/  196]   Loss 0.012199   Top1 99.601562   Top5 100.000000   BatchTime 0.138375   LR 0.000010
INFO - Training [77][  120/  196]   Loss 0.012424   Top1 99.593099   Top5 100.000000   BatchTime 0.136010   LR 0.000010
INFO - Training [77][  140/  196]   Loss 0.012672   Top1 99.584263   Top5 100.000000   BatchTime 0.134287   LR 0.000010
INFO - Training [77][  160/  196]   Loss 0.013022   Top1 99.572754   Top5 100.000000   BatchTime 0.132891   LR 0.000010
INFO - Training [77][  180/  196]   Loss 0.013023   Top1 99.585503   Top5 100.000000   BatchTime 0.131817   LR 0.000010
INFO - ==> Top1: 99.598    Top5: 100.000    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [77][   20/   40]   Loss 0.472604   Top1 90.683594   Top5 99.414062   BatchTime 0.140629
INFO - Validation [77][   40/   40]   Loss 0.459682   Top1 90.980000   Top5 99.580000   BatchTime 0.099093
INFO - ==> Top1: 90.980    Top5: 99.580    Loss: 0.460
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  78
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [78][   20/  196]   Loss 0.013107   Top1 99.628906   Top5 100.000000   BatchTime 0.217596   LR 0.000010
INFO - Training [78][   40/  196]   Loss 0.012786   Top1 99.619141   Top5 100.000000   BatchTime 0.170488   LR 0.000010
INFO - Training [78][   60/  196]   Loss 0.012456   Top1 99.622396   Top5 100.000000   BatchTime 0.154930   LR 0.000010
INFO - Training [78][   80/  196]   Loss 0.012979   Top1 99.599609   Top5 100.000000   BatchTime 0.147057   LR 0.000010
INFO - Training [78][  100/  196]   Loss 0.012626   Top1 99.625000   Top5 100.000000   BatchTime 0.142248   LR 0.000010
INFO - Training [78][  120/  196]   Loss 0.012052   Top1 99.648438   Top5 100.000000   BatchTime 0.139170   LR 0.000010
INFO - Training [78][  140/  196]   Loss 0.012318   Top1 99.626116   Top5 100.000000   BatchTime 0.136795   LR 0.000010
INFO - Training [78][  160/  196]   Loss 0.012356   Top1 99.616699   Top5 100.000000   BatchTime 0.130870   LR 0.000010
INFO - Training [78][  180/  196]   Loss 0.013260   Top1 99.587674   Top5 99.997830   BatchTime 0.127907   LR 0.000010
INFO - ==> Top1: 99.598    Top5: 99.998    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [78][   20/   40]   Loss 0.466565   Top1 90.761719   Top5 99.433594   BatchTime 0.127992
INFO - Validation [78][   40/   40]   Loss 0.453328   Top1 90.900000   Top5 99.590000   BatchTime 0.089513
INFO - ==> Top1: 90.900    Top5: 99.590    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  79
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [79][   20/  196]   Loss 0.013295   Top1 99.570312   Top5 100.000000   BatchTime 0.217724   LR 0.000010
INFO - Training [79][   40/  196]   Loss 0.012862   Top1 99.599609   Top5 100.000000   BatchTime 0.171012   LR 0.000010
INFO - Training [79][   60/  196]   Loss 0.013640   Top1 99.609375   Top5 100.000000   BatchTime 0.155633   LR 0.000010
INFO - Training [79][   80/  196]   Loss 0.013540   Top1 99.609375   Top5 100.000000   BatchTime 0.147605   LR 0.000010
INFO - Training [79][  100/  196]   Loss 0.013073   Top1 99.621094   Top5 100.000000   BatchTime 0.142989   LR 0.000010
INFO - Training [79][  120/  196]   Loss 0.013069   Top1 99.615885   Top5 100.000000   BatchTime 0.139833   LR 0.000010
INFO - Training [79][  140/  196]   Loss 0.013416   Top1 99.601004   Top5 99.997210   BatchTime 0.138188   LR 0.000010
INFO - Training [79][  160/  196]   Loss 0.013033   Top1 99.621582   Top5 99.997559   BatchTime 0.136502   LR 0.000010
INFO - Training [79][  180/  196]   Loss 0.013113   Top1 99.607205   Top5 99.997830   BatchTime 0.134789   LR 0.000010
INFO - ==> Top1: 99.614    Top5: 99.998    Loss: 0.013
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [79][   20/   40]   Loss 0.468417   Top1 91.015625   Top5 99.394531   BatchTime 0.142558
INFO - Validation [79][   40/   40]   Loss 0.457222   Top1 90.920000   Top5 99.560000   BatchTime 0.099165
INFO - ==> Top1: 90.920    Top5: 99.560    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.468417   Top1 91.015625   Top5 99.394531   BatchTime 0.140246
INFO - Validation [   40/   40]   Loss 0.457222   Top1 90.920000   Top5 99.560000   BatchTime 0.097678
INFO - ==> Top1: 90.920    Top5: 99.560    Loss: 0.457
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net