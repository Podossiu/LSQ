
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827.log
2022-11-04 00:28:27.806244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 00:28:27.955573: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 00:28:28.345380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 00:28:28.345431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 00:28:28.345437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/tb_runs
Files already downloaded and verified
hello
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
INFO - Inserted quantizers into the original model
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_15_epoch60_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.396584   Top1 90.097656   Top5 99.394531   BatchTime 0.195962
INFO - Validation [   40/   40]   Loss 0.378949   Top1 90.220000   Top5 99.520000   BatchTime 0.128391
INFO - ==> Top1: 90.220    Top5: 99.520    Loss: 0.379
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.060641   Top1 97.851562   Top5 99.980469   BatchTime 0.248982   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.060619   Top1 97.851562   Top5 99.990234   BatchTime 0.186302   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.060486   Top1 97.832031   Top5 99.986979   BatchTime 0.165319   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.060993   Top1 97.783203   Top5 99.990234   BatchTime 0.155187   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.061381   Top1 97.789062   Top5 99.988281   BatchTime 0.148806   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.061526   Top1 97.805990   Top5 99.990234   BatchTime 0.144766   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.061582   Top1 97.834821   Top5 99.991629   BatchTime 0.136335   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.062803   Top1 97.778320   Top5 99.990234   BatchTime 0.132227   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.063555   Top1 97.751736   Top5 99.991319   BatchTime 0.128606   LR 0.010000
INFO - ==> Top1: 97.704    Top5: 99.992    Loss: 0.065
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.419914   Top1 89.628906   Top5 99.472656   BatchTime 0.155464
INFO - Validation [0][   40/   40]   Loss 0.395590   Top1 90.130000   Top5 99.580000   BatchTime 0.106513
INFO - ==> Top1: 90.130    Top5: 99.580    Loss: 0.396
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.130   Top5: 99.580] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.067476   Top1 97.519531   Top5 100.000000   BatchTime 0.222475   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.066563   Top1 97.490234   Top5 100.000000   BatchTime 0.173322   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.066316   Top1 97.545573   Top5 99.993490   BatchTime 0.156868   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.065455   Top1 97.612305   Top5 99.995117   BatchTime 0.148664   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.064326   Top1 97.632812   Top5 99.996094   BatchTime 0.143665   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.063841   Top1 97.705078   Top5 99.996745   BatchTime 0.141144   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.063992   Top1 97.678571   Top5 99.997210   BatchTime 0.138592   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.064136   Top1 97.724609   Top5 99.997559   BatchTime 0.136713   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.065233   Top1 97.680122   Top5 99.997830   BatchTime 0.135203   LR 0.010000
INFO - ==> Top1: 97.664    Top5: 99.996    Loss: 0.066
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.412615   Top1 89.882812   Top5 99.414062   BatchTime 0.146939
INFO - Validation [1][   40/   40]   Loss 0.394522   Top1 90.250000   Top5 99.540000   BatchTime 0.101434
INFO - ==> Top1: 90.250    Top5: 99.540    Loss: 0.395
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.130   Top5: 99.580] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.058353   Top1 97.929688   Top5 100.000000   BatchTime 0.222403   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.058821   Top1 97.978516   Top5 100.000000   BatchTime 0.172682   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.059012   Top1 97.936198   Top5 100.000000   BatchTime 0.157434   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.060419   Top1 97.871094   Top5 100.000000   BatchTime 0.140173   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.059442   Top1 97.914062   Top5 100.000000   BatchTime 0.132602   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.060979   Top1 97.825521   Top5 99.996745   BatchTime 0.127498   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.062544   Top1 97.767857   Top5 99.997210   BatchTime 0.123323   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.063330   Top1 97.753906   Top5 99.997559   BatchTime 0.121000   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.064811   Top1 97.712674   Top5 99.997830   BatchTime 0.121227   LR 0.010000
INFO - ==> Top1: 97.698    Top5: 99.998    Loss: 0.065
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.408487   Top1 89.765625   Top5 99.453125   BatchTime 0.146476
INFO - Validation [2][   40/   40]   Loss 0.389740   Top1 89.990000   Top5 99.560000   BatchTime 0.101337
INFO - ==> Top1: 89.990    Top5: 99.560    Loss: 0.390
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.130   Top5: 99.580] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.049928   Top1 98.222656   Top5 100.000000   BatchTime 0.222225   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.053798   Top1 98.105469   Top5 100.000000   BatchTime 0.172814   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.057823   Top1 98.059896   Top5 100.000000   BatchTime 0.156406   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.059177   Top1 97.958984   Top5 99.990234   BatchTime 0.148267   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.060346   Top1 97.949219   Top5 99.984375   BatchTime 0.143351   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.060475   Top1 97.916667   Top5 99.983724   BatchTime 0.140105   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.059849   Top1 97.907366   Top5 99.986049   BatchTime 0.137644   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.060402   Top1 97.902832   Top5 99.985352   BatchTime 0.135786   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.061234   Top1 97.866753   Top5 99.986979   BatchTime 0.134358   LR 0.010000
INFO - ==> Top1: 97.890    Top5: 99.984    Loss: 0.061
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.412797   Top1 89.375000   Top5 99.414062   BatchTime 0.146563
INFO - Validation [3][   40/   40]   Loss 0.400980   Top1 89.880000   Top5 99.500000   BatchTime 0.101509
INFO - ==> Top1: 89.880    Top5: 99.500    Loss: 0.401
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.130   Top5: 99.580] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.061112   Top1 97.753906   Top5 100.000000   BatchTime 0.193533   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.054388   Top1 98.115234   Top5 100.000000   BatchTime 0.148744   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.056134   Top1 98.007812   Top5 99.993490   BatchTime 0.133233   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.057104   Top1 97.968750   Top5 99.995117   BatchTime 0.123547   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.057298   Top1 97.968750   Top5 99.992188   BatchTime 0.120234   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.057451   Top1 97.968750   Top5 99.993490   BatchTime 0.120866   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.057761   Top1 97.960379   Top5 99.994420   BatchTime 0.120687   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.058744   Top1 97.895508   Top5 99.992676   BatchTime 0.121021   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.059347   Top1 97.871094   Top5 99.993490   BatchTime 0.121216   LR 0.010000
INFO - ==> Top1: 97.862    Top5: 99.994    Loss: 0.060
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.404689   Top1 89.882812   Top5 99.433594   BatchTime 0.148008
INFO - Validation [4][   40/   40]   Loss 0.395532   Top1 90.180000   Top5 99.530000   BatchTime 0.101444
INFO - ==> Top1: 90.180    Top5: 99.530    Loss: 0.396
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.180   Top5: 99.530] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.054289   Top1 98.027344   Top5 100.000000   BatchTime 0.221621   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.052849   Top1 97.988281   Top5 100.000000   BatchTime 0.172492   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.055707   Top1 97.981771   Top5 100.000000   BatchTime 0.156235   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.055439   Top1 97.998047   Top5 99.995117   BatchTime 0.148093   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.055944   Top1 98.000000   Top5 99.996094   BatchTime 0.144501   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.057480   Top1 97.942708   Top5 99.996745   BatchTime 0.141101   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.058598   Top1 97.885045   Top5 99.997210   BatchTime 0.138561   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.058398   Top1 97.929688   Top5 99.995117   BatchTime 0.136553   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.058868   Top1 97.914497   Top5 99.993490   BatchTime 0.135017   LR 0.010000
INFO - ==> Top1: 97.898    Top5: 99.994    Loss: 0.059
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.406196   Top1 89.804688   Top5 99.492188   BatchTime 0.131322
INFO - Validation [5][   40/   40]   Loss 0.394825   Top1 90.070000   Top5 99.590000   BatchTime 0.087382
INFO - ==> Top1: 90.070    Top5: 99.590    Loss: 0.395
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.180   Top5: 99.530] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.058372   Top1 97.929688   Top5 100.000000   BatchTime 0.200281   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.055809   Top1 98.007812   Top5 99.990234   BatchTime 0.162094   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.057864   Top1 97.942708   Top5 99.993490   BatchTime 0.149299   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.054685   Top1 98.056641   Top5 99.995117   BatchTime 0.142889   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.056858   Top1 98.007812   Top5 99.980469   BatchTime 0.139030   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.056404   Top1 98.027344   Top5 99.980469   BatchTime 0.136587   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.056273   Top1 98.049665   Top5 99.983259   BatchTime 0.134724   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.056759   Top1 98.020020   Top5 99.982910   BatchTime 0.133236   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.057011   Top1 98.018663   Top5 99.984809   BatchTime 0.132118   LR 0.010000
INFO - ==> Top1: 98.006    Top5: 99.986    Loss: 0.057
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.416031   Top1 89.628906   Top5 99.433594   BatchTime 0.147746
INFO - Validation [6][   40/   40]   Loss 0.406433   Top1 89.800000   Top5 99.540000   BatchTime 0.102730
INFO - ==> Top1: 89.800    Top5: 99.540    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.180   Top5: 99.530] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.046804   Top1 98.339844   Top5 100.000000   BatchTime 0.222451   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.052047   Top1 98.271484   Top5 100.000000   BatchTime 0.172908   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.052712   Top1 98.151042   Top5 100.000000   BatchTime 0.156335   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.054550   Top1 98.032227   Top5 100.000000   BatchTime 0.148103   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.054999   Top1 98.054688   Top5 100.000000   BatchTime 0.143004   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.054628   Top1 98.076172   Top5 99.996745   BatchTime 0.139761   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.055953   Top1 98.021763   Top5 99.994420   BatchTime 0.136254   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.056366   Top1 97.985840   Top5 99.995117   BatchTime 0.130730   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.056212   Top1 97.983941   Top5 99.995660   BatchTime 0.127374   LR 0.010000
INFO - ==> Top1: 97.958    Top5: 99.996    Loss: 0.057
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.419651   Top1 89.648438   Top5 99.570312   BatchTime 0.146647
INFO - Validation [7][   40/   40]   Loss 0.407033   Top1 89.980000   Top5 99.610000   BatchTime 0.100885
INFO - ==> Top1: 89.980    Top5: 99.610    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.180   Top5: 99.530] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.048955   Top1 98.320312   Top5 100.000000   BatchTime 0.221344   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.052769   Top1 98.134766   Top5 100.000000   BatchTime 0.171579   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.053053   Top1 98.144531   Top5 100.000000   BatchTime 0.155687   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.053769   Top1 98.110352   Top5 100.000000   BatchTime 0.147590   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.052018   Top1 98.175781   Top5 100.000000   BatchTime 0.142824   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.052197   Top1 98.170573   Top5 100.000000   BatchTime 0.139594   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.053038   Top1 98.122210   Top5 100.000000   BatchTime 0.137282   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.053931   Top1 98.083496   Top5 99.997559   BatchTime 0.135573   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.053608   Top1 98.085938   Top5 99.997830   BatchTime 0.134215   LR 0.010000
INFO - ==> Top1: 98.090    Top5: 99.998    Loss: 0.054
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.426214   Top1 89.667969   Top5 99.414062   BatchTime 0.147136
INFO - Validation [8][   40/   40]   Loss 0.411542   Top1 90.000000   Top5 99.530000   BatchTime 0.101269
INFO - ==> Top1: 90.000    Top5: 99.530    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.180   Top5: 99.530] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.050377   Top1 98.281250   Top5 99.980469   BatchTime 0.223426   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.052823   Top1 98.085938   Top5 99.980469   BatchTime 0.173506   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.055044   Top1 98.033854   Top5 99.986979   BatchTime 0.156858   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.052622   Top1 98.134766   Top5 99.990234   BatchTime 0.145960   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.052189   Top1 98.187500   Top5 99.988281   BatchTime 0.135629   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.051020   Top1 98.238932   Top5 99.990234   BatchTime 0.131145   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.051069   Top1 98.236607   Top5 99.991629   BatchTime 0.126999   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.051372   Top1 98.215332   Top5 99.992676   BatchTime 0.122885   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.051829   Top1 98.181424   Top5 99.993490   BatchTime 0.122346   LR 0.010000
INFO - ==> Top1: 98.144    Top5: 99.992    Loss: 0.053
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.435874   Top1 89.531250   Top5 99.453125   BatchTime 0.147767
INFO - Validation [9][   40/   40]   Loss 0.413241   Top1 89.960000   Top5 99.590000   BatchTime 0.102072
INFO - ==> Top1: 89.960    Top5: 99.590    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.180   Top5: 99.530] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.042887   Top1 98.554688   Top5 99.980469   BatchTime 0.221997   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.045652   Top1 98.369141   Top5 99.990234   BatchTime 0.173137   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.046439   Top1 98.404948   Top5 99.986979   BatchTime 0.156898   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.047299   Top1 98.374023   Top5 99.990234   BatchTime 0.148487   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.048478   Top1 98.343750   Top5 99.992188   BatchTime 0.143659   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.050179   Top1 98.294271   Top5 99.990234   BatchTime 0.140463   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.050696   Top1 98.258929   Top5 99.991629   BatchTime 0.138059   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.050523   Top1 98.249512   Top5 99.992676   BatchTime 0.136196   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.050672   Top1 98.246528   Top5 99.991319   BatchTime 0.134697   LR 0.010000
INFO - ==> Top1: 98.260    Top5: 99.992    Loss: 0.051
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.423799   Top1 90.292969   Top5 99.433594   BatchTime 0.147540
INFO - Validation [10][   40/   40]   Loss 0.417944   Top1 90.240000   Top5 99.580000   BatchTime 0.101396
INFO - ==> Top1: 90.240    Top5: 99.580    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.044240   Top1 98.593750   Top5 100.000000   BatchTime 0.207524   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.046860   Top1 98.427734   Top5 100.000000   BatchTime 0.152334   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.049331   Top1 98.274740   Top5 100.000000   BatchTime 0.135756   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.048204   Top1 98.320312   Top5 100.000000   BatchTime 0.129146   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.049799   Top1 98.250000   Top5 99.996094   BatchTime 0.120763   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.050164   Top1 98.219401   Top5 99.996745   BatchTime 0.122007   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.050785   Top1 98.219866   Top5 99.997210   BatchTime 0.122266   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.050104   Top1 98.222656   Top5 99.997559   BatchTime 0.122404   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.051175   Top1 98.179253   Top5 99.995660   BatchTime 0.122476   LR 0.010000
INFO - ==> Top1: 98.176    Top5: 99.996    Loss: 0.052
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.438544   Top1 89.355469   Top5 99.492188   BatchTime 0.147298
INFO - Validation [11][   40/   40]   Loss 0.423315   Top1 89.830000   Top5 99.610000   BatchTime 0.099937
INFO - ==> Top1: 89.830    Top5: 99.610    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.056795   Top1 98.007812   Top5 100.000000   BatchTime 0.223993   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.050878   Top1 98.251953   Top5 100.000000   BatchTime 0.173952   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.053058   Top1 98.092448   Top5 100.000000   BatchTime 0.157063   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.051966   Top1 98.159180   Top5 100.000000   BatchTime 0.148864   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.050446   Top1 98.207031   Top5 100.000000   BatchTime 0.143796   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.050374   Top1 98.190104   Top5 100.000000   BatchTime 0.140524   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.050453   Top1 98.208705   Top5 100.000000   BatchTime 0.138108   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.050187   Top1 98.256836   Top5 99.997559   BatchTime 0.136179   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.049980   Top1 98.274740   Top5 99.997830   BatchTime 0.134649   LR 0.010000
INFO - ==> Top1: 98.262    Top5: 99.996    Loss: 0.050
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.445420   Top1 89.609375   Top5 99.414062   BatchTime 0.130796
INFO - Validation [12][   40/   40]   Loss 0.424337   Top1 89.930000   Top5 99.550000   BatchTime 0.082622
INFO - ==> Top1: 89.930    Top5: 99.550    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.049294   Top1 98.398438   Top5 99.980469   BatchTime 0.202260   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.048671   Top1 98.310547   Top5 99.990234   BatchTime 0.151139   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.049967   Top1 98.255208   Top5 99.993490   BatchTime 0.142147   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.049679   Top1 98.271484   Top5 99.995117   BatchTime 0.137460   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.049882   Top1 98.273438   Top5 99.992188   BatchTime 0.134687   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.048604   Top1 98.300781   Top5 99.990234   BatchTime 0.133033   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.048318   Top1 98.303571   Top5 99.988839   BatchTime 0.131693   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.047825   Top1 98.330078   Top5 99.990234   BatchTime 0.130636   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.047307   Top1 98.350694   Top5 99.991319   BatchTime 0.129841   LR 0.010000
INFO - ==> Top1: 98.338    Top5: 99.992    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.446198   Top1 89.433594   Top5 99.453125   BatchTime 0.149365
INFO - Validation [13][   40/   40]   Loss 0.422534   Top1 90.060000   Top5 99.520000   BatchTime 0.102576
INFO - ==> Top1: 90.060    Top5: 99.520    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.045284   Top1 98.496094   Top5 100.000000   BatchTime 0.224468   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.043721   Top1 98.554688   Top5 100.000000   BatchTime 0.174350   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.044650   Top1 98.509115   Top5 100.000000   BatchTime 0.157474   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.045542   Top1 98.500977   Top5 100.000000   BatchTime 0.149199   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.044632   Top1 98.484375   Top5 100.000000   BatchTime 0.144085   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.044427   Top1 98.476562   Top5 100.000000   BatchTime 0.140699   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.045079   Top1 98.429129   Top5 100.000000   BatchTime 0.138146   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.045495   Top1 98.413086   Top5 100.000000   BatchTime 0.134874   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.046723   Top1 98.344184   Top5 100.000000   BatchTime 0.130186   LR 0.010000
INFO - ==> Top1: 98.314    Top5: 99.998    Loss: 0.048
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.449734   Top1 89.882812   Top5 99.238281   BatchTime 0.132592
INFO - Validation [14][   40/   40]   Loss 0.429366   Top1 90.100000   Top5 99.460000   BatchTime 0.088375
INFO - ==> Top1: 90.100    Top5: 99.460    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.043554   Top1 98.320312   Top5 100.000000   BatchTime 0.223687   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.042332   Top1 98.476562   Top5 100.000000   BatchTime 0.173852   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.042227   Top1 98.430990   Top5 100.000000   BatchTime 0.157258   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.043303   Top1 98.427734   Top5 100.000000   BatchTime 0.149007   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.043248   Top1 98.437500   Top5 100.000000   BatchTime 0.143933   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.044830   Top1 98.395182   Top5 100.000000   BatchTime 0.140601   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.045755   Top1 98.370536   Top5 100.000000   BatchTime 0.138189   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.046273   Top1 98.344727   Top5 100.000000   BatchTime 0.136334   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.047004   Top1 98.346354   Top5 100.000000   BatchTime 0.134857   LR 0.010000
INFO - ==> Top1: 98.350    Top5: 100.000    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.450151   Top1 89.707031   Top5 99.316406   BatchTime 0.148634
INFO - Validation [15][   40/   40]   Loss 0.431194   Top1 90.150000   Top5 99.510000   BatchTime 0.101598
INFO - ==> Top1: 90.150    Top5: 99.510    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.050894   Top1 98.300781   Top5 100.000000   BatchTime 0.224610   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.048304   Top1 98.486328   Top5 100.000000   BatchTime 0.173965   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.049088   Top1 98.391927   Top5 100.000000   BatchTime 0.157102   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.047772   Top1 98.417969   Top5 100.000000   BatchTime 0.148782   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.047552   Top1 98.398438   Top5 100.000000   BatchTime 0.141402   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.047410   Top1 98.382161   Top5 100.000000   BatchTime 0.133686   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.047339   Top1 98.373326   Top5 99.997210   BatchTime 0.129238   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.046433   Top1 98.393555   Top5 99.995117   BatchTime 0.125670   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.046057   Top1 98.411458   Top5 99.995660   BatchTime 0.121881   LR 0.010000
INFO - ==> Top1: 98.410    Top5: 99.996    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.455042   Top1 89.804688   Top5 99.414062   BatchTime 0.147032
INFO - Validation [16][   40/   40]   Loss 0.435101   Top1 90.000000   Top5 99.540000   BatchTime 0.101677
INFO - ==> Top1: 90.000    Top5: 99.540    Loss: 0.435
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.049570   Top1 98.398438   Top5 100.000000   BatchTime 0.223633   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.045854   Top1 98.466797   Top5 100.000000   BatchTime 0.173771   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.044650   Top1 98.515625   Top5 100.000000   BatchTime 0.157090   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.045346   Top1 98.505859   Top5 100.000000   BatchTime 0.148972   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.044541   Top1 98.511719   Top5 100.000000   BatchTime 0.144067   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.044473   Top1 98.515625   Top5 100.000000   BatchTime 0.140679   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.044204   Top1 98.521205   Top5 100.000000   BatchTime 0.138337   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.043553   Top1 98.544922   Top5 100.000000   BatchTime 0.136461   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.043896   Top1 98.530816   Top5 100.000000   BatchTime 0.134996   LR 0.010000
INFO - ==> Top1: 98.500    Top5: 100.000    Loss: 0.044
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.462957   Top1 89.785156   Top5 99.472656   BatchTime 0.147920
INFO - Validation [17][   40/   40]   Loss 0.438178   Top1 90.110000   Top5 99.580000   BatchTime 0.101877
INFO - ==> Top1: 90.110    Top5: 99.580    Loss: 0.438
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.044959   Top1 98.515625   Top5 100.000000   BatchTime 0.225906   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.042011   Top1 98.554688   Top5 100.000000   BatchTime 0.168258   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.040557   Top1 98.606771   Top5 100.000000   BatchTime 0.144737   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.039986   Top1 98.613281   Top5 100.000000   BatchTime 0.134205   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.039939   Top1 98.593750   Top5 100.000000   BatchTime 0.127816   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.041156   Top1 98.551432   Top5 100.000000   BatchTime 0.121761   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.041914   Top1 98.515625   Top5 100.000000   BatchTime 0.121468   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.041550   Top1 98.510742   Top5 100.000000   BatchTime 0.121710   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.041537   Top1 98.491753   Top5 100.000000   BatchTime 0.121881   LR 0.010000
INFO - ==> Top1: 98.506    Top5: 100.000    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.476245   Top1 89.394531   Top5 99.550781   BatchTime 0.149942
INFO - Validation [18][   40/   40]   Loss 0.449382   Top1 89.860000   Top5 99.620000   BatchTime 0.102818
INFO - ==> Top1: 89.860    Top5: 99.620    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.035645   Top1 98.750000   Top5 100.000000   BatchTime 0.224923   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.036157   Top1 98.769531   Top5 100.000000   BatchTime 0.174493   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.038208   Top1 98.658854   Top5 100.000000   BatchTime 0.157847   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.038767   Top1 98.671875   Top5 100.000000   BatchTime 0.149336   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.038233   Top1 98.710938   Top5 100.000000   BatchTime 0.144539   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.039453   Top1 98.675130   Top5 100.000000   BatchTime 0.140907   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.039119   Top1 98.688616   Top5 100.000000   BatchTime 0.138506   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.039691   Top1 98.652344   Top5 100.000000   BatchTime 0.136628   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.040545   Top1 98.619792   Top5 100.000000   BatchTime 0.135218   LR 0.010000
INFO - ==> Top1: 98.588    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.463009   Top1 89.843750   Top5 99.433594   BatchTime 0.144214
INFO - Validation [19][   40/   40]   Loss 0.434606   Top1 90.130000   Top5 99.550000   BatchTime 0.100383
INFO - ==> Top1: 90.130    Top5: 99.550    Loss: 0.435
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.220   Top5: 99.520] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.043112   Top1 98.496094   Top5 100.000000   BatchTime 0.206599   LR 0.001000
INFO - Training [20][   40/  196]   Loss 0.043536   Top1 98.457031   Top5 100.000000   BatchTime 0.154631   LR 0.001000
INFO - Training [20][   60/  196]   Loss 0.043812   Top1 98.502604   Top5 100.000000   BatchTime 0.133233   LR 0.001000
INFO - Training [20][   80/  196]   Loss 0.043539   Top1 98.491211   Top5 100.000000   BatchTime 0.130581   LR 0.001000
INFO - Training [20][  100/  196]   Loss 0.042302   Top1 98.566406   Top5 100.000000   BatchTime 0.129315   LR 0.001000
INFO - Training [20][  120/  196]   Loss 0.042872   Top1 98.538411   Top5 100.000000   BatchTime 0.128433   LR 0.001000
INFO - Training [20][  140/  196]   Loss 0.043012   Top1 98.523996   Top5 100.000000   BatchTime 0.127755   LR 0.001000
INFO - Training [20][  160/  196]   Loss 0.042631   Top1 98.540039   Top5 100.000000   BatchTime 0.127135   LR 0.001000
INFO - Training [20][  180/  196]   Loss 0.042250   Top1 98.552517   Top5 100.000000   BatchTime 0.126708   LR 0.001000
INFO - ==> Top1: 98.560    Top5: 100.000    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.442953   Top1 89.921875   Top5 99.335938   BatchTime 0.147365
INFO - Validation [20][   40/   40]   Loss 0.421361   Top1 90.250000   Top5 99.500000   BatchTime 0.101508
INFO - ==> Top1: 90.250    Top5: 99.500    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 90.250   Top5: 99.500] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 90.240   Top5: 99.580] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.033586   Top1 98.789062   Top5 100.000000   BatchTime 0.222194   LR 0.001000
INFO - Training [21][   40/  196]   Loss 0.036977   Top1 98.769531   Top5 100.000000   BatchTime 0.173833   LR 0.001000
INFO - Training [21][   60/  196]   Loss 0.037722   Top1 98.743490   Top5 100.000000   BatchTime 0.157082   LR 0.001000
INFO - Training [21][   80/  196]   Loss 0.038069   Top1 98.686523   Top5 100.000000   BatchTime 0.148741   LR 0.001000
INFO - Training [21][  100/  196]   Loss 0.038301   Top1 98.671875   Top5 100.000000   BatchTime 0.143698   LR 0.001000
INFO - Training [21][  120/  196]   Loss 0.038077   Top1 98.662109   Top5 100.000000   BatchTime 0.140400   LR 0.001000
INFO - Training [21][  140/  196]   Loss 0.037883   Top1 98.688616   Top5 100.000000   BatchTime 0.137940   LR 0.001000
INFO - Training [21][  160/  196]   Loss 0.037752   Top1 98.691406   Top5 100.000000   BatchTime 0.136029   LR 0.001000
INFO - Training [21][  180/  196]   Loss 0.038184   Top1 98.676215   Top5 99.997830   BatchTime 0.134488   LR 0.001000
INFO - ==> Top1: 98.668    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.444240   Top1 90.156250   Top5 99.414062   BatchTime 0.137739
INFO - Validation [21][   40/   40]   Loss 0.420441   Top1 90.380000   Top5 99.550000   BatchTime 0.089099
INFO - ==> Top1: 90.380    Top5: 99.550    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [21][Top1: 90.380   Top5: 99.550] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 90.250   Top5: 99.500] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.033195   Top1 98.906250   Top5 100.000000   BatchTime 0.229794   LR 0.001000
INFO - Training [22][   40/  196]   Loss 0.037358   Top1 98.818359   Top5 100.000000   BatchTime 0.176640   LR 0.001000
INFO - Training [22][   60/  196]   Loss 0.034722   Top1 98.919271   Top5 100.000000   BatchTime 0.159200   LR 0.001000
INFO - Training [22][   80/  196]   Loss 0.033930   Top1 98.950195   Top5 100.000000   BatchTime 0.151816   LR 0.001000
INFO - Training [22][  100/  196]   Loss 0.034554   Top1 98.914062   Top5 100.000000   BatchTime 0.146254   LR 0.001000
INFO - Training [22][  120/  196]   Loss 0.034069   Top1 98.899740   Top5 100.000000   BatchTime 0.142634   LR 0.001000
INFO - Training [22][  140/  196]   Loss 0.034377   Top1 98.878348   Top5 100.000000   BatchTime 0.139913   LR 0.001000
INFO - Training [22][  160/  196]   Loss 0.035065   Top1 98.864746   Top5 100.000000   BatchTime 0.137759   LR 0.001000
INFO - Training [22][  180/  196]   Loss 0.035115   Top1 98.856337   Top5 100.000000   BatchTime 0.136122   LR 0.001000
INFO - ==> Top1: 98.834    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.445393   Top1 90.605469   Top5 99.511719   BatchTime 0.146780
INFO - Validation [22][   40/   40]   Loss 0.421722   Top1 90.750000   Top5 99.620000   BatchTime 0.101893
INFO - ==> Top1: 90.750    Top5: 99.620    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [21][Top1: 90.380   Top5: 99.550] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 90.250   Top5: 99.540] Sparsity : 0.855
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.030247   Top1 98.945312   Top5 100.000000   BatchTime 0.223753   LR 0.001000
INFO - Training [23][   40/  196]   Loss 0.032517   Top1 98.886719   Top5 100.000000   BatchTime 0.173516   LR 0.001000
INFO - Training [23][   60/  196]   Loss 0.031200   Top1 98.925781   Top5 100.000000   BatchTime 0.156026   LR 0.001000
INFO - Training [23][   80/  196]   Loss 0.032194   Top1 98.886719   Top5 100.000000   BatchTime 0.147794   LR 0.001000
INFO - Training [23][  100/  196]   Loss 0.032459   Top1 98.835938   Top5 100.000000   BatchTime 0.142897   LR 0.001000
INFO - Training [23][  120/  196]   Loss 0.032944   Top1 98.844401   Top5 100.000000   BatchTime 0.134850   LR 0.001000
INFO - Training [23][  140/  196]   Loss 0.033317   Top1 98.828125   Top5 100.000000   BatchTime 0.129846   LR 0.001000
INFO - Training [23][  160/  196]   Loss 0.033188   Top1 98.830566   Top5 100.000000   BatchTime 0.126215   LR 0.001000
INFO - Training [23][  180/  196]   Loss 0.033486   Top1 98.832465   Top5 100.000000   BatchTime 0.123448   LR 0.001000
INFO - ==> Top1: 98.854    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.439781   Top1 90.234375   Top5 99.531250   BatchTime 0.151629
INFO - Validation [23][   40/   40]   Loss 0.422134   Top1 90.440000   Top5 99.630000   BatchTime 0.103454
INFO - ==> Top1: 90.440    Top5: 99.630    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.440   Top5: 99.630] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 90.380   Top5: 99.550] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.028744   Top1 99.023438   Top5 100.000000   BatchTime 0.223576   LR 0.001000
INFO - Training [24][   40/  196]   Loss 0.031031   Top1 98.945312   Top5 99.990234   BatchTime 0.173741   LR 0.001000
INFO - Training [24][   60/  196]   Loss 0.032363   Top1 98.841146   Top5 99.993490   BatchTime 0.157106   LR 0.001000
INFO - Training [24][   80/  196]   Loss 0.032206   Top1 98.847656   Top5 99.995117   BatchTime 0.148616   LR 0.001000
INFO - Training [24][  100/  196]   Loss 0.032979   Top1 98.828125   Top5 99.996094   BatchTime 0.143592   LR 0.001000
INFO - Training [24][  120/  196]   Loss 0.032787   Top1 98.863932   Top5 99.993490   BatchTime 0.140136   LR 0.001000
INFO - Training [24][  140/  196]   Loss 0.032950   Top1 98.869978   Top5 99.994420   BatchTime 0.137828   LR 0.001000
INFO - Training [24][  160/  196]   Loss 0.032895   Top1 98.854980   Top5 99.995117   BatchTime 0.135990   LR 0.001000
INFO - Training [24][  180/  196]   Loss 0.033901   Top1 98.812934   Top5 99.995660   BatchTime 0.134501   LR 0.001000
INFO - ==> Top1: 98.822    Top5: 99.996    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.449540   Top1 90.000000   Top5 99.433594   BatchTime 0.146652
INFO - Validation [24][   40/   40]   Loss 0.427424   Top1 90.400000   Top5 99.510000   BatchTime 0.100605
INFO - ==> Top1: 90.400    Top5: 99.510    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.440   Top5: 99.630] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 90.400   Top5: 99.510] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.034529   Top1 98.886719   Top5 100.000000   BatchTime 0.221649   LR 0.001000
INFO - Training [25][   40/  196]   Loss 0.033766   Top1 98.945312   Top5 100.000000   BatchTime 0.172698   LR 0.001000
INFO - Training [25][   60/  196]   Loss 0.032478   Top1 98.938802   Top5 100.000000   BatchTime 0.150201   LR 0.001000
INFO - Training [25][   80/  196]   Loss 0.033464   Top1 98.862305   Top5 100.000000   BatchTime 0.137220   LR 0.001000
INFO - Training [25][  100/  196]   Loss 0.034472   Top1 98.816406   Top5 100.000000   BatchTime 0.130416   LR 0.001000
INFO - Training [25][  120/  196]   Loss 0.034618   Top1 98.821615   Top5 100.000000   BatchTime 0.126040   LR 0.001000
INFO - Training [25][  140/  196]   Loss 0.033233   Top1 98.864397   Top5 100.000000   BatchTime 0.120520   LR 0.001000
INFO - Training [25][  160/  196]   Loss 0.033702   Top1 98.845215   Top5 100.000000   BatchTime 0.120963   LR 0.001000
INFO - Training [25][  180/  196]   Loss 0.033469   Top1 98.847656   Top5 100.000000   BatchTime 0.121263   LR 0.001000
INFO - ==> Top1: 98.850    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.438984   Top1 90.351562   Top5 99.433594   BatchTime 0.148023
INFO - Validation [25][   40/   40]   Loss 0.421389   Top1 90.630000   Top5 99.590000   BatchTime 0.101443
INFO - ==> Top1: 90.630    Top5: 99.590    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 90.630   Top5: 99.590] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 90.440   Top5: 99.630] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.034743   Top1 98.750000   Top5 100.000000   BatchTime 0.223536   LR 0.001000
INFO - Training [26][   40/  196]   Loss 0.032031   Top1 98.867188   Top5 100.000000   BatchTime 0.174329   LR 0.001000
INFO - Training [26][   60/  196]   Loss 0.032691   Top1 98.847656   Top5 100.000000   BatchTime 0.157571   LR 0.001000
INFO - Training [26][   80/  196]   Loss 0.033164   Top1 98.896484   Top5 100.000000   BatchTime 0.149297   LR 0.001000
INFO - Training [26][  100/  196]   Loss 0.032946   Top1 98.898438   Top5 99.996094   BatchTime 0.145811   LR 0.001000
INFO - Training [26][  120/  196]   Loss 0.033635   Top1 98.876953   Top5 99.996745   BatchTime 0.142225   LR 0.001000
INFO - Training [26][  140/  196]   Loss 0.034392   Top1 98.842076   Top5 99.997210   BatchTime 0.139579   LR 0.001000
INFO - Training [26][  160/  196]   Loss 0.033559   Top1 98.879395   Top5 99.997559   BatchTime 0.137598   LR 0.001000
INFO - Training [26][  180/  196]   Loss 0.033741   Top1 98.867188   Top5 99.997830   BatchTime 0.135990   LR 0.001000
INFO - ==> Top1: 98.870    Top5: 99.998    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.445793   Top1 90.449219   Top5 99.531250   BatchTime 0.147317
INFO - Validation [26][   40/   40]   Loss 0.423702   Top1 90.690000   Top5 99.640000   BatchTime 0.102314
INFO - ==> Top1: 90.690    Top5: 99.640    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 90.630   Top5: 99.590] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.034307   Top1 98.671875   Top5 100.000000   BatchTime 0.210535   LR 0.001000
INFO - Training [27][   40/  196]   Loss 0.032140   Top1 98.808594   Top5 100.000000   BatchTime 0.155918   LR 0.001000
INFO - Training [27][   60/  196]   Loss 0.032742   Top1 98.834635   Top5 100.000000   BatchTime 0.137734   LR 0.001000
INFO - Training [27][   80/  196]   Loss 0.033065   Top1 98.833008   Top5 100.000000   BatchTime 0.126914   LR 0.001000
INFO - Training [27][  100/  196]   Loss 0.034367   Top1 98.765625   Top5 100.000000   BatchTime 0.126415   LR 0.001000
INFO - Training [27][  120/  196]   Loss 0.033519   Top1 98.815104   Top5 100.000000   BatchTime 0.126075   LR 0.001000
INFO - Training [27][  140/  196]   Loss 0.033049   Top1 98.844866   Top5 100.000000   BatchTime 0.125810   LR 0.001000
INFO - Training [27][  160/  196]   Loss 0.033369   Top1 98.842773   Top5 100.000000   BatchTime 0.125458   LR 0.001000
INFO - Training [27][  180/  196]   Loss 0.033046   Top1 98.856337   Top5 100.000000   BatchTime 0.125171   LR 0.001000
INFO - ==> Top1: 98.848    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.446869   Top1 90.390625   Top5 99.453125   BatchTime 0.147737
INFO - Validation [27][   40/   40]   Loss 0.423737   Top1 90.650000   Top5 99.600000   BatchTime 0.100474
INFO - ==> Top1: 90.650    Top5: 99.600    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.032498   Top1 98.828125   Top5 100.000000   BatchTime 0.221829   LR 0.001000
INFO - Training [28][   40/  196]   Loss 0.031970   Top1 98.916016   Top5 100.000000   BatchTime 0.172724   LR 0.001000
INFO - Training [28][   60/  196]   Loss 0.031722   Top1 98.899740   Top5 100.000000   BatchTime 0.156410   LR 0.001000
INFO - Training [28][   80/  196]   Loss 0.032805   Top1 98.847656   Top5 100.000000   BatchTime 0.148230   LR 0.001000
INFO - Training [28][  100/  196]   Loss 0.032997   Top1 98.839844   Top5 100.000000   BatchTime 0.143321   LR 0.001000
INFO - Training [28][  120/  196]   Loss 0.033295   Top1 98.815104   Top5 100.000000   BatchTime 0.140042   LR 0.001000
INFO - Training [28][  140/  196]   Loss 0.033014   Top1 98.839286   Top5 100.000000   BatchTime 0.137620   LR 0.001000
INFO - Training [28][  160/  196]   Loss 0.032441   Top1 98.874512   Top5 100.000000   BatchTime 0.135801   LR 0.001000
INFO - Training [28][  180/  196]   Loss 0.032306   Top1 98.891059   Top5 100.000000   BatchTime 0.134330   LR 0.001000
INFO - ==> Top1: 98.884    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.442097   Top1 90.234375   Top5 99.453125   BatchTime 0.145282
INFO - Validation [28][   40/   40]   Loss 0.422307   Top1 90.470000   Top5 99.570000   BatchTime 0.094024
INFO - ==> Top1: 90.470    Top5: 99.570    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.031052   Top1 98.886719   Top5 100.000000   BatchTime 0.215948   LR 0.001000
INFO - Training [29][   40/  196]   Loss 0.030743   Top1 98.945312   Top5 100.000000   BatchTime 0.169694   LR 0.001000
INFO - Training [29][   60/  196]   Loss 0.030520   Top1 98.971354   Top5 100.000000   BatchTime 0.154195   LR 0.001000
INFO - Training [29][   80/  196]   Loss 0.030124   Top1 98.994141   Top5 100.000000   BatchTime 0.146681   LR 0.001000
INFO - Training [29][  100/  196]   Loss 0.031128   Top1 98.949219   Top5 100.000000   BatchTime 0.141988   LR 0.001000
INFO - Training [29][  120/  196]   Loss 0.030921   Top1 98.958333   Top5 100.000000   BatchTime 0.138841   LR 0.001000
INFO - Training [29][  140/  196]   Loss 0.030188   Top1 98.992746   Top5 100.000000   BatchTime 0.136640   LR 0.001000
INFO - Training [29][  160/  196]   Loss 0.030712   Top1 98.969727   Top5 100.000000   BatchTime 0.134906   LR 0.001000
INFO - Training [29][  180/  196]   Loss 0.030558   Top1 98.990885   Top5 100.000000   BatchTime 0.133634   LR 0.001000
INFO - ==> Top1: 98.980    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.445474   Top1 90.253906   Top5 99.472656   BatchTime 0.148948
INFO - Validation [29][   40/   40]   Loss 0.423340   Top1 90.450000   Top5 99.610000   BatchTime 0.103081
INFO - ==> Top1: 90.450    Top5: 99.610    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.031300   Top1 99.003906   Top5 100.000000   BatchTime 0.223346   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.032091   Top1 98.935547   Top5 100.000000   BatchTime 0.173499   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.030588   Top1 98.958333   Top5 100.000000   BatchTime 0.156932   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.029435   Top1 99.023438   Top5 100.000000   BatchTime 0.148667   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.030807   Top1 98.953125   Top5 99.996094   BatchTime 0.143534   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.030911   Top1 98.945312   Top5 99.996745   BatchTime 0.140201   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.031027   Top1 98.953683   Top5 99.997210   BatchTime 0.135559   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.031111   Top1 98.950195   Top5 99.997559   BatchTime 0.130932   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.031338   Top1 98.936632   Top5 99.997830   BatchTime 0.127555   LR 0.001000
INFO - ==> Top1: 98.940    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.447044   Top1 90.429688   Top5 99.433594   BatchTime 0.155799
INFO - Validation [30][   40/   40]   Loss 0.428167   Top1 90.530000   Top5 99.570000   BatchTime 0.107089
INFO - ==> Top1: 90.530    Top5: 99.570    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.028769   Top1 99.179688   Top5 100.000000   BatchTime 0.222481   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.029835   Top1 99.130859   Top5 100.000000   BatchTime 0.173081   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.029547   Top1 99.114583   Top5 100.000000   BatchTime 0.156611   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.029827   Top1 99.052734   Top5 100.000000   BatchTime 0.148260   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.029607   Top1 99.054688   Top5 100.000000   BatchTime 0.143454   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.030375   Top1 99.000651   Top5 100.000000   BatchTime 0.140160   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.029976   Top1 99.023438   Top5 100.000000   BatchTime 0.137717   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.030212   Top1 98.999023   Top5 100.000000   BatchTime 0.135905   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.030860   Top1 98.980035   Top5 100.000000   BatchTime 0.134491   LR 0.001000
INFO - ==> Top1: 98.952    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.447622   Top1 90.117188   Top5 99.433594   BatchTime 0.149916
INFO - Validation [31][   40/   40]   Loss 0.429358   Top1 90.290000   Top5 99.580000   BatchTime 0.102809
INFO - ==> Top1: 90.290    Top5: 99.580    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.029140   Top1 98.964844   Top5 100.000000   BatchTime 0.220837   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.030741   Top1 99.003906   Top5 100.000000   BatchTime 0.171999   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.030716   Top1 99.003906   Top5 100.000000   BatchTime 0.155804   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.030421   Top1 98.935547   Top5 100.000000   BatchTime 0.142501   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.030365   Top1 98.937500   Top5 100.000000   BatchTime 0.133907   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.031083   Top1 98.906250   Top5 100.000000   BatchTime 0.128646   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.030850   Top1 98.922991   Top5 100.000000   BatchTime 0.125373   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.030977   Top1 98.925781   Top5 100.000000   BatchTime 0.120777   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.031043   Top1 98.912760   Top5 100.000000   BatchTime 0.121105   LR 0.001000
INFO - ==> Top1: 98.918    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.451515   Top1 90.234375   Top5 99.492188   BatchTime 0.147345
INFO - Validation [32][   40/   40]   Loss 0.430402   Top1 90.470000   Top5 99.600000   BatchTime 0.101060
INFO - ==> Top1: 90.470    Top5: 99.600    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.025055   Top1 99.179688   Top5 100.000000   BatchTime 0.223679   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.025850   Top1 99.082031   Top5 100.000000   BatchTime 0.173545   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.027107   Top1 99.042969   Top5 100.000000   BatchTime 0.157026   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.028437   Top1 99.023438   Top5 100.000000   BatchTime 0.148699   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.028341   Top1 99.023438   Top5 99.996094   BatchTime 0.143641   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.028340   Top1 99.033203   Top5 99.996745   BatchTime 0.140362   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.028789   Top1 99.001116   Top5 99.997210   BatchTime 0.137980   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.029518   Top1 98.974609   Top5 99.997559   BatchTime 0.136115   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.030086   Top1 98.958333   Top5 99.997830   BatchTime 0.134595   LR 0.001000
INFO - ==> Top1: 98.966    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.452455   Top1 90.019531   Top5 99.492188   BatchTime 0.147790
INFO - Validation [33][   40/   40]   Loss 0.426989   Top1 90.470000   Top5 99.590000   BatchTime 0.102356
INFO - ==> Top1: 90.470    Top5: 99.590    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.031769   Top1 98.808594   Top5 99.980469   BatchTime 0.192616   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.028500   Top1 98.916016   Top5 99.990234   BatchTime 0.147044   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.029926   Top1 98.893229   Top5 99.993490   BatchTime 0.131684   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.029095   Top1 98.955078   Top5 99.995117   BatchTime 0.124442   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.029299   Top1 98.929688   Top5 99.996094   BatchTime 0.118442   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.029205   Top1 98.942057   Top5 99.996745   BatchTime 0.119424   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.029426   Top1 98.922991   Top5 99.997210   BatchTime 0.119984   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.030260   Top1 98.898926   Top5 99.997559   BatchTime 0.120424   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.030524   Top1 98.899740   Top5 99.997830   BatchTime 0.120732   LR 0.001000
INFO - ==> Top1: 98.908    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.456361   Top1 90.234375   Top5 99.414062   BatchTime 0.141785
INFO - Validation [34][   40/   40]   Loss 0.431104   Top1 90.480000   Top5 99.580000   BatchTime 0.098225
INFO - ==> Top1: 90.480    Top5: 99.580    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.032408   Top1 99.101562   Top5 99.980469   BatchTime 0.225439   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.029961   Top1 99.140625   Top5 99.990234   BatchTime 0.174684   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.030924   Top1 99.036458   Top5 99.993490   BatchTime 0.157837   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.030664   Top1 99.018555   Top5 99.995117   BatchTime 0.149292   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.030313   Top1 99.007812   Top5 99.996094   BatchTime 0.144289   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.030566   Top1 98.997396   Top5 99.996745   BatchTime 0.141068   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.030370   Top1 99.001116   Top5 99.997210   BatchTime 0.138629   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.030022   Top1 99.016113   Top5 99.997559   BatchTime 0.136663   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.029911   Top1 99.016927   Top5 99.997830   BatchTime 0.135140   LR 0.001000
INFO - ==> Top1: 99.010    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.450559   Top1 90.117188   Top5 99.492188   BatchTime 0.131155
INFO - Validation [35][   40/   40]   Loss 0.427679   Top1 90.420000   Top5 99.610000   BatchTime 0.082832
INFO - ==> Top1: 90.420    Top5: 99.610    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.031702   Top1 98.925781   Top5 100.000000   BatchTime 0.195705   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.030161   Top1 98.994141   Top5 100.000000   BatchTime 0.155736   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.030646   Top1 98.971354   Top5 100.000000   BatchTime 0.145095   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.031065   Top1 98.964844   Top5 100.000000   BatchTime 0.139673   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.030252   Top1 98.988281   Top5 100.000000   BatchTime 0.136509   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.030073   Top1 98.971354   Top5 100.000000   BatchTime 0.134348   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.030698   Top1 98.931362   Top5 100.000000   BatchTime 0.132803   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.030522   Top1 98.930664   Top5 100.000000   BatchTime 0.131578   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.030260   Top1 98.925781   Top5 100.000000   BatchTime 0.130632   LR 0.001000
INFO - ==> Top1: 98.924    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.457390   Top1 90.000000   Top5 99.453125   BatchTime 0.146118
INFO - Validation [36][   40/   40]   Loss 0.431906   Top1 90.270000   Top5 99.600000   BatchTime 0.101405
INFO - ==> Top1: 90.270    Top5: 99.600    Loss: 0.432
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.650   Top5: 99.600] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.034931   Top1 98.808594   Top5 100.000000   BatchTime 0.222016   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.032976   Top1 98.828125   Top5 100.000000   BatchTime 0.172910   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.032175   Top1 98.808594   Top5 100.000000   BatchTime 0.156536   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.032200   Top1 98.823242   Top5 100.000000   BatchTime 0.148513   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.032067   Top1 98.843750   Top5 99.996094   BatchTime 0.143459   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.032688   Top1 98.828125   Top5 99.996745   BatchTime 0.140074   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.032419   Top1 98.856027   Top5 99.997210   BatchTime 0.137729   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.032344   Top1 98.845215   Top5 99.997559   BatchTime 0.132898   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.031922   Top1 98.873698   Top5 99.997830   BatchTime 0.128949   LR 0.001000
INFO - ==> Top1: 98.850    Top5: 99.998    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.452131   Top1 90.410156   Top5 99.433594   BatchTime 0.133526
INFO - Validation [37][   40/   40]   Loss 0.429888   Top1 90.740000   Top5 99.560000   BatchTime 0.092944
INFO - ==> Top1: 90.740    Top5: 99.560    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.025726   Top1 99.179688   Top5 99.980469   BatchTime 0.221681   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.029079   Top1 99.062500   Top5 99.990234   BatchTime 0.173227   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.028824   Top1 99.062500   Top5 99.993490   BatchTime 0.156738   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.029474   Top1 99.047852   Top5 99.995117   BatchTime 0.148389   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.030263   Top1 98.996094   Top5 99.992188   BatchTime 0.143555   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.030574   Top1 98.981120   Top5 99.993490   BatchTime 0.140213   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.029911   Top1 98.998326   Top5 99.994420   BatchTime 0.137777   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.029742   Top1 99.001465   Top5 99.995117   BatchTime 0.135636   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.029268   Top1 99.012587   Top5 99.995660   BatchTime 0.134207   LR 0.001000
INFO - ==> Top1: 98.988    Top5: 99.996    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.452564   Top1 90.175781   Top5 99.472656   BatchTime 0.147790
INFO - Validation [38][   40/   40]   Loss 0.434705   Top1 90.460000   Top5 99.580000   BatchTime 0.102157
INFO - ==> Top1: 90.460    Top5: 99.580    Loss: 0.435
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.029708   Top1 99.062500   Top5 100.000000   BatchTime 0.227281   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.028995   Top1 99.072266   Top5 100.000000   BatchTime 0.175337   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.031818   Top1 98.906250   Top5 100.000000   BatchTime 0.158148   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.031294   Top1 98.959961   Top5 100.000000   BatchTime 0.149397   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.032214   Top1 98.941406   Top5 100.000000   BatchTime 0.138732   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.031954   Top1 98.932292   Top5 100.000000   BatchTime 0.132492   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.032499   Top1 98.931362   Top5 100.000000   BatchTime 0.128138   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.031829   Top1 98.947754   Top5 100.000000   BatchTime 0.124902   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.032138   Top1 98.949653   Top5 100.000000   BatchTime 0.121826   LR 0.001000
INFO - ==> Top1: 98.968    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.455336   Top1 90.078125   Top5 99.394531   BatchTime 0.148619
INFO - Validation [39][   40/   40]   Loss 0.433126   Top1 90.430000   Top5 99.550000   BatchTime 0.102509
INFO - ==> Top1: 90.430    Top5: 99.550    Loss: 0.433
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.025978   Top1 99.082031   Top5 100.000000   BatchTime 0.228957   LR 0.000100
INFO - Training [40][   40/  196]   Loss 0.029740   Top1 98.847656   Top5 100.000000   BatchTime 0.176837   LR 0.000100
INFO - Training [40][   60/  196]   Loss 0.031332   Top1 98.828125   Top5 100.000000   BatchTime 0.159116   LR 0.000100
INFO - Training [40][   80/  196]   Loss 0.031537   Top1 98.847656   Top5 100.000000   BatchTime 0.150308   LR 0.000100
INFO - Training [40][  100/  196]   Loss 0.032215   Top1 98.832031   Top5 100.000000   BatchTime 0.144996   LR 0.000100
INFO - Training [40][  120/  196]   Loss 0.031776   Top1 98.850911   Top5 100.000000   BatchTime 0.141474   LR 0.000100
INFO - Training [40][  140/  196]   Loss 0.031374   Top1 98.881138   Top5 100.000000   BatchTime 0.138888   LR 0.000100
INFO - Training [40][  160/  196]   Loss 0.031211   Top1 98.901367   Top5 99.997559   BatchTime 0.136875   LR 0.000100
INFO - Training [40][  180/  196]   Loss 0.030977   Top1 98.912760   Top5 99.997830   BatchTime 0.135306   LR 0.000100
INFO - ==> Top1: 98.928    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.455848   Top1 90.156250   Top5 99.433594   BatchTime 0.147246
INFO - Validation [40][   40/   40]   Loss 0.431348   Top1 90.550000   Top5 99.570000   BatchTime 0.101907
INFO - ==> Top1: 90.550    Top5: 99.570    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.030650   Top1 98.867188   Top5 100.000000   BatchTime 0.221429   LR 0.000100
INFO - Training [41][   40/  196]   Loss 0.030357   Top1 98.925781   Top5 100.000000   BatchTime 0.156986   LR 0.000100
INFO - Training [41][   60/  196]   Loss 0.033411   Top1 98.854167   Top5 100.000000   BatchTime 0.139193   LR 0.000100
INFO - Training [41][   80/  196]   Loss 0.031829   Top1 98.925781   Top5 100.000000   BatchTime 0.130104   LR 0.000100
INFO - Training [41][  100/  196]   Loss 0.031596   Top1 98.910156   Top5 100.000000   BatchTime 0.123996   LR 0.000100
INFO - Training [41][  120/  196]   Loss 0.030872   Top1 98.945312   Top5 100.000000   BatchTime 0.121126   LR 0.000100
INFO - Training [41][  140/  196]   Loss 0.029692   Top1 98.992746   Top5 100.000000   BatchTime 0.121474   LR 0.000100
INFO - Training [41][  160/  196]   Loss 0.030234   Top1 98.972168   Top5 100.000000   BatchTime 0.121639   LR 0.000100
INFO - Training [41][  180/  196]   Loss 0.030253   Top1 98.980035   Top5 100.000000   BatchTime 0.121811   LR 0.000100
INFO - ==> Top1: 98.978    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.450388   Top1 90.312500   Top5 99.453125   BatchTime 0.146011
INFO - Validation [41][   40/   40]   Loss 0.429484   Top1 90.510000   Top5 99.590000   BatchTime 0.100763
INFO - ==> Top1: 90.510    Top5: 99.590    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.029502   Top1 99.003906   Top5 100.000000   BatchTime 0.219602   LR 0.000100
INFO - Training [42][   40/  196]   Loss 0.028519   Top1 99.062500   Top5 100.000000   BatchTime 0.171592   LR 0.000100
INFO - Training [42][   60/  196]   Loss 0.027795   Top1 99.062500   Top5 100.000000   BatchTime 0.155648   LR 0.000100
INFO - Training [42][   80/  196]   Loss 0.028857   Top1 98.964844   Top5 99.995117   BatchTime 0.147856   LR 0.000100
INFO - Training [42][  100/  196]   Loss 0.028741   Top1 99.003906   Top5 99.996094   BatchTime 0.142741   LR 0.000100
INFO - Training [42][  120/  196]   Loss 0.028807   Top1 98.987630   Top5 99.996745   BatchTime 0.139568   LR 0.000100
INFO - Training [42][  140/  196]   Loss 0.029041   Top1 98.989955   Top5 99.997210   BatchTime 0.137245   LR 0.000100
INFO - Training [42][  160/  196]   Loss 0.028710   Top1 99.006348   Top5 99.997559   BatchTime 0.135444   LR 0.000100
INFO - Training [42][  180/  196]   Loss 0.028705   Top1 99.012587   Top5 99.997830   BatchTime 0.134046   LR 0.000100
INFO - ==> Top1: 98.992    Top5: 99.998    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.455128   Top1 90.136719   Top5 99.511719   BatchTime 0.144615
INFO - Validation [42][   40/   40]   Loss 0.432474   Top1 90.450000   Top5 99.590000   BatchTime 0.090164
INFO - ==> Top1: 90.450    Top5: 99.590    Loss: 0.432
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.032835   Top1 98.828125   Top5 100.000000   BatchTime 0.204337   LR 0.000100
INFO - Training [43][   40/  196]   Loss 0.029755   Top1 99.003906   Top5 100.000000   BatchTime 0.151007   LR 0.000100
INFO - Training [43][   60/  196]   Loss 0.028913   Top1 99.082031   Top5 100.000000   BatchTime 0.135195   LR 0.000100
INFO - Training [43][   80/  196]   Loss 0.028355   Top1 99.072266   Top5 100.000000   BatchTime 0.134313   LR 0.000100
INFO - Training [43][  100/  196]   Loss 0.029490   Top1 99.031250   Top5 100.000000   BatchTime 0.132294   LR 0.000100
INFO - Training [43][  120/  196]   Loss 0.028919   Top1 99.069010   Top5 100.000000   BatchTime 0.130903   LR 0.000100
INFO - Training [43][  140/  196]   Loss 0.028766   Top1 99.042969   Top5 100.000000   BatchTime 0.129861   LR 0.000100
INFO - Training [43][  160/  196]   Loss 0.029099   Top1 99.038086   Top5 100.000000   BatchTime 0.129052   LR 0.000100
INFO - Training [43][  180/  196]   Loss 0.029551   Top1 99.014757   Top5 100.000000   BatchTime 0.128392   LR 0.000100
INFO - ==> Top1: 98.974    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.453858   Top1 90.253906   Top5 99.453125   BatchTime 0.149274
INFO - Validation [43][   40/   40]   Loss 0.431014   Top1 90.480000   Top5 99.600000   BatchTime 0.103437
INFO - ==> Top1: 90.480    Top5: 99.600    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.034322   Top1 98.769531   Top5 100.000000   BatchTime 0.223800   LR 0.000100
INFO - Training [44][   40/  196]   Loss 0.031451   Top1 98.857422   Top5 100.000000   BatchTime 0.173649   LR 0.000100
INFO - Training [44][   60/  196]   Loss 0.030616   Top1 98.854167   Top5 100.000000   BatchTime 0.157117   LR 0.000100
INFO - Training [44][   80/  196]   Loss 0.028754   Top1 98.979492   Top5 100.000000   BatchTime 0.148741   LR 0.000100
INFO - Training [44][  100/  196]   Loss 0.030610   Top1 98.937500   Top5 100.000000   BatchTime 0.143578   LR 0.000100
INFO - Training [44][  120/  196]   Loss 0.029956   Top1 98.964844   Top5 99.996745   BatchTime 0.140178   LR 0.000100
INFO - Training [44][  140/  196]   Loss 0.029721   Top1 98.995536   Top5 99.997210   BatchTime 0.137679   LR 0.000100
INFO - Training [44][  160/  196]   Loss 0.029743   Top1 98.984375   Top5 99.997559   BatchTime 0.135776   LR 0.000100
INFO - Training [44][  180/  196]   Loss 0.029735   Top1 98.993056   Top5 99.997830   BatchTime 0.131574   LR 0.000100
INFO - ==> Top1: 98.992    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.454959   Top1 90.156250   Top5 99.394531   BatchTime 0.131827
INFO - Validation [44][   40/   40]   Loss 0.433386   Top1 90.490000   Top5 99.560000   BatchTime 0.083073
INFO - ==> Top1: 90.490    Top5: 99.560    Loss: 0.433
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.030569   Top1 99.062500   Top5 100.000000   BatchTime 0.223898   LR 0.000100
INFO - Training [45][   40/  196]   Loss 0.030558   Top1 99.091797   Top5 100.000000   BatchTime 0.173838   LR 0.000100
INFO - Training [45][   60/  196]   Loss 0.029996   Top1 99.075521   Top5 100.000000   BatchTime 0.157169   LR 0.000100
INFO - Training [45][   80/  196]   Loss 0.029468   Top1 99.072266   Top5 100.000000   BatchTime 0.148746   LR 0.000100
INFO - Training [45][  100/  196]   Loss 0.029081   Top1 99.074219   Top5 100.000000   BatchTime 0.143822   LR 0.000100
INFO - Training [45][  120/  196]   Loss 0.028481   Top1 99.069010   Top5 100.000000   BatchTime 0.140492   LR 0.000100
INFO - Training [45][  140/  196]   Loss 0.029100   Top1 99.048549   Top5 100.000000   BatchTime 0.138015   LR 0.000100
INFO - Training [45][  160/  196]   Loss 0.029796   Top1 99.030762   Top5 100.000000   BatchTime 0.136109   LR 0.000100
INFO - Training [45][  180/  196]   Loss 0.029645   Top1 99.021267   Top5 100.000000   BatchTime 0.134659   LR 0.000100
INFO - ==> Top1: 99.010    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.456045   Top1 90.058594   Top5 99.492188   BatchTime 0.146628
INFO - Validation [45][   40/   40]   Loss 0.434740   Top1 90.450000   Top5 99.580000   BatchTime 0.100539
INFO - ==> Top1: 90.450    Top5: 99.580    Loss: 0.435
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.024066   Top1 99.218750   Top5 100.000000   BatchTime 0.219452   LR 0.000100
INFO - Training [46][   40/  196]   Loss 0.028545   Top1 99.101562   Top5 100.000000   BatchTime 0.172036   LR 0.000100
INFO - Training [46][   60/  196]   Loss 0.028366   Top1 99.095052   Top5 100.000000   BatchTime 0.155863   LR 0.000100
INFO - Training [46][   80/  196]   Loss 0.028352   Top1 99.135742   Top5 100.000000   BatchTime 0.147676   LR 0.000100
INFO - Training [46][  100/  196]   Loss 0.028319   Top1 99.125000   Top5 100.000000   BatchTime 0.142691   LR 0.000100
INFO - Training [46][  120/  196]   Loss 0.029165   Top1 99.078776   Top5 100.000000   BatchTime 0.133718   LR 0.000100
INFO - Training [46][  140/  196]   Loss 0.028244   Top1 99.107143   Top5 100.000000   BatchTime 0.129227   LR 0.000100
INFO - Training [46][  160/  196]   Loss 0.028728   Top1 99.077148   Top5 100.000000   BatchTime 0.125597   LR 0.000100
INFO - Training [46][  180/  196]   Loss 0.029083   Top1 99.053819   Top5 100.000000   BatchTime 0.122144   LR 0.000100
INFO - ==> Top1: 99.058    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.455664   Top1 90.351562   Top5 99.453125   BatchTime 0.147831
INFO - Validation [46][   40/   40]   Loss 0.431274   Top1 90.600000   Top5 99.590000   BatchTime 0.102849
INFO - ==> Top1: 90.600    Top5: 99.590    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.023630   Top1 99.238281   Top5 100.000000   BatchTime 0.224113   LR 0.000100
INFO - Training [47][   40/  196]   Loss 0.028436   Top1 99.042969   Top5 100.000000   BatchTime 0.174073   LR 0.000100
INFO - Training [47][   60/  196]   Loss 0.029366   Top1 99.003906   Top5 100.000000   BatchTime 0.157266   LR 0.000100
INFO - Training [47][   80/  196]   Loss 0.029641   Top1 99.003906   Top5 100.000000   BatchTime 0.148963   LR 0.000100
INFO - Training [47][  100/  196]   Loss 0.029118   Top1 99.050781   Top5 100.000000   BatchTime 0.144705   LR 0.000100
INFO - Training [47][  120/  196]   Loss 0.028529   Top1 99.098307   Top5 100.000000   BatchTime 0.141231   LR 0.000100
INFO - Training [47][  140/  196]   Loss 0.028368   Top1 99.095982   Top5 100.000000   BatchTime 0.138654   LR 0.000100
INFO - Training [47][  160/  196]   Loss 0.028331   Top1 99.104004   Top5 100.000000   BatchTime 0.136699   LR 0.000100
INFO - Training [47][  180/  196]   Loss 0.028339   Top1 99.088542   Top5 100.000000   BatchTime 0.135172   LR 0.000100
INFO - ==> Top1: 99.084    Top5: 100.000    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.456486   Top1 90.039062   Top5 99.453125   BatchTime 0.146626
INFO - Validation [47][   40/   40]   Loss 0.432353   Top1 90.470000   Top5 99.570000   BatchTime 0.101452
INFO - ==> Top1: 90.470    Top5: 99.570    Loss: 0.432
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.027340   Top1 99.062500   Top5 100.000000   BatchTime 0.220626   LR 0.000100
INFO - Training [48][   40/  196]   Loss 0.027778   Top1 99.013672   Top5 100.000000   BatchTime 0.170946   LR 0.000100
INFO - Training [48][   60/  196]   Loss 0.027714   Top1 99.069010   Top5 100.000000   BatchTime 0.145040   LR 0.000100
INFO - Training [48][   80/  196]   Loss 0.028373   Top1 99.023438   Top5 100.000000   BatchTime 0.134399   LR 0.000100
INFO - Training [48][  100/  196]   Loss 0.028937   Top1 99.031250   Top5 100.000000   BatchTime 0.127878   LR 0.000100
INFO - Training [48][  120/  196]   Loss 0.028387   Top1 99.055990   Top5 100.000000   BatchTime 0.122858   LR 0.000100
INFO - Training [48][  140/  196]   Loss 0.028614   Top1 99.048549   Top5 100.000000   BatchTime 0.121042   LR 0.000100
INFO - Training [48][  160/  196]   Loss 0.028017   Top1 99.069824   Top5 100.000000   BatchTime 0.121309   LR 0.000100
INFO - Training [48][  180/  196]   Loss 0.028053   Top1 99.064670   Top5 100.000000   BatchTime 0.121489   LR 0.000100
INFO - ==> Top1: 99.054    Top5: 100.000    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.449313   Top1 90.097656   Top5 99.511719   BatchTime 0.146834
INFO - Validation [48][   40/   40]   Loss 0.429209   Top1 90.400000   Top5 99.620000   BatchTime 0.101748
INFO - ==> Top1: 90.400    Top5: 99.620    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.690   Top5: 99.640] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.031797   Top1 98.906250   Top5 100.000000   BatchTime 0.220397   LR 0.000100
INFO - Training [49][   40/  196]   Loss 0.031243   Top1 98.837891   Top5 100.000000   BatchTime 0.171684   LR 0.000100
INFO - Training [49][   60/  196]   Loss 0.030698   Top1 98.873698   Top5 100.000000   BatchTime 0.155618   LR 0.000100
INFO - Training [49][   80/  196]   Loss 0.029973   Top1 98.916016   Top5 100.000000   BatchTime 0.147674   LR 0.000100
INFO - Training [49][  100/  196]   Loss 0.030004   Top1 98.929688   Top5 100.000000   BatchTime 0.142902   LR 0.000100
INFO - Training [49][  120/  196]   Loss 0.029655   Top1 98.942057   Top5 100.000000   BatchTime 0.139656   LR 0.000100
INFO - Training [49][  140/  196]   Loss 0.029835   Top1 98.959263   Top5 100.000000   BatchTime 0.137283   LR 0.000100
INFO - Training [49][  160/  196]   Loss 0.030124   Top1 98.950195   Top5 100.000000   BatchTime 0.135504   LR 0.000100
INFO - Training [49][  180/  196]   Loss 0.030334   Top1 98.934462   Top5 100.000000   BatchTime 0.134098   LR 0.000100
INFO - ==> Top1: 98.934    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.454450   Top1 90.195312   Top5 99.511719   BatchTime 0.146535
INFO - Validation [49][   40/   40]   Loss 0.427788   Top1 90.730000   Top5 99.620000   BatchTime 0.101626
INFO - ==> Top1: 90.730    Top5: 99.620    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.029334   Top1 99.082031   Top5 100.000000   BatchTime 0.209996   LR 0.000010
INFO - Training [50][   40/  196]   Loss 0.030063   Top1 99.023438   Top5 100.000000   BatchTime 0.156251   LR 0.000010
INFO - Training [50][   60/  196]   Loss 0.029968   Top1 98.964844   Top5 100.000000   BatchTime 0.135334   LR 0.000010
INFO - Training [50][   80/  196]   Loss 0.030417   Top1 98.925781   Top5 100.000000   BatchTime 0.128058   LR 0.000010
INFO - Training [50][  100/  196]   Loss 0.030022   Top1 98.949219   Top5 100.000000   BatchTime 0.127108   LR 0.000010
INFO - Training [50][  120/  196]   Loss 0.029840   Top1 98.945312   Top5 100.000000   BatchTime 0.126479   LR 0.000010
INFO - Training [50][  140/  196]   Loss 0.028786   Top1 98.998326   Top5 100.000000   BatchTime 0.126066   LR 0.000010
INFO - Training [50][  160/  196]   Loss 0.029168   Top1 98.999023   Top5 100.000000   BatchTime 0.125653   LR 0.000010
INFO - Training [50][  180/  196]   Loss 0.029157   Top1 99.008247   Top5 100.000000   BatchTime 0.125326   LR 0.000010
INFO - ==> Top1: 98.996    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.454417   Top1 90.195312   Top5 99.492188   BatchTime 0.148867
INFO - Validation [50][   40/   40]   Loss 0.432277   Top1 90.530000   Top5 99.580000   BatchTime 0.102834
INFO - ==> Top1: 90.530    Top5: 99.580    Loss: 0.432
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.029544   Top1 99.023438   Top5 100.000000   BatchTime 0.221398   LR 0.000010
INFO - Training [51][   40/  196]   Loss 0.029443   Top1 98.955078   Top5 100.000000   BatchTime 0.172314   LR 0.000010
INFO - Training [51][   60/  196]   Loss 0.030163   Top1 98.945312   Top5 100.000000   BatchTime 0.155908   LR 0.000010
INFO - Training [51][   80/  196]   Loss 0.030178   Top1 98.955078   Top5 100.000000   BatchTime 0.147731   LR 0.000010
INFO - Training [51][  100/  196]   Loss 0.029309   Top1 98.992188   Top5 100.000000   BatchTime 0.142856   LR 0.000010
INFO - Training [51][  120/  196]   Loss 0.029196   Top1 98.984375   Top5 100.000000   BatchTime 0.140405   LR 0.000010
INFO - Training [51][  140/  196]   Loss 0.029215   Top1 99.003906   Top5 100.000000   BatchTime 0.137909   LR 0.000010
INFO - Training [51][  160/  196]   Loss 0.029274   Top1 98.979492   Top5 100.000000   BatchTime 0.136055   LR 0.000010
INFO - Training [51][  180/  196]   Loss 0.028980   Top1 98.997396   Top5 100.000000   BatchTime 0.134533   LR 0.000010
INFO - ==> Top1: 99.008    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.453046   Top1 90.390625   Top5 99.394531   BatchTime 0.137735
INFO - Validation [51][   40/   40]   Loss 0.432676   Top1 90.600000   Top5 99.560000   BatchTime 0.090208
INFO - ==> Top1: 90.600    Top5: 99.560    Loss: 0.433
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.032787   Top1 98.984375   Top5 99.980469   BatchTime 0.229742   LR 0.000010
INFO - Training [52][   40/  196]   Loss 0.032125   Top1 98.916016   Top5 99.990234   BatchTime 0.176831   LR 0.000010
INFO - Training [52][   60/  196]   Loss 0.032909   Top1 98.854167   Top5 99.986979   BatchTime 0.159209   LR 0.000010
INFO - Training [52][   80/  196]   Loss 0.031502   Top1 98.920898   Top5 99.990234   BatchTime 0.150252   LR 0.000010
INFO - Training [52][  100/  196]   Loss 0.031783   Top1 98.933594   Top5 99.992188   BatchTime 0.144896   LR 0.000010
INFO - Training [52][  120/  196]   Loss 0.031565   Top1 98.958333   Top5 99.993490   BatchTime 0.141295   LR 0.000010
INFO - Training [52][  140/  196]   Loss 0.030982   Top1 98.995536   Top5 99.994420   BatchTime 0.138689   LR 0.000010
INFO - Training [52][  160/  196]   Loss 0.030839   Top1 99.013672   Top5 99.995117   BatchTime 0.136650   LR 0.000010
INFO - Training [52][  180/  196]   Loss 0.031031   Top1 98.995226   Top5 99.995660   BatchTime 0.135110   LR 0.000010
INFO - ==> Top1: 99.004    Top5: 99.996    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.456443   Top1 90.117188   Top5 99.472656   BatchTime 0.150059
INFO - Validation [52][   40/   40]   Loss 0.432403   Top1 90.460000   Top5 99.600000   BatchTime 0.102534
INFO - ==> Top1: 90.460    Top5: 99.600    Loss: 0.432
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.029879   Top1 98.945312   Top5 100.000000   BatchTime 0.222641   LR 0.000010
INFO - Training [53][   40/  196]   Loss 0.029050   Top1 99.003906   Top5 100.000000   BatchTime 0.173055   LR 0.000010
INFO - Training [53][   60/  196]   Loss 0.030848   Top1 98.938802   Top5 100.000000   BatchTime 0.156478   LR 0.000010
INFO - Training [53][   80/  196]   Loss 0.030647   Top1 98.925781   Top5 100.000000   BatchTime 0.148053   LR 0.000010
INFO - Training [53][  100/  196]   Loss 0.030469   Top1 98.917969   Top5 100.000000   BatchTime 0.143078   LR 0.000010
INFO - Training [53][  120/  196]   Loss 0.030778   Top1 98.919271   Top5 100.000000   BatchTime 0.140045   LR 0.000010
INFO - Training [53][  140/  196]   Loss 0.030231   Top1 98.950893   Top5 100.000000   BatchTime 0.132628   LR 0.000010
INFO - Training [53][  160/  196]   Loss 0.030331   Top1 98.952637   Top5 100.000000   BatchTime 0.128675   LR 0.000010
INFO - Training [53][  180/  196]   Loss 0.030150   Top1 98.958333   Top5 100.000000   BatchTime 0.125590   LR 0.000010
INFO - ==> Top1: 98.946    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.459020   Top1 90.175781   Top5 99.492188   BatchTime 0.139711
INFO - Validation [53][   40/   40]   Loss 0.434166   Top1 90.520000   Top5 99.600000   BatchTime 0.091128
INFO - ==> Top1: 90.520    Top5: 99.600    Loss: 0.434
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.033017   Top1 98.886719   Top5 100.000000   BatchTime 0.186307   LR 0.000010
INFO - Training [54][   40/  196]   Loss 0.033071   Top1 98.876953   Top5 100.000000   BatchTime 0.135728   LR 0.000010
INFO - Training [54][   60/  196]   Loss 0.031408   Top1 98.899740   Top5 100.000000   BatchTime 0.118420   LR 0.000010
INFO - Training [54][   80/  196]   Loss 0.029399   Top1 99.003906   Top5 100.000000   BatchTime 0.110148   LR 0.000010
INFO - Training [54][  100/  196]   Loss 0.030526   Top1 98.953125   Top5 100.000000   BatchTime 0.104941   LR 0.000010
INFO - Training [54][  120/  196]   Loss 0.030146   Top1 98.948568   Top5 100.000000   BatchTime 0.101524   LR 0.000010
INFO - Training [54][  140/  196]   Loss 0.030750   Top1 98.942522   Top5 100.000000   BatchTime 0.098905   LR 0.000010
INFO - Training [54][  160/  196]   Loss 0.029971   Top1 98.972168   Top5 100.000000   BatchTime 0.096816   LR 0.000010
INFO - Training [54][  180/  196]   Loss 0.030247   Top1 98.960503   Top5 100.000000   BatchTime 0.095258   LR 0.000010
INFO - ==> Top1: 98.934    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.455448   Top1 90.078125   Top5 99.492188   BatchTime 0.124209
INFO - Validation [54][   40/   40]   Loss 0.433842   Top1 90.480000   Top5 99.600000   BatchTime 0.079070
INFO - ==> Top1: 90.480    Top5: 99.600    Loss: 0.434
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.030549   Top1 98.984375   Top5 100.000000   BatchTime 0.181923   LR 0.000010
INFO - Training [55][   40/  196]   Loss 0.029718   Top1 99.003906   Top5 100.000000   BatchTime 0.132429   LR 0.000010
INFO - Training [55][   60/  196]   Loss 0.030086   Top1 99.023438   Top5 100.000000   BatchTime 0.116105   LR 0.000010
INFO - Training [55][   80/  196]   Loss 0.029515   Top1 99.018555   Top5 100.000000   BatchTime 0.107980   LR 0.000010
INFO - Training [55][  100/  196]   Loss 0.029463   Top1 99.015625   Top5 100.000000   BatchTime 0.102967   LR 0.000010
INFO - Training [55][  120/  196]   Loss 0.029705   Top1 98.994141   Top5 100.000000   BatchTime 0.100545   LR 0.000010
INFO - Training [55][  140/  196]   Loss 0.030223   Top1 98.987165   Top5 100.000000   BatchTime 0.098146   LR 0.000010
INFO - Training [55][  160/  196]   Loss 0.030330   Top1 98.957520   Top5 100.000000   BatchTime 0.096194   LR 0.000010
INFO - Training [55][  180/  196]   Loss 0.030479   Top1 98.945312   Top5 100.000000   BatchTime 0.094595   LR 0.000010
INFO - ==> Top1: 98.950    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.453678   Top1 90.253906   Top5 99.453125   BatchTime 0.125447
INFO - Validation [55][   40/   40]   Loss 0.430964   Top1 90.570000   Top5 99.560000   BatchTime 0.079686
INFO - ==> Top1: 90.570    Top5: 99.560    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.024539   Top1 99.296875   Top5 100.000000   BatchTime 0.181430   LR 0.000010
INFO - Training [56][   40/  196]   Loss 0.026533   Top1 99.091797   Top5 100.000000   BatchTime 0.131954   LR 0.000010
INFO - Training [56][   60/  196]   Loss 0.027193   Top1 99.069010   Top5 100.000000   BatchTime 0.116232   LR 0.000010
INFO - Training [56][   80/  196]   Loss 0.028738   Top1 99.013672   Top5 100.000000   BatchTime 0.108336   LR 0.000010
INFO - Training [56][  100/  196]   Loss 0.028113   Top1 99.011719   Top5 100.000000   BatchTime 0.103691   LR 0.000010
INFO - Training [56][  120/  196]   Loss 0.028175   Top1 99.026693   Top5 100.000000   BatchTime 0.100584   LR 0.000010
INFO - Training [56][  140/  196]   Loss 0.028722   Top1 98.987165   Top5 100.000000   BatchTime 0.098138   LR 0.000010
INFO - Training [56][  160/  196]   Loss 0.028765   Top1 98.981934   Top5 100.000000   BatchTime 0.096194   LR 0.000010
INFO - Training [56][  180/  196]   Loss 0.028794   Top1 98.971354   Top5 100.000000   BatchTime 0.094694   LR 0.000010
INFO - ==> Top1: 98.968    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.459159   Top1 90.332031   Top5 99.453125   BatchTime 0.125169
INFO - Validation [56][   40/   40]   Loss 0.436668   Top1 90.630000   Top5 99.580000   BatchTime 0.079673
INFO - ==> Top1: 90.630    Top5: 99.580    Loss: 0.437
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.028039   Top1 99.160156   Top5 100.000000   BatchTime 0.180123   LR 0.000010
INFO - Training [57][   40/  196]   Loss 0.026814   Top1 99.150391   Top5 100.000000   BatchTime 0.131848   LR 0.000010
INFO - Training [57][   60/  196]   Loss 0.026860   Top1 99.114583   Top5 100.000000   BatchTime 0.115635   LR 0.000010
INFO - Training [57][   80/  196]   Loss 0.027973   Top1 99.072266   Top5 100.000000   BatchTime 0.107500   LR 0.000010
INFO - Training [57][  100/  196]   Loss 0.028563   Top1 99.023438   Top5 100.000000   BatchTime 0.102809   LR 0.000010
INFO - Training [57][  120/  196]   Loss 0.028753   Top1 99.010417   Top5 100.000000   BatchTime 0.099526   LR 0.000010
INFO - Training [57][  140/  196]   Loss 0.028597   Top1 98.998326   Top5 100.000000   BatchTime 0.097117   LR 0.000010
INFO - Training [57][  160/  196]   Loss 0.028527   Top1 99.006348   Top5 100.000000   BatchTime 0.095233   LR 0.000010
INFO - Training [57][  180/  196]   Loss 0.028813   Top1 98.999566   Top5 100.000000   BatchTime 0.093827   LR 0.000010
INFO - ==> Top1: 98.990    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.459925   Top1 90.175781   Top5 99.355469   BatchTime 0.124297
INFO - Validation [57][   40/   40]   Loss 0.433837   Top1 90.450000   Top5 99.550000   BatchTime 0.079158
INFO - ==> Top1: 90.450    Top5: 99.550    Loss: 0.434
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.030793   Top1 98.945312   Top5 100.000000   BatchTime 0.179656   LR 0.000010
INFO - Training [58][   40/  196]   Loss 0.030094   Top1 98.955078   Top5 100.000000   BatchTime 0.131687   LR 0.000010
INFO - Training [58][   60/  196]   Loss 0.028826   Top1 98.990885   Top5 100.000000   BatchTime 0.115829   LR 0.000010
INFO - Training [58][   80/  196]   Loss 0.028331   Top1 99.018555   Top5 100.000000   BatchTime 0.107644   LR 0.000010
INFO - Training [58][  100/  196]   Loss 0.028143   Top1 99.027344   Top5 100.000000   BatchTime 0.102853   LR 0.000010
INFO - Training [58][  120/  196]   Loss 0.028500   Top1 99.029948   Top5 99.996745   BatchTime 0.099534   LR 0.000010
INFO - Training [58][  140/  196]   Loss 0.029577   Top1 98.981585   Top5 99.997210   BatchTime 0.097190   LR 0.000010
INFO - Training [58][  160/  196]   Loss 0.029403   Top1 98.977051   Top5 99.997559   BatchTime 0.095314   LR 0.000010
INFO - Training [58][  180/  196]   Loss 0.029113   Top1 98.982205   Top5 99.997830   BatchTime 0.093861   LR 0.000010
INFO - ==> Top1: 98.946    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.467286   Top1 90.410156   Top5 99.492188   BatchTime 0.124410
INFO - Validation [58][   40/   40]   Loss 0.436542   Top1 90.600000   Top5 99.580000   BatchTime 0.079224
INFO - ==> Top1: 90.600    Top5: 99.580    Loss: 0.437
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.024188   Top1 99.179688   Top5 100.000000   BatchTime 0.181978   LR 0.000010
INFO - Training [59][   40/  196]   Loss 0.025118   Top1 99.091797   Top5 100.000000   BatchTime 0.133504   LR 0.000010
INFO - Training [59][   60/  196]   Loss 0.026873   Top1 99.101562   Top5 100.000000   BatchTime 0.117135   LR 0.000010
INFO - Training [59][   80/  196]   Loss 0.027280   Top1 99.101562   Top5 100.000000   BatchTime 0.108949   LR 0.000010
INFO - Training [59][  100/  196]   Loss 0.028488   Top1 99.050781   Top5 100.000000   BatchTime 0.104062   LR 0.000010
INFO - Training [59][  120/  196]   Loss 0.029743   Top1 98.994141   Top5 100.000000   BatchTime 0.101838   LR 0.000010
INFO - Training [59][  140/  196]   Loss 0.029113   Top1 99.023438   Top5 100.000000   BatchTime 0.099294   LR 0.000010
INFO - Training [59][  160/  196]   Loss 0.029308   Top1 99.013672   Top5 100.000000   BatchTime 0.097164   LR 0.000010
INFO - Training [59][  180/  196]   Loss 0.030064   Top1 98.982205   Top5 100.000000   BatchTime 0.095501   LR 0.000010
INFO - ==> Top1: 98.972    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.448273   Top1 90.136719   Top5 99.433594   BatchTime 0.124575
INFO - Validation [59][   40/   40]   Loss 0.430746   Top1 90.470000   Top5 99.580000   BatchTime 0.079324
INFO - ==> Top1: 90.470    Top5: 99.580    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 90.750   Top5: 99.620] Sparsity : 0.856
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 90.740   Top5: 99.560] Sparsity : 0.856
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 90.730   Top5: 99.620] Sparsity : 0.856
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_20221104-002827/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.448273   Top1 90.136719   Top5 99.433594   BatchTime 0.124841
INFO - Validation [   40/   40]   Loss 0.430746   Top1 90.470000   Top5 99.580000   BatchTime 0.079363
INFO - ==> Top1: 90.470    Top5: 99.580    Loss: 0.431
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net