INFO - Log file for this run: /home/ilena7440/LSQ/out/MobileNetv2_imagenet_a8w8_5_epoch80_20221108-104336/MobileNetv2_imagenet_a8w8_5_epoch80_20221108-104336.log
INFO - TensorBoard data directory: /home/ilena7440/LSQ/out/MobileNetv2_imagenet_a8w8_5_epoch80_20221108-104336/tb_runs
INFO - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
********************pre-trained*****************
INFO - Created `MobileNetv2` model for `imagenet` dataset
          Use pre-trained model = True
/home/ilena7440/LSQ/quan/quantizer/lsq.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
INFO - Inserted quantizers into the original model
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 50000 samples (128 per mini-batch)
Munch({'update_per_batch': True, 'mode': 'multi_step', 'milestones': [20, 40, 60], 'gamma': 0.1})
multi_step
INFO - Validation [   20/  391]   Loss 27.491910   Top1 0.000000   Top5 0.195312   BatchTime 0.875960
INFO - Validation [   40/  391]   Loss 28.447756   Top1 0.000000   Top5 0.097656   BatchTime 0.516565
INFO - Validation [   60/  391]   Loss 27.423508   Top1 0.000000   Top5 0.325521   BatchTime 0.399521
INFO - Validation [   80/  391]   Loss 24.824432   Top1 0.000000   Top5 0.302734   BatchTime 0.343746
INFO - Validation [  100/  391]   Loss 23.227272   Top1 0.000000   Top5 0.242188   BatchTime 0.309943
INFO - Validation [  120/  391]   Loss 23.377299   Top1 0.305990   Top5 0.566406   BatchTime 0.287211
INFO - Validation [  140/  391]   Loss 24.091608   Top1 0.262277   Top5 0.485491   BatchTime 0.270320
INFO - Validation [  160/  391]   Loss 24.117187   Top1 0.229492   Top5 0.424805   BatchTime 0.256339
INFO - Validation [  180/  391]   Loss 23.953608   Top1 0.203993   Top5 0.377604   BatchTime 0.245878
INFO - Validation [  200/  391]   Loss 24.033311   Top1 0.183594   Top5 0.339844   BatchTime 0.237235
INFO - Validation [  220/  391]   Loss 24.153155   Top1 0.174006   Top5 0.486506   BatchTime 0.234145
INFO - Validation [  240/  391]   Loss 24.173441   Top1 0.159505   Top5 0.445964   BatchTime 0.238748
INFO - Validation [  260/  391]   Loss 24.182995   Top1 0.147236   Top5 0.411659   BatchTime 0.231682
INFO - Validation [  280/  391]   Loss 24.245764   Top1 0.136719   Top5 0.474330   BatchTime 0.225594
INFO - Validation [  300/  391]   Loss 24.187008   Top1 0.127604   Top5 0.604167   BatchTime 0.220007
INFO - Validation [  320/  391]   Loss 24.234949   Top1 0.119629   Top5 0.566406   BatchTime 0.215493
INFO - Validation [  340/  391]   Loss 24.112647   Top1 0.112592   Top5 0.567555   BatchTime 0.210831
INFO - Validation [  360/  391]   Loss 24.020886   Top1 0.106337   Top5 0.536024   BatchTime 0.210334
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc71c88dd30>
Traceback (most recent call last):
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1510, in __del__
    self._shutdown_workers()
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1474, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Traceback (most recent call last):
  File "main.py", line 175, in <module>
    main()
  File "main.py", line 118, in main
    top1, top5, _,sparsity = process.validate(val_loader, model, criterion,
  File "/home/ilena7440/LSQ/process.py", line 122, in validate
    outputs = model(inputs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/model/mobilenet.py", line 142, in forward
    x = self.features(x)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/model/mobilenet.py", line 105, in forward
    return self.conv(x)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/quan/func.py", line 23, in forward
    quantized_act = self.quan_a_fn(x)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/quan/quantizer/lsq.py", line 266, in forward
    s_scale = grad_scale(self.s, s_grad_scale)
  File "/home/ilena7440/LSQ/quan/quantizer/lsq.py", line 10, in grad_scale
    y_grad = x * scale
KeyboardInterrupt