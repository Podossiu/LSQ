
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759.log
2022-11-04 00:57:59.026659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 00:57:59.150314: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 00:57:59.541067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 00:57:59.541113: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 00:57:59.541120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/tb_runs
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
Files already downloaded and verified
hello
INFO - Inserted quantizers into the original model
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.412274   Top1 87.968750   Top5 99.257812   BatchTime 0.158560
INFO - Validation [   40/   40]   Loss 0.397417   Top1 88.100000   Top5 99.480000   BatchTime 0.097382
INFO - ==> Top1: 88.100    Top5: 99.480    Loss: 0.397
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 88.100   Top5: 99.480] Sparsity : 0.889
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.177143   Top1 93.906250   Top5 99.980469   BatchTime 0.196866   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.186201   Top1 93.417969   Top5 99.960938   BatchTime 0.140426   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.177503   Top1 93.626302   Top5 99.960938   BatchTime 0.121049   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.177453   Top1 93.691406   Top5 99.946289   BatchTime 0.111439   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.177207   Top1 93.675781   Top5 99.937500   BatchTime 0.105684   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.177202   Top1 93.636068   Top5 99.944661   BatchTime 0.101933   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.178979   Top1 93.571429   Top5 99.941406   BatchTime 0.099104   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.182516   Top1 93.464355   Top5 99.938965   BatchTime 0.096923   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.184360   Top1 93.452691   Top5 99.934896   BatchTime 0.095259   LR 0.010000
INFO - ==> Top1: 93.418    Top5: 99.938    Loss: 0.185
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.398267   Top1 88.261719   Top5 99.335938   BatchTime 0.124062
INFO - Validation [0][   40/   40]   Loss 0.384419   Top1 88.430000   Top5 99.470000   BatchTime 0.078866
INFO - ==> Top1: 88.430    Top5: 99.470    Loss: 0.384
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 88.430   Top5: 99.470] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 88.100   Top5: 99.480] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.168474   Top1 94.296875   Top5 99.960938   BatchTime 0.182193   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.174741   Top1 93.769531   Top5 99.951172   BatchTime 0.132709   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.173303   Top1 93.789062   Top5 99.941406   BatchTime 0.116372   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.172013   Top1 93.837891   Top5 99.941406   BatchTime 0.108088   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.171193   Top1 93.867188   Top5 99.937500   BatchTime 0.104249   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.170979   Top1 93.886719   Top5 99.931641   BatchTime 0.100590   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.171530   Top1 93.828125   Top5 99.933036   BatchTime 0.098038   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.170779   Top1 93.889160   Top5 99.934082   BatchTime 0.096051   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.172272   Top1 93.828125   Top5 99.928385   BatchTime 0.094501   LR 0.010000
INFO - ==> Top1: 93.816    Top5: 99.926    Loss: 0.173
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.382631   Top1 88.359375   Top5 99.433594   BatchTime 0.124522
INFO - Validation [1][   40/   40]   Loss 0.373198   Top1 88.690000   Top5 99.540000   BatchTime 0.079134
INFO - ==> Top1: 88.690    Top5: 99.540    Loss: 0.373
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 88.690   Top5: 99.540] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 88.430   Top5: 99.470] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 88.100   Top5: 99.480] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.148974   Top1 94.941406   Top5 99.980469   BatchTime 0.183785   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.151247   Top1 94.580078   Top5 99.990234   BatchTime 0.133863   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.148430   Top1 94.635417   Top5 99.980469   BatchTime 0.117175   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.153716   Top1 94.443359   Top5 99.965820   BatchTime 0.108989   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.154757   Top1 94.453125   Top5 99.968750   BatchTime 0.103984   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.156036   Top1 94.436849   Top5 99.970703   BatchTime 0.100568   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.159733   Top1 94.249442   Top5 99.966518   BatchTime 0.098180   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.160204   Top1 94.260254   Top5 99.963379   BatchTime 0.096175   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.162302   Top1 94.199219   Top5 99.954427   BatchTime 0.094624   LR 0.010000
INFO - ==> Top1: 94.168    Top5: 99.952    Loss: 0.163
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.378359   Top1 88.710938   Top5 99.472656   BatchTime 0.124878
INFO - Validation [2][   40/   40]   Loss 0.363520   Top1 88.930000   Top5 99.580000   BatchTime 0.079279
INFO - ==> Top1: 88.930    Top5: 99.580    Loss: 0.364
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 88.930   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 88.690   Top5: 99.540] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 88.430   Top5: 99.470] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.143605   Top1 95.136719   Top5 99.960938   BatchTime 0.184649   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.145886   Top1 95.000000   Top5 99.970703   BatchTime 0.134272   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.149114   Top1 94.882812   Top5 99.967448   BatchTime 0.117327   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.150871   Top1 94.809570   Top5 99.951172   BatchTime 0.109255   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.153340   Top1 94.597656   Top5 99.945312   BatchTime 0.104032   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.153755   Top1 94.557292   Top5 99.941406   BatchTime 0.100608   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.153787   Top1 94.567522   Top5 99.938616   BatchTime 0.098266   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.152555   Top1 94.602051   Top5 99.943848   BatchTime 0.096205   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.153178   Top1 94.585503   Top5 99.947917   BatchTime 0.094598   LR 0.010000
INFO - ==> Top1: 94.596    Top5: 99.948    Loss: 0.153
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.382555   Top1 88.906250   Top5 99.433594   BatchTime 0.125380
INFO - Validation [3][   40/   40]   Loss 0.368752   Top1 89.140000   Top5 99.560000   BatchTime 0.079543
INFO - ==> Top1: 89.140    Top5: 99.560    Loss: 0.369
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 89.140   Top5: 99.560] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 88.930   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 88.690   Top5: 99.540] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.146560   Top1 94.726562   Top5 99.921875   BatchTime 0.181542   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.138937   Top1 95.029297   Top5 99.951172   BatchTime 0.132116   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.145760   Top1 94.811198   Top5 99.941406   BatchTime 0.115816   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.146228   Top1 94.877930   Top5 99.951172   BatchTime 0.107531   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.146454   Top1 94.808594   Top5 99.953125   BatchTime 0.102525   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.147510   Top1 94.778646   Top5 99.954427   BatchTime 0.099191   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.149199   Top1 94.693080   Top5 99.958147   BatchTime 0.096765   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.148423   Top1 94.694824   Top5 99.956055   BatchTime 0.094891   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.149209   Top1 94.641927   Top5 99.956597   BatchTime 0.093431   LR 0.010000
INFO - ==> Top1: 94.638    Top5: 99.954    Loss: 0.150
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.376188   Top1 89.082031   Top5 99.453125   BatchTime 0.124561
INFO - Validation [4][   40/   40]   Loss 0.367918   Top1 89.260000   Top5 99.600000   BatchTime 0.079143
INFO - ==> Top1: 89.260    Top5: 99.600    Loss: 0.368
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 89.140   Top5: 99.560] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 88.930   Top5: 99.580] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.140503   Top1 94.785156   Top5 99.980469   BatchTime 0.183396   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.141982   Top1 94.697266   Top5 99.970703   BatchTime 0.134262   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.144210   Top1 94.785156   Top5 99.973958   BatchTime 0.117450   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.142364   Top1 94.907227   Top5 99.960938   BatchTime 0.110638   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.140641   Top1 94.984375   Top5 99.964844   BatchTime 0.105130   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.141817   Top1 94.918620   Top5 99.967448   BatchTime 0.101476   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.142369   Top1 94.843750   Top5 99.969308   BatchTime 0.099010   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.141902   Top1 94.873047   Top5 99.963379   BatchTime 0.096974   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.142848   Top1 94.850260   Top5 99.956597   BatchTime 0.095403   LR 0.010000
INFO - ==> Top1: 94.806    Top5: 99.958    Loss: 0.144
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.372570   Top1 89.316406   Top5 99.511719   BatchTime 0.126197
INFO - Validation [5][   40/   40]   Loss 0.366945   Top1 89.160000   Top5 99.620000   BatchTime 0.079861
INFO - ==> Top1: 89.160    Top5: 99.620    Loss: 0.367
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.160   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 89.140   Top5: 99.560] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.140323   Top1 95.234375   Top5 100.000000   BatchTime 0.183144   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.133921   Top1 95.390625   Top5 99.970703   BatchTime 0.133581   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.135056   Top1 95.338542   Top5 99.954427   BatchTime 0.117348   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.133877   Top1 95.366211   Top5 99.960938   BatchTime 0.109361   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.135624   Top1 95.273438   Top5 99.949219   BatchTime 0.104332   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.136114   Top1 95.276693   Top5 99.957682   BatchTime 0.100831   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.136619   Top1 95.228795   Top5 99.963728   BatchTime 0.098233   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.137835   Top1 95.178223   Top5 99.963379   BatchTime 0.096214   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.138578   Top1 95.123698   Top5 99.965278   BatchTime 0.094658   LR 0.010000
INFO - ==> Top1: 95.126    Top5: 99.968    Loss: 0.139
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.381856   Top1 89.003906   Top5 99.531250   BatchTime 0.125208
INFO - Validation [6][   40/   40]   Loss 0.377325   Top1 89.040000   Top5 99.600000   BatchTime 0.079392
INFO - ==> Top1: 89.040    Top5: 99.600    Loss: 0.377
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.160   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 89.140   Top5: 99.560] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.129045   Top1 95.468750   Top5 99.980469   BatchTime 0.181409   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.125937   Top1 95.615234   Top5 99.951172   BatchTime 0.132505   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.127275   Top1 95.625000   Top5 99.954427   BatchTime 0.116122   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.129755   Top1 95.449219   Top5 99.960938   BatchTime 0.107760   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.131121   Top1 95.375000   Top5 99.964844   BatchTime 0.102924   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.133299   Top1 95.292969   Top5 99.960938   BatchTime 0.099941   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.134928   Top1 95.206473   Top5 99.955357   BatchTime 0.097687   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.134564   Top1 95.197754   Top5 99.953613   BatchTime 0.095728   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.134275   Top1 95.221354   Top5 99.956597   BatchTime 0.094205   LR 0.010000
INFO - ==> Top1: 95.208    Top5: 99.960    Loss: 0.135
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.383955   Top1 89.433594   Top5 99.511719   BatchTime 0.124905
INFO - Validation [7][   40/   40]   Loss 0.378454   Top1 89.170000   Top5 99.580000   BatchTime 0.079267
INFO - ==> Top1: 89.170    Top5: 99.580    Loss: 0.378
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.170   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 89.160   Top5: 99.620] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.132519   Top1 95.214844   Top5 99.921875   BatchTime 0.181918   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.136060   Top1 95.107422   Top5 99.951172   BatchTime 0.133057   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.132499   Top1 95.305990   Top5 99.954427   BatchTime 0.116559   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.131760   Top1 95.288086   Top5 99.965820   BatchTime 0.108482   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.129027   Top1 95.429688   Top5 99.964844   BatchTime 0.103397   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.128234   Top1 95.439453   Top5 99.967448   BatchTime 0.100224   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.128387   Top1 95.452009   Top5 99.966518   BatchTime 0.097664   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.129379   Top1 95.427246   Top5 99.968262   BatchTime 0.095709   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.130299   Top1 95.410156   Top5 99.965278   BatchTime 0.094212   LR 0.010000
INFO - ==> Top1: 95.382    Top5: 99.964    Loss: 0.130
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.381891   Top1 89.277344   Top5 99.414062   BatchTime 0.124939
INFO - Validation [8][   40/   40]   Loss 0.368337   Top1 89.470000   Top5 99.580000   BatchTime 0.079203
INFO - ==> Top1: 89.470    Top5: 99.580    Loss: 0.368
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 89.470   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 89.170   Top5: 99.580] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.128750   Top1 95.683594   Top5 99.960938   BatchTime 0.181686   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.128741   Top1 95.566406   Top5 99.960938   BatchTime 0.132928   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.131365   Top1 95.351562   Top5 99.960938   BatchTime 0.116407   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.126354   Top1 95.473633   Top5 99.960938   BatchTime 0.108497   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.126359   Top1 95.457031   Top5 99.964844   BatchTime 0.103701   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.124953   Top1 95.501302   Top5 99.964193   BatchTime 0.101488   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.126201   Top1 95.454799   Top5 99.963728   BatchTime 0.098965   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.127264   Top1 95.390625   Top5 99.960938   BatchTime 0.096895   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.127755   Top1 95.412326   Top5 99.963108   BatchTime 0.095267   LR 0.010000
INFO - ==> Top1: 95.360    Top5: 99.966    Loss: 0.130
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.389353   Top1 88.964844   Top5 99.453125   BatchTime 0.124909
INFO - Validation [9][   40/   40]   Loss 0.375893   Top1 89.120000   Top5 99.550000   BatchTime 0.079213
INFO - ==> Top1: 89.120    Top5: 99.550    Loss: 0.376
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 89.470   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 89.170   Top5: 99.580] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.123203   Top1 95.644531   Top5 100.000000   BatchTime 0.183802   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.116450   Top1 96.044922   Top5 99.970703   BatchTime 0.134053   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.119315   Top1 95.976562   Top5 99.973958   BatchTime 0.117300   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.122246   Top1 95.820312   Top5 99.970703   BatchTime 0.109299   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.122469   Top1 95.773438   Top5 99.957031   BatchTime 0.103995   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.123010   Top1 95.670573   Top5 99.960938   BatchTime 0.100795   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.123104   Top1 95.680804   Top5 99.960938   BatchTime 0.098258   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.123516   Top1 95.651855   Top5 99.965820   BatchTime 0.096186   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.125156   Top1 95.559896   Top5 99.965278   BatchTime 0.094609   LR 0.010000
INFO - ==> Top1: 95.586    Top5: 99.964    Loss: 0.125
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.390700   Top1 89.121094   Top5 99.375000   BatchTime 0.125681
INFO - Validation [10][   40/   40]   Loss 0.370828   Top1 89.500000   Top5 99.520000   BatchTime 0.079858
INFO - ==> Top1: 89.500    Top5: 99.520    Loss: 0.371
INFO - Scoreboard best 1 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [8][Top1: 89.470   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.260   Top5: 99.600] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.112252   Top1 96.074219   Top5 99.980469   BatchTime 0.181134   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.116475   Top1 95.888672   Top5 99.980469   BatchTime 0.133029   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.117521   Top1 95.813802   Top5 99.967448   BatchTime 0.116512   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.118428   Top1 95.834961   Top5 99.960938   BatchTime 0.108452   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.121153   Top1 95.781250   Top5 99.949219   BatchTime 0.103488   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.120959   Top1 95.787760   Top5 99.951172   BatchTime 0.100220   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.122198   Top1 95.772879   Top5 99.946987   BatchTime 0.097725   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.121520   Top1 95.766602   Top5 99.953613   BatchTime 0.095706   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.122270   Top1 95.768229   Top5 99.956597   BatchTime 0.094195   LR 0.010000
INFO - ==> Top1: 95.740    Top5: 99.958    Loss: 0.123
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.400149   Top1 88.964844   Top5 99.433594   BatchTime 0.124516
INFO - Validation [11][   40/   40]   Loss 0.380521   Top1 89.450000   Top5 99.550000   BatchTime 0.079068
INFO - ==> Top1: 89.450    Top5: 99.550    Loss: 0.381
INFO - Scoreboard best 1 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [8][Top1: 89.470   Top5: 99.580] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 89.450   Top5: 99.550] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.114408   Top1 96.152344   Top5 99.980469   BatchTime 0.181362   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.115473   Top1 95.986328   Top5 99.990234   BatchTime 0.132365   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.119703   Top1 95.878906   Top5 99.980469   BatchTime 0.115780   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.117308   Top1 96.000977   Top5 99.985352   BatchTime 0.107895   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.116893   Top1 95.984375   Top5 99.984375   BatchTime 0.103012   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.118471   Top1 95.924479   Top5 99.983724   BatchTime 0.099656   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.118694   Top1 95.851004   Top5 99.986049   BatchTime 0.097351   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.119576   Top1 95.776367   Top5 99.985352   BatchTime 0.095415   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.119268   Top1 95.820312   Top5 99.984809   BatchTime 0.093889   LR 0.010000
INFO - ==> Top1: 95.776    Top5: 99.986    Loss: 0.120
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.385020   Top1 89.394531   Top5 99.531250   BatchTime 0.124941
INFO - Validation [12][   40/   40]   Loss 0.371462   Top1 89.530000   Top5 99.610000   BatchTime 0.079307
INFO - ==> Top1: 89.530    Top5: 99.610    Loss: 0.371
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 89.470   Top5: 99.580] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.108239   Top1 96.074219   Top5 100.000000   BatchTime 0.182289   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.116927   Top1 95.830078   Top5 100.000000   BatchTime 0.132730   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.120601   Top1 95.664062   Top5 99.986979   BatchTime 0.116299   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.118534   Top1 95.712891   Top5 99.990234   BatchTime 0.108040   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.119140   Top1 95.707031   Top5 99.984375   BatchTime 0.103092   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.120452   Top1 95.719401   Top5 99.980469   BatchTime 0.100874   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.119989   Top1 95.744978   Top5 99.974888   BatchTime 0.098217   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.119523   Top1 95.759277   Top5 99.975586   BatchTime 0.096104   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.120298   Top1 95.740017   Top5 99.969618   BatchTime 0.094469   LR 0.010000
INFO - ==> Top1: 95.758    Top5: 99.972    Loss: 0.120
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.387727   Top1 89.238281   Top5 99.492188   BatchTime 0.125080
INFO - Validation [13][   40/   40]   Loss 0.373618   Top1 89.480000   Top5 99.580000   BatchTime 0.079326
INFO - ==> Top1: 89.480    Top5: 99.580    Loss: 0.374
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [13][Top1: 89.480   Top5: 99.580] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.105805   Top1 96.386719   Top5 100.000000   BatchTime 0.183501   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.108130   Top1 96.269531   Top5 99.970703   BatchTime 0.134270   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.108582   Top1 96.302083   Top5 99.973958   BatchTime 0.117684   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.109182   Top1 96.318359   Top5 99.975586   BatchTime 0.109120   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.107971   Top1 96.332031   Top5 99.980469   BatchTime 0.104011   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.109362   Top1 96.279297   Top5 99.973958   BatchTime 0.100644   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.111519   Top1 96.149554   Top5 99.969308   BatchTime 0.098158   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.113966   Top1 96.049805   Top5 99.968262   BatchTime 0.096109   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.115889   Top1 95.972222   Top5 99.971788   BatchTime 0.094552   LR 0.010000
INFO - ==> Top1: 95.982    Top5: 99.972    Loss: 0.116
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.384217   Top1 89.101562   Top5 99.550781   BatchTime 0.124545
INFO - Validation [14][   40/   40]   Loss 0.373045   Top1 89.500000   Top5 99.630000   BatchTime 0.079220
INFO - ==> Top1: 89.500    Top5: 99.630    Loss: 0.373
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 89.500   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.114533   Top1 95.722656   Top5 99.980469   BatchTime 0.182350   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.112526   Top1 95.888672   Top5 99.960938   BatchTime 0.133050   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.109587   Top1 95.911458   Top5 99.967448   BatchTime 0.116528   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.108807   Top1 96.064453   Top5 99.975586   BatchTime 0.108333   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.111312   Top1 96.007812   Top5 99.976562   BatchTime 0.103241   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.111770   Top1 95.957031   Top5 99.973958   BatchTime 0.100175   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.112695   Top1 95.906808   Top5 99.974888   BatchTime 0.097757   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.114634   Top1 95.886230   Top5 99.968262   BatchTime 0.095751   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.114498   Top1 95.909288   Top5 99.971788   BatchTime 0.094178   LR 0.010000
INFO - ==> Top1: 95.918    Top5: 99.974    Loss: 0.114
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.392034   Top1 89.296875   Top5 99.414062   BatchTime 0.124425
INFO - Validation [15][   40/   40]   Loss 0.377765   Top1 89.420000   Top5 99.570000   BatchTime 0.079138
INFO - ==> Top1: 89.420    Top5: 99.570    Loss: 0.378
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 89.500   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.098467   Top1 96.503906   Top5 100.000000   BatchTime 0.181058   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.100135   Top1 96.523438   Top5 99.990234   BatchTime 0.132369   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.103941   Top1 96.347656   Top5 99.993490   BatchTime 0.115786   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.103836   Top1 96.303711   Top5 99.995117   BatchTime 0.108099   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.105014   Top1 96.246094   Top5 99.992188   BatchTime 0.103282   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.105794   Top1 96.210938   Top5 99.990234   BatchTime 0.099862   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.107540   Top1 96.143973   Top5 99.988839   BatchTime 0.097323   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.108010   Top1 96.137695   Top5 99.985352   BatchTime 0.095413   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.108653   Top1 96.115451   Top5 99.986979   BatchTime 0.093868   LR 0.010000
INFO - ==> Top1: 96.084    Top5: 99.986    Loss: 0.109
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.390829   Top1 89.179688   Top5 99.472656   BatchTime 0.125206
INFO - Validation [16][   40/   40]   Loss 0.377074   Top1 89.460000   Top5 99.590000   BatchTime 0.079447
INFO - ==> Top1: 89.460    Top5: 99.590    Loss: 0.377
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 89.500   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 89.500   Top5: 99.520] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.106105   Top1 96.289062   Top5 99.941406   BatchTime 0.184204   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.100671   Top1 96.513672   Top5 99.951172   BatchTime 0.134295   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.102405   Top1 96.432292   Top5 99.967448   BatchTime 0.117866   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.104987   Top1 96.333008   Top5 99.970703   BatchTime 0.109508   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.104940   Top1 96.312500   Top5 99.968750   BatchTime 0.104437   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.105027   Top1 96.292318   Top5 99.967448   BatchTime 0.100961   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.106095   Top1 96.277902   Top5 99.958147   BatchTime 0.098434   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.105297   Top1 96.303711   Top5 99.963379   BatchTime 0.096451   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.105528   Top1 96.304253   Top5 99.963108   BatchTime 0.094823   LR 0.010000
INFO - ==> Top1: 96.268    Top5: 99.962    Loss: 0.106
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.386260   Top1 89.453125   Top5 99.531250   BatchTime 0.124924
INFO - Validation [17][   40/   40]   Loss 0.371763   Top1 89.810000   Top5 99.590000   BatchTime 0.079262
INFO - ==> Top1: 89.810    Top5: 99.590    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.810   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 89.500   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.103497   Top1 96.367188   Top5 100.000000   BatchTime 0.183189   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.103487   Top1 96.191406   Top5 99.990234   BatchTime 0.133749   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.101654   Top1 96.256510   Top5 99.993490   BatchTime 0.118026   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.102905   Top1 96.220703   Top5 99.995117   BatchTime 0.109755   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.102330   Top1 96.277344   Top5 99.988281   BatchTime 0.104885   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.106614   Top1 96.110026   Top5 99.977214   BatchTime 0.101373   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.108304   Top1 96.035156   Top5 99.977679   BatchTime 0.098768   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.107589   Top1 96.083984   Top5 99.975586   BatchTime 0.096638   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.108439   Top1 96.063368   Top5 99.973958   BatchTime 0.095038   LR 0.010000
INFO - ==> Top1: 96.014    Top5: 99.972    Loss: 0.110
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.396684   Top1 88.964844   Top5 99.511719   BatchTime 0.124913
INFO - Validation [18][   40/   40]   Loss 0.376499   Top1 89.380000   Top5 99.610000   BatchTime 0.079434
INFO - ==> Top1: 89.380    Top5: 99.610    Loss: 0.376
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.810   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 89.500   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.109512   Top1 96.152344   Top5 99.980469   BatchTime 0.182752   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.099854   Top1 96.386719   Top5 99.990234   BatchTime 0.133487   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.101605   Top1 96.334635   Top5 99.993490   BatchTime 0.116881   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.101274   Top1 96.328125   Top5 99.995117   BatchTime 0.108777   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.099410   Top1 96.433594   Top5 99.992188   BatchTime 0.104769   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.101053   Top1 96.399740   Top5 99.993490   BatchTime 0.101442   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.101161   Top1 96.400670   Top5 99.994420   BatchTime 0.098929   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.103617   Top1 96.313477   Top5 99.992676   BatchTime 0.097163   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.103496   Top1 96.302083   Top5 99.991319   BatchTime 0.096160   LR 0.010000
INFO - ==> Top1: 96.280    Top5: 99.992    Loss: 0.104
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.389818   Top1 89.199219   Top5 99.609375   BatchTime 0.145158
INFO - Validation [19][   40/   40]   Loss 0.372259   Top1 89.560000   Top5 99.630000   BatchTime 0.091506
INFO - ==> Top1: 89.560    Top5: 99.630    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.810   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [19][Top1: 89.560   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 89.530   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.094976   Top1 96.835938   Top5 99.960938   BatchTime 0.260797   LR 0.001000
INFO - Training [20][   40/  196]   Loss 0.096993   Top1 96.728516   Top5 99.970703   BatchTime 0.206190   LR 0.001000
INFO - Training [20][   60/  196]   Loss 0.100895   Top1 96.523438   Top5 99.980469   BatchTime 0.187559   LR 0.001000
INFO - Training [20][   80/  196]   Loss 0.099457   Top1 96.518555   Top5 99.980469   BatchTime 0.178343   LR 0.001000
INFO - Training [20][  100/  196]   Loss 0.099223   Top1 96.492188   Top5 99.980469   BatchTime 0.172734   LR 0.001000
INFO - Training [20][  120/  196]   Loss 0.098181   Top1 96.529948   Top5 99.977214   BatchTime 0.169055   LR 0.001000
INFO - Training [20][  140/  196]   Loss 0.098076   Top1 96.548549   Top5 99.980469   BatchTime 0.166298   LR 0.001000
INFO - Training [20][  160/  196]   Loss 0.096956   Top1 96.596680   Top5 99.980469   BatchTime 0.164324   LR 0.001000
INFO - Training [20][  180/  196]   Loss 0.097175   Top1 96.575521   Top5 99.982639   BatchTime 0.162689   LR 0.001000
INFO - ==> Top1: 96.582    Top5: 99.984    Loss: 0.097
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.386811   Top1 89.414062   Top5 99.570312   BatchTime 0.147600
INFO - Validation [20][   40/   40]   Loss 0.365739   Top1 89.880000   Top5 99.650000   BatchTime 0.098577
INFO - ==> Top1: 89.880    Top5: 99.650    Loss: 0.366
INFO - Scoreboard best 1 ==> Epoch [20][Top1: 89.880   Top5: 99.650] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 89.810   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [19][Top1: 89.560   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.088100   Top1 96.835938   Top5 99.980469   BatchTime 0.256816   LR 0.001000
INFO - Training [21][   40/  196]   Loss 0.091106   Top1 96.738281   Top5 99.980469   BatchTime 0.203932   LR 0.001000
INFO - Training [21][   60/  196]   Loss 0.093394   Top1 96.640625   Top5 99.980469   BatchTime 0.186079   LR 0.001000
INFO - Training [21][   80/  196]   Loss 0.092100   Top1 96.723633   Top5 99.975586   BatchTime 0.177405   LR 0.001000
INFO - Training [21][  100/  196]   Loss 0.092198   Top1 96.730469   Top5 99.980469   BatchTime 0.172079   LR 0.001000
INFO - Training [21][  120/  196]   Loss 0.090562   Top1 96.819661   Top5 99.980469   BatchTime 0.168097   LR 0.001000
INFO - Training [21][  140/  196]   Loss 0.089973   Top1 96.852679   Top5 99.980469   BatchTime 0.165565   LR 0.001000
INFO - Training [21][  160/  196]   Loss 0.090275   Top1 96.843262   Top5 99.980469   BatchTime 0.163604   LR 0.001000
INFO - Training [21][  180/  196]   Loss 0.090551   Top1 96.814236   Top5 99.980469   BatchTime 0.162069   LR 0.001000
INFO - ==> Top1: 96.824    Top5: 99.982    Loss: 0.091
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.391199   Top1 89.218750   Top5 99.531250   BatchTime 0.148084
INFO - Validation [21][   40/   40]   Loss 0.371011   Top1 89.720000   Top5 99.620000   BatchTime 0.094736
INFO - ==> Top1: 89.720    Top5: 99.620    Loss: 0.371
INFO - Scoreboard best 1 ==> Epoch [20][Top1: 89.880   Top5: 99.650] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 89.810   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 89.720   Top5: 99.620] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.091497   Top1 96.816406   Top5 100.000000   BatchTime 0.262414   LR 0.001000
INFO - Training [22][   40/  196]   Loss 0.090372   Top1 96.767578   Top5 99.980469   BatchTime 0.206944   LR 0.001000
INFO - Training [22][   60/  196]   Loss 0.087640   Top1 96.803385   Top5 99.980469   BatchTime 0.188514   LR 0.001000
INFO - Training [22][   80/  196]   Loss 0.087825   Top1 96.816406   Top5 99.975586   BatchTime 0.179268   LR 0.001000
INFO - Training [22][  100/  196]   Loss 0.088802   Top1 96.843750   Top5 99.980469   BatchTime 0.173719   LR 0.001000
INFO - Training [22][  120/  196]   Loss 0.088281   Top1 96.861979   Top5 99.980469   BatchTime 0.170119   LR 0.001000
INFO - Training [22][  140/  196]   Loss 0.088113   Top1 96.863839   Top5 99.983259   BatchTime 0.167408   LR 0.001000
INFO - Training [22][  160/  196]   Loss 0.087827   Top1 96.884766   Top5 99.985352   BatchTime 0.165219   LR 0.001000
INFO - Training [22][  180/  196]   Loss 0.088131   Top1 96.888021   Top5 99.984809   BatchTime 0.163545   LR 0.001000
INFO - ==> Top1: 96.858    Top5: 99.986    Loss: 0.089
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.387893   Top1 89.511719   Top5 99.511719   BatchTime 0.148514
INFO - Validation [22][   40/   40]   Loss 0.363651   Top1 89.880000   Top5 99.660000   BatchTime 0.092056
INFO - ==> Top1: 89.880    Top5: 99.660    Loss: 0.364
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 89.880   Top5: 99.660] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 89.880   Top5: 99.650] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 89.810   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.082713   Top1 96.894531   Top5 100.000000   BatchTime 0.257942   LR 0.001000
INFO - Training [23][   40/  196]   Loss 0.082920   Top1 97.060547   Top5 99.990234   BatchTime 0.204713   LR 0.001000
INFO - Training [23][   60/  196]   Loss 0.082227   Top1 97.037760   Top5 99.993490   BatchTime 0.186703   LR 0.001000
INFO - Training [23][   80/  196]   Loss 0.083182   Top1 96.987305   Top5 99.995117   BatchTime 0.178044   LR 0.001000
INFO - Training [23][  100/  196]   Loss 0.083726   Top1 97.019531   Top5 99.988281   BatchTime 0.172754   LR 0.001000
INFO - Training [23][  120/  196]   Loss 0.083375   Top1 97.018229   Top5 99.983724   BatchTime 0.168966   LR 0.001000
INFO - Training [23][  140/  196]   Loss 0.084325   Top1 96.994978   Top5 99.986049   BatchTime 0.166399   LR 0.001000
INFO - Training [23][  160/  196]   Loss 0.083591   Top1 97.065430   Top5 99.985352   BatchTime 0.164360   LR 0.001000
INFO - Training [23][  180/  196]   Loss 0.085017   Top1 97.031250   Top5 99.984809   BatchTime 0.162734   LR 0.001000
INFO - ==> Top1: 97.026    Top5: 99.986    Loss: 0.085
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.388042   Top1 89.453125   Top5 99.531250   BatchTime 0.141475
INFO - Validation [23][   40/   40]   Loss 0.364709   Top1 90.050000   Top5 99.620000   BatchTime 0.087821
INFO - ==> Top1: 90.050    Top5: 99.620    Loss: 0.365
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.050   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 89.880   Top5: 99.660] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 89.880   Top5: 99.650] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.083027   Top1 97.011719   Top5 100.000000   BatchTime 0.259408   LR 0.001000
INFO - Training [24][   40/  196]   Loss 0.085496   Top1 96.933594   Top5 99.990234   BatchTime 0.205337   LR 0.001000
INFO - Training [24][   60/  196]   Loss 0.084733   Top1 97.005208   Top5 99.993490   BatchTime 0.187410   LR 0.001000
INFO - Training [24][   80/  196]   Loss 0.083323   Top1 97.089844   Top5 99.995117   BatchTime 0.178308   LR 0.001000
INFO - Training [24][  100/  196]   Loss 0.083807   Top1 97.093750   Top5 99.996094   BatchTime 0.172923   LR 0.001000
INFO - Training [24][  120/  196]   Loss 0.083487   Top1 97.070312   Top5 99.993490   BatchTime 0.169297   LR 0.001000
INFO - Training [24][  140/  196]   Loss 0.082177   Top1 97.106585   Top5 99.994420   BatchTime 0.166515   LR 0.001000
INFO - Training [24][  160/  196]   Loss 0.082837   Top1 97.070312   Top5 99.995117   BatchTime 0.164407   LR 0.001000
INFO - Training [24][  180/  196]   Loss 0.083146   Top1 97.059462   Top5 99.995660   BatchTime 0.162400   LR 0.001000
INFO - ==> Top1: 97.064    Top5: 99.994    Loss: 0.083
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.384649   Top1 89.511719   Top5 99.531250   BatchTime 0.133962
INFO - Validation [24][   40/   40]   Loss 0.367132   Top1 90.060000   Top5 99.610000   BatchTime 0.084211
INFO - ==> Top1: 90.060    Top5: 99.610    Loss: 0.367
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 90.060   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.050   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 89.880   Top5: 99.660] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.080909   Top1 96.953125   Top5 99.980469   BatchTime 0.255303   LR 0.001000
INFO - Training [25][   40/  196]   Loss 0.081185   Top1 97.158203   Top5 99.990234   BatchTime 0.203347   LR 0.001000
INFO - Training [25][   60/  196]   Loss 0.083005   Top1 97.044271   Top5 99.993490   BatchTime 0.186000   LR 0.001000
INFO - Training [25][   80/  196]   Loss 0.081942   Top1 97.075195   Top5 99.995117   BatchTime 0.177305   LR 0.001000
INFO - Training [25][  100/  196]   Loss 0.083519   Top1 96.980469   Top5 99.996094   BatchTime 0.171332   LR 0.001000
INFO - Training [25][  120/  196]   Loss 0.084081   Top1 96.992188   Top5 99.996745   BatchTime 0.167934   LR 0.001000
INFO - Training [25][  140/  196]   Loss 0.083203   Top1 97.000558   Top5 99.997210   BatchTime 0.165362   LR 0.001000
INFO - Training [25][  160/  196]   Loss 0.083304   Top1 96.972656   Top5 99.997559   BatchTime 0.163389   LR 0.001000
INFO - Training [25][  180/  196]   Loss 0.084085   Top1 96.942274   Top5 99.995660   BatchTime 0.161003   LR 0.001000
INFO - ==> Top1: 96.936    Top5: 99.996    Loss: 0.084
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.382384   Top1 89.746094   Top5 99.492188   BatchTime 0.135757
INFO - Validation [25][   40/   40]   Loss 0.365779   Top1 90.050000   Top5 99.610000   BatchTime 0.084919
INFO - ==> Top1: 90.050    Top5: 99.610    Loss: 0.366
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 90.060   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.050   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 90.050   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.079537   Top1 97.109375   Top5 100.000000   BatchTime 0.250459   LR 0.001000
INFO - Training [26][   40/  196]   Loss 0.076736   Top1 97.197266   Top5 99.990234   BatchTime 0.200918   LR 0.001000
INFO - Training [26][   60/  196]   Loss 0.076109   Top1 97.207031   Top5 99.986979   BatchTime 0.184351   LR 0.001000
INFO - Training [26][   80/  196]   Loss 0.080207   Top1 97.021484   Top5 99.990234   BatchTime 0.176215   LR 0.001000
INFO - Training [26][  100/  196]   Loss 0.082293   Top1 96.988281   Top5 99.992188   BatchTime 0.171360   LR 0.001000
INFO - Training [26][  120/  196]   Loss 0.083570   Top1 96.972656   Top5 99.990234   BatchTime 0.168063   LR 0.001000
INFO - Training [26][  140/  196]   Loss 0.083607   Top1 96.989397   Top5 99.991629   BatchTime 0.165485   LR 0.001000
INFO - Training [26][  160/  196]   Loss 0.083589   Top1 96.975098   Top5 99.992676   BatchTime 0.163502   LR 0.001000
INFO - Training [26][  180/  196]   Loss 0.083727   Top1 96.950955   Top5 99.993490   BatchTime 0.159813   LR 0.001000
INFO - ==> Top1: 96.940    Top5: 99.994    Loss: 0.084
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.382874   Top1 89.667969   Top5 99.570312   BatchTime 0.132651
INFO - Validation [26][   40/   40]   Loss 0.367388   Top1 90.090000   Top5 99.620000   BatchTime 0.091629
INFO - ==> Top1: 90.090    Top5: 99.620    Loss: 0.367
INFO - Scoreboard best 1 ==> Epoch [26][Top1: 90.090   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 90.060   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 90.050   Top5: 99.620] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.081148   Top1 97.031250   Top5 100.000000   BatchTime 0.252737   LR 0.001000
INFO - Training [27][   40/  196]   Loss 0.079246   Top1 97.167969   Top5 100.000000   BatchTime 0.201663   LR 0.001000
INFO - Training [27][   60/  196]   Loss 0.079526   Top1 97.187500   Top5 100.000000   BatchTime 0.184797   LR 0.001000
INFO - Training [27][   80/  196]   Loss 0.081220   Top1 97.128906   Top5 100.000000   BatchTime 0.176425   LR 0.001000
INFO - Training [27][  100/  196]   Loss 0.081214   Top1 97.156250   Top5 99.996094   BatchTime 0.171297   LR 0.001000
INFO - Training [27][  120/  196]   Loss 0.081928   Top1 97.106120   Top5 99.996745   BatchTime 0.167942   LR 0.001000
INFO - Training [27][  140/  196]   Loss 0.081341   Top1 97.126116   Top5 99.997210   BatchTime 0.165351   LR 0.001000
INFO - Training [27][  160/  196]   Loss 0.081833   Top1 97.131348   Top5 99.992676   BatchTime 0.163390   LR 0.001000
INFO - Training [27][  180/  196]   Loss 0.082143   Top1 97.105035   Top5 99.993490   BatchTime 0.156734   LR 0.001000
INFO - ==> Top1: 97.090    Top5: 99.992    Loss: 0.083
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.384942   Top1 89.550781   Top5 99.531250   BatchTime 0.137242
INFO - Validation [27][   40/   40]   Loss 0.366945   Top1 90.040000   Top5 99.600000   BatchTime 0.105933
INFO - ==> Top1: 90.040    Top5: 99.600    Loss: 0.367
INFO - Scoreboard best 1 ==> Epoch [26][Top1: 90.090   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 90.060   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 90.050   Top5: 99.620] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.095529   Top1 96.289062   Top5 99.960938   BatchTime 0.251177   LR 0.001000
INFO - Training [28][   40/  196]   Loss 0.086625   Top1 96.835938   Top5 99.980469   BatchTime 0.201363   LR 0.001000
INFO - Training [28][   60/  196]   Loss 0.085578   Top1 96.992188   Top5 99.986979   BatchTime 0.184661   LR 0.001000
INFO - Training [28][   80/  196]   Loss 0.083585   Top1 97.031250   Top5 99.990234   BatchTime 0.176332   LR 0.001000
INFO - Training [28][  100/  196]   Loss 0.082785   Top1 97.085938   Top5 99.992188   BatchTime 0.171208   LR 0.001000
INFO - Training [28][  120/  196]   Loss 0.082295   Top1 97.083333   Top5 99.983724   BatchTime 0.167776   LR 0.001000
INFO - Training [28][  140/  196]   Loss 0.082463   Top1 97.047991   Top5 99.983259   BatchTime 0.165196   LR 0.001000
INFO - Training [28][  160/  196]   Loss 0.082394   Top1 97.055664   Top5 99.982910   BatchTime 0.162939   LR 0.001000
INFO - Training [28][  180/  196]   Loss 0.083519   Top1 97.039931   Top5 99.982639   BatchTime 0.154626   LR 0.001000
INFO - ==> Top1: 97.010    Top5: 99.982    Loss: 0.084
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.387777   Top1 89.785156   Top5 99.511719   BatchTime 0.156063
INFO - Validation [28][   40/   40]   Loss 0.368056   Top1 90.210000   Top5 99.610000   BatchTime 0.114916
INFO - ==> Top1: 90.210    Top5: 99.610    Loss: 0.368
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.090   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 90.060   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.074636   Top1 97.285156   Top5 100.000000   BatchTime 0.252734   LR 0.001000
INFO - Training [29][   40/  196]   Loss 0.079187   Top1 97.197266   Top5 100.000000   BatchTime 0.202163   LR 0.001000
INFO - Training [29][   60/  196]   Loss 0.078193   Top1 97.259115   Top5 99.993490   BatchTime 0.185094   LR 0.001000
INFO - Training [29][   80/  196]   Loss 0.076938   Top1 97.314453   Top5 99.990234   BatchTime 0.176714   LR 0.001000
INFO - Training [29][  100/  196]   Loss 0.078849   Top1 97.269531   Top5 99.984375   BatchTime 0.171406   LR 0.001000
INFO - Training [29][  120/  196]   Loss 0.079492   Top1 97.262370   Top5 99.986979   BatchTime 0.167207   LR 0.001000
INFO - Training [29][  140/  196]   Loss 0.079615   Top1 97.282366   Top5 99.988839   BatchTime 0.164959   LR 0.001000
INFO - Training [29][  160/  196]   Loss 0.079956   Top1 97.270508   Top5 99.985352   BatchTime 0.159568   LR 0.001000
INFO - Training [29][  180/  196]   Loss 0.079912   Top1 97.267795   Top5 99.986979   BatchTime 0.152627   LR 0.001000
INFO - ==> Top1: 97.226    Top5: 99.988    Loss: 0.080
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.392481   Top1 89.667969   Top5 99.511719   BatchTime 0.176577
INFO - Validation [29][   40/   40]   Loss 0.369736   Top1 90.080000   Top5 99.610000   BatchTime 0.125302
INFO - ==> Top1: 90.080    Top5: 99.610    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 90.090   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 90.080   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.079195   Top1 96.992188   Top5 100.000000   BatchTime 0.263287   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.074118   Top1 97.304688   Top5 100.000000   BatchTime 0.207466   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.075364   Top1 97.213542   Top5 100.000000   BatchTime 0.188713   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.076420   Top1 97.241211   Top5 99.995117   BatchTime 0.179446   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.076455   Top1 97.265625   Top5 99.992188   BatchTime 0.173789   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.076983   Top1 97.285156   Top5 99.986979   BatchTime 0.169877   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.079562   Top1 97.201451   Top5 99.983259   BatchTime 0.167111   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.079718   Top1 97.233887   Top5 99.982910   BatchTime 0.159367   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.080151   Top1 97.207031   Top5 99.984809   BatchTime 0.153861   LR 0.001000
INFO - ==> Top1: 97.224    Top5: 99.986    Loss: 0.080
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.393374   Top1 89.628906   Top5 99.492188   BatchTime 0.177975
INFO - Validation [30][   40/   40]   Loss 0.367578   Top1 90.190000   Top5 99.590000   BatchTime 0.126063
INFO - ==> Top1: 90.190    Top5: 99.590    Loss: 0.368
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.090   Top5: 99.620] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.089795   Top1 96.875000   Top5 100.000000   BatchTime 0.248664   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.086076   Top1 97.001953   Top5 99.990234   BatchTime 0.199937   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.085634   Top1 97.122396   Top5 99.980469   BatchTime 0.183869   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.083865   Top1 97.138672   Top5 99.985352   BatchTime 0.175802   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.082942   Top1 97.132812   Top5 99.988281   BatchTime 0.170625   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.081709   Top1 97.158203   Top5 99.990234   BatchTime 0.167330   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.080551   Top1 97.193080   Top5 99.988839   BatchTime 0.164592   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.080796   Top1 97.160645   Top5 99.990234   BatchTime 0.154828   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.080444   Top1 97.150608   Top5 99.991319   BatchTime 0.150245   LR 0.001000
INFO - ==> Top1: 97.170    Top5: 99.990    Loss: 0.080
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.392615   Top1 89.609375   Top5 99.492188   BatchTime 0.176754
INFO - Validation [31][   40/   40]   Loss 0.370197   Top1 89.980000   Top5 99.600000   BatchTime 0.125375
INFO - ==> Top1: 89.980    Top5: 99.600    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.090   Top5: 99.620] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.072099   Top1 97.617188   Top5 100.000000   BatchTime 0.249187   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.078698   Top1 97.294922   Top5 99.990234   BatchTime 0.199888   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.078419   Top1 97.317708   Top5 99.993490   BatchTime 0.183541   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.080116   Top1 97.246094   Top5 99.990234   BatchTime 0.175589   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.080276   Top1 97.238281   Top5 99.988281   BatchTime 0.170496   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.079624   Top1 97.262370   Top5 99.990234   BatchTime 0.167153   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.078748   Top1 97.296317   Top5 99.988839   BatchTime 0.163694   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.079235   Top1 97.290039   Top5 99.985352   BatchTime 0.154295   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.079597   Top1 97.280816   Top5 99.984809   BatchTime 0.149623   LR 0.001000
INFO - ==> Top1: 97.258    Top5: 99.986    Loss: 0.080
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.385350   Top1 89.707031   Top5 99.531250   BatchTime 0.178421
INFO - Validation [32][   40/   40]   Loss 0.364970   Top1 90.130000   Top5 99.630000   BatchTime 0.126298
INFO - ==> Top1: 90.130    Top5: 99.630    Loss: 0.365
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.080781   Top1 97.050781   Top5 99.980469   BatchTime 0.250706   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.074091   Top1 97.363281   Top5 99.990234   BatchTime 0.201789   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.074123   Top1 97.415365   Top5 99.993490   BatchTime 0.184779   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.076154   Top1 97.333984   Top5 99.995117   BatchTime 0.176429   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.076816   Top1 97.316406   Top5 99.996094   BatchTime 0.171251   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.077004   Top1 97.340495   Top5 99.993490   BatchTime 0.167748   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.077978   Top1 97.296317   Top5 99.994420   BatchTime 0.162293   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.078114   Top1 97.290039   Top5 99.990234   BatchTime 0.153790   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.078482   Top1 97.256944   Top5 99.991319   BatchTime 0.149175   LR 0.001000
INFO - ==> Top1: 97.236    Top5: 99.992    Loss: 0.079
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.387378   Top1 89.628906   Top5 99.511719   BatchTime 0.176860
INFO - Validation [33][   40/   40]   Loss 0.366527   Top1 90.030000   Top5 99.610000   BatchTime 0.125416
INFO - ==> Top1: 90.030    Top5: 99.610    Loss: 0.367
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.074590   Top1 97.324219   Top5 99.980469   BatchTime 0.248286   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.074996   Top1 97.363281   Top5 99.990234   BatchTime 0.199541   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.074687   Top1 97.447917   Top5 99.993490   BatchTime 0.184877   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.075121   Top1 97.402344   Top5 99.995117   BatchTime 0.176364   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.077051   Top1 97.316406   Top5 99.996094   BatchTime 0.171093   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.076656   Top1 97.311198   Top5 99.996745   BatchTime 0.167471   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.076913   Top1 97.299107   Top5 99.997210   BatchTime 0.161718   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.077377   Top1 97.260742   Top5 99.997559   BatchTime 0.153779   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.077154   Top1 97.256944   Top5 99.995660   BatchTime 0.149435   LR 0.001000
INFO - ==> Top1: 97.250    Top5: 99.994    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.393997   Top1 89.765625   Top5 99.492188   BatchTime 0.174492
INFO - Validation [34][   40/   40]   Loss 0.372750   Top1 90.050000   Top5 99.600000   BatchTime 0.123910
INFO - ==> Top1: 90.050    Top5: 99.600    Loss: 0.373
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.080847   Top1 97.460938   Top5 100.000000   BatchTime 0.248404   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.081204   Top1 97.294922   Top5 100.000000   BatchTime 0.199651   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.079168   Top1 97.259115   Top5 100.000000   BatchTime 0.183065   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.077959   Top1 97.348633   Top5 99.995117   BatchTime 0.175224   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.076835   Top1 97.390625   Top5 99.996094   BatchTime 0.170339   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.076819   Top1 97.366536   Top5 99.993490   BatchTime 0.166974   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.077176   Top1 97.354911   Top5 99.988839   BatchTime 0.160319   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.078288   Top1 97.307129   Top5 99.987793   BatchTime 0.152675   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.078370   Top1 97.293837   Top5 99.986979   BatchTime 0.148272   LR 0.001000
INFO - ==> Top1: 97.294    Top5: 99.988    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.391105   Top1 89.824219   Top5 99.550781   BatchTime 0.174409
INFO - Validation [35][   40/   40]   Loss 0.371551   Top1 90.090000   Top5 99.630000   BatchTime 0.124248
INFO - ==> Top1: 90.090    Top5: 99.630    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.081234   Top1 97.050781   Top5 100.000000   BatchTime 0.251792   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.078832   Top1 97.167969   Top5 100.000000   BatchTime 0.201297   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.076757   Top1 97.272135   Top5 100.000000   BatchTime 0.184647   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.078111   Top1 97.260742   Top5 100.000000   BatchTime 0.176139   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.075745   Top1 97.390625   Top5 100.000000   BatchTime 0.170822   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.076083   Top1 97.402344   Top5 100.000000   BatchTime 0.167308   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.076721   Top1 97.366071   Top5 100.000000   BatchTime 0.160055   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.076594   Top1 97.363281   Top5 99.997559   BatchTime 0.152730   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.077337   Top1 97.324219   Top5 99.997830   BatchTime 0.148182   LR 0.001000
INFO - ==> Top1: 97.326    Top5: 99.998    Loss: 0.077
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.390243   Top1 89.726562   Top5 99.531250   BatchTime 0.177212
INFO - Validation [36][   40/   40]   Loss 0.372312   Top1 90.030000   Top5 99.610000   BatchTime 0.125350
INFO - ==> Top1: 90.030    Top5: 99.610    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.077818   Top1 97.148438   Top5 99.980469   BatchTime 0.249641   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.075544   Top1 97.294922   Top5 99.980469   BatchTime 0.200499   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.075632   Top1 97.233073   Top5 99.986979   BatchTime 0.183827   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.074176   Top1 97.343750   Top5 99.990234   BatchTime 0.175414   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.075222   Top1 97.328125   Top5 99.992188   BatchTime 0.170333   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.075307   Top1 97.373047   Top5 99.993490   BatchTime 0.167050   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.075828   Top1 97.354911   Top5 99.994420   BatchTime 0.159499   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.077199   Top1 97.272949   Top5 99.995117   BatchTime 0.152430   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.077676   Top1 97.276476   Top5 99.993490   BatchTime 0.147679   LR 0.001000
INFO - ==> Top1: 97.242    Top5: 99.990    Loss: 0.079
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.393907   Top1 89.433594   Top5 99.492188   BatchTime 0.171811
INFO - Validation [37][   40/   40]   Loss 0.375747   Top1 89.750000   Top5 99.590000   BatchTime 0.124001
INFO - ==> Top1: 89.750    Top5: 99.590    Loss: 0.376
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.069604   Top1 97.714844   Top5 100.000000   BatchTime 0.253242   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.072260   Top1 97.451172   Top5 100.000000   BatchTime 0.201905   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.073745   Top1 97.441406   Top5 100.000000   BatchTime 0.184821   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.077841   Top1 97.290039   Top5 99.995117   BatchTime 0.176249   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.078948   Top1 97.281250   Top5 99.996094   BatchTime 0.171891   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.079036   Top1 97.233073   Top5 99.996745   BatchTime 0.168241   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.079382   Top1 97.198661   Top5 99.997210   BatchTime 0.158447   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.079074   Top1 97.211914   Top5 99.997559   BatchTime 0.152191   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.078370   Top1 97.256944   Top5 99.997830   BatchTime 0.146918   LR 0.001000
INFO - ==> Top1: 97.252    Top5: 99.998    Loss: 0.079
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.396452   Top1 89.648438   Top5 99.570312   BatchTime 0.168057
INFO - Validation [38][   40/   40]   Loss 0.374780   Top1 89.980000   Top5 99.700000   BatchTime 0.121137
INFO - ==> Top1: 89.980    Top5: 99.700    Loss: 0.375
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.072257   Top1 97.519531   Top5 99.980469   BatchTime 0.246776   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.075116   Top1 97.333984   Top5 99.990234   BatchTime 0.199058   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.076160   Top1 97.278646   Top5 99.993490   BatchTime 0.182876   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.077028   Top1 97.221680   Top5 99.995117   BatchTime 0.174943   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.077193   Top1 97.199219   Top5 99.996094   BatchTime 0.169953   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.077041   Top1 97.233073   Top5 99.993490   BatchTime 0.166664   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.077681   Top1 97.240513   Top5 99.994420   BatchTime 0.156021   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.078018   Top1 97.224121   Top5 99.995117   BatchTime 0.150739   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.078286   Top1 97.213542   Top5 99.995660   BatchTime 0.145337   LR 0.001000
INFO - ==> Top1: 97.212    Top5: 99.996    Loss: 0.079
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.397776   Top1 89.453125   Top5 99.531250   BatchTime 0.165671
INFO - Validation [39][   40/   40]   Loss 0.375635   Top1 90.020000   Top5 99.590000   BatchTime 0.119993
INFO - ==> Top1: 90.020    Top5: 99.590    Loss: 0.376
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.076829   Top1 97.187500   Top5 100.000000   BatchTime 0.252347   LR 0.000100
INFO - Training [40][   40/  196]   Loss 0.077366   Top1 97.207031   Top5 99.990234   BatchTime 0.201859   LR 0.000100
INFO - Training [40][   60/  196]   Loss 0.079207   Top1 97.161458   Top5 99.993490   BatchTime 0.184898   LR 0.000100
INFO - Training [40][   80/  196]   Loss 0.078051   Top1 97.231445   Top5 99.995117   BatchTime 0.176100   LR 0.000100
INFO - Training [40][  100/  196]   Loss 0.079004   Top1 97.222656   Top5 99.996094   BatchTime 0.171003   LR 0.000100
INFO - Training [40][  120/  196]   Loss 0.077988   Top1 97.285156   Top5 99.996745   BatchTime 0.165796   LR 0.000100
INFO - Training [40][  140/  196]   Loss 0.078504   Top1 97.268415   Top5 99.994420   BatchTime 0.155344   LR 0.000100
INFO - Training [40][  160/  196]   Loss 0.077190   Top1 97.319336   Top5 99.992676   BatchTime 0.150001   LR 0.000100
INFO - Training [40][  180/  196]   Loss 0.076745   Top1 97.345920   Top5 99.993490   BatchTime 0.143772   LR 0.000100
INFO - ==> Top1: 97.332    Top5: 99.992    Loss: 0.077
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.396602   Top1 89.531250   Top5 99.609375   BatchTime 0.167077
INFO - Validation [40][   40/   40]   Loss 0.375272   Top1 89.890000   Top5 99.640000   BatchTime 0.120339
INFO - ==> Top1: 89.890    Top5: 99.640    Loss: 0.375
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.075913   Top1 97.246094   Top5 100.000000   BatchTime 0.250851   LR 0.000100
INFO - Training [41][   40/  196]   Loss 0.077838   Top1 97.207031   Top5 100.000000   BatchTime 0.201051   LR 0.000100
INFO - Training [41][   60/  196]   Loss 0.077923   Top1 97.259115   Top5 100.000000   BatchTime 0.184242   LR 0.000100
INFO - Training [41][   80/  196]   Loss 0.078002   Top1 97.211914   Top5 100.000000   BatchTime 0.175706   LR 0.000100
INFO - Training [41][  100/  196]   Loss 0.077886   Top1 97.167969   Top5 100.000000   BatchTime 0.170570   LR 0.000100
INFO - Training [41][  120/  196]   Loss 0.077191   Top1 97.180990   Top5 99.996745   BatchTime 0.164099   LR 0.000100
INFO - Training [41][  140/  196]   Loss 0.077490   Top1 97.198661   Top5 99.997210   BatchTime 0.154685   LR 0.000100
INFO - Training [41][  160/  196]   Loss 0.077620   Top1 97.211914   Top5 99.997559   BatchTime 0.149256   LR 0.000100
INFO - Training [41][  180/  196]   Loss 0.077499   Top1 97.226562   Top5 99.995660   BatchTime 0.142225   LR 0.000100
INFO - ==> Top1: 97.240    Top5: 99.996    Loss: 0.077
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.392633   Top1 89.589844   Top5 99.472656   BatchTime 0.166376
INFO - Validation [41][   40/   40]   Loss 0.370386   Top1 90.120000   Top5 99.570000   BatchTime 0.120197
INFO - ==> Top1: 90.120    Top5: 99.570    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.130   Top5: 99.630] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.077150   Top1 97.382812   Top5 100.000000   BatchTime 0.250048   LR 0.000100
INFO - Training [42][   40/  196]   Loss 0.075672   Top1 97.402344   Top5 100.000000   BatchTime 0.200585   LR 0.000100
INFO - Training [42][   60/  196]   Loss 0.076659   Top1 97.415365   Top5 100.000000   BatchTime 0.184141   LR 0.000100
INFO - Training [42][   80/  196]   Loss 0.074602   Top1 97.460938   Top5 100.000000   BatchTime 0.175502   LR 0.000100
INFO - Training [42][  100/  196]   Loss 0.074703   Top1 97.421875   Top5 100.000000   BatchTime 0.170425   LR 0.000100
INFO - Training [42][  120/  196]   Loss 0.076568   Top1 97.327474   Top5 99.996745   BatchTime 0.163495   LR 0.000100
INFO - Training [42][  140/  196]   Loss 0.076572   Top1 97.321429   Top5 99.997210   BatchTime 0.153791   LR 0.000100
INFO - Training [42][  160/  196]   Loss 0.075949   Top1 97.331543   Top5 99.995117   BatchTime 0.149860   LR 0.000100
INFO - Training [42][  180/  196]   Loss 0.076243   Top1 97.302517   Top5 99.993490   BatchTime 0.142656   LR 0.000100
INFO - ==> Top1: 97.312    Top5: 99.994    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.391402   Top1 89.882812   Top5 99.550781   BatchTime 0.167018
INFO - Validation [42][   40/   40]   Loss 0.369956   Top1 90.270000   Top5 99.630000   BatchTime 0.120244
INFO - ==> Top1: 90.270    Top5: 99.630    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.080858   Top1 97.011719   Top5 100.000000   BatchTime 0.249516   LR 0.000100
INFO - Training [43][   40/  196]   Loss 0.076948   Top1 97.265625   Top5 99.990234   BatchTime 0.200510   LR 0.000100
INFO - Training [43][   60/  196]   Loss 0.076057   Top1 97.343750   Top5 99.980469   BatchTime 0.184009   LR 0.000100
INFO - Training [43][   80/  196]   Loss 0.074908   Top1 97.446289   Top5 99.985352   BatchTime 0.175657   LR 0.000100
INFO - Training [43][  100/  196]   Loss 0.075589   Top1 97.398438   Top5 99.984375   BatchTime 0.170472   LR 0.000100
INFO - Training [43][  120/  196]   Loss 0.075557   Top1 97.360026   Top5 99.986979   BatchTime 0.161228   LR 0.000100
INFO - Training [43][  140/  196]   Loss 0.075184   Top1 97.366071   Top5 99.988839   BatchTime 0.153320   LR 0.000100
INFO - Training [43][  160/  196]   Loss 0.075508   Top1 97.360840   Top5 99.990234   BatchTime 0.147609   LR 0.000100
INFO - Training [43][  180/  196]   Loss 0.076491   Top1 97.313368   Top5 99.986979   BatchTime 0.141512   LR 0.000100
INFO - ==> Top1: 97.308    Top5: 99.988    Loss: 0.077
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.389199   Top1 89.804688   Top5 99.570312   BatchTime 0.167351
INFO - Validation [43][   40/   40]   Loss 0.369700   Top1 90.110000   Top5 99.630000   BatchTime 0.120276
INFO - ==> Top1: 90.110    Top5: 99.630    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.083926   Top1 96.972656   Top5 99.980469   BatchTime 0.248887   LR 0.000100
INFO - Training [44][   40/  196]   Loss 0.082685   Top1 97.070312   Top5 99.990234   BatchTime 0.199746   LR 0.000100
INFO - Training [44][   60/  196]   Loss 0.081555   Top1 97.128906   Top5 99.993490   BatchTime 0.183388   LR 0.000100
INFO - Training [44][   80/  196]   Loss 0.077747   Top1 97.231445   Top5 99.995117   BatchTime 0.175124   LR 0.000100
INFO - Training [44][  100/  196]   Loss 0.079012   Top1 97.179688   Top5 99.992188   BatchTime 0.170062   LR 0.000100
INFO - Training [44][  120/  196]   Loss 0.077597   Top1 97.278646   Top5 99.993490   BatchTime 0.159237   LR 0.000100
INFO - Training [44][  140/  196]   Loss 0.077405   Top1 97.251674   Top5 99.994420   BatchTime 0.151706   LR 0.000100
INFO - Training [44][  160/  196]   Loss 0.077139   Top1 97.270508   Top5 99.995117   BatchTime 0.146302   LR 0.000100
INFO - Training [44][  180/  196]   Loss 0.077214   Top1 97.289497   Top5 99.995660   BatchTime 0.139742   LR 0.000100
INFO - ==> Top1: 97.320    Top5: 99.996    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.391158   Top1 89.765625   Top5 99.589844   BatchTime 0.165490
INFO - Validation [44][   40/   40]   Loss 0.373531   Top1 90.110000   Top5 99.640000   BatchTime 0.119690
INFO - ==> Top1: 90.110    Top5: 99.640    Loss: 0.374
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.075830   Top1 97.167969   Top5 99.980469   BatchTime 0.248722   LR 0.000100
INFO - Training [45][   40/  196]   Loss 0.076422   Top1 97.324219   Top5 99.980469   BatchTime 0.200082   LR 0.000100
INFO - Training [45][   60/  196]   Loss 0.078382   Top1 97.207031   Top5 99.986979   BatchTime 0.183572   LR 0.000100
INFO - Training [45][   80/  196]   Loss 0.076476   Top1 97.314453   Top5 99.990234   BatchTime 0.175192   LR 0.000100
INFO - Training [45][  100/  196]   Loss 0.076691   Top1 97.332031   Top5 99.992188   BatchTime 0.170197   LR 0.000100
INFO - Training [45][  120/  196]   Loss 0.075175   Top1 97.386068   Top5 99.993490   BatchTime 0.160182   LR 0.000100
INFO - Training [45][  140/  196]   Loss 0.076032   Top1 97.366071   Top5 99.991629   BatchTime 0.152267   LR 0.000100
INFO - Training [45][  160/  196]   Loss 0.077276   Top1 97.304688   Top5 99.992676   BatchTime 0.146989   LR 0.000100
INFO - Training [45][  180/  196]   Loss 0.077792   Top1 97.298177   Top5 99.991319   BatchTime 0.142171   LR 0.000100
INFO - ==> Top1: 97.268    Top5: 99.992    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.397855   Top1 89.726562   Top5 99.570312   BatchTime 0.166885
INFO - Validation [45][   40/   40]   Loss 0.377573   Top1 90.040000   Top5 99.600000   BatchTime 0.117334
INFO - ==> Top1: 90.040    Top5: 99.600    Loss: 0.378
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.076145   Top1 97.109375   Top5 99.980469   BatchTime 0.250747   LR 0.000100
INFO - Training [46][   40/  196]   Loss 0.076997   Top1 97.158203   Top5 99.980469   BatchTime 0.201014   LR 0.000100
INFO - Training [46][   60/  196]   Loss 0.074597   Top1 97.350260   Top5 99.986979   BatchTime 0.184084   LR 0.000100
INFO - Training [46][   80/  196]   Loss 0.074545   Top1 97.348633   Top5 99.990234   BatchTime 0.175710   LR 0.000100
INFO - Training [46][  100/  196]   Loss 0.076132   Top1 97.257812   Top5 99.992188   BatchTime 0.170662   LR 0.000100
INFO - Training [46][  120/  196]   Loss 0.075976   Top1 97.229818   Top5 99.993490   BatchTime 0.159580   LR 0.000100
INFO - Training [46][  140/  196]   Loss 0.075720   Top1 97.268415   Top5 99.994420   BatchTime 0.152226   LR 0.000100
INFO - Training [46][  160/  196]   Loss 0.075741   Top1 97.294922   Top5 99.995117   BatchTime 0.146529   LR 0.000100
INFO - Training [46][  180/  196]   Loss 0.075107   Top1 97.315538   Top5 99.995660   BatchTime 0.142740   LR 0.000100
INFO - ==> Top1: 97.318    Top5: 99.996    Loss: 0.075
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.387616   Top1 89.746094   Top5 99.589844   BatchTime 0.166946
INFO - Validation [46][   40/   40]   Loss 0.369647   Top1 90.050000   Top5 99.640000   BatchTime 0.121525
INFO - ==> Top1: 90.050    Top5: 99.640    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.074965   Top1 97.343750   Top5 100.000000   BatchTime 0.250291   LR 0.000100
INFO - Training [47][   40/  196]   Loss 0.077217   Top1 97.304688   Top5 99.990234   BatchTime 0.200855   LR 0.000100
INFO - Training [47][   60/  196]   Loss 0.078224   Top1 97.213542   Top5 99.993490   BatchTime 0.184076   LR 0.000100
INFO - Training [47][   80/  196]   Loss 0.079151   Top1 97.172852   Top5 99.990234   BatchTime 0.175702   LR 0.000100
INFO - Training [47][  100/  196]   Loss 0.079044   Top1 97.230469   Top5 99.988281   BatchTime 0.170677   LR 0.000100
INFO - Training [47][  120/  196]   Loss 0.078453   Top1 97.291667   Top5 99.990234   BatchTime 0.156798   LR 0.000100
INFO - Training [47][  140/  196]   Loss 0.077404   Top1 97.310268   Top5 99.991629   BatchTime 0.150436   LR 0.000100
INFO - Training [47][  160/  196]   Loss 0.077562   Top1 97.319336   Top5 99.990234   BatchTime 0.143943   LR 0.000100
INFO - Training [47][  180/  196]   Loss 0.078018   Top1 97.317708   Top5 99.989149   BatchTime 0.141669   LR 0.000100
INFO - ==> Top1: 97.312    Top5: 99.988    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.393174   Top1 89.765625   Top5 99.511719   BatchTime 0.168266
INFO - Validation [47][   40/   40]   Loss 0.370739   Top1 90.120000   Top5 99.600000   BatchTime 0.121022
INFO - ==> Top1: 90.120    Top5: 99.600    Loss: 0.371
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.081976   Top1 97.031250   Top5 100.000000   BatchTime 0.248621   LR 0.000100
INFO - Training [48][   40/  196]   Loss 0.078409   Top1 97.177734   Top5 100.000000   BatchTime 0.199852   LR 0.000100
INFO - Training [48][   60/  196]   Loss 0.076153   Top1 97.285156   Top5 100.000000   BatchTime 0.183480   LR 0.000100
INFO - Training [48][   80/  196]   Loss 0.075428   Top1 97.348633   Top5 100.000000   BatchTime 0.175167   LR 0.000100
INFO - Training [48][  100/  196]   Loss 0.075111   Top1 97.355469   Top5 99.996094   BatchTime 0.168268   LR 0.000100
INFO - Training [48][  120/  196]   Loss 0.074302   Top1 97.395833   Top5 99.996745   BatchTime 0.156042   LR 0.000100
INFO - Training [48][  140/  196]   Loss 0.075367   Top1 97.346540   Top5 99.994420   BatchTime 0.149872   LR 0.000100
INFO - Training [48][  160/  196]   Loss 0.074374   Top1 97.382812   Top5 99.992676   BatchTime 0.143036   LR 0.000100
INFO - Training [48][  180/  196]   Loss 0.074752   Top1 97.365451   Top5 99.993490   BatchTime 0.141844   LR 0.000100
INFO - ==> Top1: 97.350    Top5: 99.994    Loss: 0.075
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.394896   Top1 89.707031   Top5 99.531250   BatchTime 0.166516
INFO - Validation [48][   40/   40]   Loss 0.374059   Top1 89.960000   Top5 99.600000   BatchTime 0.120315
INFO - ==> Top1: 89.960    Top5: 99.600    Loss: 0.374
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.078056   Top1 97.460938   Top5 99.980469   BatchTime 0.251434   LR 0.000100
INFO - Training [49][   40/  196]   Loss 0.078056   Top1 97.402344   Top5 99.980469   BatchTime 0.201222   LR 0.000100
INFO - Training [49][   60/  196]   Loss 0.076722   Top1 97.428385   Top5 99.986979   BatchTime 0.184207   LR 0.000100
INFO - Training [49][   80/  196]   Loss 0.076193   Top1 97.392578   Top5 99.990234   BatchTime 0.175512   LR 0.000100
INFO - Training [49][  100/  196]   Loss 0.077005   Top1 97.328125   Top5 99.992188   BatchTime 0.168046   LR 0.000100
INFO - Training [49][  120/  196]   Loss 0.077482   Top1 97.301432   Top5 99.993490   BatchTime 0.155947   LR 0.000100
INFO - Training [49][  140/  196]   Loss 0.077492   Top1 97.315848   Top5 99.991629   BatchTime 0.149801   LR 0.000100
INFO - Training [49][  160/  196]   Loss 0.076155   Top1 97.392578   Top5 99.992676   BatchTime 0.142555   LR 0.000100
INFO - Training [49][  180/  196]   Loss 0.076374   Top1 97.387153   Top5 99.993490   BatchTime 0.141930   LR 0.000100
INFO - ==> Top1: 97.384    Top5: 99.992    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.395489   Top1 89.550781   Top5 99.531250   BatchTime 0.167136
INFO - Validation [49][   40/   40]   Loss 0.372182   Top1 90.080000   Top5 99.580000   BatchTime 0.120404
INFO - ==> Top1: 90.080    Top5: 99.580    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.068895   Top1 97.617188   Top5 100.000000   BatchTime 0.252000   LR 0.000010
INFO - Training [50][   40/  196]   Loss 0.073312   Top1 97.460938   Top5 100.000000   BatchTime 0.201463   LR 0.000010
INFO - Training [50][   60/  196]   Loss 0.074131   Top1 97.402344   Top5 99.993490   BatchTime 0.184562   LR 0.000010
INFO - Training [50][   80/  196]   Loss 0.074374   Top1 97.436523   Top5 99.995117   BatchTime 0.176003   LR 0.000010
INFO - Training [50][  100/  196]   Loss 0.074704   Top1 97.367188   Top5 99.992188   BatchTime 0.166938   LR 0.000010
INFO - Training [50][  120/  196]   Loss 0.075192   Top1 97.340495   Top5 99.993490   BatchTime 0.154970   LR 0.000010
INFO - Training [50][  140/  196]   Loss 0.073526   Top1 97.424665   Top5 99.994420   BatchTime 0.148944   LR 0.000010
INFO - Training [50][  160/  196]   Loss 0.074112   Top1 97.426758   Top5 99.995117   BatchTime 0.141257   LR 0.000010
INFO - Training [50][  180/  196]   Loss 0.073293   Top1 97.441406   Top5 99.995660   BatchTime 0.139986   LR 0.000010
INFO - ==> Top1: 97.396    Top5: 99.996    Loss: 0.074
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.396238   Top1 89.394531   Top5 99.531250   BatchTime 0.166630
INFO - Validation [50][   40/   40]   Loss 0.372032   Top1 89.950000   Top5 99.610000   BatchTime 0.119922
INFO - ==> Top1: 89.950    Top5: 99.610    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.073406   Top1 97.558594   Top5 100.000000   BatchTime 0.251126   LR 0.000010
INFO - Training [51][   40/  196]   Loss 0.079259   Top1 97.324219   Top5 99.990234   BatchTime 0.201246   LR 0.000010
INFO - Training [51][   60/  196]   Loss 0.076088   Top1 97.415365   Top5 99.993490   BatchTime 0.185728   LR 0.000010
INFO - Training [51][   80/  196]   Loss 0.074682   Top1 97.485352   Top5 99.990234   BatchTime 0.176984   LR 0.000010
INFO - Training [51][  100/  196]   Loss 0.074569   Top1 97.425781   Top5 99.988281   BatchTime 0.168240   LR 0.000010
INFO - Training [51][  120/  196]   Loss 0.074594   Top1 97.438151   Top5 99.986979   BatchTime 0.156191   LR 0.000010
INFO - Training [51][  140/  196]   Loss 0.074241   Top1 97.438616   Top5 99.988839   BatchTime 0.150004   LR 0.000010
INFO - Training [51][  160/  196]   Loss 0.074083   Top1 97.421875   Top5 99.990234   BatchTime 0.142723   LR 0.000010
INFO - Training [51][  180/  196]   Loss 0.074068   Top1 97.411024   Top5 99.989149   BatchTime 0.142440   LR 0.000010
INFO - ==> Top1: 97.420    Top5: 99.990    Loss: 0.074
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.391767   Top1 89.785156   Top5 99.531250   BatchTime 0.167367
INFO - Validation [51][   40/   40]   Loss 0.374699   Top1 90.140000   Top5 99.600000   BatchTime 0.120825
INFO - ==> Top1: 90.140    Top5: 99.600    Loss: 0.375
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.070623   Top1 97.460938   Top5 99.960938   BatchTime 0.251505   LR 0.000010
INFO - Training [52][   40/  196]   Loss 0.073563   Top1 97.353516   Top5 99.980469   BatchTime 0.201155   LR 0.000010
INFO - Training [52][   60/  196]   Loss 0.076863   Top1 97.252604   Top5 99.986979   BatchTime 0.184016   LR 0.000010
INFO - Training [52][   80/  196]   Loss 0.075694   Top1 97.294922   Top5 99.990234   BatchTime 0.175557   LR 0.000010
INFO - Training [52][  100/  196]   Loss 0.075950   Top1 97.296875   Top5 99.992188   BatchTime 0.165321   LR 0.000010
INFO - Training [52][  120/  196]   Loss 0.076831   Top1 97.272135   Top5 99.993490   BatchTime 0.154859   LR 0.000010
INFO - Training [52][  140/  196]   Loss 0.076760   Top1 97.296317   Top5 99.991629   BatchTime 0.148593   LR 0.000010
INFO - Training [52][  160/  196]   Loss 0.077446   Top1 97.277832   Top5 99.992676   BatchTime 0.140582   LR 0.000010
INFO - Training [52][  180/  196]   Loss 0.077866   Top1 97.254774   Top5 99.993490   BatchTime 0.142334   LR 0.000010
INFO - ==> Top1: 97.228    Top5: 99.992    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.395817   Top1 89.707031   Top5 99.511719   BatchTime 0.167572
INFO - Validation [52][   40/   40]   Loss 0.375161   Top1 89.940000   Top5 99.620000   BatchTime 0.120913
INFO - ==> Top1: 89.940    Top5: 99.620    Loss: 0.375
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.074549   Top1 97.382812   Top5 99.980469   BatchTime 0.251295   LR 0.000010
INFO - Training [53][   40/  196]   Loss 0.075722   Top1 97.353516   Top5 99.980469   BatchTime 0.201172   LR 0.000010
INFO - Training [53][   60/  196]   Loss 0.075497   Top1 97.389323   Top5 99.980469   BatchTime 0.184125   LR 0.000010
INFO - Training [53][   80/  196]   Loss 0.077983   Top1 97.211914   Top5 99.980469   BatchTime 0.175552   LR 0.000010
INFO - Training [53][  100/  196]   Loss 0.077055   Top1 97.257812   Top5 99.984375   BatchTime 0.163673   LR 0.000010
INFO - Training [53][  120/  196]   Loss 0.076338   Top1 97.304688   Top5 99.986979   BatchTime 0.153904   LR 0.000010
INFO - Training [53][  140/  196]   Loss 0.075234   Top1 97.329799   Top5 99.988839   BatchTime 0.147588   LR 0.000010
INFO - Training [53][  160/  196]   Loss 0.076017   Top1 97.297363   Top5 99.987793   BatchTime 0.140992   LR 0.000010
INFO - Training [53][  180/  196]   Loss 0.075715   Top1 97.317708   Top5 99.989149   BatchTime 0.142326   LR 0.000010
INFO - ==> Top1: 97.294    Top5: 99.990    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.393762   Top1 89.824219   Top5 99.550781   BatchTime 0.167890
INFO - Validation [53][   40/   40]   Loss 0.375157   Top1 90.010000   Top5 99.610000   BatchTime 0.120930
INFO - ==> Top1: 90.010    Top5: 99.610    Loss: 0.375
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.590] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.070905   Top1 97.617188   Top5 100.000000   BatchTime 0.254125   LR 0.000010
INFO - Training [54][   40/  196]   Loss 0.075303   Top1 97.363281   Top5 100.000000   BatchTime 0.202299   LR 0.000010
INFO - Training [54][   60/  196]   Loss 0.074446   Top1 97.395833   Top5 100.000000   BatchTime 0.185207   LR 0.000010
INFO - Training [54][   80/  196]   Loss 0.072496   Top1 97.451172   Top5 100.000000   BatchTime 0.176525   LR 0.000010
INFO - Training [54][  100/  196]   Loss 0.074000   Top1 97.375000   Top5 99.996094   BatchTime 0.161577   LR 0.000010
INFO - Training [54][  120/  196]   Loss 0.074369   Top1 97.343750   Top5 99.990234   BatchTime 0.153165   LR 0.000010
INFO - Training [54][  140/  196]   Loss 0.075501   Top1 97.301897   Top5 99.991629   BatchTime 0.146381   LR 0.000010
INFO - Training [54][  160/  196]   Loss 0.074246   Top1 97.370605   Top5 99.992676   BatchTime 0.142179   LR 0.000010
INFO - Training [54][  180/  196]   Loss 0.075143   Top1 97.332899   Top5 99.991319   BatchTime 0.143046   LR 0.000010
INFO - ==> Top1: 97.306    Top5: 99.992    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.397039   Top1 89.628906   Top5 99.550781   BatchTime 0.167967
INFO - Validation [54][   40/   40]   Loss 0.375093   Top1 90.220000   Top5 99.620000   BatchTime 0.120819
INFO - ==> Top1: 90.220    Top5: 99.620    Loss: 0.375
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 90.220   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.077636   Top1 97.500000   Top5 100.000000   BatchTime 0.250808   LR 0.000010
INFO - Training [55][   40/  196]   Loss 0.074180   Top1 97.490234   Top5 100.000000   BatchTime 0.200518   LR 0.000010
INFO - Training [55][   60/  196]   Loss 0.074904   Top1 97.421875   Top5 99.993490   BatchTime 0.183943   LR 0.000010
INFO - Training [55][   80/  196]   Loss 0.072582   Top1 97.470703   Top5 99.995117   BatchTime 0.175233   LR 0.000010
INFO - Training [55][  100/  196]   Loss 0.072562   Top1 97.468750   Top5 99.996094   BatchTime 0.158798   LR 0.000010
INFO - Training [55][  120/  196]   Loss 0.074370   Top1 97.376302   Top5 99.996745   BatchTime 0.151223   LR 0.000010
INFO - Training [55][  140/  196]   Loss 0.075548   Top1 97.363281   Top5 99.997210   BatchTime 0.143874   LR 0.000010
INFO - Training [55][  160/  196]   Loss 0.075863   Top1 97.355957   Top5 99.997559   BatchTime 0.141293   LR 0.000010
INFO - Training [55][  180/  196]   Loss 0.076021   Top1 97.345920   Top5 99.995660   BatchTime 0.142263   LR 0.000010
INFO - ==> Top1: 97.356    Top5: 99.994    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.393935   Top1 89.882812   Top5 99.570312   BatchTime 0.166858
INFO - Validation [55][   40/   40]   Loss 0.376580   Top1 90.060000   Top5 99.600000   BatchTime 0.120536
INFO - ==> Top1: 90.060    Top5: 99.600    Loss: 0.377
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 90.220   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.078035   Top1 97.265625   Top5 100.000000   BatchTime 0.249947   LR 0.000010
INFO - Training [56][   40/  196]   Loss 0.074632   Top1 97.421875   Top5 100.000000   BatchTime 0.200129   LR 0.000010
INFO - Training [56][   60/  196]   Loss 0.072150   Top1 97.441406   Top5 100.000000   BatchTime 0.183571   LR 0.000010
INFO - Training [56][   80/  196]   Loss 0.072954   Top1 97.392578   Top5 100.000000   BatchTime 0.172679   LR 0.000010
INFO - Training [56][  100/  196]   Loss 0.072704   Top1 97.421875   Top5 100.000000   BatchTime 0.156869   LR 0.000010
INFO - Training [56][  120/  196]   Loss 0.073013   Top1 97.386068   Top5 100.000000   BatchTime 0.149755   LR 0.000010
INFO - Training [56][  140/  196]   Loss 0.073737   Top1 97.346540   Top5 99.997210   BatchTime 0.142041   LR 0.000010
INFO - Training [56][  160/  196]   Loss 0.074274   Top1 97.353516   Top5 99.997559   BatchTime 0.141927   LR 0.000010
INFO - Training [56][  180/  196]   Loss 0.074881   Top1 97.343750   Top5 99.991319   BatchTime 0.142861   LR 0.000010
INFO - ==> Top1: 97.364    Top5: 99.992    Loss: 0.074
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.388131   Top1 89.863281   Top5 99.531250   BatchTime 0.169517
INFO - Validation [56][   40/   40]   Loss 0.369588   Top1 90.120000   Top5 99.630000   BatchTime 0.121767
INFO - ==> Top1: 90.120    Top5: 99.630    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 90.220   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.069042   Top1 97.519531   Top5 100.000000   BatchTime 0.250934   LR 0.000010
INFO - Training [57][   40/  196]   Loss 0.068400   Top1 97.539062   Top5 100.000000   BatchTime 0.200724   LR 0.000010
INFO - Training [57][   60/  196]   Loss 0.071647   Top1 97.421875   Top5 100.000000   BatchTime 0.183990   LR 0.000010
INFO - Training [57][   80/  196]   Loss 0.072351   Top1 97.426758   Top5 100.000000   BatchTime 0.169356   LR 0.000010
INFO - Training [57][  100/  196]   Loss 0.074935   Top1 97.332031   Top5 100.000000   BatchTime 0.155788   LR 0.000010
INFO - Training [57][  120/  196]   Loss 0.074646   Top1 97.379557   Top5 100.000000   BatchTime 0.148989   LR 0.000010
INFO - Training [57][  140/  196]   Loss 0.073474   Top1 97.416295   Top5 100.000000   BatchTime 0.140697   LR 0.000010
INFO - Training [57][  160/  196]   Loss 0.072789   Top1 97.438965   Top5 99.997559   BatchTime 0.142617   LR 0.000010
INFO - Training [57][  180/  196]   Loss 0.073040   Top1 97.417535   Top5 99.997830   BatchTime 0.143528   LR 0.000010
INFO - ==> Top1: 97.424    Top5: 99.998    Loss: 0.073
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.390868   Top1 89.707031   Top5 99.628906   BatchTime 0.165541
INFO - Validation [57][   40/   40]   Loss 0.372362   Top1 90.080000   Top5 99.660000   BatchTime 0.116619
INFO - ==> Top1: 90.080    Top5: 99.660    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 90.220   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.076601   Top1 97.421875   Top5 99.980469   BatchTime 0.251773   LR 0.000010
INFO - Training [58][   40/  196]   Loss 0.072958   Top1 97.500000   Top5 99.990234   BatchTime 0.201069   LR 0.000010
INFO - Training [58][   60/  196]   Loss 0.074787   Top1 97.434896   Top5 99.993490   BatchTime 0.184228   LR 0.000010
INFO - Training [58][   80/  196]   Loss 0.075197   Top1 97.387695   Top5 99.995117   BatchTime 0.167060   LR 0.000010
INFO - Training [58][  100/  196]   Loss 0.074545   Top1 97.371094   Top5 99.996094   BatchTime 0.154650   LR 0.000010
INFO - Training [58][  120/  196]   Loss 0.074531   Top1 97.373047   Top5 99.996745   BatchTime 0.147463   LR 0.000010
INFO - Training [58][  140/  196]   Loss 0.074130   Top1 97.377232   Top5 99.994420   BatchTime 0.140943   LR 0.000010
INFO - Training [58][  160/  196]   Loss 0.074256   Top1 97.375488   Top5 99.995117   BatchTime 0.142093   LR 0.000010
INFO - Training [58][  180/  196]   Loss 0.074917   Top1 97.324219   Top5 99.995660   BatchTime 0.143002   LR 0.000010
INFO - ==> Top1: 97.304    Top5: 99.996    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.388199   Top1 89.687500   Top5 99.550781   BatchTime 0.167225
INFO - Validation [58][   40/   40]   Loss 0.370389   Top1 90.190000   Top5 99.640000   BatchTime 0.120493
INFO - ==> Top1: 90.190    Top5: 99.640    Loss: 0.370
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 90.220   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.072219   Top1 97.597656   Top5 100.000000   BatchTime 0.249824   LR 0.000010
INFO - Training [59][   40/  196]   Loss 0.074378   Top1 97.490234   Top5 100.000000   BatchTime 0.199823   LR 0.000010
INFO - Training [59][   60/  196]   Loss 0.075175   Top1 97.434896   Top5 99.993490   BatchTime 0.183119   LR 0.000010
INFO - Training [59][   80/  196]   Loss 0.076067   Top1 97.387695   Top5 99.990234   BatchTime 0.162774   LR 0.000010
INFO - Training [59][  100/  196]   Loss 0.075756   Top1 97.371094   Top5 99.992188   BatchTime 0.152379   LR 0.000010
INFO - Training [59][  120/  196]   Loss 0.077076   Top1 97.291667   Top5 99.993490   BatchTime 0.144571   LR 0.000010
INFO - Training [59][  140/  196]   Loss 0.076632   Top1 97.315848   Top5 99.994420   BatchTime 0.140008   LR 0.000010
INFO - Training [59][  160/  196]   Loss 0.076687   Top1 97.321777   Top5 99.995117   BatchTime 0.141373   LR 0.000010
INFO - Training [59][  180/  196]   Loss 0.077185   Top1 97.300347   Top5 99.995660   BatchTime 0.142902   LR 0.000010
INFO - ==> Top1: 97.296    Top5: 99.996    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.393568   Top1 89.667969   Top5 99.550781   BatchTime 0.166685
INFO - Validation [59][   40/   40]   Loss 0.372432   Top1 90.110000   Top5 99.630000   BatchTime 0.120218
INFO - ==> Top1: 90.110    Top5: 99.630    Loss: 0.372
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.270   Top5: 99.630] Sparsity : 0.889
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 90.220   Top5: 99.620] Sparsity : 0.889
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.210   Top5: 99.610] Sparsity : 0.889
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_20221104-005759/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.393568   Top1 89.667969   Top5 99.550781   BatchTime 0.166271
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Validation [   40/   40]   Loss 0.372432   Top1 90.110000   Top5 99.630000   BatchTime 0.119931
INFO - ==> Top1: 90.110    Top5: 99.630    Loss: 0.372
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net