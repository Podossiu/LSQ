
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541.log
2022-11-04 02:25:41.543738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 02:25:41.670601: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 02:25:42.073777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 02:25:42.073831: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 02:25:42.073838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/tb_runs
Files already downloaded and verified
hello
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
INFO - Inserted quantizers into the original model
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.403770   Top1 89.003906   Top5 99.453125   BatchTime 0.196851
INFO - Validation [   40/   40]   Loss 0.389260   Top1 89.200000   Top5 99.600000   BatchTime 0.129403
INFO - ==> Top1: 89.200    Top5: 99.600    Loss: 0.389
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.086413   Top1 97.031250   Top5 100.000000   BatchTime 0.244044   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.088526   Top1 96.835938   Top5 99.990234   BatchTime 0.183417   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.085977   Top1 96.940104   Top5 99.993490   BatchTime 0.158596   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.084929   Top1 96.997070   Top5 99.995117   BatchTime 0.142743   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.085184   Top1 96.968750   Top5 99.996094   BatchTime 0.134512   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.084374   Top1 97.037760   Top5 99.993490   BatchTime 0.129144   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.085021   Top1 97.011719   Top5 99.991629   BatchTime 0.123804   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.087064   Top1 96.921387   Top5 99.990234   BatchTime 0.122739   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.088273   Top1 96.864149   Top5 99.991319   BatchTime 0.122784   LR 0.010000
INFO - ==> Top1: 96.846    Top5: 99.992    Loss: 0.089
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.418054   Top1 88.945312   Top5 99.570312   BatchTime 0.145781
INFO - Validation [0][   40/   40]   Loss 0.411619   Top1 89.100000   Top5 99.580000   BatchTime 0.101159
INFO - ==> Top1: 89.100    Top5: 99.580    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 89.100   Top5: 99.580] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.080844   Top1 96.992188   Top5 99.980469   BatchTime 0.218674   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.082513   Top1 97.041016   Top5 99.990234   BatchTime 0.171256   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.085548   Top1 97.011719   Top5 99.993490   BatchTime 0.155324   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.085441   Top1 97.041016   Top5 99.980469   BatchTime 0.147407   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.084878   Top1 97.054688   Top5 99.980469   BatchTime 0.142627   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.085358   Top1 96.995443   Top5 99.983724   BatchTime 0.140529   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.086360   Top1 96.955915   Top5 99.983259   BatchTime 0.138185   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.085622   Top1 96.982422   Top5 99.985352   BatchTime 0.135883   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.086073   Top1 96.959635   Top5 99.986979   BatchTime 0.134607   LR 0.010000
INFO - ==> Top1: 96.944    Top5: 99.988    Loss: 0.086
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.421002   Top1 88.808594   Top5 99.589844   BatchTime 0.143011
INFO - Validation [1][   40/   40]   Loss 0.406165   Top1 89.170000   Top5 99.620000   BatchTime 0.100063
INFO - ==> Top1: 89.170    Top5: 99.620    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.170   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 89.100   Top5: 99.580] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.075325   Top1 97.480469   Top5 100.000000   BatchTime 0.198840   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.078276   Top1 97.099609   Top5 100.000000   BatchTime 0.150425   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.076813   Top1 97.187500   Top5 100.000000   BatchTime 0.134188   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.080436   Top1 97.089844   Top5 99.995117   BatchTime 0.123276   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.079418   Top1 97.164062   Top5 99.996094   BatchTime 0.122312   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.079732   Top1 97.180990   Top5 99.993490   BatchTime 0.122721   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.082306   Top1 97.059152   Top5 99.994420   BatchTime 0.122821   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.084289   Top1 96.958008   Top5 99.995117   BatchTime 0.122876   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.084388   Top1 96.970486   Top5 99.993490   BatchTime 0.122901   LR 0.010000
INFO - ==> Top1: 96.966    Top5: 99.994    Loss: 0.085
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.410674   Top1 89.589844   Top5 99.511719   BatchTime 0.144239
INFO - Validation [2][   40/   40]   Loss 0.404980   Top1 89.600000   Top5 99.580000   BatchTime 0.100035
INFO - ==> Top1: 89.600    Top5: 99.580    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 89.600   Top5: 99.580] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 89.170   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.072102   Top1 97.382812   Top5 99.980469   BatchTime 0.220445   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.075279   Top1 97.392578   Top5 99.980469   BatchTime 0.172501   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.078542   Top1 97.317708   Top5 99.986979   BatchTime 0.156142   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.079897   Top1 97.231445   Top5 99.980469   BatchTime 0.148090   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.080749   Top1 97.210938   Top5 99.972656   BatchTime 0.143157   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.082807   Top1 97.109375   Top5 99.977214   BatchTime 0.139854   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.082424   Top1 97.109375   Top5 99.974888   BatchTime 0.137445   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.083002   Top1 97.089844   Top5 99.975586   BatchTime 0.135563   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.083327   Top1 97.050781   Top5 99.976128   BatchTime 0.134083   LR 0.010000
INFO - ==> Top1: 97.038    Top5: 99.976    Loss: 0.083
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.414420   Top1 89.570312   Top5 99.433594   BatchTime 0.132667
INFO - Validation [3][   40/   40]   Loss 0.409284   Top1 89.620000   Top5 99.480000   BatchTime 0.089413
INFO - ==> Top1: 89.620    Top5: 99.480    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 89.620   Top5: 99.480] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 89.600   Top5: 99.580] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.085244   Top1 96.796875   Top5 100.000000   BatchTime 0.198519   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.077827   Top1 97.099609   Top5 100.000000   BatchTime 0.150710   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.078619   Top1 97.089844   Top5 99.993490   BatchTime 0.134753   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.079419   Top1 97.089844   Top5 99.995117   BatchTime 0.123634   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.080401   Top1 97.085938   Top5 99.992188   BatchTime 0.115870   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.080793   Top1 97.073568   Top5 99.993490   BatchTime 0.110382   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.080733   Top1 97.114955   Top5 99.994420   BatchTime 0.106532   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.080939   Top1 97.106934   Top5 99.995117   BatchTime 0.103841   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.081536   Top1 97.042101   Top5 99.995660   BatchTime 0.101791   LR 0.010000
INFO - ==> Top1: 97.058    Top5: 99.996    Loss: 0.081
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.405439   Top1 89.726562   Top5 99.570312   BatchTime 0.127019
INFO - Validation [4][   40/   40]   Loss 0.397967   Top1 89.720000   Top5 99.620000   BatchTime 0.081568
INFO - ==> Top1: 89.720    Top5: 99.620    Loss: 0.398
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 89.620   Top5: 99.480] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.600   Top5: 99.580] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.070819   Top1 97.460938   Top5 99.980469   BatchTime 0.195312   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.072699   Top1 97.402344   Top5 99.990234   BatchTime 0.146607   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.072001   Top1 97.415365   Top5 99.993490   BatchTime 0.131829   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.071551   Top1 97.465820   Top5 99.995117   BatchTime 0.124340   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.073336   Top1 97.414062   Top5 99.996094   BatchTime 0.118769   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.073957   Top1 97.340495   Top5 99.996745   BatchTime 0.118795   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.075230   Top1 97.307478   Top5 99.994420   BatchTime 0.119467   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.074325   Top1 97.324219   Top5 99.992676   BatchTime 0.120005   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.075088   Top1 97.289497   Top5 99.993490   BatchTime 0.120333   LR 0.010000
INFO - ==> Top1: 97.270    Top5: 99.992    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.399813   Top1 89.785156   Top5 99.492188   BatchTime 0.145575
INFO - Validation [5][   40/   40]   Loss 0.391039   Top1 89.750000   Top5 99.590000   BatchTime 0.100957
INFO - ==> Top1: 89.750    Top5: 99.590    Loss: 0.391
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 89.620   Top5: 99.480] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.074017   Top1 97.324219   Top5 100.000000   BatchTime 0.220281   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.073041   Top1 97.431641   Top5 99.990234   BatchTime 0.172007   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.073628   Top1 97.421875   Top5 99.993490   BatchTime 0.156003   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.071406   Top1 97.475586   Top5 99.995117   BatchTime 0.147966   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.072223   Top1 97.453125   Top5 99.992188   BatchTime 0.143116   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.071906   Top1 97.480469   Top5 99.993490   BatchTime 0.139860   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.072647   Top1 97.435826   Top5 99.991629   BatchTime 0.137549   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.072366   Top1 97.438965   Top5 99.992676   BatchTime 0.135723   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.072981   Top1 97.421875   Top5 99.993490   BatchTime 0.134239   LR 0.010000
INFO - ==> Top1: 97.424    Top5: 99.994    Loss: 0.073
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.408951   Top1 90.039062   Top5 99.570312   BatchTime 0.137866
INFO - Validation [6][   40/   40]   Loss 0.403155   Top1 89.820000   Top5 99.570000   BatchTime 0.086832
INFO - ==> Top1: 89.820    Top5: 99.570    Loss: 0.403
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.063842   Top1 97.578125   Top5 100.000000   BatchTime 0.203230   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.065586   Top1 97.626953   Top5 99.990234   BatchTime 0.149349   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.067372   Top1 97.604167   Top5 99.993490   BatchTime 0.139442   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.068610   Top1 97.524414   Top5 99.995117   BatchTime 0.135719   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.069709   Top1 97.460938   Top5 99.996094   BatchTime 0.133384   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.069879   Top1 97.447917   Top5 99.996745   BatchTime 0.131862   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.070847   Top1 97.427455   Top5 99.997210   BatchTime 0.130820   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.071603   Top1 97.387695   Top5 99.995117   BatchTime 0.129870   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.071493   Top1 97.395833   Top5 99.995660   BatchTime 0.129118   LR 0.010000
INFO - ==> Top1: 97.390    Top5: 99.996    Loss: 0.072
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.412415   Top1 89.394531   Top5 99.492188   BatchTime 0.144771
INFO - Validation [7][   40/   40]   Loss 0.406938   Top1 89.610000   Top5 99.580000   BatchTime 0.100150
INFO - ==> Top1: 89.610    Top5: 99.580    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.068212   Top1 97.812500   Top5 99.980469   BatchTime 0.218723   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.066342   Top1 97.744141   Top5 99.990234   BatchTime 0.170979   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.068634   Top1 97.623698   Top5 99.993490   BatchTime 0.155182   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.068033   Top1 97.636719   Top5 99.995117   BatchTime 0.147196   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.068802   Top1 97.597656   Top5 99.992188   BatchTime 0.142512   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.067822   Top1 97.649740   Top5 99.993490   BatchTime 0.139265   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.067167   Top1 97.670201   Top5 99.994420   BatchTime 0.136991   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.068521   Top1 97.626953   Top5 99.995117   BatchTime 0.135145   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.068394   Top1 97.604167   Top5 99.995660   BatchTime 0.130749   LR 0.010000
INFO - ==> Top1: 97.562    Top5: 99.996    Loss: 0.070
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.414967   Top1 89.707031   Top5 99.511719   BatchTime 0.130448
INFO - Validation [8][   40/   40]   Loss 0.402811   Top1 89.790000   Top5 99.600000   BatchTime 0.082476
INFO - ==> Top1: 89.790    Top5: 99.600    Loss: 0.403
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [8][Top1: 89.790   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.064796   Top1 97.578125   Top5 99.960938   BatchTime 0.223332   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.065401   Top1 97.705078   Top5 99.970703   BatchTime 0.173606   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.065565   Top1 97.734375   Top5 99.980469   BatchTime 0.156842   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.065690   Top1 97.739258   Top5 99.985352   BatchTime 0.148640   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.066222   Top1 97.687500   Top5 99.984375   BatchTime 0.143549   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.065452   Top1 97.705078   Top5 99.986979   BatchTime 0.140967   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.066374   Top1 97.670201   Top5 99.986049   BatchTime 0.138596   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.066959   Top1 97.685547   Top5 99.987793   BatchTime 0.136630   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.067281   Top1 97.667101   Top5 99.989149   BatchTime 0.135091   LR 0.010000
INFO - ==> Top1: 97.612    Top5: 99.988    Loss: 0.069
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.405753   Top1 89.707031   Top5 99.550781   BatchTime 0.144449
INFO - Validation [9][   40/   40]   Loss 0.404721   Top1 89.830000   Top5 99.590000   BatchTime 0.099357
INFO - ==> Top1: 89.830    Top5: 99.590    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 89.790   Top5: 99.600] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.057342   Top1 98.066406   Top5 100.000000   BatchTime 0.218732   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.058293   Top1 97.929688   Top5 99.990234   BatchTime 0.171108   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.063175   Top1 97.812500   Top5 99.980469   BatchTime 0.154973   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.064864   Top1 97.700195   Top5 99.985352   BatchTime 0.146978   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.065408   Top1 97.675781   Top5 99.988281   BatchTime 0.142044   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.065915   Top1 97.656250   Top5 99.986979   BatchTime 0.133510   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.066676   Top1 97.603237   Top5 99.988839   BatchTime 0.129243   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.066018   Top1 97.614746   Top5 99.990234   BatchTime 0.125600   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.066324   Top1 97.591146   Top5 99.991319   BatchTime 0.122505   LR 0.010000
INFO - ==> Top1: 97.584    Top5: 99.992    Loss: 0.067
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.411230   Top1 89.824219   Top5 99.511719   BatchTime 0.148412
INFO - Validation [10][   40/   40]   Loss 0.405139   Top1 89.830000   Top5 99.540000   BatchTime 0.102103
INFO - ==> Top1: 89.830    Top5: 99.540    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 89.830   Top5: 99.540] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.063195   Top1 97.675781   Top5 100.000000   BatchTime 0.219969   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.062096   Top1 97.773438   Top5 100.000000   BatchTime 0.171940   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.061782   Top1 97.714844   Top5 100.000000   BatchTime 0.155709   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.064814   Top1 97.592773   Top5 100.000000   BatchTime 0.147745   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.066201   Top1 97.542969   Top5 99.996094   BatchTime 0.143036   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.066100   Top1 97.532552   Top5 99.996745   BatchTime 0.139811   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.066311   Top1 97.533482   Top5 99.997210   BatchTime 0.137424   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.066194   Top1 97.573242   Top5 99.997559   BatchTime 0.135600   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.066510   Top1 97.562934   Top5 99.995660   BatchTime 0.134170   LR 0.010000
INFO - ==> Top1: 97.568    Top5: 99.996    Loss: 0.067
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.413018   Top1 90.058594   Top5 99.511719   BatchTime 0.144961
INFO - Validation [11][   40/   40]   Loss 0.404523   Top1 89.950000   Top5 99.560000   BatchTime 0.100148
INFO - ==> Top1: 89.950    Top5: 99.560    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [11][Top1: 89.950   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 89.830   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.064474   Top1 97.714844   Top5 99.980469   BatchTime 0.220142   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.062174   Top1 97.890625   Top5 99.990234   BatchTime 0.171304   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.063158   Top1 97.779948   Top5 99.993490   BatchTime 0.149319   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.063281   Top1 97.783203   Top5 99.995117   BatchTime 0.136691   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.063744   Top1 97.750000   Top5 99.996094   BatchTime 0.129753   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.065187   Top1 97.688802   Top5 99.996745   BatchTime 0.125611   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.065595   Top1 97.714844   Top5 99.994420   BatchTime 0.119859   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.065569   Top1 97.707520   Top5 99.995117   BatchTime 0.119771   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.065283   Top1 97.719184   Top5 99.995660   BatchTime 0.120145   LR 0.010000
INFO - ==> Top1: 97.710    Top5: 99.996    Loss: 0.065
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.401190   Top1 90.000000   Top5 99.492188   BatchTime 0.143185
INFO - Validation [12][   40/   40]   Loss 0.394713   Top1 90.110000   Top5 99.560000   BatchTime 0.098976
INFO - ==> Top1: 90.110    Top5: 99.560    Loss: 0.395
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [11][Top1: 89.950   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.058482   Top1 97.714844   Top5 100.000000   BatchTime 0.219916   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.059051   Top1 97.714844   Top5 100.000000   BatchTime 0.171826   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.062891   Top1 97.669271   Top5 100.000000   BatchTime 0.157427   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.061907   Top1 97.729492   Top5 100.000000   BatchTime 0.149181   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.061536   Top1 97.757812   Top5 100.000000   BatchTime 0.144263   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.062474   Top1 97.721354   Top5 100.000000   BatchTime 0.140795   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.062500   Top1 97.734375   Top5 100.000000   BatchTime 0.138354   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.062676   Top1 97.744141   Top5 99.997559   BatchTime 0.136433   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.062954   Top1 97.727865   Top5 99.995660   BatchTime 0.134958   LR 0.010000
INFO - ==> Top1: 97.724    Top5: 99.996    Loss: 0.063
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.423223   Top1 89.921875   Top5 99.531250   BatchTime 0.143859
INFO - Validation [13][   40/   40]   Loss 0.412509   Top1 90.060000   Top5 99.520000   BatchTime 0.099709
INFO - ==> Top1: 90.060    Top5: 99.520    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 89.950   Top5: 99.560] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.055952   Top1 97.949219   Top5 100.000000   BatchTime 0.203406   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.056878   Top1 97.919922   Top5 100.000000   BatchTime 0.152416   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.062543   Top1 97.760417   Top5 100.000000   BatchTime 0.136747   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.063020   Top1 97.744141   Top5 100.000000   BatchTime 0.124357   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.062805   Top1 97.761719   Top5 99.996094   BatchTime 0.123615   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.062275   Top1 97.773438   Top5 99.996745   BatchTime 0.123983   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.063326   Top1 97.734375   Top5 99.997210   BatchTime 0.123974   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.064008   Top1 97.717285   Top5 99.997559   BatchTime 0.123913   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.065001   Top1 97.701823   Top5 99.995660   BatchTime 0.123840   LR 0.010000
INFO - ==> Top1: 97.710    Top5: 99.994    Loss: 0.065
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.416732   Top1 89.902344   Top5 99.570312   BatchTime 0.144837
INFO - Validation [14][   40/   40]   Loss 0.407526   Top1 89.990000   Top5 99.610000   BatchTime 0.101010
INFO - ==> Top1: 89.990    Top5: 99.610    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 89.990   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.061283   Top1 97.832031   Top5 100.000000   BatchTime 0.220579   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.059819   Top1 97.929688   Top5 100.000000   BatchTime 0.172202   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.061506   Top1 97.884115   Top5 100.000000   BatchTime 0.156132   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.061572   Top1 97.856445   Top5 100.000000   BatchTime 0.147924   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.062292   Top1 97.777344   Top5 100.000000   BatchTime 0.143007   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.061973   Top1 97.783203   Top5 99.996745   BatchTime 0.139789   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.061924   Top1 97.776228   Top5 99.997210   BatchTime 0.137427   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.062601   Top1 97.739258   Top5 99.997559   BatchTime 0.135607   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.062316   Top1 97.745226   Top5 99.997830   BatchTime 0.134151   LR 0.010000
INFO - ==> Top1: 97.710    Top5: 99.998    Loss: 0.063
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.429839   Top1 89.765625   Top5 99.550781   BatchTime 0.134023
INFO - Validation [15][   40/   40]   Loss 0.415216   Top1 89.840000   Top5 99.610000   BatchTime 0.089357
INFO - ==> Top1: 89.840    Top5: 99.610    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 89.990   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.055780   Top1 98.007812   Top5 99.980469   BatchTime 0.200022   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.056345   Top1 98.017578   Top5 99.990234   BatchTime 0.162028   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.055961   Top1 98.040365   Top5 99.993490   BatchTime 0.149179   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.056409   Top1 98.046875   Top5 99.995117   BatchTime 0.142813   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.057423   Top1 97.941406   Top5 99.996094   BatchTime 0.139170   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.058075   Top1 97.916667   Top5 99.996745   BatchTime 0.136644   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.060110   Top1 97.845982   Top5 99.997210   BatchTime 0.134706   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.060608   Top1 97.770996   Top5 99.995117   BatchTime 0.133242   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.060860   Top1 97.764757   Top5 99.995660   BatchTime 0.132108   LR 0.010000
INFO - ==> Top1: 97.758    Top5: 99.996    Loss: 0.061
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.435992   Top1 89.726562   Top5 99.570312   BatchTime 0.145105
INFO - Validation [16][   40/   40]   Loss 0.433133   Top1 89.570000   Top5 99.590000   BatchTime 0.100147
INFO - ==> Top1: 89.570    Top5: 99.590    Loss: 0.433
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 89.990   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.060041   Top1 97.890625   Top5 100.000000   BatchTime 0.221293   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.055898   Top1 97.919922   Top5 100.000000   BatchTime 0.172656   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.058147   Top1 97.897135   Top5 100.000000   BatchTime 0.157887   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.061136   Top1 97.807617   Top5 100.000000   BatchTime 0.149366   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.060870   Top1 97.765625   Top5 100.000000   BatchTime 0.144210   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.060418   Top1 97.832031   Top5 100.000000   BatchTime 0.140664   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.060176   Top1 97.851562   Top5 100.000000   BatchTime 0.137960   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.060010   Top1 97.863770   Top5 99.997559   BatchTime 0.131997   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.060838   Top1 97.847222   Top5 99.995660   BatchTime 0.128502   LR 0.010000
INFO - ==> Top1: 97.884    Top5: 99.996    Loss: 0.060
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.427046   Top1 89.863281   Top5 99.433594   BatchTime 0.141064
INFO - Validation [17][   40/   40]   Loss 0.414662   Top1 90.090000   Top5 99.540000   BatchTime 0.097647
INFO - ==> Top1: 90.090    Top5: 99.540    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.057421   Top1 97.929688   Top5 100.000000   BatchTime 0.218723   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.055076   Top1 98.066406   Top5 100.000000   BatchTime 0.170608   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.056111   Top1 97.981771   Top5 100.000000   BatchTime 0.155122   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.057551   Top1 97.944336   Top5 100.000000   BatchTime 0.147224   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.057568   Top1 97.925781   Top5 99.996094   BatchTime 0.142623   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.059291   Top1 97.841797   Top5 99.996745   BatchTime 0.139554   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.059435   Top1 97.834821   Top5 99.997210   BatchTime 0.137250   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.058989   Top1 97.868652   Top5 99.995117   BatchTime 0.135411   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.058452   Top1 97.884115   Top5 99.995660   BatchTime 0.134060   LR 0.010000
INFO - ==> Top1: 97.900    Top5: 99.996    Loss: 0.059
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.421294   Top1 90.019531   Top5 99.550781   BatchTime 0.145678
INFO - Validation [18][   40/   40]   Loss 0.410693   Top1 90.140000   Top5 99.630000   BatchTime 0.100808
INFO - ==> Top1: 90.140    Top5: 99.630    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.053053   Top1 98.125000   Top5 100.000000   BatchTime 0.219412   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.051668   Top1 98.154297   Top5 100.000000   BatchTime 0.171307   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.055746   Top1 98.014323   Top5 100.000000   BatchTime 0.155197   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.057906   Top1 97.905273   Top5 99.995117   BatchTime 0.146799   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.057501   Top1 97.929688   Top5 99.996094   BatchTime 0.135102   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.058309   Top1 97.845052   Top5 99.996745   BatchTime 0.129762   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.057742   Top1 97.882254   Top5 99.997210   BatchTime 0.125731   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.058648   Top1 97.841797   Top5 99.997559   BatchTime 0.122178   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.058967   Top1 97.862413   Top5 99.995660   BatchTime 0.120191   LR 0.010000
INFO - ==> Top1: 97.864    Top5: 99.996    Loss: 0.059
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.436813   Top1 89.765625   Top5 99.433594   BatchTime 0.146330
INFO - Validation [19][   40/   40]   Loss 0.422059   Top1 89.860000   Top5 99.530000   BatchTime 0.100697
INFO - ==> Top1: 89.860    Top5: 99.530    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.058625   Top1 97.832031   Top5 100.000000   BatchTime 0.222308   LR 0.010000
INFO - Training [20][   40/  196]   Loss 0.059137   Top1 97.812500   Top5 99.990234   BatchTime 0.173083   LR 0.010000
INFO - Training [20][   60/  196]   Loss 0.059610   Top1 97.845052   Top5 99.993490   BatchTime 0.156629   LR 0.010000
INFO - Training [20][   80/  196]   Loss 0.058692   Top1 97.885742   Top5 99.990234   BatchTime 0.148374   LR 0.010000
INFO - Training [20][  100/  196]   Loss 0.059296   Top1 97.886719   Top5 99.992188   BatchTime 0.143492   LR 0.010000
INFO - Training [20][  120/  196]   Loss 0.058920   Top1 97.936198   Top5 99.990234   BatchTime 0.140184   LR 0.010000
INFO - Training [20][  140/  196]   Loss 0.059579   Top1 97.901786   Top5 99.991629   BatchTime 0.137909   LR 0.010000
INFO - Training [20][  160/  196]   Loss 0.059562   Top1 97.917480   Top5 99.992676   BatchTime 0.136013   LR 0.010000
INFO - Training [20][  180/  196]   Loss 0.060345   Top1 97.894965   Top5 99.991319   BatchTime 0.134562   LR 0.010000
INFO - ==> Top1: 97.868    Top5: 99.992    Loss: 0.061
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.425188   Top1 89.980469   Top5 99.472656   BatchTime 0.144638
INFO - Validation [20][   40/   40]   Loss 0.415178   Top1 89.950000   Top5 99.580000   BatchTime 0.100280
INFO - ==> Top1: 89.950    Top5: 99.580    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.050600   Top1 98.066406   Top5 100.000000   BatchTime 0.221794   LR 0.010000
INFO - Training [21][   40/  196]   Loss 0.053567   Top1 97.919922   Top5 100.000000   BatchTime 0.155480   LR 0.010000
INFO - Training [21][   60/  196]   Loss 0.055867   Top1 97.858073   Top5 100.000000   BatchTime 0.137921   LR 0.010000
INFO - Training [21][   80/  196]   Loss 0.056064   Top1 97.875977   Top5 99.995117   BatchTime 0.128940   LR 0.010000
INFO - Training [21][  100/  196]   Loss 0.055256   Top1 97.929688   Top5 99.996094   BatchTime 0.123784   LR 0.010000
INFO - Training [21][  120/  196]   Loss 0.054563   Top1 97.994792   Top5 99.996745   BatchTime 0.121578   LR 0.010000
INFO - Training [21][  140/  196]   Loss 0.055797   Top1 97.985491   Top5 99.991629   BatchTime 0.121843   LR 0.010000
INFO - Training [21][  160/  196]   Loss 0.056337   Top1 97.978516   Top5 99.992676   BatchTime 0.121970   LR 0.010000
INFO - Training [21][  180/  196]   Loss 0.056819   Top1 97.962240   Top5 99.993490   BatchTime 0.122089   LR 0.010000
INFO - ==> Top1: 97.932    Top5: 99.994    Loss: 0.058
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.436165   Top1 89.726562   Top5 99.492188   BatchTime 0.145370
INFO - Validation [21][   40/   40]   Loss 0.420442   Top1 89.880000   Top5 99.560000   BatchTime 0.098574
INFO - ==> Top1: 89.880    Top5: 99.560    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.051299   Top1 98.300781   Top5 100.000000   BatchTime 0.220831   LR 0.010000
INFO - Training [22][   40/  196]   Loss 0.052534   Top1 98.203125   Top5 100.000000   BatchTime 0.172433   LR 0.010000
INFO - Training [22][   60/  196]   Loss 0.053519   Top1 98.157552   Top5 100.000000   BatchTime 0.156197   LR 0.010000
INFO - Training [22][   80/  196]   Loss 0.055371   Top1 98.110352   Top5 99.995117   BatchTime 0.148105   LR 0.010000
INFO - Training [22][  100/  196]   Loss 0.056307   Top1 98.035156   Top5 99.996094   BatchTime 0.143150   LR 0.010000
INFO - Training [22][  120/  196]   Loss 0.055924   Top1 98.030599   Top5 99.996745   BatchTime 0.139909   LR 0.010000
INFO - Training [22][  140/  196]   Loss 0.056219   Top1 98.018973   Top5 99.994420   BatchTime 0.137569   LR 0.010000
INFO - Training [22][  160/  196]   Loss 0.056270   Top1 98.034668   Top5 99.995117   BatchTime 0.135728   LR 0.010000
INFO - Training [22][  180/  196]   Loss 0.056630   Top1 97.990451   Top5 99.995660   BatchTime 0.134258   LR 0.010000
INFO - ==> Top1: 97.942    Top5: 99.996    Loss: 0.057
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.435211   Top1 89.687500   Top5 99.589844   BatchTime 0.143037
INFO - Validation [22][   40/   40]   Loss 0.416820   Top1 89.950000   Top5 99.630000   BatchTime 0.090865
INFO - ==> Top1: 89.950    Top5: 99.630    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.055179   Top1 97.949219   Top5 100.000000   BatchTime 0.202833   LR 0.010000
INFO - Training [23][   40/  196]   Loss 0.053416   Top1 98.037109   Top5 100.000000   BatchTime 0.151948   LR 0.010000
INFO - Training [23][   60/  196]   Loss 0.052692   Top1 98.066406   Top5 99.993490   BatchTime 0.135650   LR 0.010000
INFO - Training [23][   80/  196]   Loss 0.052749   Top1 98.105469   Top5 99.995117   BatchTime 0.132586   LR 0.010000
INFO - Training [23][  100/  196]   Loss 0.055577   Top1 98.015625   Top5 99.996094   BatchTime 0.130968   LR 0.010000
INFO - Training [23][  120/  196]   Loss 0.055576   Top1 98.020833   Top5 99.996745   BatchTime 0.129703   LR 0.010000
INFO - Training [23][  140/  196]   Loss 0.057393   Top1 97.968750   Top5 99.997210   BatchTime 0.128822   LR 0.010000
INFO - Training [23][  160/  196]   Loss 0.057698   Top1 97.939453   Top5 99.997559   BatchTime 0.128104   LR 0.010000
INFO - Training [23][  180/  196]   Loss 0.057819   Top1 97.964410   Top5 99.997830   BatchTime 0.127537   LR 0.010000
INFO - ==> Top1: 97.978    Top5: 99.998    Loss: 0.057
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.433529   Top1 89.843750   Top5 99.687500   BatchTime 0.146116
INFO - Validation [23][   40/   40]   Loss 0.426339   Top1 90.040000   Top5 99.640000   BatchTime 0.101235
INFO - ==> Top1: 90.040    Top5: 99.640    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.054225   Top1 98.105469   Top5 100.000000   BatchTime 0.221675   LR 0.010000
INFO - Training [24][   40/  196]   Loss 0.051040   Top1 98.173828   Top5 100.000000   BatchTime 0.172663   LR 0.010000
INFO - Training [24][   60/  196]   Loss 0.051025   Top1 98.170573   Top5 100.000000   BatchTime 0.156506   LR 0.010000
INFO - Training [24][   80/  196]   Loss 0.051308   Top1 98.173828   Top5 100.000000   BatchTime 0.148421   LR 0.010000
INFO - Training [24][  100/  196]   Loss 0.051838   Top1 98.148438   Top5 100.000000   BatchTime 0.143406   LR 0.010000
INFO - Training [24][  120/  196]   Loss 0.051979   Top1 98.170573   Top5 99.993490   BatchTime 0.140099   LR 0.010000
INFO - Training [24][  140/  196]   Loss 0.051042   Top1 98.189174   Top5 99.994420   BatchTime 0.137675   LR 0.010000
INFO - Training [24][  160/  196]   Loss 0.052289   Top1 98.139648   Top5 99.995117   BatchTime 0.135760   LR 0.010000
INFO - Training [24][  180/  196]   Loss 0.052698   Top1 98.120660   Top5 99.995660   BatchTime 0.133578   LR 0.010000
INFO - ==> Top1: 98.116    Top5: 99.996    Loss: 0.053
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.439511   Top1 89.765625   Top5 99.550781   BatchTime 0.131617
INFO - Validation [24][   40/   40]   Loss 0.433519   Top1 89.840000   Top5 99.590000   BatchTime 0.083241
INFO - ==> Top1: 89.840    Top5: 99.590    Loss: 0.434
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.050679   Top1 98.378906   Top5 100.000000   BatchTime 0.223683   LR 0.010000
INFO - Training [25][   40/  196]   Loss 0.051550   Top1 98.144531   Top5 100.000000   BatchTime 0.173640   LR 0.010000
INFO - Training [25][   60/  196]   Loss 0.052205   Top1 98.105469   Top5 100.000000   BatchTime 0.157107   LR 0.010000
INFO - Training [25][   80/  196]   Loss 0.052025   Top1 98.129883   Top5 100.000000   BatchTime 0.148756   LR 0.010000
INFO - Training [25][  100/  196]   Loss 0.052111   Top1 98.148438   Top5 100.000000   BatchTime 0.143675   LR 0.010000
INFO - Training [25][  120/  196]   Loss 0.052065   Top1 98.173828   Top5 100.000000   BatchTime 0.140410   LR 0.010000
INFO - Training [25][  140/  196]   Loss 0.051444   Top1 98.197545   Top5 100.000000   BatchTime 0.137958   LR 0.010000
INFO - Training [25][  160/  196]   Loss 0.052874   Top1 98.139648   Top5 100.000000   BatchTime 0.135792   LR 0.010000
INFO - Training [25][  180/  196]   Loss 0.053109   Top1 98.148872   Top5 100.000000   BatchTime 0.134841   LR 0.010000
INFO - ==> Top1: 98.144    Top5: 99.998    Loss: 0.053
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.436772   Top1 89.609375   Top5 99.453125   BatchTime 0.144142
INFO - Validation [25][   40/   40]   Loss 0.423505   Top1 89.980000   Top5 99.550000   BatchTime 0.099636
INFO - ==> Top1: 89.980    Top5: 99.550    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.050997   Top1 98.300781   Top5 100.000000   BatchTime 0.220545   LR 0.010000
INFO - Training [26][   40/  196]   Loss 0.050574   Top1 98.310547   Top5 100.000000   BatchTime 0.171884   LR 0.010000
INFO - Training [26][   60/  196]   Loss 0.052554   Top1 98.274740   Top5 99.993490   BatchTime 0.155660   LR 0.010000
INFO - Training [26][   80/  196]   Loss 0.054130   Top1 98.193359   Top5 99.995117   BatchTime 0.147362   LR 0.010000
INFO - Training [26][  100/  196]   Loss 0.054525   Top1 98.132812   Top5 99.996094   BatchTime 0.142343   LR 0.010000
INFO - Training [26][  120/  196]   Loss 0.054674   Top1 98.102214   Top5 99.996745   BatchTime 0.135542   LR 0.010000
INFO - Training [26][  140/  196]   Loss 0.054186   Top1 98.122210   Top5 99.997210   BatchTime 0.130141   LR 0.010000
INFO - Training [26][  160/  196]   Loss 0.054059   Top1 98.125000   Top5 99.997559   BatchTime 0.126367   LR 0.010000
INFO - Training [26][  180/  196]   Loss 0.054810   Top1 98.098958   Top5 99.997830   BatchTime 0.123447   LR 0.010000
INFO - ==> Top1: 98.076    Top5: 99.998    Loss: 0.055
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.438121   Top1 89.941406   Top5 99.453125   BatchTime 0.149732
INFO - Validation [26][   40/   40]   Loss 0.424594   Top1 90.090000   Top5 99.570000   BatchTime 0.103309
INFO - ==> Top1: 90.090    Top5: 99.570    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.090   Top5: 99.570] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.051838   Top1 98.222656   Top5 100.000000   BatchTime 0.219726   LR 0.010000
INFO - Training [27][   40/  196]   Loss 0.049860   Top1 98.242188   Top5 100.000000   BatchTime 0.171540   LR 0.010000
INFO - Training [27][   60/  196]   Loss 0.050971   Top1 98.183594   Top5 100.000000   BatchTime 0.155445   LR 0.010000
INFO - Training [27][   80/  196]   Loss 0.052272   Top1 98.164062   Top5 100.000000   BatchTime 0.147465   LR 0.010000
INFO - Training [27][  100/  196]   Loss 0.054337   Top1 98.062500   Top5 100.000000   BatchTime 0.142604   LR 0.010000
INFO - Training [27][  120/  196]   Loss 0.053161   Top1 98.105469   Top5 100.000000   BatchTime 0.139427   LR 0.010000
INFO - Training [27][  140/  196]   Loss 0.053247   Top1 98.088728   Top5 100.000000   BatchTime 0.137087   LR 0.010000
INFO - Training [27][  160/  196]   Loss 0.053640   Top1 98.081055   Top5 100.000000   BatchTime 0.135284   LR 0.010000
INFO - Training [27][  180/  196]   Loss 0.053402   Top1 98.094618   Top5 100.000000   BatchTime 0.133937   LR 0.010000
INFO - ==> Top1: 98.084    Top5: 100.000    Loss: 0.054
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.436028   Top1 90.117188   Top5 99.492188   BatchTime 0.144860
INFO - Validation [27][   40/   40]   Loss 0.425793   Top1 90.100000   Top5 99.570000   BatchTime 0.100406
INFO - ==> Top1: 90.100    Top5: 99.570    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.100   Top5: 99.570] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.052638   Top1 98.203125   Top5 100.000000   BatchTime 0.218340   LR 0.010000
INFO - Training [28][   40/  196]   Loss 0.050131   Top1 98.242188   Top5 100.000000   BatchTime 0.170535   LR 0.010000
INFO - Training [28][   60/  196]   Loss 0.048808   Top1 98.242188   Top5 100.000000   BatchTime 0.152098   LR 0.010000
INFO - Training [28][   80/  196]   Loss 0.048825   Top1 98.276367   Top5 100.000000   BatchTime 0.137480   LR 0.010000
INFO - Training [28][  100/  196]   Loss 0.050011   Top1 98.222656   Top5 100.000000   BatchTime 0.130507   LR 0.010000
INFO - Training [28][  120/  196]   Loss 0.051042   Top1 98.167318   Top5 99.996745   BatchTime 0.125816   LR 0.010000
INFO - Training [28][  140/  196]   Loss 0.050529   Top1 98.164062   Top5 99.997210   BatchTime 0.121587   LR 0.010000
INFO - Training [28][  160/  196]   Loss 0.050771   Top1 98.166504   Top5 99.997559   BatchTime 0.120135   LR 0.010000
INFO - Training [28][  180/  196]   Loss 0.051354   Top1 98.157552   Top5 99.997830   BatchTime 0.120423   LR 0.010000
INFO - ==> Top1: 98.160    Top5: 99.996    Loss: 0.052
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.442969   Top1 89.667969   Top5 99.550781   BatchTime 0.143727
INFO - Validation [28][   40/   40]   Loss 0.429040   Top1 89.950000   Top5 99.600000   BatchTime 0.099386
INFO - ==> Top1: 89.950    Top5: 99.600    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.100   Top5: 99.570] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.049481   Top1 98.125000   Top5 100.000000   BatchTime 0.218430   LR 0.010000
INFO - Training [29][   40/  196]   Loss 0.049114   Top1 98.115234   Top5 100.000000   BatchTime 0.171269   LR 0.010000
INFO - Training [29][   60/  196]   Loss 0.047823   Top1 98.209635   Top5 100.000000   BatchTime 0.155347   LR 0.010000
INFO - Training [29][   80/  196]   Loss 0.046617   Top1 98.281250   Top5 100.000000   BatchTime 0.147413   LR 0.010000
INFO - Training [29][  100/  196]   Loss 0.046717   Top1 98.296875   Top5 100.000000   BatchTime 0.142690   LR 0.010000
INFO - Training [29][  120/  196]   Loss 0.046620   Top1 98.320312   Top5 100.000000   BatchTime 0.139575   LR 0.010000
INFO - Training [29][  140/  196]   Loss 0.047517   Top1 98.286830   Top5 99.997210   BatchTime 0.136946   LR 0.010000
INFO - Training [29][  160/  196]   Loss 0.048031   Top1 98.266602   Top5 99.997559   BatchTime 0.135164   LR 0.010000
INFO - Training [29][  180/  196]   Loss 0.048702   Top1 98.246528   Top5 99.997830   BatchTime 0.133822   LR 0.010000
INFO - ==> Top1: 98.224    Top5: 99.998    Loss: 0.049
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.447336   Top1 89.687500   Top5 99.531250   BatchTime 0.143984
INFO - Validation [29][   40/   40]   Loss 0.438053   Top1 89.980000   Top5 99.560000   BatchTime 0.099787
INFO - ==> Top1: 89.980    Top5: 99.560    Loss: 0.438
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.100   Top5: 99.570] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.056209   Top1 97.871094   Top5 100.000000   BatchTime 0.200735   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.050928   Top1 98.154297   Top5 99.990234   BatchTime 0.151526   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.048787   Top1 98.196615   Top5 99.993490   BatchTime 0.135299   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.047706   Top1 98.281250   Top5 99.995117   BatchTime 0.125931   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.048323   Top1 98.257812   Top5 99.992188   BatchTime 0.121663   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.047591   Top1 98.258464   Top5 99.993490   BatchTime 0.121952   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.048663   Top1 98.228237   Top5 99.994420   BatchTime 0.122157   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.047255   Top1 98.281250   Top5 99.995117   BatchTime 0.122260   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.047146   Top1 98.309462   Top5 99.995660   BatchTime 0.122316   LR 0.001000
INFO - ==> Top1: 98.336    Top5: 99.996    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.434981   Top1 90.175781   Top5 99.570312   BatchTime 0.143221
INFO - Validation [30][   40/   40]   Loss 0.421283   Top1 90.320000   Top5 99.640000   BatchTime 0.099358
INFO - ==> Top1: 90.320    Top5: 99.640    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.049121   Top1 98.222656   Top5 100.000000   BatchTime 0.220564   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.043598   Top1 98.535156   Top5 100.000000   BatchTime 0.172195   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.043517   Top1 98.535156   Top5 100.000000   BatchTime 0.156136   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.043842   Top1 98.515625   Top5 100.000000   BatchTime 0.148202   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.043911   Top1 98.542969   Top5 99.996094   BatchTime 0.143283   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.042865   Top1 98.567708   Top5 99.996745   BatchTime 0.139994   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.042291   Top1 98.577009   Top5 99.997210   BatchTime 0.137662   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.041819   Top1 98.581543   Top5 99.995117   BatchTime 0.135801   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.042166   Top1 98.559028   Top5 99.995660   BatchTime 0.134323   LR 0.001000
INFO - ==> Top1: 98.534    Top5: 99.996    Loss: 0.043
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.428077   Top1 90.039062   Top5 99.609375   BatchTime 0.128883
INFO - Validation [31][   40/   40]   Loss 0.415420   Top1 90.330000   Top5 99.660000   BatchTime 0.085430
INFO - ==> Top1: 90.330    Top5: 99.660    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.038475   Top1 98.691406   Top5 100.000000   BatchTime 0.196820   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.038400   Top1 98.681641   Top5 100.000000   BatchTime 0.160033   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.039097   Top1 98.639323   Top5 100.000000   BatchTime 0.147837   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.038557   Top1 98.706055   Top5 100.000000   BatchTime 0.141782   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.040593   Top1 98.621094   Top5 100.000000   BatchTime 0.138215   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.040699   Top1 98.610026   Top5 99.996745   BatchTime 0.135762   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.040628   Top1 98.613281   Top5 99.997210   BatchTime 0.134002   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.040736   Top1 98.608398   Top5 99.997559   BatchTime 0.132631   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.041515   Top1 98.585069   Top5 99.995660   BatchTime 0.131577   LR 0.001000
INFO - ==> Top1: 98.576    Top5: 99.996    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.430293   Top1 89.785156   Top5 99.609375   BatchTime 0.145185
INFO - Validation [32][   40/   40]   Loss 0.420866   Top1 90.130000   Top5 99.670000   BatchTime 0.100260
INFO - ==> Top1: 90.130    Top5: 99.670    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.038982   Top1 98.710938   Top5 100.000000   BatchTime 0.221139   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.038553   Top1 98.710938   Top5 100.000000   BatchTime 0.172512   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.038875   Top1 98.691406   Top5 100.000000   BatchTime 0.156308   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.039019   Top1 98.657227   Top5 100.000000   BatchTime 0.147666   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.038702   Top1 98.675781   Top5 99.996094   BatchTime 0.142793   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.038081   Top1 98.694661   Top5 99.996745   BatchTime 0.139496   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.038422   Top1 98.663504   Top5 99.997210   BatchTime 0.137451   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.038655   Top1 98.654785   Top5 99.997559   BatchTime 0.131071   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.039035   Top1 98.654514   Top5 99.997830   BatchTime 0.127843   LR 0.001000
INFO - ==> Top1: 98.638    Top5: 99.996    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.432688   Top1 90.175781   Top5 99.628906   BatchTime 0.131740
INFO - Validation [33][   40/   40]   Loss 0.417816   Top1 90.370000   Top5 99.670000   BatchTime 0.094035
INFO - ==> Top1: 90.370    Top5: 99.670    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.036086   Top1 98.789062   Top5 100.000000   BatchTime 0.235313   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.038398   Top1 98.632812   Top5 100.000000   BatchTime 0.179550   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.038804   Top1 98.658854   Top5 100.000000   BatchTime 0.161089   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.038656   Top1 98.647461   Top5 100.000000   BatchTime 0.151745   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.039215   Top1 98.644531   Top5 100.000000   BatchTime 0.146184   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.038845   Top1 98.671875   Top5 100.000000   BatchTime 0.142377   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.038956   Top1 98.674665   Top5 100.000000   BatchTime 0.139690   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.038851   Top1 98.654785   Top5 100.000000   BatchTime 0.137616   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.038767   Top1 98.661024   Top5 99.997830   BatchTime 0.135957   LR 0.001000
INFO - ==> Top1: 98.662    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.432835   Top1 90.097656   Top5 99.609375   BatchTime 0.144983
INFO - Validation [34][   40/   40]   Loss 0.423339   Top1 90.330000   Top5 99.640000   BatchTime 0.099794
INFO - ==> Top1: 90.330    Top5: 99.640    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.330   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.036716   Top1 98.886719   Top5 100.000000   BatchTime 0.221694   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.037070   Top1 98.808594   Top5 100.000000   BatchTime 0.172381   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.038436   Top1 98.678385   Top5 100.000000   BatchTime 0.155845   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.037323   Top1 98.701172   Top5 100.000000   BatchTime 0.147638   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.037231   Top1 98.691406   Top5 100.000000   BatchTime 0.135630   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.037737   Top1 98.678385   Top5 100.000000   BatchTime 0.130018   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.037926   Top1 98.663504   Top5 100.000000   BatchTime 0.125891   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.037245   Top1 98.713379   Top5 100.000000   BatchTime 0.122435   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.037169   Top1 98.723958   Top5 100.000000   BatchTime 0.119817   LR 0.001000
INFO - ==> Top1: 98.716    Top5: 100.000    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.417452   Top1 90.332031   Top5 99.687500   BatchTime 0.144543
INFO - Validation [35][   40/   40]   Loss 0.411926   Top1 90.490000   Top5 99.660000   BatchTime 0.099802
INFO - ==> Top1: 90.490    Top5: 99.660    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.033571   Top1 98.945312   Top5 100.000000   BatchTime 0.219061   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.034023   Top1 98.906250   Top5 100.000000   BatchTime 0.171408   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.034011   Top1 98.847656   Top5 100.000000   BatchTime 0.155601   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.034655   Top1 98.808594   Top5 100.000000   BatchTime 0.147577   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.034418   Top1 98.832031   Top5 100.000000   BatchTime 0.142740   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.034378   Top1 98.818359   Top5 100.000000   BatchTime 0.139475   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.035143   Top1 98.783482   Top5 100.000000   BatchTime 0.137161   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.035675   Top1 98.767090   Top5 100.000000   BatchTime 0.135423   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.035850   Top1 98.745660   Top5 100.000000   BatchTime 0.134064   LR 0.001000
INFO - ==> Top1: 98.726    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.428114   Top1 89.941406   Top5 99.648438   BatchTime 0.146030
INFO - Validation [36][   40/   40]   Loss 0.417463   Top1 90.350000   Top5 99.640000   BatchTime 0.100954
INFO - ==> Top1: 90.350    Top5: 99.640    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.350   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.039313   Top1 98.750000   Top5 100.000000   BatchTime 0.216739   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.036524   Top1 98.828125   Top5 100.000000   BatchTime 0.152666   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.037846   Top1 98.736979   Top5 100.000000   BatchTime 0.136058   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.037809   Top1 98.750000   Top5 100.000000   BatchTime 0.127618   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.037266   Top1 98.761719   Top5 99.996094   BatchTime 0.121785   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.037068   Top1 98.746745   Top5 99.996745   BatchTime 0.119082   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.036937   Top1 98.755580   Top5 99.997210   BatchTime 0.119706   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.036593   Top1 98.754883   Top5 99.997559   BatchTime 0.120202   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.036935   Top1 98.728299   Top5 99.997830   BatchTime 0.120605   LR 0.001000
INFO - ==> Top1: 98.718    Top5: 99.998    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.432591   Top1 89.980469   Top5 99.628906   BatchTime 0.146041
INFO - Validation [37][   40/   40]   Loss 0.419551   Top1 90.310000   Top5 99.630000   BatchTime 0.101076
INFO - ==> Top1: 90.310    Top5: 99.630    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.350   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.035312   Top1 98.750000   Top5 100.000000   BatchTime 0.223257   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.035407   Top1 98.779297   Top5 100.000000   BatchTime 0.173348   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.035275   Top1 98.710938   Top5 100.000000   BatchTime 0.156846   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.035468   Top1 98.696289   Top5 99.995117   BatchTime 0.148535   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.034811   Top1 98.734375   Top5 99.996094   BatchTime 0.143480   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.035535   Top1 98.714193   Top5 99.996745   BatchTime 0.140198   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.035680   Top1 98.719308   Top5 99.997210   BatchTime 0.137830   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.035518   Top1 98.742676   Top5 99.997559   BatchTime 0.135942   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.035206   Top1 98.752170   Top5 99.997830   BatchTime 0.134496   LR 0.001000
INFO - ==> Top1: 98.736    Top5: 99.998    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.429448   Top1 90.332031   Top5 99.570312   BatchTime 0.139939
INFO - Validation [38][   40/   40]   Loss 0.416152   Top1 90.510000   Top5 99.610000   BatchTime 0.087277
INFO - ==> Top1: 90.510    Top5: 99.610    Loss: 0.416
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.039126   Top1 98.769531   Top5 99.980469   BatchTime 0.204646   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.036586   Top1 98.779297   Top5 99.990234   BatchTime 0.146387   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.037295   Top1 98.763021   Top5 99.993490   BatchTime 0.137623   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.036591   Top1 98.754883   Top5 99.995117   BatchTime 0.134283   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.036946   Top1 98.742188   Top5 99.996094   BatchTime 0.132337   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.036074   Top1 98.753255   Top5 99.996745   BatchTime 0.130944   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.037614   Top1 98.680246   Top5 99.997210   BatchTime 0.129884   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.037399   Top1 98.696289   Top5 99.997559   BatchTime 0.128995   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.037615   Top1 98.697917   Top5 99.997830   BatchTime 0.128377   LR 0.001000
INFO - ==> Top1: 98.692    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.427051   Top1 90.312500   Top5 99.628906   BatchTime 0.145924
INFO - Validation [39][   40/   40]   Loss 0.414187   Top1 90.430000   Top5 99.650000   BatchTime 0.100999
INFO - ==> Top1: 90.430    Top5: 99.650    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.430   Top5: 99.650] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.035625   Top1 98.808594   Top5 100.000000   BatchTime 0.218486   LR 0.001000
INFO - Training [40][   40/  196]   Loss 0.037321   Top1 98.720703   Top5 100.000000   BatchTime 0.171557   LR 0.001000
INFO - Training [40][   60/  196]   Loss 0.036226   Top1 98.756510   Top5 100.000000   BatchTime 0.155712   LR 0.001000
INFO - Training [40][   80/  196]   Loss 0.036052   Top1 98.818359   Top5 100.000000   BatchTime 0.147735   LR 0.001000
INFO - Training [40][  100/  196]   Loss 0.036451   Top1 98.796875   Top5 100.000000   BatchTime 0.142885   LR 0.001000
INFO - Training [40][  120/  196]   Loss 0.036586   Top1 98.785807   Top5 100.000000   BatchTime 0.139681   LR 0.001000
INFO - Training [40][  140/  196]   Loss 0.036280   Top1 98.814174   Top5 100.000000   BatchTime 0.137252   LR 0.001000
INFO - Training [40][  160/  196]   Loss 0.035979   Top1 98.847656   Top5 99.997559   BatchTime 0.135356   LR 0.001000
INFO - Training [40][  180/  196]   Loss 0.035763   Top1 98.856337   Top5 99.997830   BatchTime 0.131171   LR 0.001000
INFO - ==> Top1: 98.860    Top5: 99.998    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.427918   Top1 90.234375   Top5 99.609375   BatchTime 0.129558
INFO - Validation [40][   40/   40]   Loss 0.419334   Top1 90.470000   Top5 99.650000   BatchTime 0.081835
INFO - ==> Top1: 90.470    Top5: 99.650    Loss: 0.419
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [40][Top1: 90.470   Top5: 99.650] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.034707   Top1 98.808594   Top5 100.000000   BatchTime 0.224879   LR 0.001000
INFO - Training [41][   40/  196]   Loss 0.033618   Top1 98.828125   Top5 100.000000   BatchTime 0.174042   LR 0.001000
INFO - Training [41][   60/  196]   Loss 0.037113   Top1 98.606771   Top5 100.000000   BatchTime 0.157072   LR 0.001000
INFO - Training [41][   80/  196]   Loss 0.036441   Top1 98.686523   Top5 100.000000   BatchTime 0.148857   LR 0.001000
INFO - Training [41][  100/  196]   Loss 0.035503   Top1 98.761719   Top5 100.000000   BatchTime 0.143830   LR 0.001000
INFO - Training [41][  120/  196]   Loss 0.035816   Top1 98.756510   Top5 100.000000   BatchTime 0.140526   LR 0.001000
INFO - Training [41][  140/  196]   Loss 0.036097   Top1 98.755580   Top5 100.000000   BatchTime 0.138061   LR 0.001000
INFO - Training [41][  160/  196]   Loss 0.036674   Top1 98.740234   Top5 100.000000   BatchTime 0.136118   LR 0.001000
INFO - Training [41][  180/  196]   Loss 0.036959   Top1 98.756510   Top5 100.000000   BatchTime 0.134674   LR 0.001000
INFO - ==> Top1: 98.748    Top5: 100.000    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.426380   Top1 90.156250   Top5 99.589844   BatchTime 0.145088
INFO - Validation [41][   40/   40]   Loss 0.414595   Top1 90.390000   Top5 99.610000   BatchTime 0.100216
INFO - ==> Top1: 90.390    Top5: 99.610    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [40][Top1: 90.470   Top5: 99.650] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.029607   Top1 99.042969   Top5 100.000000   BatchTime 0.219568   LR 0.001000
INFO - Training [42][   40/  196]   Loss 0.031938   Top1 98.994141   Top5 100.000000   BatchTime 0.171973   LR 0.001000
INFO - Training [42][   60/  196]   Loss 0.032988   Top1 98.925781   Top5 100.000000   BatchTime 0.155602   LR 0.001000
INFO - Training [42][   80/  196]   Loss 0.033090   Top1 98.930664   Top5 100.000000   BatchTime 0.148613   LR 0.001000
INFO - Training [42][  100/  196]   Loss 0.033095   Top1 98.925781   Top5 100.000000   BatchTime 0.143829   LR 0.001000
INFO - Training [42][  120/  196]   Loss 0.033700   Top1 98.899740   Top5 100.000000   BatchTime 0.134684   LR 0.001000
INFO - Training [42][  140/  196]   Loss 0.033498   Top1 98.903460   Top5 100.000000   BatchTime 0.129989   LR 0.001000
INFO - Training [42][  160/  196]   Loss 0.033724   Top1 98.869629   Top5 100.000000   BatchTime 0.126250   LR 0.001000
INFO - Training [42][  180/  196]   Loss 0.033700   Top1 98.865017   Top5 100.000000   BatchTime 0.123264   LR 0.001000
INFO - ==> Top1: 98.844    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.423782   Top1 90.117188   Top5 99.570312   BatchTime 0.143830
INFO - Validation [42][   40/   40]   Loss 0.415140   Top1 90.530000   Top5 99.620000   BatchTime 0.099176
INFO - ==> Top1: 90.530    Top5: 99.620    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.038046   Top1 98.730469   Top5 100.000000   BatchTime 0.218926   LR 0.001000
INFO - Training [43][   40/  196]   Loss 0.036873   Top1 98.710938   Top5 100.000000   BatchTime 0.171399   LR 0.001000
INFO - Training [43][   60/  196]   Loss 0.037501   Top1 98.763021   Top5 100.000000   BatchTime 0.155448   LR 0.001000
INFO - Training [43][   80/  196]   Loss 0.036929   Top1 98.750000   Top5 100.000000   BatchTime 0.147459   LR 0.001000
INFO - Training [43][  100/  196]   Loss 0.036020   Top1 98.777344   Top5 100.000000   BatchTime 0.142754   LR 0.001000
INFO - Training [43][  120/  196]   Loss 0.035513   Top1 98.811849   Top5 100.000000   BatchTime 0.139580   LR 0.001000
INFO - Training [43][  140/  196]   Loss 0.035230   Top1 98.828125   Top5 100.000000   BatchTime 0.137258   LR 0.001000
INFO - Training [43][  160/  196]   Loss 0.034985   Top1 98.847656   Top5 100.000000   BatchTime 0.135494   LR 0.001000
INFO - Training [43][  180/  196]   Loss 0.035296   Top1 98.832465   Top5 99.997830   BatchTime 0.134060   LR 0.001000
INFO - ==> Top1: 98.832    Top5: 99.998    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.429719   Top1 90.097656   Top5 99.570312   BatchTime 0.143208
INFO - Validation [43][   40/   40]   Loss 0.417351   Top1 90.430000   Top5 99.600000   BatchTime 0.099695
INFO - ==> Top1: 90.430    Top5: 99.600    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.038610   Top1 98.710938   Top5 100.000000   BatchTime 0.218011   LR 0.001000
INFO - Training [44][   40/  196]   Loss 0.036103   Top1 98.837891   Top5 100.000000   BatchTime 0.170953   LR 0.001000
INFO - Training [44][   60/  196]   Loss 0.036288   Top1 98.769531   Top5 100.000000   BatchTime 0.145716   LR 0.001000
INFO - Training [44][   80/  196]   Loss 0.034953   Top1 98.842773   Top5 100.000000   BatchTime 0.135036   LR 0.001000
INFO - Training [44][  100/  196]   Loss 0.035522   Top1 98.843750   Top5 100.000000   BatchTime 0.128735   LR 0.001000
INFO - Training [44][  120/  196]   Loss 0.034328   Top1 98.876953   Top5 100.000000   BatchTime 0.124300   LR 0.001000
INFO - Training [44][  140/  196]   Loss 0.034351   Top1 98.864397   Top5 100.000000   BatchTime 0.120578   LR 0.001000
INFO - Training [44][  160/  196]   Loss 0.034051   Top1 98.869629   Top5 100.000000   BatchTime 0.120907   LR 0.001000
INFO - Training [44][  180/  196]   Loss 0.034436   Top1 98.869358   Top5 100.000000   BatchTime 0.121182   LR 0.001000
INFO - ==> Top1: 98.886    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.433240   Top1 89.941406   Top5 99.570312   BatchTime 0.140021
INFO - Validation [44][   40/   40]   Loss 0.418161   Top1 90.290000   Top5 99.620000   BatchTime 0.098016
INFO - ==> Top1: 90.290    Top5: 99.620    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.034178   Top1 98.964844   Top5 100.000000   BatchTime 0.219573   LR 0.001000
INFO - Training [45][   40/  196]   Loss 0.033718   Top1 98.867188   Top5 100.000000   BatchTime 0.171439   LR 0.001000
INFO - Training [45][   60/  196]   Loss 0.034892   Top1 98.808594   Top5 100.000000   BatchTime 0.155369   LR 0.001000
INFO - Training [45][   80/  196]   Loss 0.034586   Top1 98.842773   Top5 100.000000   BatchTime 0.147382   LR 0.001000
INFO - Training [45][  100/  196]   Loss 0.034015   Top1 98.878906   Top5 100.000000   BatchTime 0.142884   LR 0.001000
INFO - Training [45][  120/  196]   Loss 0.033448   Top1 98.886719   Top5 100.000000   BatchTime 0.139912   LR 0.001000
INFO - Training [45][  140/  196]   Loss 0.033707   Top1 98.867188   Top5 100.000000   BatchTime 0.137530   LR 0.001000
INFO - Training [45][  160/  196]   Loss 0.034127   Top1 98.857422   Top5 100.000000   BatchTime 0.135733   LR 0.001000
INFO - Training [45][  180/  196]   Loss 0.033998   Top1 98.871528   Top5 100.000000   BatchTime 0.134313   LR 0.001000
INFO - ==> Top1: 98.852    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.427845   Top1 90.136719   Top5 99.570312   BatchTime 0.144700
INFO - Validation [45][   40/   40]   Loss 0.416760   Top1 90.360000   Top5 99.610000   BatchTime 0.100427
INFO - ==> Top1: 90.360    Top5: 99.610    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.032894   Top1 98.867188   Top5 100.000000   BatchTime 0.202936   LR 0.001000
INFO - Training [46][   40/  196]   Loss 0.034938   Top1 98.779297   Top5 100.000000   BatchTime 0.152864   LR 0.001000
INFO - Training [46][   60/  196]   Loss 0.035603   Top1 98.769531   Top5 100.000000   BatchTime 0.137468   LR 0.001000
INFO - Training [46][   80/  196]   Loss 0.033995   Top1 98.867188   Top5 100.000000   BatchTime 0.124330   LR 0.001000
INFO - Training [46][  100/  196]   Loss 0.033286   Top1 98.894531   Top5 100.000000   BatchTime 0.124450   LR 0.001000
INFO - Training [46][  120/  196]   Loss 0.034111   Top1 98.847656   Top5 100.000000   BatchTime 0.125113   LR 0.001000
INFO - Training [46][  140/  196]   Loss 0.033801   Top1 98.875558   Top5 100.000000   BatchTime 0.124823   LR 0.001000
INFO - Training [46][  160/  196]   Loss 0.034395   Top1 98.862305   Top5 100.000000   BatchTime 0.124586   LR 0.001000
INFO - Training [46][  180/  196]   Loss 0.033824   Top1 98.897569   Top5 100.000000   BatchTime 0.124388   LR 0.001000
INFO - ==> Top1: 98.890    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.428832   Top1 90.195312   Top5 99.453125   BatchTime 0.144190
INFO - Validation [46][   40/   40]   Loss 0.418967   Top1 90.500000   Top5 99.550000   BatchTime 0.100080
INFO - ==> Top1: 90.500    Top5: 99.550    Loss: 0.419
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.034038   Top1 98.925781   Top5 100.000000   BatchTime 0.220422   LR 0.001000
INFO - Training [47][   40/  196]   Loss 0.032181   Top1 98.994141   Top5 100.000000   BatchTime 0.172401   LR 0.001000
INFO - Training [47][   60/  196]   Loss 0.034337   Top1 98.906250   Top5 100.000000   BatchTime 0.156069   LR 0.001000
INFO - Training [47][   80/  196]   Loss 0.035614   Top1 98.847656   Top5 100.000000   BatchTime 0.148035   LR 0.001000
INFO - Training [47][  100/  196]   Loss 0.036313   Top1 98.828125   Top5 99.996094   BatchTime 0.143246   LR 0.001000
INFO - Training [47][  120/  196]   Loss 0.035427   Top1 98.854167   Top5 99.996745   BatchTime 0.140167   LR 0.001000
INFO - Training [47][  140/  196]   Loss 0.035042   Top1 98.847656   Top5 99.997210   BatchTime 0.137735   LR 0.001000
INFO - Training [47][  160/  196]   Loss 0.035223   Top1 98.833008   Top5 99.997559   BatchTime 0.135833   LR 0.001000
INFO - Training [47][  180/  196]   Loss 0.035374   Top1 98.810764   Top5 99.997830   BatchTime 0.134347   LR 0.001000
INFO - ==> Top1: 98.808    Top5: 99.998    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.441276   Top1 89.882812   Top5 99.511719   BatchTime 0.138929
INFO - Validation [47][   40/   40]   Loss 0.422306   Top1 90.340000   Top5 99.560000   BatchTime 0.090778
INFO - ==> Top1: 90.340    Top5: 99.560    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.036459   Top1 98.710938   Top5 100.000000   BatchTime 0.206307   LR 0.001000
INFO - Training [48][   40/  196]   Loss 0.034487   Top1 98.789062   Top5 99.990234   BatchTime 0.165146   LR 0.001000
INFO - Training [48][   60/  196]   Loss 0.033861   Top1 98.802083   Top5 99.993490   BatchTime 0.151285   LR 0.001000
INFO - Training [48][   80/  196]   Loss 0.033111   Top1 98.837891   Top5 99.995117   BatchTime 0.144330   LR 0.001000
INFO - Training [48][  100/  196]   Loss 0.033956   Top1 98.828125   Top5 99.996094   BatchTime 0.140208   LR 0.001000
INFO - Training [48][  120/  196]   Loss 0.033603   Top1 98.860677   Top5 99.996745   BatchTime 0.137513   LR 0.001000
INFO - Training [48][  140/  196]   Loss 0.034178   Top1 98.839286   Top5 99.997210   BatchTime 0.135181   LR 0.001000
INFO - Training [48][  160/  196]   Loss 0.034086   Top1 98.833008   Top5 99.997559   BatchTime 0.133648   LR 0.001000
INFO - Training [48][  180/  196]   Loss 0.033982   Top1 98.823785   Top5 99.997830   BatchTime 0.132448   LR 0.001000
INFO - ==> Top1: 98.818    Top5: 99.998    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.433363   Top1 89.960938   Top5 99.609375   BatchTime 0.143200
INFO - Validation [48][   40/   40]   Loss 0.417968   Top1 90.450000   Top5 99.630000   BatchTime 0.099225
INFO - ==> Top1: 90.450    Top5: 99.630    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.029920   Top1 99.121094   Top5 100.000000   BatchTime 0.218240   LR 0.001000
INFO - Training [49][   40/  196]   Loss 0.033410   Top1 98.886719   Top5 100.000000   BatchTime 0.170955   LR 0.001000
INFO - Training [49][   60/  196]   Loss 0.032545   Top1 98.860677   Top5 100.000000   BatchTime 0.155036   LR 0.001000
INFO - Training [49][   80/  196]   Loss 0.032542   Top1 98.896484   Top5 100.000000   BatchTime 0.147438   LR 0.001000
INFO - Training [49][  100/  196]   Loss 0.032515   Top1 98.914062   Top5 100.000000   BatchTime 0.142629   LR 0.001000
INFO - Training [49][  120/  196]   Loss 0.033092   Top1 98.896484   Top5 100.000000   BatchTime 0.139389   LR 0.001000
INFO - Training [49][  140/  196]   Loss 0.033083   Top1 98.900670   Top5 100.000000   BatchTime 0.136725   LR 0.001000
INFO - Training [49][  160/  196]   Loss 0.032951   Top1 98.918457   Top5 100.000000   BatchTime 0.130707   LR 0.001000
INFO - Training [49][  180/  196]   Loss 0.033473   Top1 98.901910   Top5 100.000000   BatchTime 0.127399   LR 0.001000
INFO - ==> Top1: 98.872    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.435246   Top1 89.960938   Top5 99.609375   BatchTime 0.135337
INFO - Validation [49][   40/   40]   Loss 0.420567   Top1 90.300000   Top5 99.650000   BatchTime 0.094630
INFO - ==> Top1: 90.300    Top5: 99.650    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.029610   Top1 98.964844   Top5 100.000000   BatchTime 0.220593   LR 0.001000
INFO - Training [50][   40/  196]   Loss 0.032696   Top1 98.876953   Top5 100.000000   BatchTime 0.172046   LR 0.001000
INFO - Training [50][   60/  196]   Loss 0.031654   Top1 98.964844   Top5 100.000000   BatchTime 0.156259   LR 0.001000
INFO - Training [50][   80/  196]   Loss 0.032392   Top1 98.945312   Top5 100.000000   BatchTime 0.148052   LR 0.001000
INFO - Training [50][  100/  196]   Loss 0.032925   Top1 98.925781   Top5 100.000000   BatchTime 0.143123   LR 0.001000
INFO - Training [50][  120/  196]   Loss 0.032685   Top1 98.929036   Top5 100.000000   BatchTime 0.139902   LR 0.001000
INFO - Training [50][  140/  196]   Loss 0.032340   Top1 98.925781   Top5 100.000000   BatchTime 0.137574   LR 0.001000
INFO - Training [50][  160/  196]   Loss 0.032880   Top1 98.881836   Top5 100.000000   BatchTime 0.135788   LR 0.001000
INFO - Training [50][  180/  196]   Loss 0.033073   Top1 98.867188   Top5 100.000000   BatchTime 0.134780   LR 0.001000
INFO - ==> Top1: 98.858    Top5: 99.998    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.423570   Top1 90.253906   Top5 99.492188   BatchTime 0.143182
INFO - Validation [50][   40/   40]   Loss 0.413712   Top1 90.630000   Top5 99.560000   BatchTime 0.099001
INFO - ==> Top1: 90.630    Top5: 99.560    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.027245   Top1 99.062500   Top5 100.000000   BatchTime 0.219847   LR 0.001000
INFO - Training [51][   40/  196]   Loss 0.028934   Top1 99.023438   Top5 100.000000   BatchTime 0.171612   LR 0.001000
INFO - Training [51][   60/  196]   Loss 0.030242   Top1 98.958333   Top5 100.000000   BatchTime 0.155396   LR 0.001000
INFO - Training [51][   80/  196]   Loss 0.029842   Top1 98.964844   Top5 100.000000   BatchTime 0.147610   LR 0.001000
INFO - Training [51][  100/  196]   Loss 0.030265   Top1 98.949219   Top5 100.000000   BatchTime 0.135587   LR 0.001000
INFO - Training [51][  120/  196]   Loss 0.030963   Top1 98.922526   Top5 100.000000   BatchTime 0.130182   LR 0.001000
INFO - Training [51][  140/  196]   Loss 0.030824   Top1 98.936942   Top5 100.000000   BatchTime 0.126022   LR 0.001000
INFO - Training [51][  160/  196]   Loss 0.031076   Top1 98.920898   Top5 100.000000   BatchTime 0.122364   LR 0.001000
INFO - Training [51][  180/  196]   Loss 0.031273   Top1 98.921441   Top5 100.000000   BatchTime 0.119764   LR 0.001000
INFO - ==> Top1: 98.900    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.431651   Top1 90.058594   Top5 99.609375   BatchTime 0.144213
INFO - Validation [51][   40/   40]   Loss 0.420282   Top1 90.480000   Top5 99.610000   BatchTime 0.099593
INFO - ==> Top1: 90.480    Top5: 99.610    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.035323   Top1 98.769531   Top5 99.980469   BatchTime 0.221087   LR 0.001000
INFO - Training [52][   40/  196]   Loss 0.033970   Top1 98.876953   Top5 99.990234   BatchTime 0.172386   LR 0.001000
INFO - Training [52][   60/  196]   Loss 0.034453   Top1 98.860677   Top5 99.993490   BatchTime 0.156036   LR 0.001000
INFO - Training [52][   80/  196]   Loss 0.033549   Top1 98.901367   Top5 99.995117   BatchTime 0.148027   LR 0.001000
INFO - Training [52][  100/  196]   Loss 0.033653   Top1 98.871094   Top5 99.996094   BatchTime 0.142809   LR 0.001000
INFO - Training [52][  120/  196]   Loss 0.033687   Top1 98.850911   Top5 99.996745   BatchTime 0.139609   LR 0.001000
INFO - Training [52][  140/  196]   Loss 0.033573   Top1 98.858817   Top5 99.997210   BatchTime 0.137255   LR 0.001000
INFO - Training [52][  160/  196]   Loss 0.033659   Top1 98.854980   Top5 99.997559   BatchTime 0.135398   LR 0.001000
INFO - Training [52][  180/  196]   Loss 0.034008   Top1 98.819444   Top5 99.997830   BatchTime 0.134010   LR 0.001000
INFO - ==> Top1: 98.818    Top5: 99.998    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.428578   Top1 89.902344   Top5 99.570312   BatchTime 0.143486
INFO - Validation [52][   40/   40]   Loss 0.419319   Top1 90.320000   Top5 99.620000   BatchTime 0.099973
INFO - ==> Top1: 90.320    Top5: 99.620    Loss: 0.419
INFO - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.030026   Top1 98.945312   Top5 100.000000   BatchTime 0.217097   LR 0.001000
INFO - Training [53][   40/  196]   Loss 0.029122   Top1 99.062500   Top5 100.000000   BatchTime 0.157484   LR 0.001000
INFO - Training [53][   60/  196]   Loss 0.031542   Top1 98.951823   Top5 100.000000   BatchTime 0.138391   LR 0.001000
INFO - Training [53][   80/  196]   Loss 0.032859   Top1 98.867188   Top5 100.000000   BatchTime 0.129246   LR 0.001000
INFO - Training [53][  100/  196]   Loss 0.032767   Top1 98.863281   Top5 100.000000   BatchTime 0.123990   LR 0.001000
INFO - Training [53][  120/  196]   Loss 0.031802   Top1 98.889974   Top5 100.000000   BatchTime 0.117542   LR 0.001000
INFO - Training [53][  140/  196]   Loss 0.031609   Top1 98.869978   Top5 100.000000   BatchTime 0.118923   LR 0.001000
INFO - Training [53][  160/  196]   Loss 0.032095   Top1 98.852539   Top5 99.997559   BatchTime 0.119419   LR 0.001000
INFO - Training [53][  180/  196]   Loss 0.032287   Top1 98.847656   Top5 99.997830   BatchTime 0.119797   LR 0.001000
INFO - ==> Top1: 98.830    Top5: 99.998    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.428238   Top1 90.136719   Top5 99.550781   BatchTime 0.143858
INFO - Validation [53][   40/   40]   Loss 0.422203   Top1 90.500000   Top5 99.610000   BatchTime 0.099400
INFO - ==> Top1: 90.500    Top5: 99.610    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.034896   Top1 98.710938   Top5 100.000000   BatchTime 0.216822   LR 0.001000
INFO - Training [54][   40/  196]   Loss 0.032974   Top1 98.847656   Top5 100.000000   BatchTime 0.170130   LR 0.001000
INFO - Training [54][   60/  196]   Loss 0.032466   Top1 98.873698   Top5 100.000000   BatchTime 0.154605   LR 0.001000
INFO - Training [54][   80/  196]   Loss 0.031730   Top1 98.916016   Top5 100.000000   BatchTime 0.147157   LR 0.001000
INFO - Training [54][  100/  196]   Loss 0.032582   Top1 98.882812   Top5 100.000000   BatchTime 0.142378   LR 0.001000
INFO - Training [54][  120/  196]   Loss 0.032141   Top1 98.893229   Top5 99.996745   BatchTime 0.139218   LR 0.001000
INFO - Training [54][  140/  196]   Loss 0.032123   Top1 98.917411   Top5 99.997210   BatchTime 0.136886   LR 0.001000
INFO - Training [54][  160/  196]   Loss 0.031987   Top1 98.906250   Top5 99.997559   BatchTime 0.135161   LR 0.001000
INFO - Training [54][  180/  196]   Loss 0.032225   Top1 98.886719   Top5 99.997830   BatchTime 0.134343   LR 0.001000
INFO - ==> Top1: 98.836    Top5: 99.998    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.436469   Top1 89.765625   Top5 99.589844   BatchTime 0.143959
INFO - Validation [54][   40/   40]   Loss 0.422775   Top1 90.260000   Top5 99.610000   BatchTime 0.097710
INFO - ==> Top1: 90.260    Top5: 99.610    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.031007   Top1 99.023438   Top5 100.000000   BatchTime 0.204931   LR 0.001000
INFO - Training [55][   40/  196]   Loss 0.030509   Top1 99.033203   Top5 100.000000   BatchTime 0.153444   LR 0.001000
INFO - Training [55][   60/  196]   Loss 0.030114   Top1 99.055990   Top5 100.000000   BatchTime 0.133123   LR 0.001000
INFO - Training [55][   80/  196]   Loss 0.030380   Top1 99.038086   Top5 100.000000   BatchTime 0.128109   LR 0.001000
INFO - Training [55][  100/  196]   Loss 0.030484   Top1 99.015625   Top5 100.000000   BatchTime 0.127253   LR 0.001000
INFO - Training [55][  120/  196]   Loss 0.030926   Top1 98.994141   Top5 100.000000   BatchTime 0.126641   LR 0.001000
INFO - Training [55][  140/  196]   Loss 0.031351   Top1 98.967634   Top5 100.000000   BatchTime 0.126240   LR 0.001000
INFO - Training [55][  160/  196]   Loss 0.031638   Top1 98.950195   Top5 100.000000   BatchTime 0.125865   LR 0.001000
INFO - Training [55][  180/  196]   Loss 0.031607   Top1 98.962674   Top5 100.000000   BatchTime 0.125568   LR 0.001000
INFO - ==> Top1: 98.984    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.428939   Top1 90.449219   Top5 99.609375   BatchTime 0.144810
INFO - Validation [55][   40/   40]   Loss 0.421316   Top1 90.640000   Top5 99.600000   BatchTime 0.099864
INFO - ==> Top1: 90.640    Top5: 99.600    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.030930   Top1 98.906250   Top5 100.000000   BatchTime 0.218960   LR 0.001000
INFO - Training [56][   40/  196]   Loss 0.030483   Top1 98.925781   Top5 100.000000   BatchTime 0.170176   LR 0.001000
INFO - Training [56][   60/  196]   Loss 0.030491   Top1 98.906250   Top5 100.000000   BatchTime 0.154962   LR 0.001000
INFO - Training [56][   80/  196]   Loss 0.030376   Top1 98.940430   Top5 100.000000   BatchTime 0.147356   LR 0.001000
INFO - Training [56][  100/  196]   Loss 0.031376   Top1 98.894531   Top5 100.000000   BatchTime 0.142637   LR 0.001000
INFO - Training [56][  120/  196]   Loss 0.031529   Top1 98.893229   Top5 100.000000   BatchTime 0.139433   LR 0.001000
INFO - Training [56][  140/  196]   Loss 0.031932   Top1 98.892299   Top5 100.000000   BatchTime 0.137266   LR 0.001000
INFO - Training [56][  160/  196]   Loss 0.031838   Top1 98.891602   Top5 100.000000   BatchTime 0.135391   LR 0.001000
INFO - Training [56][  180/  196]   Loss 0.032057   Top1 98.895399   Top5 100.000000   BatchTime 0.133966   LR 0.001000
INFO - ==> Top1: 98.896    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.431372   Top1 90.214844   Top5 99.628906   BatchTime 0.135797
INFO - Validation [56][   40/   40]   Loss 0.425167   Top1 90.480000   Top5 99.650000   BatchTime 0.089232
INFO - ==> Top1: 90.480    Top5: 99.650    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.029247   Top1 98.984375   Top5 100.000000   BatchTime 0.228530   LR 0.001000
INFO - Training [57][   40/  196]   Loss 0.028923   Top1 99.042969   Top5 100.000000   BatchTime 0.176586   LR 0.001000
INFO - Training [57][   60/  196]   Loss 0.029179   Top1 99.003906   Top5 100.000000   BatchTime 0.159003   LR 0.001000
INFO - Training [57][   80/  196]   Loss 0.029507   Top1 98.984375   Top5 100.000000   BatchTime 0.150258   LR 0.001000
INFO - Training [57][  100/  196]   Loss 0.031064   Top1 98.906250   Top5 100.000000   BatchTime 0.145013   LR 0.001000
INFO - Training [57][  120/  196]   Loss 0.030438   Top1 98.929036   Top5 100.000000   BatchTime 0.141554   LR 0.001000
INFO - Training [57][  140/  196]   Loss 0.031329   Top1 98.909040   Top5 100.000000   BatchTime 0.138994   LR 0.001000
INFO - Training [57][  160/  196]   Loss 0.031661   Top1 98.916016   Top5 100.000000   BatchTime 0.136982   LR 0.001000
INFO - Training [57][  180/  196]   Loss 0.031442   Top1 98.921441   Top5 100.000000   BatchTime 0.135461   LR 0.001000
INFO - ==> Top1: 98.914    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.436991   Top1 90.156250   Top5 99.589844   BatchTime 0.146091
INFO - Validation [57][   40/   40]   Loss 0.426409   Top1 90.330000   Top5 99.630000   BatchTime 0.101550
INFO - ==> Top1: 90.330    Top5: 99.630    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.032753   Top1 98.828125   Top5 100.000000   BatchTime 0.220497   LR 0.001000
INFO - Training [58][   40/  196]   Loss 0.032968   Top1 98.857422   Top5 100.000000   BatchTime 0.171865   LR 0.001000
INFO - Training [58][   60/  196]   Loss 0.033038   Top1 98.906250   Top5 100.000000   BatchTime 0.155846   LR 0.001000
INFO - Training [58][   80/  196]   Loss 0.033303   Top1 98.945312   Top5 100.000000   BatchTime 0.147498   LR 0.001000
INFO - Training [58][  100/  196]   Loss 0.032532   Top1 98.953125   Top5 100.000000   BatchTime 0.142606   LR 0.001000
INFO - Training [58][  120/  196]   Loss 0.032047   Top1 98.948568   Top5 100.000000   BatchTime 0.139347   LR 0.001000
INFO - Training [58][  140/  196]   Loss 0.032241   Top1 98.934152   Top5 100.000000   BatchTime 0.132463   LR 0.001000
INFO - Training [58][  160/  196]   Loss 0.032773   Top1 98.908691   Top5 100.000000   BatchTime 0.128445   LR 0.001000
INFO - Training [58][  180/  196]   Loss 0.032184   Top1 98.943142   Top5 100.000000   BatchTime 0.125393   LR 0.001000
INFO - ==> Top1: 98.936    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.430917   Top1 90.097656   Top5 99.570312   BatchTime 0.150819
INFO - Validation [58][   40/   40]   Loss 0.422603   Top1 90.490000   Top5 99.640000   BatchTime 0.102406
INFO - ==> Top1: 90.490    Top5: 99.640    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.028424   Top1 99.218750   Top5 100.000000   BatchTime 0.219773   LR 0.001000
INFO - Training [59][   40/  196]   Loss 0.030924   Top1 99.052734   Top5 99.990234   BatchTime 0.171580   LR 0.001000
INFO - Training [59][   60/  196]   Loss 0.030734   Top1 98.977865   Top5 99.993490   BatchTime 0.155496   LR 0.001000
INFO - Training [59][   80/  196]   Loss 0.031103   Top1 98.945312   Top5 99.995117   BatchTime 0.147546   LR 0.001000
INFO - Training [59][  100/  196]   Loss 0.030793   Top1 98.933594   Top5 99.996094   BatchTime 0.142726   LR 0.001000
INFO - Training [59][  120/  196]   Loss 0.031225   Top1 98.932292   Top5 99.996745   BatchTime 0.139496   LR 0.001000
INFO - Training [59][  140/  196]   Loss 0.031359   Top1 98.920201   Top5 99.997210   BatchTime 0.137243   LR 0.001000
INFO - Training [59][  160/  196]   Loss 0.031633   Top1 98.916016   Top5 99.995117   BatchTime 0.135431   LR 0.001000
INFO - Training [59][  180/  196]   Loss 0.031559   Top1 98.921441   Top5 99.995660   BatchTime 0.134019   LR 0.001000
INFO - ==> Top1: 98.928    Top5: 99.996    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.428809   Top1 90.253906   Top5 99.570312   BatchTime 0.144938
INFO - Validation [59][   40/   40]   Loss 0.427629   Top1 90.440000   Top5 99.610000   BatchTime 0.099747
INFO - ==> Top1: 90.440    Top5: 99.610    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [60][   20/  196]   Loss 0.030585   Top1 98.925781   Top5 100.000000   BatchTime 0.218775   LR 0.000100
INFO - Training [60][   40/  196]   Loss 0.028510   Top1 98.994141   Top5 100.000000   BatchTime 0.171106   LR 0.000100
INFO - Training [60][   60/  196]   Loss 0.029165   Top1 98.971354   Top5 100.000000   BatchTime 0.155183   LR 0.000100
INFO - Training [60][   80/  196]   Loss 0.029855   Top1 98.955078   Top5 100.000000   BatchTime 0.144164   LR 0.000100
INFO - Training [60][  100/  196]   Loss 0.030047   Top1 98.968750   Top5 100.000000   BatchTime 0.134459   LR 0.000100
INFO - Training [60][  120/  196]   Loss 0.029469   Top1 98.968099   Top5 100.000000   BatchTime 0.128999   LR 0.000100
INFO - Training [60][  140/  196]   Loss 0.029578   Top1 98.976004   Top5 99.997210   BatchTime 0.125017   LR 0.000100
INFO - Training [60][  160/  196]   Loss 0.029973   Top1 98.977051   Top5 99.997559   BatchTime 0.120845   LR 0.000100
INFO - Training [60][  180/  196]   Loss 0.030066   Top1 98.962674   Top5 99.997830   BatchTime 0.119569   LR 0.000100
INFO - ==> Top1: 98.968    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 0.439641   Top1 89.941406   Top5 99.609375   BatchTime 0.144726
INFO - Validation [60][   40/   40]   Loss 0.429081   Top1 90.340000   Top5 99.630000   BatchTime 0.099763
INFO - ==> Top1: 90.340    Top5: 99.630    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [61][   20/  196]   Loss 0.031869   Top1 98.945312   Top5 100.000000   BatchTime 0.220291   LR 0.000100
INFO - Training [61][   40/  196]   Loss 0.031777   Top1 98.886719   Top5 100.000000   BatchTime 0.171869   LR 0.000100
INFO - Training [61][   60/  196]   Loss 0.029896   Top1 99.016927   Top5 100.000000   BatchTime 0.155856   LR 0.000100
INFO - Training [61][   80/  196]   Loss 0.029600   Top1 98.989258   Top5 100.000000   BatchTime 0.147837   LR 0.000100
INFO - Training [61][  100/  196]   Loss 0.030873   Top1 98.945312   Top5 99.996094   BatchTime 0.143041   LR 0.000100
INFO - Training [61][  120/  196]   Loss 0.031571   Top1 98.925781   Top5 99.996745   BatchTime 0.139854   LR 0.000100
INFO - Training [61][  140/  196]   Loss 0.031397   Top1 98.931362   Top5 99.997210   BatchTime 0.137612   LR 0.000100
INFO - Training [61][  160/  196]   Loss 0.031904   Top1 98.920898   Top5 99.997559   BatchTime 0.135791   LR 0.000100
INFO - Training [61][  180/  196]   Loss 0.031892   Top1 98.947483   Top5 99.997830   BatchTime 0.134373   LR 0.000100
INFO - ==> Top1: 98.958    Top5: 99.998    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 0.431096   Top1 90.175781   Top5 99.687500   BatchTime 0.146381
INFO - Validation [61][   40/   40]   Loss 0.422660   Top1 90.530000   Top5 99.640000   BatchTime 0.100932
INFO - ==> Top1: 90.530    Top5: 99.640    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [62][   20/  196]   Loss 0.032757   Top1 98.847656   Top5 100.000000   BatchTime 0.218883   LR 0.000100
INFO - Training [62][   40/  196]   Loss 0.030242   Top1 98.994141   Top5 100.000000   BatchTime 0.153447   LR 0.000100
INFO - Training [62][   60/  196]   Loss 0.030451   Top1 98.990885   Top5 100.000000   BatchTime 0.136776   LR 0.000100
INFO - Training [62][   80/  196]   Loss 0.029696   Top1 99.047852   Top5 100.000000   BatchTime 0.127886   LR 0.000100
INFO - Training [62][  100/  196]   Loss 0.030883   Top1 98.980469   Top5 100.000000   BatchTime 0.122729   LR 0.000100
INFO - Training [62][  120/  196]   Loss 0.031259   Top1 98.964844   Top5 100.000000   BatchTime 0.119405   LR 0.000100
INFO - Training [62][  140/  196]   Loss 0.031315   Top1 98.936942   Top5 99.997210   BatchTime 0.119922   LR 0.000100
INFO - Training [62][  160/  196]   Loss 0.031384   Top1 98.930664   Top5 99.997559   BatchTime 0.120417   LR 0.000100
INFO - Training [62][  180/  196]   Loss 0.030894   Top1 98.956163   Top5 99.995660   BatchTime 0.120691   LR 0.000100
INFO - ==> Top1: 98.948    Top5: 99.996    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 0.439130   Top1 89.960938   Top5 99.648438   BatchTime 0.146310
INFO - Validation [62][   40/   40]   Loss 0.426707   Top1 90.350000   Top5 99.640000   BatchTime 0.100794
INFO - ==> Top1: 90.350    Top5: 99.640    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 0.027876   Top1 99.042969   Top5 100.000000   BatchTime 0.219027   LR 0.000100
INFO - Training [63][   40/  196]   Loss 0.028845   Top1 99.003906   Top5 100.000000   BatchTime 0.171345   LR 0.000100
INFO - Training [63][   60/  196]   Loss 0.027777   Top1 99.075521   Top5 100.000000   BatchTime 0.155442   LR 0.000100
INFO - Training [63][   80/  196]   Loss 0.028123   Top1 99.057617   Top5 100.000000   BatchTime 0.147444   LR 0.000100
INFO - Training [63][  100/  196]   Loss 0.029718   Top1 98.984375   Top5 100.000000   BatchTime 0.142766   LR 0.000100
INFO - Training [63][  120/  196]   Loss 0.030591   Top1 98.945312   Top5 100.000000   BatchTime 0.139576   LR 0.000100
INFO - Training [63][  140/  196]   Loss 0.030295   Top1 98.978795   Top5 100.000000   BatchTime 0.137274   LR 0.000100
INFO - Training [63][  160/  196]   Loss 0.031172   Top1 98.940430   Top5 100.000000   BatchTime 0.135505   LR 0.000100
INFO - Training [63][  180/  196]   Loss 0.031142   Top1 98.949653   Top5 100.000000   BatchTime 0.134099   LR 0.000100
INFO - ==> Top1: 98.946    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 0.440136   Top1 90.195312   Top5 99.628906   BatchTime 0.144045
INFO - Validation [63][   40/   40]   Loss 0.427744   Top1 90.480000   Top5 99.650000   BatchTime 0.093490
INFO - ==> Top1: 90.480    Top5: 99.650    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 0.022329   Top1 99.238281   Top5 100.000000   BatchTime 0.202710   LR 0.000100
INFO - Training [64][   40/  196]   Loss 0.027591   Top1 99.013672   Top5 100.000000   BatchTime 0.154144   LR 0.000100
INFO - Training [64][   60/  196]   Loss 0.027083   Top1 99.069010   Top5 100.000000   BatchTime 0.135679   LR 0.000100
INFO - Training [64][   80/  196]   Loss 0.027785   Top1 99.038086   Top5 100.000000   BatchTime 0.132779   LR 0.000100
INFO - Training [64][  100/  196]   Loss 0.028171   Top1 99.031250   Top5 100.000000   BatchTime 0.131031   LR 0.000100
INFO - Training [64][  120/  196]   Loss 0.028537   Top1 99.003906   Top5 100.000000   BatchTime 0.129764   LR 0.000100
INFO - Training [64][  140/  196]   Loss 0.028976   Top1 98.987165   Top5 100.000000   BatchTime 0.128985   LR 0.000100
INFO - Training [64][  160/  196]   Loss 0.029256   Top1 98.984375   Top5 100.000000   BatchTime 0.128204   LR 0.000100
INFO - Training [64][  180/  196]   Loss 0.029792   Top1 98.967014   Top5 100.000000   BatchTime 0.127713   LR 0.000100
INFO - ==> Top1: 98.942    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [64][   20/   40]   Loss 0.434906   Top1 89.804688   Top5 99.550781   BatchTime 0.145271
INFO - Validation [64][   40/   40]   Loss 0.427729   Top1 90.330000   Top5 99.590000   BatchTime 0.099634
INFO - ==> Top1: 90.330    Top5: 99.590    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [65][   20/  196]   Loss 0.031106   Top1 99.160156   Top5 100.000000   BatchTime 0.220012   LR 0.000100
INFO - Training [65][   40/  196]   Loss 0.029619   Top1 99.140625   Top5 100.000000   BatchTime 0.171968   LR 0.000100
INFO - Training [65][   60/  196]   Loss 0.030339   Top1 99.016927   Top5 100.000000   BatchTime 0.155880   LR 0.000100
INFO - Training [65][   80/  196]   Loss 0.029893   Top1 99.013672   Top5 100.000000   BatchTime 0.147886   LR 0.000100
INFO - Training [65][  100/  196]   Loss 0.031713   Top1 98.925781   Top5 100.000000   BatchTime 0.143052   LR 0.000100
INFO - Training [65][  120/  196]   Loss 0.031330   Top1 98.942057   Top5 100.000000   BatchTime 0.139920   LR 0.000100
INFO - Training [65][  140/  196]   Loss 0.031593   Top1 98.953683   Top5 100.000000   BatchTime 0.137549   LR 0.000100
INFO - Training [65][  160/  196]   Loss 0.031566   Top1 98.952637   Top5 100.000000   BatchTime 0.135689   LR 0.000100
INFO - Training [65][  180/  196]   Loss 0.031156   Top1 98.971354   Top5 100.000000   BatchTime 0.134257   LR 0.000100
INFO - ==> Top1: 98.966    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 0.433163   Top1 90.312500   Top5 99.648438   BatchTime 0.134413
INFO - Validation [65][   40/   40]   Loss 0.424717   Top1 90.570000   Top5 99.640000   BatchTime 0.087496
INFO - ==> Top1: 90.570    Top5: 99.640    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [66][   20/  196]   Loss 0.028237   Top1 99.160156   Top5 100.000000   BatchTime 0.224248   LR 0.000100
INFO - Training [66][   40/  196]   Loss 0.030862   Top1 98.945312   Top5 99.990234   BatchTime 0.173996   LR 0.000100
INFO - Training [66][   60/  196]   Loss 0.031173   Top1 98.919271   Top5 99.993490   BatchTime 0.157103   LR 0.000100
INFO - Training [66][   80/  196]   Loss 0.030498   Top1 98.920898   Top5 99.995117   BatchTime 0.148697   LR 0.000100
INFO - Training [66][  100/  196]   Loss 0.030774   Top1 98.929688   Top5 99.996094   BatchTime 0.143674   LR 0.000100
INFO - Training [66][  120/  196]   Loss 0.030878   Top1 98.925781   Top5 99.996745   BatchTime 0.140359   LR 0.000100
INFO - Training [66][  140/  196]   Loss 0.030442   Top1 98.934152   Top5 99.997210   BatchTime 0.137999   LR 0.000100
INFO - Training [66][  160/  196]   Loss 0.030757   Top1 98.930664   Top5 99.997559   BatchTime 0.136158   LR 0.000100
INFO - Training [66][  180/  196]   Loss 0.030908   Top1 98.936632   Top5 99.997830   BatchTime 0.134695   LR 0.000100
INFO - ==> Top1: 98.936    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 0.432095   Top1 90.175781   Top5 99.648438   BatchTime 0.144166
INFO - Validation [66][   40/   40]   Loss 0.425051   Top1 90.550000   Top5 99.660000   BatchTime 0.100291
INFO - ==> Top1: 90.550    Top5: 99.660    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 0.030025   Top1 99.003906   Top5 100.000000   BatchTime 0.237012   LR 0.000100
INFO - Training [67][   40/  196]   Loss 0.030353   Top1 98.964844   Top5 100.000000   BatchTime 0.180494   LR 0.000100
INFO - Training [67][   60/  196]   Loss 0.030419   Top1 98.958333   Top5 100.000000   BatchTime 0.161665   LR 0.000100
INFO - Training [67][   80/  196]   Loss 0.030511   Top1 98.945312   Top5 100.000000   BatchTime 0.152183   LR 0.000100
INFO - Training [67][  100/  196]   Loss 0.031132   Top1 98.949219   Top5 100.000000   BatchTime 0.146348   LR 0.000100
INFO - Training [67][  120/  196]   Loss 0.030544   Top1 98.958333   Top5 99.996745   BatchTime 0.139940   LR 0.000100
INFO - Training [67][  140/  196]   Loss 0.030603   Top1 98.945312   Top5 99.997210   BatchTime 0.133856   LR 0.000100
INFO - Training [67][  160/  196]   Loss 0.030764   Top1 98.913574   Top5 99.997559   BatchTime 0.129711   LR 0.000100
INFO - Training [67][  180/  196]   Loss 0.030552   Top1 98.930122   Top5 99.997830   BatchTime 0.126475   LR 0.000100
INFO - ==> Top1: 98.920    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 0.436161   Top1 89.863281   Top5 99.628906   BatchTime 0.151262
INFO - Validation [67][   40/   40]   Loss 0.424610   Top1 90.300000   Top5 99.640000   BatchTime 0.103903
INFO - ==> Top1: 90.300    Top5: 99.640    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 0.028108   Top1 98.945312   Top5 100.000000   BatchTime 0.219429   LR 0.000100
INFO - Training [68][   40/  196]   Loss 0.029170   Top1 98.984375   Top5 100.000000   BatchTime 0.171725   LR 0.000100
INFO - Training [68][   60/  196]   Loss 0.029030   Top1 98.997396   Top5 100.000000   BatchTime 0.155901   LR 0.000100
INFO - Training [68][   80/  196]   Loss 0.027639   Top1 99.067383   Top5 100.000000   BatchTime 0.148056   LR 0.000100
INFO - Training [68][  100/  196]   Loss 0.028256   Top1 99.046875   Top5 100.000000   BatchTime 0.143175   LR 0.000100
INFO - Training [68][  120/  196]   Loss 0.028980   Top1 99.016927   Top5 100.000000   BatchTime 0.139980   LR 0.000100
INFO - Training [68][  140/  196]   Loss 0.029085   Top1 98.989955   Top5 100.000000   BatchTime 0.137666   LR 0.000100
INFO - Training [68][  160/  196]   Loss 0.029239   Top1 99.006348   Top5 100.000000   BatchTime 0.135808   LR 0.000100
INFO - Training [68][  180/  196]   Loss 0.029792   Top1 99.001736   Top5 100.000000   BatchTime 0.134397   LR 0.000100
INFO - ==> Top1: 98.984    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.428882   Top1 90.156250   Top5 99.609375   BatchTime 0.143825
INFO - Validation [68][   40/   40]   Loss 0.422347   Top1 90.460000   Top5 99.620000   BatchTime 0.099323
INFO - ==> Top1: 90.460    Top5: 99.620    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 0.026419   Top1 99.121094   Top5 100.000000   BatchTime 0.223490   LR 0.000100
INFO - Training [69][   40/  196]   Loss 0.028125   Top1 98.984375   Top5 100.000000   BatchTime 0.173414   LR 0.000100
INFO - Training [69][   60/  196]   Loss 0.029088   Top1 98.925781   Top5 100.000000   BatchTime 0.156587   LR 0.000100
INFO - Training [69][   80/  196]   Loss 0.027878   Top1 99.013672   Top5 100.000000   BatchTime 0.141619   LR 0.000100
INFO - Training [69][  100/  196]   Loss 0.027868   Top1 99.039062   Top5 100.000000   BatchTime 0.134171   LR 0.000100
INFO - Training [69][  120/  196]   Loss 0.028122   Top1 99.023438   Top5 100.000000   BatchTime 0.128790   LR 0.000100
INFO - Training [69][  140/  196]   Loss 0.028338   Top1 99.031808   Top5 100.000000   BatchTime 0.124444   LR 0.000100
INFO - Training [69][  160/  196]   Loss 0.028718   Top1 99.023438   Top5 100.000000   BatchTime 0.120488   LR 0.000100
INFO - Training [69][  180/  196]   Loss 0.028635   Top1 99.027778   Top5 100.000000   BatchTime 0.120834   LR 0.000100
INFO - ==> Top1: 99.012    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [69][   20/   40]   Loss 0.434272   Top1 90.078125   Top5 99.589844   BatchTime 0.143646
INFO - Validation [69][   40/   40]   Loss 0.424550   Top1 90.460000   Top5 99.610000   BatchTime 0.099828
INFO - ==> Top1: 90.460    Top5: 99.610    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  70
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [70][   20/  196]   Loss 0.030880   Top1 99.003906   Top5 100.000000   BatchTime 0.220286   LR 0.000010
INFO - Training [70][   40/  196]   Loss 0.030631   Top1 99.003906   Top5 100.000000   BatchTime 0.171832   LR 0.000010
INFO - Training [70][   60/  196]   Loss 0.030020   Top1 99.069010   Top5 100.000000   BatchTime 0.155671   LR 0.000010
INFO - Training [70][   80/  196]   Loss 0.031369   Top1 98.979492   Top5 100.000000   BatchTime 0.147643   LR 0.000010
INFO - Training [70][  100/  196]   Loss 0.030920   Top1 99.007812   Top5 100.000000   BatchTime 0.142849   LR 0.000010
INFO - Training [70][  120/  196]   Loss 0.030412   Top1 99.000651   Top5 100.000000   BatchTime 0.139595   LR 0.000010
INFO - Training [70][  140/  196]   Loss 0.030254   Top1 98.998326   Top5 100.000000   BatchTime 0.137251   LR 0.000010
INFO - Training [70][  160/  196]   Loss 0.031028   Top1 98.955078   Top5 99.997559   BatchTime 0.135446   LR 0.000010
INFO - Training [70][  180/  196]   Loss 0.030647   Top1 98.962674   Top5 99.997830   BatchTime 0.134038   LR 0.000010
INFO - ==> Top1: 98.956    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [70][   20/   40]   Loss 0.436523   Top1 89.960938   Top5 99.570312   BatchTime 0.145162
INFO - Validation [70][   40/   40]   Loss 0.424295   Top1 90.440000   Top5 99.600000   BatchTime 0.100854
INFO - ==> Top1: 90.440    Top5: 99.600    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  71
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [71][   20/  196]   Loss 0.031285   Top1 98.789062   Top5 100.000000   BatchTime 0.197700   LR 0.000010
INFO - Training [71][   40/  196]   Loss 0.030347   Top1 98.935547   Top5 100.000000   BatchTime 0.148246   LR 0.000010
INFO - Training [71][   60/  196]   Loss 0.030702   Top1 98.984375   Top5 100.000000   BatchTime 0.132849   LR 0.000010
INFO - Training [71][   80/  196]   Loss 0.031327   Top1 98.959961   Top5 100.000000   BatchTime 0.125743   LR 0.000010
INFO - Training [71][  100/  196]   Loss 0.030894   Top1 98.984375   Top5 100.000000   BatchTime 0.117952   LR 0.000010
INFO - Training [71][  120/  196]   Loss 0.031134   Top1 98.955078   Top5 100.000000   BatchTime 0.119308   LR 0.000010
INFO - Training [71][  140/  196]   Loss 0.030870   Top1 98.970424   Top5 100.000000   BatchTime 0.119884   LR 0.000010
INFO - Training [71][  160/  196]   Loss 0.030767   Top1 98.959961   Top5 100.000000   BatchTime 0.120079   LR 0.000010
INFO - Training [71][  180/  196]   Loss 0.030284   Top1 98.988715   Top5 100.000000   BatchTime 0.120426   LR 0.000010
INFO - ==> Top1: 98.986    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [71][   20/   40]   Loss 0.441990   Top1 90.175781   Top5 99.628906   BatchTime 0.144392
INFO - Validation [71][   40/   40]   Loss 0.432338   Top1 90.470000   Top5 99.640000   BatchTime 0.100432
INFO - ==> Top1: 90.470    Top5: 99.640    Loss: 0.432
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  72
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [72][   20/  196]   Loss 0.030580   Top1 98.867188   Top5 100.000000   BatchTime 0.220736   LR 0.000010
INFO - Training [72][   40/  196]   Loss 0.031588   Top1 98.886719   Top5 100.000000   BatchTime 0.172366   LR 0.000010
INFO - Training [72][   60/  196]   Loss 0.030567   Top1 98.860677   Top5 100.000000   BatchTime 0.156020   LR 0.000010
INFO - Training [72][   80/  196]   Loss 0.030397   Top1 98.916016   Top5 100.000000   BatchTime 0.148036   LR 0.000010
INFO - Training [72][  100/  196]   Loss 0.031330   Top1 98.882812   Top5 100.000000   BatchTime 0.143188   LR 0.000010
INFO - Training [72][  120/  196]   Loss 0.030924   Top1 98.886719   Top5 100.000000   BatchTime 0.139982   LR 0.000010
INFO - Training [72][  140/  196]   Loss 0.031259   Top1 98.869978   Top5 100.000000   BatchTime 0.137615   LR 0.000010
INFO - Training [72][  160/  196]   Loss 0.031607   Top1 98.874512   Top5 100.000000   BatchTime 0.135778   LR 0.000010
INFO - Training [72][  180/  196]   Loss 0.031761   Top1 98.880208   Top5 100.000000   BatchTime 0.134281   LR 0.000010
INFO - ==> Top1: 98.874    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [72][   20/   40]   Loss 0.430282   Top1 90.156250   Top5 99.609375   BatchTime 0.127852
INFO - Validation [72][   40/   40]   Loss 0.422216   Top1 90.550000   Top5 99.620000   BatchTime 0.081022
INFO - ==> Top1: 90.550    Top5: 99.620    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  73
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [73][   20/  196]   Loss 0.026625   Top1 99.277344   Top5 100.000000   BatchTime 0.201451   LR 0.000010
INFO - Training [73][   40/  196]   Loss 0.030010   Top1 99.003906   Top5 100.000000   BatchTime 0.144833   LR 0.000010
INFO - Training [73][   60/  196]   Loss 0.029819   Top1 98.984375   Top5 100.000000   BatchTime 0.139354   LR 0.000010
INFO - Training [73][   80/  196]   Loss 0.030989   Top1 98.906250   Top5 100.000000   BatchTime 0.135464   LR 0.000010
INFO - Training [73][  100/  196]   Loss 0.031512   Top1 98.921875   Top5 100.000000   BatchTime 0.133102   LR 0.000010
INFO - Training [73][  120/  196]   Loss 0.031497   Top1 98.932292   Top5 100.000000   BatchTime 0.131517   LR 0.000010
INFO - Training [73][  140/  196]   Loss 0.031120   Top1 98.942522   Top5 100.000000   BatchTime 0.130353   LR 0.000010
INFO - Training [73][  160/  196]   Loss 0.030950   Top1 98.955078   Top5 100.000000   BatchTime 0.129428   LR 0.000010
INFO - Training [73][  180/  196]   Loss 0.030371   Top1 98.980035   Top5 100.000000   BatchTime 0.128714   LR 0.000010
INFO - ==> Top1: 98.984    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [73][   20/   40]   Loss 0.432856   Top1 89.902344   Top5 99.609375   BatchTime 0.146077
INFO - Validation [73][   40/   40]   Loss 0.425027   Top1 90.350000   Top5 99.630000   BatchTime 0.100297
INFO - ==> Top1: 90.350    Top5: 99.630    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  74
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [74][   20/  196]   Loss 0.025598   Top1 99.121094   Top5 100.000000   BatchTime 0.218953   LR 0.000010
INFO - Training [74][   40/  196]   Loss 0.025960   Top1 99.169922   Top5 99.990234   BatchTime 0.171226   LR 0.000010
INFO - Training [74][   60/  196]   Loss 0.027893   Top1 99.062500   Top5 99.993490   BatchTime 0.155294   LR 0.000010
INFO - Training [74][   80/  196]   Loss 0.027129   Top1 99.077148   Top5 99.995117   BatchTime 0.147277   LR 0.000010
INFO - Training [74][  100/  196]   Loss 0.026864   Top1 99.097656   Top5 99.996094   BatchTime 0.142537   LR 0.000010
INFO - Training [74][  120/  196]   Loss 0.028753   Top1 99.039714   Top5 99.996745   BatchTime 0.139386   LR 0.000010
INFO - Training [74][  140/  196]   Loss 0.029340   Top1 99.006696   Top5 99.997210   BatchTime 0.137005   LR 0.000010
INFO - Training [74][  160/  196]   Loss 0.030398   Top1 98.977051   Top5 99.997559   BatchTime 0.135090   LR 0.000010
INFO - Training [74][  180/  196]   Loss 0.030247   Top1 98.975694   Top5 99.997830   BatchTime 0.129767   LR 0.000010
INFO - ==> Top1: 98.952    Top5: 99.998    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [74][   20/   40]   Loss 0.431682   Top1 90.175781   Top5 99.609375   BatchTime 0.127592
INFO - Validation [74][   40/   40]   Loss 0.422402   Top1 90.520000   Top5 99.610000   BatchTime 0.081332
INFO - ==> Top1: 90.520    Top5: 99.610    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  75
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [75][   20/  196]   Loss 0.029846   Top1 99.101562   Top5 100.000000   BatchTime 0.224782   LR 0.000010
INFO - Training [75][   40/  196]   Loss 0.030076   Top1 99.111328   Top5 99.990234   BatchTime 0.176669   LR 0.000010
INFO - Training [75][   60/  196]   Loss 0.029837   Top1 99.082031   Top5 99.986979   BatchTime 0.159197   LR 0.000010
INFO - Training [75][   80/  196]   Loss 0.030369   Top1 99.023438   Top5 99.990234   BatchTime 0.150300   LR 0.000010
INFO - Training [75][  100/  196]   Loss 0.030798   Top1 98.996094   Top5 99.992188   BatchTime 0.144658   LR 0.000010
INFO - Training [75][  120/  196]   Loss 0.030448   Top1 98.987630   Top5 99.993490   BatchTime 0.141287   LR 0.000010
INFO - Training [75][  140/  196]   Loss 0.030625   Top1 98.976004   Top5 99.994420   BatchTime 0.138714   LR 0.000010
INFO - Training [75][  160/  196]   Loss 0.030725   Top1 98.979492   Top5 99.995117   BatchTime 0.136816   LR 0.000010
INFO - Training [75][  180/  196]   Loss 0.030716   Top1 98.977865   Top5 99.995660   BatchTime 0.135316   LR 0.000010
INFO - ==> Top1: 98.962    Top5: 99.996    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [75][   20/   40]   Loss 0.433682   Top1 90.000000   Top5 99.628906   BatchTime 0.146004
INFO - Validation [75][   40/   40]   Loss 0.424304   Top1 90.390000   Top5 99.620000   BatchTime 0.100978
INFO - ==> Top1: 90.390    Top5: 99.620    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  76
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [76][   20/  196]   Loss 0.024526   Top1 99.199219   Top5 100.000000   BatchTime 0.222127   LR 0.000010
INFO - Training [76][   40/  196]   Loss 0.026263   Top1 99.189453   Top5 100.000000   BatchTime 0.172886   LR 0.000010
INFO - Training [76][   60/  196]   Loss 0.025968   Top1 99.205729   Top5 100.000000   BatchTime 0.156391   LR 0.000010
INFO - Training [76][   80/  196]   Loss 0.027171   Top1 99.125977   Top5 100.000000   BatchTime 0.148099   LR 0.000010
INFO - Training [76][  100/  196]   Loss 0.028573   Top1 99.074219   Top5 100.000000   BatchTime 0.143275   LR 0.000010
INFO - Training [76][  120/  196]   Loss 0.029268   Top1 99.039714   Top5 100.000000   BatchTime 0.134031   LR 0.000010
INFO - Training [76][  140/  196]   Loss 0.029822   Top1 99.023438   Top5 100.000000   BatchTime 0.129476   LR 0.000010
INFO - Training [76][  160/  196]   Loss 0.030316   Top1 98.999023   Top5 100.000000   BatchTime 0.125871   LR 0.000010
INFO - Training [76][  180/  196]   Loss 0.029698   Top1 99.027778   Top5 100.000000   BatchTime 0.122548   LR 0.000010
INFO - ==> Top1: 99.006    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [76][   20/   40]   Loss 0.432005   Top1 90.117188   Top5 99.628906   BatchTime 0.143276
INFO - Validation [76][   40/   40]   Loss 0.425760   Top1 90.550000   Top5 99.630000   BatchTime 0.099468
INFO - ==> Top1: 90.550    Top5: 99.630    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  77
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [77][   20/  196]   Loss 0.032933   Top1 98.789062   Top5 100.000000   BatchTime 0.220207   LR 0.000010
INFO - Training [77][   40/  196]   Loss 0.031290   Top1 98.886719   Top5 100.000000   BatchTime 0.171684   LR 0.000010
INFO - Training [77][   60/  196]   Loss 0.031794   Top1 98.899740   Top5 100.000000   BatchTime 0.155643   LR 0.000010
INFO - Training [77][   80/  196]   Loss 0.031288   Top1 98.920898   Top5 100.000000   BatchTime 0.147843   LR 0.000010
INFO - Training [77][  100/  196]   Loss 0.031082   Top1 98.917969   Top5 100.000000   BatchTime 0.142972   LR 0.000010
INFO - Training [77][  120/  196]   Loss 0.031338   Top1 98.883464   Top5 100.000000   BatchTime 0.139830   LR 0.000010
INFO - Training [77][  140/  196]   Loss 0.030900   Top1 98.909040   Top5 100.000000   BatchTime 0.137528   LR 0.000010
INFO - Training [77][  160/  196]   Loss 0.030684   Top1 98.935547   Top5 100.000000   BatchTime 0.135710   LR 0.000010
INFO - Training [77][  180/  196]   Loss 0.030711   Top1 98.940972   Top5 100.000000   BatchTime 0.134283   LR 0.000010
INFO - ==> Top1: 98.934    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [77][   20/   40]   Loss 0.436687   Top1 89.707031   Top5 99.492188   BatchTime 0.145082
INFO - Validation [77][   40/   40]   Loss 0.426865   Top1 90.280000   Top5 99.550000   BatchTime 0.100102
INFO - ==> Top1: 90.280    Top5: 99.550    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  78
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [78][   20/  196]   Loss 0.028347   Top1 99.101562   Top5 100.000000   BatchTime 0.219608   LR 0.000010
INFO - Training [78][   40/  196]   Loss 0.029542   Top1 99.101562   Top5 100.000000   BatchTime 0.171479   LR 0.000010
INFO - Training [78][   60/  196]   Loss 0.030074   Top1 99.075521   Top5 100.000000   BatchTime 0.148183   LR 0.000010
INFO - Training [78][   80/  196]   Loss 0.031110   Top1 98.979492   Top5 100.000000   BatchTime 0.135705   LR 0.000010
INFO - Training [78][  100/  196]   Loss 0.029789   Top1 99.007812   Top5 100.000000   BatchTime 0.129149   LR 0.000010
INFO - Training [78][  120/  196]   Loss 0.029634   Top1 99.013672   Top5 100.000000   BatchTime 0.125068   LR 0.000010
INFO - Training [78][  140/  196]   Loss 0.029789   Top1 99.006696   Top5 99.997210   BatchTime 0.119418   LR 0.000010
INFO - Training [78][  160/  196]   Loss 0.030176   Top1 98.994141   Top5 99.997559   BatchTime 0.119926   LR 0.000010
INFO - Training [78][  180/  196]   Loss 0.030344   Top1 98.993056   Top5 99.997830   BatchTime 0.120272   LR 0.000010
INFO - ==> Top1: 98.994    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [78][   20/   40]   Loss 0.424612   Top1 90.078125   Top5 99.667969   BatchTime 0.144787
INFO - Validation [78][   40/   40]   Loss 0.418604   Top1 90.370000   Top5 99.640000   BatchTime 0.100088
INFO - ==> Top1: 90.370    Top5: 99.640    Loss: 0.419
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  79
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [79][   20/  196]   Loss 0.031341   Top1 99.023438   Top5 100.000000   BatchTime 0.219941   LR 0.000010
INFO - Training [79][   40/  196]   Loss 0.029996   Top1 99.042969   Top5 100.000000   BatchTime 0.170899   LR 0.000010
INFO - Training [79][   60/  196]   Loss 0.030463   Top1 98.990885   Top5 100.000000   BatchTime 0.156806   LR 0.000010
INFO - Training [79][   80/  196]   Loss 0.029264   Top1 99.047852   Top5 100.000000   BatchTime 0.148594   LR 0.000010
INFO - Training [79][  100/  196]   Loss 0.029250   Top1 99.027344   Top5 100.000000   BatchTime 0.143563   LR 0.000010
INFO - Training [79][  120/  196]   Loss 0.029556   Top1 98.987630   Top5 100.000000   BatchTime 0.140200   LR 0.000010
INFO - Training [79][  140/  196]   Loss 0.029991   Top1 98.950893   Top5 100.000000   BatchTime 0.137802   LR 0.000010
INFO - Training [79][  160/  196]   Loss 0.030358   Top1 98.925781   Top5 100.000000   BatchTime 0.135851   LR 0.000010
INFO - Training [79][  180/  196]   Loss 0.030531   Top1 98.947483   Top5 100.000000   BatchTime 0.134395   LR 0.000010
INFO - ==> Top1: 98.948    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [79][   20/   40]   Loss 0.437743   Top1 90.097656   Top5 99.628906   BatchTime 0.144077
INFO - Validation [79][   40/   40]   Loss 0.424009   Top1 90.500000   Top5 99.610000   BatchTime 0.100181
INFO - ==> Top1: 90.500    Top5: 99.610    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.437743   Top1 90.097656   Top5 99.628906   BatchTime 0.130480
INFO - Validation [   40/   40]   Loss 0.424009   Top1 90.500000   Top5 99.610000   BatchTime 0.086014
INFO - ==> Top1: 90.500    Top5: 99.610    Loss: 0.424
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net