INFO - Log file for this run: /home/ilena7440/LSQ/out/ResNet18_imagenet_a8w8_30_epoch80_20221107-151058/ResNet18_imagenet_a8w8_30_epoch80_20221107-151058.log
INFO - TensorBoard data directory: /home/ilena7440/LSQ/out/ResNet18_imagenet_a8w8_30_epoch80_20221107-151058/tb_runs
INFO - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
INFO - Created `resnet18` model for `imagenet` dataset
          Use pre-trained model = True
/home/ilena7440/LSQ/quan/quantizer/lsq.py:128: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
*******************pre-trained****************
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
INFO - Inserted quantizers into the original model
Traceback (most recent call last):
  File "main.py", line 175, in <module>
    main()
  File "main.py", line 104, in main
    lr_scheduler = util.lr_scheduler(optimizer,
  File "/home/ilena7440/LSQ/util/lr_scheduler.py", line 24, in lr_scheduler
    return scheduler(optimizer=optimizer, batch_size=batch_size, num_samples=num_samples,
  File "/home/ilena7440/LSQ/util/lr_scheduler.py", line 140, in __init__
    super(CosineWarmRestartsLr, self).__init__(**kwargs)
TypeError: __init__() got an unexpected keyword argument 'milestones'
Munch({'update_per_batch': True, 'mode': 'cos_warm_restarts', 'milestones': [20, 40, 60], 'gamma': 0.1, 'lr_min': 0, 'cycle': 5, 'cycle_scale': 2, 'amp_scale': 0.5})
cos_warm_restarts