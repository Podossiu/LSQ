
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424.log
2022-11-04 04:04:24.807232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 04:04:24.929818: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 04:04:25.299484: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 04:04:25.299528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 04:04:25.299533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/tb_runs
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
Files already downloaded and verified
hello
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
INFO - Inserted quantizers into the original model
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_25_epoch80_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.394300   Top1 88.750000   Top5 99.492188   BatchTime 0.161983
INFO - Validation [   40/   40]   Loss 0.390075   Top1 88.970000   Top5 99.610000   BatchTime 0.099388
INFO - ==> Top1: 88.970    Top5: 99.610    Loss: 0.390
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 88.970   Top5: 99.610] Sparsity : 0.894
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.079945   Top1 97.167969   Top5 100.000000   BatchTime 0.201162   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.082712   Top1 97.128906   Top5 100.000000   BatchTime 0.142581   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.079296   Top1 97.226562   Top5 100.000000   BatchTime 0.123054   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.080116   Top1 97.177734   Top5 99.995117   BatchTime 0.113065   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.081195   Top1 97.167969   Top5 99.996094   BatchTime 0.107376   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.080642   Top1 97.190755   Top5 99.996745   BatchTime 0.103586   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.081267   Top1 97.123326   Top5 99.997210   BatchTime 0.100851   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.083511   Top1 97.019043   Top5 99.997559   BatchTime 0.098510   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.085390   Top1 97.000868   Top5 99.993490   BatchTime 0.096697   LR 0.010000
INFO - ==> Top1: 96.956    Top5: 99.992    Loss: 0.086
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.384429   Top1 89.687500   Top5 99.628906   BatchTime 0.127392
INFO - Validation [0][   40/   40]   Loss 0.384266   Top1 89.550000   Top5 99.640000   BatchTime 0.080663
INFO - ==> Top1: 89.550    Top5: 99.640    Loss: 0.384
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 89.550   Top5: 99.640] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 88.970   Top5: 99.610] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.080384   Top1 97.265625   Top5 100.000000   BatchTime 0.183597   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.084484   Top1 97.050781   Top5 99.990234   BatchTime 0.134012   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.087113   Top1 96.959635   Top5 99.993490   BatchTime 0.117475   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.087783   Top1 96.977539   Top5 99.985352   BatchTime 0.109234   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.086887   Top1 97.007812   Top5 99.980469   BatchTime 0.105430   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.086562   Top1 97.005208   Top5 99.983724   BatchTime 0.102178   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.087563   Top1 96.972656   Top5 99.986049   BatchTime 0.099465   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.086656   Top1 96.997070   Top5 99.987793   BatchTime 0.097311   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.088282   Top1 96.935764   Top5 99.984809   BatchTime 0.095626   LR 0.010000
INFO - ==> Top1: 96.914    Top5: 99.986    Loss: 0.089
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.386676   Top1 89.667969   Top5 99.570312   BatchTime 0.126841
INFO - Validation [1][   40/   40]   Loss 0.381681   Top1 89.730000   Top5 99.590000   BatchTime 0.080468
INFO - ==> Top1: 89.730    Top5: 99.590    Loss: 0.382
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 89.550   Top5: 99.640] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 88.970   Top5: 99.610] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.082530   Top1 96.992188   Top5 100.000000   BatchTime 0.183972   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.079901   Top1 97.070312   Top5 100.000000   BatchTime 0.133635   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.078206   Top1 97.115885   Top5 100.000000   BatchTime 0.116734   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.082041   Top1 97.016602   Top5 99.995117   BatchTime 0.108292   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.081566   Top1 97.054688   Top5 99.996094   BatchTime 0.103257   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.082334   Top1 97.027995   Top5 99.993490   BatchTime 0.099896   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.083355   Top1 97.011719   Top5 99.988839   BatchTime 0.097523   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.084707   Top1 96.958008   Top5 99.990234   BatchTime 0.095681   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.085670   Top1 96.924913   Top5 99.989149   BatchTime 0.094244   LR 0.010000
INFO - ==> Top1: 96.916    Top5: 99.988    Loss: 0.086
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.388075   Top1 89.902344   Top5 99.609375   BatchTime 0.127010
INFO - Validation [2][   40/   40]   Loss 0.384797   Top1 89.860000   Top5 99.670000   BatchTime 0.080480
INFO - ==> Top1: 89.860    Top5: 99.670    Loss: 0.385
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 89.550   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.070424   Top1 97.558594   Top5 100.000000   BatchTime 0.184455   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.075215   Top1 97.460938   Top5 100.000000   BatchTime 0.134028   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.080162   Top1 97.226562   Top5 99.993490   BatchTime 0.116904   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.083499   Top1 97.119141   Top5 99.985352   BatchTime 0.108515   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.085586   Top1 97.011719   Top5 99.988281   BatchTime 0.103455   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.085996   Top1 96.956380   Top5 99.990234   BatchTime 0.100234   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.085978   Top1 96.961496   Top5 99.988839   BatchTime 0.097896   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.085843   Top1 96.938477   Top5 99.987793   BatchTime 0.095935   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.087051   Top1 96.872830   Top5 99.982639   BatchTime 0.094406   LR 0.010000
INFO - ==> Top1: 96.862    Top5: 99.982    Loss: 0.087
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.391815   Top1 89.453125   Top5 99.609375   BatchTime 0.126063
INFO - Validation [3][   40/   40]   Loss 0.393692   Top1 89.540000   Top5 99.650000   BatchTime 0.079955
INFO - ==> Top1: 89.540    Top5: 99.650    Loss: 0.394
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 89.550   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.081364   Top1 97.031250   Top5 100.000000   BatchTime 0.183787   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.076998   Top1 97.177734   Top5 100.000000   BatchTime 0.133960   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.078541   Top1 97.115885   Top5 100.000000   BatchTime 0.117683   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.081929   Top1 97.011719   Top5 99.995117   BatchTime 0.109414   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.081727   Top1 97.066406   Top5 99.996094   BatchTime 0.104212   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.082199   Top1 97.008464   Top5 99.996745   BatchTime 0.100995   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.082975   Top1 96.983817   Top5 99.997210   BatchTime 0.098707   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.083267   Top1 96.979980   Top5 99.997559   BatchTime 0.096782   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.083818   Top1 96.963976   Top5 99.995660   BatchTime 0.095231   LR 0.010000
INFO - ==> Top1: 96.972    Top5: 99.996    Loss: 0.084
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.390118   Top1 89.960938   Top5 99.609375   BatchTime 0.126182
INFO - Validation [4][   40/   40]   Loss 0.392619   Top1 89.680000   Top5 99.660000   BatchTime 0.080070
INFO - ==> Top1: 89.680    Top5: 99.660    Loss: 0.393
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.680   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.077967   Top1 97.382812   Top5 99.980469   BatchTime 0.183601   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.079269   Top1 97.265625   Top5 99.990234   BatchTime 0.133646   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.083980   Top1 97.050781   Top5 99.993490   BatchTime 0.117676   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.082867   Top1 97.109375   Top5 99.995117   BatchTime 0.110892   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.082815   Top1 97.113281   Top5 99.996094   BatchTime 0.106046   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.084708   Top1 97.014974   Top5 99.996745   BatchTime 0.102440   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.085146   Top1 97.022879   Top5 99.997210   BatchTime 0.099670   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.084266   Top1 97.026367   Top5 99.997559   BatchTime 0.097542   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.084259   Top1 97.059462   Top5 99.993490   BatchTime 0.095876   LR 0.010000
INFO - ==> Top1: 96.988    Top5: 99.994    Loss: 0.086
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.399504   Top1 89.628906   Top5 99.589844   BatchTime 0.126201
INFO - Validation [5][   40/   40]   Loss 0.396744   Top1 89.510000   Top5 99.640000   BatchTime 0.080242
INFO - ==> Top1: 89.510    Top5: 99.640    Loss: 0.397
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.680   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.084792   Top1 97.050781   Top5 99.980469   BatchTime 0.183421   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.082871   Top1 97.109375   Top5 99.970703   BatchTime 0.134034   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.083396   Top1 97.135417   Top5 99.973958   BatchTime 0.117429   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.079295   Top1 97.280273   Top5 99.975586   BatchTime 0.109710   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.081757   Top1 97.199219   Top5 99.968750   BatchTime 0.104829   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.082981   Top1 97.158203   Top5 99.970703   BatchTime 0.101270   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.081898   Top1 97.184710   Top5 99.974888   BatchTime 0.098899   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.082203   Top1 97.177734   Top5 99.975586   BatchTime 0.096954   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.082513   Top1 97.170139   Top5 99.978299   BatchTime 0.095410   LR 0.010000
INFO - ==> Top1: 97.172    Top5: 99.980    Loss: 0.082
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.417298   Top1 89.550781   Top5 99.550781   BatchTime 0.125942
INFO - Validation [6][   40/   40]   Loss 0.402388   Top1 89.560000   Top5 99.600000   BatchTime 0.080130
INFO - ==> Top1: 89.560    Top5: 99.600    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.680   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.076527   Top1 97.207031   Top5 100.000000   BatchTime 0.182243   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.077842   Top1 97.216797   Top5 99.990234   BatchTime 0.133415   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.079722   Top1 97.076823   Top5 99.993490   BatchTime 0.116917   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.079143   Top1 97.084961   Top5 99.995117   BatchTime 0.108752   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.079925   Top1 97.039062   Top5 99.992188   BatchTime 0.103724   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.079542   Top1 97.070312   Top5 99.990234   BatchTime 0.100450   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.081705   Top1 96.969866   Top5 99.991629   BatchTime 0.098073   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.082359   Top1 96.979980   Top5 99.992676   BatchTime 0.096043   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.082677   Top1 96.992188   Top5 99.993490   BatchTime 0.094498   LR 0.010000
INFO - ==> Top1: 96.988    Top5: 99.994    Loss: 0.083
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.391110   Top1 89.960938   Top5 99.511719   BatchTime 0.126394
INFO - Validation [7][   40/   40]   Loss 0.391514   Top1 89.880000   Top5 99.590000   BatchTime 0.080215
INFO - ==> Top1: 89.880    Top5: 99.590    Loss: 0.392
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 89.730   Top5: 99.590] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.076764   Top1 97.343750   Top5 99.980469   BatchTime 0.183328   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.078900   Top1 97.158203   Top5 99.990234   BatchTime 0.133990   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.079431   Top1 97.148438   Top5 99.986979   BatchTime 0.117716   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.077520   Top1 97.138672   Top5 99.990234   BatchTime 0.109477   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.077550   Top1 97.175781   Top5 99.988281   BatchTime 0.104543   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.079418   Top1 97.125651   Top5 99.990234   BatchTime 0.101284   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.079283   Top1 97.131696   Top5 99.991629   BatchTime 0.098755   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.080726   Top1 97.084961   Top5 99.990234   BatchTime 0.096752   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.080929   Top1 97.107205   Top5 99.989149   BatchTime 0.095217   LR 0.010000
INFO - ==> Top1: 97.102    Top5: 99.990    Loss: 0.081
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.396393   Top1 89.785156   Top5 99.628906   BatchTime 0.125927
INFO - Validation [8][   40/   40]   Loss 0.395385   Top1 89.750000   Top5 99.690000   BatchTime 0.080075
INFO - ==> Top1: 89.750    Top5: 99.690    Loss: 0.395
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 89.750   Top5: 99.690] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.071780   Top1 97.382812   Top5 99.960938   BatchTime 0.185679   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.074216   Top1 97.392578   Top5 99.980469   BatchTime 0.135109   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.075649   Top1 97.311198   Top5 99.980469   BatchTime 0.118251   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.076747   Top1 97.250977   Top5 99.980469   BatchTime 0.109913   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.076264   Top1 97.292969   Top5 99.984375   BatchTime 0.104931   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.075244   Top1 97.304688   Top5 99.986979   BatchTime 0.101594   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.075861   Top1 97.279576   Top5 99.988839   BatchTime 0.099954   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.076251   Top1 97.282715   Top5 99.987793   BatchTime 0.097824   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.076359   Top1 97.289497   Top5 99.986979   BatchTime 0.096108   LR 0.010000
INFO - ==> Top1: 97.252    Top5: 99.986    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.399948   Top1 89.843750   Top5 99.472656   BatchTime 0.125952
INFO - Validation [9][   40/   40]   Loss 0.395530   Top1 89.960000   Top5 99.630000   BatchTime 0.080220
INFO - ==> Top1: 89.960    Top5: 99.630    Loss: 0.396
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.066579   Top1 97.753906   Top5 99.980469   BatchTime 0.184849   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.069973   Top1 97.480469   Top5 99.990234   BatchTime 0.134520   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.074898   Top1 97.337240   Top5 99.986979   BatchTime 0.117854   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.076137   Top1 97.236328   Top5 99.985352   BatchTime 0.109400   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.076127   Top1 97.273438   Top5 99.988281   BatchTime 0.104323   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.076909   Top1 97.272135   Top5 99.986979   BatchTime 0.100820   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.077537   Top1 97.232143   Top5 99.986049   BatchTime 0.098213   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.076924   Top1 97.250977   Top5 99.987793   BatchTime 0.096245   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.077339   Top1 97.235243   Top5 99.989149   BatchTime 0.094742   LR 0.010000
INFO - ==> Top1: 97.216    Top5: 99.990    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.396594   Top1 89.550781   Top5 99.394531   BatchTime 0.126323
INFO - Validation [10][   40/   40]   Loss 0.394957   Top1 89.430000   Top5 99.550000   BatchTime 0.080188
INFO - ==> Top1: 89.430    Top5: 99.550    Loss: 0.395
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.077762   Top1 97.285156   Top5 100.000000   BatchTime 0.185575   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.072615   Top1 97.373047   Top5 100.000000   BatchTime 0.134993   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.070291   Top1 97.454427   Top5 100.000000   BatchTime 0.117801   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.073216   Top1 97.402344   Top5 99.995117   BatchTime 0.109543   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.075944   Top1 97.281250   Top5 99.996094   BatchTime 0.104532   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.077486   Top1 97.262370   Top5 99.996745   BatchTime 0.101193   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.078229   Top1 97.204241   Top5 99.994420   BatchTime 0.098652   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.077177   Top1 97.219238   Top5 99.995117   BatchTime 0.096668   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.078218   Top1 97.196181   Top5 99.995660   BatchTime 0.095115   LR 0.010000
INFO - ==> Top1: 97.186    Top5: 99.996    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.398582   Top1 89.609375   Top5 99.511719   BatchTime 0.126426
INFO - Validation [11][   40/   40]   Loss 0.391688   Top1 89.630000   Top5 99.590000   BatchTime 0.080255
INFO - ==> Top1: 89.630    Top5: 99.590    Loss: 0.392
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.074385   Top1 97.519531   Top5 99.960938   BatchTime 0.184476   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.073096   Top1 97.470703   Top5 99.980469   BatchTime 0.134066   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.075388   Top1 97.369792   Top5 99.980469   BatchTime 0.117315   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.073353   Top1 97.421875   Top5 99.980469   BatchTime 0.108942   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.073248   Top1 97.382812   Top5 99.984375   BatchTime 0.103891   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.074783   Top1 97.272135   Top5 99.986979   BatchTime 0.100432   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.076090   Top1 97.257254   Top5 99.983259   BatchTime 0.098202   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.075843   Top1 97.304688   Top5 99.982910   BatchTime 0.096214   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.075254   Top1 97.315538   Top5 99.984809   BatchTime 0.094701   LR 0.010000
INFO - ==> Top1: 97.328    Top5: 99.984    Loss: 0.075
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.389543   Top1 89.628906   Top5 99.550781   BatchTime 0.126601
INFO - Validation [12][   40/   40]   Loss 0.385328   Top1 89.690000   Top5 99.600000   BatchTime 0.080332
INFO - ==> Top1: 89.690    Top5: 99.600    Loss: 0.385
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.067626   Top1 97.675781   Top5 99.980469   BatchTime 0.184320   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.073594   Top1 97.324219   Top5 99.990234   BatchTime 0.134534   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.073558   Top1 97.382812   Top5 99.973958   BatchTime 0.118071   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.075542   Top1 97.309570   Top5 99.980469   BatchTime 0.109543   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.076707   Top1 97.250000   Top5 99.972656   BatchTime 0.104438   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.076127   Top1 97.278646   Top5 99.977214   BatchTime 0.101225   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.075228   Top1 97.318638   Top5 99.980469   BatchTime 0.098712   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.075291   Top1 97.321777   Top5 99.980469   BatchTime 0.097381   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.074873   Top1 97.315538   Top5 99.980469   BatchTime 0.095701   LR 0.010000
INFO - ==> Top1: 97.314    Top5: 99.980    Loss: 0.075
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.432678   Top1 89.003906   Top5 99.550781   BatchTime 0.126386
INFO - Validation [13][   40/   40]   Loss 0.415300   Top1 89.510000   Top5 99.630000   BatchTime 0.080182
INFO - ==> Top1: 89.510    Top5: 99.630    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.061033   Top1 97.871094   Top5 100.000000   BatchTime 0.184021   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.065850   Top1 97.705078   Top5 100.000000   BatchTime 0.133946   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.068966   Top1 97.584635   Top5 100.000000   BatchTime 0.117585   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.070450   Top1 97.519531   Top5 100.000000   BatchTime 0.109436   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.071436   Top1 97.457031   Top5 100.000000   BatchTime 0.104413   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.071688   Top1 97.402344   Top5 100.000000   BatchTime 0.100997   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.071669   Top1 97.413504   Top5 99.997210   BatchTime 0.098431   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.072683   Top1 97.373047   Top5 99.997559   BatchTime 0.096408   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.073810   Top1 97.374132   Top5 99.997830   BatchTime 0.094995   LR 0.010000
INFO - ==> Top1: 97.346    Top5: 99.996    Loss: 0.074
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.418075   Top1 89.316406   Top5 99.648438   BatchTime 0.126525
INFO - Validation [14][   40/   40]   Loss 0.403519   Top1 89.570000   Top5 99.680000   BatchTime 0.080196
INFO - ==> Top1: 89.570    Top5: 99.680    Loss: 0.404
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.860   Top5: 99.670] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.071874   Top1 97.460938   Top5 100.000000   BatchTime 0.184662   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.070680   Top1 97.646484   Top5 99.990234   BatchTime 0.134504   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.071848   Top1 97.545573   Top5 99.986979   BatchTime 0.117724   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.072716   Top1 97.436523   Top5 99.985352   BatchTime 0.109304   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.073794   Top1 97.410156   Top5 99.988281   BatchTime 0.104274   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.074460   Top1 97.379557   Top5 99.980469   BatchTime 0.100957   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.074551   Top1 97.380022   Top5 99.983259   BatchTime 0.098436   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.074292   Top1 97.392578   Top5 99.985352   BatchTime 0.096466   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.074299   Top1 97.424045   Top5 99.986979   BatchTime 0.094895   LR 0.010000
INFO - ==> Top1: 97.432    Top5: 99.988    Loss: 0.074
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.402877   Top1 89.921875   Top5 99.453125   BatchTime 0.126524
INFO - Validation [15][   40/   40]   Loss 0.394468   Top1 89.900000   Top5 99.580000   BatchTime 0.080323
INFO - ==> Top1: 89.900    Top5: 99.580    Loss: 0.394
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [15][Top1: 89.900   Top5: 99.580] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.059622   Top1 97.910156   Top5 100.000000   BatchTime 0.184810   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.063548   Top1 97.714844   Top5 99.990234   BatchTime 0.134445   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.065872   Top1 97.636719   Top5 99.993490   BatchTime 0.118170   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.068052   Top1 97.548828   Top5 99.995117   BatchTime 0.109992   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.069444   Top1 97.527344   Top5 99.996094   BatchTime 0.105113   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.067783   Top1 97.568359   Top5 99.996745   BatchTime 0.101716   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.069129   Top1 97.513951   Top5 99.994420   BatchTime 0.099192   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.069639   Top1 97.485352   Top5 99.992676   BatchTime 0.097115   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.070124   Top1 97.452257   Top5 99.991319   BatchTime 0.095540   LR 0.010000
INFO - ==> Top1: 97.440    Top5: 99.992    Loss: 0.070
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.421050   Top1 89.531250   Top5 99.570312   BatchTime 0.126050
INFO - Validation [16][   40/   40]   Loss 0.413428   Top1 89.490000   Top5 99.640000   BatchTime 0.080055
INFO - ==> Top1: 89.490    Top5: 99.640    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [15][Top1: 89.900   Top5: 99.580] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 89.880   Top5: 99.590] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.068530   Top1 97.480469   Top5 99.980469   BatchTime 0.187038   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.067893   Top1 97.519531   Top5 99.990234   BatchTime 0.136660   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.069522   Top1 97.395833   Top5 99.993490   BatchTime 0.119088   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.072772   Top1 97.304688   Top5 99.995117   BatchTime 0.110311   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.073621   Top1 97.269531   Top5 99.996094   BatchTime 0.105193   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.072588   Top1 97.343750   Top5 99.990234   BatchTime 0.101804   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.072747   Top1 97.385603   Top5 99.991629   BatchTime 0.099173   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.072197   Top1 97.392578   Top5 99.990234   BatchTime 0.097106   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.072078   Top1 97.411024   Top5 99.989149   BatchTime 0.095549   LR 0.010000
INFO - ==> Top1: 97.408    Top5: 99.990    Loss: 0.072
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.394456   Top1 90.039062   Top5 99.492188   BatchTime 0.126425
INFO - Validation [17][   40/   40]   Loss 0.399849   Top1 89.970000   Top5 99.610000   BatchTime 0.080274
INFO - ==> Top1: 89.970    Top5: 99.610    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [15][Top1: 89.900   Top5: 99.580] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.064248   Top1 97.773438   Top5 100.000000   BatchTime 0.183889   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.064146   Top1 97.675781   Top5 100.000000   BatchTime 0.133581   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.064011   Top1 97.662760   Top5 100.000000   BatchTime 0.116666   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.065865   Top1 97.578125   Top5 100.000000   BatchTime 0.108112   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.065280   Top1 97.566406   Top5 100.000000   BatchTime 0.103000   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.067536   Top1 97.480469   Top5 100.000000   BatchTime 0.099574   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.067824   Top1 97.500000   Top5 99.997210   BatchTime 0.097265   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.067882   Top1 97.539062   Top5 99.992676   BatchTime 0.095461   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.068148   Top1 97.519531   Top5 99.993490   BatchTime 0.094018   LR 0.010000
INFO - ==> Top1: 97.518    Top5: 99.992    Loss: 0.068
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.416403   Top1 90.019531   Top5 99.550781   BatchTime 0.126407
INFO - Validation [18][   40/   40]   Loss 0.412280   Top1 89.940000   Top5 99.680000   BatchTime 0.080230
INFO - ==> Top1: 89.940    Top5: 99.680    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 89.940   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.064992   Top1 97.714844   Top5 100.000000   BatchTime 0.184537   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.061650   Top1 97.841797   Top5 100.000000   BatchTime 0.134924   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.063801   Top1 97.753906   Top5 99.993490   BatchTime 0.118164   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.065909   Top1 97.734375   Top5 99.990234   BatchTime 0.109962   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.066110   Top1 97.714844   Top5 99.992188   BatchTime 0.104818   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.068713   Top1 97.607422   Top5 99.993490   BatchTime 0.101326   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.067878   Top1 97.661830   Top5 99.994420   BatchTime 0.098811   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.068208   Top1 97.629395   Top5 99.995117   BatchTime 0.096860   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.069155   Top1 97.571615   Top5 99.995660   BatchTime 0.095290   LR 0.010000
INFO - ==> Top1: 97.510    Top5: 99.996    Loss: 0.070
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.412387   Top1 89.667969   Top5 99.628906   BatchTime 0.126117
INFO - Validation [19][   40/   40]   Loss 0.405677   Top1 89.720000   Top5 99.680000   BatchTime 0.080157
INFO - ==> Top1: 89.720    Top5: 99.680    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 89.940   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.070426   Top1 97.558594   Top5 100.000000   BatchTime 0.185014   LR 0.010000
INFO - Training [20][   40/  196]   Loss 0.066028   Top1 97.666016   Top5 100.000000   BatchTime 0.134445   LR 0.010000
INFO - Training [20][   60/  196]   Loss 0.067141   Top1 97.649740   Top5 100.000000   BatchTime 0.117814   LR 0.010000
INFO - Training [20][   80/  196]   Loss 0.065606   Top1 97.695312   Top5 100.000000   BatchTime 0.109554   LR 0.010000
INFO - Training [20][  100/  196]   Loss 0.065823   Top1 97.617188   Top5 99.996094   BatchTime 0.104800   LR 0.010000
INFO - Training [20][  120/  196]   Loss 0.067579   Top1 97.574870   Top5 99.993490   BatchTime 0.101338   LR 0.010000
INFO - Training [20][  140/  196]   Loss 0.068897   Top1 97.505580   Top5 99.994420   BatchTime 0.098899   LR 0.010000
INFO - Training [20][  160/  196]   Loss 0.068550   Top1 97.514648   Top5 99.995117   BatchTime 0.096830   LR 0.010000
INFO - Training [20][  180/  196]   Loss 0.069379   Top1 97.491319   Top5 99.995660   BatchTime 0.095364   LR 0.010000
INFO - ==> Top1: 97.488    Top5: 99.996    Loss: 0.070
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.414832   Top1 89.726562   Top5 99.628906   BatchTime 0.126387
INFO - Validation [20][   40/   40]   Loss 0.406244   Top1 89.890000   Top5 99.680000   BatchTime 0.080135
INFO - ==> Top1: 89.890    Top5: 99.680    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 89.940   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.055674   Top1 98.007812   Top5 100.000000   BatchTime 0.184078   LR 0.010000
INFO - Training [21][   40/  196]   Loss 0.060458   Top1 97.822266   Top5 100.000000   BatchTime 0.133859   LR 0.010000
INFO - Training [21][   60/  196]   Loss 0.061327   Top1 97.747396   Top5 100.000000   BatchTime 0.117128   LR 0.010000
INFO - Training [21][   80/  196]   Loss 0.063975   Top1 97.646484   Top5 100.000000   BatchTime 0.108815   LR 0.010000
INFO - Training [21][  100/  196]   Loss 0.064614   Top1 97.648438   Top5 100.000000   BatchTime 0.103804   LR 0.010000
INFO - Training [21][  120/  196]   Loss 0.065412   Top1 97.613932   Top5 100.000000   BatchTime 0.100485   LR 0.010000
INFO - Training [21][  140/  196]   Loss 0.065342   Top1 97.639509   Top5 99.997210   BatchTime 0.097977   LR 0.010000
INFO - Training [21][  160/  196]   Loss 0.066181   Top1 97.604980   Top5 99.997559   BatchTime 0.095970   LR 0.010000
INFO - Training [21][  180/  196]   Loss 0.066440   Top1 97.604167   Top5 99.997830   BatchTime 0.094479   LR 0.010000
INFO - ==> Top1: 97.608    Top5: 99.996    Loss: 0.066
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.436935   Top1 89.492188   Top5 99.531250   BatchTime 0.126184
INFO - Validation [21][   40/   40]   Loss 0.421809   Top1 89.680000   Top5 99.630000   BatchTime 0.080209
INFO - ==> Top1: 89.680    Top5: 99.630    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 89.940   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.063568   Top1 98.027344   Top5 100.000000   BatchTime 0.189730   LR 0.010000
INFO - Training [22][   40/  196]   Loss 0.060706   Top1 97.929688   Top5 100.000000   BatchTime 0.137494   LR 0.010000
INFO - Training [22][   60/  196]   Loss 0.060046   Top1 97.949219   Top5 99.993490   BatchTime 0.119502   LR 0.010000
INFO - Training [22][   80/  196]   Loss 0.061385   Top1 97.919922   Top5 99.990234   BatchTime 0.110505   LR 0.010000
INFO - Training [22][  100/  196]   Loss 0.062909   Top1 97.828125   Top5 99.988281   BatchTime 0.105505   LR 0.010000
INFO - Training [22][  120/  196]   Loss 0.062396   Top1 97.832031   Top5 99.990234   BatchTime 0.102067   LR 0.010000
INFO - Training [22][  140/  196]   Loss 0.062333   Top1 97.832031   Top5 99.988839   BatchTime 0.099552   LR 0.010000
INFO - Training [22][  160/  196]   Loss 0.062866   Top1 97.810059   Top5 99.990234   BatchTime 0.097397   LR 0.010000
INFO - Training [22][  180/  196]   Loss 0.063250   Top1 97.779948   Top5 99.989149   BatchTime 0.095759   LR 0.010000
INFO - ==> Top1: 97.746    Top5: 99.990    Loss: 0.064
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.421853   Top1 89.511719   Top5 99.589844   BatchTime 0.126466
INFO - Validation [22][   40/   40]   Loss 0.413569   Top1 89.550000   Top5 99.620000   BatchTime 0.080303
INFO - ==> Top1: 89.550    Top5: 99.620    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 89.940   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.063620   Top1 97.714844   Top5 99.980469   BatchTime 0.185124   LR 0.010000
INFO - Training [23][   40/  196]   Loss 0.062604   Top1 97.753906   Top5 99.970703   BatchTime 0.135162   LR 0.010000
INFO - Training [23][   60/  196]   Loss 0.062220   Top1 97.805990   Top5 99.980469   BatchTime 0.118475   LR 0.010000
INFO - Training [23][   80/  196]   Loss 0.061789   Top1 97.846680   Top5 99.985352   BatchTime 0.109892   LR 0.010000
INFO - Training [23][  100/  196]   Loss 0.063987   Top1 97.750000   Top5 99.988281   BatchTime 0.105008   LR 0.010000
INFO - Training [23][  120/  196]   Loss 0.065150   Top1 97.705078   Top5 99.990234   BatchTime 0.101716   LR 0.010000
INFO - Training [23][  140/  196]   Loss 0.065838   Top1 97.681362   Top5 99.991629   BatchTime 0.099113   LR 0.010000
INFO - Training [23][  160/  196]   Loss 0.064866   Top1 97.709961   Top5 99.990234   BatchTime 0.097103   LR 0.010000
INFO - Training [23][  180/  196]   Loss 0.066195   Top1 97.662760   Top5 99.991319   BatchTime 0.095554   LR 0.010000
INFO - ==> Top1: 97.654    Top5: 99.992    Loss: 0.066
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.417043   Top1 90.156250   Top5 99.472656   BatchTime 0.126323
INFO - Validation [23][   40/   40]   Loss 0.410132   Top1 90.190000   Top5 99.590000   BatchTime 0.080234
INFO - ==> Top1: 90.190    Top5: 99.590    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.065716   Top1 97.519531   Top5 100.000000   BatchTime 0.183373   LR 0.010000
INFO - Training [24][   40/  196]   Loss 0.063132   Top1 97.714844   Top5 100.000000   BatchTime 0.133630   LR 0.010000
INFO - Training [24][   60/  196]   Loss 0.061581   Top1 97.832031   Top5 100.000000   BatchTime 0.117035   LR 0.010000
INFO - Training [24][   80/  196]   Loss 0.059292   Top1 97.910156   Top5 100.000000   BatchTime 0.108787   LR 0.010000
INFO - Training [24][  100/  196]   Loss 0.059765   Top1 97.929688   Top5 100.000000   BatchTime 0.103749   LR 0.010000
INFO - Training [24][  120/  196]   Loss 0.060065   Top1 97.913411   Top5 99.996745   BatchTime 0.100340   LR 0.010000
INFO - Training [24][  140/  196]   Loss 0.060059   Top1 97.890625   Top5 99.994420   BatchTime 0.097951   LR 0.010000
INFO - Training [24][  160/  196]   Loss 0.061047   Top1 97.834473   Top5 99.995117   BatchTime 0.096037   LR 0.010000
INFO - Training [24][  180/  196]   Loss 0.061713   Top1 97.803819   Top5 99.993490   BatchTime 0.094560   LR 0.010000
INFO - ==> Top1: 97.800    Top5: 99.994    Loss: 0.062
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.418010   Top1 90.097656   Top5 99.492188   BatchTime 0.126474
INFO - Validation [24][   40/   40]   Loss 0.416540   Top1 89.930000   Top5 99.630000   BatchTime 0.080309
INFO - ==> Top1: 89.930    Top5: 99.630    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.058121   Top1 97.968750   Top5 99.980469   BatchTime 0.184824   LR 0.010000
INFO - Training [25][   40/  196]   Loss 0.058780   Top1 97.900391   Top5 99.990234   BatchTime 0.134487   LR 0.010000
INFO - Training [25][   60/  196]   Loss 0.060706   Top1 97.916667   Top5 99.993490   BatchTime 0.117875   LR 0.010000
INFO - Training [25][   80/  196]   Loss 0.062056   Top1 97.871094   Top5 99.990234   BatchTime 0.109331   LR 0.010000
INFO - Training [25][  100/  196]   Loss 0.062524   Top1 97.812500   Top5 99.992188   BatchTime 0.104161   LR 0.010000
INFO - Training [25][  120/  196]   Loss 0.061448   Top1 97.848307   Top5 99.990234   BatchTime 0.100891   LR 0.010000
INFO - Training [25][  140/  196]   Loss 0.060960   Top1 97.862723   Top5 99.991629   BatchTime 0.098587   LR 0.010000
INFO - Training [25][  160/  196]   Loss 0.061895   Top1 97.797852   Top5 99.990234   BatchTime 0.096607   LR 0.010000
INFO - Training [25][  180/  196]   Loss 0.061589   Top1 97.808160   Top5 99.989149   BatchTime 0.095138   LR 0.010000
INFO - ==> Top1: 97.798    Top5: 99.990    Loss: 0.062
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.431440   Top1 89.570312   Top5 99.609375   BatchTime 0.126021
INFO - Validation [25][   40/   40]   Loss 0.418465   Top1 89.800000   Top5 99.640000   BatchTime 0.080004
INFO - ==> Top1: 89.800    Top5: 99.640    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.064558   Top1 97.656250   Top5 100.000000   BatchTime 0.184110   LR 0.010000
INFO - Training [26][   40/  196]   Loss 0.061788   Top1 97.802734   Top5 100.000000   BatchTime 0.134595   LR 0.010000
INFO - Training [26][   60/  196]   Loss 0.059990   Top1 97.858073   Top5 100.000000   BatchTime 0.119894   LR 0.010000
INFO - Training [26][   80/  196]   Loss 0.062380   Top1 97.778320   Top5 100.000000   BatchTime 0.110831   LR 0.010000
INFO - Training [26][  100/  196]   Loss 0.062105   Top1 97.828125   Top5 100.000000   BatchTime 0.105290   LR 0.010000
INFO - Training [26][  120/  196]   Loss 0.063289   Top1 97.763672   Top5 100.000000   BatchTime 0.101627   LR 0.010000
INFO - Training [26][  140/  196]   Loss 0.063626   Top1 97.762277   Top5 99.997210   BatchTime 0.099020   LR 0.010000
INFO - Training [26][  160/  196]   Loss 0.062378   Top1 97.807617   Top5 99.997559   BatchTime 0.097009   LR 0.010000
INFO - Training [26][  180/  196]   Loss 0.062687   Top1 97.790799   Top5 99.997830   BatchTime 0.095433   LR 0.010000
INFO - ==> Top1: 97.776    Top5: 99.998    Loss: 0.063
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.421943   Top1 89.667969   Top5 99.511719   BatchTime 0.125555
INFO - Validation [26][   40/   40]   Loss 0.414039   Top1 89.930000   Top5 99.610000   BatchTime 0.079725
INFO - ==> Top1: 89.930    Top5: 99.610    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.960   Top5: 99.630] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.062321   Top1 97.753906   Top5 100.000000   BatchTime 0.184605   LR 0.010000
INFO - Training [27][   40/  196]   Loss 0.060146   Top1 97.841797   Top5 99.990234   BatchTime 0.134039   LR 0.010000
INFO - Training [27][   60/  196]   Loss 0.059657   Top1 97.884115   Top5 99.986979   BatchTime 0.116932   LR 0.010000
INFO - Training [27][   80/  196]   Loss 0.060507   Top1 97.841797   Top5 99.990234   BatchTime 0.108359   LR 0.010000
INFO - Training [27][  100/  196]   Loss 0.061891   Top1 97.800781   Top5 99.992188   BatchTime 0.103414   LR 0.010000
INFO - Training [27][  120/  196]   Loss 0.061049   Top1 97.799479   Top5 99.993490   BatchTime 0.100169   LR 0.010000
INFO - Training [27][  140/  196]   Loss 0.061348   Top1 97.826451   Top5 99.994420   BatchTime 0.097655   LR 0.010000
INFO - Training [27][  160/  196]   Loss 0.062044   Top1 97.795410   Top5 99.995117   BatchTime 0.095754   LR 0.010000
INFO - Training [27][  180/  196]   Loss 0.061797   Top1 97.810330   Top5 99.995660   BatchTime 0.094258   LR 0.010000
INFO - ==> Top1: 97.806    Top5: 99.996    Loss: 0.062
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.421851   Top1 89.648438   Top5 99.589844   BatchTime 0.126173
INFO - Validation [27][   40/   40]   Loss 0.410860   Top1 90.070000   Top5 99.600000   BatchTime 0.080125
INFO - ==> Top1: 90.070    Top5: 99.600    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.070   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.051478   Top1 97.988281   Top5 100.000000   BatchTime 0.183163   LR 0.010000
INFO - Training [28][   40/  196]   Loss 0.053753   Top1 98.066406   Top5 100.000000   BatchTime 0.133318   LR 0.010000
INFO - Training [28][   60/  196]   Loss 0.054762   Top1 98.098958   Top5 100.000000   BatchTime 0.117177   LR 0.010000
INFO - Training [28][   80/  196]   Loss 0.055640   Top1 98.085938   Top5 100.000000   BatchTime 0.108845   LR 0.010000
INFO - Training [28][  100/  196]   Loss 0.057626   Top1 97.968750   Top5 100.000000   BatchTime 0.104112   LR 0.010000
INFO - Training [28][  120/  196]   Loss 0.058034   Top1 97.975260   Top5 100.000000   BatchTime 0.100935   LR 0.010000
INFO - Training [28][  140/  196]   Loss 0.058439   Top1 97.965960   Top5 100.000000   BatchTime 0.098494   LR 0.010000
INFO - Training [28][  160/  196]   Loss 0.058259   Top1 98.000488   Top5 100.000000   BatchTime 0.096415   LR 0.010000
INFO - Training [28][  180/  196]   Loss 0.058499   Top1 97.973090   Top5 100.000000   BatchTime 0.094915   LR 0.010000
INFO - ==> Top1: 97.940    Top5: 100.000    Loss: 0.059
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.416330   Top1 89.648438   Top5 99.667969   BatchTime 0.126835
INFO - Validation [28][   40/   40]   Loss 0.411387   Top1 89.890000   Top5 99.650000   BatchTime 0.080417
INFO - ==> Top1: 89.890    Top5: 99.650    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.070   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.057780   Top1 97.851562   Top5 99.980469   BatchTime 0.184162   LR 0.010000
INFO - Training [29][   40/  196]   Loss 0.059142   Top1 97.832031   Top5 99.990234   BatchTime 0.134036   LR 0.010000
INFO - Training [29][   60/  196]   Loss 0.061230   Top1 97.734375   Top5 99.993490   BatchTime 0.117426   LR 0.010000
INFO - Training [29][   80/  196]   Loss 0.060459   Top1 97.763672   Top5 99.995117   BatchTime 0.109114   LR 0.010000
INFO - Training [29][  100/  196]   Loss 0.060823   Top1 97.777344   Top5 99.996094   BatchTime 0.104127   LR 0.010000
INFO - Training [29][  120/  196]   Loss 0.060777   Top1 97.822266   Top5 99.993490   BatchTime 0.101033   LR 0.010000
INFO - Training [29][  140/  196]   Loss 0.060870   Top1 97.829241   Top5 99.991629   BatchTime 0.098617   LR 0.010000
INFO - Training [29][  160/  196]   Loss 0.060364   Top1 97.856445   Top5 99.992676   BatchTime 0.096608   LR 0.010000
INFO - Training [29][  180/  196]   Loss 0.060247   Top1 97.860243   Top5 99.991319   BatchTime 0.095013   LR 0.010000
INFO - ==> Top1: 97.864    Top5: 99.992    Loss: 0.060
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.420301   Top1 89.902344   Top5 99.492188   BatchTime 0.126907
INFO - Validation [29][   40/   40]   Loss 0.416410   Top1 89.830000   Top5 99.590000   BatchTime 0.080428
INFO - ==> Top1: 89.830    Top5: 99.590    Loss: 0.416
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.070   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 89.970   Top5: 99.610] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.057390   Top1 98.007812   Top5 100.000000   BatchTime 0.186958   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.054086   Top1 98.076172   Top5 100.000000   BatchTime 0.135750   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.050649   Top1 98.235677   Top5 100.000000   BatchTime 0.118368   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.050478   Top1 98.237305   Top5 100.000000   BatchTime 0.110041   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.050934   Top1 98.226562   Top5 99.996094   BatchTime 0.104791   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.051275   Top1 98.222656   Top5 99.993490   BatchTime 0.101576   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.052083   Top1 98.208705   Top5 99.994420   BatchTime 0.099916   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.051318   Top1 98.234863   Top5 99.995117   BatchTime 0.097841   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.052038   Top1 98.224826   Top5 99.995660   BatchTime 0.096180   LR 0.001000
INFO - ==> Top1: 98.212    Top5: 99.996    Loss: 0.052
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.416252   Top1 90.097656   Top5 99.511719   BatchTime 0.125365
INFO - Validation [30][   40/   40]   Loss 0.410641   Top1 90.290000   Top5 99.600000   BatchTime 0.079611
INFO - ==> Top1: 90.290    Top5: 99.600    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 90.290   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.070   Top5: 99.600] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.060853   Top1 97.792969   Top5 100.000000   BatchTime 0.181132   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.054562   Top1 98.007812   Top5 100.000000   BatchTime 0.131799   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.054887   Top1 98.033854   Top5 100.000000   BatchTime 0.115704   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.053547   Top1 98.090820   Top5 100.000000   BatchTime 0.107590   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.053109   Top1 98.132812   Top5 99.996094   BatchTime 0.102529   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.052542   Top1 98.180339   Top5 99.996745   BatchTime 0.099533   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.052006   Top1 98.180804   Top5 99.997210   BatchTime 0.097158   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.051454   Top1 98.212891   Top5 99.997559   BatchTime 0.095294   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.051927   Top1 98.179253   Top5 99.997830   BatchTime 0.093929   LR 0.001000
INFO - ==> Top1: 98.166    Top5: 99.998    Loss: 0.052
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.406335   Top1 90.195312   Top5 99.511719   BatchTime 0.125538
INFO - Validation [31][   40/   40]   Loss 0.401910   Top1 90.340000   Top5 99.590000   BatchTime 0.079744
INFO - ==> Top1: 90.340    Top5: 99.590    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.290   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 90.190   Top5: 99.590] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.048675   Top1 98.281250   Top5 100.000000   BatchTime 0.182738   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.048575   Top1 98.251953   Top5 100.000000   BatchTime 0.133123   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.049261   Top1 98.235677   Top5 100.000000   BatchTime 0.116607   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.047556   Top1 98.310547   Top5 99.995117   BatchTime 0.108412   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.048992   Top1 98.253906   Top5 99.996094   BatchTime 0.103653   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.049632   Top1 98.225911   Top5 99.996745   BatchTime 0.100407   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.049731   Top1 98.233817   Top5 99.997210   BatchTime 0.098098   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.049744   Top1 98.237305   Top5 99.995117   BatchTime 0.096199   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.051015   Top1 98.179253   Top5 99.995660   BatchTime 0.094657   LR 0.001000
INFO - ==> Top1: 98.204    Top5: 99.996    Loss: 0.051
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.406973   Top1 90.488281   Top5 99.492188   BatchTime 0.125784
INFO - Validation [32][   40/   40]   Loss 0.403692   Top1 90.440000   Top5 99.620000   BatchTime 0.079850
INFO - ==> Top1: 90.440    Top5: 99.620    Loss: 0.404
INFO - Scoreboard best 1 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.290   Top5: 99.600] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.047592   Top1 98.359375   Top5 100.000000   BatchTime 0.183835   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.049185   Top1 98.359375   Top5 100.000000   BatchTime 0.133665   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.050897   Top1 98.229167   Top5 100.000000   BatchTime 0.117247   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.050593   Top1 98.212891   Top5 100.000000   BatchTime 0.108930   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.050287   Top1 98.222656   Top5 100.000000   BatchTime 0.103800   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.049650   Top1 98.242188   Top5 100.000000   BatchTime 0.100660   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.049612   Top1 98.225446   Top5 100.000000   BatchTime 0.098164   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.049246   Top1 98.254395   Top5 99.997559   BatchTime 0.096183   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.050211   Top1 98.224826   Top5 99.995660   BatchTime 0.094736   LR 0.001000
INFO - ==> Top1: 98.246    Top5: 99.996    Loss: 0.050
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.403861   Top1 90.273438   Top5 99.609375   BatchTime 0.125428
INFO - Validation [33][   40/   40]   Loss 0.400025   Top1 90.270000   Top5 99.660000   BatchTime 0.079685
INFO - ==> Top1: 90.270    Top5: 99.660    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.290   Top5: 99.600] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.045538   Top1 98.378906   Top5 100.000000   BatchTime 0.183284   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.044069   Top1 98.398438   Top5 100.000000   BatchTime 0.134095   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.043940   Top1 98.417969   Top5 100.000000   BatchTime 0.117706   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.043282   Top1 98.442383   Top5 100.000000   BatchTime 0.109117   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.044068   Top1 98.429688   Top5 100.000000   BatchTime 0.104334   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.044356   Top1 98.401693   Top5 100.000000   BatchTime 0.100949   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.045160   Top1 98.376116   Top5 100.000000   BatchTime 0.099360   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.045675   Top1 98.359375   Top5 100.000000   BatchTime 0.097183   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.046133   Top1 98.335503   Top5 100.000000   BatchTime 0.095521   LR 0.001000
INFO - ==> Top1: 98.330    Top5: 100.000    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.405968   Top1 90.214844   Top5 99.550781   BatchTime 0.125752
INFO - Validation [34][   40/   40]   Loss 0.400470   Top1 90.280000   Top5 99.650000   BatchTime 0.079944
INFO - ==> Top1: 90.280    Top5: 99.650    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.290   Top5: 99.600] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.038607   Top1 98.710938   Top5 100.000000   BatchTime 0.182908   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.044218   Top1 98.496094   Top5 100.000000   BatchTime 0.133822   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.043965   Top1 98.476562   Top5 100.000000   BatchTime 0.117433   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.043474   Top1 98.505859   Top5 100.000000   BatchTime 0.108980   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.044588   Top1 98.457031   Top5 100.000000   BatchTime 0.103912   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.044243   Top1 98.453776   Top5 100.000000   BatchTime 0.100677   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.043975   Top1 98.468192   Top5 100.000000   BatchTime 0.098171   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.044088   Top1 98.483887   Top5 100.000000   BatchTime 0.096173   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.044300   Top1 98.478733   Top5 100.000000   BatchTime 0.094606   LR 0.001000
INFO - ==> Top1: 98.466    Top5: 100.000    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.403526   Top1 90.078125   Top5 99.531250   BatchTime 0.125845
INFO - Validation [35][   40/   40]   Loss 0.400698   Top1 90.200000   Top5 99.630000   BatchTime 0.079899
INFO - ==> Top1: 90.200    Top5: 99.630    Loss: 0.401
INFO - Scoreboard best 1 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.290   Top5: 99.600] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.048372   Top1 98.339844   Top5 100.000000   BatchTime 0.183128   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.047352   Top1 98.359375   Top5 100.000000   BatchTime 0.133960   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.048271   Top1 98.339844   Top5 100.000000   BatchTime 0.117249   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.048054   Top1 98.349609   Top5 100.000000   BatchTime 0.109120   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.046773   Top1 98.375000   Top5 100.000000   BatchTime 0.104084   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.046829   Top1 98.336589   Top5 100.000000   BatchTime 0.100944   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.046713   Top1 98.359375   Top5 100.000000   BatchTime 0.098476   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.046416   Top1 98.371582   Top5 100.000000   BatchTime 0.096456   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.046573   Top1 98.350694   Top5 100.000000   BatchTime 0.094870   LR 0.001000
INFO - ==> Top1: 98.350    Top5: 100.000    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.401599   Top1 90.664062   Top5 99.609375   BatchTime 0.127693
INFO - Validation [36][   40/   40]   Loss 0.402489   Top1 90.600000   Top5 99.650000   BatchTime 0.080789
INFO - ==> Top1: 90.600    Top5: 99.650    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.046943   Top1 98.417969   Top5 100.000000   BatchTime 0.182944   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.049517   Top1 98.271484   Top5 100.000000   BatchTime 0.133221   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.048771   Top1 98.281250   Top5 100.000000   BatchTime 0.116661   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.047868   Top1 98.354492   Top5 100.000000   BatchTime 0.108369   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.047961   Top1 98.351562   Top5 99.996094   BatchTime 0.103473   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.048575   Top1 98.320312   Top5 99.993490   BatchTime 0.100097   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.048129   Top1 98.337054   Top5 99.994420   BatchTime 0.097756   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.048115   Top1 98.310547   Top5 99.995117   BatchTime 0.095865   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.047809   Top1 98.318142   Top5 99.995660   BatchTime 0.094390   LR 0.001000
INFO - ==> Top1: 98.288    Top5: 99.996    Loss: 0.049
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.417266   Top1 90.195312   Top5 99.589844   BatchTime 0.125782
INFO - Validation [37][   40/   40]   Loss 0.412921   Top1 90.070000   Top5 99.640000   BatchTime 0.079900
INFO - ==> Top1: 90.070    Top5: 99.640    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 90.340   Top5: 99.590] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.043997   Top1 98.378906   Top5 100.000000   BatchTime 0.183668   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.045162   Top1 98.447266   Top5 100.000000   BatchTime 0.133297   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.043902   Top1 98.548177   Top5 100.000000   BatchTime 0.116622   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.044215   Top1 98.486328   Top5 100.000000   BatchTime 0.108184   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.043559   Top1 98.488281   Top5 100.000000   BatchTime 0.103126   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.043960   Top1 98.473307   Top5 99.996745   BatchTime 0.099698   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.044604   Top1 98.459821   Top5 99.997210   BatchTime 0.097412   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.044074   Top1 98.483887   Top5 99.997559   BatchTime 0.095547   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.043508   Top1 98.489583   Top5 99.997830   BatchTime 0.094104   LR 0.001000
INFO - ==> Top1: 98.456    Top5: 99.998    Loss: 0.044
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.403548   Top1 90.546875   Top5 99.648438   BatchTime 0.131511
INFO - Validation [38][   40/   40]   Loss 0.400184   Top1 90.560000   Top5 99.680000   BatchTime 0.082678
INFO - ==> Top1: 90.560    Top5: 99.680    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.041325   Top1 98.535156   Top5 100.000000   BatchTime 0.184939   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.042738   Top1 98.457031   Top5 100.000000   BatchTime 0.134570   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.044177   Top1 98.424479   Top5 100.000000   BatchTime 0.117615   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.044932   Top1 98.388672   Top5 100.000000   BatchTime 0.109118   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.044897   Top1 98.410156   Top5 99.996094   BatchTime 0.103963   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.044609   Top1 98.417969   Top5 99.996745   BatchTime 0.100493   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.046151   Top1 98.348214   Top5 99.994420   BatchTime 0.098155   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.045797   Top1 98.393555   Top5 99.995117   BatchTime 0.096229   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.045722   Top1 98.398438   Top5 99.995660   BatchTime 0.094689   LR 0.001000
INFO - ==> Top1: 98.398    Top5: 99.996    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.409547   Top1 90.371094   Top5 99.570312   BatchTime 0.125518
INFO - Validation [39][   40/   40]   Loss 0.406185   Top1 90.320000   Top5 99.640000   BatchTime 0.079673
INFO - ==> Top1: 90.320    Top5: 99.640    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.042325   Top1 98.710938   Top5 100.000000   BatchTime 0.184190   LR 0.001000
INFO - Training [40][   40/  196]   Loss 0.045118   Top1 98.457031   Top5 100.000000   BatchTime 0.134078   LR 0.001000
INFO - Training [40][   60/  196]   Loss 0.047400   Top1 98.346354   Top5 100.000000   BatchTime 0.117228   LR 0.001000
INFO - Training [40][   80/  196]   Loss 0.047089   Top1 98.374023   Top5 100.000000   BatchTime 0.108983   LR 0.001000
INFO - Training [40][  100/  196]   Loss 0.047218   Top1 98.355469   Top5 100.000000   BatchTime 0.103835   LR 0.001000
INFO - Training [40][  120/  196]   Loss 0.046952   Top1 98.365885   Top5 100.000000   BatchTime 0.100455   LR 0.001000
INFO - Training [40][  140/  196]   Loss 0.047528   Top1 98.378906   Top5 100.000000   BatchTime 0.097860   LR 0.001000
INFO - Training [40][  160/  196]   Loss 0.047326   Top1 98.354492   Top5 100.000000   BatchTime 0.095908   LR 0.001000
INFO - Training [40][  180/  196]   Loss 0.047033   Top1 98.394097   Top5 100.000000   BatchTime 0.094411   LR 0.001000
INFO - ==> Top1: 98.404    Top5: 99.998    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.405974   Top1 90.410156   Top5 99.570312   BatchTime 0.125545
INFO - Validation [40][   40/   40]   Loss 0.405346   Top1 90.360000   Top5 99.630000   BatchTime 0.079727
INFO - ==> Top1: 90.360    Top5: 99.630    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.042444   Top1 98.593750   Top5 100.000000   BatchTime 0.183814   LR 0.001000
INFO - Training [41][   40/  196]   Loss 0.042318   Top1 98.505859   Top5 100.000000   BatchTime 0.134057   LR 0.001000
INFO - Training [41][   60/  196]   Loss 0.045750   Top1 98.359375   Top5 100.000000   BatchTime 0.117600   LR 0.001000
INFO - Training [41][   80/  196]   Loss 0.043986   Top1 98.432617   Top5 100.000000   BatchTime 0.109075   LR 0.001000
INFO - Training [41][  100/  196]   Loss 0.043301   Top1 98.453125   Top5 100.000000   BatchTime 0.104076   LR 0.001000
INFO - Training [41][  120/  196]   Loss 0.044364   Top1 98.424479   Top5 100.000000   BatchTime 0.100573   LR 0.001000
INFO - Training [41][  140/  196]   Loss 0.045003   Top1 98.406808   Top5 100.000000   BatchTime 0.098152   LR 0.001000
INFO - Training [41][  160/  196]   Loss 0.045799   Top1 98.354492   Top5 99.997559   BatchTime 0.096132   LR 0.001000
INFO - Training [41][  180/  196]   Loss 0.046161   Top1 98.352865   Top5 99.997830   BatchTime 0.094589   LR 0.001000
INFO - ==> Top1: 98.354    Top5: 99.998    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.411102   Top1 90.273438   Top5 99.628906   BatchTime 0.127180
INFO - Validation [41][   40/   40]   Loss 0.403975   Top1 90.420000   Top5 99.650000   BatchTime 0.080608
INFO - ==> Top1: 90.420    Top5: 99.650    Loss: 0.404
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.440   Top5: 99.620] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.041557   Top1 98.632812   Top5 100.000000   BatchTime 0.185334   LR 0.001000
INFO - Training [42][   40/  196]   Loss 0.042413   Top1 98.642578   Top5 100.000000   BatchTime 0.134929   LR 0.001000
INFO - Training [42][   60/  196]   Loss 0.040725   Top1 98.665365   Top5 100.000000   BatchTime 0.117825   LR 0.001000
INFO - Training [42][   80/  196]   Loss 0.041103   Top1 98.666992   Top5 100.000000   BatchTime 0.109139   LR 0.001000
INFO - Training [42][  100/  196]   Loss 0.041741   Top1 98.621094   Top5 100.000000   BatchTime 0.103908   LR 0.001000
INFO - Training [42][  120/  196]   Loss 0.043670   Top1 98.554688   Top5 100.000000   BatchTime 0.100420   LR 0.001000
INFO - Training [42][  140/  196]   Loss 0.043269   Top1 98.560268   Top5 100.000000   BatchTime 0.097956   LR 0.001000
INFO - Training [42][  160/  196]   Loss 0.043572   Top1 98.532715   Top5 100.000000   BatchTime 0.096053   LR 0.001000
INFO - Training [42][  180/  196]   Loss 0.043324   Top1 98.524306   Top5 100.000000   BatchTime 0.094513   LR 0.001000
INFO - ==> Top1: 98.514    Top5: 100.000    Loss: 0.043
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.404354   Top1 90.625000   Top5 99.550781   BatchTime 0.125873
INFO - Validation [42][   40/   40]   Loss 0.399763   Top1 90.450000   Top5 99.620000   BatchTime 0.079974
INFO - ==> Top1: 90.450    Top5: 99.620    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.450   Top5: 99.620] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.039508   Top1 98.691406   Top5 100.000000   BatchTime 0.185669   LR 0.001000
INFO - Training [43][   40/  196]   Loss 0.042376   Top1 98.564453   Top5 100.000000   BatchTime 0.137979   LR 0.001000
INFO - Training [43][   60/  196]   Loss 0.042860   Top1 98.574219   Top5 99.993490   BatchTime 0.119841   LR 0.001000
INFO - Training [43][   80/  196]   Loss 0.041631   Top1 98.608398   Top5 99.995117   BatchTime 0.111134   LR 0.001000
INFO - Training [43][  100/  196]   Loss 0.041494   Top1 98.617188   Top5 99.996094   BatchTime 0.106332   LR 0.001000
INFO - Training [43][  120/  196]   Loss 0.041171   Top1 98.593750   Top5 99.996745   BatchTime 0.102583   LR 0.001000
INFO - Training [43][  140/  196]   Loss 0.041477   Top1 98.568638   Top5 99.997210   BatchTime 0.099844   LR 0.001000
INFO - Training [43][  160/  196]   Loss 0.041519   Top1 98.566895   Top5 99.997559   BatchTime 0.097636   LR 0.001000
INFO - Training [43][  180/  196]   Loss 0.041649   Top1 98.554688   Top5 99.997830   BatchTime 0.095882   LR 0.001000
INFO - ==> Top1: 98.546    Top5: 99.998    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.417732   Top1 90.332031   Top5 99.550781   BatchTime 0.125766
INFO - Validation [43][   40/   40]   Loss 0.405533   Top1 90.310000   Top5 99.620000   BatchTime 0.080021
INFO - ==> Top1: 90.310    Top5: 99.620    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 90.450   Top5: 99.620] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.044175   Top1 98.496094   Top5 100.000000   BatchTime 0.186019   LR 0.001000
INFO - Training [44][   40/  196]   Loss 0.046591   Top1 98.291016   Top5 100.000000   BatchTime 0.135264   LR 0.001000
INFO - Training [44][   60/  196]   Loss 0.045756   Top1 98.326823   Top5 100.000000   BatchTime 0.118379   LR 0.001000
INFO - Training [44][   80/  196]   Loss 0.043315   Top1 98.432617   Top5 100.000000   BatchTime 0.110050   LR 0.001000
INFO - Training [44][  100/  196]   Loss 0.044100   Top1 98.417969   Top5 100.000000   BatchTime 0.104719   LR 0.001000
INFO - Training [44][  120/  196]   Loss 0.044039   Top1 98.417969   Top5 100.000000   BatchTime 0.101139   LR 0.001000
INFO - Training [44][  140/  196]   Loss 0.043473   Top1 98.429129   Top5 100.000000   BatchTime 0.098663   LR 0.001000
INFO - Training [44][  160/  196]   Loss 0.042989   Top1 98.444824   Top5 100.000000   BatchTime 0.096574   LR 0.001000
INFO - Training [44][  180/  196]   Loss 0.042815   Top1 98.454861   Top5 100.000000   BatchTime 0.094954   LR 0.001000
INFO - ==> Top1: 98.478    Top5: 100.000    Loss: 0.043
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.412976   Top1 90.585938   Top5 99.550781   BatchTime 0.126764
INFO - Validation [44][   40/   40]   Loss 0.408213   Top1 90.490000   Top5 99.640000   BatchTime 0.080511
INFO - ==> Top1: 90.490    Top5: 99.640    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.490   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.041715   Top1 98.515625   Top5 100.000000   BatchTime 0.184124   LR 0.001000
INFO - Training [45][   40/  196]   Loss 0.041538   Top1 98.632812   Top5 100.000000   BatchTime 0.133879   LR 0.001000
INFO - Training [45][   60/  196]   Loss 0.042964   Top1 98.619792   Top5 100.000000   BatchTime 0.117738   LR 0.001000
INFO - Training [45][   80/  196]   Loss 0.042789   Top1 98.564453   Top5 100.000000   BatchTime 0.109358   LR 0.001000
INFO - Training [45][  100/  196]   Loss 0.042156   Top1 98.542969   Top5 100.000000   BatchTime 0.104464   LR 0.001000
INFO - Training [45][  120/  196]   Loss 0.041485   Top1 98.564453   Top5 100.000000   BatchTime 0.100951   LR 0.001000
INFO - Training [45][  140/  196]   Loss 0.042000   Top1 98.551897   Top5 100.000000   BatchTime 0.098445   LR 0.001000
INFO - Training [45][  160/  196]   Loss 0.041778   Top1 98.566895   Top5 100.000000   BatchTime 0.096367   LR 0.001000
INFO - Training [45][  180/  196]   Loss 0.041510   Top1 98.548177   Top5 100.000000   BatchTime 0.094784   LR 0.001000
INFO - ==> Top1: 98.548    Top5: 100.000    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.414498   Top1 90.507812   Top5 99.589844   BatchTime 0.125962
INFO - Validation [45][   40/   40]   Loss 0.408720   Top1 90.430000   Top5 99.630000   BatchTime 0.079963
INFO - ==> Top1: 90.430    Top5: 99.630    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.490   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.041275   Top1 98.632812   Top5 100.000000   BatchTime 0.183090   LR 0.001000
INFO - Training [46][   40/  196]   Loss 0.042133   Top1 98.554688   Top5 100.000000   BatchTime 0.133035   LR 0.001000
INFO - Training [46][   60/  196]   Loss 0.040707   Top1 98.587240   Top5 100.000000   BatchTime 0.116308   LR 0.001000
INFO - Training [46][   80/  196]   Loss 0.041058   Top1 98.603516   Top5 100.000000   BatchTime 0.108353   LR 0.001000
INFO - Training [46][  100/  196]   Loss 0.041918   Top1 98.570312   Top5 100.000000   BatchTime 0.103415   LR 0.001000
INFO - Training [46][  120/  196]   Loss 0.041888   Top1 98.577474   Top5 100.000000   BatchTime 0.100121   LR 0.001000
INFO - Training [46][  140/  196]   Loss 0.041440   Top1 98.568638   Top5 100.000000   BatchTime 0.097710   LR 0.001000
INFO - Training [46][  160/  196]   Loss 0.042038   Top1 98.540039   Top5 100.000000   BatchTime 0.095796   LR 0.001000
INFO - Training [46][  180/  196]   Loss 0.041793   Top1 98.532986   Top5 100.000000   BatchTime 0.094287   LR 0.001000
INFO - ==> Top1: 98.516    Top5: 99.998    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.406711   Top1 90.722656   Top5 99.453125   BatchTime 0.125847
INFO - Validation [46][   40/   40]   Loss 0.399819   Top1 90.620000   Top5 99.600000   BatchTime 0.079964
INFO - ==> Top1: 90.620    Top5: 99.600    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.039664   Top1 98.652344   Top5 100.000000   BatchTime 0.183972   LR 0.001000
INFO - Training [47][   40/  196]   Loss 0.039662   Top1 98.642578   Top5 100.000000   BatchTime 0.134233   LR 0.001000
INFO - Training [47][   60/  196]   Loss 0.042680   Top1 98.483073   Top5 100.000000   BatchTime 0.119426   LR 0.001000
INFO - Training [47][   80/  196]   Loss 0.043188   Top1 98.471680   Top5 100.000000   BatchTime 0.110515   LR 0.001000
INFO - Training [47][  100/  196]   Loss 0.043186   Top1 98.500000   Top5 99.996094   BatchTime 0.105139   LR 0.001000
INFO - Training [47][  120/  196]   Loss 0.042308   Top1 98.522135   Top5 99.996745   BatchTime 0.101648   LR 0.001000
INFO - Training [47][  140/  196]   Loss 0.042636   Top1 98.498884   Top5 99.997210   BatchTime 0.098964   LR 0.001000
INFO - Training [47][  160/  196]   Loss 0.043178   Top1 98.498535   Top5 99.997559   BatchTime 0.096973   LR 0.001000
INFO - Training [47][  180/  196]   Loss 0.043350   Top1 98.504774   Top5 99.997830   BatchTime 0.095440   LR 0.001000
INFO - ==> Top1: 98.510    Top5: 99.998    Loss: 0.043
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.415023   Top1 90.332031   Top5 99.550781   BatchTime 0.126277
INFO - Validation [47][   40/   40]   Loss 0.409239   Top1 90.320000   Top5 99.600000   BatchTime 0.080201
INFO - ==> Top1: 90.320    Top5: 99.600    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.038408   Top1 98.652344   Top5 100.000000   BatchTime 0.182886   LR 0.001000
INFO - Training [48][   40/  196]   Loss 0.039022   Top1 98.642578   Top5 100.000000   BatchTime 0.133185   LR 0.001000
INFO - Training [48][   60/  196]   Loss 0.039759   Top1 98.606771   Top5 100.000000   BatchTime 0.116895   LR 0.001000
INFO - Training [48][   80/  196]   Loss 0.039043   Top1 98.662109   Top5 100.000000   BatchTime 0.108436   LR 0.001000
INFO - Training [48][  100/  196]   Loss 0.041315   Top1 98.597656   Top5 100.000000   BatchTime 0.103552   LR 0.001000
INFO - Training [48][  120/  196]   Loss 0.040577   Top1 98.616536   Top5 100.000000   BatchTime 0.100183   LR 0.001000
INFO - Training [48][  140/  196]   Loss 0.041041   Top1 98.599330   Top5 100.000000   BatchTime 0.097744   LR 0.001000
INFO - Training [48][  160/  196]   Loss 0.041039   Top1 98.586426   Top5 100.000000   BatchTime 0.095825   LR 0.001000
INFO - Training [48][  180/  196]   Loss 0.041320   Top1 98.556858   Top5 99.997830   BatchTime 0.094392   LR 0.001000
INFO - ==> Top1: 98.546    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.409512   Top1 90.312500   Top5 99.531250   BatchTime 0.125835
INFO - Validation [48][   40/   40]   Loss 0.404732   Top1 90.270000   Top5 99.640000   BatchTime 0.079937
INFO - ==> Top1: 90.270    Top5: 99.640    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.043592   Top1 98.398438   Top5 100.000000   BatchTime 0.184737   LR 0.001000
INFO - Training [49][   40/  196]   Loss 0.042741   Top1 98.466797   Top5 100.000000   BatchTime 0.134806   LR 0.001000
INFO - Training [49][   60/  196]   Loss 0.041816   Top1 98.561198   Top5 100.000000   BatchTime 0.117632   LR 0.001000
INFO - Training [49][   80/  196]   Loss 0.042888   Top1 98.505859   Top5 100.000000   BatchTime 0.109459   LR 0.001000
INFO - Training [49][  100/  196]   Loss 0.042669   Top1 98.535156   Top5 100.000000   BatchTime 0.104487   LR 0.001000
INFO - Training [49][  120/  196]   Loss 0.042757   Top1 98.525391   Top5 100.000000   BatchTime 0.101102   LR 0.001000
INFO - Training [49][  140/  196]   Loss 0.042388   Top1 98.521205   Top5 100.000000   BatchTime 0.098583   LR 0.001000
INFO - Training [49][  160/  196]   Loss 0.042327   Top1 98.522949   Top5 100.000000   BatchTime 0.096525   LR 0.001000
INFO - Training [49][  180/  196]   Loss 0.042600   Top1 98.509115   Top5 100.000000   BatchTime 0.094953   LR 0.001000
INFO - ==> Top1: 98.528    Top5: 100.000    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.419681   Top1 90.117188   Top5 99.531250   BatchTime 0.126253
INFO - Validation [49][   40/   40]   Loss 0.408975   Top1 90.370000   Top5 99.640000   BatchTime 0.080175
INFO - ==> Top1: 90.370    Top5: 99.640    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.042047   Top1 98.632812   Top5 100.000000   BatchTime 0.183331   LR 0.001000
INFO - Training [50][   40/  196]   Loss 0.043076   Top1 98.544922   Top5 100.000000   BatchTime 0.133936   LR 0.001000
INFO - Training [50][   60/  196]   Loss 0.042585   Top1 98.587240   Top5 100.000000   BatchTime 0.117148   LR 0.001000
INFO - Training [50][   80/  196]   Loss 0.042345   Top1 98.574219   Top5 100.000000   BatchTime 0.109405   LR 0.001000
INFO - Training [50][  100/  196]   Loss 0.042699   Top1 98.578125   Top5 100.000000   BatchTime 0.104613   LR 0.001000
INFO - Training [50][  120/  196]   Loss 0.041678   Top1 98.619792   Top5 100.000000   BatchTime 0.101314   LR 0.001000
INFO - Training [50][  140/  196]   Loss 0.041005   Top1 98.657924   Top5 100.000000   BatchTime 0.099071   LR 0.001000
INFO - Training [50][  160/  196]   Loss 0.041778   Top1 98.635254   Top5 100.000000   BatchTime 0.097011   LR 0.001000
INFO - Training [50][  180/  196]   Loss 0.041826   Top1 98.637153   Top5 100.000000   BatchTime 0.095518   LR 0.001000
INFO - ==> Top1: 98.622    Top5: 100.000    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.415646   Top1 90.312500   Top5 99.511719   BatchTime 0.126673
INFO - Validation [50][   40/   40]   Loss 0.409853   Top1 90.270000   Top5 99.610000   BatchTime 0.080272
INFO - ==> Top1: 90.270    Top5: 99.610    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.044764   Top1 98.457031   Top5 100.000000   BatchTime 0.182717   LR 0.001000
INFO - Training [51][   40/  196]   Loss 0.041160   Top1 98.613281   Top5 100.000000   BatchTime 0.134266   LR 0.001000
INFO - Training [51][   60/  196]   Loss 0.041781   Top1 98.626302   Top5 99.993490   BatchTime 0.117470   LR 0.001000
INFO - Training [51][   80/  196]   Loss 0.041310   Top1 98.623047   Top5 99.995117   BatchTime 0.109165   LR 0.001000
INFO - Training [51][  100/  196]   Loss 0.041340   Top1 98.601562   Top5 99.996094   BatchTime 0.104301   LR 0.001000
INFO - Training [51][  120/  196]   Loss 0.041651   Top1 98.574219   Top5 99.993490   BatchTime 0.100947   LR 0.001000
INFO - Training [51][  140/  196]   Loss 0.041454   Top1 98.585379   Top5 99.994420   BatchTime 0.099377   LR 0.001000
INFO - Training [51][  160/  196]   Loss 0.041428   Top1 98.581543   Top5 99.995117   BatchTime 0.097246   LR 0.001000
INFO - Training [51][  180/  196]   Loss 0.041206   Top1 98.572049   Top5 99.995660   BatchTime 0.095613   LR 0.001000
INFO - ==> Top1: 98.560    Top5: 99.996    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.421324   Top1 90.039062   Top5 99.472656   BatchTime 0.125509
INFO - Validation [51][   40/   40]   Loss 0.412542   Top1 90.160000   Top5 99.600000   BatchTime 0.079678
INFO - ==> Top1: 90.160    Top5: 99.600    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.039029   Top1 98.593750   Top5 99.980469   BatchTime 0.184437   LR 0.001000
INFO - Training [52][   40/  196]   Loss 0.041727   Top1 98.505859   Top5 99.990234   BatchTime 0.133732   LR 0.001000
INFO - Training [52][   60/  196]   Loss 0.041263   Top1 98.489583   Top5 99.993490   BatchTime 0.116790   LR 0.001000
INFO - Training [52][   80/  196]   Loss 0.040987   Top1 98.510742   Top5 99.995117   BatchTime 0.108501   LR 0.001000
INFO - Training [52][  100/  196]   Loss 0.041573   Top1 98.511719   Top5 99.996094   BatchTime 0.103377   LR 0.001000
INFO - Training [52][  120/  196]   Loss 0.041304   Top1 98.525391   Top5 99.996745   BatchTime 0.099973   LR 0.001000
INFO - Training [52][  140/  196]   Loss 0.041103   Top1 98.543527   Top5 99.997210   BatchTime 0.097573   LR 0.001000
INFO - Training [52][  160/  196]   Loss 0.040993   Top1 98.544922   Top5 99.997559   BatchTime 0.095694   LR 0.001000
INFO - Training [52][  180/  196]   Loss 0.041170   Top1 98.530816   Top5 99.997830   BatchTime 0.094180   LR 0.001000
INFO - ==> Top1: 98.526    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.423983   Top1 90.175781   Top5 99.570312   BatchTime 0.126214
INFO - Validation [52][   40/   40]   Loss 0.415457   Top1 90.240000   Top5 99.630000   BatchTime 0.080076
INFO - ==> Top1: 90.240    Top5: 99.630    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.040592   Top1 98.554688   Top5 100.000000   BatchTime 0.184162   LR 0.001000
INFO - Training [53][   40/  196]   Loss 0.040184   Top1 98.564453   Top5 100.000000   BatchTime 0.133835   LR 0.001000
INFO - Training [53][   60/  196]   Loss 0.041672   Top1 98.476562   Top5 100.000000   BatchTime 0.117502   LR 0.001000
INFO - Training [53][   80/  196]   Loss 0.042285   Top1 98.422852   Top5 100.000000   BatchTime 0.109181   LR 0.001000
INFO - Training [53][  100/  196]   Loss 0.042376   Top1 98.453125   Top5 100.000000   BatchTime 0.104026   LR 0.001000
INFO - Training [53][  120/  196]   Loss 0.041226   Top1 98.515625   Top5 100.000000   BatchTime 0.100527   LR 0.001000
INFO - Training [53][  140/  196]   Loss 0.041367   Top1 98.529576   Top5 100.000000   BatchTime 0.098023   LR 0.001000
INFO - Training [53][  160/  196]   Loss 0.041423   Top1 98.532715   Top5 100.000000   BatchTime 0.096035   LR 0.001000
INFO - Training [53][  180/  196]   Loss 0.041439   Top1 98.537326   Top5 100.000000   BatchTime 0.094602   LR 0.001000
INFO - ==> Top1: 98.524    Top5: 100.000    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.429541   Top1 90.488281   Top5 99.531250   BatchTime 0.126615
INFO - Validation [53][   40/   40]   Loss 0.420905   Top1 90.520000   Top5 99.620000   BatchTime 0.080366
INFO - ==> Top1: 90.520    Top5: 99.620    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.040057   Top1 98.554688   Top5 100.000000   BatchTime 0.184268   LR 0.001000
INFO - Training [54][   40/  196]   Loss 0.044610   Top1 98.486328   Top5 100.000000   BatchTime 0.133948   LR 0.001000
INFO - Training [54][   60/  196]   Loss 0.042541   Top1 98.593750   Top5 100.000000   BatchTime 0.117921   LR 0.001000
INFO - Training [54][   80/  196]   Loss 0.041897   Top1 98.579102   Top5 100.000000   BatchTime 0.109749   LR 0.001000
INFO - Training [54][  100/  196]   Loss 0.043054   Top1 98.542969   Top5 100.000000   BatchTime 0.104803   LR 0.001000
INFO - Training [54][  120/  196]   Loss 0.041961   Top1 98.587240   Top5 100.000000   BatchTime 0.101431   LR 0.001000
INFO - Training [54][  140/  196]   Loss 0.041614   Top1 98.577009   Top5 100.000000   BatchTime 0.098978   LR 0.001000
INFO - Training [54][  160/  196]   Loss 0.040488   Top1 98.618164   Top5 100.000000   BatchTime 0.096852   LR 0.001000
INFO - Training [54][  180/  196]   Loss 0.040106   Top1 98.621962   Top5 100.000000   BatchTime 0.095187   LR 0.001000
INFO - ==> Top1: 98.594    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.424332   Top1 90.175781   Top5 99.511719   BatchTime 0.126344
INFO - Validation [54][   40/   40]   Loss 0.417744   Top1 90.240000   Top5 99.570000   BatchTime 0.080219
INFO - ==> Top1: 90.240    Top5: 99.570    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.035070   Top1 98.789062   Top5 100.000000   BatchTime 0.185586   LR 0.001000
INFO - Training [55][   40/  196]   Loss 0.037127   Top1 98.750000   Top5 100.000000   BatchTime 0.135030   LR 0.001000
INFO - Training [55][   60/  196]   Loss 0.037202   Top1 98.782552   Top5 100.000000   BatchTime 0.118254   LR 0.001000
INFO - Training [55][   80/  196]   Loss 0.037298   Top1 98.735352   Top5 100.000000   BatchTime 0.109673   LR 0.001000
INFO - Training [55][  100/  196]   Loss 0.037331   Top1 98.773438   Top5 100.000000   BatchTime 0.104616   LR 0.001000
INFO - Training [55][  120/  196]   Loss 0.038490   Top1 98.733724   Top5 100.000000   BatchTime 0.101173   LR 0.001000
INFO - Training [55][  140/  196]   Loss 0.039486   Top1 98.674665   Top5 100.000000   BatchTime 0.098619   LR 0.001000
INFO - Training [55][  160/  196]   Loss 0.040675   Top1 98.640137   Top5 100.000000   BatchTime 0.096523   LR 0.001000
INFO - Training [55][  180/  196]   Loss 0.041086   Top1 98.621962   Top5 100.000000   BatchTime 0.094937   LR 0.001000
INFO - ==> Top1: 98.632    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.424370   Top1 90.234375   Top5 99.472656   BatchTime 0.126832
INFO - Validation [55][   40/   40]   Loss 0.415473   Top1 90.260000   Top5 99.580000   BatchTime 0.080320
INFO - ==> Top1: 90.260    Top5: 99.580    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.033370   Top1 98.945312   Top5 100.000000   BatchTime 0.183804   LR 0.001000
INFO - Training [56][   40/  196]   Loss 0.035204   Top1 98.808594   Top5 100.000000   BatchTime 0.134017   LR 0.001000
INFO - Training [56][   60/  196]   Loss 0.035372   Top1 98.763021   Top5 100.000000   BatchTime 0.117041   LR 0.001000
INFO - Training [56][   80/  196]   Loss 0.036254   Top1 98.740234   Top5 100.000000   BatchTime 0.108646   LR 0.001000
INFO - Training [56][  100/  196]   Loss 0.036432   Top1 98.726562   Top5 100.000000   BatchTime 0.103789   LR 0.001000
INFO - Training [56][  120/  196]   Loss 0.037614   Top1 98.697917   Top5 100.000000   BatchTime 0.100667   LR 0.001000
INFO - Training [56][  140/  196]   Loss 0.038165   Top1 98.680246   Top5 100.000000   BatchTime 0.098375   LR 0.001000
INFO - Training [56][  160/  196]   Loss 0.038916   Top1 98.652344   Top5 100.000000   BatchTime 0.096460   LR 0.001000
INFO - Training [56][  180/  196]   Loss 0.039228   Top1 98.641493   Top5 100.000000   BatchTime 0.094955   LR 0.001000
INFO - ==> Top1: 98.648    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.421934   Top1 90.214844   Top5 99.550781   BatchTime 0.126391
INFO - Validation [56][   40/   40]   Loss 0.415291   Top1 90.540000   Top5 99.650000   BatchTime 0.080326
INFO - ==> Top1: 90.540    Top5: 99.650    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.037813   Top1 98.730469   Top5 99.980469   BatchTime 0.183483   LR 0.001000
INFO - Training [57][   40/  196]   Loss 0.037092   Top1 98.837891   Top5 99.990234   BatchTime 0.132992   LR 0.001000
INFO - Training [57][   60/  196]   Loss 0.036202   Top1 98.841146   Top5 99.993490   BatchTime 0.116450   LR 0.001000
INFO - Training [57][   80/  196]   Loss 0.039424   Top1 98.686523   Top5 99.995117   BatchTime 0.108035   LR 0.001000
INFO - Training [57][  100/  196]   Loss 0.040223   Top1 98.628906   Top5 99.996094   BatchTime 0.103244   LR 0.001000
INFO - Training [57][  120/  196]   Loss 0.040325   Top1 98.636068   Top5 99.996745   BatchTime 0.099918   LR 0.001000
INFO - Training [57][  140/  196]   Loss 0.040182   Top1 98.663504   Top5 99.997210   BatchTime 0.097455   LR 0.001000
INFO - Training [57][  160/  196]   Loss 0.039564   Top1 98.681641   Top5 99.997559   BatchTime 0.095526   LR 0.001000
INFO - Training [57][  180/  196]   Loss 0.039332   Top1 98.704427   Top5 99.997830   BatchTime 0.094040   LR 0.001000
INFO - ==> Top1: 98.672    Top5: 99.998    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.423212   Top1 90.546875   Top5 99.550781   BatchTime 0.126124
INFO - Validation [57][   40/   40]   Loss 0.416122   Top1 90.560000   Top5 99.620000   BatchTime 0.080156
INFO - ==> Top1: 90.560    Top5: 99.620    Loss: 0.416
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.035983   Top1 98.906250   Top5 100.000000   BatchTime 0.183216   LR 0.001000
INFO - Training [58][   40/  196]   Loss 0.037276   Top1 98.808594   Top5 100.000000   BatchTime 0.133558   LR 0.001000
INFO - Training [58][   60/  196]   Loss 0.038899   Top1 98.697917   Top5 100.000000   BatchTime 0.116908   LR 0.001000
INFO - Training [58][   80/  196]   Loss 0.040123   Top1 98.583984   Top5 100.000000   BatchTime 0.108471   LR 0.001000
INFO - Training [58][  100/  196]   Loss 0.039884   Top1 98.593750   Top5 99.996094   BatchTime 0.103671   LR 0.001000
INFO - Training [58][  120/  196]   Loss 0.039585   Top1 98.629557   Top5 99.996745   BatchTime 0.100596   LR 0.001000
INFO - Training [58][  140/  196]   Loss 0.040110   Top1 98.588170   Top5 99.997210   BatchTime 0.098165   LR 0.001000
INFO - Training [58][  160/  196]   Loss 0.040850   Top1 98.566895   Top5 99.997559   BatchTime 0.096183   LR 0.001000
INFO - Training [58][  180/  196]   Loss 0.040960   Top1 98.585069   Top5 99.997830   BatchTime 0.094691   LR 0.001000
INFO - ==> Top1: 98.592    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.419833   Top1 90.195312   Top5 99.550781   BatchTime 0.126555
INFO - Validation [58][   40/   40]   Loss 0.412518   Top1 90.420000   Top5 99.640000   BatchTime 0.080282
INFO - ==> Top1: 90.420    Top5: 99.640    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.038636   Top1 98.652344   Top5 100.000000   BatchTime 0.185327   LR 0.001000
INFO - Training [59][   40/  196]   Loss 0.039212   Top1 98.642578   Top5 99.990234   BatchTime 0.134599   LR 0.001000
INFO - Training [59][   60/  196]   Loss 0.039398   Top1 98.665365   Top5 99.993490   BatchTime 0.118166   LR 0.001000
INFO - Training [59][   80/  196]   Loss 0.039622   Top1 98.642578   Top5 99.995117   BatchTime 0.109888   LR 0.001000
INFO - Training [59][  100/  196]   Loss 0.039230   Top1 98.664062   Top5 99.996094   BatchTime 0.105054   LR 0.001000
INFO - Training [59][  120/  196]   Loss 0.040152   Top1 98.639323   Top5 99.996745   BatchTime 0.101646   LR 0.001000
INFO - Training [59][  140/  196]   Loss 0.039858   Top1 98.649554   Top5 99.997210   BatchTime 0.099120   LR 0.001000
INFO - Training [59][  160/  196]   Loss 0.040276   Top1 98.625488   Top5 99.997559   BatchTime 0.097077   LR 0.001000
INFO - Training [59][  180/  196]   Loss 0.040746   Top1 98.600260   Top5 99.997830   BatchTime 0.095528   LR 0.001000
INFO - ==> Top1: 98.604    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.427399   Top1 90.429688   Top5 99.589844   BatchTime 0.126068
INFO - Validation [59][   40/   40]   Loss 0.418272   Top1 90.500000   Top5 99.650000   BatchTime 0.079982
INFO - ==> Top1: 90.500    Top5: 99.650    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [60][   20/  196]   Loss 0.042719   Top1 98.496094   Top5 100.000000   BatchTime 0.189865   LR 0.000100
INFO - Training [60][   40/  196]   Loss 0.039881   Top1 98.613281   Top5 100.000000   BatchTime 0.136189   LR 0.000100
INFO - Training [60][   60/  196]   Loss 0.039335   Top1 98.658854   Top5 100.000000   BatchTime 0.118309   LR 0.000100
INFO - Training [60][   80/  196]   Loss 0.039590   Top1 98.647461   Top5 100.000000   BatchTime 0.109442   LR 0.000100
INFO - Training [60][  100/  196]   Loss 0.039316   Top1 98.636719   Top5 100.000000   BatchTime 0.104032   LR 0.000100
INFO - Training [60][  120/  196]   Loss 0.039086   Top1 98.658854   Top5 100.000000   BatchTime 0.100432   LR 0.000100
INFO - Training [60][  140/  196]   Loss 0.040398   Top1 98.616071   Top5 100.000000   BatchTime 0.097855   LR 0.000100
INFO - Training [60][  160/  196]   Loss 0.040574   Top1 98.598633   Top5 100.000000   BatchTime 0.095891   LR 0.000100
INFO - Training [60][  180/  196]   Loss 0.040470   Top1 98.600260   Top5 100.000000   BatchTime 0.094391   LR 0.000100
INFO - ==> Top1: 98.606    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 0.421197   Top1 90.371094   Top5 99.531250   BatchTime 0.126738
INFO - Validation [60][   40/   40]   Loss 0.414983   Top1 90.420000   Top5 99.620000   BatchTime 0.080345
INFO - ==> Top1: 90.420    Top5: 99.620    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [61][   20/  196]   Loss 0.034868   Top1 98.828125   Top5 100.000000   BatchTime 0.184815   LR 0.000100
INFO - Training [61][   40/  196]   Loss 0.036479   Top1 98.730469   Top5 100.000000   BatchTime 0.135298   LR 0.000100
INFO - Training [61][   60/  196]   Loss 0.036410   Top1 98.743490   Top5 100.000000   BatchTime 0.118284   LR 0.000100
INFO - Training [61][   80/  196]   Loss 0.037740   Top1 98.681641   Top5 100.000000   BatchTime 0.109768   LR 0.000100
INFO - Training [61][  100/  196]   Loss 0.038933   Top1 98.632812   Top5 100.000000   BatchTime 0.104701   LR 0.000100
INFO - Training [61][  120/  196]   Loss 0.039484   Top1 98.613281   Top5 100.000000   BatchTime 0.101334   LR 0.000100
INFO - Training [61][  140/  196]   Loss 0.039083   Top1 98.630022   Top5 100.000000   BatchTime 0.098711   LR 0.000100
INFO - Training [61][  160/  196]   Loss 0.039510   Top1 98.613281   Top5 100.000000   BatchTime 0.096771   LR 0.000100
INFO - Training [61][  180/  196]   Loss 0.039640   Top1 98.606771   Top5 100.000000   BatchTime 0.095160   LR 0.000100
INFO - ==> Top1: 98.620    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 0.424998   Top1 90.390625   Top5 99.511719   BatchTime 0.125957
INFO - Validation [61][   40/   40]   Loss 0.416237   Top1 90.410000   Top5 99.610000   BatchTime 0.080039
INFO - ==> Top1: 90.410    Top5: 99.610    Loss: 0.416
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [62][   20/  196]   Loss 0.042104   Top1 98.496094   Top5 100.000000   BatchTime 0.182955   LR 0.000100
INFO - Training [62][   40/  196]   Loss 0.042115   Top1 98.593750   Top5 99.990234   BatchTime 0.133243   LR 0.000100
INFO - Training [62][   60/  196]   Loss 0.039375   Top1 98.678385   Top5 99.993490   BatchTime 0.116392   LR 0.000100
INFO - Training [62][   80/  196]   Loss 0.039632   Top1 98.637695   Top5 99.995117   BatchTime 0.108107   LR 0.000100
INFO - Training [62][  100/  196]   Loss 0.040084   Top1 98.640625   Top5 99.996094   BatchTime 0.103124   LR 0.000100
INFO - Training [62][  120/  196]   Loss 0.040078   Top1 98.642578   Top5 99.996745   BatchTime 0.099796   LR 0.000100
INFO - Training [62][  140/  196]   Loss 0.040117   Top1 98.630022   Top5 99.997210   BatchTime 0.097455   LR 0.000100
INFO - Training [62][  160/  196]   Loss 0.039561   Top1 98.664551   Top5 99.997559   BatchTime 0.095540   LR 0.000100
INFO - Training [62][  180/  196]   Loss 0.038759   Top1 98.702257   Top5 99.997830   BatchTime 0.094057   LR 0.000100
INFO - ==> Top1: 98.692    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 0.422822   Top1 90.488281   Top5 99.550781   BatchTime 0.126746
INFO - Validation [62][   40/   40]   Loss 0.416830   Top1 90.480000   Top5 99.660000   BatchTime 0.080340
INFO - ==> Top1: 90.480    Top5: 99.660    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 0.037489   Top1 98.906250   Top5 100.000000   BatchTime 0.182213   LR 0.000100
INFO - Training [63][   40/  196]   Loss 0.036602   Top1 98.867188   Top5 99.990234   BatchTime 0.132714   LR 0.000100
INFO - Training [63][   60/  196]   Loss 0.037001   Top1 98.834635   Top5 99.993490   BatchTime 0.116138   LR 0.000100
INFO - Training [63][   80/  196]   Loss 0.037333   Top1 98.842773   Top5 99.995117   BatchTime 0.107761   LR 0.000100
INFO - Training [63][  100/  196]   Loss 0.037949   Top1 98.777344   Top5 99.992188   BatchTime 0.102711   LR 0.000100
INFO - Training [63][  120/  196]   Loss 0.038515   Top1 98.763021   Top5 99.993490   BatchTime 0.099493   LR 0.000100
INFO - Training [63][  140/  196]   Loss 0.038907   Top1 98.713728   Top5 99.991629   BatchTime 0.097110   LR 0.000100
INFO - Training [63][  160/  196]   Loss 0.038528   Top1 98.720703   Top5 99.992676   BatchTime 0.095240   LR 0.000100
INFO - Training [63][  180/  196]   Loss 0.038173   Top1 98.715278   Top5 99.993490   BatchTime 0.093777   LR 0.000100
INFO - ==> Top1: 98.692    Top5: 99.994    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 0.418139   Top1 90.312500   Top5 99.628906   BatchTime 0.127813
INFO - Validation [63][   40/   40]   Loss 0.411618   Top1 90.260000   Top5 99.670000   BatchTime 0.081012
INFO - ==> Top1: 90.260    Top5: 99.670    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 0.031478   Top1 98.964844   Top5 99.980469   BatchTime 0.183720   LR 0.000100
INFO - Training [64][   40/  196]   Loss 0.035369   Top1 98.798828   Top5 99.990234   BatchTime 0.133432   LR 0.000100
INFO - Training [64][   60/  196]   Loss 0.035229   Top1 98.815104   Top5 99.993490   BatchTime 0.116954   LR 0.000100
INFO - Training [64][   80/  196]   Loss 0.036148   Top1 98.759766   Top5 99.995117   BatchTime 0.110241   LR 0.000100
INFO - Training [64][  100/  196]   Loss 0.035869   Top1 98.781250   Top5 99.996094   BatchTime 0.105042   LR 0.000100
INFO - Training [64][  120/  196]   Loss 0.036566   Top1 98.743490   Top5 99.996745   BatchTime 0.101611   LR 0.000100
INFO - Training [64][  140/  196]   Loss 0.037216   Top1 98.705357   Top5 99.997210   BatchTime 0.099005   LR 0.000100
INFO - Training [64][  160/  196]   Loss 0.038456   Top1 98.647461   Top5 99.997559   BatchTime 0.096914   LR 0.000100
INFO - Training [64][  180/  196]   Loss 0.038257   Top1 98.641493   Top5 99.995660   BatchTime 0.095301   LR 0.000100
INFO - ==> Top1: 98.648    Top5: 99.996    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [64][   20/   40]   Loss 0.420967   Top1 90.449219   Top5 99.550781   BatchTime 0.126971
INFO - Validation [64][   40/   40]   Loss 0.410492   Top1 90.500000   Top5 99.640000   BatchTime 0.080500
INFO - ==> Top1: 90.500    Top5: 99.640    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.560   Top5: 99.680] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [65][   20/  196]   Loss 0.035688   Top1 98.925781   Top5 100.000000   BatchTime 0.182354   LR 0.000100
INFO - Training [65][   40/  196]   Loss 0.035790   Top1 98.828125   Top5 100.000000   BatchTime 0.132753   LR 0.000100
INFO - Training [65][   60/  196]   Loss 0.036216   Top1 98.828125   Top5 100.000000   BatchTime 0.116422   LR 0.000100
INFO - Training [65][   80/  196]   Loss 0.036286   Top1 98.793945   Top5 100.000000   BatchTime 0.108737   LR 0.000100
INFO - Training [65][  100/  196]   Loss 0.037424   Top1 98.722656   Top5 100.000000   BatchTime 0.103692   LR 0.000100
INFO - Training [65][  120/  196]   Loss 0.037248   Top1 98.723958   Top5 100.000000   BatchTime 0.100287   LR 0.000100
INFO - Training [65][  140/  196]   Loss 0.037479   Top1 98.719308   Top5 99.997210   BatchTime 0.097805   LR 0.000100
INFO - Training [65][  160/  196]   Loss 0.038135   Top1 98.701172   Top5 99.997559   BatchTime 0.095867   LR 0.000100
INFO - Training [65][  180/  196]   Loss 0.038347   Top1 98.680556   Top5 99.997830   BatchTime 0.094354   LR 0.000100
INFO - ==> Top1: 98.672    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 0.416716   Top1 90.625000   Top5 99.550781   BatchTime 0.126404
INFO - Validation [65][   40/   40]   Loss 0.410888   Top1 90.580000   Top5 99.640000   BatchTime 0.080166
INFO - ==> Top1: 90.580    Top5: 99.640    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.580   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [66][   20/  196]   Loss 0.039453   Top1 98.632812   Top5 100.000000   BatchTime 0.183486   LR 0.000100
INFO - Training [66][   40/  196]   Loss 0.040267   Top1 98.593750   Top5 100.000000   BatchTime 0.132995   LR 0.000100
INFO - Training [66][   60/  196]   Loss 0.038904   Top1 98.691406   Top5 100.000000   BatchTime 0.116125   LR 0.000100
INFO - Training [66][   80/  196]   Loss 0.039374   Top1 98.666992   Top5 100.000000   BatchTime 0.107701   LR 0.000100
INFO - Training [66][  100/  196]   Loss 0.039891   Top1 98.605469   Top5 100.000000   BatchTime 0.102664   LR 0.000100
INFO - Training [66][  120/  196]   Loss 0.039606   Top1 98.613281   Top5 100.000000   BatchTime 0.099396   LR 0.000100
INFO - Training [66][  140/  196]   Loss 0.039120   Top1 98.646763   Top5 100.000000   BatchTime 0.097076   LR 0.000100
INFO - Training [66][  160/  196]   Loss 0.038621   Top1 98.642578   Top5 100.000000   BatchTime 0.095353   LR 0.000100
INFO - Training [66][  180/  196]   Loss 0.038859   Top1 98.650174   Top5 100.000000   BatchTime 0.093947   LR 0.000100
INFO - ==> Top1: 98.678    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 0.418361   Top1 90.527344   Top5 99.609375   BatchTime 0.126222
INFO - Validation [66][   40/   40]   Loss 0.412642   Top1 90.530000   Top5 99.640000   BatchTime 0.080015
INFO - ==> Top1: 90.530    Top5: 99.640    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.580   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 0.041280   Top1 98.574219   Top5 100.000000   BatchTime 0.182570   LR 0.000100
INFO - Training [67][   40/  196]   Loss 0.040893   Top1 98.583984   Top5 100.000000   BatchTime 0.133160   LR 0.000100
INFO - Training [67][   60/  196]   Loss 0.040095   Top1 98.593750   Top5 100.000000   BatchTime 0.117099   LR 0.000100
INFO - Training [67][   80/  196]   Loss 0.041535   Top1 98.549805   Top5 100.000000   BatchTime 0.108752   LR 0.000100
INFO - Training [67][  100/  196]   Loss 0.042446   Top1 98.492188   Top5 100.000000   BatchTime 0.103734   LR 0.000100
INFO - Training [67][  120/  196]   Loss 0.041484   Top1 98.531901   Top5 100.000000   BatchTime 0.100504   LR 0.000100
INFO - Training [67][  140/  196]   Loss 0.040774   Top1 98.568638   Top5 100.000000   BatchTime 0.098180   LR 0.000100
INFO - Training [67][  160/  196]   Loss 0.039977   Top1 98.593750   Top5 100.000000   BatchTime 0.096153   LR 0.000100
INFO - Training [67][  180/  196]   Loss 0.039748   Top1 98.600260   Top5 100.000000   BatchTime 0.094613   LR 0.000100
INFO - ==> Top1: 98.622    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 0.422973   Top1 90.312500   Top5 99.589844   BatchTime 0.126137
INFO - Validation [67][   40/   40]   Loss 0.410954   Top1 90.540000   Top5 99.670000   BatchTime 0.080144
INFO - ==> Top1: 90.540    Top5: 99.670    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.580   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 0.036819   Top1 98.847656   Top5 100.000000   BatchTime 0.183362   LR 0.000100
INFO - Training [68][   40/  196]   Loss 0.040701   Top1 98.603516   Top5 100.000000   BatchTime 0.133566   LR 0.000100
INFO - Training [68][   60/  196]   Loss 0.041757   Top1 98.515625   Top5 100.000000   BatchTime 0.117246   LR 0.000100
INFO - Training [68][   80/  196]   Loss 0.041134   Top1 98.549805   Top5 100.000000   BatchTime 0.108716   LR 0.000100
INFO - Training [68][  100/  196]   Loss 0.040033   Top1 98.601562   Top5 99.996094   BatchTime 0.103638   LR 0.000100
INFO - Training [68][  120/  196]   Loss 0.040994   Top1 98.518880   Top5 99.996745   BatchTime 0.101282   LR 0.000100
INFO - Training [68][  140/  196]   Loss 0.040974   Top1 98.498884   Top5 99.997210   BatchTime 0.098661   LR 0.000100
INFO - Training [68][  160/  196]   Loss 0.041067   Top1 98.503418   Top5 99.997559   BatchTime 0.096564   LR 0.000100
INFO - Training [68][  180/  196]   Loss 0.041196   Top1 98.498264   Top5 99.997830   BatchTime 0.094940   LR 0.000100
INFO - ==> Top1: 98.512    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.416571   Top1 90.625000   Top5 99.511719   BatchTime 0.125543
INFO - Validation [68][   40/   40]   Loss 0.411999   Top1 90.560000   Top5 99.610000   BatchTime 0.079855
INFO - ==> Top1: 90.560    Top5: 99.610    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 90.580   Top5: 99.640] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 0.038028   Top1 98.535156   Top5 100.000000   BatchTime 0.184193   LR 0.000100
INFO - Training [69][   40/  196]   Loss 0.036310   Top1 98.662109   Top5 100.000000   BatchTime 0.133621   LR 0.000100
INFO - Training [69][   60/  196]   Loss 0.037136   Top1 98.678385   Top5 100.000000   BatchTime 0.117200   LR 0.000100
INFO - Training [69][   80/  196]   Loss 0.036727   Top1 98.706055   Top5 100.000000   BatchTime 0.108987   LR 0.000100
INFO - Training [69][  100/  196]   Loss 0.035764   Top1 98.750000   Top5 100.000000   BatchTime 0.104219   LR 0.000100
INFO - Training [69][  120/  196]   Loss 0.036122   Top1 98.750000   Top5 100.000000   BatchTime 0.100764   LR 0.000100
INFO - Training [69][  140/  196]   Loss 0.036903   Top1 98.724888   Top5 100.000000   BatchTime 0.098186   LR 0.000100
INFO - Training [69][  160/  196]   Loss 0.037210   Top1 98.706055   Top5 100.000000   BatchTime 0.096185   LR 0.000100
INFO - Training [69][  180/  196]   Loss 0.037464   Top1 98.695747   Top5 100.000000   BatchTime 0.094609   LR 0.000100
INFO - ==> Top1: 98.692    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [69][   20/   40]   Loss 0.417499   Top1 90.605469   Top5 99.550781   BatchTime 0.126311
INFO - Validation [69][   40/   40]   Loss 0.408075   Top1 90.610000   Top5 99.660000   BatchTime 0.080078
INFO - ==> Top1: 90.610    Top5: 99.660    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  70
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [70][   20/  196]   Loss 0.033822   Top1 98.828125   Top5 100.000000   BatchTime 0.182251   LR 0.000010
INFO - Training [70][   40/  196]   Loss 0.035329   Top1 98.847656   Top5 100.000000   BatchTime 0.132957   LR 0.000010
INFO - Training [70][   60/  196]   Loss 0.036554   Top1 98.815104   Top5 100.000000   BatchTime 0.116661   LR 0.000010
INFO - Training [70][   80/  196]   Loss 0.038657   Top1 98.764648   Top5 100.000000   BatchTime 0.108361   LR 0.000010
INFO - Training [70][  100/  196]   Loss 0.039003   Top1 98.742188   Top5 100.000000   BatchTime 0.103330   LR 0.000010
INFO - Training [70][  120/  196]   Loss 0.039151   Top1 98.730469   Top5 100.000000   BatchTime 0.100016   LR 0.000010
INFO - Training [70][  140/  196]   Loss 0.038781   Top1 98.730469   Top5 100.000000   BatchTime 0.097602   LR 0.000010
INFO - Training [70][  160/  196]   Loss 0.038937   Top1 98.710938   Top5 100.000000   BatchTime 0.095674   LR 0.000010
INFO - Training [70][  180/  196]   Loss 0.038637   Top1 98.708767   Top5 100.000000   BatchTime 0.094148   LR 0.000010
INFO - ==> Top1: 98.712    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [70][   20/   40]   Loss 0.420508   Top1 90.175781   Top5 99.550781   BatchTime 0.125523
INFO - Validation [70][   40/   40]   Loss 0.407282   Top1 90.430000   Top5 99.640000   BatchTime 0.079708
INFO - ==> Top1: 90.430    Top5: 99.640    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  71
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [71][   20/  196]   Loss 0.040693   Top1 98.828125   Top5 100.000000   BatchTime 0.184039   LR 0.000010
INFO - Training [71][   40/  196]   Loss 0.040173   Top1 98.818359   Top5 99.990234   BatchTime 0.134218   LR 0.000010
INFO - Training [71][   60/  196]   Loss 0.037940   Top1 98.828125   Top5 99.993490   BatchTime 0.118058   LR 0.000010
INFO - Training [71][   80/  196]   Loss 0.038362   Top1 98.793945   Top5 99.995117   BatchTime 0.109335   LR 0.000010
INFO - Training [71][  100/  196]   Loss 0.038013   Top1 98.765625   Top5 99.996094   BatchTime 0.104210   LR 0.000010
INFO - Training [71][  120/  196]   Loss 0.038384   Top1 98.743490   Top5 99.996745   BatchTime 0.100805   LR 0.000010
INFO - Training [71][  140/  196]   Loss 0.039093   Top1 98.708147   Top5 99.997210   BatchTime 0.098268   LR 0.000010
INFO - Training [71][  160/  196]   Loss 0.039042   Top1 98.701172   Top5 99.997559   BatchTime 0.096240   LR 0.000010
INFO - Training [71][  180/  196]   Loss 0.038200   Top1 98.743490   Top5 99.997830   BatchTime 0.094706   LR 0.000010
INFO - ==> Top1: 98.754    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [71][   20/   40]   Loss 0.418836   Top1 90.488281   Top5 99.550781   BatchTime 0.126063
INFO - Validation [71][   40/   40]   Loss 0.410167   Top1 90.530000   Top5 99.660000   BatchTime 0.080145
INFO - ==> Top1: 90.530    Top5: 99.660    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  72
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [72][   20/  196]   Loss 0.041309   Top1 98.437500   Top5 100.000000   BatchTime 0.183506   LR 0.000010
INFO - Training [72][   40/  196]   Loss 0.039753   Top1 98.574219   Top5 100.000000   BatchTime 0.133128   LR 0.000010
INFO - Training [72][   60/  196]   Loss 0.037880   Top1 98.671875   Top5 100.000000   BatchTime 0.116517   LR 0.000010
INFO - Training [72][   80/  196]   Loss 0.037276   Top1 98.671875   Top5 100.000000   BatchTime 0.108211   LR 0.000010
INFO - Training [72][  100/  196]   Loss 0.038327   Top1 98.671875   Top5 99.996094   BatchTime 0.103149   LR 0.000010
INFO - Training [72][  120/  196]   Loss 0.037886   Top1 98.675130   Top5 99.996745   BatchTime 0.099798   LR 0.000010
INFO - Training [72][  140/  196]   Loss 0.038187   Top1 98.655134   Top5 99.997210   BatchTime 0.097387   LR 0.000010
INFO - Training [72][  160/  196]   Loss 0.038901   Top1 98.618164   Top5 99.997559   BatchTime 0.096212   LR 0.000010
INFO - Training [72][  180/  196]   Loss 0.038828   Top1 98.632812   Top5 99.997830   BatchTime 0.094664   LR 0.000010
INFO - ==> Top1: 98.630    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [72][   20/   40]   Loss 0.422750   Top1 90.429688   Top5 99.511719   BatchTime 0.125731
INFO - Validation [72][   40/   40]   Loss 0.412476   Top1 90.600000   Top5 99.630000   BatchTime 0.079803
INFO - ==> Top1: 90.600    Top5: 99.630    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  73
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [73][   20/  196]   Loss 0.037699   Top1 98.847656   Top5 100.000000   BatchTime 0.185563   LR 0.000010
INFO - Training [73][   40/  196]   Loss 0.037125   Top1 98.740234   Top5 100.000000   BatchTime 0.134761   LR 0.000010
INFO - Training [73][   60/  196]   Loss 0.039195   Top1 98.639323   Top5 100.000000   BatchTime 0.117472   LR 0.000010
INFO - Training [73][   80/  196]   Loss 0.040216   Top1 98.603516   Top5 100.000000   BatchTime 0.109133   LR 0.000010
INFO - Training [73][  100/  196]   Loss 0.039975   Top1 98.585938   Top5 100.000000   BatchTime 0.103928   LR 0.000010
INFO - Training [73][  120/  196]   Loss 0.039528   Top1 98.639323   Top5 100.000000   BatchTime 0.100468   LR 0.000010
INFO - Training [73][  140/  196]   Loss 0.040008   Top1 98.618862   Top5 100.000000   BatchTime 0.098068   LR 0.000010
INFO - Training [73][  160/  196]   Loss 0.039849   Top1 98.623047   Top5 99.997559   BatchTime 0.096057   LR 0.000010
INFO - Training [73][  180/  196]   Loss 0.039438   Top1 98.641493   Top5 99.995660   BatchTime 0.094529   LR 0.000010
INFO - ==> Top1: 98.640    Top5: 99.996    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [73][   20/   40]   Loss 0.416520   Top1 90.234375   Top5 99.511719   BatchTime 0.126252
INFO - Validation [73][   40/   40]   Loss 0.409065   Top1 90.390000   Top5 99.630000   BatchTime 0.080162
INFO - ==> Top1: 90.390    Top5: 99.630    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.600   Top5: 99.650] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  74
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [74][   20/  196]   Loss 0.033073   Top1 98.808594   Top5 100.000000   BatchTime 0.183696   LR 0.000010
INFO - Training [74][   40/  196]   Loss 0.035455   Top1 98.759766   Top5 100.000000   BatchTime 0.133969   LR 0.000010
INFO - Training [74][   60/  196]   Loss 0.036149   Top1 98.697917   Top5 100.000000   BatchTime 0.117286   LR 0.000010
INFO - Training [74][   80/  196]   Loss 0.036732   Top1 98.676758   Top5 100.000000   BatchTime 0.108943   LR 0.000010
INFO - Training [74][  100/  196]   Loss 0.036725   Top1 98.695312   Top5 100.000000   BatchTime 0.104223   LR 0.000010
INFO - Training [74][  120/  196]   Loss 0.037826   Top1 98.655599   Top5 100.000000   BatchTime 0.100881   LR 0.000010
INFO - Training [74][  140/  196]   Loss 0.038672   Top1 98.646763   Top5 100.000000   BatchTime 0.098409   LR 0.000010
INFO - Training [74][  160/  196]   Loss 0.038924   Top1 98.632812   Top5 100.000000   BatchTime 0.096463   LR 0.000010
INFO - Training [74][  180/  196]   Loss 0.038388   Top1 98.656684   Top5 100.000000   BatchTime 0.094927   LR 0.000010
INFO - ==> Top1: 98.660    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [74][   20/   40]   Loss 0.418853   Top1 90.546875   Top5 99.492188   BatchTime 0.125861
INFO - Validation [74][   40/   40]   Loss 0.411603   Top1 90.650000   Top5 99.600000   BatchTime 0.079943
INFO - ==> Top1: 90.650    Top5: 99.600    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [74][Top1: 90.650   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  75
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [75][   20/  196]   Loss 0.038226   Top1 98.691406   Top5 100.000000   BatchTime 0.184974   LR 0.000010
INFO - Training [75][   40/  196]   Loss 0.038443   Top1 98.691406   Top5 99.990234   BatchTime 0.134129   LR 0.000010
INFO - Training [75][   60/  196]   Loss 0.038537   Top1 98.678385   Top5 99.993490   BatchTime 0.117380   LR 0.000010
INFO - Training [75][   80/  196]   Loss 0.039791   Top1 98.598633   Top5 99.995117   BatchTime 0.108975   LR 0.000010
INFO - Training [75][  100/  196]   Loss 0.039722   Top1 98.589844   Top5 99.996094   BatchTime 0.103847   LR 0.000010
INFO - Training [75][  120/  196]   Loss 0.038564   Top1 98.629557   Top5 99.996745   BatchTime 0.100490   LR 0.000010
INFO - Training [75][  140/  196]   Loss 0.038941   Top1 98.638393   Top5 99.997210   BatchTime 0.098035   LR 0.000010
INFO - Training [75][  160/  196]   Loss 0.038991   Top1 98.640137   Top5 99.997559   BatchTime 0.096097   LR 0.000010
INFO - Training [75][  180/  196]   Loss 0.038996   Top1 98.641493   Top5 99.997830   BatchTime 0.094581   LR 0.000010
INFO - ==> Top1: 98.618    Top5: 99.998    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [75][   20/   40]   Loss 0.427415   Top1 90.351562   Top5 99.570312   BatchTime 0.126343
INFO - Validation [75][   40/   40]   Loss 0.416927   Top1 90.350000   Top5 99.650000   BatchTime 0.080024
INFO - ==> Top1: 90.350    Top5: 99.650    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [74][Top1: 90.650   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  76
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [76][   20/  196]   Loss 0.036328   Top1 98.691406   Top5 100.000000   BatchTime 0.183539   LR 0.000010
INFO - Training [76][   40/  196]   Loss 0.034916   Top1 98.750000   Top5 100.000000   BatchTime 0.133770   LR 0.000010
INFO - Training [76][   60/  196]   Loss 0.034102   Top1 98.815104   Top5 100.000000   BatchTime 0.116967   LR 0.000010
INFO - Training [76][   80/  196]   Loss 0.034807   Top1 98.837891   Top5 100.000000   BatchTime 0.108721   LR 0.000010
INFO - Training [76][  100/  196]   Loss 0.036014   Top1 98.792969   Top5 100.000000   BatchTime 0.103775   LR 0.000010
INFO - Training [76][  120/  196]   Loss 0.036966   Top1 98.763021   Top5 100.000000   BatchTime 0.100343   LR 0.000010
INFO - Training [76][  140/  196]   Loss 0.037733   Top1 98.724888   Top5 100.000000   BatchTime 0.097883   LR 0.000010
INFO - Training [76][  160/  196]   Loss 0.038225   Top1 98.708496   Top5 100.000000   BatchTime 0.095940   LR 0.000010
INFO - Training [76][  180/  196]   Loss 0.037990   Top1 98.721788   Top5 100.000000   BatchTime 0.095064   LR 0.000010
INFO - ==> Top1: 98.714    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [76][   20/   40]   Loss 0.416831   Top1 90.449219   Top5 99.550781   BatchTime 0.125511
INFO - Validation [76][   40/   40]   Loss 0.410362   Top1 90.550000   Top5 99.650000   BatchTime 0.079699
INFO - ==> Top1: 90.550    Top5: 99.650    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [74][Top1: 90.650   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [69][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  77
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [77][   20/  196]   Loss 0.044223   Top1 98.437500   Top5 100.000000   BatchTime 0.184952   LR 0.000010
INFO - Training [77][   40/  196]   Loss 0.041023   Top1 98.505859   Top5 100.000000   BatchTime 0.135664   LR 0.000010
INFO - Training [77][   60/  196]   Loss 0.040367   Top1 98.593750   Top5 99.993490   BatchTime 0.119017   LR 0.000010
INFO - Training [77][   80/  196]   Loss 0.039949   Top1 98.618164   Top5 99.995117   BatchTime 0.110249   LR 0.000010
INFO - Training [77][  100/  196]   Loss 0.039336   Top1 98.664062   Top5 99.996094   BatchTime 0.105177   LR 0.000010
INFO - Training [77][  120/  196]   Loss 0.039109   Top1 98.662109   Top5 99.996745   BatchTime 0.101817   LR 0.000010
INFO - Training [77][  140/  196]   Loss 0.039635   Top1 98.646763   Top5 99.997210   BatchTime 0.099368   LR 0.000010
INFO - Training [77][  160/  196]   Loss 0.039868   Top1 98.635254   Top5 99.995117   BatchTime 0.097214   LR 0.000010
INFO - Training [77][  180/  196]   Loss 0.039723   Top1 98.650174   Top5 99.995660   BatchTime 0.095566   LR 0.000010
INFO - ==> Top1: 98.628    Top5: 99.996    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [77][   20/   40]   Loss 0.421644   Top1 90.664062   Top5 99.570312   BatchTime 0.126791
INFO - Validation [77][   40/   40]   Loss 0.415441   Top1 90.610000   Top5 99.660000   BatchTime 0.080275
INFO - ==> Top1: 90.610    Top5: 99.660    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [74][Top1: 90.650   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [77][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  78
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [78][   20/  196]   Loss 0.037502   Top1 98.632812   Top5 100.000000   BatchTime 0.182947   LR 0.000010
INFO - Training [78][   40/  196]   Loss 0.039412   Top1 98.583984   Top5 100.000000   BatchTime 0.133577   LR 0.000010
INFO - Training [78][   60/  196]   Loss 0.039504   Top1 98.580729   Top5 100.000000   BatchTime 0.116865   LR 0.000010
INFO - Training [78][   80/  196]   Loss 0.038863   Top1 98.623047   Top5 100.000000   BatchTime 0.108573   LR 0.000010
INFO - Training [78][  100/  196]   Loss 0.038130   Top1 98.644531   Top5 100.000000   BatchTime 0.103572   LR 0.000010
INFO - Training [78][  120/  196]   Loss 0.037814   Top1 98.668620   Top5 100.000000   BatchTime 0.100296   LR 0.000010
INFO - Training [78][  140/  196]   Loss 0.038909   Top1 98.621652   Top5 100.000000   BatchTime 0.097846   LR 0.000010
INFO - Training [78][  160/  196]   Loss 0.038691   Top1 98.649902   Top5 100.000000   BatchTime 0.095935   LR 0.000010
INFO - Training [78][  180/  196]   Loss 0.038871   Top1 98.648003   Top5 99.997830   BatchTime 0.094477   LR 0.000010
INFO - ==> Top1: 98.656    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [78][   20/   40]   Loss 0.415400   Top1 90.410156   Top5 99.531250   BatchTime 0.126418
INFO - Validation [78][   40/   40]   Loss 0.411413   Top1 90.400000   Top5 99.630000   BatchTime 0.080258
INFO - ==> Top1: 90.400    Top5: 99.630    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [74][Top1: 90.650   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [77][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  79
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [79][   20/  196]   Loss 0.038971   Top1 98.535156   Top5 100.000000   BatchTime 0.183258   LR 0.000010
INFO - Training [79][   40/  196]   Loss 0.038309   Top1 98.662109   Top5 100.000000   BatchTime 0.133099   LR 0.000010
INFO - Training [79][   60/  196]   Loss 0.038642   Top1 98.639323   Top5 100.000000   BatchTime 0.116289   LR 0.000010
INFO - Training [79][   80/  196]   Loss 0.037996   Top1 98.676758   Top5 100.000000   BatchTime 0.107998   LR 0.000010
INFO - Training [79][  100/  196]   Loss 0.037209   Top1 98.714844   Top5 100.000000   BatchTime 0.103019   LR 0.000010
INFO - Training [79][  120/  196]   Loss 0.037726   Top1 98.714193   Top5 100.000000   BatchTime 0.099642   LR 0.000010
INFO - Training [79][  140/  196]   Loss 0.038030   Top1 98.691406   Top5 100.000000   BatchTime 0.097159   LR 0.000010
INFO - Training [79][  160/  196]   Loss 0.037808   Top1 98.681641   Top5 100.000000   BatchTime 0.095316   LR 0.000010
INFO - Training [79][  180/  196]   Loss 0.038506   Top1 98.643663   Top5 100.000000   BatchTime 0.093888   LR 0.000010
INFO - ==> Top1: 98.658    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [79][   20/   40]   Loss 0.422810   Top1 90.507812   Top5 99.531250   BatchTime 0.125583
INFO - Validation [79][   40/   40]   Loss 0.412565   Top1 90.530000   Top5 99.620000   BatchTime 0.079799
INFO - ==> Top1: 90.530    Top5: 99.620    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [74][Top1: 90.650   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 90.620   Top5: 99.600] Sparsity : 0.894
INFO - Scoreboard best 3 ==> Epoch [77][Top1: 90.610   Top5: 99.660] Sparsity : 0.894
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_20221104-040424/MobileNetv2_cifar10_a8w8_hard_pruning_25_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.422810   Top1 90.507812   Top5 99.531250   BatchTime 0.126949
INFO - Validation [   40/   40]   Loss 0.412565   Top1 90.530000   Top5 99.620000   BatchTime 0.080414
INFO - ==> Top1: 90.530    Top5: 99.620    Loss: 0.413
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)