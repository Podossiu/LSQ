INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538.log
2022-11-04 03:05:38.468858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 03:05:38.617897: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 03:05:39.021902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 03:05:39.021954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 03:05:39.021960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/tb_runs
Files already downloaded and verified
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
Files already downloaded and verified
hello
INFO - Inserted quantizers into the original model
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_20_epoch80_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.427234   Top1 88.906250   Top5 99.257812   BatchTime 0.203568
INFO - Validation [   40/   40]   Loss 0.421873   Top1 88.880000   Top5 99.300000   BatchTime 0.132142
INFO - ==> Top1: 88.880    Top5: 99.300    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 88.880   Top5: 99.300] Sparsity : 0.892
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.076963   Top1 97.167969   Top5 100.000000   BatchTime 0.245319   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.083223   Top1 97.001953   Top5 100.000000   BatchTime 0.184464   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.081400   Top1 97.115885   Top5 99.993490   BatchTime 0.164368   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.082263   Top1 97.050781   Top5 99.995117   BatchTime 0.154360   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.085263   Top1 96.949219   Top5 99.996094   BatchTime 0.148162   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.085850   Top1 96.933594   Top5 99.993490   BatchTime 0.144131   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.086749   Top1 96.886161   Top5 99.994420   BatchTime 0.140993   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.088896   Top1 96.789551   Top5 99.995117   BatchTime 0.134367   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.090771   Top1 96.738281   Top5 99.991319   BatchTime 0.130741   LR 0.010000
INFO - ==> Top1: 96.684    Top5: 99.990    Loss: 0.092
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.401924   Top1 89.140625   Top5 99.628906   BatchTime 0.147239
INFO - Validation [0][   40/   40]   Loss 0.388427   Top1 89.290000   Top5 99.680000   BatchTime 0.101755
INFO - ==> Top1: 89.290    Top5: 99.680    Loss: 0.388
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 89.290   Top5: 99.680] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 88.880   Top5: 99.300] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.089644   Top1 97.070312   Top5 99.980469   BatchTime 0.222829   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.088608   Top1 96.943359   Top5 99.970703   BatchTime 0.173871   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.093025   Top1 96.744792   Top5 99.980469   BatchTime 0.157133   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.093140   Top1 96.767578   Top5 99.980469   BatchTime 0.148805   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.091671   Top1 96.808594   Top5 99.976562   BatchTime 0.143791   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.091902   Top1 96.741536   Top5 99.980469   BatchTime 0.141563   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.094620   Top1 96.629464   Top5 99.983259   BatchTime 0.138973   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.094156   Top1 96.633301   Top5 99.985352   BatchTime 0.137018   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.095091   Top1 96.590712   Top5 99.986979   BatchTime 0.135436   LR 0.010000
INFO - ==> Top1: 96.614    Top5: 99.988    Loss: 0.095
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.389986   Top1 89.550781   Top5 99.628906   BatchTime 0.144365
INFO - Validation [1][   40/   40]   Loss 0.386786   Top1 89.730000   Top5 99.640000   BatchTime 0.099748
INFO - ==> Top1: 89.730    Top5: 99.640    Loss: 0.387
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 89.290   Top5: 99.680] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 88.880   Top5: 99.300] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.081766   Top1 96.933594   Top5 100.000000   BatchTime 0.220208   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.087492   Top1 96.757812   Top5 100.000000   BatchTime 0.172036   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.084757   Top1 96.907552   Top5 100.000000   BatchTime 0.155857   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.088729   Top1 96.728516   Top5 100.000000   BatchTime 0.144246   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.089253   Top1 96.753906   Top5 99.992188   BatchTime 0.134588   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.090532   Top1 96.705729   Top5 99.990234   BatchTime 0.129257   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.093038   Top1 96.629464   Top5 99.988839   BatchTime 0.125434   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.093367   Top1 96.604004   Top5 99.985352   BatchTime 0.120906   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.093142   Top1 96.623264   Top5 99.986979   BatchTime 0.120473   LR 0.010000
INFO - ==> Top1: 96.626    Top5: 99.988    Loss: 0.093
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.401655   Top1 89.101562   Top5 99.414062   BatchTime 0.146038
INFO - Validation [2][   40/   40]   Loss 0.396351   Top1 89.300000   Top5 99.530000   BatchTime 0.100677
INFO - ==> Top1: 89.300    Top5: 99.530    Loss: 0.396
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 89.300   Top5: 99.530] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 89.290   Top5: 99.680] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.076090   Top1 97.070312   Top5 100.000000   BatchTime 0.220677   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.082310   Top1 96.933594   Top5 100.000000   BatchTime 0.172162   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.085654   Top1 96.959635   Top5 100.000000   BatchTime 0.156104   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.089006   Top1 96.850586   Top5 99.990234   BatchTime 0.147952   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.090843   Top1 96.785156   Top5 99.992188   BatchTime 0.143245   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.091360   Top1 96.754557   Top5 99.993490   BatchTime 0.139970   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.091633   Top1 96.727121   Top5 99.994420   BatchTime 0.137610   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.091355   Top1 96.735840   Top5 99.995117   BatchTime 0.135783   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.092352   Top1 96.684028   Top5 99.993490   BatchTime 0.134401   LR 0.010000
INFO - ==> Top1: 96.678    Top5: 99.992    Loss: 0.092
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.402380   Top1 89.824219   Top5 99.550781   BatchTime 0.145908
INFO - Validation [3][   40/   40]   Loss 0.399379   Top1 89.730000   Top5 99.640000   BatchTime 0.100645
INFO - ==> Top1: 89.730    Top5: 99.640    Loss: 0.399
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 89.300   Top5: 99.530] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.090919   Top1 96.875000   Top5 99.960938   BatchTime 0.208057   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.084385   Top1 97.070312   Top5 99.980469   BatchTime 0.152040   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.085833   Top1 97.024740   Top5 99.980469   BatchTime 0.135706   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.087379   Top1 96.982422   Top5 99.985352   BatchTime 0.127451   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.086951   Top1 96.996094   Top5 99.988281   BatchTime 0.120500   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.087046   Top1 97.008464   Top5 99.983724   BatchTime 0.120073   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.087217   Top1 96.981027   Top5 99.986049   BatchTime 0.120582   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.087785   Top1 96.889648   Top5 99.987793   BatchTime 0.120881   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.087970   Top1 96.901042   Top5 99.989149   BatchTime 0.121148   LR 0.010000
INFO - ==> Top1: 96.922    Top5: 99.986    Loss: 0.087
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.386903   Top1 89.804688   Top5 99.648438   BatchTime 0.143866
INFO - Validation [4][   40/   40]   Loss 0.391297   Top1 89.730000   Top5 99.620000   BatchTime 0.098783
INFO - ==> Top1: 89.730    Top5: 99.620    Loss: 0.391
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 89.730   Top5: 99.620] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.070920   Top1 97.460938   Top5 100.000000   BatchTime 0.222806   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.076056   Top1 97.373047   Top5 99.990234   BatchTime 0.173530   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.078682   Top1 97.317708   Top5 99.986979   BatchTime 0.156998   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.080538   Top1 97.285156   Top5 99.985352   BatchTime 0.148726   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.081126   Top1 97.218750   Top5 99.988281   BatchTime 0.143795   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.082095   Top1 97.161458   Top5 99.990234   BatchTime 0.140176   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.083232   Top1 97.098214   Top5 99.986049   BatchTime 0.138688   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.082983   Top1 97.067871   Top5 99.987793   BatchTime 0.136744   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.084193   Top1 97.018229   Top5 99.984809   BatchTime 0.135207   LR 0.010000
INFO - ==> Top1: 96.984    Top5: 99.984    Loss: 0.085
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.388876   Top1 90.097656   Top5 99.628906   BatchTime 0.135756
INFO - Validation [5][   40/   40]   Loss 0.386485   Top1 89.920000   Top5 99.710000   BatchTime 0.084973
INFO - ==> Top1: 89.920    Top5: 99.710    Loss: 0.386
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.082007   Top1 96.855469   Top5 100.000000   BatchTime 0.202032   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.081352   Top1 96.904297   Top5 100.000000   BatchTime 0.146725   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.083207   Top1 96.940104   Top5 99.993490   BatchTime 0.139396   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.081352   Top1 96.997070   Top5 99.995117   BatchTime 0.135542   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.082831   Top1 96.988281   Top5 99.988281   BatchTime 0.133100   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.084766   Top1 96.927083   Top5 99.990234   BatchTime 0.131465   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.085398   Top1 96.941964   Top5 99.988839   BatchTime 0.130329   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.085058   Top1 96.972656   Top5 99.990234   BatchTime 0.129461   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.085457   Top1 96.931424   Top5 99.991319   BatchTime 0.128774   LR 0.010000
INFO - ==> Top1: 96.930    Top5: 99.992    Loss: 0.086
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.405752   Top1 89.648438   Top5 99.570312   BatchTime 0.143615
INFO - Validation [6][   40/   40]   Loss 0.397239   Top1 89.620000   Top5 99.640000   BatchTime 0.099076
INFO - ==> Top1: 89.620    Top5: 99.640    Loss: 0.397
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.081672   Top1 97.265625   Top5 100.000000   BatchTime 0.220720   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.082655   Top1 97.148438   Top5 99.990234   BatchTime 0.172012   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.080900   Top1 97.161458   Top5 99.993490   BatchTime 0.155918   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.080542   Top1 97.114258   Top5 99.995117   BatchTime 0.147971   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.080788   Top1 97.156250   Top5 99.996094   BatchTime 0.143219   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.081114   Top1 97.115885   Top5 99.990234   BatchTime 0.139927   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.082184   Top1 97.061942   Top5 99.991629   BatchTime 0.137570   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.082662   Top1 97.058105   Top5 99.985352   BatchTime 0.135665   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.082245   Top1 97.039931   Top5 99.986979   BatchTime 0.131175   LR 0.010000
INFO - ==> Top1: 97.028    Top5: 99.988    Loss: 0.083
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.395968   Top1 89.941406   Top5 99.609375   BatchTime 0.128331
INFO - Validation [7][   40/   40]   Loss 0.396742   Top1 89.930000   Top5 99.720000   BatchTime 0.081308
INFO - ==> Top1: 89.930    Top5: 99.720    Loss: 0.397
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.072513   Top1 97.324219   Top5 99.980469   BatchTime 0.220641   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.076117   Top1 97.255859   Top5 99.990234   BatchTime 0.172160   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.078174   Top1 97.161458   Top5 99.993490   BatchTime 0.155911   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.079005   Top1 97.153320   Top5 99.990234   BatchTime 0.147897   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.079894   Top1 97.156250   Top5 99.992188   BatchTime 0.143016   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.079831   Top1 97.151693   Top5 99.993490   BatchTime 0.139818   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.080266   Top1 97.145647   Top5 99.994420   BatchTime 0.137486   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.080695   Top1 97.150879   Top5 99.992676   BatchTime 0.135675   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.080786   Top1 97.126736   Top5 99.989149   BatchTime 0.134266   LR 0.010000
INFO - ==> Top1: 97.142    Top5: 99.988    Loss: 0.081
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.399601   Top1 89.531250   Top5 99.531250   BatchTime 0.144096
INFO - Validation [8][   40/   40]   Loss 0.396642   Top1 89.600000   Top5 99.570000   BatchTime 0.099362
INFO - ==> Top1: 89.600    Top5: 99.570    Loss: 0.397
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.073254   Top1 97.539062   Top5 99.980469   BatchTime 0.220808   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.074736   Top1 97.353516   Top5 99.990234   BatchTime 0.169951   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.076111   Top1 97.350260   Top5 99.986979   BatchTime 0.154457   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.076319   Top1 97.368164   Top5 99.990234   BatchTime 0.146745   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.076461   Top1 97.351562   Top5 99.992188   BatchTime 0.142060   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.075687   Top1 97.373047   Top5 99.993490   BatchTime 0.133221   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.075750   Top1 97.366071   Top5 99.994420   BatchTime 0.129775   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.076790   Top1 97.312012   Top5 99.992676   BatchTime 0.126102   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.076801   Top1 97.337240   Top5 99.993490   BatchTime 0.122958   LR 0.010000
INFO - ==> Top1: 97.316    Top5: 99.990    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.397051   Top1 89.843750   Top5 99.667969   BatchTime 0.143767
INFO - Validation [9][   40/   40]   Loss 0.389503   Top1 89.910000   Top5 99.680000   BatchTime 0.099193
INFO - ==> Top1: 89.910    Top5: 99.680    Loss: 0.390
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.910   Top5: 99.680] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.065667   Top1 97.617188   Top5 100.000000   BatchTime 0.219233   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.069110   Top1 97.568359   Top5 100.000000   BatchTime 0.171563   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.071744   Top1 97.467448   Top5 99.993490   BatchTime 0.155611   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.073637   Top1 97.397461   Top5 99.995117   BatchTime 0.147595   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.074608   Top1 97.367188   Top5 99.992188   BatchTime 0.143038   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.075447   Top1 97.356771   Top5 99.993490   BatchTime 0.139845   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.076284   Top1 97.329799   Top5 99.988839   BatchTime 0.137521   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.076843   Top1 97.292480   Top5 99.990234   BatchTime 0.135718   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.078202   Top1 97.217882   Top5 99.989149   BatchTime 0.134329   LR 0.010000
INFO - ==> Top1: 97.216    Top5: 99.990    Loss: 0.078
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.402299   Top1 89.628906   Top5 99.628906   BatchTime 0.143951
INFO - Validation [10][   40/   40]   Loss 0.400620   Top1 89.750000   Top5 99.680000   BatchTime 0.099625
INFO - ==> Top1: 89.750    Top5: 99.680    Loss: 0.401
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.910   Top5: 99.680] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.066755   Top1 97.656250   Top5 100.000000   BatchTime 0.219419   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.067706   Top1 97.714844   Top5 100.000000   BatchTime 0.171116   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.068806   Top1 97.688802   Top5 100.000000   BatchTime 0.143662   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.071558   Top1 97.563477   Top5 99.995117   BatchTime 0.133719   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.073088   Top1 97.445312   Top5 99.996094   BatchTime 0.127319   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.074202   Top1 97.373047   Top5 99.996745   BatchTime 0.123343   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.074322   Top1 97.382812   Top5 99.997210   BatchTime 0.119973   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.074252   Top1 97.365723   Top5 99.997559   BatchTime 0.120414   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.075538   Top1 97.324219   Top5 99.997830   BatchTime 0.120756   LR 0.010000
INFO - ==> Top1: 97.322    Top5: 99.998    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.411556   Top1 89.667969   Top5 99.628906   BatchTime 0.144187
INFO - Validation [11][   40/   40]   Loss 0.403545   Top1 89.780000   Top5 99.640000   BatchTime 0.099702
INFO - ==> Top1: 89.780    Top5: 99.640    Loss: 0.404
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 89.910   Top5: 99.680] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.080934   Top1 97.343750   Top5 99.960938   BatchTime 0.219355   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.075122   Top1 97.539062   Top5 99.980469   BatchTime 0.171564   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.075897   Top1 97.421875   Top5 99.986979   BatchTime 0.155808   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.076084   Top1 97.407227   Top5 99.980469   BatchTime 0.147784   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.076086   Top1 97.335938   Top5 99.984375   BatchTime 0.142983   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.077101   Top1 97.249349   Top5 99.986979   BatchTime 0.139852   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.078164   Top1 97.204241   Top5 99.988839   BatchTime 0.137482   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.077619   Top1 97.250977   Top5 99.990234   BatchTime 0.135668   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.076350   Top1 97.296007   Top5 99.991319   BatchTime 0.134292   LR 0.010000
INFO - ==> Top1: 97.306    Top5: 99.992    Loss: 0.076
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.414053   Top1 89.941406   Top5 99.570312   BatchTime 0.142676
INFO - Validation [12][   40/   40]   Loss 0.395072   Top1 90.090000   Top5 99.640000   BatchTime 0.099722
INFO - ==> Top1: 90.090    Top5: 99.640    Loss: 0.395
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.066754   Top1 97.558594   Top5 100.000000   BatchTime 0.209939   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.070907   Top1 97.509766   Top5 99.990234   BatchTime 0.155669   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.073822   Top1 97.363281   Top5 99.993490   BatchTime 0.137328   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.072962   Top1 97.416992   Top5 99.995117   BatchTime 0.127243   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.073101   Top1 97.371094   Top5 99.996094   BatchTime 0.126555   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.072850   Top1 97.373047   Top5 99.993490   BatchTime 0.126957   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.072351   Top1 97.388393   Top5 99.991629   BatchTime 0.126530   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.072153   Top1 97.382812   Top5 99.990234   BatchTime 0.126158   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.071943   Top1 97.384983   Top5 99.991319   BatchTime 0.125811   LR 0.010000
INFO - ==> Top1: 97.382    Top5: 99.992    Loss: 0.072
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.409129   Top1 89.648438   Top5 99.707031   BatchTime 0.143088
INFO - Validation [13][   40/   40]   Loss 0.400637   Top1 89.850000   Top5 99.690000   BatchTime 0.099684
INFO - ==> Top1: 89.850    Top5: 99.690    Loss: 0.401
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.060100   Top1 97.929688   Top5 99.980469   BatchTime 0.220244   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.063611   Top1 97.910156   Top5 99.990234   BatchTime 0.171932   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.068476   Top1 97.675781   Top5 99.993490   BatchTime 0.155885   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.068752   Top1 97.700195   Top5 99.995117   BatchTime 0.147818   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.068396   Top1 97.703125   Top5 99.996094   BatchTime 0.142936   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.068792   Top1 97.646484   Top5 99.996745   BatchTime 0.139779   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.069890   Top1 97.547433   Top5 99.994420   BatchTime 0.137334   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.070708   Top1 97.502441   Top5 99.992676   BatchTime 0.135528   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.071358   Top1 97.447917   Top5 99.993490   BatchTime 0.134102   LR 0.010000
INFO - ==> Top1: 97.434    Top5: 99.992    Loss: 0.072
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.412530   Top1 89.648438   Top5 99.589844   BatchTime 0.141688
INFO - Validation [14][   40/   40]   Loss 0.405428   Top1 89.720000   Top5 99.660000   BatchTime 0.092064
INFO - ==> Top1: 89.720    Top5: 99.660    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.065279   Top1 97.539062   Top5 99.980469   BatchTime 0.211183   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.067893   Top1 97.558594   Top5 99.990234   BatchTime 0.167735   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.069549   Top1 97.513021   Top5 99.986979   BatchTime 0.152983   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.069619   Top1 97.519531   Top5 99.990234   BatchTime 0.145718   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.070639   Top1 97.476562   Top5 99.992188   BatchTime 0.141394   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.071363   Top1 97.444661   Top5 99.990234   BatchTime 0.138511   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.072063   Top1 97.421875   Top5 99.991629   BatchTime 0.136357   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.072851   Top1 97.392578   Top5 99.992676   BatchTime 0.134684   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.073086   Top1 97.374132   Top5 99.993490   BatchTime 0.133412   LR 0.010000
INFO - ==> Top1: 97.366    Top5: 99.994    Loss: 0.073
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.423537   Top1 89.765625   Top5 99.570312   BatchTime 0.144516
INFO - Validation [15][   40/   40]   Loss 0.407148   Top1 89.910000   Top5 99.660000   BatchTime 0.099731
INFO - ==> Top1: 89.910    Top5: 99.660    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.072957   Top1 97.519531   Top5 100.000000   BatchTime 0.221082   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.073778   Top1 97.421875   Top5 99.980469   BatchTime 0.172363   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.073388   Top1 97.421875   Top5 99.986979   BatchTime 0.156116   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.072434   Top1 97.465820   Top5 99.990234   BatchTime 0.148008   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.071583   Top1 97.496094   Top5 99.992188   BatchTime 0.143058   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.070395   Top1 97.558594   Top5 99.993490   BatchTime 0.139727   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.071023   Top1 97.511161   Top5 99.991629   BatchTime 0.135482   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.071581   Top1 97.463379   Top5 99.990234   BatchTime 0.130220   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.071468   Top1 97.465278   Top5 99.991319   BatchTime 0.126902   LR 0.010000
INFO - ==> Top1: 97.414    Top5: 99.992    Loss: 0.072
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.421756   Top1 89.667969   Top5 99.589844   BatchTime 0.142480
INFO - Validation [16][   40/   40]   Loss 0.405434   Top1 89.930000   Top5 99.640000   BatchTime 0.098870
INFO - ==> Top1: 89.930    Top5: 99.640    Loss: 0.405
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 89.930   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.073140   Top1 97.285156   Top5 100.000000   BatchTime 0.220775   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.070598   Top1 97.314453   Top5 100.000000   BatchTime 0.171016   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.070945   Top1 97.265625   Top5 100.000000   BatchTime 0.155128   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.072047   Top1 97.285156   Top5 100.000000   BatchTime 0.147347   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.071117   Top1 97.386719   Top5 100.000000   BatchTime 0.142614   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.071669   Top1 97.376302   Top5 100.000000   BatchTime 0.139446   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.071087   Top1 97.444196   Top5 100.000000   BatchTime 0.137153   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.070441   Top1 97.456055   Top5 100.000000   BatchTime 0.135430   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.070090   Top1 97.491319   Top5 100.000000   BatchTime 0.134133   LR 0.010000
INFO - ==> Top1: 97.494    Top5: 100.000    Loss: 0.070
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.414587   Top1 89.785156   Top5 99.570312   BatchTime 0.143762
INFO - Validation [17][   40/   40]   Loss 0.408457   Top1 89.820000   Top5 99.610000   BatchTime 0.099871
INFO - ==> Top1: 89.820    Top5: 99.610    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 89.930   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.063254   Top1 97.812500   Top5 100.000000   BatchTime 0.220318   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.064494   Top1 97.724609   Top5 100.000000   BatchTime 0.171930   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.063245   Top1 97.760417   Top5 100.000000   BatchTime 0.155681   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.065539   Top1 97.636719   Top5 100.000000   BatchTime 0.147383   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.066408   Top1 97.613281   Top5 99.996094   BatchTime 0.135995   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.067936   Top1 97.548828   Top5 99.990234   BatchTime 0.130616   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.068214   Top1 97.541853   Top5 99.991629   BatchTime 0.126498   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.068238   Top1 97.551270   Top5 99.992676   BatchTime 0.122934   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.068597   Top1 97.534722   Top5 99.993490   BatchTime 0.120823   LR 0.010000
INFO - ==> Top1: 97.526    Top5: 99.994    Loss: 0.069
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.402839   Top1 89.785156   Top5 99.726562   BatchTime 0.142658
INFO - Validation [18][   40/   40]   Loss 0.398942   Top1 90.030000   Top5 99.720000   BatchTime 0.098966
INFO - ==> Top1: 90.030    Top5: 99.720    Loss: 0.399
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.066703   Top1 97.734375   Top5 99.980469   BatchTime 0.219293   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.064508   Top1 97.714844   Top5 99.990234   BatchTime 0.171178   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.065353   Top1 97.669271   Top5 99.986979   BatchTime 0.155131   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.063963   Top1 97.773438   Top5 99.990234   BatchTime 0.147375   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.063932   Top1 97.781250   Top5 99.992188   BatchTime 0.142524   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.065024   Top1 97.766927   Top5 99.990234   BatchTime 0.139364   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.065050   Top1 97.773438   Top5 99.991629   BatchTime 0.137082   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.065139   Top1 97.775879   Top5 99.992676   BatchTime 0.135290   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.065531   Top1 97.753906   Top5 99.993490   BatchTime 0.133903   LR 0.010000
INFO - ==> Top1: 97.722    Top5: 99.992    Loss: 0.066
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.455195   Top1 89.218750   Top5 99.492188   BatchTime 0.143195
INFO - Validation [19][   40/   40]   Loss 0.426278   Top1 89.570000   Top5 99.600000   BatchTime 0.099556
INFO - ==> Top1: 89.570    Top5: 99.600    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.068440   Top1 97.500000   Top5 99.980469   BatchTime 0.218150   LR 0.010000
INFO - Training [20][   40/  196]   Loss 0.066276   Top1 97.519531   Top5 99.990234   BatchTime 0.156479   LR 0.010000
INFO - Training [20][   60/  196]   Loss 0.069017   Top1 97.460938   Top5 99.993490   BatchTime 0.138288   LR 0.010000
INFO - Training [20][   80/  196]   Loss 0.068920   Top1 97.495117   Top5 99.995117   BatchTime 0.129281   LR 0.010000
INFO - Training [20][  100/  196]   Loss 0.068440   Top1 97.539062   Top5 99.996094   BatchTime 0.124161   LR 0.010000
INFO - Training [20][  120/  196]   Loss 0.068061   Top1 97.561849   Top5 99.996745   BatchTime 0.119886   LR 0.010000
INFO - Training [20][  140/  196]   Loss 0.068688   Top1 97.519531   Top5 99.994420   BatchTime 0.120528   LR 0.010000
INFO - Training [20][  160/  196]   Loss 0.067904   Top1 97.563477   Top5 99.995117   BatchTime 0.120827   LR 0.010000
INFO - Training [20][  180/  196]   Loss 0.068424   Top1 97.526042   Top5 99.995660   BatchTime 0.121050   LR 0.010000
INFO - ==> Top1: 97.514    Top5: 99.996    Loss: 0.069
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.426163   Top1 89.804688   Top5 99.609375   BatchTime 0.145492
INFO - Validation [20][   40/   40]   Loss 0.411114   Top1 89.960000   Top5 99.650000   BatchTime 0.101190
INFO - ==> Top1: 89.960    Top5: 99.650    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.056221   Top1 97.968750   Top5 100.000000   BatchTime 0.219879   LR 0.010000
INFO - Training [21][   40/  196]   Loss 0.061213   Top1 97.880859   Top5 100.000000   BatchTime 0.172126   LR 0.010000
INFO - Training [21][   60/  196]   Loss 0.065377   Top1 97.695312   Top5 99.993490   BatchTime 0.155886   LR 0.010000
INFO - Training [21][   80/  196]   Loss 0.066114   Top1 97.636719   Top5 99.995117   BatchTime 0.147730   LR 0.010000
INFO - Training [21][  100/  196]   Loss 0.065793   Top1 97.652344   Top5 99.996094   BatchTime 0.142743   LR 0.010000
INFO - Training [21][  120/  196]   Loss 0.065019   Top1 97.698568   Top5 99.996745   BatchTime 0.139544   LR 0.010000
INFO - Training [21][  140/  196]   Loss 0.064038   Top1 97.728795   Top5 99.997210   BatchTime 0.137165   LR 0.010000
INFO - Training [21][  160/  196]   Loss 0.064122   Top1 97.739258   Top5 99.997559   BatchTime 0.135429   LR 0.010000
INFO - Training [21][  180/  196]   Loss 0.064408   Top1 97.719184   Top5 99.995660   BatchTime 0.134011   LR 0.010000
INFO - ==> Top1: 97.720    Top5: 99.996    Loss: 0.065
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.420133   Top1 89.667969   Top5 99.726562   BatchTime 0.143741
INFO - Validation [21][   40/   40]   Loss 0.406379   Top1 89.870000   Top5 99.730000   BatchTime 0.093326
INFO - ==> Top1: 89.870    Top5: 99.730    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.056018   Top1 97.910156   Top5 100.000000   BatchTime 0.202049   LR 0.010000
INFO - Training [22][   40/  196]   Loss 0.057177   Top1 97.900391   Top5 100.000000   BatchTime 0.152016   LR 0.010000
INFO - Training [22][   60/  196]   Loss 0.058288   Top1 97.955729   Top5 100.000000   BatchTime 0.135696   LR 0.010000
INFO - Training [22][   80/  196]   Loss 0.059909   Top1 97.841797   Top5 100.000000   BatchTime 0.132681   LR 0.010000
INFO - Training [22][  100/  196]   Loss 0.061113   Top1 97.792969   Top5 99.996094   BatchTime 0.130804   LR 0.010000
INFO - Training [22][  120/  196]   Loss 0.060816   Top1 97.822266   Top5 99.993490   BatchTime 0.129600   LR 0.010000
INFO - Training [22][  140/  196]   Loss 0.061146   Top1 97.829241   Top5 99.994420   BatchTime 0.128704   LR 0.010000
INFO - Training [22][  160/  196]   Loss 0.061524   Top1 97.824707   Top5 99.995117   BatchTime 0.127954   LR 0.010000
INFO - Training [22][  180/  196]   Loss 0.061930   Top1 97.816840   Top5 99.995660   BatchTime 0.127375   LR 0.010000
INFO - ==> Top1: 97.752    Top5: 99.996    Loss: 0.064
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.428081   Top1 89.472656   Top5 99.589844   BatchTime 0.142183
INFO - Validation [22][   40/   40]   Loss 0.410041   Top1 89.810000   Top5 99.680000   BatchTime 0.098351
INFO - ==> Top1: 89.810    Top5: 99.680    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.064665   Top1 97.792969   Top5 99.980469   BatchTime 0.219723   LR 0.010000
INFO - Training [23][   40/  196]   Loss 0.064138   Top1 97.871094   Top5 99.990234   BatchTime 0.171760   LR 0.010000
INFO - Training [23][   60/  196]   Loss 0.061850   Top1 97.890625   Top5 99.993490   BatchTime 0.155714   LR 0.010000
INFO - Training [23][   80/  196]   Loss 0.063306   Top1 97.788086   Top5 99.990234   BatchTime 0.147738   LR 0.010000
INFO - Training [23][  100/  196]   Loss 0.065097   Top1 97.660156   Top5 99.992188   BatchTime 0.142880   LR 0.010000
INFO - Training [23][  120/  196]   Loss 0.064483   Top1 97.666016   Top5 99.993490   BatchTime 0.139723   LR 0.010000
INFO - Training [23][  140/  196]   Loss 0.064692   Top1 97.650670   Top5 99.994420   BatchTime 0.137372   LR 0.010000
INFO - Training [23][  160/  196]   Loss 0.063876   Top1 97.700195   Top5 99.995117   BatchTime 0.135565   LR 0.010000
INFO - Training [23][  180/  196]   Loss 0.064144   Top1 97.690972   Top5 99.995660   BatchTime 0.133195   LR 0.010000
INFO - ==> Top1: 97.672    Top5: 99.996    Loss: 0.064
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.437174   Top1 89.511719   Top5 99.628906   BatchTime 0.130298
INFO - Validation [23][   40/   40]   Loss 0.414496   Top1 89.690000   Top5 99.640000   BatchTime 0.082233
INFO - ==> Top1: 89.690    Top5: 99.640    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.060908   Top1 97.812500   Top5 100.000000   BatchTime 0.227312   LR 0.010000
INFO - Training [24][   40/  196]   Loss 0.058685   Top1 97.919922   Top5 100.000000   BatchTime 0.176189   LR 0.010000
INFO - Training [24][   60/  196]   Loss 0.059720   Top1 97.916667   Top5 100.000000   BatchTime 0.158606   LR 0.010000
INFO - Training [24][   80/  196]   Loss 0.058762   Top1 97.939453   Top5 100.000000   BatchTime 0.149849   LR 0.010000
INFO - Training [24][  100/  196]   Loss 0.060288   Top1 97.878906   Top5 100.000000   BatchTime 0.144732   LR 0.010000
INFO - Training [24][  120/  196]   Loss 0.060532   Top1 97.851562   Top5 99.996745   BatchTime 0.141276   LR 0.010000
INFO - Training [24][  140/  196]   Loss 0.060222   Top1 97.862723   Top5 99.997210   BatchTime 0.138741   LR 0.010000
INFO - Training [24][  160/  196]   Loss 0.059964   Top1 97.875977   Top5 99.997559   BatchTime 0.136814   LR 0.010000
INFO - Training [24][  180/  196]   Loss 0.060194   Top1 97.875434   Top5 99.997830   BatchTime 0.135097   LR 0.010000
INFO - ==> Top1: 97.874    Top5: 99.998    Loss: 0.060
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.417285   Top1 90.058594   Top5 99.628906   BatchTime 0.143485
INFO - Validation [24][   40/   40]   Loss 0.406834   Top1 89.990000   Top5 99.640000   BatchTime 0.099074
INFO - ==> Top1: 89.990    Top5: 99.640    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.059390   Top1 98.046875   Top5 100.000000   BatchTime 0.220050   LR 0.010000
INFO - Training [25][   40/  196]   Loss 0.058792   Top1 98.037109   Top5 100.000000   BatchTime 0.171944   LR 0.010000
INFO - Training [25][   60/  196]   Loss 0.058380   Top1 98.053385   Top5 99.993490   BatchTime 0.155665   LR 0.010000
INFO - Training [25][   80/  196]   Loss 0.058401   Top1 98.061523   Top5 99.995117   BatchTime 0.147434   LR 0.010000
INFO - Training [25][  100/  196]   Loss 0.058842   Top1 98.015625   Top5 99.996094   BatchTime 0.142520   LR 0.010000
INFO - Training [25][  120/  196]   Loss 0.059417   Top1 97.978516   Top5 99.996745   BatchTime 0.136322   LR 0.010000
INFO - Training [25][  140/  196]   Loss 0.059140   Top1 97.960379   Top5 99.997210   BatchTime 0.130644   LR 0.010000
INFO - Training [25][  160/  196]   Loss 0.059538   Top1 97.929688   Top5 99.997559   BatchTime 0.126835   LR 0.010000
INFO - Training [25][  180/  196]   Loss 0.060028   Top1 97.899306   Top5 99.997830   BatchTime 0.123866   LR 0.010000
INFO - ==> Top1: 97.882    Top5: 99.998    Loss: 0.061
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.424810   Top1 89.785156   Top5 99.609375   BatchTime 0.148293
INFO - Validation [25][   40/   40]   Loss 0.412109   Top1 89.950000   Top5 99.630000   BatchTime 0.102263
INFO - ==> Top1: 89.950    Top5: 99.630    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.053987   Top1 98.066406   Top5 100.000000   BatchTime 0.220679   LR 0.010000
INFO - Training [26][   40/  196]   Loss 0.057193   Top1 97.900391   Top5 100.000000   BatchTime 0.172266   LR 0.010000
INFO - Training [26][   60/  196]   Loss 0.056624   Top1 97.936198   Top5 99.986979   BatchTime 0.156268   LR 0.010000
INFO - Training [26][   80/  196]   Loss 0.059507   Top1 97.783203   Top5 99.985352   BatchTime 0.148169   LR 0.010000
INFO - Training [26][  100/  196]   Loss 0.059979   Top1 97.781250   Top5 99.988281   BatchTime 0.144249   LR 0.010000
INFO - Training [26][  120/  196]   Loss 0.060862   Top1 97.776693   Top5 99.990234   BatchTime 0.140749   LR 0.010000
INFO - Training [26][  140/  196]   Loss 0.060948   Top1 97.804129   Top5 99.991629   BatchTime 0.138312   LR 0.010000
INFO - Training [26][  160/  196]   Loss 0.060864   Top1 97.790527   Top5 99.992676   BatchTime 0.136368   LR 0.010000
INFO - Training [26][  180/  196]   Loss 0.062478   Top1 97.719184   Top5 99.993490   BatchTime 0.134833   LR 0.010000
INFO - ==> Top1: 97.698    Top5: 99.994    Loss: 0.063
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.423916   Top1 89.453125   Top5 99.531250   BatchTime 0.143723
INFO - Validation [26][   40/   40]   Loss 0.420057   Top1 89.640000   Top5 99.570000   BatchTime 0.099296
INFO - ==> Top1: 89.640    Top5: 99.570    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.062545   Top1 97.675781   Top5 100.000000   BatchTime 0.219330   LR 0.010000
INFO - Training [27][   40/  196]   Loss 0.058296   Top1 97.910156   Top5 100.000000   BatchTime 0.171150   LR 0.010000
INFO - Training [27][   60/  196]   Loss 0.060039   Top1 97.858073   Top5 100.000000   BatchTime 0.154280   LR 0.010000
INFO - Training [27][   80/  196]   Loss 0.060697   Top1 97.875977   Top5 100.000000   BatchTime 0.137834   LR 0.010000
INFO - Training [27][  100/  196]   Loss 0.060110   Top1 97.851562   Top5 100.000000   BatchTime 0.130657   LR 0.010000
INFO - Training [27][  120/  196]   Loss 0.060935   Top1 97.828776   Top5 100.000000   BatchTime 0.125712   LR 0.010000
INFO - Training [27][  140/  196]   Loss 0.060973   Top1 97.826451   Top5 100.000000   BatchTime 0.121498   LR 0.010000
INFO - Training [27][  160/  196]   Loss 0.061907   Top1 97.792969   Top5 99.995117   BatchTime 0.118690   LR 0.010000
INFO - Training [27][  180/  196]   Loss 0.061483   Top1 97.808160   Top5 99.995660   BatchTime 0.119188   LR 0.010000
INFO - ==> Top1: 97.796    Top5: 99.996    Loss: 0.062
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.450972   Top1 89.492188   Top5 99.609375   BatchTime 0.145653
INFO - Validation [27][   40/   40]   Loss 0.427793   Top1 89.870000   Top5 99.660000   BatchTime 0.100426
INFO - ==> Top1: 89.870    Top5: 99.660    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.059305   Top1 97.753906   Top5 100.000000   BatchTime 0.220018   LR 0.010000
INFO - Training [28][   40/  196]   Loss 0.057830   Top1 97.890625   Top5 100.000000   BatchTime 0.171815   LR 0.010000
INFO - Training [28][   60/  196]   Loss 0.057304   Top1 97.884115   Top5 100.000000   BatchTime 0.155628   LR 0.010000
INFO - Training [28][   80/  196]   Loss 0.057542   Top1 97.890625   Top5 100.000000   BatchTime 0.147504   LR 0.010000
INFO - Training [28][  100/  196]   Loss 0.057349   Top1 97.945312   Top5 100.000000   BatchTime 0.142817   LR 0.010000
INFO - Training [28][  120/  196]   Loss 0.057434   Top1 97.939453   Top5 99.996745   BatchTime 0.139300   LR 0.010000
INFO - Training [28][  140/  196]   Loss 0.057864   Top1 97.887835   Top5 99.997210   BatchTime 0.137046   LR 0.010000
INFO - Training [28][  160/  196]   Loss 0.058549   Top1 97.875977   Top5 99.997559   BatchTime 0.135238   LR 0.010000
INFO - Training [28][  180/  196]   Loss 0.059209   Top1 97.829861   Top5 99.997830   BatchTime 0.133880   LR 0.010000
INFO - ==> Top1: 97.788    Top5: 99.998    Loss: 0.060
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.453962   Top1 89.531250   Top5 99.628906   BatchTime 0.145297
INFO - Validation [28][   40/   40]   Loss 0.431439   Top1 89.720000   Top5 99.700000   BatchTime 0.100767
INFO - ==> Top1: 89.720    Top5: 99.700    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.050679   Top1 98.203125   Top5 100.000000   BatchTime 0.192034   LR 0.010000
INFO - Training [29][   40/  196]   Loss 0.052193   Top1 98.125000   Top5 100.000000   BatchTime 0.146632   LR 0.010000
INFO - Training [29][   60/  196]   Loss 0.052748   Top1 98.125000   Top5 100.000000   BatchTime 0.132135   LR 0.010000
INFO - Training [29][   80/  196]   Loss 0.054038   Top1 98.032227   Top5 100.000000   BatchTime 0.124652   LR 0.010000
INFO - Training [29][  100/  196]   Loss 0.055197   Top1 97.992188   Top5 99.996094   BatchTime 0.118385   LR 0.010000
INFO - Training [29][  120/  196]   Loss 0.055933   Top1 97.962240   Top5 99.993490   BatchTime 0.119183   LR 0.010000
INFO - Training [29][  140/  196]   Loss 0.055964   Top1 97.968750   Top5 99.988839   BatchTime 0.119781   LR 0.010000
INFO - Training [29][  160/  196]   Loss 0.055872   Top1 97.983398   Top5 99.990234   BatchTime 0.120199   LR 0.010000
INFO - Training [29][  180/  196]   Loss 0.056293   Top1 97.977431   Top5 99.991319   BatchTime 0.120492   LR 0.010000
INFO - ==> Top1: 97.970    Top5: 99.990    Loss: 0.057
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.461514   Top1 89.511719   Top5 99.550781   BatchTime 0.144141
INFO - Validation [29][   40/   40]   Loss 0.442576   Top1 89.740000   Top5 99.620000   BatchTime 0.099516
INFO - ==> Top1: 89.740    Top5: 99.620    Loss: 0.443
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.059238   Top1 98.066406   Top5 100.000000   BatchTime 0.219608   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.053937   Top1 98.173828   Top5 99.990234   BatchTime 0.171121   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.052449   Top1 98.248698   Top5 99.993490   BatchTime 0.155318   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.052623   Top1 98.168945   Top5 99.995117   BatchTime 0.147452   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.052886   Top1 98.140625   Top5 99.988281   BatchTime 0.142683   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.052745   Top1 98.147786   Top5 99.990234   BatchTime 0.139439   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.052230   Top1 98.144531   Top5 99.991629   BatchTime 0.137050   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.052308   Top1 98.159180   Top5 99.992676   BatchTime 0.135258   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.052916   Top1 98.142361   Top5 99.993490   BatchTime 0.134299   LR 0.001000
INFO - ==> Top1: 98.166    Top5: 99.994    Loss: 0.053
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.423754   Top1 89.902344   Top5 99.628906   BatchTime 0.130475
INFO - Validation [30][   40/   40]   Loss 0.411422   Top1 90.090000   Top5 99.680000   BatchTime 0.082369
INFO - ==> Top1: 90.090    Top5: 99.680    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 90.090   Top5: 99.680] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.050303   Top1 98.300781   Top5 100.000000   BatchTime 0.192455   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.051166   Top1 98.193359   Top5 100.000000   BatchTime 0.151502   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.050360   Top1 98.209635   Top5 100.000000   BatchTime 0.142493   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.050710   Top1 98.139648   Top5 100.000000   BatchTime 0.137746   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.051184   Top1 98.132812   Top5 100.000000   BatchTime 0.134851   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.050325   Top1 98.186849   Top5 100.000000   BatchTime 0.133023   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.049665   Top1 98.214286   Top5 100.000000   BatchTime 0.131700   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.049580   Top1 98.234863   Top5 100.000000   BatchTime 0.130607   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.049717   Top1 98.229167   Top5 100.000000   BatchTime 0.129900   LR 0.001000
INFO - ==> Top1: 98.234    Top5: 100.000    Loss: 0.049
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.419674   Top1 89.902344   Top5 99.609375   BatchTime 0.142516
INFO - Validation [31][   40/   40]   Loss 0.406517   Top1 90.160000   Top5 99.630000   BatchTime 0.100020
INFO - ==> Top1: 90.160    Top5: 99.630    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.090   Top5: 99.680] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.041048   Top1 98.476562   Top5 100.000000   BatchTime 0.219275   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.042237   Top1 98.515625   Top5 100.000000   BatchTime 0.170717   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.043724   Top1 98.457031   Top5 100.000000   BatchTime 0.154876   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.044337   Top1 98.457031   Top5 100.000000   BatchTime 0.147034   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.045031   Top1 98.429688   Top5 99.996094   BatchTime 0.142166   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.045222   Top1 98.450521   Top5 99.996745   BatchTime 0.138952   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.045821   Top1 98.404018   Top5 99.997210   BatchTime 0.136652   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.046758   Top1 98.388672   Top5 99.997559   BatchTime 0.132390   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.046925   Top1 98.398438   Top5 99.997830   BatchTime 0.128276   LR 0.001000
INFO - ==> Top1: 98.390    Top5: 99.998    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.418308   Top1 89.707031   Top5 99.707031   BatchTime 0.128451
INFO - Validation [32][   40/   40]   Loss 0.406254   Top1 90.100000   Top5 99.670000   BatchTime 0.087103
INFO - ==> Top1: 90.100    Top5: 99.670    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [32][Top1: 90.100   Top5: 99.670] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.090   Top5: 99.680] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.039259   Top1 98.710938   Top5 100.000000   BatchTime 0.221045   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.042104   Top1 98.603516   Top5 100.000000   BatchTime 0.172258   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.042349   Top1 98.619792   Top5 100.000000   BatchTime 0.155879   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.044371   Top1 98.540039   Top5 100.000000   BatchTime 0.147739   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.044472   Top1 98.507812   Top5 100.000000   BatchTime 0.142876   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.044761   Top1 98.463542   Top5 100.000000   BatchTime 0.139668   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.044607   Top1 98.473772   Top5 100.000000   BatchTime 0.137425   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.044689   Top1 98.471680   Top5 100.000000   BatchTime 0.135583   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.045721   Top1 98.428819   Top5 100.000000   BatchTime 0.134209   LR 0.001000
INFO - ==> Top1: 98.424    Top5: 100.000    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.408693   Top1 90.253906   Top5 99.667969   BatchTime 0.142540
INFO - Validation [33][   40/   40]   Loss 0.399583   Top1 90.470000   Top5 99.700000   BatchTime 0.098931
INFO - ==> Top1: 90.470    Top5: 99.700    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.100   Top5: 99.670] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.037296   Top1 98.730469   Top5 99.980469   BatchTime 0.218646   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.042600   Top1 98.593750   Top5 99.990234   BatchTime 0.170837   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.041961   Top1 98.606771   Top5 99.993490   BatchTime 0.155095   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.041470   Top1 98.623047   Top5 99.995117   BatchTime 0.147072   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.042587   Top1 98.562500   Top5 99.996094   BatchTime 0.138366   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.042989   Top1 98.531901   Top5 99.996745   BatchTime 0.131549   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.044086   Top1 98.484933   Top5 99.997210   BatchTime 0.128083   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.044347   Top1 98.454590   Top5 99.997559   BatchTime 0.125107   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.045079   Top1 98.448351   Top5 99.997830   BatchTime 0.120414   LR 0.001000
INFO - ==> Top1: 98.446    Top5: 99.998    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.424013   Top1 89.941406   Top5 99.667969   BatchTime 0.143891
INFO - Validation [34][   40/   40]   Loss 0.410851   Top1 90.170000   Top5 99.680000   BatchTime 0.099161
INFO - ==> Top1: 90.170    Top5: 99.680    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [34][Top1: 90.170   Top5: 99.680] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.037425   Top1 98.828125   Top5 100.000000   BatchTime 0.219163   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.039792   Top1 98.710938   Top5 100.000000   BatchTime 0.171548   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.042508   Top1 98.515625   Top5 100.000000   BatchTime 0.155696   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.041944   Top1 98.549805   Top5 100.000000   BatchTime 0.147903   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.042336   Top1 98.546875   Top5 99.996094   BatchTime 0.143025   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.042990   Top1 98.525391   Top5 99.996745   BatchTime 0.139730   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.043449   Top1 98.507254   Top5 99.997210   BatchTime 0.137340   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.043770   Top1 98.488770   Top5 99.992676   BatchTime 0.135526   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.043822   Top1 98.489583   Top5 99.993490   BatchTime 0.134131   LR 0.001000
INFO - ==> Top1: 98.490    Top5: 99.994    Loss: 0.044
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.413152   Top1 90.058594   Top5 99.628906   BatchTime 0.144233
INFO - Validation [35][   40/   40]   Loss 0.402102   Top1 90.320000   Top5 99.690000   BatchTime 0.099876
INFO - ==> Top1: 90.320    Top5: 99.690    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.170   Top5: 99.680] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.045218   Top1 98.320312   Top5 100.000000   BatchTime 0.220342   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.042566   Top1 98.457031   Top5 100.000000   BatchTime 0.166098   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.042857   Top1 98.509115   Top5 100.000000   BatchTime 0.142496   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.042657   Top1 98.530273   Top5 100.000000   BatchTime 0.132101   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.042230   Top1 98.527344   Top5 100.000000   BatchTime 0.126016   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.043805   Top1 98.479818   Top5 100.000000   BatchTime 0.120406   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.043571   Top1 98.493304   Top5 100.000000   BatchTime 0.119213   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.043831   Top1 98.481445   Top5 100.000000   BatchTime 0.119670   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.043794   Top1 98.472222   Top5 100.000000   BatchTime 0.120027   LR 0.001000
INFO - ==> Top1: 98.460    Top5: 100.000    Loss: 0.044
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.422426   Top1 90.078125   Top5 99.628906   BatchTime 0.143541
INFO - Validation [36][   40/   40]   Loss 0.406728   Top1 90.300000   Top5 99.650000   BatchTime 0.099081
INFO - ==> Top1: 90.300    Top5: 99.650    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.300   Top5: 99.650] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.045928   Top1 98.437500   Top5 100.000000   BatchTime 0.220391   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.043530   Top1 98.466797   Top5 100.000000   BatchTime 0.171932   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.043970   Top1 98.463542   Top5 100.000000   BatchTime 0.156035   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.044302   Top1 98.481445   Top5 100.000000   BatchTime 0.147923   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.043707   Top1 98.492188   Top5 100.000000   BatchTime 0.143052   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.043380   Top1 98.499349   Top5 100.000000   BatchTime 0.139866   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.043440   Top1 98.515625   Top5 99.997210   BatchTime 0.137479   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.044152   Top1 98.505859   Top5 99.997559   BatchTime 0.135655   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.044338   Top1 98.504774   Top5 99.997830   BatchTime 0.134217   LR 0.001000
INFO - ==> Top1: 98.472    Top5: 99.996    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.413926   Top1 90.351562   Top5 99.589844   BatchTime 0.143104
INFO - Validation [37][   40/   40]   Loss 0.402404   Top1 90.300000   Top5 99.640000   BatchTime 0.099527
INFO - ==> Top1: 90.300    Top5: 99.640    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 90.300   Top5: 99.650] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.044806   Top1 98.437500   Top5 100.000000   BatchTime 0.211523   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.045014   Top1 98.417969   Top5 100.000000   BatchTime 0.156632   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.044852   Top1 98.385417   Top5 100.000000   BatchTime 0.137857   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.045477   Top1 98.359375   Top5 100.000000   BatchTime 0.128528   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.045432   Top1 98.378906   Top5 100.000000   BatchTime 0.127617   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.045291   Top1 98.362630   Top5 100.000000   BatchTime 0.126998   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.045400   Top1 98.362165   Top5 99.997210   BatchTime 0.126446   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.045376   Top1 98.344727   Top5 99.997559   BatchTime 0.126061   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.045017   Top1 98.357205   Top5 99.997830   BatchTime 0.126474   LR 0.001000
INFO - ==> Top1: 98.388    Top5: 99.998    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.413021   Top1 90.429688   Top5 99.570312   BatchTime 0.143345
INFO - Validation [38][   40/   40]   Loss 0.403527   Top1 90.500000   Top5 99.660000   BatchTime 0.099755
INFO - ==> Top1: 90.500    Top5: 99.660    Loss: 0.404
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.038176   Top1 98.652344   Top5 100.000000   BatchTime 0.218877   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.041369   Top1 98.496094   Top5 100.000000   BatchTime 0.170832   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.042657   Top1 98.457031   Top5 100.000000   BatchTime 0.154894   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.043097   Top1 98.442383   Top5 100.000000   BatchTime 0.147238   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.043000   Top1 98.445312   Top5 100.000000   BatchTime 0.142745   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.043373   Top1 98.421224   Top5 100.000000   BatchTime 0.139531   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.043603   Top1 98.434710   Top5 100.000000   BatchTime 0.137168   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.043929   Top1 98.422852   Top5 99.997559   BatchTime 0.135341   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.044413   Top1 98.398438   Top5 99.997830   BatchTime 0.133875   LR 0.001000
INFO - ==> Top1: 98.394    Top5: 99.998    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.419078   Top1 90.097656   Top5 99.628906   BatchTime 0.136620
INFO - Validation [39][   40/   40]   Loss 0.406950   Top1 90.330000   Top5 99.670000   BatchTime 0.089623
INFO - ==> Top1: 90.330    Top5: 99.670    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.330   Top5: 99.670] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.044146   Top1 98.437500   Top5 100.000000   BatchTime 0.221194   LR 0.001000
INFO - Training [40][   40/  196]   Loss 0.044786   Top1 98.378906   Top5 100.000000   BatchTime 0.172556   LR 0.001000
INFO - Training [40][   60/  196]   Loss 0.046918   Top1 98.346354   Top5 100.000000   BatchTime 0.156270   LR 0.001000
INFO - Training [40][   80/  196]   Loss 0.045371   Top1 98.403320   Top5 100.000000   BatchTime 0.148123   LR 0.001000
INFO - Training [40][  100/  196]   Loss 0.044974   Top1 98.441406   Top5 100.000000   BatchTime 0.143277   LR 0.001000
INFO - Training [40][  120/  196]   Loss 0.044619   Top1 98.421224   Top5 100.000000   BatchTime 0.140073   LR 0.001000
INFO - Training [40][  140/  196]   Loss 0.045101   Top1 98.412388   Top5 100.000000   BatchTime 0.137676   LR 0.001000
INFO - Training [40][  160/  196]   Loss 0.044726   Top1 98.420410   Top5 100.000000   BatchTime 0.135904   LR 0.001000
INFO - Training [40][  180/  196]   Loss 0.045249   Top1 98.404948   Top5 100.000000   BatchTime 0.134450   LR 0.001000
INFO - ==> Top1: 98.402    Top5: 100.000    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.414171   Top1 90.332031   Top5 99.667969   BatchTime 0.143597
INFO - Validation [40][   40/   40]   Loss 0.403302   Top1 90.290000   Top5 99.690000   BatchTime 0.100007
INFO - ==> Top1: 90.290    Top5: 99.690    Loss: 0.403
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.330   Top5: 99.670] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.046609   Top1 98.300781   Top5 100.000000   BatchTime 0.217253   LR 0.001000
INFO - Training [41][   40/  196]   Loss 0.043243   Top1 98.457031   Top5 99.990234   BatchTime 0.170719   LR 0.001000
INFO - Training [41][   60/  196]   Loss 0.044162   Top1 98.437500   Top5 99.993490   BatchTime 0.154971   LR 0.001000
INFO - Training [41][   80/  196]   Loss 0.043109   Top1 98.496094   Top5 99.995117   BatchTime 0.147043   LR 0.001000
INFO - Training [41][  100/  196]   Loss 0.043300   Top1 98.476562   Top5 99.996094   BatchTime 0.142202   LR 0.001000
INFO - Training [41][  120/  196]   Loss 0.043456   Top1 98.492839   Top5 99.996745   BatchTime 0.138900   LR 0.001000
INFO - Training [41][  140/  196]   Loss 0.043226   Top1 98.515625   Top5 99.997210   BatchTime 0.133826   LR 0.001000
INFO - Training [41][  160/  196]   Loss 0.044047   Top1 98.491211   Top5 99.997559   BatchTime 0.129264   LR 0.001000
INFO - Training [41][  180/  196]   Loss 0.043967   Top1 98.493924   Top5 99.997830   BatchTime 0.126002   LR 0.001000
INFO - ==> Top1: 98.494    Top5: 99.998    Loss: 0.044
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.420463   Top1 90.253906   Top5 99.667969   BatchTime 0.148187
INFO - Validation [41][   40/   40]   Loss 0.408594   Top1 90.380000   Top5 99.710000   BatchTime 0.102254
INFO - ==> Top1: 90.380    Top5: 99.710    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 90.380   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.037550   Top1 98.847656   Top5 100.000000   BatchTime 0.217479   LR 0.001000
INFO - Training [42][   40/  196]   Loss 0.041227   Top1 98.554688   Top5 100.000000   BatchTime 0.170638   LR 0.001000
INFO - Training [42][   60/  196]   Loss 0.039374   Top1 98.567708   Top5 100.000000   BatchTime 0.155314   LR 0.001000
INFO - Training [42][   80/  196]   Loss 0.039482   Top1 98.549805   Top5 100.000000   BatchTime 0.147582   LR 0.001000
INFO - Training [42][  100/  196]   Loss 0.039718   Top1 98.585938   Top5 100.000000   BatchTime 0.142720   LR 0.001000
INFO - Training [42][  120/  196]   Loss 0.040595   Top1 98.570964   Top5 100.000000   BatchTime 0.139579   LR 0.001000
INFO - Training [42][  140/  196]   Loss 0.040460   Top1 98.563058   Top5 100.000000   BatchTime 0.137362   LR 0.001000
INFO - Training [42][  160/  196]   Loss 0.040588   Top1 98.574219   Top5 100.000000   BatchTime 0.135549   LR 0.001000
INFO - Training [42][  180/  196]   Loss 0.040278   Top1 98.576389   Top5 99.997830   BatchTime 0.134115   LR 0.001000
INFO - ==> Top1: 98.590    Top5: 99.998    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.405838   Top1 90.332031   Top5 99.667969   BatchTime 0.144444
INFO - Validation [42][   40/   40]   Loss 0.397913   Top1 90.660000   Top5 99.730000   BatchTime 0.099867
INFO - ==> Top1: 90.660    Top5: 99.730    Loss: 0.398
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.044915   Top1 98.437500   Top5 99.980469   BatchTime 0.216996   LR 0.001000
INFO - Training [43][   40/  196]   Loss 0.043497   Top1 98.378906   Top5 99.990234   BatchTime 0.169904   LR 0.001000
INFO - Training [43][   60/  196]   Loss 0.043631   Top1 98.391927   Top5 99.993490   BatchTime 0.154294   LR 0.001000
INFO - Training [43][   80/  196]   Loss 0.042366   Top1 98.500977   Top5 99.995117   BatchTime 0.143381   LR 0.001000
INFO - Training [43][  100/  196]   Loss 0.042612   Top1 98.503906   Top5 99.996094   BatchTime 0.133747   LR 0.001000
INFO - Training [43][  120/  196]   Loss 0.042097   Top1 98.505859   Top5 99.996745   BatchTime 0.128568   LR 0.001000
INFO - Training [43][  140/  196]   Loss 0.042151   Top1 98.518415   Top5 99.997210   BatchTime 0.124800   LR 0.001000
INFO - Training [43][  160/  196]   Loss 0.042668   Top1 98.510742   Top5 99.997559   BatchTime 0.120716   LR 0.001000
INFO - Training [43][  180/  196]   Loss 0.042687   Top1 98.500434   Top5 99.997830   BatchTime 0.119595   LR 0.001000
INFO - ==> Top1: 98.506    Top5: 99.998    Loss: 0.043
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.417792   Top1 90.214844   Top5 99.687500   BatchTime 0.143322
INFO - Validation [43][   40/   40]   Loss 0.407998   Top1 90.270000   Top5 99.720000   BatchTime 0.099305
INFO - ==> Top1: 90.270    Top5: 99.720    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.041999   Top1 98.476562   Top5 99.980469   BatchTime 0.218735   LR 0.001000
INFO - Training [44][   40/  196]   Loss 0.042433   Top1 98.427734   Top5 99.990234   BatchTime 0.171139   LR 0.001000
INFO - Training [44][   60/  196]   Loss 0.042413   Top1 98.444010   Top5 99.993490   BatchTime 0.155474   LR 0.001000
INFO - Training [44][   80/  196]   Loss 0.041986   Top1 98.486328   Top5 99.995117   BatchTime 0.147783   LR 0.001000
INFO - Training [44][  100/  196]   Loss 0.043152   Top1 98.457031   Top5 99.996094   BatchTime 0.143112   LR 0.001000
INFO - Training [44][  120/  196]   Loss 0.041827   Top1 98.505859   Top5 99.996745   BatchTime 0.139864   LR 0.001000
INFO - Training [44][  140/  196]   Loss 0.041483   Top1 98.512835   Top5 99.994420   BatchTime 0.137577   LR 0.001000
INFO - Training [44][  160/  196]   Loss 0.040977   Top1 98.525391   Top5 99.995117   BatchTime 0.135722   LR 0.001000
INFO - Training [44][  180/  196]   Loss 0.041766   Top1 98.489583   Top5 99.995660   BatchTime 0.134325   LR 0.001000
INFO - ==> Top1: 98.504    Top5: 99.996    Loss: 0.042
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.416142   Top1 90.371094   Top5 99.648438   BatchTime 0.144141
INFO - Validation [44][   40/   40]   Loss 0.402628   Top1 90.340000   Top5 99.670000   BatchTime 0.100125
INFO - ==> Top1: 90.340    Top5: 99.670    Loss: 0.403
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.037336   Top1 98.554688   Top5 100.000000   BatchTime 0.215918   LR 0.001000
INFO - Training [45][   40/  196]   Loss 0.039363   Top1 98.505859   Top5 100.000000   BatchTime 0.152070   LR 0.001000
INFO - Training [45][   60/  196]   Loss 0.040382   Top1 98.580729   Top5 100.000000   BatchTime 0.135470   LR 0.001000
INFO - Training [45][   80/  196]   Loss 0.041232   Top1 98.505859   Top5 100.000000   BatchTime 0.126964   LR 0.001000
INFO - Training [45][  100/  196]   Loss 0.041307   Top1 98.566406   Top5 100.000000   BatchTime 0.121589   LR 0.001000
INFO - Training [45][  120/  196]   Loss 0.040523   Top1 98.600260   Top5 100.000000   BatchTime 0.118874   LR 0.001000
INFO - Training [45][  140/  196]   Loss 0.039898   Top1 98.604911   Top5 100.000000   BatchTime 0.119531   LR 0.001000
INFO - Training [45][  160/  196]   Loss 0.040411   Top1 98.562012   Top5 100.000000   BatchTime 0.119961   LR 0.001000
INFO - Training [45][  180/  196]   Loss 0.040664   Top1 98.563368   Top5 100.000000   BatchTime 0.120271   LR 0.001000
INFO - ==> Top1: 98.552    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.419574   Top1 90.175781   Top5 99.628906   BatchTime 0.144510
INFO - Validation [45][   40/   40]   Loss 0.407823   Top1 90.200000   Top5 99.700000   BatchTime 0.100643
INFO - ==> Top1: 90.200    Top5: 99.700    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.038750   Top1 98.632812   Top5 100.000000   BatchTime 0.217750   LR 0.001000
INFO - Training [46][   40/  196]   Loss 0.039962   Top1 98.583984   Top5 100.000000   BatchTime 0.170677   LR 0.001000
INFO - Training [46][   60/  196]   Loss 0.040036   Top1 98.554688   Top5 100.000000   BatchTime 0.154909   LR 0.001000
INFO - Training [46][   80/  196]   Loss 0.040878   Top1 98.554688   Top5 100.000000   BatchTime 0.146956   LR 0.001000
INFO - Training [46][  100/  196]   Loss 0.040657   Top1 98.593750   Top5 100.000000   BatchTime 0.142401   LR 0.001000
INFO - Training [46][  120/  196]   Loss 0.041127   Top1 98.593750   Top5 100.000000   BatchTime 0.139168   LR 0.001000
INFO - Training [46][  140/  196]   Loss 0.040575   Top1 98.610491   Top5 99.997210   BatchTime 0.136980   LR 0.001000
INFO - Training [46][  160/  196]   Loss 0.041034   Top1 98.608398   Top5 99.997559   BatchTime 0.135145   LR 0.001000
INFO - Training [46][  180/  196]   Loss 0.040998   Top1 98.600260   Top5 99.997830   BatchTime 0.134290   LR 0.001000
INFO - ==> Top1: 98.582    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.416817   Top1 90.449219   Top5 99.687500   BatchTime 0.142208
INFO - Validation [46][   40/   40]   Loss 0.405572   Top1 90.480000   Top5 99.710000   BatchTime 0.088150
INFO - ==> Top1: 90.480    Top5: 99.710    Loss: 0.406
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.037769   Top1 98.632812   Top5 100.000000   BatchTime 0.201051   LR 0.001000
INFO - Training [47][   40/  196]   Loss 0.040358   Top1 98.701172   Top5 100.000000   BatchTime 0.149464   LR 0.001000
INFO - Training [47][   60/  196]   Loss 0.039743   Top1 98.684896   Top5 100.000000   BatchTime 0.136031   LR 0.001000
INFO - Training [47][   80/  196]   Loss 0.040216   Top1 98.623047   Top5 100.000000   BatchTime 0.133138   LR 0.001000
INFO - Training [47][  100/  196]   Loss 0.041400   Top1 98.593750   Top5 100.000000   BatchTime 0.131344   LR 0.001000
INFO - Training [47][  120/  196]   Loss 0.040070   Top1 98.649089   Top5 100.000000   BatchTime 0.130113   LR 0.001000
INFO - Training [47][  140/  196]   Loss 0.039724   Top1 98.646763   Top5 100.000000   BatchTime 0.129030   LR 0.001000
INFO - Training [47][  160/  196]   Loss 0.040248   Top1 98.637695   Top5 99.995117   BatchTime 0.128334   LR 0.001000
INFO - Training [47][  180/  196]   Loss 0.040534   Top1 98.619792   Top5 99.995660   BatchTime 0.127759   LR 0.001000
INFO - ==> Top1: 98.616    Top5: 99.996    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.423563   Top1 90.292969   Top5 99.648438   BatchTime 0.144211
INFO - Validation [47][   40/   40]   Loss 0.409820   Top1 90.460000   Top5 99.710000   BatchTime 0.099498
INFO - ==> Top1: 90.460    Top5: 99.710    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.042023   Top1 98.750000   Top5 100.000000   BatchTime 0.218283   LR 0.001000
INFO - Training [48][   40/  196]   Loss 0.038574   Top1 98.818359   Top5 100.000000   BatchTime 0.171088   LR 0.001000
INFO - Training [48][   60/  196]   Loss 0.038488   Top1 98.789062   Top5 100.000000   BatchTime 0.155173   LR 0.001000
INFO - Training [48][   80/  196]   Loss 0.037210   Top1 98.808594   Top5 100.000000   BatchTime 0.147091   LR 0.001000
INFO - Training [48][  100/  196]   Loss 0.037906   Top1 98.789062   Top5 100.000000   BatchTime 0.142327   LR 0.001000
INFO - Training [48][  120/  196]   Loss 0.037269   Top1 98.811849   Top5 100.000000   BatchTime 0.139090   LR 0.001000
INFO - Training [48][  140/  196]   Loss 0.037467   Top1 98.822545   Top5 100.000000   BatchTime 0.136897   LR 0.001000
INFO - Training [48][  160/  196]   Loss 0.037275   Top1 98.813477   Top5 100.000000   BatchTime 0.135078   LR 0.001000
INFO - Training [48][  180/  196]   Loss 0.037225   Top1 98.808594   Top5 99.997830   BatchTime 0.132583   LR 0.001000
INFO - ==> Top1: 98.792    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.422687   Top1 90.214844   Top5 99.648438   BatchTime 0.126819
INFO - Validation [48][   40/   40]   Loss 0.410798   Top1 90.260000   Top5 99.710000   BatchTime 0.080483
INFO - ==> Top1: 90.260    Top5: 99.710    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.034143   Top1 98.964844   Top5 100.000000   BatchTime 0.224732   LR 0.001000
INFO - Training [49][   40/  196]   Loss 0.037661   Top1 98.798828   Top5 99.990234   BatchTime 0.174351   LR 0.001000
INFO - Training [49][   60/  196]   Loss 0.037921   Top1 98.697917   Top5 99.993490   BatchTime 0.157544   LR 0.001000
INFO - Training [49][   80/  196]   Loss 0.039192   Top1 98.623047   Top5 99.995117   BatchTime 0.148926   LR 0.001000
INFO - Training [49][  100/  196]   Loss 0.039658   Top1 98.636719   Top5 99.996094   BatchTime 0.143861   LR 0.001000
INFO - Training [49][  120/  196]   Loss 0.040738   Top1 98.580729   Top5 99.996745   BatchTime 0.140458   LR 0.001000
INFO - Training [49][  140/  196]   Loss 0.040378   Top1 98.574219   Top5 99.997210   BatchTime 0.137902   LR 0.001000
INFO - Training [49][  160/  196]   Loss 0.040480   Top1 98.569336   Top5 99.997559   BatchTime 0.136014   LR 0.001000
INFO - Training [49][  180/  196]   Loss 0.040974   Top1 98.543837   Top5 99.997830   BatchTime 0.134564   LR 0.001000
INFO - ==> Top1: 98.566    Top5: 99.998    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.418246   Top1 90.195312   Top5 99.589844   BatchTime 0.144300
INFO - Validation [49][   40/   40]   Loss 0.407488   Top1 90.350000   Top5 99.660000   BatchTime 0.099335
INFO - ==> Top1: 90.350    Top5: 99.660    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.040660   Top1 98.515625   Top5 100.000000   BatchTime 0.219627   LR 0.001000
INFO - Training [50][   40/  196]   Loss 0.039940   Top1 98.505859   Top5 100.000000   BatchTime 0.171832   LR 0.001000
INFO - Training [50][   60/  196]   Loss 0.038563   Top1 98.606771   Top5 100.000000   BatchTime 0.155541   LR 0.001000
INFO - Training [50][   80/  196]   Loss 0.039049   Top1 98.549805   Top5 100.000000   BatchTime 0.147390   LR 0.001000
INFO - Training [50][  100/  196]   Loss 0.039813   Top1 98.511719   Top5 100.000000   BatchTime 0.142511   LR 0.001000
INFO - Training [50][  120/  196]   Loss 0.039552   Top1 98.548177   Top5 100.000000   BatchTime 0.135443   LR 0.001000
INFO - Training [50][  140/  196]   Loss 0.038698   Top1 98.593750   Top5 100.000000   BatchTime 0.130108   LR 0.001000
INFO - Training [50][  160/  196]   Loss 0.039334   Top1 98.574219   Top5 100.000000   BatchTime 0.126275   LR 0.001000
INFO - Training [50][  180/  196]   Loss 0.039489   Top1 98.578559   Top5 100.000000   BatchTime 0.124230   LR 0.001000
INFO - ==> Top1: 98.542    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.419219   Top1 90.097656   Top5 99.609375   BatchTime 0.145165
INFO - Validation [50][   40/   40]   Loss 0.411201   Top1 90.240000   Top5 99.690000   BatchTime 0.101322
INFO - ==> Top1: 90.240    Top5: 99.690    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.038732   Top1 98.652344   Top5 100.000000   BatchTime 0.220254   LR 0.001000
INFO - Training [51][   40/  196]   Loss 0.038973   Top1 98.681641   Top5 100.000000   BatchTime 0.171917   LR 0.001000
INFO - Training [51][   60/  196]   Loss 0.039287   Top1 98.671875   Top5 100.000000   BatchTime 0.154800   LR 0.001000
INFO - Training [51][   80/  196]   Loss 0.038640   Top1 98.681641   Top5 100.000000   BatchTime 0.147258   LR 0.001000
INFO - Training [51][  100/  196]   Loss 0.039131   Top1 98.660156   Top5 100.000000   BatchTime 0.142571   LR 0.001000
INFO - Training [51][  120/  196]   Loss 0.039603   Top1 98.642578   Top5 100.000000   BatchTime 0.139384   LR 0.001000
INFO - Training [51][  140/  196]   Loss 0.040067   Top1 98.624442   Top5 100.000000   BatchTime 0.137156   LR 0.001000
INFO - Training [51][  160/  196]   Loss 0.040083   Top1 98.605957   Top5 100.000000   BatchTime 0.135412   LR 0.001000
INFO - Training [51][  180/  196]   Loss 0.040176   Top1 98.600260   Top5 100.000000   BatchTime 0.134041   LR 0.001000
INFO - ==> Top1: 98.596    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.422050   Top1 90.253906   Top5 99.667969   BatchTime 0.142304
INFO - Validation [51][   40/   40]   Loss 0.413627   Top1 90.220000   Top5 99.700000   BatchTime 0.099007
INFO - ==> Top1: 90.220    Top5: 99.700    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.037442   Top1 98.632812   Top5 100.000000   BatchTime 0.219790   LR 0.001000
INFO - Training [52][   40/  196]   Loss 0.039967   Top1 98.564453   Top5 100.000000   BatchTime 0.171547   LR 0.001000
INFO - Training [52][   60/  196]   Loss 0.038853   Top1 98.626302   Top5 100.000000   BatchTime 0.150951   LR 0.001000
INFO - Training [52][   80/  196]   Loss 0.037812   Top1 98.657227   Top5 100.000000   BatchTime 0.137122   LR 0.001000
INFO - Training [52][  100/  196]   Loss 0.039346   Top1 98.617188   Top5 100.000000   BatchTime 0.129977   LR 0.001000
INFO - Training [52][  120/  196]   Loss 0.039208   Top1 98.626302   Top5 100.000000   BatchTime 0.125245   LR 0.001000
INFO - Training [52][  140/  196]   Loss 0.038425   Top1 98.671875   Top5 100.000000   BatchTime 0.120940   LR 0.001000
INFO - Training [52][  160/  196]   Loss 0.039368   Top1 98.645020   Top5 100.000000   BatchTime 0.119766   LR 0.001000
INFO - Training [52][  180/  196]   Loss 0.039332   Top1 98.652344   Top5 100.000000   BatchTime 0.120143   LR 0.001000
INFO - ==> Top1: 98.620    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.420699   Top1 90.175781   Top5 99.707031   BatchTime 0.143694
INFO - Validation [52][   40/   40]   Loss 0.412922   Top1 90.360000   Top5 99.730000   BatchTime 0.099809
INFO - ==> Top1: 90.360    Top5: 99.730    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.038144   Top1 98.515625   Top5 100.000000   BatchTime 0.218195   LR 0.001000
INFO - Training [53][   40/  196]   Loss 0.035113   Top1 98.710938   Top5 100.000000   BatchTime 0.170821   LR 0.001000
INFO - Training [53][   60/  196]   Loss 0.037225   Top1 98.652344   Top5 100.000000   BatchTime 0.155050   LR 0.001000
INFO - Training [53][   80/  196]   Loss 0.038633   Top1 98.613281   Top5 100.000000   BatchTime 0.147208   LR 0.001000
INFO - Training [53][  100/  196]   Loss 0.039263   Top1 98.597656   Top5 100.000000   BatchTime 0.142405   LR 0.001000
INFO - Training [53][  120/  196]   Loss 0.038508   Top1 98.600260   Top5 100.000000   BatchTime 0.139193   LR 0.001000
INFO - Training [53][  140/  196]   Loss 0.038344   Top1 98.604911   Top5 100.000000   BatchTime 0.136933   LR 0.001000
INFO - Training [53][  160/  196]   Loss 0.038563   Top1 98.613281   Top5 100.000000   BatchTime 0.135139   LR 0.001000
INFO - Training [53][  180/  196]   Loss 0.038264   Top1 98.630642   Top5 100.000000   BatchTime 0.133758   LR 0.001000
INFO - ==> Top1: 98.620    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.420265   Top1 90.449219   Top5 99.687500   BatchTime 0.143319
INFO - Validation [53][   40/   40]   Loss 0.413411   Top1 90.300000   Top5 99.670000   BatchTime 0.099693
INFO - ==> Top1: 90.300    Top5: 99.670    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.044738   Top1 98.378906   Top5 100.000000   BatchTime 0.192811   LR 0.001000
INFO - Training [54][   40/  196]   Loss 0.043387   Top1 98.515625   Top5 100.000000   BatchTime 0.147209   LR 0.001000
INFO - Training [54][   60/  196]   Loss 0.041088   Top1 98.619792   Top5 100.000000   BatchTime 0.132279   LR 0.001000
INFO - Training [54][   80/  196]   Loss 0.039290   Top1 98.662109   Top5 100.000000   BatchTime 0.123829   LR 0.001000
INFO - Training [54][  100/  196]   Loss 0.041590   Top1 98.562500   Top5 100.000000   BatchTime 0.120546   LR 0.001000
INFO - Training [54][  120/  196]   Loss 0.040648   Top1 98.606771   Top5 99.996745   BatchTime 0.120976   LR 0.001000
INFO - Training [54][  140/  196]   Loss 0.040740   Top1 98.596540   Top5 99.997210   BatchTime 0.121408   LR 0.001000
INFO - Training [54][  160/  196]   Loss 0.040412   Top1 98.610840   Top5 99.997559   BatchTime 0.121576   LR 0.001000
INFO - Training [54][  180/  196]   Loss 0.039706   Top1 98.650174   Top5 99.997830   BatchTime 0.121769   LR 0.001000
INFO - ==> Top1: 98.630    Top5: 99.998    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.428403   Top1 90.195312   Top5 99.667969   BatchTime 0.146087
INFO - Validation [54][   40/   40]   Loss 0.408911   Top1 90.430000   Top5 99.720000   BatchTime 0.099751
INFO - ==> Top1: 90.430    Top5: 99.720    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.045549   Top1 98.339844   Top5 100.000000   BatchTime 0.222686   LR 0.001000
INFO - Training [55][   40/  196]   Loss 0.043087   Top1 98.437500   Top5 100.000000   BatchTime 0.173582   LR 0.001000
INFO - Training [55][   60/  196]   Loss 0.041282   Top1 98.561198   Top5 100.000000   BatchTime 0.157320   LR 0.001000
INFO - Training [55][   80/  196]   Loss 0.040952   Top1 98.564453   Top5 100.000000   BatchTime 0.148967   LR 0.001000
INFO - Training [55][  100/  196]   Loss 0.040218   Top1 98.597656   Top5 100.000000   BatchTime 0.143850   LR 0.001000
INFO - Training [55][  120/  196]   Loss 0.039694   Top1 98.632812   Top5 100.000000   BatchTime 0.140523   LR 0.001000
INFO - Training [55][  140/  196]   Loss 0.040291   Top1 98.627232   Top5 100.000000   BatchTime 0.138084   LR 0.001000
INFO - Training [55][  160/  196]   Loss 0.040532   Top1 98.613281   Top5 100.000000   BatchTime 0.136134   LR 0.001000
INFO - Training [55][  180/  196]   Loss 0.040942   Top1 98.621962   Top5 100.000000   BatchTime 0.134568   LR 0.001000
INFO - ==> Top1: 98.634    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.427068   Top1 89.980469   Top5 99.707031   BatchTime 0.127713
INFO - Validation [55][   40/   40]   Loss 0.414997   Top1 90.010000   Top5 99.700000   BatchTime 0.082957
INFO - ==> Top1: 90.010    Top5: 99.700    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.039626   Top1 98.671875   Top5 100.000000   BatchTime 0.187699   LR 0.001000
INFO - Training [56][   40/  196]   Loss 0.038563   Top1 98.662109   Top5 100.000000   BatchTime 0.154024   LR 0.001000
INFO - Training [56][   60/  196]   Loss 0.038053   Top1 98.717448   Top5 100.000000   BatchTime 0.144052   LR 0.001000
INFO - Training [56][   80/  196]   Loss 0.037404   Top1 98.715820   Top5 100.000000   BatchTime 0.138857   LR 0.001000
INFO - Training [56][  100/  196]   Loss 0.037665   Top1 98.695312   Top5 100.000000   BatchTime 0.135844   LR 0.001000
INFO - Training [56][  120/  196]   Loss 0.038984   Top1 98.642578   Top5 100.000000   BatchTime 0.133858   LR 0.001000
INFO - Training [56][  140/  196]   Loss 0.039641   Top1 98.616071   Top5 100.000000   BatchTime 0.132435   LR 0.001000
INFO - Training [56][  160/  196]   Loss 0.039574   Top1 98.615723   Top5 100.000000   BatchTime 0.131217   LR 0.001000
INFO - Training [56][  180/  196]   Loss 0.039624   Top1 98.626302   Top5 100.000000   BatchTime 0.130294   LR 0.001000
INFO - ==> Top1: 98.636    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.418194   Top1 90.312500   Top5 99.667969   BatchTime 0.144108
INFO - Validation [56][   40/   40]   Loss 0.413063   Top1 90.260000   Top5 99.710000   BatchTime 0.099868
INFO - ==> Top1: 90.260    Top5: 99.710    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.034913   Top1 98.828125   Top5 100.000000   BatchTime 0.219800   LR 0.001000
INFO - Training [57][   40/  196]   Loss 0.034749   Top1 98.808594   Top5 100.000000   BatchTime 0.171540   LR 0.001000
INFO - Training [57][   60/  196]   Loss 0.035460   Top1 98.808594   Top5 100.000000   BatchTime 0.155509   LR 0.001000
INFO - Training [57][   80/  196]   Loss 0.037606   Top1 98.701172   Top5 100.000000   BatchTime 0.147547   LR 0.001000
INFO - Training [57][  100/  196]   Loss 0.038761   Top1 98.648438   Top5 100.000000   BatchTime 0.142626   LR 0.001000
INFO - Training [57][  120/  196]   Loss 0.038445   Top1 98.655599   Top5 100.000000   BatchTime 0.139355   LR 0.001000
INFO - Training [57][  140/  196]   Loss 0.038479   Top1 98.663504   Top5 100.000000   BatchTime 0.136996   LR 0.001000
INFO - Training [57][  160/  196]   Loss 0.038747   Top1 98.652344   Top5 100.000000   BatchTime 0.132012   LR 0.001000
INFO - Training [57][  180/  196]   Loss 0.039357   Top1 98.628472   Top5 100.000000   BatchTime 0.128135   LR 0.001000
INFO - ==> Top1: 98.614    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.416904   Top1 90.136719   Top5 99.687500   BatchTime 0.131898
INFO - Validation [57][   40/   40]   Loss 0.410869   Top1 90.330000   Top5 99.720000   BatchTime 0.092236
INFO - ==> Top1: 90.330    Top5: 99.720    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.034288   Top1 98.906250   Top5 99.980469   BatchTime 0.221432   LR 0.001000
INFO - Training [58][   40/  196]   Loss 0.035711   Top1 98.750000   Top5 99.990234   BatchTime 0.172658   LR 0.001000
INFO - Training [58][   60/  196]   Loss 0.037296   Top1 98.730469   Top5 99.993490   BatchTime 0.156175   LR 0.001000
INFO - Training [58][   80/  196]   Loss 0.036887   Top1 98.745117   Top5 99.995117   BatchTime 0.148126   LR 0.001000
INFO - Training [58][  100/  196]   Loss 0.036747   Top1 98.730469   Top5 99.996094   BatchTime 0.143246   LR 0.001000
INFO - Training [58][  120/  196]   Loss 0.036927   Top1 98.681641   Top5 99.996745   BatchTime 0.139921   LR 0.001000
INFO - Training [58][  140/  196]   Loss 0.037617   Top1 98.677455   Top5 99.997210   BatchTime 0.137562   LR 0.001000
INFO - Training [58][  160/  196]   Loss 0.038171   Top1 98.654785   Top5 99.997559   BatchTime 0.135654   LR 0.001000
INFO - Training [58][  180/  196]   Loss 0.038530   Top1 98.658854   Top5 99.997830   BatchTime 0.134234   LR 0.001000
INFO - ==> Top1: 98.644    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.420231   Top1 90.156250   Top5 99.628906   BatchTime 0.143996
INFO - Validation [58][   40/   40]   Loss 0.407195   Top1 90.300000   Top5 99.700000   BatchTime 0.098376
INFO - ==> Top1: 90.300    Top5: 99.700    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.032957   Top1 98.886719   Top5 100.000000   BatchTime 0.219531   LR 0.001000
INFO - Training [59][   40/  196]   Loss 0.036004   Top1 98.779297   Top5 100.000000   BatchTime 0.171215   LR 0.001000
INFO - Training [59][   60/  196]   Loss 0.036128   Top1 98.743490   Top5 100.000000   BatchTime 0.157435   LR 0.001000
INFO - Training [59][   80/  196]   Loss 0.035856   Top1 98.745117   Top5 100.000000   BatchTime 0.148753   LR 0.001000
INFO - Training [59][  100/  196]   Loss 0.037133   Top1 98.746094   Top5 100.000000   BatchTime 0.139246   LR 0.001000
INFO - Training [59][  120/  196]   Loss 0.037487   Top1 98.743490   Top5 100.000000   BatchTime 0.132682   LR 0.001000
INFO - Training [59][  140/  196]   Loss 0.037442   Top1 98.738839   Top5 100.000000   BatchTime 0.128135   LR 0.001000
INFO - Training [59][  160/  196]   Loss 0.038355   Top1 98.696289   Top5 100.000000   BatchTime 0.124730   LR 0.001000
INFO - Training [59][  180/  196]   Loss 0.038615   Top1 98.674045   Top5 100.000000   BatchTime 0.120196   LR 0.001000
INFO - ==> Top1: 98.682    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.417847   Top1 90.273438   Top5 99.648438   BatchTime 0.145558
INFO - Validation [59][   40/   40]   Loss 0.410295   Top1 90.440000   Top5 99.690000   BatchTime 0.101145
INFO - ==> Top1: 90.440    Top5: 99.690    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [60][   20/  196]   Loss 0.038664   Top1 98.652344   Top5 100.000000   BatchTime 0.219401   LR 0.000100
INFO - Training [60][   40/  196]   Loss 0.036266   Top1 98.710938   Top5 100.000000   BatchTime 0.171376   LR 0.000100
INFO - Training [60][   60/  196]   Loss 0.037412   Top1 98.658854   Top5 100.000000   BatchTime 0.155515   LR 0.000100
INFO - Training [60][   80/  196]   Loss 0.038154   Top1 98.637695   Top5 100.000000   BatchTime 0.147556   LR 0.000100
INFO - Training [60][  100/  196]   Loss 0.037206   Top1 98.667969   Top5 100.000000   BatchTime 0.142669   LR 0.000100
INFO - Training [60][  120/  196]   Loss 0.037544   Top1 98.671875   Top5 100.000000   BatchTime 0.139355   LR 0.000100
INFO - Training [60][  140/  196]   Loss 0.038167   Top1 98.663504   Top5 99.994420   BatchTime 0.137014   LR 0.000100
INFO - Training [60][  160/  196]   Loss 0.038104   Top1 98.688965   Top5 99.995117   BatchTime 0.135283   LR 0.000100
INFO - Training [60][  180/  196]   Loss 0.038019   Top1 98.691406   Top5 99.995660   BatchTime 0.133911   LR 0.000100
INFO - ==> Top1: 98.692    Top5: 99.996    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 0.419013   Top1 90.273438   Top5 99.687500   BatchTime 0.143416
INFO - Validation [60][   40/   40]   Loss 0.408947   Top1 90.440000   Top5 99.710000   BatchTime 0.099977
INFO - ==> Top1: 90.440    Top5: 99.710    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [61][   20/  196]   Loss 0.038584   Top1 98.632812   Top5 100.000000   BatchTime 0.217258   LR 0.000100
INFO - Training [61][   40/  196]   Loss 0.037016   Top1 98.671875   Top5 100.000000   BatchTime 0.164239   LR 0.000100
INFO - Training [61][   60/  196]   Loss 0.036026   Top1 98.736979   Top5 100.000000   BatchTime 0.141290   LR 0.000100
INFO - Training [61][   80/  196]   Loss 0.036272   Top1 98.735352   Top5 100.000000   BatchTime 0.131399   LR 0.000100
INFO - Training [61][  100/  196]   Loss 0.038105   Top1 98.648438   Top5 100.000000   BatchTime 0.125632   LR 0.000100
INFO - Training [61][  120/  196]   Loss 0.037960   Top1 98.668620   Top5 100.000000   BatchTime 0.119907   LR 0.000100
INFO - Training [61][  140/  196]   Loss 0.037974   Top1 98.699777   Top5 100.000000   BatchTime 0.119309   LR 0.000100
INFO - Training [61][  160/  196]   Loss 0.038092   Top1 98.715820   Top5 99.997559   BatchTime 0.119712   LR 0.000100
INFO - Training [61][  180/  196]   Loss 0.038400   Top1 98.704427   Top5 99.997830   BatchTime 0.120038   LR 0.000100
INFO - ==> Top1: 98.706    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 0.417956   Top1 90.253906   Top5 99.667969   BatchTime 0.144509
INFO - Validation [61][   40/   40]   Loss 0.408508   Top1 90.360000   Top5 99.720000   BatchTime 0.099731
INFO - ==> Top1: 90.360    Top5: 99.720    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [62][   20/  196]   Loss 0.041208   Top1 98.613281   Top5 100.000000   BatchTime 0.219682   LR 0.000100
INFO - Training [62][   40/  196]   Loss 0.040768   Top1 98.593750   Top5 100.000000   BatchTime 0.171545   LR 0.000100
INFO - Training [62][   60/  196]   Loss 0.039793   Top1 98.652344   Top5 100.000000   BatchTime 0.155475   LR 0.000100
INFO - Training [62][   80/  196]   Loss 0.039444   Top1 98.671875   Top5 100.000000   BatchTime 0.147610   LR 0.000100
INFO - Training [62][  100/  196]   Loss 0.039632   Top1 98.636719   Top5 100.000000   BatchTime 0.142845   LR 0.000100
INFO - Training [62][  120/  196]   Loss 0.040026   Top1 98.636068   Top5 100.000000   BatchTime 0.139603   LR 0.000100
INFO - Training [62][  140/  196]   Loss 0.039277   Top1 98.674665   Top5 100.000000   BatchTime 0.137244   LR 0.000100
INFO - Training [62][  160/  196]   Loss 0.038924   Top1 98.684082   Top5 100.000000   BatchTime 0.135458   LR 0.000100
INFO - Training [62][  180/  196]   Loss 0.038612   Top1 98.695747   Top5 100.000000   BatchTime 0.134057   LR 0.000100
INFO - ==> Top1: 98.710    Top5: 100.000    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 0.422488   Top1 90.292969   Top5 99.570312   BatchTime 0.143958
INFO - Validation [62][   40/   40]   Loss 0.408844   Top1 90.480000   Top5 99.650000   BatchTime 0.100187
INFO - ==> Top1: 90.480    Top5: 99.650    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 0.035728   Top1 98.906250   Top5 100.000000   BatchTime 0.211250   LR 0.000100
INFO - Training [63][   40/  196]   Loss 0.037513   Top1 98.720703   Top5 100.000000   BatchTime 0.156414   LR 0.000100
INFO - Training [63][   60/  196]   Loss 0.037165   Top1 98.671875   Top5 99.993490   BatchTime 0.139287   LR 0.000100
INFO - Training [63][   80/  196]   Loss 0.036891   Top1 98.720703   Top5 99.995117   BatchTime 0.131340   LR 0.000100
INFO - Training [63][  100/  196]   Loss 0.037935   Top1 98.703125   Top5 99.996094   BatchTime 0.129717   LR 0.000100
INFO - Training [63][  120/  196]   Loss 0.038782   Top1 98.678385   Top5 99.996745   BatchTime 0.128675   LR 0.000100
INFO - Training [63][  140/  196]   Loss 0.038856   Top1 98.660714   Top5 99.997210   BatchTime 0.127960   LR 0.000100
INFO - Training [63][  160/  196]   Loss 0.038991   Top1 98.666992   Top5 99.997559   BatchTime 0.127324   LR 0.000100
INFO - Training [63][  180/  196]   Loss 0.038806   Top1 98.669705   Top5 99.997830   BatchTime 0.126864   LR 0.000100
INFO - ==> Top1: 98.672    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 0.418542   Top1 90.390625   Top5 99.687500   BatchTime 0.143017
INFO - Validation [63][   40/   40]   Loss 0.411224   Top1 90.320000   Top5 99.710000   BatchTime 0.099019
INFO - ==> Top1: 90.320    Top5: 99.710    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 0.034640   Top1 98.710938   Top5 100.000000   BatchTime 0.220061   LR 0.000100
INFO - Training [64][   40/  196]   Loss 0.036177   Top1 98.691406   Top5 100.000000   BatchTime 0.171650   LR 0.000100
INFO - Training [64][   60/  196]   Loss 0.034705   Top1 98.763021   Top5 100.000000   BatchTime 0.155609   LR 0.000100
INFO - Training [64][   80/  196]   Loss 0.035787   Top1 98.759766   Top5 100.000000   BatchTime 0.147549   LR 0.000100
INFO - Training [64][  100/  196]   Loss 0.035639   Top1 98.796875   Top5 99.992188   BatchTime 0.142732   LR 0.000100
INFO - Training [64][  120/  196]   Loss 0.035831   Top1 98.772786   Top5 99.993490   BatchTime 0.139647   LR 0.000100
INFO - Training [64][  140/  196]   Loss 0.035813   Top1 98.780692   Top5 99.994420   BatchTime 0.137214   LR 0.000100
INFO - Training [64][  160/  196]   Loss 0.036580   Top1 98.759766   Top5 99.995117   BatchTime 0.135348   LR 0.000100
INFO - Training [64][  180/  196]   Loss 0.036985   Top1 98.754340   Top5 99.995660   BatchTime 0.133937   LR 0.000100
INFO - ==> Top1: 98.708    Top5: 99.996    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [64][   20/   40]   Loss 0.417539   Top1 90.429688   Top5 99.589844   BatchTime 0.136299
INFO - Validation [64][   40/   40]   Loss 0.408609   Top1 90.490000   Top5 99.670000   BatchTime 0.089474
INFO - ==> Top1: 90.490    Top5: 99.670    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [64][Top1: 90.490   Top5: 99.670] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [65][   20/  196]   Loss 0.033540   Top1 99.003906   Top5 100.000000   BatchTime 0.219057   LR 0.000100
INFO - Training [65][   40/  196]   Loss 0.032856   Top1 98.925781   Top5 100.000000   BatchTime 0.171405   LR 0.000100
INFO - Training [65][   60/  196]   Loss 0.034242   Top1 98.880208   Top5 100.000000   BatchTime 0.155613   LR 0.000100
INFO - Training [65][   80/  196]   Loss 0.034243   Top1 98.881836   Top5 100.000000   BatchTime 0.147712   LR 0.000100
INFO - Training [65][  100/  196]   Loss 0.035285   Top1 98.835938   Top5 100.000000   BatchTime 0.142956   LR 0.000100
INFO - Training [65][  120/  196]   Loss 0.036114   Top1 98.802083   Top5 100.000000   BatchTime 0.139834   LR 0.000100
INFO - Training [65][  140/  196]   Loss 0.035410   Top1 98.825335   Top5 100.000000   BatchTime 0.137501   LR 0.000100
INFO - Training [65][  160/  196]   Loss 0.035903   Top1 98.784180   Top5 100.000000   BatchTime 0.135672   LR 0.000100
INFO - Training [65][  180/  196]   Loss 0.036116   Top1 98.767361   Top5 100.000000   BatchTime 0.134226   LR 0.000100
INFO - ==> Top1: 98.764    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 0.421326   Top1 90.429688   Top5 99.687500   BatchTime 0.145854
INFO - Validation [65][   40/   40]   Loss 0.410774   Top1 90.470000   Top5 99.730000   BatchTime 0.100776
INFO - ==> Top1: 90.470    Top5: 99.730    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [64][Top1: 90.490   Top5: 99.670] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [66][   20/  196]   Loss 0.032669   Top1 98.789062   Top5 100.000000   BatchTime 0.216627   LR 0.000100
INFO - Training [66][   40/  196]   Loss 0.034963   Top1 98.867188   Top5 100.000000   BatchTime 0.169997   LR 0.000100
INFO - Training [66][   60/  196]   Loss 0.035578   Top1 98.815104   Top5 100.000000   BatchTime 0.154502   LR 0.000100
INFO - Training [66][   80/  196]   Loss 0.036142   Top1 98.789062   Top5 100.000000   BatchTime 0.146617   LR 0.000100
INFO - Training [66][  100/  196]   Loss 0.036195   Top1 98.804688   Top5 99.996094   BatchTime 0.141934   LR 0.000100
INFO - Training [66][  120/  196]   Loss 0.036156   Top1 98.824870   Top5 99.996745   BatchTime 0.138772   LR 0.000100
INFO - Training [66][  140/  196]   Loss 0.035751   Top1 98.844866   Top5 99.997210   BatchTime 0.133689   LR 0.000100
INFO - Training [66][  160/  196]   Loss 0.035547   Top1 98.837891   Top5 99.997559   BatchTime 0.128998   LR 0.000100
INFO - Training [66][  180/  196]   Loss 0.035944   Top1 98.825955   Top5 99.997830   BatchTime 0.125810   LR 0.000100
INFO - ==> Top1: 98.842    Top5: 99.998    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 0.419670   Top1 90.371094   Top5 99.687500   BatchTime 0.138309
INFO - Validation [66][   40/   40]   Loss 0.408838   Top1 90.520000   Top5 99.750000   BatchTime 0.090405
INFO - ==> Top1: 90.520    Top5: 99.750    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 0.035116   Top1 98.750000   Top5 100.000000   BatchTime 0.185170   LR 0.000100
INFO - Training [67][   40/  196]   Loss 0.032762   Top1 98.867188   Top5 100.000000   BatchTime 0.134765   LR 0.000100
INFO - Training [67][   60/  196]   Loss 0.034873   Top1 98.795573   Top5 100.000000   BatchTime 0.117892   LR 0.000100
INFO - Training [67][   80/  196]   Loss 0.035176   Top1 98.759766   Top5 100.000000   BatchTime 0.111046   LR 0.000100
INFO - Training [67][  100/  196]   Loss 0.036057   Top1 98.738281   Top5 99.996094   BatchTime 0.106143   LR 0.000100
INFO - Training [67][  120/  196]   Loss 0.035817   Top1 98.756510   Top5 99.996745   BatchTime 0.102432   LR 0.000100
INFO - Training [67][  140/  196]   Loss 0.035374   Top1 98.777902   Top5 99.997210   BatchTime 0.099822   LR 0.000100
INFO - Training [67][  160/  196]   Loss 0.035640   Top1 98.762207   Top5 99.997559   BatchTime 0.097758   LR 0.000100
INFO - Training [67][  180/  196]   Loss 0.035635   Top1 98.760851   Top5 99.997830   BatchTime 0.096612   LR 0.000100
INFO - ==> Top1: 98.778    Top5: 99.998    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 0.424181   Top1 90.253906   Top5 99.628906   BatchTime 0.147521
INFO - Validation [67][   40/   40]   Loss 0.412139   Top1 90.440000   Top5 99.680000   BatchTime 0.098646
INFO - ==> Top1: 90.440    Top5: 99.680    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 0.033344   Top1 98.964844   Top5 100.000000   BatchTime 0.257001   LR 0.000100
INFO - Training [68][   40/  196]   Loss 0.037819   Top1 98.798828   Top5 100.000000   BatchTime 0.204129   LR 0.000100
INFO - Training [68][   60/  196]   Loss 0.038150   Top1 98.717448   Top5 100.000000   BatchTime 0.186461   LR 0.000100
INFO - Training [68][   80/  196]   Loss 0.037642   Top1 98.735352   Top5 100.000000   BatchTime 0.177742   LR 0.000100
INFO - Training [68][  100/  196]   Loss 0.037182   Top1 98.746094   Top5 100.000000   BatchTime 0.172279   LR 0.000100
INFO - Training [68][  120/  196]   Loss 0.038959   Top1 98.665365   Top5 99.996745   BatchTime 0.168861   LR 0.000100
INFO - Training [68][  140/  196]   Loss 0.038856   Top1 98.660714   Top5 99.997210   BatchTime 0.166161   LR 0.000100
INFO - Training [68][  160/  196]   Loss 0.038535   Top1 98.671875   Top5 99.997559   BatchTime 0.164015   LR 0.000100
INFO - Training [68][  180/  196]   Loss 0.038782   Top1 98.667535   Top5 99.997830   BatchTime 0.162443   LR 0.000100
INFO - ==> Top1: 98.666    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.418660   Top1 90.410156   Top5 99.609375   BatchTime 0.135180
INFO - Validation [68][   40/   40]   Loss 0.413305   Top1 90.420000   Top5 99.710000   BatchTime 0.092852
INFO - ==> Top1: 90.420    Top5: 99.710    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 0.036458   Top1 98.730469   Top5 100.000000   BatchTime 0.242295   LR 0.000100
INFO - Training [69][   40/  196]   Loss 0.035594   Top1 98.691406   Top5 100.000000   BatchTime 0.196709   LR 0.000100
INFO - Training [69][   60/  196]   Loss 0.034653   Top1 98.802083   Top5 100.000000   BatchTime 0.181701   LR 0.000100
INFO - Training [69][   80/  196]   Loss 0.035453   Top1 98.764648   Top5 100.000000   BatchTime 0.174014   LR 0.000100
INFO - Training [69][  100/  196]   Loss 0.035168   Top1 98.781250   Top5 100.000000   BatchTime 0.169494   LR 0.000100
INFO - Training [69][  120/  196]   Loss 0.035510   Top1 98.779297   Top5 100.000000   BatchTime 0.165482   LR 0.000100
INFO - Training [69][  140/  196]   Loss 0.036336   Top1 98.733259   Top5 100.000000   BatchTime 0.163511   LR 0.000100
INFO - Training [69][  160/  196]   Loss 0.036683   Top1 98.730469   Top5 100.000000   BatchTime 0.161770   LR 0.000100
INFO - Training [69][  180/  196]   Loss 0.036350   Top1 98.750000   Top5 100.000000   BatchTime 0.160437   LR 0.000100
INFO - ==> Top1: 98.764    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [69][   20/   40]   Loss 0.419779   Top1 90.332031   Top5 99.609375   BatchTime 0.137331
INFO - Validation [69][   40/   40]   Loss 0.408472   Top1 90.410000   Top5 99.700000   BatchTime 0.093782
INFO - ==> Top1: 90.410    Top5: 99.700    Loss: 0.408
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  70
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [70][   20/  196]   Loss 0.033535   Top1 98.945312   Top5 100.000000   BatchTime 0.241221   LR 0.000010
INFO - Training [70][   40/  196]   Loss 0.035088   Top1 98.847656   Top5 100.000000   BatchTime 0.196271   LR 0.000010
INFO - Training [70][   60/  196]   Loss 0.036775   Top1 98.717448   Top5 100.000000   BatchTime 0.181046   LR 0.000010
INFO - Training [70][   80/  196]   Loss 0.037667   Top1 98.715820   Top5 100.000000   BatchTime 0.173561   LR 0.000010
INFO - Training [70][  100/  196]   Loss 0.037916   Top1 98.707031   Top5 100.000000   BatchTime 0.169013   LR 0.000010
INFO - Training [70][  120/  196]   Loss 0.037453   Top1 98.710938   Top5 100.000000   BatchTime 0.166086   LR 0.000010
INFO - Training [70][  140/  196]   Loss 0.037330   Top1 98.736049   Top5 100.000000   BatchTime 0.163909   LR 0.000010
INFO - Training [70][  160/  196]   Loss 0.037557   Top1 98.725586   Top5 99.997559   BatchTime 0.162162   LR 0.000010
INFO - Training [70][  180/  196]   Loss 0.037508   Top1 98.750000   Top5 99.997830   BatchTime 0.160779   LR 0.000010
INFO - ==> Top1: 98.746    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [70][   20/   40]   Loss 0.420866   Top1 90.234375   Top5 99.648438   BatchTime 0.134605
INFO - Validation [70][   40/   40]   Loss 0.409148   Top1 90.450000   Top5 99.720000   BatchTime 0.092202
INFO - ==> Top1: 90.450    Top5: 99.720    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  71
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [71][   20/  196]   Loss 0.038427   Top1 98.710938   Top5 100.000000   BatchTime 0.230002   LR 0.000010
INFO - Training [71][   40/  196]   Loss 0.040021   Top1 98.593750   Top5 99.990234   BatchTime 0.190421   LR 0.000010
INFO - Training [71][   60/  196]   Loss 0.038496   Top1 98.652344   Top5 99.993490   BatchTime 0.177623   LR 0.000010
INFO - Training [71][   80/  196]   Loss 0.039126   Top1 98.613281   Top5 99.995117   BatchTime 0.170917   LR 0.000010
INFO - Training [71][  100/  196]   Loss 0.039294   Top1 98.609375   Top5 99.996094   BatchTime 0.166961   LR 0.000010
INFO - Training [71][  120/  196]   Loss 0.038402   Top1 98.652344   Top5 99.996745   BatchTime 0.164825   LR 0.000010
INFO - Training [71][  140/  196]   Loss 0.037909   Top1 98.677455   Top5 99.997210   BatchTime 0.162876   LR 0.000010
INFO - Training [71][  160/  196]   Loss 0.038092   Top1 98.676758   Top5 99.997559   BatchTime 0.161236   LR 0.000010
INFO - Training [71][  180/  196]   Loss 0.038083   Top1 98.669705   Top5 99.997830   BatchTime 0.159979   LR 0.000010
INFO - ==> Top1: 98.692    Top5: 99.998    Loss: 0.038
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [71][   20/   40]   Loss 0.418342   Top1 90.195312   Top5 99.648438   BatchTime 0.131354
INFO - Validation [71][   40/   40]   Loss 0.408723   Top1 90.360000   Top5 99.710000   BatchTime 0.091084
INFO - ==> Top1: 90.360    Top5: 99.710    Loss: 0.409
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  72
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [72][   20/  196]   Loss 0.037937   Top1 98.613281   Top5 100.000000   BatchTime 0.232738   LR 0.000010
INFO - Training [72][   40/  196]   Loss 0.037902   Top1 98.652344   Top5 100.000000   BatchTime 0.191750   LR 0.000010
INFO - Training [72][   60/  196]   Loss 0.036802   Top1 98.691406   Top5 100.000000   BatchTime 0.178142   LR 0.000010
INFO - Training [72][   80/  196]   Loss 0.037403   Top1 98.681641   Top5 100.000000   BatchTime 0.171403   LR 0.000010
INFO - Training [72][  100/  196]   Loss 0.036960   Top1 98.707031   Top5 99.996094   BatchTime 0.167402   LR 0.000010
INFO - Training [72][  120/  196]   Loss 0.036550   Top1 98.730469   Top5 99.996745   BatchTime 0.164694   LR 0.000010
INFO - Training [72][  140/  196]   Loss 0.036692   Top1 98.738839   Top5 99.997210   BatchTime 0.162717   LR 0.000010
INFO - Training [72][  160/  196]   Loss 0.037085   Top1 98.703613   Top5 99.997559   BatchTime 0.161083   LR 0.000010
INFO - Training [72][  180/  196]   Loss 0.037280   Top1 98.706597   Top5 99.997830   BatchTime 0.159873   LR 0.000010
INFO - ==> Top1: 98.694    Top5: 99.998    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [72][   20/   40]   Loss 0.422274   Top1 90.214844   Top5 99.648438   BatchTime 0.133977
INFO - Validation [72][   40/   40]   Loss 0.410019   Top1 90.350000   Top5 99.710000   BatchTime 0.092081
INFO - ==> Top1: 90.350    Top5: 99.710    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  73
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [73][   20/  196]   Loss 0.034169   Top1 98.789062   Top5 100.000000   BatchTime 0.243069   LR 0.000010
INFO - Training [73][   40/  196]   Loss 0.034714   Top1 98.808594   Top5 100.000000   BatchTime 0.197061   LR 0.000010
INFO - Training [73][   60/  196]   Loss 0.034797   Top1 98.808594   Top5 100.000000   BatchTime 0.181531   LR 0.000010
INFO - Training [73][   80/  196]   Loss 0.035536   Top1 98.759766   Top5 100.000000   BatchTime 0.173973   LR 0.000010
INFO - Training [73][  100/  196]   Loss 0.036296   Top1 98.718750   Top5 100.000000   BatchTime 0.169285   LR 0.000010
INFO - Training [73][  120/  196]   Loss 0.035870   Top1 98.736979   Top5 100.000000   BatchTime 0.165613   LR 0.000010
INFO - Training [73][  140/  196]   Loss 0.036130   Top1 98.741629   Top5 100.000000   BatchTime 0.163455   LR 0.000010
INFO - Training [73][  160/  196]   Loss 0.035708   Top1 98.750000   Top5 99.997559   BatchTime 0.161713   LR 0.000010
INFO - Training [73][  180/  196]   Loss 0.035752   Top1 98.747830   Top5 99.997830   BatchTime 0.160357   LR 0.000010
INFO - ==> Top1: 98.744    Top5: 99.998    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [73][   20/   40]   Loss 0.420472   Top1 90.351562   Top5 99.648438   BatchTime 0.132574
INFO - Validation [73][   40/   40]   Loss 0.410256   Top1 90.460000   Top5 99.730000   BatchTime 0.091334
INFO - ==> Top1: 90.460    Top5: 99.730    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  74
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [74][   20/  196]   Loss 0.035903   Top1 98.632812   Top5 100.000000   BatchTime 0.234630   LR 0.000010
INFO - Training [74][   40/  196]   Loss 0.036668   Top1 98.632812   Top5 100.000000   BatchTime 0.192811   LR 0.000010
INFO - Training [74][   60/  196]   Loss 0.036876   Top1 98.652344   Top5 100.000000   BatchTime 0.178757   LR 0.000010
INFO - Training [74][   80/  196]   Loss 0.036425   Top1 98.696289   Top5 100.000000   BatchTime 0.171827   LR 0.000010
INFO - Training [74][  100/  196]   Loss 0.036074   Top1 98.722656   Top5 100.000000   BatchTime 0.167731   LR 0.000010
INFO - Training [74][  120/  196]   Loss 0.036404   Top1 98.714193   Top5 100.000000   BatchTime 0.165065   LR 0.000010
INFO - Training [74][  140/  196]   Loss 0.035782   Top1 98.755580   Top5 100.000000   BatchTime 0.163063   LR 0.000010
INFO - Training [74][  160/  196]   Loss 0.036292   Top1 98.750000   Top5 100.000000   BatchTime 0.161377   LR 0.000010
INFO - Training [74][  180/  196]   Loss 0.036406   Top1 98.741319   Top5 100.000000   BatchTime 0.160160   LR 0.000010
INFO - ==> Top1: 98.694    Top5: 100.000    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [74][   20/   40]   Loss 0.422309   Top1 90.000000   Top5 99.667969   BatchTime 0.131897
INFO - Validation [74][   40/   40]   Loss 0.412792   Top1 90.290000   Top5 99.720000   BatchTime 0.091394
INFO - ==> Top1: 90.290    Top5: 99.720    Loss: 0.413
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  75
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [75][   20/  196]   Loss 0.034253   Top1 98.847656   Top5 100.000000   BatchTime 0.238926   LR 0.000010
INFO - Training [75][   40/  196]   Loss 0.036208   Top1 98.740234   Top5 100.000000   BatchTime 0.195205   LR 0.000010
INFO - Training [75][   60/  196]   Loss 0.036460   Top1 98.710938   Top5 100.000000   BatchTime 0.180392   LR 0.000010
INFO - Training [75][   80/  196]   Loss 0.036888   Top1 98.657227   Top5 100.000000   BatchTime 0.172876   LR 0.000010
INFO - Training [75][  100/  196]   Loss 0.036326   Top1 98.699219   Top5 100.000000   BatchTime 0.168528   LR 0.000010
INFO - Training [75][  120/  196]   Loss 0.036250   Top1 98.720703   Top5 100.000000   BatchTime 0.165650   LR 0.000010
INFO - Training [75][  140/  196]   Loss 0.036923   Top1 98.708147   Top5 100.000000   BatchTime 0.163473   LR 0.000010
INFO - Training [75][  160/  196]   Loss 0.037128   Top1 98.693848   Top5 100.000000   BatchTime 0.162300   LR 0.000010
INFO - Training [75][  180/  196]   Loss 0.036904   Top1 98.695747   Top5 100.000000   BatchTime 0.160865   LR 0.000010
INFO - ==> Top1: 98.680    Top5: 100.000    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [75][   20/   40]   Loss 0.418140   Top1 90.332031   Top5 99.687500   BatchTime 0.135644
INFO - Validation [75][   40/   40]   Loss 0.407207   Top1 90.460000   Top5 99.730000   BatchTime 0.092885
INFO - ==> Top1: 90.460    Top5: 99.730    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  76
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [76][   20/  196]   Loss 0.035322   Top1 98.847656   Top5 100.000000   BatchTime 0.254297   LR 0.000010
INFO - Training [76][   40/  196]   Loss 0.035679   Top1 98.828125   Top5 100.000000   BatchTime 0.202829   LR 0.000010
INFO - Training [76][   60/  196]   Loss 0.033954   Top1 98.847656   Top5 100.000000   BatchTime 0.185833   LR 0.000010
INFO - Training [76][   80/  196]   Loss 0.035535   Top1 98.808594   Top5 100.000000   BatchTime 0.177115   LR 0.000010
INFO - Training [76][  100/  196]   Loss 0.035282   Top1 98.828125   Top5 100.000000   BatchTime 0.171925   LR 0.000010
INFO - Training [76][  120/  196]   Loss 0.035189   Top1 98.847656   Top5 100.000000   BatchTime 0.168413   LR 0.000010
INFO - Training [76][  140/  196]   Loss 0.035327   Top1 98.842076   Top5 100.000000   BatchTime 0.165912   LR 0.000010
INFO - Training [76][  160/  196]   Loss 0.035836   Top1 98.815918   Top5 100.000000   BatchTime 0.163857   LR 0.000010
INFO - Training [76][  180/  196]   Loss 0.035467   Top1 98.819444   Top5 100.000000   BatchTime 0.162332   LR 0.000010
INFO - ==> Top1: 98.812    Top5: 100.000    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [76][   20/   40]   Loss 0.419730   Top1 90.371094   Top5 99.707031   BatchTime 0.143564
INFO - Validation [76][   40/   40]   Loss 0.411233   Top1 90.410000   Top5 99.730000   BatchTime 0.097012
INFO - ==> Top1: 90.410    Top5: 99.730    Loss: 0.411
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  77
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [77][   20/  196]   Loss 0.037566   Top1 98.554688   Top5 100.000000   BatchTime 0.259711   LR 0.000010
INFO - Training [77][   40/  196]   Loss 0.037370   Top1 98.623047   Top5 100.000000   BatchTime 0.205317   LR 0.000010
INFO - Training [77][   60/  196]   Loss 0.038993   Top1 98.580729   Top5 100.000000   BatchTime 0.187445   LR 0.000010
INFO - Training [77][   80/  196]   Loss 0.038139   Top1 98.598633   Top5 100.000000   BatchTime 0.178373   LR 0.000010
INFO - Training [77][  100/  196]   Loss 0.037351   Top1 98.648438   Top5 100.000000   BatchTime 0.172753   LR 0.000010
INFO - Training [77][  120/  196]   Loss 0.037284   Top1 98.662109   Top5 100.000000   BatchTime 0.169148   LR 0.000010
INFO - Training [77][  140/  196]   Loss 0.037191   Top1 98.683036   Top5 100.000000   BatchTime 0.166015   LR 0.000010
INFO - Training [77][  160/  196]   Loss 0.036571   Top1 98.737793   Top5 100.000000   BatchTime 0.163945   LR 0.000010
INFO - Training [77][  180/  196]   Loss 0.036171   Top1 98.758681   Top5 100.000000   BatchTime 0.162343   LR 0.000010
INFO - ==> Top1: 98.738    Top5: 100.000    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [77][   20/   40]   Loss 0.425536   Top1 90.429688   Top5 99.609375   BatchTime 0.145523
INFO - Validation [77][   40/   40]   Loss 0.412255   Top1 90.490000   Top5 99.710000   BatchTime 0.097992
INFO - ==> Top1: 90.490    Top5: 99.710    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  78
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [78][   20/  196]   Loss 0.031845   Top1 98.925781   Top5 100.000000   BatchTime 0.258967   LR 0.000010
INFO - Training [78][   40/  196]   Loss 0.032701   Top1 98.925781   Top5 100.000000   BatchTime 0.204861   LR 0.000010
INFO - Training [78][   60/  196]   Loss 0.034465   Top1 98.841146   Top5 100.000000   BatchTime 0.186726   LR 0.000010
INFO - Training [78][   80/  196]   Loss 0.034832   Top1 98.842773   Top5 100.000000   BatchTime 0.177797   LR 0.000010
INFO - Training [78][  100/  196]   Loss 0.034333   Top1 98.867188   Top5 100.000000   BatchTime 0.172556   LR 0.000010
INFO - Training [78][  120/  196]   Loss 0.034927   Top1 98.789062   Top5 100.000000   BatchTime 0.169062   LR 0.000010
INFO - Training [78][  140/  196]   Loss 0.035959   Top1 98.750000   Top5 100.000000   BatchTime 0.166376   LR 0.000010
INFO - Training [78][  160/  196]   Loss 0.035948   Top1 98.754883   Top5 100.000000   BatchTime 0.164260   LR 0.000010
INFO - Training [78][  180/  196]   Loss 0.036312   Top1 98.743490   Top5 100.000000   BatchTime 0.162658   LR 0.000010
INFO - ==> Top1: 98.752    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [78][   20/   40]   Loss 0.424067   Top1 90.351562   Top5 99.667969   BatchTime 0.146889
INFO - Validation [78][   40/   40]   Loss 0.412324   Top1 90.470000   Top5 99.720000   BatchTime 0.098529
INFO - ==> Top1: 90.470    Top5: 99.720    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  79
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [79][   20/  196]   Loss 0.035400   Top1 98.710938   Top5 100.000000   BatchTime 0.265619   LR 0.000010
INFO - Training [79][   40/  196]   Loss 0.035367   Top1 98.662109   Top5 100.000000   BatchTime 0.208351   LR 0.000010
INFO - Training [79][   60/  196]   Loss 0.035835   Top1 98.691406   Top5 100.000000   BatchTime 0.189267   LR 0.000010
INFO - Training [79][   80/  196]   Loss 0.036128   Top1 98.706055   Top5 99.995117   BatchTime 0.179748   LR 0.000010
INFO - Training [79][  100/  196]   Loss 0.036204   Top1 98.726562   Top5 99.996094   BatchTime 0.174047   LR 0.000010
INFO - Training [79][  120/  196]   Loss 0.036479   Top1 98.733724   Top5 99.996745   BatchTime 0.170257   LR 0.000010
INFO - Training [79][  140/  196]   Loss 0.036950   Top1 98.716518   Top5 99.997210   BatchTime 0.167489   LR 0.000010
INFO - Training [79][  160/  196]   Loss 0.036537   Top1 98.715820   Top5 99.997559   BatchTime 0.165242   LR 0.000010
INFO - Training [79][  180/  196]   Loss 0.036983   Top1 98.704427   Top5 99.997830   BatchTime 0.163561   LR 0.000010
INFO - ==> Top1: 98.724    Top5: 99.996    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [79][   20/   40]   Loss 0.420183   Top1 90.683594   Top5 99.628906   BatchTime 0.143638
INFO - Validation [79][   40/   40]   Loss 0.410325   Top1 90.640000   Top5 99.710000   BatchTime 0.097711
INFO - ==> Top1: 90.640    Top5: 99.710    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
INFO - Scoreboard best 2 ==> Epoch [79][Top1: 90.640   Top5: 99.710] Sparsity : 0.892
INFO - Scoreboard best 3 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.420183   Top1 90.683594   Top5 99.628906   BatchTime 0.175831
INFO - Validation [   40/   40]   Loss 0.410325   Top1 90.640000   Top5 99.710000   BatchTime 0.125529
INFO - ==> Top1: 90.640    Top5: 99.710    Loss: 0.410
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net