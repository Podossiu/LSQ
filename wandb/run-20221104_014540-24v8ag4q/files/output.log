
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541.log
2022-11-04 01:45:41.138855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-04 01:45:41.264195: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-04 01:45:41.748820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-04 01:45:41.748870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-04 01:45:41.748877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/tb_runs
Files already downloaded and verified
hello
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
INFO - Inserted quantizers into the original model
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Validation [   20/   40]   Loss 0.428771   Top1 89.902344   Top5 99.531250   BatchTime 0.193965
INFO - Validation [   40/   40]   Loss 0.406859   Top1 90.290000   Top5 99.610000   BatchTime 0.127516
INFO - ==> Top1: 90.290    Top5: 99.610    Loss: 0.407
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.030883   Top1 99.042969   Top5 99.980469   BatchTime 0.241954   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.032406   Top1 98.994141   Top5 99.990234   BatchTime 0.183313   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.032962   Top1 98.951823   Top5 99.986979   BatchTime 0.163482   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.033481   Top1 98.876953   Top5 99.990234   BatchTime 0.153589   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.034038   Top1 98.832031   Top5 99.992188   BatchTime 0.147777   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.033622   Top1 98.873698   Top5 99.993490   BatchTime 0.143776   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.033913   Top1 98.856027   Top5 99.994420   BatchTime 0.140855   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.035028   Top1 98.813477   Top5 99.995117   BatchTime 0.138633   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.036411   Top1 98.754340   Top5 99.995660   BatchTime 0.136871   LR 0.010000
INFO - ==> Top1: 98.746    Top5: 99.996    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.443432   Top1 89.667969   Top5 99.511719   BatchTime 0.130045
INFO - Validation [0][   40/   40]   Loss 0.424122   Top1 90.090000   Top5 99.570000   BatchTime 0.082235
INFO - ==> Top1: 90.090    Top5: 99.570    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.090   Top5: 99.570] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.037351   Top1 98.671875   Top5 100.000000   BatchTime 0.198093   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.042507   Top1 98.466797   Top5 100.000000   BatchTime 0.145221   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.040985   Top1 98.515625   Top5 100.000000   BatchTime 0.137970   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.040021   Top1 98.554688   Top5 100.000000   BatchTime 0.134328   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.039331   Top1 98.570312   Top5 100.000000   BatchTime 0.132256   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.039111   Top1 98.564453   Top5 100.000000   BatchTime 0.131597   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.039419   Top1 98.554688   Top5 100.000000   BatchTime 0.130370   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.039254   Top1 98.562012   Top5 100.000000   BatchTime 0.129498   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.039490   Top1 98.546007   Top5 100.000000   BatchTime 0.128760   LR 0.010000
INFO - ==> Top1: 98.542    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.429537   Top1 89.882812   Top5 99.550781   BatchTime 0.142966
INFO - Validation [1][   40/   40]   Loss 0.419554   Top1 90.170000   Top5 99.610000   BatchTime 0.099957
INFO - ==> Top1: 90.170    Top5: 99.610    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 90.170   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.090   Top5: 99.570] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.034160   Top1 98.808594   Top5 100.000000   BatchTime 0.218772   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.037098   Top1 98.740234   Top5 100.000000   BatchTime 0.171149   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.036184   Top1 98.789062   Top5 100.000000   BatchTime 0.155313   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.036917   Top1 98.710938   Top5 100.000000   BatchTime 0.147636   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.036439   Top1 98.726562   Top5 100.000000   BatchTime 0.142754   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.037377   Top1 98.704427   Top5 100.000000   BatchTime 0.139433   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.039036   Top1 98.660714   Top5 100.000000   BatchTime 0.137130   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.039064   Top1 98.664551   Top5 100.000000   BatchTime 0.135346   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.039218   Top1 98.648003   Top5 100.000000   BatchTime 0.130186   LR 0.010000
INFO - ==> Top1: 98.634    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.437987   Top1 90.195312   Top5 99.531250   BatchTime 0.128847
INFO - Validation [2][   40/   40]   Loss 0.425587   Top1 90.390000   Top5 99.610000   BatchTime 0.081537
INFO - ==> Top1: 90.390    Top5: 99.610    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 90.170   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.033557   Top1 98.652344   Top5 100.000000   BatchTime 0.218484   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.034278   Top1 98.710938   Top5 100.000000   BatchTime 0.171732   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.037968   Top1 98.567708   Top5 100.000000   BatchTime 0.155746   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.038911   Top1 98.540039   Top5 100.000000   BatchTime 0.147781   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.039247   Top1 98.562500   Top5 100.000000   BatchTime 0.142977   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.039822   Top1 98.590495   Top5 100.000000   BatchTime 0.139740   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.039876   Top1 98.602121   Top5 100.000000   BatchTime 0.137460   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.039667   Top1 98.627930   Top5 100.000000   BatchTime 0.135745   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.039629   Top1 98.628472   Top5 100.000000   BatchTime 0.134316   LR 0.010000
INFO - ==> Top1: 98.630    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.435744   Top1 90.410156   Top5 99.531250   BatchTime 0.142150
INFO - Validation [3][   40/   40]   Loss 0.426056   Top1 90.490000   Top5 99.610000   BatchTime 0.098830
INFO - ==> Top1: 90.490    Top5: 99.610    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.035181   Top1 98.750000   Top5 100.000000   BatchTime 0.218413   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.034881   Top1 98.681641   Top5 100.000000   BatchTime 0.171318   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.035994   Top1 98.697917   Top5 99.993490   BatchTime 0.155394   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.037283   Top1 98.632812   Top5 99.995117   BatchTime 0.147407   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.038390   Top1 98.640625   Top5 99.992188   BatchTime 0.141409   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.038468   Top1 98.658854   Top5 99.993490   BatchTime 0.132793   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.040092   Top1 98.604911   Top5 99.991629   BatchTime 0.128228   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.040836   Top1 98.583984   Top5 99.992676   BatchTime 0.124684   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.040878   Top1 98.578559   Top5 99.993490   BatchTime 0.121487   LR 0.010000
INFO - ==> Top1: 98.586    Top5: 99.994    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.445881   Top1 90.273438   Top5 99.433594   BatchTime 0.143160
INFO - Validation [4][   40/   40]   Loss 0.431353   Top1 90.250000   Top5 99.570000   BatchTime 0.099861
INFO - ==> Top1: 90.250    Top5: 99.570    Loss: 0.431
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.039981   Top1 98.515625   Top5 100.000000   BatchTime 0.216975   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.040475   Top1 98.593750   Top5 99.990234   BatchTime 0.170272   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.040244   Top1 98.613281   Top5 99.993490   BatchTime 0.156281   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.038894   Top1 98.662109   Top5 99.995117   BatchTime 0.148067   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.038879   Top1 98.632812   Top5 99.996094   BatchTime 0.143168   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.038286   Top1 98.652344   Top5 99.996745   BatchTime 0.139858   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.039080   Top1 98.610491   Top5 99.997210   BatchTime 0.137447   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.038663   Top1 98.652344   Top5 99.997559   BatchTime 0.135686   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.039114   Top1 98.624132   Top5 99.997830   BatchTime 0.134238   LR 0.010000
INFO - ==> Top1: 98.636    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.440643   Top1 90.527344   Top5 99.492188   BatchTime 0.138860
INFO - Validation [5][   40/   40]   Loss 0.427343   Top1 90.710000   Top5 99.580000   BatchTime 0.097288
INFO - ==> Top1: 90.710    Top5: 99.580    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.039057   Top1 98.710938   Top5 100.000000   BatchTime 0.218369   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.040087   Top1 98.642578   Top5 100.000000   BatchTime 0.172016   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.041739   Top1 98.561198   Top5 100.000000   BatchTime 0.143628   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.039694   Top1 98.652344   Top5 100.000000   BatchTime 0.133802   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.040155   Top1 98.660156   Top5 100.000000   BatchTime 0.127324   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.040291   Top1 98.658854   Top5 100.000000   BatchTime 0.122775   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.040132   Top1 98.652344   Top5 100.000000   BatchTime 0.119771   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.039495   Top1 98.684082   Top5 100.000000   BatchTime 0.120247   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.039604   Top1 98.682726   Top5 100.000000   BatchTime 0.120612   LR 0.010000
INFO - ==> Top1: 98.654    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.442836   Top1 90.468750   Top5 99.531250   BatchTime 0.143506
INFO - Validation [6][   40/   40]   Loss 0.434453   Top1 90.440000   Top5 99.610000   BatchTime 0.099757
INFO - ==> Top1: 90.440    Top5: 99.610    Loss: 0.434
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 90.440   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.034204   Top1 98.867188   Top5 100.000000   BatchTime 0.217913   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.035197   Top1 98.798828   Top5 100.000000   BatchTime 0.170642   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.035207   Top1 98.769531   Top5 100.000000   BatchTime 0.154912   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.035838   Top1 98.759766   Top5 99.995117   BatchTime 0.147196   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.036160   Top1 98.730469   Top5 99.996094   BatchTime 0.142398   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.036127   Top1 98.717448   Top5 99.996745   BatchTime 0.139305   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.036076   Top1 98.727679   Top5 99.997210   BatchTime 0.137069   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.036817   Top1 98.696289   Top5 99.997559   BatchTime 0.135380   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.036568   Top1 98.702257   Top5 99.997830   BatchTime 0.134016   LR 0.010000
INFO - ==> Top1: 98.714    Top5: 99.998    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.443434   Top1 90.253906   Top5 99.472656   BatchTime 0.142423
INFO - Validation [7][   40/   40]   Loss 0.435011   Top1 90.400000   Top5 99.550000   BatchTime 0.099406
INFO - ==> Top1: 90.400    Top5: 99.550    Loss: 0.435
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 90.440   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.032443   Top1 98.828125   Top5 100.000000   BatchTime 0.203484   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.033900   Top1 98.847656   Top5 100.000000   BatchTime 0.153041   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.034640   Top1 98.802083   Top5 100.000000   BatchTime 0.136673   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.034802   Top1 98.789062   Top5 100.000000   BatchTime 0.125234   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.033571   Top1 98.851562   Top5 100.000000   BatchTime 0.125039   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.034219   Top1 98.831380   Top5 100.000000   BatchTime 0.124873   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.034603   Top1 98.803013   Top5 100.000000   BatchTime 0.124622   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.035121   Top1 98.781738   Top5 100.000000   BatchTime 0.124443   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.035748   Top1 98.765191   Top5 100.000000   BatchTime 0.124300   LR 0.010000
INFO - ==> Top1: 98.764    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.448289   Top1 90.078125   Top5 99.433594   BatchTime 0.143605
INFO - Validation [8][   40/   40]   Loss 0.435918   Top1 90.290000   Top5 99.540000   BatchTime 0.099742
INFO - ==> Top1: 90.290    Top5: 99.540    Loss: 0.436
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 90.440   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.035072   Top1 98.789062   Top5 99.980469   BatchTime 0.217234   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.036125   Top1 98.779297   Top5 99.990234   BatchTime 0.170538   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.037315   Top1 98.756510   Top5 99.993490   BatchTime 0.156628   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.037025   Top1 98.769531   Top5 99.995117   BatchTime 0.148242   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.037700   Top1 98.746094   Top5 99.996094   BatchTime 0.143340   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.037497   Top1 98.750000   Top5 99.996745   BatchTime 0.140147   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.036978   Top1 98.766741   Top5 99.997210   BatchTime 0.137830   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.036171   Top1 98.793945   Top5 99.997559   BatchTime 0.135668   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.035691   Top1 98.817274   Top5 99.997830   BatchTime 0.134208   LR 0.010000
INFO - ==> Top1: 98.810    Top5: 99.998    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.452233   Top1 90.351562   Top5 99.511719   BatchTime 0.135895
INFO - Validation [9][   40/   40]   Loss 0.433553   Top1 90.460000   Top5 99.600000   BatchTime 0.089311
INFO - ==> Top1: 90.460    Top5: 99.600    Loss: 0.434
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 90.460   Top5: 99.600] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.033538   Top1 98.730469   Top5 100.000000   BatchTime 0.201648   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.032217   Top1 98.837891   Top5 100.000000   BatchTime 0.162839   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.034252   Top1 98.808594   Top5 100.000000   BatchTime 0.149706   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.036621   Top1 98.754883   Top5 100.000000   BatchTime 0.143216   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.036637   Top1 98.730469   Top5 100.000000   BatchTime 0.139363   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.036554   Top1 98.733724   Top5 100.000000   BatchTime 0.136783   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.036318   Top1 98.744420   Top5 100.000000   BatchTime 0.135007   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.036137   Top1 98.735352   Top5 100.000000   BatchTime 0.133505   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.036504   Top1 98.721788   Top5 100.000000   BatchTime 0.132300   LR 0.010000
INFO - ==> Top1: 98.718    Top5: 100.000    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.447884   Top1 90.058594   Top5 99.492188   BatchTime 0.144929
INFO - Validation [10][   40/   40]   Loss 0.436141   Top1 90.280000   Top5 99.590000   BatchTime 0.100449
INFO - ==> Top1: 90.280    Top5: 99.590    Loss: 0.436
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 90.460   Top5: 99.600] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.035348   Top1 98.730469   Top5 100.000000   BatchTime 0.218763   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.034937   Top1 98.779297   Top5 100.000000   BatchTime 0.171084   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.034700   Top1 98.795573   Top5 100.000000   BatchTime 0.155259   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.034703   Top1 98.793945   Top5 100.000000   BatchTime 0.147301   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.035721   Top1 98.765625   Top5 100.000000   BatchTime 0.142364   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.035924   Top1 98.736979   Top5 100.000000   BatchTime 0.139202   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.035599   Top1 98.736049   Top5 100.000000   BatchTime 0.136129   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.034858   Top1 98.789062   Top5 100.000000   BatchTime 0.130460   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.035510   Top1 98.743490   Top5 100.000000   BatchTime 0.127231   LR 0.010000
INFO - ==> Top1: 98.750    Top5: 100.000    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.450426   Top1 90.097656   Top5 99.550781   BatchTime 0.133185
INFO - Validation [11][   40/   40]   Loss 0.441413   Top1 90.260000   Top5 99.600000   BatchTime 0.095037
INFO - ==> Top1: 90.260    Top5: 99.600    Loss: 0.441
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 90.460   Top5: 99.600] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.038802   Top1 98.671875   Top5 99.980469   BatchTime 0.220300   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.035047   Top1 98.798828   Top5 99.990234   BatchTime 0.172041   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.036153   Top1 98.750000   Top5 99.993490   BatchTime 0.155785   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.036249   Top1 98.759766   Top5 99.990234   BatchTime 0.147733   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.034537   Top1 98.863281   Top5 99.992188   BatchTime 0.142972   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.035930   Top1 98.792318   Top5 99.993490   BatchTime 0.139835   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.036318   Top1 98.772321   Top5 99.994420   BatchTime 0.137484   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.035985   Top1 98.774414   Top5 99.995117   BatchTime 0.135694   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.035805   Top1 98.763021   Top5 99.995660   BatchTime 0.134244   LR 0.010000
INFO - ==> Top1: 98.752    Top5: 99.996    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.447702   Top1 90.292969   Top5 99.531250   BatchTime 0.144153
INFO - Validation [12][   40/   40]   Loss 0.427656   Top1 90.490000   Top5 99.630000   BatchTime 0.099711
INFO - ==> Top1: 90.490    Top5: 99.630    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.028067   Top1 99.003906   Top5 100.000000   BatchTime 0.217542   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.029725   Top1 98.906250   Top5 100.000000   BatchTime 0.170581   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.032731   Top1 98.776042   Top5 100.000000   BatchTime 0.156236   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.033022   Top1 98.750000   Top5 100.000000   BatchTime 0.148073   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.034506   Top1 98.714844   Top5 100.000000   BatchTime 0.136644   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.034459   Top1 98.740234   Top5 100.000000   BatchTime 0.131254   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.033797   Top1 98.783482   Top5 100.000000   BatchTime 0.126976   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.034394   Top1 98.769531   Top5 100.000000   BatchTime 0.123469   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.034962   Top1 98.765191   Top5 100.000000   BatchTime 0.119942   LR 0.010000
INFO - ==> Top1: 98.750    Top5: 100.000    Loss: 0.035
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.452017   Top1 90.234375   Top5 99.531250   BatchTime 0.142132
INFO - Validation [13][   40/   40]   Loss 0.438522   Top1 90.490000   Top5 99.590000   BatchTime 0.098722
INFO - ==> Top1: 90.490    Top5: 99.590    Loss: 0.439
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.031665   Top1 98.925781   Top5 100.000000   BatchTime 0.219620   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.031836   Top1 98.886719   Top5 100.000000   BatchTime 0.171183   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.032669   Top1 98.854167   Top5 100.000000   BatchTime 0.155293   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.032638   Top1 98.842773   Top5 100.000000   BatchTime 0.147369   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.033373   Top1 98.781250   Top5 100.000000   BatchTime 0.142596   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.033057   Top1 98.798828   Top5 100.000000   BatchTime 0.139402   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.032965   Top1 98.836496   Top5 100.000000   BatchTime 0.137202   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.033318   Top1 98.840332   Top5 100.000000   BatchTime 0.135393   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.033822   Top1 98.819444   Top5 99.997830   BatchTime 0.134031   LR 0.010000
INFO - ==> Top1: 98.810    Top5: 99.998    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.464042   Top1 89.824219   Top5 99.433594   BatchTime 0.142847
INFO - Validation [14][   40/   40]   Loss 0.448392   Top1 90.180000   Top5 99.520000   BatchTime 0.098805
INFO - ==> Top1: 90.180    Top5: 99.520    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.030246   Top1 99.101562   Top5 100.000000   BatchTime 0.217473   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.031888   Top1 98.964844   Top5 100.000000   BatchTime 0.162739   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.031434   Top1 98.886719   Top5 100.000000   BatchTime 0.140755   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.031298   Top1 98.906250   Top5 100.000000   BatchTime 0.131095   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.031459   Top1 98.933594   Top5 100.000000   BatchTime 0.125220   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.032455   Top1 98.883464   Top5 100.000000   BatchTime 0.119566   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.033025   Top1 98.861607   Top5 100.000000   BatchTime 0.119825   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.033572   Top1 98.833008   Top5 100.000000   BatchTime 0.120248   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.033397   Top1 98.847656   Top5 100.000000   BatchTime 0.120580   LR 0.010000
INFO - ==> Top1: 98.840    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.466704   Top1 90.039062   Top5 99.453125   BatchTime 0.144193
INFO - Validation [15][   40/   40]   Loss 0.447945   Top1 90.370000   Top5 99.520000   BatchTime 0.101032
INFO - ==> Top1: 90.370    Top5: 99.520    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.033567   Top1 98.925781   Top5 100.000000   BatchTime 0.217002   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.034974   Top1 98.876953   Top5 99.990234   BatchTime 0.170186   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.034139   Top1 98.854167   Top5 99.993490   BatchTime 0.154641   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.035834   Top1 98.779297   Top5 99.995117   BatchTime 0.147063   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.037097   Top1 98.714844   Top5 99.996094   BatchTime 0.142418   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.036720   Top1 98.740234   Top5 99.996745   BatchTime 0.139291   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.036506   Top1 98.741629   Top5 99.997210   BatchTime 0.137028   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.035778   Top1 98.774414   Top5 99.997559   BatchTime 0.135264   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.035987   Top1 98.778212   Top5 99.997830   BatchTime 0.133916   LR 0.010000
INFO - ==> Top1: 98.796    Top5: 99.998    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.477535   Top1 89.472656   Top5 99.589844   BatchTime 0.142713
INFO - Validation [16][   40/   40]   Loss 0.453381   Top1 90.070000   Top5 99.620000   BatchTime 0.097587
INFO - ==> Top1: 90.070    Top5: 99.620    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.032903   Top1 98.808594   Top5 100.000000   BatchTime 0.202640   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.033888   Top1 98.779297   Top5 100.000000   BatchTime 0.152095   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.031846   Top1 98.912760   Top5 100.000000   BatchTime 0.132164   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.033534   Top1 98.833008   Top5 100.000000   BatchTime 0.128129   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.032874   Top1 98.863281   Top5 100.000000   BatchTime 0.128209   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.033093   Top1 98.876953   Top5 100.000000   BatchTime 0.127446   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.032786   Top1 98.903460   Top5 100.000000   BatchTime 0.126903   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.032659   Top1 98.913574   Top5 100.000000   BatchTime 0.126463   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.032126   Top1 98.936632   Top5 100.000000   BatchTime 0.126094   LR 0.010000
INFO - ==> Top1: 98.922    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.466033   Top1 89.687500   Top5 99.394531   BatchTime 0.141815
INFO - Validation [17][   40/   40]   Loss 0.451392   Top1 90.240000   Top5 99.510000   BatchTime 0.099367
INFO - ==> Top1: 90.240    Top5: 99.510    Loss: 0.451
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.035696   Top1 98.789062   Top5 100.000000   BatchTime 0.217339   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.033335   Top1 98.886719   Top5 100.000000   BatchTime 0.170543   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.031907   Top1 98.906250   Top5 100.000000   BatchTime 0.155323   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.032086   Top1 98.886719   Top5 100.000000   BatchTime 0.147219   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.032881   Top1 98.867188   Top5 100.000000   BatchTime 0.142531   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.033079   Top1 98.821615   Top5 100.000000   BatchTime 0.139427   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.033268   Top1 98.830915   Top5 100.000000   BatchTime 0.137073   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.032914   Top1 98.842773   Top5 99.997559   BatchTime 0.135204   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.032477   Top1 98.867188   Top5 99.997830   BatchTime 0.133785   LR 0.010000
INFO - ==> Top1: 98.870    Top5: 99.998    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.465007   Top1 89.882812   Top5 99.492188   BatchTime 0.133582
INFO - Validation [18][   40/   40]   Loss 0.448706   Top1 90.380000   Top5 99.610000   BatchTime 0.088085
INFO - ==> Top1: 90.380    Top5: 99.610    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.029661   Top1 98.925781   Top5 100.000000   BatchTime 0.228282   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.027248   Top1 99.033203   Top5 100.000000   BatchTime 0.176169   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.030007   Top1 98.951823   Top5 100.000000   BatchTime 0.158640   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.028607   Top1 99.062500   Top5 100.000000   BatchTime 0.149862   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.028596   Top1 99.039062   Top5 100.000000   BatchTime 0.144908   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.029100   Top1 99.023438   Top5 100.000000   BatchTime 0.141388   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.028838   Top1 99.023438   Top5 100.000000   BatchTime 0.138902   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.029534   Top1 99.001465   Top5 100.000000   BatchTime 0.136947   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.030349   Top1 98.977865   Top5 100.000000   BatchTime 0.135387   LR 0.010000
INFO - ==> Top1: 98.984    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.460573   Top1 90.175781   Top5 99.472656   BatchTime 0.141114
INFO - Validation [19][   40/   40]   Loss 0.454406   Top1 90.270000   Top5 99.560000   BatchTime 0.098733
INFO - ==> Top1: 90.270    Top5: 99.560    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.027084   Top1 99.062500   Top5 100.000000   BatchTime 0.220492   LR 0.010000
INFO - Training [20][   40/  196]   Loss 0.028055   Top1 98.945312   Top5 100.000000   BatchTime 0.172645   LR 0.010000
INFO - Training [20][   60/  196]   Loss 0.031037   Top1 98.886719   Top5 100.000000   BatchTime 0.156880   LR 0.010000
INFO - Training [20][   80/  196]   Loss 0.032746   Top1 98.828125   Top5 100.000000   BatchTime 0.148545   LR 0.010000
INFO - Training [20][  100/  196]   Loss 0.031158   Top1 98.882812   Top5 100.000000   BatchTime 0.143510   LR 0.010000
INFO - Training [20][  120/  196]   Loss 0.031367   Top1 98.876953   Top5 99.996745   BatchTime 0.140140   LR 0.010000
INFO - Training [20][  140/  196]   Loss 0.032011   Top1 98.864397   Top5 99.997210   BatchTime 0.133677   LR 0.010000
INFO - Training [20][  160/  196]   Loss 0.031652   Top1 98.894043   Top5 99.997559   BatchTime 0.129339   LR 0.010000
INFO - Training [20][  180/  196]   Loss 0.031920   Top1 98.882378   Top5 99.997830   BatchTime 0.126129   LR 0.010000
INFO - ==> Top1: 98.872    Top5: 99.998    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.475492   Top1 89.746094   Top5 99.433594   BatchTime 0.141221
INFO - Validation [20][   40/   40]   Loss 0.453262   Top1 90.110000   Top5 99.550000   BatchTime 0.099260
INFO - ==> Top1: 90.110    Top5: 99.550    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.030876   Top1 99.101562   Top5 100.000000   BatchTime 0.216769   LR 0.010000
INFO - Training [21][   40/  196]   Loss 0.032583   Top1 98.955078   Top5 100.000000   BatchTime 0.170013   LR 0.010000
INFO - Training [21][   60/  196]   Loss 0.031984   Top1 98.912760   Top5 100.000000   BatchTime 0.154302   LR 0.010000
INFO - Training [21][   80/  196]   Loss 0.031462   Top1 98.906250   Top5 100.000000   BatchTime 0.146547   LR 0.010000
INFO - Training [21][  100/  196]   Loss 0.031341   Top1 98.906250   Top5 100.000000   BatchTime 0.141961   LR 0.010000
INFO - Training [21][  120/  196]   Loss 0.030640   Top1 98.925781   Top5 100.000000   BatchTime 0.138968   LR 0.010000
INFO - Training [21][  140/  196]   Loss 0.029848   Top1 98.962054   Top5 100.000000   BatchTime 0.137377   LR 0.010000
INFO - Training [21][  160/  196]   Loss 0.030266   Top1 98.928223   Top5 100.000000   BatchTime 0.135579   LR 0.010000
INFO - Training [21][  180/  196]   Loss 0.030406   Top1 98.925781   Top5 100.000000   BatchTime 0.134194   LR 0.010000
INFO - ==> Top1: 98.894    Top5: 100.000    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.489961   Top1 90.136719   Top5 99.394531   BatchTime 0.142008
INFO - Validation [21][   40/   40]   Loss 0.467026   Top1 90.320000   Top5 99.540000   BatchTime 0.099105
INFO - ==> Top1: 90.320    Top5: 99.540    Loss: 0.467
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.029385   Top1 99.023438   Top5 100.000000   BatchTime 0.218950   LR 0.010000
INFO - Training [22][   40/  196]   Loss 0.027623   Top1 99.033203   Top5 100.000000   BatchTime 0.171263   LR 0.010000
INFO - Training [22][   60/  196]   Loss 0.027115   Top1 99.055990   Top5 100.000000   BatchTime 0.155088   LR 0.010000
INFO - Training [22][   80/  196]   Loss 0.028389   Top1 98.974609   Top5 100.000000   BatchTime 0.146197   LR 0.010000
INFO - Training [22][  100/  196]   Loss 0.028883   Top1 98.968750   Top5 100.000000   BatchTime 0.135486   LR 0.010000
INFO - Training [22][  120/  196]   Loss 0.028149   Top1 99.013672   Top5 100.000000   BatchTime 0.129969   LR 0.010000
INFO - Training [22][  140/  196]   Loss 0.028564   Top1 99.001116   Top5 100.000000   BatchTime 0.125914   LR 0.010000
INFO - Training [22][  160/  196]   Loss 0.029154   Top1 98.984375   Top5 100.000000   BatchTime 0.121979   LR 0.010000
INFO - Training [22][  180/  196]   Loss 0.029641   Top1 98.962674   Top5 100.000000   BatchTime 0.120102   LR 0.010000
INFO - ==> Top1: 98.918    Top5: 100.000    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.478536   Top1 89.765625   Top5 99.531250   BatchTime 0.143018
INFO - Validation [22][   40/   40]   Loss 0.456180   Top1 90.250000   Top5 99.610000   BatchTime 0.099105
INFO - ==> Top1: 90.250    Top5: 99.610    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.033639   Top1 98.886719   Top5 100.000000   BatchTime 0.220192   LR 0.010000
INFO - Training [23][   40/  196]   Loss 0.033858   Top1 98.886719   Top5 100.000000   BatchTime 0.172078   LR 0.010000
INFO - Training [23][   60/  196]   Loss 0.031415   Top1 98.964844   Top5 100.000000   BatchTime 0.156109   LR 0.010000
INFO - Training [23][   80/  196]   Loss 0.030582   Top1 98.994141   Top5 99.995117   BatchTime 0.148298   LR 0.010000
INFO - Training [23][  100/  196]   Loss 0.029807   Top1 99.031250   Top5 99.996094   BatchTime 0.143291   LR 0.010000
INFO - Training [23][  120/  196]   Loss 0.030722   Top1 99.007161   Top5 99.996745   BatchTime 0.139920   LR 0.010000
INFO - Training [23][  140/  196]   Loss 0.030723   Top1 98.973214   Top5 99.997210   BatchTime 0.137569   LR 0.010000
INFO - Training [23][  160/  196]   Loss 0.030575   Top1 98.977051   Top5 99.995117   BatchTime 0.135701   LR 0.010000
INFO - Training [23][  180/  196]   Loss 0.030894   Top1 98.962674   Top5 99.995660   BatchTime 0.134284   LR 0.010000
INFO - ==> Top1: 98.940    Top5: 99.996    Loss: 0.031
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.463593   Top1 89.921875   Top5 99.453125   BatchTime 0.143300
INFO - Validation [23][   40/   40]   Loss 0.449620   Top1 90.320000   Top5 99.590000   BatchTime 0.099608
INFO - ==> Top1: 90.320    Top5: 99.590    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.025383   Top1 99.082031   Top5 100.000000   BatchTime 0.215528   LR 0.010000
INFO - Training [24][   40/  196]   Loss 0.023869   Top1 99.179688   Top5 100.000000   BatchTime 0.155147   LR 0.010000
INFO - Training [24][   60/  196]   Loss 0.025568   Top1 99.108073   Top5 100.000000   BatchTime 0.137158   LR 0.010000
INFO - Training [24][   80/  196]   Loss 0.026802   Top1 99.067383   Top5 100.000000   BatchTime 0.128403   LR 0.010000
INFO - Training [24][  100/  196]   Loss 0.027533   Top1 99.031250   Top5 100.000000   BatchTime 0.123246   LR 0.010000
INFO - Training [24][  120/  196]   Loss 0.028397   Top1 99.020182   Top5 99.996745   BatchTime 0.118459   LR 0.010000
INFO - Training [24][  140/  196]   Loss 0.027856   Top1 99.034598   Top5 99.997210   BatchTime 0.119294   LR 0.010000
INFO - Training [24][  160/  196]   Loss 0.028331   Top1 99.018555   Top5 99.997559   BatchTime 0.119723   LR 0.010000
INFO - Training [24][  180/  196]   Loss 0.028873   Top1 98.993056   Top5 99.997830   BatchTime 0.120083   LR 0.010000
INFO - ==> Top1: 98.988    Top5: 99.998    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.464884   Top1 90.117188   Top5 99.492188   BatchTime 0.141827
INFO - Validation [24][   40/   40]   Loss 0.447492   Top1 90.480000   Top5 99.610000   BatchTime 0.098238
INFO - ==> Top1: 90.480    Top5: 99.610    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.028452   Top1 99.062500   Top5 100.000000   BatchTime 0.217774   LR 0.010000
INFO - Training [25][   40/  196]   Loss 0.027489   Top1 99.082031   Top5 100.000000   BatchTime 0.170700   LR 0.010000
INFO - Training [25][   60/  196]   Loss 0.030105   Top1 98.951823   Top5 100.000000   BatchTime 0.155271   LR 0.010000
INFO - Training [25][   80/  196]   Loss 0.029755   Top1 98.940430   Top5 100.000000   BatchTime 0.147377   LR 0.010000
INFO - Training [25][  100/  196]   Loss 0.029538   Top1 98.972656   Top5 100.000000   BatchTime 0.142608   LR 0.010000
INFO - Training [25][  120/  196]   Loss 0.029413   Top1 98.987630   Top5 100.000000   BatchTime 0.139493   LR 0.010000
INFO - Training [25][  140/  196]   Loss 0.028931   Top1 98.998326   Top5 100.000000   BatchTime 0.137192   LR 0.010000
INFO - Training [25][  160/  196]   Loss 0.029390   Top1 98.977051   Top5 100.000000   BatchTime 0.135398   LR 0.010000
INFO - Training [25][  180/  196]   Loss 0.029292   Top1 98.980035   Top5 100.000000   BatchTime 0.134064   LR 0.010000
INFO - ==> Top1: 98.972    Top5: 100.000    Loss: 0.029
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.477746   Top1 89.941406   Top5 99.531250   BatchTime 0.143390
INFO - Validation [25][   40/   40]   Loss 0.464094   Top1 90.320000   Top5 99.600000   BatchTime 0.096708
INFO - ==> Top1: 90.320    Top5: 99.600    Loss: 0.464
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.026424   Top1 99.042969   Top5 100.000000   BatchTime 0.208537   LR 0.010000
INFO - Training [26][   40/  196]   Loss 0.025325   Top1 99.091797   Top5 100.000000   BatchTime 0.156707   LR 0.010000
INFO - Training [26][   60/  196]   Loss 0.024799   Top1 99.134115   Top5 100.000000   BatchTime 0.134242   LR 0.010000
INFO - Training [26][   80/  196]   Loss 0.026649   Top1 99.057617   Top5 100.000000   BatchTime 0.131039   LR 0.010000
INFO - Training [26][  100/  196]   Loss 0.026517   Top1 99.085938   Top5 100.000000   BatchTime 0.129538   LR 0.010000
INFO - Training [26][  120/  196]   Loss 0.027229   Top1 99.049479   Top5 100.000000   BatchTime 0.128515   LR 0.010000
INFO - Training [26][  140/  196]   Loss 0.027549   Top1 99.031808   Top5 100.000000   BatchTime 0.127773   LR 0.010000
INFO - Training [26][  160/  196]   Loss 0.027918   Top1 99.025879   Top5 100.000000   BatchTime 0.127205   LR 0.010000
INFO - Training [26][  180/  196]   Loss 0.027976   Top1 99.012587   Top5 100.000000   BatchTime 0.126821   LR 0.010000
INFO - ==> Top1: 99.008    Top5: 100.000    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.463764   Top1 90.449219   Top5 99.453125   BatchTime 0.143659
INFO - Validation [26][   40/   40]   Loss 0.459129   Top1 90.480000   Top5 99.560000   BatchTime 0.099337
INFO - ==> Top1: 90.480    Top5: 99.560    Loss: 0.459
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.027537   Top1 98.984375   Top5 100.000000   BatchTime 0.219686   LR 0.010000
INFO - Training [27][   40/  196]   Loss 0.025075   Top1 99.082031   Top5 100.000000   BatchTime 0.171809   LR 0.010000
INFO - Training [27][   60/  196]   Loss 0.027760   Top1 99.003906   Top5 100.000000   BatchTime 0.155704   LR 0.010000
INFO - Training [27][   80/  196]   Loss 0.027625   Top1 99.003906   Top5 100.000000   BatchTime 0.147621   LR 0.010000
INFO - Training [27][  100/  196]   Loss 0.026625   Top1 99.035156   Top5 100.000000   BatchTime 0.142818   LR 0.010000
INFO - Training [27][  120/  196]   Loss 0.027639   Top1 99.020182   Top5 100.000000   BatchTime 0.139613   LR 0.010000
INFO - Training [27][  140/  196]   Loss 0.027156   Top1 99.040179   Top5 100.000000   BatchTime 0.137221   LR 0.010000
INFO - Training [27][  160/  196]   Loss 0.027637   Top1 99.035645   Top5 100.000000   BatchTime 0.135372   LR 0.010000
INFO - Training [27][  180/  196]   Loss 0.027251   Top1 99.042969   Top5 100.000000   BatchTime 0.133971   LR 0.010000
INFO - ==> Top1: 99.024    Top5: 100.000    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.481411   Top1 90.078125   Top5 99.394531   BatchTime 0.132858
INFO - Validation [27][   40/   40]   Loss 0.466874   Top1 90.430000   Top5 99.500000   BatchTime 0.087950
INFO - ==> Top1: 90.430    Top5: 99.500    Loss: 0.467
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.027531   Top1 98.984375   Top5 100.000000   BatchTime 0.224014   LR 0.010000
INFO - Training [28][   40/  196]   Loss 0.028661   Top1 98.994141   Top5 100.000000   BatchTime 0.173658   LR 0.010000
INFO - Training [28][   60/  196]   Loss 0.028901   Top1 98.984375   Top5 100.000000   BatchTime 0.157034   LR 0.010000
INFO - Training [28][   80/  196]   Loss 0.028902   Top1 98.989258   Top5 100.000000   BatchTime 0.148679   LR 0.010000
INFO - Training [28][  100/  196]   Loss 0.028866   Top1 98.945312   Top5 100.000000   BatchTime 0.143694   LR 0.010000
INFO - Training [28][  120/  196]   Loss 0.030224   Top1 98.896484   Top5 100.000000   BatchTime 0.140401   LR 0.010000
INFO - Training [28][  140/  196]   Loss 0.030055   Top1 98.889509   Top5 100.000000   BatchTime 0.138090   LR 0.010000
INFO - Training [28][  160/  196]   Loss 0.029405   Top1 98.925781   Top5 100.000000   BatchTime 0.136247   LR 0.010000
INFO - Training [28][  180/  196]   Loss 0.029647   Top1 98.912760   Top5 99.997830   BatchTime 0.134812   LR 0.010000
INFO - ==> Top1: 98.928    Top5: 99.998    Loss: 0.030
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.474316   Top1 89.960938   Top5 99.355469   BatchTime 0.144042
INFO - Validation [28][   40/   40]   Loss 0.459344   Top1 90.400000   Top5 99.500000   BatchTime 0.100116
INFO - ==> Top1: 90.400    Top5: 99.500    Loss: 0.459
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.024823   Top1 99.082031   Top5 100.000000   BatchTime 0.219489   LR 0.010000
INFO - Training [29][   40/  196]   Loss 0.025960   Top1 99.013672   Top5 100.000000   BatchTime 0.171721   LR 0.010000
INFO - Training [29][   60/  196]   Loss 0.025230   Top1 99.055990   Top5 100.000000   BatchTime 0.155829   LR 0.010000
INFO - Training [29][   80/  196]   Loss 0.025490   Top1 99.042969   Top5 100.000000   BatchTime 0.147760   LR 0.010000
INFO - Training [29][  100/  196]   Loss 0.026416   Top1 99.035156   Top5 100.000000   BatchTime 0.142965   LR 0.010000
INFO - Training [29][  120/  196]   Loss 0.026460   Top1 99.059245   Top5 100.000000   BatchTime 0.139646   LR 0.010000
INFO - Training [29][  140/  196]   Loss 0.026629   Top1 99.054129   Top5 100.000000   BatchTime 0.133280   LR 0.010000
INFO - Training [29][  160/  196]   Loss 0.026141   Top1 99.086914   Top5 100.000000   BatchTime 0.129108   LR 0.010000
INFO - Training [29][  180/  196]   Loss 0.026402   Top1 99.082031   Top5 100.000000   BatchTime 0.125898   LR 0.010000
INFO - ==> Top1: 99.080    Top5: 100.000    Loss: 0.027
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.481493   Top1 90.195312   Top5 99.335938   BatchTime 0.140046
INFO - Validation [29][   40/   40]   Loss 0.464011   Top1 90.570000   Top5 99.470000   BatchTime 0.097219
INFO - ==> Top1: 90.570    Top5: 99.470    Loss: 0.464
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 90.570   Top5: 99.470] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.028533   Top1 99.023438   Top5 100.000000   BatchTime 0.219712   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.027068   Top1 99.042969   Top5 100.000000   BatchTime 0.174003   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.028456   Top1 98.997396   Top5 100.000000   BatchTime 0.157146   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.027923   Top1 99.033203   Top5 100.000000   BatchTime 0.148663   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.028880   Top1 99.011719   Top5 99.996094   BatchTime 0.143637   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.028264   Top1 99.039714   Top5 99.996745   BatchTime 0.140262   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.028327   Top1 99.059710   Top5 99.994420   BatchTime 0.137850   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.027763   Top1 99.074707   Top5 99.995117   BatchTime 0.135991   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.027719   Top1 99.058160   Top5 99.995660   BatchTime 0.134541   LR 0.001000
INFO - ==> Top1: 99.078    Top5: 99.996    Loss: 0.027
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.463391   Top1 90.546875   Top5 99.335938   BatchTime 0.143054
INFO - Validation [30][   40/   40]   Loss 0.450204   Top1 90.780000   Top5 99.530000   BatchTime 0.098940
INFO - ==> Top1: 90.780    Top5: 99.530    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 90.570   Top5: 99.470] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.029329   Top1 98.984375   Top5 100.000000   BatchTime 0.214929   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.026528   Top1 99.091797   Top5 100.000000   BatchTime 0.169174   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.024227   Top1 99.160156   Top5 100.000000   BatchTime 0.153845   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.023984   Top1 99.174805   Top5 100.000000   BatchTime 0.143630   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.023711   Top1 99.179688   Top5 100.000000   BatchTime 0.133894   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.022958   Top1 99.205729   Top5 100.000000   BatchTime 0.128467   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.022624   Top1 99.204799   Top5 100.000000   BatchTime 0.124530   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.022461   Top1 99.189453   Top5 100.000000   BatchTime 0.120562   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.022916   Top1 99.181858   Top5 100.000000   BatchTime 0.119187   LR 0.001000
INFO - ==> Top1: 99.184    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.461916   Top1 90.800781   Top5 99.414062   BatchTime 0.142039
INFO - Validation [31][   40/   40]   Loss 0.447801   Top1 91.050000   Top5 99.560000   BatchTime 0.099572
INFO - ==> Top1: 91.050    Top5: 99.560    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.020276   Top1 99.296875   Top5 100.000000   BatchTime 0.217955   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.021671   Top1 99.267578   Top5 100.000000   BatchTime 0.170696   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.022663   Top1 99.205729   Top5 99.993490   BatchTime 0.155041   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.022639   Top1 99.218750   Top5 99.995117   BatchTime 0.147314   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.022180   Top1 99.250000   Top5 99.996094   BatchTime 0.142720   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.021809   Top1 99.270833   Top5 99.996745   BatchTime 0.139651   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.022334   Top1 99.241071   Top5 99.997210   BatchTime 0.136993   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.022264   Top1 99.257812   Top5 99.997559   BatchTime 0.135307   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.022425   Top1 99.259983   Top5 99.997830   BatchTime 0.133921   LR 0.001000
INFO - ==> Top1: 99.270    Top5: 99.998    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.464956   Top1 90.351562   Top5 99.453125   BatchTime 0.142922
INFO - Validation [32][   40/   40]   Loss 0.449856   Top1 90.630000   Top5 99.560000   BatchTime 0.099484
INFO - ==> Top1: 90.630    Top5: 99.560    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.020359   Top1 99.335938   Top5 100.000000   BatchTime 0.213911   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.018739   Top1 99.296875   Top5 100.000000   BatchTime 0.151899   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.020357   Top1 99.199219   Top5 100.000000   BatchTime 0.135414   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.022383   Top1 99.145508   Top5 100.000000   BatchTime 0.126770   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.022165   Top1 99.199219   Top5 100.000000   BatchTime 0.121557   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.021678   Top1 99.222005   Top5 100.000000   BatchTime 0.118452   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.021417   Top1 99.238281   Top5 100.000000   BatchTime 0.119129   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.021693   Top1 99.228516   Top5 100.000000   BatchTime 0.119670   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.022028   Top1 99.227431   Top5 100.000000   BatchTime 0.120080   LR 0.001000
INFO - ==> Top1: 99.234    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.459805   Top1 90.781250   Top5 99.472656   BatchTime 0.142164
INFO - Validation [33][   40/   40]   Loss 0.447397   Top1 90.900000   Top5 99.610000   BatchTime 0.097875
INFO - ==> Top1: 90.900    Top5: 99.610    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.019758   Top1 99.414062   Top5 100.000000   BatchTime 0.217774   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.019464   Top1 99.414062   Top5 100.000000   BatchTime 0.170740   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.019280   Top1 99.394531   Top5 100.000000   BatchTime 0.157234   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.020343   Top1 99.370117   Top5 100.000000   BatchTime 0.148935   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.020952   Top1 99.343750   Top5 100.000000   BatchTime 0.143861   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.020112   Top1 99.378255   Top5 100.000000   BatchTime 0.140477   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.020951   Top1 99.327567   Top5 100.000000   BatchTime 0.138055   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.021204   Top1 99.318848   Top5 100.000000   BatchTime 0.136194   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.020906   Top1 99.325087   Top5 100.000000   BatchTime 0.134708   LR 0.001000
INFO - ==> Top1: 99.328    Top5: 100.000    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.465314   Top1 90.507812   Top5 99.375000   BatchTime 0.141652
INFO - Validation [34][   40/   40]   Loss 0.450541   Top1 90.840000   Top5 99.510000   BatchTime 0.089177
INFO - ==> Top1: 90.840    Top5: 99.510    Loss: 0.451
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.024515   Top1 99.257812   Top5 100.000000   BatchTime 0.200655   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.023037   Top1 99.267578   Top5 100.000000   BatchTime 0.150597   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.023680   Top1 99.212240   Top5 100.000000   BatchTime 0.132284   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.023038   Top1 99.223633   Top5 100.000000   BatchTime 0.130247   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.022491   Top1 99.218750   Top5 100.000000   BatchTime 0.128974   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.022567   Top1 99.218750   Top5 100.000000   BatchTime 0.128094   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.021915   Top1 99.249442   Top5 100.000000   BatchTime 0.127429   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.022182   Top1 99.240723   Top5 100.000000   BatchTime 0.126939   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.021894   Top1 99.253472   Top5 100.000000   BatchTime 0.126533   LR 0.001000
INFO - ==> Top1: 99.256    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.459945   Top1 90.253906   Top5 99.453125   BatchTime 0.143351
INFO - Validation [35][   40/   40]   Loss 0.448185   Top1 90.700000   Top5 99.610000   BatchTime 0.099653
INFO - ==> Top1: 90.700    Top5: 99.610    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.019598   Top1 99.355469   Top5 100.000000   BatchTime 0.215754   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.021788   Top1 99.267578   Top5 100.000000   BatchTime 0.169613   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.021949   Top1 99.212240   Top5 100.000000   BatchTime 0.154250   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.022179   Top1 99.233398   Top5 100.000000   BatchTime 0.146573   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.021551   Top1 99.257812   Top5 100.000000   BatchTime 0.141551   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.021306   Top1 99.280599   Top5 100.000000   BatchTime 0.138514   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.021511   Top1 99.271763   Top5 100.000000   BatchTime 0.136289   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.021162   Top1 99.279785   Top5 100.000000   BatchTime 0.134531   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.020970   Top1 99.286024   Top5 100.000000   BatchTime 0.133365   LR 0.001000
INFO - ==> Top1: 99.280    Top5: 100.000    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.459182   Top1 90.449219   Top5 99.433594   BatchTime 0.132053
INFO - Validation [36][   40/   40]   Loss 0.447006   Top1 90.670000   Top5 99.550000   BatchTime 0.087101
INFO - ==> Top1: 90.670    Top5: 99.550    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.021570   Top1 99.355469   Top5 100.000000   BatchTime 0.223175   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.021662   Top1 99.267578   Top5 100.000000   BatchTime 0.173580   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.019985   Top1 99.290365   Top5 100.000000   BatchTime 0.157053   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.020568   Top1 99.282227   Top5 100.000000   BatchTime 0.148771   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.020131   Top1 99.296875   Top5 100.000000   BatchTime 0.143925   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.020025   Top1 99.309896   Top5 100.000000   BatchTime 0.140542   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.020614   Top1 99.296875   Top5 100.000000   BatchTime 0.138146   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.020379   Top1 99.313965   Top5 100.000000   BatchTime 0.136319   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.020311   Top1 99.318576   Top5 100.000000   BatchTime 0.134855   LR 0.001000
INFO - ==> Top1: 99.320    Top5: 100.000    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.462820   Top1 90.292969   Top5 99.472656   BatchTime 0.144553
INFO - Validation [37][   40/   40]   Loss 0.451193   Top1 90.620000   Top5 99.590000   BatchTime 0.101364
INFO - ==> Top1: 90.620    Top5: 99.590    Loss: 0.451
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.016520   Top1 99.394531   Top5 100.000000   BatchTime 0.216330   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.017980   Top1 99.384766   Top5 100.000000   BatchTime 0.169963   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.018345   Top1 99.361979   Top5 100.000000   BatchTime 0.154953   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.019484   Top1 99.316406   Top5 100.000000   BatchTime 0.148764   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.019536   Top1 99.339844   Top5 100.000000   BatchTime 0.143620   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.019162   Top1 99.355469   Top5 100.000000   BatchTime 0.138938   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.019389   Top1 99.355469   Top5 100.000000   BatchTime 0.132320   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.019230   Top1 99.375000   Top5 100.000000   BatchTime 0.128355   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.019101   Top1 99.370660   Top5 100.000000   BatchTime 0.125218   LR 0.001000
INFO - ==> Top1: 99.366    Top5: 100.000    Loss: 0.019
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.464872   Top1 90.312500   Top5 99.453125   BatchTime 0.145244
INFO - Validation [38][   40/   40]   Loss 0.448126   Top1 90.610000   Top5 99.590000   BatchTime 0.100079
INFO - ==> Top1: 90.610    Top5: 99.590    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.017085   Top1 99.453125   Top5 100.000000   BatchTime 0.216379   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.018691   Top1 99.335938   Top5 100.000000   BatchTime 0.169901   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.019198   Top1 99.329427   Top5 100.000000   BatchTime 0.154548   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.019467   Top1 99.360352   Top5 100.000000   BatchTime 0.146825   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.020379   Top1 99.316406   Top5 99.996094   BatchTime 0.142192   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.020436   Top1 99.309896   Top5 99.996745   BatchTime 0.139077   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.020831   Top1 99.302455   Top5 99.997210   BatchTime 0.136819   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.020758   Top1 99.291992   Top5 99.995117   BatchTime 0.135093   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.020835   Top1 99.279514   Top5 99.995660   BatchTime 0.133777   LR 0.001000
INFO - ==> Top1: 99.268    Top5: 99.996    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.462321   Top1 90.332031   Top5 99.511719   BatchTime 0.143499
INFO - Validation [39][   40/   40]   Loss 0.447399   Top1 90.760000   Top5 99.630000   BatchTime 0.099287
INFO - ==> Top1: 90.760    Top5: 99.630    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.022088   Top1 99.414062   Top5 100.000000   BatchTime 0.216872   LR 0.001000
INFO - Training [40][   40/  196]   Loss 0.021890   Top1 99.345703   Top5 100.000000   BatchTime 0.169071   LR 0.001000
INFO - Training [40][   60/  196]   Loss 0.020881   Top1 99.355469   Top5 100.000000   BatchTime 0.153926   LR 0.001000
INFO - Training [40][   80/  196]   Loss 0.020590   Top1 99.360352   Top5 100.000000   BatchTime 0.140600   LR 0.001000
INFO - Training [40][  100/  196]   Loss 0.020363   Top1 99.363281   Top5 100.000000   BatchTime 0.132541   LR 0.001000
INFO - Training [40][  120/  196]   Loss 0.020529   Top1 99.355469   Top5 100.000000   BatchTime 0.127591   LR 0.001000
INFO - Training [40][  140/  196]   Loss 0.020524   Top1 99.338728   Top5 100.000000   BatchTime 0.124313   LR 0.001000
INFO - Training [40][  160/  196]   Loss 0.020243   Top1 99.353027   Top5 100.000000   BatchTime 0.119930   LR 0.001000
INFO - Training [40][  180/  196]   Loss 0.019911   Top1 99.359809   Top5 100.000000   BatchTime 0.120473   LR 0.001000
INFO - ==> Top1: 99.356    Top5: 100.000    Loss: 0.020
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.459816   Top1 90.312500   Top5 99.433594   BatchTime 0.142170
INFO - Validation [40][   40/   40]   Loss 0.444359   Top1 90.730000   Top5 99.570000   BatchTime 0.098542
INFO - ==> Top1: 90.730    Top5: 99.570    Loss: 0.444
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.024416   Top1 99.238281   Top5 100.000000   BatchTime 0.219246   LR 0.001000
INFO - Training [41][   40/  196]   Loss 0.022571   Top1 99.316406   Top5 100.000000   BatchTime 0.171494   LR 0.001000
INFO - Training [41][   60/  196]   Loss 0.023790   Top1 99.238281   Top5 100.000000   BatchTime 0.155783   LR 0.001000
INFO - Training [41][   80/  196]   Loss 0.022560   Top1 99.267578   Top5 100.000000   BatchTime 0.147824   LR 0.001000
INFO - Training [41][  100/  196]   Loss 0.021833   Top1 99.281250   Top5 100.000000   BatchTime 0.143053   LR 0.001000
INFO - Training [41][  120/  196]   Loss 0.021893   Top1 99.251302   Top5 100.000000   BatchTime 0.139895   LR 0.001000
INFO - Training [41][  140/  196]   Loss 0.021541   Top1 99.282924   Top5 100.000000   BatchTime 0.137492   LR 0.001000
INFO - Training [41][  160/  196]   Loss 0.021917   Top1 99.270020   Top5 100.000000   BatchTime 0.135667   LR 0.001000
INFO - Training [41][  180/  196]   Loss 0.022393   Top1 99.251302   Top5 100.000000   BatchTime 0.134285   LR 0.001000
INFO - ==> Top1: 99.264    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.454415   Top1 90.429688   Top5 99.433594   BatchTime 0.142544
INFO - Validation [41][   40/   40]   Loss 0.441744   Top1 90.880000   Top5 99.540000   BatchTime 0.099478
INFO - ==> Top1: 90.880    Top5: 99.540    Loss: 0.442
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 90.880   Top5: 99.540] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.014688   Top1 99.609375   Top5 100.000000   BatchTime 0.199007   LR 0.001000
INFO - Training [42][   40/  196]   Loss 0.017571   Top1 99.384766   Top5 100.000000   BatchTime 0.148205   LR 0.001000
INFO - Training [42][   60/  196]   Loss 0.017761   Top1 99.394531   Top5 100.000000   BatchTime 0.133158   LR 0.001000
INFO - Training [42][   80/  196]   Loss 0.017960   Top1 99.365234   Top5 100.000000   BatchTime 0.126592   LR 0.001000
INFO - Training [42][  100/  196]   Loss 0.017707   Top1 99.386719   Top5 100.000000   BatchTime 0.118641   LR 0.001000
INFO - Training [42][  120/  196]   Loss 0.018270   Top1 99.365234   Top5 100.000000   BatchTime 0.120201   LR 0.001000
INFO - Training [42][  140/  196]   Loss 0.018075   Top1 99.377790   Top5 100.000000   BatchTime 0.120720   LR 0.001000
INFO - Training [42][  160/  196]   Loss 0.018183   Top1 99.370117   Top5 100.000000   BatchTime 0.121003   LR 0.001000
INFO - Training [42][  180/  196]   Loss 0.018026   Top1 99.390191   Top5 100.000000   BatchTime 0.121218   LR 0.001000
INFO - ==> Top1: 99.390    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.460122   Top1 90.449219   Top5 99.453125   BatchTime 0.144079
INFO - Validation [42][   40/   40]   Loss 0.446955   Top1 90.780000   Top5 99.600000   BatchTime 0.100070
INFO - ==> Top1: 90.780    Top5: 99.600    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 90.880   Top5: 99.540] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.018556   Top1 99.394531   Top5 100.000000   BatchTime 0.219302   LR 0.001000
INFO - Training [43][   40/  196]   Loss 0.018502   Top1 99.355469   Top5 100.000000   BatchTime 0.171298   LR 0.001000
INFO - Training [43][   60/  196]   Loss 0.018827   Top1 99.394531   Top5 100.000000   BatchTime 0.155542   LR 0.001000
INFO - Training [43][   80/  196]   Loss 0.019694   Top1 99.375000   Top5 100.000000   BatchTime 0.147581   LR 0.001000
INFO - Training [43][  100/  196]   Loss 0.019779   Top1 99.367188   Top5 100.000000   BatchTime 0.142877   LR 0.001000
INFO - Training [43][  120/  196]   Loss 0.019588   Top1 99.348958   Top5 100.000000   BatchTime 0.139766   LR 0.001000
INFO - Training [43][  140/  196]   Loss 0.019716   Top1 99.335938   Top5 100.000000   BatchTime 0.137446   LR 0.001000
INFO - Training [43][  160/  196]   Loss 0.020098   Top1 99.333496   Top5 100.000000   BatchTime 0.135661   LR 0.001000
INFO - Training [43][  180/  196]   Loss 0.020173   Top1 99.338108   Top5 100.000000   BatchTime 0.134178   LR 0.001000
INFO - ==> Top1: 99.336    Top5: 100.000    Loss: 0.020
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.466644   Top1 90.546875   Top5 99.433594   BatchTime 0.127770
INFO - Validation [43][   40/   40]   Loss 0.450326   Top1 90.730000   Top5 99.540000   BatchTime 0.081381
INFO - ==> Top1: 90.730    Top5: 99.540    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 90.880   Top5: 99.540] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.015043   Top1 99.492188   Top5 100.000000   BatchTime 0.201185   LR 0.001000
INFO - Training [44][   40/  196]   Loss 0.017716   Top1 99.404297   Top5 100.000000   BatchTime 0.145871   LR 0.001000
INFO - Training [44][   60/  196]   Loss 0.019627   Top1 99.368490   Top5 100.000000   BatchTime 0.138425   LR 0.001000
INFO - Training [44][   80/  196]   Loss 0.019933   Top1 99.321289   Top5 100.000000   BatchTime 0.134854   LR 0.001000
INFO - Training [44][  100/  196]   Loss 0.020254   Top1 99.343750   Top5 100.000000   BatchTime 0.132611   LR 0.001000
INFO - Training [44][  120/  196]   Loss 0.019713   Top1 99.345703   Top5 100.000000   BatchTime 0.131177   LR 0.001000
INFO - Training [44][  140/  196]   Loss 0.019772   Top1 99.355469   Top5 100.000000   BatchTime 0.129999   LR 0.001000
INFO - Training [44][  160/  196]   Loss 0.019817   Top1 99.353027   Top5 100.000000   BatchTime 0.129104   LR 0.001000
INFO - Training [44][  180/  196]   Loss 0.020013   Top1 99.335938   Top5 100.000000   BatchTime 0.128449   LR 0.001000
INFO - ==> Top1: 99.340    Top5: 100.000    Loss: 0.020
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.458927   Top1 90.781250   Top5 99.472656   BatchTime 0.141685
INFO - Validation [44][   40/   40]   Loss 0.445720   Top1 90.920000   Top5 99.610000   BatchTime 0.097906
INFO - ==> Top1: 90.920    Top5: 99.610    Loss: 0.446
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.021074   Top1 99.296875   Top5 100.000000   BatchTime 0.218308   LR 0.001000
INFO - Training [45][   40/  196]   Loss 0.021017   Top1 99.316406   Top5 100.000000   BatchTime 0.171129   LR 0.001000
INFO - Training [45][   60/  196]   Loss 0.020500   Top1 99.309896   Top5 100.000000   BatchTime 0.155397   LR 0.001000
INFO - Training [45][   80/  196]   Loss 0.019879   Top1 99.335938   Top5 100.000000   BatchTime 0.147393   LR 0.001000
INFO - Training [45][  100/  196]   Loss 0.019394   Top1 99.332031   Top5 100.000000   BatchTime 0.142745   LR 0.001000
INFO - Training [45][  120/  196]   Loss 0.018986   Top1 99.378255   Top5 100.000000   BatchTime 0.139477   LR 0.001000
INFO - Training [45][  140/  196]   Loss 0.018804   Top1 99.377790   Top5 100.000000   BatchTime 0.137071   LR 0.001000
INFO - Training [45][  160/  196]   Loss 0.018751   Top1 99.394531   Top5 100.000000   BatchTime 0.135259   LR 0.001000
INFO - Training [45][  180/  196]   Loss 0.018707   Top1 99.390191   Top5 100.000000   BatchTime 0.130572   LR 0.001000
INFO - ==> Top1: 99.388    Top5: 100.000    Loss: 0.019
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.464469   Top1 90.664062   Top5 99.492188   BatchTime 0.128361
INFO - Validation [45][   40/   40]   Loss 0.449046   Top1 90.900000   Top5 99.550000   BatchTime 0.081342
INFO - ==> Top1: 90.900    Top5: 99.550    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.015988   Top1 99.511719   Top5 100.000000   BatchTime 0.220396   LR 0.001000
INFO - Training [46][   40/  196]   Loss 0.016377   Top1 99.482422   Top5 100.000000   BatchTime 0.171911   LR 0.001000
INFO - Training [46][   60/  196]   Loss 0.016186   Top1 99.466146   Top5 100.000000   BatchTime 0.156150   LR 0.001000
INFO - Training [46][   80/  196]   Loss 0.016241   Top1 99.467773   Top5 100.000000   BatchTime 0.148180   LR 0.001000
INFO - Training [46][  100/  196]   Loss 0.016293   Top1 99.476562   Top5 100.000000   BatchTime 0.143219   LR 0.001000
INFO - Training [46][  120/  196]   Loss 0.016739   Top1 99.440104   Top5 100.000000   BatchTime 0.140018   LR 0.001000
INFO - Training [46][  140/  196]   Loss 0.016604   Top1 99.439174   Top5 100.000000   BatchTime 0.137633   LR 0.001000
INFO - Training [46][  160/  196]   Loss 0.017394   Top1 99.409180   Top5 100.000000   BatchTime 0.136652   LR 0.001000
INFO - Training [46][  180/  196]   Loss 0.017537   Top1 99.396701   Top5 100.000000   BatchTime 0.135114   LR 0.001000
INFO - ==> Top1: 99.386    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.464011   Top1 90.566406   Top5 99.531250   BatchTime 0.143657
INFO - Validation [46][   40/   40]   Loss 0.450095   Top1 90.830000   Top5 99.640000   BatchTime 0.099695
INFO - ==> Top1: 90.830    Top5: 99.640    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.014256   Top1 99.589844   Top5 100.000000   BatchTime 0.218858   LR 0.001000
INFO - Training [47][   40/  196]   Loss 0.016951   Top1 99.423828   Top5 100.000000   BatchTime 0.171023   LR 0.001000
INFO - Training [47][   60/  196]   Loss 0.018556   Top1 99.388021   Top5 100.000000   BatchTime 0.155104   LR 0.001000
INFO - Training [47][   80/  196]   Loss 0.019043   Top1 99.355469   Top5 100.000000   BatchTime 0.147082   LR 0.001000
INFO - Training [47][  100/  196]   Loss 0.018528   Top1 99.406250   Top5 100.000000   BatchTime 0.143031   LR 0.001000
INFO - Training [47][  120/  196]   Loss 0.018062   Top1 99.420573   Top5 100.000000   BatchTime 0.133535   LR 0.001000
INFO - Training [47][  140/  196]   Loss 0.018108   Top1 99.416853   Top5 100.000000   BatchTime 0.129437   LR 0.001000
INFO - Training [47][  160/  196]   Loss 0.018533   Top1 99.399414   Top5 100.000000   BatchTime 0.125782   LR 0.001000
INFO - Training [47][  180/  196]   Loss 0.018472   Top1 99.405382   Top5 99.997830   BatchTime 0.122506   LR 0.001000
INFO - ==> Top1: 99.398    Top5: 99.998    Loss: 0.019
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.456862   Top1 90.351562   Top5 99.511719   BatchTime 0.142612
INFO - Validation [47][   40/   40]   Loss 0.448107   Top1 90.710000   Top5 99.600000   BatchTime 0.099765
INFO - ==> Top1: 90.710    Top5: 99.600    Loss: 0.448
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.015961   Top1 99.492188   Top5 100.000000   BatchTime 0.217224   LR 0.001000
INFO - Training [48][   40/  196]   Loss 0.018442   Top1 99.326172   Top5 100.000000   BatchTime 0.170458   LR 0.001000
INFO - Training [48][   60/  196]   Loss 0.017257   Top1 99.414062   Top5 100.000000   BatchTime 0.154992   LR 0.001000
INFO - Training [48][   80/  196]   Loss 0.017691   Top1 99.404297   Top5 100.000000   BatchTime 0.147185   LR 0.001000
INFO - Training [48][  100/  196]   Loss 0.017719   Top1 99.414062   Top5 100.000000   BatchTime 0.142414   LR 0.001000
INFO - Training [48][  120/  196]   Loss 0.017090   Top1 99.446615   Top5 100.000000   BatchTime 0.139321   LR 0.001000
INFO - Training [48][  140/  196]   Loss 0.017471   Top1 99.447545   Top5 100.000000   BatchTime 0.137054   LR 0.001000
INFO - Training [48][  160/  196]   Loss 0.017046   Top1 99.450684   Top5 100.000000   BatchTime 0.135319   LR 0.001000
INFO - Training [48][  180/  196]   Loss 0.017666   Top1 99.424913   Top5 100.000000   BatchTime 0.133924   LR 0.001000
INFO - ==> Top1: 99.420    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.462342   Top1 90.332031   Top5 99.453125   BatchTime 0.143215
INFO - Validation [48][   40/   40]   Loss 0.451522   Top1 90.630000   Top5 99.610000   BatchTime 0.100280
INFO - ==> Top1: 90.630    Top5: 99.610    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.015934   Top1 99.570312   Top5 100.000000   BatchTime 0.216528   LR 0.001000
INFO - Training [49][   40/  196]   Loss 0.017815   Top1 99.511719   Top5 100.000000   BatchTime 0.169770   LR 0.001000
INFO - Training [49][   60/  196]   Loss 0.018216   Top1 99.466146   Top5 100.000000   BatchTime 0.147695   LR 0.001000
INFO - Training [49][   80/  196]   Loss 0.017992   Top1 99.467773   Top5 100.000000   BatchTime 0.135494   LR 0.001000
INFO - Training [49][  100/  196]   Loss 0.017760   Top1 99.464844   Top5 100.000000   BatchTime 0.128935   LR 0.001000
INFO - Training [49][  120/  196]   Loss 0.017790   Top1 99.453125   Top5 100.000000   BatchTime 0.124863   LR 0.001000
INFO - Training [49][  140/  196]   Loss 0.018353   Top1 99.430804   Top5 100.000000   BatchTime 0.119192   LR 0.001000
INFO - Training [49][  160/  196]   Loss 0.018426   Top1 99.418945   Top5 100.000000   BatchTime 0.119955   LR 0.001000
INFO - Training [49][  180/  196]   Loss 0.018957   Top1 99.401042   Top5 100.000000   BatchTime 0.120291   LR 0.001000
INFO - ==> Top1: 99.406    Top5: 100.000    Loss: 0.019
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.455580   Top1 90.664062   Top5 99.511719   BatchTime 0.143251
INFO - Validation [49][   40/   40]   Loss 0.448918   Top1 90.940000   Top5 99.590000   BatchTime 0.099154
INFO - ==> Top1: 90.940    Top5: 99.590    Loss: 0.449
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.016996   Top1 99.472656   Top5 100.000000   BatchTime 0.216588   LR 0.001000
INFO - Training [50][   40/  196]   Loss 0.016963   Top1 99.404297   Top5 100.000000   BatchTime 0.170107   LR 0.001000
INFO - Training [50][   60/  196]   Loss 0.017594   Top1 99.388021   Top5 100.000000   BatchTime 0.154975   LR 0.001000
INFO - Training [50][   80/  196]   Loss 0.018162   Top1 99.384766   Top5 100.000000   BatchTime 0.147305   LR 0.001000
INFO - Training [50][  100/  196]   Loss 0.018578   Top1 99.339844   Top5 100.000000   BatchTime 0.142680   LR 0.001000
INFO - Training [50][  120/  196]   Loss 0.018615   Top1 99.322917   Top5 100.000000   BatchTime 0.139496   LR 0.001000
INFO - Training [50][  140/  196]   Loss 0.018286   Top1 99.344308   Top5 100.000000   BatchTime 0.137181   LR 0.001000
INFO - Training [50][  160/  196]   Loss 0.017884   Top1 99.372559   Top5 100.000000   BatchTime 0.135939   LR 0.001000
INFO - Training [50][  180/  196]   Loss 0.017932   Top1 99.355469   Top5 100.000000   BatchTime 0.134523   LR 0.001000
INFO - ==> Top1: 99.348    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.463700   Top1 90.566406   Top5 99.531250   BatchTime 0.143132
INFO - Validation [50][   40/   40]   Loss 0.450397   Top1 90.790000   Top5 99.630000   BatchTime 0.099794
INFO - ==> Top1: 90.790    Top5: 99.630    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.017648   Top1 99.394531   Top5 100.000000   BatchTime 0.196524   LR 0.001000
INFO - Training [51][   40/  196]   Loss 0.017455   Top1 99.375000   Top5 100.000000   BatchTime 0.149256   LR 0.001000
INFO - Training [51][   60/  196]   Loss 0.017048   Top1 99.420573   Top5 100.000000   BatchTime 0.133886   LR 0.001000
INFO - Training [51][   80/  196]   Loss 0.017204   Top1 99.394531   Top5 100.000000   BatchTime 0.123609   LR 0.001000
INFO - Training [51][  100/  196]   Loss 0.017238   Top1 99.398438   Top5 100.000000   BatchTime 0.122806   LR 0.001000
INFO - Training [51][  120/  196]   Loss 0.017301   Top1 99.394531   Top5 100.000000   BatchTime 0.123132   LR 0.001000
INFO - Training [51][  140/  196]   Loss 0.017340   Top1 99.397321   Top5 100.000000   BatchTime 0.123182   LR 0.001000
INFO - Training [51][  160/  196]   Loss 0.017453   Top1 99.392090   Top5 100.000000   BatchTime 0.123206   LR 0.001000
INFO - Training [51][  180/  196]   Loss 0.017671   Top1 99.392361   Top5 100.000000   BatchTime 0.123186   LR 0.001000
INFO - ==> Top1: 99.388    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.464870   Top1 90.488281   Top5 99.472656   BatchTime 0.143483
INFO - Validation [51][   40/   40]   Loss 0.453911   Top1 90.760000   Top5 99.570000   BatchTime 0.099335
INFO - ==> Top1: 90.760    Top5: 99.570    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.016290   Top1 99.511719   Top5 100.000000   BatchTime 0.219636   LR 0.001000
INFO - Training [52][   40/  196]   Loss 0.016236   Top1 99.521484   Top5 100.000000   BatchTime 0.171466   LR 0.001000
INFO - Training [52][   60/  196]   Loss 0.017590   Top1 99.453125   Top5 100.000000   BatchTime 0.155651   LR 0.001000
INFO - Training [52][   80/  196]   Loss 0.017913   Top1 99.423828   Top5 100.000000   BatchTime 0.147641   LR 0.001000
INFO - Training [52][  100/  196]   Loss 0.018266   Top1 99.414062   Top5 100.000000   BatchTime 0.142783   LR 0.001000
INFO - Training [52][  120/  196]   Loss 0.018695   Top1 99.404297   Top5 100.000000   BatchTime 0.139613   LR 0.001000
INFO - Training [52][  140/  196]   Loss 0.018533   Top1 99.414062   Top5 100.000000   BatchTime 0.137314   LR 0.001000
INFO - Training [52][  160/  196]   Loss 0.018384   Top1 99.418945   Top5 100.000000   BatchTime 0.135479   LR 0.001000
INFO - Training [52][  180/  196]   Loss 0.018344   Top1 99.409722   Top5 100.000000   BatchTime 0.134050   LR 0.001000
INFO - ==> Top1: 99.414    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.467412   Top1 90.429688   Top5 99.511719   BatchTime 0.130237
INFO - Validation [52][   40/   40]   Loss 0.454293   Top1 90.670000   Top5 99.620000   BatchTime 0.087714
INFO - ==> Top1: 90.670    Top5: 99.620    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.018399   Top1 99.355469   Top5 100.000000   BatchTime 0.200088   LR 0.001000
INFO - Training [53][   40/  196]   Loss 0.017278   Top1 99.423828   Top5 100.000000   BatchTime 0.161966   LR 0.001000
INFO - Training [53][   60/  196]   Loss 0.016906   Top1 99.427083   Top5 100.000000   BatchTime 0.149229   LR 0.001000
INFO - Training [53][   80/  196]   Loss 0.017455   Top1 99.438477   Top5 100.000000   BatchTime 0.142719   LR 0.001000
INFO - Training [53][  100/  196]   Loss 0.018064   Top1 99.410156   Top5 100.000000   BatchTime 0.138946   LR 0.001000
INFO - Training [53][  120/  196]   Loss 0.017591   Top1 99.410807   Top5 100.000000   BatchTime 0.136416   LR 0.001000
INFO - Training [53][  140/  196]   Loss 0.017976   Top1 99.402902   Top5 100.000000   BatchTime 0.134542   LR 0.001000
INFO - Training [53][  160/  196]   Loss 0.017890   Top1 99.406738   Top5 100.000000   BatchTime 0.133123   LR 0.001000
INFO - Training [53][  180/  196]   Loss 0.017654   Top1 99.420573   Top5 100.000000   BatchTime 0.131972   LR 0.001000
INFO - ==> Top1: 99.400    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.461574   Top1 90.468750   Top5 99.472656   BatchTime 0.143766
INFO - Validation [53][   40/   40]   Loss 0.450203   Top1 90.860000   Top5 99.560000   BatchTime 0.100009
INFO - ==> Top1: 90.860    Top5: 99.560    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.016738   Top1 99.453125   Top5 100.000000   BatchTime 0.219072   LR 0.001000
INFO - Training [54][   40/  196]   Loss 0.017147   Top1 99.462891   Top5 100.000000   BatchTime 0.171361   LR 0.001000
INFO - Training [54][   60/  196]   Loss 0.017026   Top1 99.492188   Top5 100.000000   BatchTime 0.155415   LR 0.001000
INFO - Training [54][   80/  196]   Loss 0.017279   Top1 99.467773   Top5 100.000000   BatchTime 0.147298   LR 0.001000
INFO - Training [54][  100/  196]   Loss 0.017476   Top1 99.457031   Top5 99.996094   BatchTime 0.142609   LR 0.001000
INFO - Training [54][  120/  196]   Loss 0.017278   Top1 99.466146   Top5 99.996745   BatchTime 0.139374   LR 0.001000
INFO - Training [54][  140/  196]   Loss 0.017013   Top1 99.461496   Top5 99.997210   BatchTime 0.136328   LR 0.001000
INFO - Training [54][  160/  196]   Loss 0.016495   Top1 99.482422   Top5 99.997559   BatchTime 0.130378   LR 0.001000
INFO - Training [54][  180/  196]   Loss 0.016813   Top1 99.463976   Top5 99.997830   BatchTime 0.127611   LR 0.001000
INFO - ==> Top1: 99.456    Top5: 99.998    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.469030   Top1 90.429688   Top5 99.531250   BatchTime 0.133668
INFO - Validation [54][   40/   40]   Loss 0.459324   Top1 90.650000   Top5 99.590000   BatchTime 0.095049
INFO - ==> Top1: 90.650    Top5: 99.590    Loss: 0.459
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.017761   Top1 99.453125   Top5 100.000000   BatchTime 0.216821   LR 0.001000
INFO - Training [55][   40/  196]   Loss 0.016996   Top1 99.433594   Top5 100.000000   BatchTime 0.170836   LR 0.001000
INFO - Training [55][   60/  196]   Loss 0.016319   Top1 99.446615   Top5 100.000000   BatchTime 0.155218   LR 0.001000
INFO - Training [55][   80/  196]   Loss 0.016355   Top1 99.448242   Top5 100.000000   BatchTime 0.147342   LR 0.001000
INFO - Training [55][  100/  196]   Loss 0.016521   Top1 99.453125   Top5 100.000000   BatchTime 0.142622   LR 0.001000
INFO - Training [55][  120/  196]   Loss 0.017133   Top1 99.427083   Top5 100.000000   BatchTime 0.139434   LR 0.001000
INFO - Training [55][  140/  196]   Loss 0.017262   Top1 99.419643   Top5 100.000000   BatchTime 0.137157   LR 0.001000
INFO - Training [55][  160/  196]   Loss 0.017738   Top1 99.406738   Top5 100.000000   BatchTime 0.135415   LR 0.001000
INFO - Training [55][  180/  196]   Loss 0.017851   Top1 99.398872   Top5 100.000000   BatchTime 0.133836   LR 0.001000
INFO - ==> Top1: 99.402    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.469343   Top1 90.683594   Top5 99.472656   BatchTime 0.145312
INFO - Validation [55][   40/   40]   Loss 0.457411   Top1 90.670000   Top5 99.580000   BatchTime 0.100659
INFO - ==> Top1: 90.670    Top5: 99.580    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.016360   Top1 99.414062   Top5 100.000000   BatchTime 0.218693   LR 0.001000
INFO - Training [56][   40/  196]   Loss 0.017727   Top1 99.443359   Top5 100.000000   BatchTime 0.171068   LR 0.001000
INFO - Training [56][   60/  196]   Loss 0.018003   Top1 99.401042   Top5 100.000000   BatchTime 0.155240   LR 0.001000
INFO - Training [56][   80/  196]   Loss 0.017501   Top1 99.423828   Top5 100.000000   BatchTime 0.147100   LR 0.001000
INFO - Training [56][  100/  196]   Loss 0.017550   Top1 99.425781   Top5 100.000000   BatchTime 0.135889   LR 0.001000
INFO - Training [56][  120/  196]   Loss 0.017389   Top1 99.453125   Top5 100.000000   BatchTime 0.130380   LR 0.001000
INFO - Training [56][  140/  196]   Loss 0.017853   Top1 99.419643   Top5 100.000000   BatchTime 0.126219   LR 0.001000
INFO - Training [56][  160/  196]   Loss 0.018168   Top1 99.396973   Top5 100.000000   BatchTime 0.122928   LR 0.001000
INFO - Training [56][  180/  196]   Loss 0.018142   Top1 99.414062   Top5 100.000000   BatchTime 0.119352   LR 0.001000
INFO - ==> Top1: 99.424    Top5: 100.000    Loss: 0.018
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.463272   Top1 90.273438   Top5 99.394531   BatchTime 0.143966
INFO - Validation [56][   40/   40]   Loss 0.451790   Top1 90.660000   Top5 99.530000   BatchTime 0.100625
INFO - ==> Top1: 90.660    Top5: 99.530    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.015460   Top1 99.570312   Top5 100.000000   BatchTime 0.219496   LR 0.001000
INFO - Training [57][   40/  196]   Loss 0.014949   Top1 99.531250   Top5 100.000000   BatchTime 0.171844   LR 0.001000
INFO - Training [57][   60/  196]   Loss 0.015975   Top1 99.485677   Top5 100.000000   BatchTime 0.155986   LR 0.001000
INFO - Training [57][   80/  196]   Loss 0.016659   Top1 99.477539   Top5 100.000000   BatchTime 0.147970   LR 0.001000
INFO - Training [57][  100/  196]   Loss 0.016890   Top1 99.464844   Top5 100.000000   BatchTime 0.143226   LR 0.001000
INFO - Training [57][  120/  196]   Loss 0.016651   Top1 99.469401   Top5 100.000000   BatchTime 0.140113   LR 0.001000
INFO - Training [57][  140/  196]   Loss 0.016731   Top1 99.455915   Top5 100.000000   BatchTime 0.137845   LR 0.001000
INFO - Training [57][  160/  196]   Loss 0.016747   Top1 99.460449   Top5 100.000000   BatchTime 0.136019   LR 0.001000
INFO - Training [57][  180/  196]   Loss 0.016592   Top1 99.459635   Top5 100.000000   BatchTime 0.134529   LR 0.001000
INFO - ==> Top1: 99.456    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.465578   Top1 90.644531   Top5 99.394531   BatchTime 0.143173
INFO - Validation [57][   40/   40]   Loss 0.452675   Top1 90.910000   Top5 99.530000   BatchTime 0.099062
INFO - ==> Top1: 90.910    Top5: 99.530    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.018945   Top1 99.394531   Top5 100.000000   BatchTime 0.215514   LR 0.001000
INFO - Training [58][   40/  196]   Loss 0.018305   Top1 99.384766   Top5 100.000000   BatchTime 0.161191   LR 0.001000
INFO - Training [58][   60/  196]   Loss 0.019442   Top1 99.322917   Top5 100.000000   BatchTime 0.140091   LR 0.001000
INFO - Training [58][   80/  196]   Loss 0.018163   Top1 99.384766   Top5 100.000000   BatchTime 0.130537   LR 0.001000
INFO - Training [58][  100/  196]   Loss 0.017122   Top1 99.437500   Top5 100.000000   BatchTime 0.125034   LR 0.001000
INFO - Training [58][  120/  196]   Loss 0.016988   Top1 99.430339   Top5 100.000000   BatchTime 0.118950   LR 0.001000
INFO - Training [58][  140/  196]   Loss 0.017147   Top1 99.416853   Top5 100.000000   BatchTime 0.119718   LR 0.001000
INFO - Training [58][  160/  196]   Loss 0.017624   Top1 99.392090   Top5 100.000000   BatchTime 0.120160   LR 0.001000
INFO - Training [58][  180/  196]   Loss 0.017393   Top1 99.405382   Top5 100.000000   BatchTime 0.120503   LR 0.001000
INFO - Validation [58][   20/   40]   Loss 0.462911   Top1 90.527344   Top5 99.570312   BatchTime 0.142971
INFO - Validation [58][   40/   40]   Loss 0.451529   Top1 90.800000   Top5 99.640000   BatchTime 0.099374
INFO - ==> Top1: 90.800    Top5: 99.640    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.013620   Top1 99.550781   Top5 100.000000   BatchTime 0.225386   LR 0.001000
INFO - Training [59][   40/  196]   Loss 0.014759   Top1 99.531250   Top5 100.000000   BatchTime 0.174623   LR 0.001000
INFO - Training [59][   60/  196]   Loss 0.015694   Top1 99.479167   Top5 100.000000   BatchTime 0.158022   LR 0.001000
INFO - Training [59][   80/  196]   Loss 0.015595   Top1 99.501953   Top5 100.000000   BatchTime 0.149593   LR 0.001000
INFO - Training [59][  100/  196]   Loss 0.016632   Top1 99.457031   Top5 100.000000   BatchTime 0.144743   LR 0.001000
INFO - Training [59][  120/  196]   Loss 0.016685   Top1 99.459635   Top5 100.000000   BatchTime 0.141265   LR 0.001000
INFO - Training [59][  140/  196]   Loss 0.016373   Top1 99.481027   Top5 100.000000   BatchTime 0.138570   LR 0.001000
INFO - Training [59][  160/  196]   Loss 0.016567   Top1 99.470215   Top5 100.000000   BatchTime 0.136658   LR 0.001000
INFO - Training [59][  180/  196]   Loss 0.016707   Top1 99.461806   Top5 100.000000   BatchTime 0.135193   LR 0.001000
INFO - ==> Top1: 99.450    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.465670   Top1 90.605469   Top5 99.492188   BatchTime 0.141571
INFO - Validation [59][   40/   40]   Loss 0.455527   Top1 90.640000   Top5 99.630000   BatchTime 0.099741
INFO - ==> Top1: 90.640    Top5: 99.630    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [60][   20/  196]   Loss 0.014287   Top1 99.531250   Top5 100.000000   BatchTime 0.203335   LR 0.000100
INFO - Training [60][   40/  196]   Loss 0.015071   Top1 99.521484   Top5 100.000000   BatchTime 0.153329   LR 0.000100
INFO - Training [60][   60/  196]   Loss 0.015557   Top1 99.472656   Top5 100.000000   BatchTime 0.133951   LR 0.000100
INFO - Training [60][   80/  196]   Loss 0.016744   Top1 99.409180   Top5 100.000000   BatchTime 0.128272   LR 0.000100
INFO - Training [60][  100/  196]   Loss 0.016353   Top1 99.445312   Top5 100.000000   BatchTime 0.127407   LR 0.000100
INFO - Training [60][  120/  196]   Loss 0.016972   Top1 99.436849   Top5 100.000000   BatchTime 0.126781   LR 0.000100
INFO - Training [60][  140/  196]   Loss 0.017166   Top1 99.444754   Top5 100.000000   BatchTime 0.126319   LR 0.000100
INFO - Training [60][  160/  196]   Loss 0.017335   Top1 99.436035   Top5 100.000000   BatchTime 0.125903   LR 0.000100
INFO - Training [60][  180/  196]   Loss 0.017361   Top1 99.431424   Top5 100.000000   BatchTime 0.125649   LR 0.000100
INFO - ==> Top1: 99.432    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 0.459109   Top1 90.605469   Top5 99.531250   BatchTime 0.144172
INFO - Validation [60][   40/   40]   Loss 0.447254   Top1 90.730000   Top5 99.620000   BatchTime 0.099749
INFO - ==> Top1: 90.730    Top5: 99.620    Loss: 0.447
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [61][   20/  196]   Loss 0.013038   Top1 99.531250   Top5 100.000000   BatchTime 0.219257   LR 0.000100
INFO - Training [61][   40/  196]   Loss 0.014273   Top1 99.541016   Top5 100.000000   BatchTime 0.171199   LR 0.000100
INFO - Training [61][   60/  196]   Loss 0.014205   Top1 99.531250   Top5 100.000000   BatchTime 0.155444   LR 0.000100
INFO - Training [61][   80/  196]   Loss 0.014568   Top1 99.506836   Top5 100.000000   BatchTime 0.147476   LR 0.000100
INFO - Training [61][  100/  196]   Loss 0.016131   Top1 99.472656   Top5 100.000000   BatchTime 0.142728   LR 0.000100
INFO - Training [61][  120/  196]   Loss 0.016996   Top1 99.433594   Top5 100.000000   BatchTime 0.139605   LR 0.000100
INFO - Training [61][  140/  196]   Loss 0.016920   Top1 99.430804   Top5 100.000000   BatchTime 0.137327   LR 0.000100
INFO - Training [61][  160/  196]   Loss 0.017460   Top1 99.433594   Top5 100.000000   BatchTime 0.135516   LR 0.000100
INFO - Training [61][  180/  196]   Loss 0.017264   Top1 99.440104   Top5 100.000000   BatchTime 0.134094   LR 0.000100
INFO - ==> Top1: 99.442    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 0.469534   Top1 90.527344   Top5 99.472656   BatchTime 0.134767
INFO - Validation [61][   40/   40]   Loss 0.454906   Top1 90.680000   Top5 99.640000   BatchTime 0.088949
INFO - ==> Top1: 90.680    Top5: 99.640    Loss: 0.455
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [62][   20/  196]   Loss 0.015695   Top1 99.550781   Top5 100.000000   BatchTime 0.213151   LR 0.000100
INFO - Training [62][   40/  196]   Loss 0.016601   Top1 99.462891   Top5 100.000000   BatchTime 0.168584   LR 0.000100
INFO - Training [62][   60/  196]   Loss 0.015779   Top1 99.485677   Top5 100.000000   BatchTime 0.153882   LR 0.000100
INFO - Training [62][   80/  196]   Loss 0.016344   Top1 99.462891   Top5 100.000000   BatchTime 0.146489   LR 0.000100
INFO - Training [62][  100/  196]   Loss 0.017195   Top1 99.425781   Top5 100.000000   BatchTime 0.141969   LR 0.000100
INFO - Training [62][  120/  196]   Loss 0.017497   Top1 99.407552   Top5 100.000000   BatchTime 0.139098   LR 0.000100
INFO - Training [62][  140/  196]   Loss 0.017449   Top1 99.419643   Top5 100.000000   BatchTime 0.136917   LR 0.000100
INFO - Training [62][  160/  196]   Loss 0.016885   Top1 99.440918   Top5 100.000000   BatchTime 0.135242   LR 0.000100
INFO - Training [62][  180/  196]   Loss 0.016411   Top1 99.461806   Top5 100.000000   BatchTime 0.133910   LR 0.000100
INFO - ==> Top1: 99.472    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 0.464845   Top1 90.468750   Top5 99.511719   BatchTime 0.144440
INFO - Validation [62][   40/   40]   Loss 0.454329   Top1 90.700000   Top5 99.600000   BatchTime 0.100373
INFO - ==> Top1: 90.700    Top5: 99.600    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 0.010882   Top1 99.687500   Top5 100.000000   BatchTime 0.218365   LR 0.000100
INFO - Training [63][   40/  196]   Loss 0.012320   Top1 99.687500   Top5 100.000000   BatchTime 0.171198   LR 0.000100
INFO - Training [63][   60/  196]   Loss 0.014804   Top1 99.563802   Top5 100.000000   BatchTime 0.157612   LR 0.000100
INFO - Training [63][   80/  196]   Loss 0.016105   Top1 99.511719   Top5 100.000000   BatchTime 0.149068   LR 0.000100
INFO - Training [63][  100/  196]   Loss 0.016060   Top1 99.492188   Top5 100.000000   BatchTime 0.143606   LR 0.000100
INFO - Training [63][  120/  196]   Loss 0.016099   Top1 99.485677   Top5 100.000000   BatchTime 0.140296   LR 0.000100
INFO - Training [63][  140/  196]   Loss 0.016439   Top1 99.475446   Top5 100.000000   BatchTime 0.135717   LR 0.000100
INFO - Training [63][  160/  196]   Loss 0.016592   Top1 99.470215   Top5 100.000000   BatchTime 0.130571   LR 0.000100
INFO - Training [63][  180/  196]   Loss 0.016214   Top1 99.485677   Top5 100.000000   BatchTime 0.127416   LR 0.000100
INFO - ==> Top1: 99.476    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 0.468958   Top1 90.312500   Top5 99.550781   BatchTime 0.138629
INFO - Validation [63][   40/   40]   Loss 0.454926   Top1 90.490000   Top5 99.670000   BatchTime 0.097867
INFO - ==> Top1: 90.490    Top5: 99.670    Loss: 0.455
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 0.014762   Top1 99.570312   Top5 100.000000   BatchTime 0.219511   LR 0.000100
INFO - Training [64][   40/  196]   Loss 0.016526   Top1 99.472656   Top5 100.000000   BatchTime 0.171588   LR 0.000100
INFO - Training [64][   60/  196]   Loss 0.015810   Top1 99.537760   Top5 100.000000   BatchTime 0.155681   LR 0.000100
INFO - Training [64][   80/  196]   Loss 0.016405   Top1 99.492188   Top5 100.000000   BatchTime 0.147633   LR 0.000100
INFO - Training [64][  100/  196]   Loss 0.015864   Top1 99.519531   Top5 100.000000   BatchTime 0.142843   LR 0.000100
INFO - Training [64][  120/  196]   Loss 0.015585   Top1 99.524740   Top5 100.000000   BatchTime 0.139664   LR 0.000100
INFO - Training [64][  140/  196]   Loss 0.015545   Top1 99.520089   Top5 100.000000   BatchTime 0.137337   LR 0.000100
INFO - Training [64][  160/  196]   Loss 0.016209   Top1 99.497070   Top5 100.000000   BatchTime 0.135535   LR 0.000100
INFO - Training [64][  180/  196]   Loss 0.016347   Top1 99.505208   Top5 100.000000   BatchTime 0.134238   LR 0.000100
INFO - ==> Top1: 99.488    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [64][   20/   40]   Loss 0.469178   Top1 90.488281   Top5 99.531250   BatchTime 0.141994
INFO - Validation [64][   40/   40]   Loss 0.453470   Top1 90.610000   Top5 99.630000   BatchTime 0.098540
INFO - ==> Top1: 90.610    Top5: 99.630    Loss: 0.453
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [65][   20/  196]   Loss 0.011737   Top1 99.687500   Top5 100.000000   BatchTime 0.217960   LR 0.000100
INFO - Training [65][   40/  196]   Loss 0.014397   Top1 99.550781   Top5 100.000000   BatchTime 0.170596   LR 0.000100
INFO - Training [65][   60/  196]   Loss 0.015620   Top1 99.485677   Top5 100.000000   BatchTime 0.154892   LR 0.000100
INFO - Training [65][   80/  196]   Loss 0.016085   Top1 99.482422   Top5 100.000000   BatchTime 0.147066   LR 0.000100
INFO - Training [65][  100/  196]   Loss 0.016330   Top1 99.449219   Top5 100.000000   BatchTime 0.136883   LR 0.000100
INFO - Training [65][  120/  196]   Loss 0.016588   Top1 99.449870   Top5 100.000000   BatchTime 0.131475   LR 0.000100
INFO - Training [65][  140/  196]   Loss 0.016807   Top1 99.453125   Top5 100.000000   BatchTime 0.127389   LR 0.000100
INFO - Training [65][  160/  196]   Loss 0.016996   Top1 99.448242   Top5 100.000000   BatchTime 0.123912   LR 0.000100
INFO - Training [65][  180/  196]   Loss 0.017138   Top1 99.442274   Top5 100.000000   BatchTime 0.121118   LR 0.000100
INFO - ==> Top1: 99.440    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 0.471253   Top1 90.527344   Top5 99.550781   BatchTime 0.143385
INFO - Validation [65][   40/   40]   Loss 0.456351   Top1 90.820000   Top5 99.660000   BatchTime 0.099312
INFO - ==> Top1: 90.820    Top5: 99.660    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [66][   20/  196]   Loss 0.014806   Top1 99.453125   Top5 100.000000   BatchTime 0.218025   LR 0.000100
INFO - Training [66][   40/  196]   Loss 0.017466   Top1 99.375000   Top5 100.000000   BatchTime 0.170887   LR 0.000100
INFO - Training [66][   60/  196]   Loss 0.016638   Top1 99.427083   Top5 100.000000   BatchTime 0.155494   LR 0.000100
INFO - Training [66][   80/  196]   Loss 0.016737   Top1 99.404297   Top5 100.000000   BatchTime 0.147602   LR 0.000100
INFO - Training [66][  100/  196]   Loss 0.016357   Top1 99.429688   Top5 100.000000   BatchTime 0.142955   LR 0.000100
INFO - Training [66][  120/  196]   Loss 0.016463   Top1 99.433594   Top5 100.000000   BatchTime 0.139649   LR 0.000100
INFO - Training [66][  140/  196]   Loss 0.016929   Top1 99.428013   Top5 100.000000   BatchTime 0.137429   LR 0.000100
INFO - Training [66][  160/  196]   Loss 0.016461   Top1 99.448242   Top5 100.000000   BatchTime 0.135669   LR 0.000100
INFO - Training [66][  180/  196]   Loss 0.016748   Top1 99.440104   Top5 100.000000   BatchTime 0.134326   LR 0.000100
INFO - ==> Top1: 99.448    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 0.473861   Top1 90.175781   Top5 99.511719   BatchTime 0.141984
INFO - Validation [66][   40/   40]   Loss 0.458582   Top1 90.510000   Top5 99.640000   BatchTime 0.099119
INFO - ==> Top1: 90.510    Top5: 99.640    Loss: 0.459
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 0.012602   Top1 99.609375   Top5 100.000000   BatchTime 0.216232   LR 0.000100
INFO - Training [67][   40/  196]   Loss 0.013859   Top1 99.570312   Top5 100.000000   BatchTime 0.159672   LR 0.000100
INFO - Training [67][   60/  196]   Loss 0.015650   Top1 99.511719   Top5 100.000000   BatchTime 0.139990   LR 0.000100
INFO - Training [67][   80/  196]   Loss 0.015695   Top1 99.506836   Top5 100.000000   BatchTime 0.130747   LR 0.000100
INFO - Training [67][  100/  196]   Loss 0.015969   Top1 99.488281   Top5 100.000000   BatchTime 0.125382   LR 0.000100
INFO - Training [67][  120/  196]   Loss 0.016337   Top1 99.475911   Top5 100.000000   BatchTime 0.119440   LR 0.000100
INFO - Training [67][  140/  196]   Loss 0.015962   Top1 99.497768   Top5 100.000000   BatchTime 0.120625   LR 0.000100
INFO - Training [67][  160/  196]   Loss 0.016312   Top1 99.482422   Top5 100.000000   BatchTime 0.120975   LR 0.000100
INFO - Training [67][  180/  196]   Loss 0.016234   Top1 99.485677   Top5 100.000000   BatchTime 0.121222   LR 0.000100
INFO - ==> Top1: 99.476    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 0.474380   Top1 90.253906   Top5 99.492188   BatchTime 0.145039
INFO - Validation [67][   40/   40]   Loss 0.457162   Top1 90.580000   Top5 99.630000   BatchTime 0.100197
INFO - ==> Top1: 90.580    Top5: 99.630    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 0.015413   Top1 99.550781   Top5 100.000000   BatchTime 0.220362   LR 0.000100
INFO - Training [68][   40/  196]   Loss 0.017188   Top1 99.511719   Top5 100.000000   BatchTime 0.172205   LR 0.000100
INFO - Training [68][   60/  196]   Loss 0.017278   Top1 99.498698   Top5 100.000000   BatchTime 0.156153   LR 0.000100
INFO - Training [68][   80/  196]   Loss 0.016593   Top1 99.506836   Top5 100.000000   BatchTime 0.148027   LR 0.000100
INFO - Training [68][  100/  196]   Loss 0.016673   Top1 99.484375   Top5 100.000000   BatchTime 0.143183   LR 0.000100
INFO - Training [68][  120/  196]   Loss 0.017806   Top1 99.427083   Top5 100.000000   BatchTime 0.140018   LR 0.000100
INFO - Training [68][  140/  196]   Loss 0.017713   Top1 99.428013   Top5 100.000000   BatchTime 0.137600   LR 0.000100
INFO - Training [68][  160/  196]   Loss 0.017714   Top1 99.428711   Top5 100.000000   BatchTime 0.135756   LR 0.000100
INFO - Training [68][  180/  196]   Loss 0.017544   Top1 99.433594   Top5 100.000000   BatchTime 0.134346   LR 0.000100
INFO - ==> Top1: 99.452    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.469829   Top1 90.410156   Top5 99.550781   BatchTime 0.141819
INFO - Validation [68][   40/   40]   Loss 0.455291   Top1 90.680000   Top5 99.610000   BatchTime 0.095991
INFO - ==> Top1: 90.680    Top5: 99.610    Loss: 0.455
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 0.017982   Top1 99.375000   Top5 100.000000   BatchTime 0.203463   LR 0.000100
INFO - Training [69][   40/  196]   Loss 0.018364   Top1 99.384766   Top5 100.000000   BatchTime 0.152735   LR 0.000100
INFO - Training [69][   60/  196]   Loss 0.017276   Top1 99.401042   Top5 100.000000   BatchTime 0.132974   LR 0.000100
INFO - Training [69][   80/  196]   Loss 0.015762   Top1 99.492188   Top5 100.000000   BatchTime 0.128215   LR 0.000100
INFO - Training [69][  100/  196]   Loss 0.015299   Top1 99.496094   Top5 100.000000   BatchTime 0.127334   LR 0.000100
INFO - Training [69][  120/  196]   Loss 0.015481   Top1 99.492188   Top5 100.000000   BatchTime 0.126825   LR 0.000100
INFO - Training [69][  140/  196]   Loss 0.016245   Top1 99.458705   Top5 100.000000   BatchTime 0.126355   LR 0.000100
INFO - Training [69][  160/  196]   Loss 0.016381   Top1 99.462891   Top5 100.000000   BatchTime 0.125956   LR 0.000100
INFO - Training [69][  180/  196]   Loss 0.016375   Top1 99.463976   Top5 100.000000   BatchTime 0.125585   LR 0.000100
INFO - ==> Top1: 99.462    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [69][   20/   40]   Loss 0.473780   Top1 90.371094   Top5 99.531250   BatchTime 0.141836
INFO - Validation [69][   40/   40]   Loss 0.456006   Top1 90.720000   Top5 99.650000   BatchTime 0.098537
INFO - ==> Top1: 90.720    Top5: 99.650    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  70
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [70][   20/  196]   Loss 0.013943   Top1 99.550781   Top5 100.000000   BatchTime 0.218778   LR 0.000010
INFO - Training [70][   40/  196]   Loss 0.016744   Top1 99.453125   Top5 100.000000   BatchTime 0.171304   LR 0.000010
INFO - Training [70][   60/  196]   Loss 0.016773   Top1 99.459635   Top5 100.000000   BatchTime 0.155318   LR 0.000010
INFO - Training [70][   80/  196]   Loss 0.016696   Top1 99.477539   Top5 100.000000   BatchTime 0.147519   LR 0.000010
INFO - Training [70][  100/  196]   Loss 0.017207   Top1 99.445312   Top5 100.000000   BatchTime 0.142787   LR 0.000010
INFO - Training [70][  120/  196]   Loss 0.016625   Top1 99.472656   Top5 100.000000   BatchTime 0.139669   LR 0.000010
INFO - Training [70][  140/  196]   Loss 0.016396   Top1 99.492188   Top5 100.000000   BatchTime 0.137319   LR 0.000010
INFO - Training [70][  160/  196]   Loss 0.016559   Top1 99.492188   Top5 100.000000   BatchTime 0.135468   LR 0.000010
INFO - Training [70][  180/  196]   Loss 0.016388   Top1 99.498698   Top5 100.000000   BatchTime 0.134037   LR 0.000010
INFO - ==> Top1: 99.488    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [70][   20/   40]   Loss 0.469385   Top1 90.390625   Top5 99.550781   BatchTime 0.134215
INFO - Validation [70][   40/   40]   Loss 0.451553   Top1 90.780000   Top5 99.650000   BatchTime 0.088565
INFO - ==> Top1: 90.780    Top5: 99.650    Loss: 0.452
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  71
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [71][   20/  196]   Loss 0.013782   Top1 99.648438   Top5 100.000000   BatchTime 0.217649   LR 0.000010
INFO - Training [71][   40/  196]   Loss 0.014118   Top1 99.580078   Top5 100.000000   BatchTime 0.170581   LR 0.000010
INFO - Training [71][   60/  196]   Loss 0.014418   Top1 99.570312   Top5 100.000000   BatchTime 0.154839   LR 0.000010
INFO - Training [71][   80/  196]   Loss 0.014820   Top1 99.560547   Top5 100.000000   BatchTime 0.147097   LR 0.000010
INFO - Training [71][  100/  196]   Loss 0.015298   Top1 99.542969   Top5 100.000000   BatchTime 0.141957   LR 0.000010
INFO - Training [71][  120/  196]   Loss 0.016028   Top1 99.508464   Top5 100.000000   BatchTime 0.138880   LR 0.000010
INFO - Training [71][  140/  196]   Loss 0.016410   Top1 99.494978   Top5 100.000000   BatchTime 0.136675   LR 0.000010
INFO - Training [71][  160/  196]   Loss 0.016386   Top1 99.489746   Top5 100.000000   BatchTime 0.134958   LR 0.000010
INFO - Training [71][  180/  196]   Loss 0.016281   Top1 99.492188   Top5 100.000000   BatchTime 0.133609   LR 0.000010
INFO - ==> Top1: 99.490    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [71][   20/   40]   Loss 0.458481   Top1 90.507812   Top5 99.550781   BatchTime 0.142542
INFO - Validation [71][   40/   40]   Loss 0.450133   Top1 90.860000   Top5 99.650000   BatchTime 0.098799
INFO - ==> Top1: 90.860    Top5: 99.650    Loss: 0.450
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  72
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [72][   20/  196]   Loss 0.020344   Top1 99.355469   Top5 100.000000   BatchTime 0.216843   LR 0.000010
INFO - Training [72][   40/  196]   Loss 0.019038   Top1 99.306641   Top5 100.000000   BatchTime 0.170330   LR 0.000010
INFO - Training [72][   60/  196]   Loss 0.017867   Top1 99.381510   Top5 100.000000   BatchTime 0.154666   LR 0.000010
INFO - Training [72][   80/  196]   Loss 0.017367   Top1 99.409180   Top5 100.000000   BatchTime 0.146874   LR 0.000010
INFO - Training [72][  100/  196]   Loss 0.017724   Top1 99.406250   Top5 99.996094   BatchTime 0.142191   LR 0.000010
INFO - Training [72][  120/  196]   Loss 0.017154   Top1 99.420573   Top5 99.996745   BatchTime 0.139006   LR 0.000010
INFO - Training [72][  140/  196]   Loss 0.017137   Top1 99.425223   Top5 99.997210   BatchTime 0.134374   LR 0.000010
INFO - Training [72][  160/  196]   Loss 0.017309   Top1 99.406738   Top5 99.997559   BatchTime 0.129315   LR 0.000010
INFO - Training [72][  180/  196]   Loss 0.017234   Top1 99.414062   Top5 99.997830   BatchTime 0.126132   LR 0.000010
INFO - ==> Top1: 99.428    Top5: 99.998    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [72][   20/   40]   Loss 0.467318   Top1 90.371094   Top5 99.492188   BatchTime 0.147026
INFO - Validation [72][   40/   40]   Loss 0.454404   Top1 90.600000   Top5 99.600000   BatchTime 0.100849
INFO - ==> Top1: 90.600    Top5: 99.600    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  73
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [73][   20/  196]   Loss 0.012877   Top1 99.589844   Top5 100.000000   BatchTime 0.217414   LR 0.000010
INFO - Training [73][   40/  196]   Loss 0.014996   Top1 99.541016   Top5 100.000000   BatchTime 0.170917   LR 0.000010
INFO - Training [73][   60/  196]   Loss 0.016679   Top1 99.440104   Top5 100.000000   BatchTime 0.155212   LR 0.000010
INFO - Training [73][   80/  196]   Loss 0.017236   Top1 99.414062   Top5 100.000000   BatchTime 0.147702   LR 0.000010
INFO - Training [73][  100/  196]   Loss 0.017599   Top1 99.394531   Top5 100.000000   BatchTime 0.142905   LR 0.000010
INFO - Training [73][  120/  196]   Loss 0.017173   Top1 99.433594   Top5 100.000000   BatchTime 0.139743   LR 0.000010
INFO - Training [73][  140/  196]   Loss 0.017064   Top1 99.441964   Top5 100.000000   BatchTime 0.137507   LR 0.000010
INFO - Training [73][  160/  196]   Loss 0.017185   Top1 99.443359   Top5 100.000000   BatchTime 0.135711   LR 0.000010
INFO - Training [73][  180/  196]   Loss 0.017106   Top1 99.433594   Top5 100.000000   BatchTime 0.134315   LR 0.000010
INFO - ==> Top1: 99.436    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [73][   20/   40]   Loss 0.470263   Top1 90.371094   Top5 99.472656   BatchTime 0.142588
INFO - Validation [73][   40/   40]   Loss 0.457271   Top1 90.680000   Top5 99.610000   BatchTime 0.098814
INFO - ==> Top1: 90.680    Top5: 99.610    Loss: 0.457
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  74
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [74][   20/  196]   Loss 0.014287   Top1 99.648438   Top5 100.000000   BatchTime 0.218176   LR 0.000010
INFO - Training [74][   40/  196]   Loss 0.016644   Top1 99.541016   Top5 100.000000   BatchTime 0.170694   LR 0.000010
INFO - Training [74][   60/  196]   Loss 0.017117   Top1 99.472656   Top5 100.000000   BatchTime 0.155130   LR 0.000010
INFO - Training [74][   80/  196]   Loss 0.015768   Top1 99.526367   Top5 100.000000   BatchTime 0.145888   LR 0.000010
INFO - Training [74][  100/  196]   Loss 0.015637   Top1 99.531250   Top5 100.000000   BatchTime 0.134932   LR 0.000010
INFO - Training [74][  120/  196]   Loss 0.015898   Top1 99.511719   Top5 100.000000   BatchTime 0.129362   LR 0.000010
INFO - Training [74][  140/  196]   Loss 0.015814   Top1 99.522879   Top5 100.000000   BatchTime 0.125198   LR 0.000010
INFO - Training [74][  160/  196]   Loss 0.015757   Top1 99.523926   Top5 100.000000   BatchTime 0.121695   LR 0.000010
INFO - Training [74][  180/  196]   Loss 0.015858   Top1 99.524740   Top5 100.000000   BatchTime 0.119345   LR 0.000010
INFO - ==> Top1: 99.516    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [74][   20/   40]   Loss 0.474758   Top1 90.253906   Top5 99.453125   BatchTime 0.143362
INFO - Validation [74][   40/   40]   Loss 0.459340   Top1 90.600000   Top5 99.580000   BatchTime 0.100217
INFO - ==> Top1: 90.600    Top5: 99.580    Loss: 0.459
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  75
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [75][   20/  196]   Loss 0.019451   Top1 99.316406   Top5 100.000000   BatchTime 0.218161   LR 0.000010
INFO - Training [75][   40/  196]   Loss 0.019292   Top1 99.316406   Top5 100.000000   BatchTime 0.170817   LR 0.000010
INFO - Training [75][   60/  196]   Loss 0.017673   Top1 99.368490   Top5 100.000000   BatchTime 0.154659   LR 0.000010
INFO - Training [75][   80/  196]   Loss 0.017352   Top1 99.399414   Top5 100.000000   BatchTime 0.146889   LR 0.000010
INFO - Training [75][  100/  196]   Loss 0.017042   Top1 99.417969   Top5 100.000000   BatchTime 0.142286   LR 0.000010
INFO - Training [75][  120/  196]   Loss 0.016812   Top1 99.423828   Top5 100.000000   BatchTime 0.139269   LR 0.000010
INFO - Training [75][  140/  196]   Loss 0.016613   Top1 99.428013   Top5 100.000000   BatchTime 0.136978   LR 0.000010
INFO - Training [75][  160/  196]   Loss 0.016717   Top1 99.433594   Top5 100.000000   BatchTime 0.135309   LR 0.000010
INFO - Training [75][  180/  196]   Loss 0.016458   Top1 99.446615   Top5 100.000000   BatchTime 0.133968   LR 0.000010
INFO - ==> Top1: 99.438    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [75][   20/   40]   Loss 0.465711   Top1 90.410156   Top5 99.531250   BatchTime 0.142647
INFO - Validation [75][   40/   40]   Loss 0.454809   Top1 90.650000   Top5 99.650000   BatchTime 0.099415
INFO - ==> Top1: 90.650    Top5: 99.650    Loss: 0.455
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  76
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [76][   20/  196]   Loss 0.016096   Top1 99.472656   Top5 100.000000   BatchTime 0.220989   LR 0.000010
INFO - Training [76][   40/  196]   Loss 0.015485   Top1 99.511719   Top5 100.000000   BatchTime 0.154467   LR 0.000010
INFO - Training [76][   60/  196]   Loss 0.015102   Top1 99.544271   Top5 100.000000   BatchTime 0.137628   LR 0.000010
INFO - Training [76][   80/  196]   Loss 0.015062   Top1 99.536133   Top5 100.000000   BatchTime 0.128423   LR 0.000010
INFO - Training [76][  100/  196]   Loss 0.014661   Top1 99.550781   Top5 100.000000   BatchTime 0.122921   LR 0.000010
INFO - Training [76][  120/  196]   Loss 0.015138   Top1 99.537760   Top5 100.000000   BatchTime 0.119145   LR 0.000010
INFO - Training [76][  140/  196]   Loss 0.015338   Top1 99.534040   Top5 100.000000   BatchTime 0.119839   LR 0.000010
INFO - Training [76][  160/  196]   Loss 0.016654   Top1 99.484863   Top5 100.000000   BatchTime 0.120239   LR 0.000010
INFO - Training [76][  180/  196]   Loss 0.016591   Top1 99.476997   Top5 100.000000   BatchTime 0.120545   LR 0.000010
INFO - ==> Top1: 99.474    Top5: 100.000    Loss: 0.017
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [76][   20/   40]   Loss 0.469583   Top1 90.390625   Top5 99.531250   BatchTime 0.141094
INFO - Validation [76][   40/   40]   Loss 0.456106   Top1 90.730000   Top5 99.640000   BatchTime 0.098484
INFO - ==> Top1: 90.730    Top5: 99.640    Loss: 0.456
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  77
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [77][   20/  196]   Loss 0.015608   Top1 99.570312   Top5 100.000000   BatchTime 0.218497   LR 0.000010
INFO - Training [77][   40/  196]   Loss 0.016744   Top1 99.492188   Top5 100.000000   BatchTime 0.170994   LR 0.000010
INFO - Training [77][   60/  196]   Loss 0.017085   Top1 99.446615   Top5 100.000000   BatchTime 0.155238   LR 0.000010
INFO - Training [77][   80/  196]   Loss 0.016420   Top1 99.472656   Top5 100.000000   BatchTime 0.147343   LR 0.000010
INFO - Training [77][  100/  196]   Loss 0.016014   Top1 99.480469   Top5 100.000000   BatchTime 0.142692   LR 0.000010
INFO - Training [77][  120/  196]   Loss 0.015819   Top1 99.495443   Top5 100.000000   BatchTime 0.139530   LR 0.000010
INFO - Training [77][  140/  196]   Loss 0.016310   Top1 99.478237   Top5 100.000000   BatchTime 0.137263   LR 0.000010
INFO - Training [77][  160/  196]   Loss 0.016165   Top1 99.482422   Top5 100.000000   BatchTime 0.135532   LR 0.000010
INFO - Training [77][  180/  196]   Loss 0.016276   Top1 99.483507   Top5 100.000000   BatchTime 0.134113   LR 0.000010
INFO - ==> Top1: 99.488    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [77][   20/   40]   Loss 0.470061   Top1 90.507812   Top5 99.472656   BatchTime 0.143156
INFO - Validation [77][   40/   40]   Loss 0.457941   Top1 90.790000   Top5 99.580000   BatchTime 0.092595
INFO - ==> Top1: 90.790    Top5: 99.580    Loss: 0.458
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  78
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [78][   20/  196]   Loss 0.012658   Top1 99.609375   Top5 100.000000   BatchTime 0.201177   LR 0.000010
INFO - Training [78][   40/  196]   Loss 0.013501   Top1 99.560547   Top5 100.000000   BatchTime 0.152266   LR 0.000010
INFO - Training [78][   60/  196]   Loss 0.014294   Top1 99.550781   Top5 100.000000   BatchTime 0.132855   LR 0.000010
INFO - Training [78][   80/  196]   Loss 0.014958   Top1 99.492188   Top5 100.000000   BatchTime 0.130548   LR 0.000010
INFO - Training [78][  100/  196]   Loss 0.014505   Top1 99.527344   Top5 100.000000   BatchTime 0.129116   LR 0.000010
INFO - Training [78][  120/  196]   Loss 0.014934   Top1 99.514974   Top5 100.000000   BatchTime 0.128216   LR 0.000010
INFO - Training [78][  140/  196]   Loss 0.015332   Top1 99.503348   Top5 100.000000   BatchTime 0.127528   LR 0.000010
INFO - Training [78][  160/  196]   Loss 0.015681   Top1 99.499512   Top5 100.000000   BatchTime 0.126984   LR 0.000010
INFO - Training [78][  180/  196]   Loss 0.015845   Top1 99.503038   Top5 99.997830   BatchTime 0.126557   LR 0.000010
INFO - ==> Top1: 99.490    Top5: 99.998    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [78][   20/   40]   Loss 0.459752   Top1 90.644531   Top5 99.511719   BatchTime 0.143473
INFO - Validation [78][   40/   40]   Loss 0.453736   Top1 90.760000   Top5 99.620000   BatchTime 0.100215
INFO - ==> Top1: 90.760    Top5: 99.620    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  79
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [79][   20/  196]   Loss 0.015122   Top1 99.472656   Top5 100.000000   BatchTime 0.217300   LR 0.000010
INFO - Training [79][   40/  196]   Loss 0.013846   Top1 99.550781   Top5 100.000000   BatchTime 0.170461   LR 0.000010
INFO - Training [79][   60/  196]   Loss 0.016147   Top1 99.440104   Top5 100.000000   BatchTime 0.154666   LR 0.000010
INFO - Training [79][   80/  196]   Loss 0.016572   Top1 99.433594   Top5 100.000000   BatchTime 0.146851   LR 0.000010
INFO - Training [79][  100/  196]   Loss 0.016209   Top1 99.457031   Top5 100.000000   BatchTime 0.142292   LR 0.000010
INFO - Training [79][  120/  196]   Loss 0.015995   Top1 99.479167   Top5 100.000000   BatchTime 0.139244   LR 0.000010
INFO - Training [79][  140/  196]   Loss 0.016409   Top1 99.453125   Top5 100.000000   BatchTime 0.136988   LR 0.000010
INFO - Training [79][  160/  196]   Loss 0.016303   Top1 99.450684   Top5 100.000000   BatchTime 0.135242   LR 0.000010
INFO - Training [79][  180/  196]   Loss 0.016233   Top1 99.450955   Top5 100.000000   BatchTime 0.133891   LR 0.000010
INFO - ==> Top1: 99.466    Top5: 100.000    Loss: 0.016
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [79][   20/   40]   Loss 0.468345   Top1 90.664062   Top5 99.492188   BatchTime 0.131224
INFO - Validation [79][   40/   40]   Loss 0.453618   Top1 90.830000   Top5 99.650000   BatchTime 0.085354
INFO - ==> Top1: 90.830    Top5: 99.650    Loss: 0.454
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.468345   Top1 90.664062   Top5 99.492188   BatchTime 0.150577
INFO - Validation [   40/   40]   Loss 0.453618   Top1 90.830000   Top5 99.650000   BatchTime 0.102809
INFO - ==> Top1: 90.830    Top5: 99.650    Loss: 0.454
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net