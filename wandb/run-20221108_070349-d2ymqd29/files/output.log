INFO - Log file for this run: /home/ilena7440/LSQ/out/ResNet18_imagenet_a8w8_2_5_epoch80_20221108-070350/ResNet18_imagenet_a8w8_2_5_epoch80_20221108-070350.log
INFO - TensorBoard data directory: /home/ilena7440/LSQ/out/ResNet18_imagenet_a8w8_2_5_epoch80_20221108-070350/tb_runs
INFO - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
INFO - Created `resnet18` model for `imagenet` dataset
          Use pre-trained model = True
*******************pre-trained****************
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
/home/ilena7440/LSQ/quan/quantizer/lsq.py:137: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
INFO - Inserted quantizers into the original model
Munch({'update_per_batch': True, 'mode': 'multi_step', 'milestones': [20, 40, 60], 'gamma': 0.1})
multi_step
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 50000 samples (128 per mini-batch)
INFO - Validation [   20/  391]   Loss 10.426115   Top1 0.000000   Top5 0.000000   BatchTime 0.843098
INFO - Validation [   40/  391]   Loss 9.851932   Top1 0.058594   Top5 0.390625   BatchTime 0.473377
INFO - Validation [   60/  391]   Loss 10.078457   Top1 0.039062   Top5 0.299479   BatchTime 0.343891
INFO - Validation [   80/  391]   Loss 9.897195   Top1 0.029297   Top5 0.234375   BatchTime 0.293699
INFO - Validation [  100/  391]   Loss 9.835794   Top1 0.023438   Top5 0.234375   BatchTime 0.276810
INFO - Validation [  120/  391]   Loss 9.867029   Top1 0.019531   Top5 0.208333   BatchTime 0.253849
INFO - Validation [  140/  391]   Loss 9.910343   Top1 0.033482   Top5 0.251116   BatchTime 0.231076
INFO - Validation [  160/  391]   Loss 9.933602   Top1 0.219727   Top5 0.517578   BatchTime 0.213661
INFO - Validation [  180/  391]   Loss 9.767149   Top1 0.199653   Top5 0.594618   BatchTime 0.201309
INFO - Validation [  200/  391]   Loss 9.629207   Top1 0.261719   Top5 0.882812   BatchTime 0.191052
INFO - Validation [  220/  391]   Loss 9.559465   Top1 0.255682   Top5 0.948153   BatchTime 0.183284
INFO - Validation [  240/  391]   Loss 9.480269   Top1 0.341797   Top5 1.103516   BatchTime 0.176331
INFO - Validation [  260/  391]   Loss 9.385702   Top1 0.357572   Top5 1.259014   BatchTime 0.170299
INFO - Validation [  280/  391]   Loss 9.332992   Top1 0.357143   Top5 1.283482   BatchTime 0.165234
INFO - Validation [  300/  391]   Loss 9.263727   Top1 0.390625   Top5 1.419271   BatchTime 0.160789
INFO - Validation [  320/  391]   Loss 9.216885   Top1 0.427246   Top5 1.542969   BatchTime 0.156773
INFO - Validation [  340/  391]   Loss 9.160497   Top1 0.418199   Top5 1.592371   BatchTime 0.152695
INFO - Validation [  360/  391]   Loss 9.129761   Top1 0.444878   Top5 1.740451   BatchTime 0.147994
INFO - Validation [  380/  391]   Loss 9.136724   Top1 0.425576   Top5 1.679688   BatchTime 0.143598
INFO - ==> Top1: 0.414    Top5: 1.678    Loss: 9.133
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 0.414   Top5: 1.678] Sparsity : 0.058
INFO - >>>>>>>> Epoch   0
INFO - Training: 1281167 samples (128 per mini-batch)
Traceback (most recent call last):
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/munch/__init__.py", line 103, in __getattr__
    return object.__getattribute__(self, k)
AttributeError: 'Munch' object has no attribute 'sigmoid'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/munch/__init__.py", line 106, in __getattr__
    return self[k]
KeyError: 'sigmoid'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "main.py", line 175, in <module>
    main()
  File "main.py", line 123, in main
    t_top1, t_top5, t_loss, masking_loss = process.train(train_loader, model, criterion, optimizer,
  File "/home/ilena7440/LSQ/process.py", line 46, in train
    if epoch in args.sigmoid.mile_stone:
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/munch/__init__.py", line 108, in __getattr__
    raise AttributeError(k)
AttributeError: sigmoid