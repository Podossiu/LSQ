
Files already downloaded and verified
INFO - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803.log
2022-11-03 23:58:03.497955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-03 23:58:03.642905: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-03 23:58:04.051568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-03 23:58:04.051617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-03 23:58:04.051623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
INFO - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/tb_runs
Files already downloaded and verified
hello
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/slsq/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
INFO - Inserted quantizers into the original model
DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Sequential(
        (0): QuanConv2d(
          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (quan_w_fn): IdentityQuan()
          (quan_a_fn): IdentityQuan()
        )
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): QuanConv2d(
            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): QuanConv2d(
            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): QuanConv2d(
            960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
            (quan_w_fn): SLsqQuan()
            (quan_a_fn): LsqQuan()
          )
          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): QuanConv2d(
        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
        (quan_w_fn): SLsqQuan()
        (quan_a_fn): LsqQuan()
      )
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): QuanLinear(
      in_features=1280, out_features=10, bias=True
      (quan_w_fn): IdentityQuan()
      (quan_a_fn): IdentityQuan()
    )
  )
)
INFO - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.394165   Top1 90.351562   Top5 99.648438   BatchTime 0.197034
INFO - Validation [   40/   40]   Loss 0.383492   Top1 90.380000   Top5 99.660000   BatchTime 0.129471
INFO - ==> Top1: 90.380    Top5: 99.660    Loss: 0.383
INFO - Scoreboard best 1 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - >>>>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.036699   Top1 98.769531   Top5 100.000000   BatchTime 0.214989   LR 0.010000
INFO - Training [0][   40/  196]   Loss 0.040467   Top1 98.603516   Top5 100.000000   BatchTime 0.158481   LR 0.010000
INFO - Training [0][   60/  196]   Loss 0.042308   Top1 98.619792   Top5 99.993490   BatchTime 0.139271   LR 0.010000
INFO - Training [0][   80/  196]   Loss 0.043505   Top1 98.574219   Top5 99.995117   BatchTime 0.129644   LR 0.010000
INFO - Training [0][  100/  196]   Loss 0.044471   Top1 98.550781   Top5 99.996094   BatchTime 0.126161   LR 0.010000
INFO - Training [0][  120/  196]   Loss 0.044117   Top1 98.535156   Top5 99.996745   BatchTime 0.126080   LR 0.010000
INFO - Training [0][  140/  196]   Loss 0.044450   Top1 98.493304   Top5 99.997210   BatchTime 0.125706   LR 0.010000
INFO - Training [0][  160/  196]   Loss 0.046188   Top1 98.413086   Top5 99.995117   BatchTime 0.125401   LR 0.010000
INFO - Training [0][  180/  196]   Loss 0.047974   Top1 98.352865   Top5 99.995660   BatchTime 0.125151   LR 0.010000
INFO - ==> Top1: 98.322    Top5: 99.996    Loss: 0.049
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.405257   Top1 90.390625   Top5 99.414062   BatchTime 0.147502
INFO - Validation [0][   40/   40]   Loss 0.395530   Top1 90.390000   Top5 99.540000   BatchTime 0.102461
INFO - ==> Top1: 90.390    Top5: 99.540    Loss: 0.396
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.043257   Top1 98.535156   Top5 100.000000   BatchTime 0.224667   LR 0.010000
INFO - Training [1][   40/  196]   Loss 0.047632   Top1 98.359375   Top5 100.000000   BatchTime 0.176444   LR 0.010000
INFO - Training [1][   60/  196]   Loss 0.051511   Top1 98.248698   Top5 100.000000   BatchTime 0.158769   LR 0.010000
INFO - Training [1][   80/  196]   Loss 0.049009   Top1 98.388672   Top5 100.000000   BatchTime 0.149556   LR 0.010000
INFO - Training [1][  100/  196]   Loss 0.047107   Top1 98.457031   Top5 100.000000   BatchTime 0.144483   LR 0.010000
INFO - Training [1][  120/  196]   Loss 0.047382   Top1 98.470052   Top5 100.000000   BatchTime 0.140973   LR 0.010000
INFO - Training [1][  140/  196]   Loss 0.047563   Top1 98.473772   Top5 99.997210   BatchTime 0.138432   LR 0.010000
INFO - Training [1][  160/  196]   Loss 0.047269   Top1 98.481445   Top5 99.997559   BatchTime 0.136454   LR 0.010000
INFO - Training [1][  180/  196]   Loss 0.047654   Top1 98.430990   Top5 99.997830   BatchTime 0.134881   LR 0.010000
INFO - ==> Top1: 98.396    Top5: 99.998    Loss: 0.048
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.424630   Top1 90.019531   Top5 99.589844   BatchTime 0.142436
INFO - Validation [1][   40/   40]   Loss 0.412254   Top1 90.180000   Top5 99.620000   BatchTime 0.092508
INFO - ==> Top1: 90.180    Top5: 99.620    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 90.180   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.043746   Top1 98.457031   Top5 100.000000   BatchTime 0.211293   LR 0.010000
INFO - Training [2][   40/  196]   Loss 0.043902   Top1 98.310547   Top5 100.000000   BatchTime 0.167540   LR 0.010000
INFO - Training [2][   60/  196]   Loss 0.044116   Top1 98.320312   Top5 99.993490   BatchTime 0.153375   LR 0.010000
INFO - Training [2][   80/  196]   Loss 0.046015   Top1 98.261719   Top5 99.995117   BatchTime 0.145961   LR 0.010000
INFO - Training [2][  100/  196]   Loss 0.045999   Top1 98.285156   Top5 99.996094   BatchTime 0.141591   LR 0.010000
INFO - Training [2][  120/  196]   Loss 0.045907   Top1 98.317057   Top5 99.996745   BatchTime 0.138525   LR 0.010000
INFO - Training [2][  140/  196]   Loss 0.047063   Top1 98.284040   Top5 99.997210   BatchTime 0.136396   LR 0.010000
INFO - Training [2][  160/  196]   Loss 0.047715   Top1 98.266602   Top5 99.995117   BatchTime 0.134696   LR 0.010000
INFO - Training [2][  180/  196]   Loss 0.048013   Top1 98.259549   Top5 99.995660   BatchTime 0.133385   LR 0.010000
INFO - ==> Top1: 98.266    Top5: 99.996    Loss: 0.048
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.422561   Top1 89.960938   Top5 99.511719   BatchTime 0.147608
INFO - Validation [2][   40/   40]   Loss 0.410054   Top1 90.140000   Top5 99.570000   BatchTime 0.101890
INFO - ==> Top1: 90.140    Top5: 99.570    Loss: 0.410
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 90.180   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 0.041520   Top1 98.515625   Top5 100.000000   BatchTime 0.221823   LR 0.010000
INFO - Training [3][   40/  196]   Loss 0.044242   Top1 98.457031   Top5 99.990234   BatchTime 0.172519   LR 0.010000
INFO - Training [3][   60/  196]   Loss 0.045110   Top1 98.372396   Top5 99.993490   BatchTime 0.156122   LR 0.010000
INFO - Training [3][   80/  196]   Loss 0.046022   Top1 98.339844   Top5 99.995117   BatchTime 0.147867   LR 0.010000
INFO - Training [3][  100/  196]   Loss 0.046498   Top1 98.347656   Top5 99.996094   BatchTime 0.142886   LR 0.010000
INFO - Training [3][  120/  196]   Loss 0.046493   Top1 98.362630   Top5 99.996745   BatchTime 0.139756   LR 0.010000
INFO - Training [3][  140/  196]   Loss 0.046746   Top1 98.331473   Top5 99.997210   BatchTime 0.134814   LR 0.010000
INFO - Training [3][  160/  196]   Loss 0.046618   Top1 98.342285   Top5 99.997559   BatchTime 0.130015   LR 0.010000
INFO - Training [3][  180/  196]   Loss 0.047538   Top1 98.300781   Top5 99.997830   BatchTime 0.126756   LR 0.010000
INFO - ==> Top1: 98.322    Top5: 99.998    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 0.412581   Top1 90.019531   Top5 99.511719   BatchTime 0.154063
INFO - Validation [3][   40/   40]   Loss 0.402157   Top1 90.200000   Top5 99.560000   BatchTime 0.105144
INFO - ==> Top1: 90.200    Top5: 99.560    Loss: 0.402
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 90.200   Top5: 99.560] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 0.047202   Top1 98.300781   Top5 100.000000   BatchTime 0.225228   LR 0.010000
INFO - Training [4][   40/  196]   Loss 0.040255   Top1 98.593750   Top5 100.000000   BatchTime 0.174275   LR 0.010000
INFO - Training [4][   60/  196]   Loss 0.042780   Top1 98.483073   Top5 100.000000   BatchTime 0.157599   LR 0.010000
INFO - Training [4][   80/  196]   Loss 0.045138   Top1 98.388672   Top5 99.995117   BatchTime 0.149182   LR 0.010000
INFO - Training [4][  100/  196]   Loss 0.044662   Top1 98.433594   Top5 99.996094   BatchTime 0.144120   LR 0.010000
INFO - Training [4][  120/  196]   Loss 0.044608   Top1 98.444010   Top5 99.996745   BatchTime 0.140650   LR 0.010000
INFO - Training [4][  140/  196]   Loss 0.045648   Top1 98.384487   Top5 99.997210   BatchTime 0.138217   LR 0.010000
INFO - Training [4][  160/  196]   Loss 0.046711   Top1 98.352051   Top5 99.997559   BatchTime 0.136343   LR 0.010000
INFO - Training [4][  180/  196]   Loss 0.047074   Top1 98.326823   Top5 99.997830   BatchTime 0.134870   LR 0.010000
INFO - ==> Top1: 98.326    Top5: 99.998    Loss: 0.047
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 0.406136   Top1 90.625000   Top5 99.511719   BatchTime 0.148956
INFO - Validation [4][   40/   40]   Loss 0.400077   Top1 90.710000   Top5 99.510000   BatchTime 0.103125
INFO - ==> Top1: 90.710    Top5: 99.510    Loss: 0.400
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 0.039834   Top1 98.574219   Top5 100.000000   BatchTime 0.227146   LR 0.010000
INFO - Training [5][   40/  196]   Loss 0.040818   Top1 98.603516   Top5 100.000000   BatchTime 0.175526   LR 0.010000
INFO - Training [5][   60/  196]   Loss 0.043380   Top1 98.457031   Top5 100.000000   BatchTime 0.158180   LR 0.010000
INFO - Training [5][   80/  196]   Loss 0.043058   Top1 98.496094   Top5 100.000000   BatchTime 0.143109   LR 0.010000
INFO - Training [5][  100/  196]   Loss 0.043084   Top1 98.503906   Top5 99.996094   BatchTime 0.134832   LR 0.010000
INFO - Training [5][  120/  196]   Loss 0.044085   Top1 98.447266   Top5 99.996745   BatchTime 0.129448   LR 0.010000
INFO - Training [5][  140/  196]   Loss 0.044670   Top1 98.426339   Top5 99.997210   BatchTime 0.125758   LR 0.010000
INFO - Training [5][  160/  196]   Loss 0.044077   Top1 98.444824   Top5 99.997559   BatchTime 0.121954   LR 0.010000
INFO - Training [5][  180/  196]   Loss 0.044698   Top1 98.444010   Top5 99.995660   BatchTime 0.122130   LR 0.010000
INFO - ==> Top1: 98.436    Top5: 99.996    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.415628   Top1 90.390625   Top5 99.492188   BatchTime 0.148230
INFO - Validation [5][   40/   40]   Loss 0.416535   Top1 90.180000   Top5 99.580000   BatchTime 0.102839
INFO - ==> Top1: 90.180    Top5: 99.580    Loss: 0.417
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 0.042893   Top1 98.515625   Top5 100.000000   BatchTime 0.225934   LR 0.010000
INFO - Training [6][   40/  196]   Loss 0.044085   Top1 98.437500   Top5 100.000000   BatchTime 0.175026   LR 0.010000
INFO - Training [6][   60/  196]   Loss 0.044402   Top1 98.417969   Top5 100.000000   BatchTime 0.157930   LR 0.010000
INFO - Training [6][   80/  196]   Loss 0.041640   Top1 98.525391   Top5 100.000000   BatchTime 0.149468   LR 0.010000
INFO - Training [6][  100/  196]   Loss 0.043594   Top1 98.429688   Top5 100.000000   BatchTime 0.144610   LR 0.010000
INFO - Training [6][  120/  196]   Loss 0.044153   Top1 98.414714   Top5 100.000000   BatchTime 0.141185   LR 0.010000
INFO - Training [6][  140/  196]   Loss 0.044582   Top1 98.404018   Top5 100.000000   BatchTime 0.138705   LR 0.010000
INFO - Training [6][  160/  196]   Loss 0.045351   Top1 98.391113   Top5 100.000000   BatchTime 0.136796   LR 0.010000
INFO - Training [6][  180/  196]   Loss 0.045046   Top1 98.383247   Top5 100.000000   BatchTime 0.135314   LR 0.010000
INFO - ==> Top1: 98.384    Top5: 99.998    Loss: 0.045
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 0.423459   Top1 90.078125   Top5 99.589844   BatchTime 0.147973
INFO - Validation [6][   40/   40]   Loss 0.411558   Top1 90.230000   Top5 99.630000   BatchTime 0.101446
INFO - ==> Top1: 90.230    Top5: 99.630    Loss: 0.412
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 0.040320   Top1 98.515625   Top5 100.000000   BatchTime 0.198222   LR 0.010000
INFO - Training [7][   40/  196]   Loss 0.041122   Top1 98.662109   Top5 100.000000   BatchTime 0.150462   LR 0.010000
INFO - Training [7][   60/  196]   Loss 0.041214   Top1 98.606771   Top5 100.000000   BatchTime 0.134504   LR 0.010000
INFO - Training [7][   80/  196]   Loss 0.042479   Top1 98.549805   Top5 99.995117   BatchTime 0.125067   LR 0.010000
INFO - Training [7][  100/  196]   Loss 0.044581   Top1 98.445312   Top5 99.996094   BatchTime 0.121975   LR 0.010000
INFO - Training [7][  120/  196]   Loss 0.045072   Top1 98.430990   Top5 99.996745   BatchTime 0.122321   LR 0.010000
INFO - Training [7][  140/  196]   Loss 0.044911   Top1 98.431920   Top5 99.997210   BatchTime 0.122629   LR 0.010000
INFO - Training [7][  160/  196]   Loss 0.045196   Top1 98.430176   Top5 99.997559   BatchTime 0.122752   LR 0.010000
INFO - Training [7][  180/  196]   Loss 0.045342   Top1 98.411458   Top5 99.997830   BatchTime 0.122904   LR 0.010000
INFO - ==> Top1: 98.386    Top5: 99.998    Loss: 0.046
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.423513   Top1 89.941406   Top5 99.550781   BatchTime 0.146456
INFO - Validation [7][   40/   40]   Loss 0.413985   Top1 90.010000   Top5 99.590000   BatchTime 0.101745
INFO - ==> Top1: 90.010    Top5: 99.590    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 0.039058   Top1 98.710938   Top5 100.000000   BatchTime 0.223237   LR 0.010000
INFO - Training [8][   40/  196]   Loss 0.041088   Top1 98.613281   Top5 100.000000   BatchTime 0.173877   LR 0.010000
INFO - Training [8][   60/  196]   Loss 0.041796   Top1 98.619792   Top5 100.000000   BatchTime 0.157288   LR 0.010000
INFO - Training [8][   80/  196]   Loss 0.043267   Top1 98.496094   Top5 100.000000   BatchTime 0.148968   LR 0.010000
INFO - Training [8][  100/  196]   Loss 0.042048   Top1 98.523438   Top5 100.000000   BatchTime 0.143929   LR 0.010000
INFO - Training [8][  120/  196]   Loss 0.041575   Top1 98.535156   Top5 100.000000   BatchTime 0.140510   LR 0.010000
INFO - Training [8][  140/  196]   Loss 0.040838   Top1 98.549107   Top5 100.000000   BatchTime 0.138059   LR 0.010000
INFO - Training [8][  160/  196]   Loss 0.040575   Top1 98.579102   Top5 100.000000   BatchTime 0.136179   LR 0.010000
INFO - Training [8][  180/  196]   Loss 0.040685   Top1 98.572049   Top5 100.000000   BatchTime 0.134709   LR 0.010000
INFO - ==> Top1: 98.570    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.434809   Top1 90.332031   Top5 99.492188   BatchTime 0.135631
INFO - Validation [8][   40/   40]   Loss 0.426610   Top1 90.360000   Top5 99.550000   BatchTime 0.089228
INFO - ==> Top1: 90.360    Top5: 99.550    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 0.042218   Top1 98.398438   Top5 100.000000   BatchTime 0.196324   LR 0.010000
INFO - Training [9][   40/  196]   Loss 0.039455   Top1 98.476562   Top5 100.000000   BatchTime 0.160389   LR 0.010000
INFO - Training [9][   60/  196]   Loss 0.039847   Top1 98.483073   Top5 100.000000   BatchTime 0.149712   LR 0.010000
INFO - Training [9][   80/  196]   Loss 0.039560   Top1 98.505859   Top5 100.000000   BatchTime 0.143312   LR 0.010000
INFO - Training [9][  100/  196]   Loss 0.040085   Top1 98.519531   Top5 100.000000   BatchTime 0.139651   LR 0.010000
INFO - Training [9][  120/  196]   Loss 0.039327   Top1 98.538411   Top5 99.996745   BatchTime 0.137148   LR 0.010000
INFO - Training [9][  140/  196]   Loss 0.039461   Top1 98.515625   Top5 99.997210   BatchTime 0.135223   LR 0.010000
INFO - Training [9][  160/  196]   Loss 0.039541   Top1 98.525391   Top5 99.997559   BatchTime 0.133708   LR 0.010000
INFO - Training [9][  180/  196]   Loss 0.039495   Top1 98.539497   Top5 99.997830   BatchTime 0.132565   LR 0.010000
INFO - ==> Top1: 98.546    Top5: 99.996    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [9][   20/   40]   Loss 0.432330   Top1 90.214844   Top5 99.492188   BatchTime 0.148586
INFO - Validation [9][   40/   40]   Loss 0.414308   Top1 90.270000   Top5 99.600000   BatchTime 0.102159
INFO - ==> Top1: 90.270    Top5: 99.600    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 0.032440   Top1 98.750000   Top5 100.000000   BatchTime 0.225088   LR 0.010000
INFO - Training [10][   40/  196]   Loss 0.035528   Top1 98.720703   Top5 100.000000   BatchTime 0.174276   LR 0.010000
INFO - Training [10][   60/  196]   Loss 0.037197   Top1 98.691406   Top5 100.000000   BatchTime 0.157487   LR 0.010000
INFO - Training [10][   80/  196]   Loss 0.038163   Top1 98.676758   Top5 100.000000   BatchTime 0.149077   LR 0.010000
INFO - Training [10][  100/  196]   Loss 0.037626   Top1 98.683594   Top5 100.000000   BatchTime 0.144030   LR 0.010000
INFO - Training [10][  120/  196]   Loss 0.037973   Top1 98.688151   Top5 100.000000   BatchTime 0.140602   LR 0.010000
INFO - Training [10][  140/  196]   Loss 0.037998   Top1 98.666295   Top5 100.000000   BatchTime 0.137425   LR 0.010000
INFO - Training [10][  160/  196]   Loss 0.038387   Top1 98.657227   Top5 100.000000   BatchTime 0.131545   LR 0.010000
INFO - Training [10][  180/  196]   Loss 0.038504   Top1 98.645833   Top5 100.000000   BatchTime 0.128118   LR 0.010000
INFO - ==> Top1: 98.638    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 0.426188   Top1 90.312500   Top5 99.492188   BatchTime 0.146382
INFO - Validation [10][   40/   40]   Loss 0.415799   Top1 90.400000   Top5 99.550000   BatchTime 0.101594
INFO - ==> Top1: 90.400    Top5: 99.550    Loss: 0.416
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 0.037111   Top1 98.593750   Top5 100.000000   BatchTime 0.222224   LR 0.010000
INFO - Training [11][   40/  196]   Loss 0.036809   Top1 98.740234   Top5 100.000000   BatchTime 0.173166   LR 0.010000
INFO - Training [11][   60/  196]   Loss 0.037754   Top1 98.645833   Top5 100.000000   BatchTime 0.156718   LR 0.010000
INFO - Training [11][   80/  196]   Loss 0.039395   Top1 98.603516   Top5 100.000000   BatchTime 0.148499   LR 0.010000
INFO - Training [11][  100/  196]   Loss 0.040788   Top1 98.539062   Top5 100.000000   BatchTime 0.144014   LR 0.010000
INFO - Training [11][  120/  196]   Loss 0.040040   Top1 98.603516   Top5 100.000000   BatchTime 0.140737   LR 0.010000
INFO - Training [11][  140/  196]   Loss 0.040322   Top1 98.582589   Top5 100.000000   BatchTime 0.138284   LR 0.010000
INFO - Training [11][  160/  196]   Loss 0.039196   Top1 98.620605   Top5 100.000000   BatchTime 0.136404   LR 0.010000
INFO - Training [11][  180/  196]   Loss 0.040128   Top1 98.563368   Top5 100.000000   BatchTime 0.134970   LR 0.010000
INFO - ==> Top1: 98.566    Top5: 100.000    Loss: 0.040
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.422850   Top1 90.117188   Top5 99.589844   BatchTime 0.148198
INFO - Validation [11][   40/   40]   Loss 0.414019   Top1 90.430000   Top5 99.630000   BatchTime 0.101423
INFO - ==> Top1: 90.430    Top5: 99.630    Loss: 0.414
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 0.039213   Top1 98.671875   Top5 100.000000   BatchTime 0.222000   LR 0.010000
INFO - Training [12][   40/  196]   Loss 0.039908   Top1 98.613281   Top5 100.000000   BatchTime 0.172669   LR 0.010000
INFO - Training [12][   60/  196]   Loss 0.040502   Top1 98.593750   Top5 100.000000   BatchTime 0.156347   LR 0.010000
INFO - Training [12][   80/  196]   Loss 0.040878   Top1 98.525391   Top5 100.000000   BatchTime 0.146201   LR 0.010000
INFO - Training [12][  100/  196]   Loss 0.039676   Top1 98.585938   Top5 100.000000   BatchTime 0.135447   LR 0.010000
INFO - Training [12][  120/  196]   Loss 0.041051   Top1 98.522135   Top5 100.000000   BatchTime 0.129976   LR 0.010000
INFO - Training [12][  140/  196]   Loss 0.041062   Top1 98.521205   Top5 100.000000   BatchTime 0.126011   LR 0.010000
INFO - Training [12][  160/  196]   Loss 0.041569   Top1 98.481445   Top5 100.000000   BatchTime 0.121981   LR 0.010000
INFO - Training [12][  180/  196]   Loss 0.040796   Top1 98.522135   Top5 100.000000   BatchTime 0.120944   LR 0.010000
INFO - ==> Top1: 98.494    Top5: 100.000    Loss: 0.041
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.428623   Top1 90.332031   Top5 99.648438   BatchTime 0.148488
INFO - Validation [12][   40/   40]   Loss 0.415409   Top1 90.350000   Top5 99.690000   BatchTime 0.102269
INFO - ==> Top1: 90.350    Top5: 99.690    Loss: 0.415
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 0.033332   Top1 98.691406   Top5 99.980469   BatchTime 0.224345   LR 0.010000
INFO - Training [13][   40/  196]   Loss 0.037839   Top1 98.642578   Top5 99.990234   BatchTime 0.174296   LR 0.010000
INFO - Training [13][   60/  196]   Loss 0.038808   Top1 98.580729   Top5 99.993490   BatchTime 0.157734   LR 0.010000
INFO - Training [13][   80/  196]   Loss 0.039166   Top1 98.559570   Top5 99.995117   BatchTime 0.149298   LR 0.010000
INFO - Training [13][  100/  196]   Loss 0.038971   Top1 98.621094   Top5 99.996094   BatchTime 0.144264   LR 0.010000
INFO - Training [13][  120/  196]   Loss 0.039203   Top1 98.606771   Top5 99.996745   BatchTime 0.140883   LR 0.010000
INFO - Training [13][  140/  196]   Loss 0.038807   Top1 98.627232   Top5 99.997210   BatchTime 0.139361   LR 0.010000
INFO - Training [13][  160/  196]   Loss 0.038491   Top1 98.640137   Top5 99.997559   BatchTime 0.137397   LR 0.010000
INFO - Training [13][  180/  196]   Loss 0.038252   Top1 98.669705   Top5 99.997830   BatchTime 0.135806   LR 0.010000
INFO - ==> Top1: 98.642    Top5: 99.998    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [13][   20/   40]   Loss 0.432988   Top1 90.214844   Top5 99.531250   BatchTime 0.149827
INFO - Validation [13][   40/   40]   Loss 0.425946   Top1 90.280000   Top5 99.590000   BatchTime 0.103134
INFO - ==> Top1: 90.280    Top5: 99.590    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 0.026767   Top1 99.160156   Top5 100.000000   BatchTime 0.205912   LR 0.010000
INFO - Training [14][   40/  196]   Loss 0.032999   Top1 98.876953   Top5 100.000000   BatchTime 0.151588   LR 0.010000
INFO - Training [14][   60/  196]   Loss 0.034225   Top1 98.808594   Top5 100.000000   BatchTime 0.135347   LR 0.010000
INFO - Training [14][   80/  196]   Loss 0.036427   Top1 98.735352   Top5 100.000000   BatchTime 0.126641   LR 0.010000
INFO - Training [14][  100/  196]   Loss 0.035490   Top1 98.769531   Top5 100.000000   BatchTime 0.119052   LR 0.010000
INFO - Training [14][  120/  196]   Loss 0.035285   Top1 98.776042   Top5 100.000000   BatchTime 0.119330   LR 0.010000
INFO - Training [14][  140/  196]   Loss 0.035746   Top1 98.763951   Top5 100.000000   BatchTime 0.119941   LR 0.010000
INFO - Training [14][  160/  196]   Loss 0.035884   Top1 98.764648   Top5 100.000000   BatchTime 0.120362   LR 0.010000
INFO - Training [14][  180/  196]   Loss 0.036777   Top1 98.719618   Top5 100.000000   BatchTime 0.120705   LR 0.010000
INFO - ==> Top1: 98.728    Top5: 99.998    Loss: 0.037
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.436463   Top1 90.390625   Top5 99.570312   BatchTime 0.150175
INFO - Validation [14][   40/   40]   Loss 0.424772   Top1 90.620000   Top5 99.650000   BatchTime 0.103667
INFO - ==> Top1: 90.620    Top5: 99.650    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 0.038358   Top1 98.535156   Top5 100.000000   BatchTime 0.221946   LR 0.010000
INFO - Training [15][   40/  196]   Loss 0.037470   Top1 98.593750   Top5 100.000000   BatchTime 0.173073   LR 0.010000
INFO - Training [15][   60/  196]   Loss 0.034578   Top1 98.743490   Top5 100.000000   BatchTime 0.156959   LR 0.010000
INFO - Training [15][   80/  196]   Loss 0.036112   Top1 98.696289   Top5 100.000000   BatchTime 0.148782   LR 0.010000
INFO - Training [15][  100/  196]   Loss 0.037031   Top1 98.675781   Top5 100.000000   BatchTime 0.143818   LR 0.010000
INFO - Training [15][  120/  196]   Loss 0.037828   Top1 98.623047   Top5 100.000000   BatchTime 0.140526   LR 0.010000
INFO - Training [15][  140/  196]   Loss 0.037745   Top1 98.643973   Top5 100.000000   BatchTime 0.138169   LR 0.010000
INFO - Training [15][  160/  196]   Loss 0.038270   Top1 98.632812   Top5 100.000000   BatchTime 0.136290   LR 0.010000
INFO - Training [15][  180/  196]   Loss 0.038713   Top1 98.602431   Top5 100.000000   BatchTime 0.134804   LR 0.010000
INFO - ==> Top1: 98.614    Top5: 100.000    Loss: 0.039
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.425692   Top1 90.253906   Top5 99.648438   BatchTime 0.131750
INFO - Validation [15][   40/   40]   Loss 0.429446   Top1 90.050000   Top5 99.640000   BatchTime 0.083143
INFO - ==> Top1: 90.050    Top5: 99.640    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 0.030476   Top1 98.828125   Top5 100.000000   BatchTime 0.202029   LR 0.010000
INFO - Training [16][   40/  196]   Loss 0.033811   Top1 98.681641   Top5 100.000000   BatchTime 0.154785   LR 0.010000
INFO - Training [16][   60/  196]   Loss 0.035962   Top1 98.671875   Top5 100.000000   BatchTime 0.144354   LR 0.010000
INFO - Training [16][   80/  196]   Loss 0.034920   Top1 98.745117   Top5 100.000000   BatchTime 0.139394   LR 0.010000
INFO - Training [16][  100/  196]   Loss 0.035958   Top1 98.726562   Top5 100.000000   BatchTime 0.136271   LR 0.010000
INFO - Training [16][  120/  196]   Loss 0.036216   Top1 98.704427   Top5 100.000000   BatchTime 0.134282   LR 0.010000
INFO - Training [16][  140/  196]   Loss 0.036578   Top1 98.691406   Top5 100.000000   BatchTime 0.132442   LR 0.010000
INFO - Training [16][  160/  196]   Loss 0.036382   Top1 98.701172   Top5 100.000000   BatchTime 0.131299   LR 0.010000
INFO - Training [16][  180/  196]   Loss 0.036649   Top1 98.695747   Top5 100.000000   BatchTime 0.130390   LR 0.010000
INFO - ==> Top1: 98.694    Top5: 100.000    Loss: 0.036
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.440802   Top1 90.019531   Top5 99.550781   BatchTime 0.149444
INFO - Validation [16][   40/   40]   Loss 0.430241   Top1 90.380000   Top5 99.580000   BatchTime 0.103631
INFO - ==> Top1: 90.380    Top5: 99.580    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 0.033036   Top1 98.925781   Top5 100.000000   BatchTime 0.223192   LR 0.010000
INFO - Training [17][   40/  196]   Loss 0.032232   Top1 98.886719   Top5 100.000000   BatchTime 0.173673   LR 0.010000
INFO - Training [17][   60/  196]   Loss 0.033475   Top1 98.815104   Top5 100.000000   BatchTime 0.157280   LR 0.010000
INFO - Training [17][   80/  196]   Loss 0.034508   Top1 98.754883   Top5 100.000000   BatchTime 0.149316   LR 0.010000
INFO - Training [17][  100/  196]   Loss 0.034699   Top1 98.750000   Top5 100.000000   BatchTime 0.144282   LR 0.010000
INFO - Training [17][  120/  196]   Loss 0.034016   Top1 98.798828   Top5 100.000000   BatchTime 0.140834   LR 0.010000
INFO - Training [17][  140/  196]   Loss 0.033562   Top1 98.822545   Top5 100.000000   BatchTime 0.138430   LR 0.010000
INFO - Training [17][  160/  196]   Loss 0.032840   Top1 98.847656   Top5 100.000000   BatchTime 0.134214   LR 0.010000
INFO - Training [17][  180/  196]   Loss 0.033157   Top1 98.841146   Top5 100.000000   BatchTime 0.129860   LR 0.010000
INFO - ==> Top1: 98.858    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.435134   Top1 90.468750   Top5 99.492188   BatchTime 0.131838
INFO - Validation [17][   40/   40]   Loss 0.425159   Top1 90.500000   Top5 99.540000   BatchTime 0.090543
INFO - ==> Top1: 90.500    Top5: 99.540    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.500   Top5: 99.540] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 0.035123   Top1 98.828125   Top5 100.000000   BatchTime 0.221996   LR 0.010000
INFO - Training [18][   40/  196]   Loss 0.032861   Top1 98.955078   Top5 100.000000   BatchTime 0.172910   LR 0.010000
INFO - Training [18][   60/  196]   Loss 0.030344   Top1 99.010417   Top5 100.000000   BatchTime 0.156690   LR 0.010000
INFO - Training [18][   80/  196]   Loss 0.030320   Top1 98.964844   Top5 100.000000   BatchTime 0.148414   LR 0.010000
INFO - Training [18][  100/  196]   Loss 0.031016   Top1 98.910156   Top5 100.000000   BatchTime 0.143617   LR 0.010000
INFO - Training [18][  120/  196]   Loss 0.032425   Top1 98.867188   Top5 100.000000   BatchTime 0.140320   LR 0.010000
INFO - Training [18][  140/  196]   Loss 0.032790   Top1 98.875558   Top5 100.000000   BatchTime 0.137945   LR 0.010000
INFO - Training [18][  160/  196]   Loss 0.032683   Top1 98.869629   Top5 100.000000   BatchTime 0.136112   LR 0.010000
INFO - Training [18][  180/  196]   Loss 0.033050   Top1 98.865017   Top5 100.000000   BatchTime 0.134697   LR 0.010000
INFO - ==> Top1: 98.886    Top5: 100.000    Loss: 0.033
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.430705   Top1 90.273438   Top5 99.570312   BatchTime 0.148594
INFO - Validation [18][   40/   40]   Loss 0.427353   Top1 90.420000   Top5 99.620000   BatchTime 0.102815
INFO - ==> Top1: 90.420    Top5: 99.620    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.500   Top5: 99.540] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 0.032786   Top1 98.847656   Top5 100.000000   BatchTime 0.224729   LR 0.010000
INFO - Training [19][   40/  196]   Loss 0.031144   Top1 99.003906   Top5 100.000000   BatchTime 0.174215   LR 0.010000
INFO - Training [19][   60/  196]   Loss 0.030661   Top1 98.945312   Top5 100.000000   BatchTime 0.157242   LR 0.010000
INFO - Training [19][   80/  196]   Loss 0.031023   Top1 98.955078   Top5 100.000000   BatchTime 0.148739   LR 0.010000
INFO - Training [19][  100/  196]   Loss 0.029932   Top1 98.984375   Top5 100.000000   BatchTime 0.138905   LR 0.010000
INFO - Training [19][  120/  196]   Loss 0.030694   Top1 98.961589   Top5 100.000000   BatchTime 0.132750   LR 0.010000
INFO - Training [19][  140/  196]   Loss 0.030465   Top1 98.964844   Top5 100.000000   BatchTime 0.128332   LR 0.010000
INFO - Training [19][  160/  196]   Loss 0.030650   Top1 98.945312   Top5 100.000000   BatchTime 0.125350   LR 0.010000
INFO - Training [19][  180/  196]   Loss 0.031353   Top1 98.923611   Top5 100.000000   BatchTime 0.120929   LR 0.010000
INFO - ==> Top1: 98.906    Top5: 100.000    Loss: 0.032
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.453067   Top1 90.136719   Top5 99.609375   BatchTime 0.148366
INFO - Validation [19][   40/   40]   Loss 0.437638   Top1 90.290000   Top5 99.650000   BatchTime 0.101955
INFO - ==> Top1: 90.290    Top5: 99.650    Loss: 0.438
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 90.500   Top5: 99.540] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 0.031859   Top1 98.945312   Top5 100.000000   BatchTime 0.223048   LR 0.001000
INFO - Training [20][   40/  196]   Loss 0.035630   Top1 98.828125   Top5 100.000000   BatchTime 0.173786   LR 0.001000
INFO - Training [20][   60/  196]   Loss 0.036671   Top1 98.763021   Top5 100.000000   BatchTime 0.157138   LR 0.001000
INFO - Training [20][   80/  196]   Loss 0.036485   Top1 98.774414   Top5 100.000000   BatchTime 0.148417   LR 0.001000
INFO - Training [20][  100/  196]   Loss 0.033892   Top1 98.875000   Top5 100.000000   BatchTime 0.143631   LR 0.001000
INFO - Training [20][  120/  196]   Loss 0.034445   Top1 98.873698   Top5 100.000000   BatchTime 0.140365   LR 0.001000
INFO - Training [20][  140/  196]   Loss 0.034191   Top1 98.867188   Top5 100.000000   BatchTime 0.137981   LR 0.001000
INFO - Training [20][  160/  196]   Loss 0.034312   Top1 98.872070   Top5 100.000000   BatchTime 0.136102   LR 0.001000
INFO - Training [20][  180/  196]   Loss 0.034106   Top1 98.867188   Top5 100.000000   BatchTime 0.134697   LR 0.001000
INFO - ==> Top1: 98.864    Top5: 100.000    Loss: 0.034
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.434568   Top1 90.371094   Top5 99.628906   BatchTime 0.151162
INFO - Validation [20][   40/   40]   Loss 0.422013   Top1 90.510000   Top5 99.620000   BatchTime 0.103815
INFO - ==> Top1: 90.510    Top5: 99.620    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 90.510   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 0.025494   Top1 99.257812   Top5 100.000000   BatchTime 0.221326   LR 0.001000
INFO - Training [21][   40/  196]   Loss 0.027727   Top1 99.062500   Top5 100.000000   BatchTime 0.159468   LR 0.001000
INFO - Training [21][   60/  196]   Loss 0.028431   Top1 98.977865   Top5 100.000000   BatchTime 0.139952   LR 0.001000
INFO - Training [21][   80/  196]   Loss 0.028309   Top1 98.964844   Top5 100.000000   BatchTime 0.130262   LR 0.001000
INFO - Training [21][  100/  196]   Loss 0.027885   Top1 98.980469   Top5 100.000000   BatchTime 0.125019   LR 0.001000
INFO - Training [21][  120/  196]   Loss 0.027511   Top1 99.003906   Top5 100.000000   BatchTime 0.119967   LR 0.001000
INFO - Training [21][  140/  196]   Loss 0.027789   Top1 98.984375   Top5 100.000000   BatchTime 0.120622   LR 0.001000
INFO - Training [21][  160/  196]   Loss 0.027613   Top1 99.006348   Top5 100.000000   BatchTime 0.120958   LR 0.001000
INFO - Training [21][  180/  196]   Loss 0.027383   Top1 99.012587   Top5 100.000000   BatchTime 0.121222   LR 0.001000
INFO - ==> Top1: 99.016    Top5: 100.000    Loss: 0.027
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.430813   Top1 90.527344   Top5 99.628906   BatchTime 0.147740
INFO - Validation [21][   40/   40]   Loss 0.423175   Top1 90.530000   Top5 99.650000   BatchTime 0.101220
INFO - ==> Top1: 90.530    Top5: 99.650    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 90.530   Top5: 99.650] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 0.024027   Top1 99.277344   Top5 100.000000   BatchTime 0.225154   LR 0.001000
INFO - Training [22][   40/  196]   Loss 0.023991   Top1 99.208984   Top5 100.000000   BatchTime 0.174843   LR 0.001000
INFO - Training [22][   60/  196]   Loss 0.025725   Top1 99.147135   Top5 100.000000   BatchTime 0.159385   LR 0.001000
INFO - Training [22][   80/  196]   Loss 0.026084   Top1 99.116211   Top5 100.000000   BatchTime 0.150475   LR 0.001000
INFO - Training [22][  100/  196]   Loss 0.027392   Top1 99.042969   Top5 100.000000   BatchTime 0.145101   LR 0.001000
INFO - Training [22][  120/  196]   Loss 0.027030   Top1 99.082031   Top5 100.000000   BatchTime 0.141614   LR 0.001000
INFO - Training [22][  140/  196]   Loss 0.027743   Top1 99.059710   Top5 100.000000   BatchTime 0.139033   LR 0.001000
INFO - Training [22][  160/  196]   Loss 0.027559   Top1 99.074707   Top5 100.000000   BatchTime 0.137102   LR 0.001000
INFO - Training [22][  180/  196]   Loss 0.027265   Top1 99.071181   Top5 100.000000   BatchTime 0.135602   LR 0.001000
INFO - ==> Top1: 99.056    Top5: 100.000    Loss: 0.028
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.438004   Top1 90.644531   Top5 99.609375   BatchTime 0.144633
INFO - Validation [22][   40/   40]   Loss 0.423044   Top1 90.690000   Top5 99.660000   BatchTime 0.093391
INFO - ==> Top1: 90.690    Top5: 99.660    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 90.690   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 0.022296   Top1 99.316406   Top5 100.000000   BatchTime 0.206012   LR 0.001000
INFO - Training [23][   40/  196]   Loss 0.025112   Top1 99.130859   Top5 100.000000   BatchTime 0.153257   LR 0.001000
INFO - Training [23][   60/  196]   Loss 0.024185   Top1 99.179688   Top5 100.000000   BatchTime 0.135669   LR 0.001000
INFO - Training [23][   80/  196]   Loss 0.025129   Top1 99.165039   Top5 100.000000   BatchTime 0.132758   LR 0.001000
INFO - Training [23][  100/  196]   Loss 0.025754   Top1 99.101562   Top5 100.000000   BatchTime 0.131341   LR 0.001000
INFO - Training [23][  120/  196]   Loss 0.025895   Top1 99.121094   Top5 100.000000   BatchTime 0.130214   LR 0.001000
INFO - Training [23][  140/  196]   Loss 0.025973   Top1 99.129464   Top5 100.000000   BatchTime 0.129345   LR 0.001000
INFO - Training [23][  160/  196]   Loss 0.026132   Top1 99.130859   Top5 100.000000   BatchTime 0.128596   LR 0.001000
INFO - Training [23][  180/  196]   Loss 0.026771   Top1 99.105903   Top5 100.000000   BatchTime 0.127991   LR 0.001000
INFO - ==> Top1: 99.098    Top5: 100.000    Loss: 0.027
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.424975   Top1 90.683594   Top5 99.511719   BatchTime 0.148653
INFO - Validation [23][   40/   40]   Loss 0.417675   Top1 90.880000   Top5 99.590000   BatchTime 0.101951
INFO - ==> Top1: 90.880    Top5: 99.590    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 90.690   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 0.023546   Top1 99.296875   Top5 100.000000   BatchTime 0.223852   LR 0.001000
INFO - Training [24][   40/  196]   Loss 0.024920   Top1 99.199219   Top5 100.000000   BatchTime 0.174445   LR 0.001000
INFO - Training [24][   60/  196]   Loss 0.026141   Top1 99.147135   Top5 100.000000   BatchTime 0.157721   LR 0.001000
INFO - Training [24][   80/  196]   Loss 0.025810   Top1 99.140625   Top5 100.000000   BatchTime 0.149255   LR 0.001000
INFO - Training [24][  100/  196]   Loss 0.026283   Top1 99.125000   Top5 100.000000   BatchTime 0.144257   LR 0.001000
INFO - Training [24][  120/  196]   Loss 0.026232   Top1 99.130859   Top5 99.996745   BatchTime 0.140903   LR 0.001000
INFO - Training [24][  140/  196]   Loss 0.026249   Top1 99.121094   Top5 99.994420   BatchTime 0.138398   LR 0.001000
INFO - Training [24][  160/  196]   Loss 0.026110   Top1 99.147949   Top5 99.995117   BatchTime 0.136439   LR 0.001000
INFO - Training [24][  180/  196]   Loss 0.026310   Top1 99.136285   Top5 99.995660   BatchTime 0.133482   LR 0.001000
INFO - ==> Top1: 99.150    Top5: 99.996    Loss: 0.026
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.432468   Top1 90.644531   Top5 99.550781   BatchTime 0.136731
INFO - Validation [24][   40/   40]   Loss 0.421676   Top1 90.710000   Top5 99.580000   BatchTime 0.085564
INFO - ==> Top1: 90.710    Top5: 99.580    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 90.710   Top5: 99.580] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 0.028315   Top1 98.984375   Top5 100.000000   BatchTime 0.224303   LR 0.001000
INFO - Training [25][   40/  196]   Loss 0.029280   Top1 99.033203   Top5 100.000000   BatchTime 0.174207   LR 0.001000
INFO - Training [25][   60/  196]   Loss 0.028062   Top1 99.055990   Top5 100.000000   BatchTime 0.157786   LR 0.001000
INFO - Training [25][   80/  196]   Loss 0.028766   Top1 99.013672   Top5 100.000000   BatchTime 0.149471   LR 0.001000
INFO - Training [25][  100/  196]   Loss 0.028324   Top1 99.031250   Top5 100.000000   BatchTime 0.144446   LR 0.001000
INFO - Training [25][  120/  196]   Loss 0.027851   Top1 99.062500   Top5 100.000000   BatchTime 0.141158   LR 0.001000
INFO - Training [25][  140/  196]   Loss 0.027428   Top1 99.076451   Top5 100.000000   BatchTime 0.138693   LR 0.001000
INFO - Training [25][  160/  196]   Loss 0.027279   Top1 99.077148   Top5 100.000000   BatchTime 0.136738   LR 0.001000
INFO - Training [25][  180/  196]   Loss 0.027223   Top1 99.092882   Top5 100.000000   BatchTime 0.135230   LR 0.001000
INFO - ==> Top1: 99.102    Top5: 100.000    Loss: 0.027
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.429012   Top1 90.839844   Top5 99.570312   BatchTime 0.148978
INFO - Validation [25][   40/   40]   Loss 0.417949   Top1 90.830000   Top5 99.620000   BatchTime 0.103640
INFO - ==> Top1: 90.830    Top5: 99.620    Loss: 0.418
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 90.830   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 90.710   Top5: 99.580] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 0.023571   Top1 99.277344   Top5 100.000000   BatchTime 0.224286   LR 0.001000
INFO - Training [26][   40/  196]   Loss 0.022979   Top1 99.287109   Top5 100.000000   BatchTime 0.174414   LR 0.001000
INFO - Training [26][   60/  196]   Loss 0.024033   Top1 99.244792   Top5 100.000000   BatchTime 0.159906   LR 0.001000
INFO - Training [26][   80/  196]   Loss 0.025453   Top1 99.189453   Top5 100.000000   BatchTime 0.150755   LR 0.001000
INFO - Training [26][  100/  196]   Loss 0.025792   Top1 99.167969   Top5 100.000000   BatchTime 0.145023   LR 0.001000
INFO - Training [26][  120/  196]   Loss 0.026210   Top1 99.160156   Top5 100.000000   BatchTime 0.136171   LR 0.001000
INFO - Training [26][  140/  196]   Loss 0.026171   Top1 99.160156   Top5 100.000000   BatchTime 0.131325   LR 0.001000
INFO - Training [26][  160/  196]   Loss 0.025900   Top1 99.152832   Top5 100.000000   BatchTime 0.127598   LR 0.001000
INFO - Training [26][  180/  196]   Loss 0.026018   Top1 99.140625   Top5 100.000000   BatchTime 0.124028   LR 0.001000
INFO - ==> Top1: 99.130    Top5: 100.000    Loss: 0.026
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.434593   Top1 90.683594   Top5 99.589844   BatchTime 0.149992
INFO - Validation [26][   40/   40]   Loss 0.423876   Top1 90.790000   Top5 99.640000   BatchTime 0.102378
INFO - ==> Top1: 90.790    Top5: 99.640    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 90.830   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 90.790   Top5: 99.640] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 0.027646   Top1 99.082031   Top5 100.000000   BatchTime 0.221011   LR 0.001000
INFO - Training [27][   40/  196]   Loss 0.024035   Top1 99.208984   Top5 100.000000   BatchTime 0.172741   LR 0.001000
INFO - Training [27][   60/  196]   Loss 0.025841   Top1 99.114583   Top5 100.000000   BatchTime 0.156583   LR 0.001000
INFO - Training [27][   80/  196]   Loss 0.025438   Top1 99.145508   Top5 100.000000   BatchTime 0.148427   LR 0.001000
INFO - Training [27][  100/  196]   Loss 0.025392   Top1 99.152344   Top5 100.000000   BatchTime 0.143480   LR 0.001000
INFO - Training [27][  120/  196]   Loss 0.025566   Top1 99.134115   Top5 100.000000   BatchTime 0.140196   LR 0.001000
INFO - Training [27][  140/  196]   Loss 0.025043   Top1 99.148996   Top5 100.000000   BatchTime 0.137818   LR 0.001000
INFO - Training [27][  160/  196]   Loss 0.025750   Top1 99.128418   Top5 100.000000   BatchTime 0.135969   LR 0.001000
INFO - Training [27][  180/  196]   Loss 0.025588   Top1 99.142795   Top5 100.000000   BatchTime 0.134548   LR 0.001000
INFO - ==> Top1: 99.122    Top5: 100.000    Loss: 0.026
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [27][   20/   40]   Loss 0.434353   Top1 90.898438   Top5 99.550781   BatchTime 0.147853
INFO - Validation [27][   40/   40]   Loss 0.423590   Top1 90.910000   Top5 99.620000   BatchTime 0.102594
INFO - ==> Top1: 90.910    Top5: 99.620    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 90.830   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 0.023370   Top1 99.296875   Top5 100.000000   BatchTime 0.222496   LR 0.001000
INFO - Training [28][   40/  196]   Loss 0.022784   Top1 99.316406   Top5 100.000000   BatchTime 0.168778   LR 0.001000
INFO - Training [28][   60/  196]   Loss 0.022711   Top1 99.303385   Top5 100.000000   BatchTime 0.144499   LR 0.001000
INFO - Training [28][   80/  196]   Loss 0.024029   Top1 99.223633   Top5 100.000000   BatchTime 0.134088   LR 0.001000
INFO - Training [28][  100/  196]   Loss 0.025034   Top1 99.187500   Top5 100.000000   BatchTime 0.127827   LR 0.001000
INFO - Training [28][  120/  196]   Loss 0.025368   Top1 99.176432   Top5 100.000000   BatchTime 0.121785   LR 0.001000
INFO - Training [28][  140/  196]   Loss 0.025761   Top1 99.146205   Top5 100.000000   BatchTime 0.120922   LR 0.001000
INFO - Training [28][  160/  196]   Loss 0.025241   Top1 99.160156   Top5 100.000000   BatchTime 0.121185   LR 0.001000
INFO - Training [28][  180/  196]   Loss 0.025824   Top1 99.136285   Top5 100.000000   BatchTime 0.121448   LR 0.001000
INFO - ==> Top1: 99.130    Top5: 100.000    Loss: 0.026
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.433596   Top1 90.761719   Top5 99.609375   BatchTime 0.147320
INFO - Validation [28][   40/   40]   Loss 0.421149   Top1 90.840000   Top5 99.630000   BatchTime 0.101501
INFO - ==> Top1: 90.840    Top5: 99.630    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.840   Top5: 99.630] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 0.024455   Top1 99.160156   Top5 100.000000   BatchTime 0.224505   LR 0.001000
INFO - Training [29][   40/  196]   Loss 0.024652   Top1 99.072266   Top5 100.000000   BatchTime 0.174664   LR 0.001000
INFO - Training [29][   60/  196]   Loss 0.022792   Top1 99.166667   Top5 100.000000   BatchTime 0.157966   LR 0.001000
INFO - Training [29][   80/  196]   Loss 0.022357   Top1 99.194336   Top5 100.000000   BatchTime 0.149467   LR 0.001000
INFO - Training [29][  100/  196]   Loss 0.023028   Top1 99.179688   Top5 100.000000   BatchTime 0.144279   LR 0.001000
INFO - Training [29][  120/  196]   Loss 0.022641   Top1 99.205729   Top5 100.000000   BatchTime 0.140928   LR 0.001000
INFO - Training [29][  140/  196]   Loss 0.022840   Top1 99.196429   Top5 100.000000   BatchTime 0.138467   LR 0.001000
INFO - Training [29][  160/  196]   Loss 0.022867   Top1 99.191895   Top5 100.000000   BatchTime 0.136527   LR 0.001000
INFO - Training [29][  180/  196]   Loss 0.022928   Top1 99.184028   Top5 100.000000   BatchTime 0.135010   LR 0.001000
INFO - ==> Top1: 99.186    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.433929   Top1 90.625000   Top5 99.628906   BatchTime 0.147490
INFO - Validation [29][   40/   40]   Loss 0.422932   Top1 90.790000   Top5 99.660000   BatchTime 0.103726
INFO - ==> Top1: 90.790    Top5: 99.660    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 90.840   Top5: 99.630] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 0.024693   Top1 99.042969   Top5 100.000000   BatchTime 0.205303   LR 0.001000
INFO - Training [30][   40/  196]   Loss 0.022680   Top1 99.238281   Top5 100.000000   BatchTime 0.157792   LR 0.001000
INFO - Training [30][   60/  196]   Loss 0.023471   Top1 99.212240   Top5 100.000000   BatchTime 0.134386   LR 0.001000
INFO - Training [30][   80/  196]   Loss 0.023217   Top1 99.208984   Top5 100.000000   BatchTime 0.131577   LR 0.001000
INFO - Training [30][  100/  196]   Loss 0.024321   Top1 99.171875   Top5 99.996094   BatchTime 0.130158   LR 0.001000
INFO - Training [30][  120/  196]   Loss 0.024581   Top1 99.143880   Top5 99.996745   BatchTime 0.129162   LR 0.001000
INFO - Training [30][  140/  196]   Loss 0.024793   Top1 99.135045   Top5 99.997210   BatchTime 0.128485   LR 0.001000
INFO - Training [30][  160/  196]   Loss 0.024781   Top1 99.130859   Top5 99.997559   BatchTime 0.127891   LR 0.001000
INFO - Training [30][  180/  196]   Loss 0.024848   Top1 99.118924   Top5 99.997830   BatchTime 0.127431   LR 0.001000
INFO - ==> Top1: 99.128    Top5: 99.998    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.435921   Top1 90.839844   Top5 99.628906   BatchTime 0.147695
INFO - Validation [30][   40/   40]   Loss 0.426439   Top1 90.930000   Top5 99.680000   BatchTime 0.102230
INFO - ==> Top1: 90.930    Top5: 99.680    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 0.025723   Top1 99.121094   Top5 100.000000   BatchTime 0.223949   LR 0.001000
INFO - Training [31][   40/  196]   Loss 0.024384   Top1 99.218750   Top5 100.000000   BatchTime 0.174540   LR 0.001000
INFO - Training [31][   60/  196]   Loss 0.023272   Top1 99.277344   Top5 100.000000   BatchTime 0.157803   LR 0.001000
INFO - Training [31][   80/  196]   Loss 0.023765   Top1 99.267578   Top5 100.000000   BatchTime 0.149253   LR 0.001000
INFO - Training [31][  100/  196]   Loss 0.023770   Top1 99.230469   Top5 100.000000   BatchTime 0.144123   LR 0.001000
INFO - Training [31][  120/  196]   Loss 0.024325   Top1 99.208984   Top5 100.000000   BatchTime 0.140169   LR 0.001000
INFO - Training [31][  140/  196]   Loss 0.024426   Top1 99.221540   Top5 100.000000   BatchTime 0.137893   LR 0.001000
INFO - Training [31][  160/  196]   Loss 0.024312   Top1 99.208984   Top5 100.000000   BatchTime 0.135994   LR 0.001000
INFO - Training [31][  180/  196]   Loss 0.024724   Top1 99.197049   Top5 100.000000   BatchTime 0.134513   LR 0.001000
INFO - ==> Top1: 99.194    Top5: 100.000    Loss: 0.025
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 0.428663   Top1 91.015625   Top5 99.589844   BatchTime 0.137734
INFO - Validation [31][   40/   40]   Loss 0.421103   Top1 90.970000   Top5 99.660000   BatchTime 0.090999
INFO - ==> Top1: 90.970    Top5: 99.660    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 0.021745   Top1 99.257812   Top5 100.000000   BatchTime 0.231487   LR 0.001000
INFO - Training [32][   40/  196]   Loss 0.021606   Top1 99.306641   Top5 100.000000   BatchTime 0.177807   LR 0.001000
INFO - Training [32][   60/  196]   Loss 0.021542   Top1 99.290365   Top5 100.000000   BatchTime 0.160095   LR 0.001000
INFO - Training [32][   80/  196]   Loss 0.022124   Top1 99.252930   Top5 100.000000   BatchTime 0.151375   LR 0.001000
INFO - Training [32][  100/  196]   Loss 0.022851   Top1 99.214844   Top5 100.000000   BatchTime 0.145916   LR 0.001000
INFO - Training [32][  120/  196]   Loss 0.023436   Top1 99.195964   Top5 100.000000   BatchTime 0.142334   LR 0.001000
INFO - Training [32][  140/  196]   Loss 0.023588   Top1 99.210379   Top5 100.000000   BatchTime 0.139721   LR 0.001000
INFO - Training [32][  160/  196]   Loss 0.023639   Top1 99.206543   Top5 100.000000   BatchTime 0.137674   LR 0.001000
INFO - Training [32][  180/  196]   Loss 0.023419   Top1 99.207899   Top5 100.000000   BatchTime 0.136068   LR 0.001000
INFO - ==> Top1: 99.208    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.441955   Top1 90.722656   Top5 99.570312   BatchTime 0.148429
INFO - Validation [32][   40/   40]   Loss 0.425704   Top1 90.930000   Top5 99.640000   BatchTime 0.102564
INFO - ==> Top1: 90.930    Top5: 99.640    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.930   Top5: 99.640] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 0.022023   Top1 99.355469   Top5 100.000000   BatchTime 0.222971   LR 0.001000
INFO - Training [33][   40/  196]   Loss 0.020904   Top1 99.394531   Top5 100.000000   BatchTime 0.173656   LR 0.001000
INFO - Training [33][   60/  196]   Loss 0.022407   Top1 99.296875   Top5 100.000000   BatchTime 0.156792   LR 0.001000
INFO - Training [33][   80/  196]   Loss 0.022902   Top1 99.277344   Top5 100.000000   BatchTime 0.148668   LR 0.001000
INFO - Training [33][  100/  196]   Loss 0.023606   Top1 99.234375   Top5 100.000000   BatchTime 0.143632   LR 0.001000
INFO - Training [33][  120/  196]   Loss 0.023512   Top1 99.225260   Top5 100.000000   BatchTime 0.137658   LR 0.001000
INFO - Training [33][  140/  196]   Loss 0.022644   Top1 99.266183   Top5 100.000000   BatchTime 0.131805   LR 0.001000
INFO - Training [33][  160/  196]   Loss 0.022950   Top1 99.245605   Top5 100.000000   BatchTime 0.127868   LR 0.001000
INFO - Training [33][  180/  196]   Loss 0.023299   Top1 99.240451   Top5 100.000000   BatchTime 0.124766   LR 0.001000
INFO - ==> Top1: 99.246    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.429903   Top1 90.839844   Top5 99.531250   BatchTime 0.150089
INFO - Validation [33][   40/   40]   Loss 0.420455   Top1 90.870000   Top5 99.620000   BatchTime 0.103090
INFO - ==> Top1: 90.870    Top5: 99.620    Loss: 0.420
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.930   Top5: 99.640] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 0.023986   Top1 99.199219   Top5 100.000000   BatchTime 0.224973   LR 0.001000
INFO - Training [34][   40/  196]   Loss 0.022800   Top1 99.248047   Top5 100.000000   BatchTime 0.176902   LR 0.001000
INFO - Training [34][   60/  196]   Loss 0.022920   Top1 99.218750   Top5 100.000000   BatchTime 0.159269   LR 0.001000
INFO - Training [34][   80/  196]   Loss 0.022577   Top1 99.252930   Top5 100.000000   BatchTime 0.150653   LR 0.001000
INFO - Training [34][  100/  196]   Loss 0.022491   Top1 99.253906   Top5 100.000000   BatchTime 0.145319   LR 0.001000
INFO - Training [34][  120/  196]   Loss 0.022016   Top1 99.267578   Top5 100.000000   BatchTime 0.141778   LR 0.001000
INFO - Training [34][  140/  196]   Loss 0.022046   Top1 99.243862   Top5 100.000000   BatchTime 0.139303   LR 0.001000
INFO - Training [34][  160/  196]   Loss 0.022022   Top1 99.255371   Top5 100.000000   BatchTime 0.137281   LR 0.001000
INFO - Training [34][  180/  196]   Loss 0.022072   Top1 99.257812   Top5 100.000000   BatchTime 0.135729   LR 0.001000
INFO - ==> Top1: 99.266    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.436984   Top1 90.878906   Top5 99.570312   BatchTime 0.149312
INFO - Validation [34][   40/   40]   Loss 0.428904   Top1 90.810000   Top5 99.640000   BatchTime 0.103326
INFO - ==> Top1: 90.810    Top5: 99.640    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 90.930   Top5: 99.640] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 0.025846   Top1 99.140625   Top5 100.000000   BatchTime 0.221674   LR 0.001000
INFO - Training [35][   40/  196]   Loss 0.023358   Top1 99.238281   Top5 100.000000   BatchTime 0.172720   LR 0.001000
INFO - Training [35][   60/  196]   Loss 0.023943   Top1 99.179688   Top5 100.000000   BatchTime 0.151373   LR 0.001000
INFO - Training [35][   80/  196]   Loss 0.024070   Top1 99.174805   Top5 100.000000   BatchTime 0.136622   LR 0.001000
INFO - Training [35][  100/  196]   Loss 0.024174   Top1 99.171875   Top5 100.000000   BatchTime 0.129800   LR 0.001000
INFO - Training [35][  120/  196]   Loss 0.023821   Top1 99.189453   Top5 100.000000   BatchTime 0.125133   LR 0.001000
INFO - Training [35][  140/  196]   Loss 0.023530   Top1 99.202009   Top5 100.000000   BatchTime 0.120890   LR 0.001000
INFO - Training [35][  160/  196]   Loss 0.023186   Top1 99.216309   Top5 100.000000   BatchTime 0.119369   LR 0.001000
INFO - Training [35][  180/  196]   Loss 0.023067   Top1 99.223090   Top5 100.000000   BatchTime 0.119818   LR 0.001000
INFO - ==> Top1: 99.228    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.432806   Top1 90.820312   Top5 99.570312   BatchTime 0.147284
INFO - Validation [35][   40/   40]   Loss 0.420817   Top1 91.000000   Top5 99.620000   BatchTime 0.100713
INFO - ==> Top1: 91.000    Top5: 99.620    Loss: 0.421
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 0.028170   Top1 99.023438   Top5 100.000000   BatchTime 0.224435   LR 0.001000
INFO - Training [36][   40/  196]   Loss 0.027060   Top1 99.130859   Top5 100.000000   BatchTime 0.174437   LR 0.001000
INFO - Training [36][   60/  196]   Loss 0.026807   Top1 99.101562   Top5 100.000000   BatchTime 0.157779   LR 0.001000
INFO - Training [36][   80/  196]   Loss 0.026088   Top1 99.116211   Top5 100.000000   BatchTime 0.149322   LR 0.001000
INFO - Training [36][  100/  196]   Loss 0.025841   Top1 99.109375   Top5 100.000000   BatchTime 0.144148   LR 0.001000
INFO - Training [36][  120/  196]   Loss 0.025708   Top1 99.111328   Top5 100.000000   BatchTime 0.140779   LR 0.001000
INFO - Training [36][  140/  196]   Loss 0.025354   Top1 99.115513   Top5 100.000000   BatchTime 0.138356   LR 0.001000
INFO - Training [36][  160/  196]   Loss 0.025122   Top1 99.128418   Top5 100.000000   BatchTime 0.136531   LR 0.001000
INFO - Training [36][  180/  196]   Loss 0.024355   Top1 99.160156   Top5 100.000000   BatchTime 0.135097   LR 0.001000
INFO - ==> Top1: 99.156    Top5: 100.000    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.436465   Top1 90.449219   Top5 99.628906   BatchTime 0.148240
INFO - Validation [36][   40/   40]   Loss 0.427609   Top1 90.720000   Top5 99.670000   BatchTime 0.102336
INFO - ==> Top1: 90.720    Top5: 99.670    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 0.024876   Top1 99.140625   Top5 100.000000   BatchTime 0.201899   LR 0.001000
INFO - Training [37][   40/  196]   Loss 0.025162   Top1 99.208984   Top5 100.000000   BatchTime 0.152935   LR 0.001000
INFO - Training [37][   60/  196]   Loss 0.023951   Top1 99.244792   Top5 100.000000   BatchTime 0.136607   LR 0.001000
INFO - Training [37][   80/  196]   Loss 0.024350   Top1 99.204102   Top5 100.000000   BatchTime 0.124843   LR 0.001000
INFO - Training [37][  100/  196]   Loss 0.024140   Top1 99.191406   Top5 100.000000   BatchTime 0.125157   LR 0.001000
INFO - Training [37][  120/  196]   Loss 0.024646   Top1 99.182943   Top5 100.000000   BatchTime 0.124976   LR 0.001000
INFO - Training [37][  140/  196]   Loss 0.024826   Top1 99.171317   Top5 100.000000   BatchTime 0.124809   LR 0.001000
INFO - Training [37][  160/  196]   Loss 0.024383   Top1 99.179688   Top5 100.000000   BatchTime 0.124632   LR 0.001000
INFO - Training [37][  180/  196]   Loss 0.024060   Top1 99.171007   Top5 100.000000   BatchTime 0.124448   LR 0.001000
INFO - ==> Top1: 99.162    Top5: 100.000    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.439838   Top1 90.683594   Top5 99.589844   BatchTime 0.147494
INFO - Validation [37][   40/   40]   Loss 0.430386   Top1 90.850000   Top5 99.640000   BatchTime 0.101306
INFO - ==> Top1: 90.850    Top5: 99.640    Loss: 0.430
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 0.023519   Top1 99.257812   Top5 100.000000   BatchTime 0.223516   LR 0.001000
INFO - Training [38][   40/  196]   Loss 0.023073   Top1 99.218750   Top5 100.000000   BatchTime 0.174057   LR 0.001000
INFO - Training [38][   60/  196]   Loss 0.023359   Top1 99.166667   Top5 100.000000   BatchTime 0.157640   LR 0.001000
INFO - Training [38][   80/  196]   Loss 0.024247   Top1 99.091797   Top5 100.000000   BatchTime 0.150447   LR 0.001000
INFO - Training [38][  100/  196]   Loss 0.023912   Top1 99.136719   Top5 100.000000   BatchTime 0.145205   LR 0.001000
INFO - Training [38][  120/  196]   Loss 0.023098   Top1 99.169922   Top5 100.000000   BatchTime 0.141839   LR 0.001000
INFO - Training [38][  140/  196]   Loss 0.022677   Top1 99.196429   Top5 100.000000   BatchTime 0.139281   LR 0.001000
INFO - Training [38][  160/  196]   Loss 0.022649   Top1 99.208984   Top5 100.000000   BatchTime 0.137249   LR 0.001000
INFO - Training [38][  180/  196]   Loss 0.022752   Top1 99.205729   Top5 100.000000   BatchTime 0.135685   LR 0.001000
INFO - ==> Top1: 99.200    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 0.436234   Top1 90.917969   Top5 99.628906   BatchTime 0.149865
INFO - Validation [38][   40/   40]   Loss 0.423642   Top1 91.040000   Top5 99.680000   BatchTime 0.096182
INFO - ==> Top1: 91.040    Top5: 99.680    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 0.021116   Top1 99.238281   Top5 100.000000   BatchTime 0.224174   LR 0.001000
INFO - Training [39][   40/  196]   Loss 0.020821   Top1 99.287109   Top5 100.000000   BatchTime 0.173189   LR 0.001000
INFO - Training [39][   60/  196]   Loss 0.021168   Top1 99.283854   Top5 100.000000   BatchTime 0.156852   LR 0.001000
INFO - Training [39][   80/  196]   Loss 0.021085   Top1 99.316406   Top5 100.000000   BatchTime 0.148661   LR 0.001000
INFO - Training [39][  100/  196]   Loss 0.021435   Top1 99.320312   Top5 100.000000   BatchTime 0.143738   LR 0.001000
INFO - Training [39][  120/  196]   Loss 0.021346   Top1 99.319661   Top5 100.000000   BatchTime 0.140523   LR 0.001000
INFO - Training [39][  140/  196]   Loss 0.021879   Top1 99.305246   Top5 100.000000   BatchTime 0.138213   LR 0.001000
INFO - Training [39][  160/  196]   Loss 0.021794   Top1 99.296875   Top5 100.000000   BatchTime 0.136397   LR 0.001000
INFO - Training [39][  180/  196]   Loss 0.022005   Top1 99.281684   Top5 100.000000   BatchTime 0.134952   LR 0.001000
INFO - ==> Top1: 99.270    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.440801   Top1 91.269531   Top5 99.550781   BatchTime 0.150980
INFO - Validation [39][   40/   40]   Loss 0.428137   Top1 91.200000   Top5 99.650000   BatchTime 0.103050
INFO - ==> Top1: 91.200    Top5: 99.650    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar
INFO - >>>>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 0.023547   Top1 99.355469   Top5 100.000000   BatchTime 0.225548   LR 0.000100
INFO - Training [40][   40/  196]   Loss 0.024941   Top1 99.189453   Top5 100.000000   BatchTime 0.175047   LR 0.000100
INFO - Training [40][   60/  196]   Loss 0.024926   Top1 99.205729   Top5 99.993490   BatchTime 0.157846   LR 0.000100
INFO - Training [40][   80/  196]   Loss 0.024802   Top1 99.174805   Top5 99.995117   BatchTime 0.149514   LR 0.000100
INFO - Training [40][  100/  196]   Loss 0.025751   Top1 99.132812   Top5 99.996094   BatchTime 0.144437   LR 0.000100
INFO - Training [40][  120/  196]   Loss 0.024904   Top1 99.160156   Top5 99.996745   BatchTime 0.140928   LR 0.000100
INFO - Training [40][  140/  196]   Loss 0.024906   Top1 99.168527   Top5 99.997210   BatchTime 0.133858   LR 0.000100
INFO - Training [40][  160/  196]   Loss 0.024938   Top1 99.167480   Top5 99.997559   BatchTime 0.129986   LR 0.000100
INFO - Training [40][  180/  196]   Loss 0.024672   Top1 99.184028   Top5 99.997830   BatchTime 0.126663   LR 0.000100
INFO - ==> Top1: 99.198    Top5: 99.998    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.436330   Top1 90.800781   Top5 99.570312   BatchTime 0.156607
INFO - Validation [40][   40/   40]   Loss 0.426583   Top1 90.990000   Top5 99.660000   BatchTime 0.106475
INFO - ==> Top1: 90.990    Top5: 99.660    Loss: 0.427
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 0.026519   Top1 99.121094   Top5 100.000000   BatchTime 0.224135   LR 0.000100
INFO - Training [41][   40/  196]   Loss 0.026800   Top1 99.072266   Top5 99.990234   BatchTime 0.173867   LR 0.000100
INFO - Training [41][   60/  196]   Loss 0.026682   Top1 99.062500   Top5 99.993490   BatchTime 0.157380   LR 0.000100
INFO - Training [41][   80/  196]   Loss 0.025384   Top1 99.130859   Top5 99.995117   BatchTime 0.149175   LR 0.000100
INFO - Training [41][  100/  196]   Loss 0.024997   Top1 99.160156   Top5 99.996094   BatchTime 0.144195   LR 0.000100
INFO - Training [41][  120/  196]   Loss 0.024651   Top1 99.166667   Top5 99.996745   BatchTime 0.140742   LR 0.000100
INFO - Training [41][  140/  196]   Loss 0.024028   Top1 99.196429   Top5 99.997210   BatchTime 0.138379   LR 0.000100
INFO - Training [41][  160/  196]   Loss 0.023924   Top1 99.187012   Top5 99.997559   BatchTime 0.136481   LR 0.000100
INFO - Training [41][  180/  196]   Loss 0.024045   Top1 99.181858   Top5 99.997830   BatchTime 0.135029   LR 0.000100
INFO - ==> Top1: 99.180    Top5: 99.998    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.436933   Top1 91.093750   Top5 99.609375   BatchTime 0.148975
INFO - Validation [41][   40/   40]   Loss 0.428555   Top1 91.020000   Top5 99.670000   BatchTime 0.102815
INFO - ==> Top1: 91.020    Top5: 99.670    Loss: 0.429
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 0.018508   Top1 99.550781   Top5 100.000000   BatchTime 0.221334   LR 0.000100
INFO - Training [42][   40/  196]   Loss 0.020872   Top1 99.326172   Top5 100.000000   BatchTime 0.172370   LR 0.000100
INFO - Training [42][   60/  196]   Loss 0.020623   Top1 99.375000   Top5 100.000000   BatchTime 0.156147   LR 0.000100
INFO - Training [42][   80/  196]   Loss 0.021782   Top1 99.326172   Top5 100.000000   BatchTime 0.140556   LR 0.000100
INFO - Training [42][  100/  196]   Loss 0.022270   Top1 99.300781   Top5 100.000000   BatchTime 0.133825   LR 0.000100
INFO - Training [42][  120/  196]   Loss 0.022388   Top1 99.280599   Top5 100.000000   BatchTime 0.128213   LR 0.000100
INFO - Training [42][  140/  196]   Loss 0.022193   Top1 99.282924   Top5 100.000000   BatchTime 0.124279   LR 0.000100
INFO - Training [42][  160/  196]   Loss 0.022763   Top1 99.257812   Top5 100.000000   BatchTime 0.120217   LR 0.000100
INFO - Training [42][  180/  196]   Loss 0.022163   Top1 99.290365   Top5 100.000000   BatchTime 0.120610   LR 0.000100
INFO - ==> Top1: 99.272    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.439158   Top1 90.917969   Top5 99.648438   BatchTime 0.146036
INFO - Validation [42][   40/   40]   Loss 0.427523   Top1 90.950000   Top5 99.680000   BatchTime 0.100527
INFO - ==> Top1: 90.950    Top5: 99.680    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 0.023713   Top1 99.316406   Top5 100.000000   BatchTime 0.223473   LR 0.000100
INFO - Training [43][   40/  196]   Loss 0.023672   Top1 99.248047   Top5 100.000000   BatchTime 0.173932   LR 0.000100
INFO - Training [43][   60/  196]   Loss 0.023524   Top1 99.244792   Top5 100.000000   BatchTime 0.157354   LR 0.000100
INFO - Training [43][   80/  196]   Loss 0.023446   Top1 99.262695   Top5 100.000000   BatchTime 0.149212   LR 0.000100
INFO - Training [43][  100/  196]   Loss 0.024187   Top1 99.207031   Top5 100.000000   BatchTime 0.144217   LR 0.000100
INFO - Training [43][  120/  196]   Loss 0.024061   Top1 99.199219   Top5 100.000000   BatchTime 0.140877   LR 0.000100
INFO - Training [43][  140/  196]   Loss 0.023610   Top1 99.227121   Top5 100.000000   BatchTime 0.138488   LR 0.000100
INFO - Training [43][  160/  196]   Loss 0.023463   Top1 99.230957   Top5 100.000000   BatchTime 0.136588   LR 0.000100
INFO - Training [43][  180/  196]   Loss 0.023696   Top1 99.220920   Top5 100.000000   BatchTime 0.135192   LR 0.000100
INFO - ==> Top1: 99.230    Top5: 100.000    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.431464   Top1 90.781250   Top5 99.570312   BatchTime 0.150021
INFO - Validation [43][   40/   40]   Loss 0.422555   Top1 90.880000   Top5 99.670000   BatchTime 0.103226
INFO - ==> Top1: 90.880    Top5: 99.670    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 0.025345   Top1 99.121094   Top5 100.000000   BatchTime 0.192734   LR 0.000100
INFO - Training [44][   40/  196]   Loss 0.023487   Top1 99.160156   Top5 100.000000   BatchTime 0.147959   LR 0.000100
INFO - Training [44][   60/  196]   Loss 0.024178   Top1 99.160156   Top5 100.000000   BatchTime 0.132812   LR 0.000100
INFO - Training [44][   80/  196]   Loss 0.023629   Top1 99.179688   Top5 100.000000   BatchTime 0.124920   LR 0.000100
INFO - Training [44][  100/  196]   Loss 0.023915   Top1 99.171875   Top5 100.000000   BatchTime 0.119408   LR 0.000100
INFO - Training [44][  120/  196]   Loss 0.023033   Top1 99.231771   Top5 100.000000   BatchTime 0.120240   LR 0.000100
INFO - Training [44][  140/  196]   Loss 0.023869   Top1 99.210379   Top5 100.000000   BatchTime 0.120782   LR 0.000100
INFO - Training [44][  160/  196]   Loss 0.023635   Top1 99.213867   Top5 100.000000   BatchTime 0.121102   LR 0.000100
INFO - Training [44][  180/  196]   Loss 0.023555   Top1 99.220920   Top5 100.000000   BatchTime 0.121324   LR 0.000100
INFO - ==> Top1: 99.232    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 0.434922   Top1 90.761719   Top5 99.570312   BatchTime 0.148643
INFO - Validation [44][   40/   40]   Loss 0.424448   Top1 90.920000   Top5 99.650000   BatchTime 0.102306
INFO - ==> Top1: 90.920    Top5: 99.650    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 0.023371   Top1 99.121094   Top5 100.000000   BatchTime 0.221885   LR 0.000100
INFO - Training [45][   40/  196]   Loss 0.023289   Top1 99.150391   Top5 100.000000   BatchTime 0.172971   LR 0.000100
INFO - Training [45][   60/  196]   Loss 0.022548   Top1 99.186198   Top5 100.000000   BatchTime 0.156650   LR 0.000100
INFO - Training [45][   80/  196]   Loss 0.022301   Top1 99.218750   Top5 100.000000   BatchTime 0.148597   LR 0.000100
INFO - Training [45][  100/  196]   Loss 0.022562   Top1 99.222656   Top5 100.000000   BatchTime 0.143634   LR 0.000100
INFO - Training [45][  120/  196]   Loss 0.022375   Top1 99.235026   Top5 100.000000   BatchTime 0.140516   LR 0.000100
INFO - Training [45][  140/  196]   Loss 0.023500   Top1 99.210379   Top5 100.000000   BatchTime 0.138080   LR 0.000100
INFO - Training [45][  160/  196]   Loss 0.023502   Top1 99.221191   Top5 100.000000   BatchTime 0.136259   LR 0.000100
INFO - Training [45][  180/  196]   Loss 0.022949   Top1 99.227431   Top5 100.000000   BatchTime 0.134787   LR 0.000100
INFO - ==> Top1: 99.240    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.436971   Top1 90.722656   Top5 99.628906   BatchTime 0.134042
INFO - Validation [45][   40/   40]   Loss 0.423851   Top1 90.930000   Top5 99.670000   BatchTime 0.087520
INFO - ==> Top1: 90.930    Top5: 99.670    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 0.020990   Top1 99.375000   Top5 100.000000   BatchTime 0.191179   LR 0.000100
INFO - Training [46][   40/  196]   Loss 0.022584   Top1 99.208984   Top5 100.000000   BatchTime 0.158300   LR 0.000100
INFO - Training [46][   60/  196]   Loss 0.023049   Top1 99.199219   Top5 100.000000   BatchTime 0.147118   LR 0.000100
INFO - Training [46][   80/  196]   Loss 0.022904   Top1 99.189453   Top5 100.000000   BatchTime 0.141391   LR 0.000100
INFO - Training [46][  100/  196]   Loss 0.022882   Top1 99.171875   Top5 100.000000   BatchTime 0.138031   LR 0.000100
INFO - Training [46][  120/  196]   Loss 0.023753   Top1 99.169922   Top5 100.000000   BatchTime 0.135712   LR 0.000100
INFO - Training [46][  140/  196]   Loss 0.023340   Top1 99.204799   Top5 100.000000   BatchTime 0.134706   LR 0.000100
INFO - Training [46][  160/  196]   Loss 0.023830   Top1 99.194336   Top5 100.000000   BatchTime 0.133289   LR 0.000100
INFO - Training [46][  180/  196]   Loss 0.023660   Top1 99.212240   Top5 100.000000   BatchTime 0.131958   LR 0.000100
INFO - ==> Top1: 99.222    Top5: 100.000    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.437181   Top1 90.839844   Top5 99.609375   BatchTime 0.151085
INFO - Validation [46][   40/   40]   Loss 0.424094   Top1 91.060000   Top5 99.680000   BatchTime 0.103587
INFO - ==> Top1: 91.060    Top5: 99.680    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 0.020342   Top1 99.335938   Top5 100.000000   BatchTime 0.224315   LR 0.000100
INFO - Training [47][   40/  196]   Loss 0.022204   Top1 99.267578   Top5 100.000000   BatchTime 0.174065   LR 0.000100
INFO - Training [47][   60/  196]   Loss 0.022336   Top1 99.264323   Top5 100.000000   BatchTime 0.157295   LR 0.000100
INFO - Training [47][   80/  196]   Loss 0.022734   Top1 99.262695   Top5 100.000000   BatchTime 0.149118   LR 0.000100
INFO - Training [47][  100/  196]   Loss 0.022222   Top1 99.285156   Top5 100.000000   BatchTime 0.144063   LR 0.000100
INFO - Training [47][  120/  196]   Loss 0.021984   Top1 99.316406   Top5 99.996745   BatchTime 0.140612   LR 0.000100
INFO - Training [47][  140/  196]   Loss 0.021960   Top1 99.302455   Top5 99.997210   BatchTime 0.138033   LR 0.000100
INFO - Training [47][  160/  196]   Loss 0.021786   Top1 99.296875   Top5 99.997559   BatchTime 0.131818   LR 0.000100
INFO - Training [47][  180/  196]   Loss 0.022445   Top1 99.266493   Top5 99.997830   BatchTime 0.128649   LR 0.000100
INFO - ==> Top1: 99.270    Top5: 99.998    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.438073   Top1 90.781250   Top5 99.589844   BatchTime 0.135935
INFO - Validation [47][   40/   40]   Loss 0.424670   Top1 90.920000   Top5 99.690000   BatchTime 0.096429
INFO - ==> Top1: 90.920    Top5: 99.690    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 0.018862   Top1 99.492188   Top5 100.000000   BatchTime 0.224521   LR 0.000100
INFO - Training [48][   40/  196]   Loss 0.020109   Top1 99.365234   Top5 100.000000   BatchTime 0.174354   LR 0.000100
INFO - Training [48][   60/  196]   Loss 0.020478   Top1 99.375000   Top5 100.000000   BatchTime 0.157436   LR 0.000100
INFO - Training [48][   80/  196]   Loss 0.020016   Top1 99.394531   Top5 100.000000   BatchTime 0.149103   LR 0.000100
INFO - Training [48][  100/  196]   Loss 0.020490   Top1 99.371094   Top5 100.000000   BatchTime 0.144135   LR 0.000100
INFO - Training [48][  120/  196]   Loss 0.020031   Top1 99.384766   Top5 100.000000   BatchTime 0.140809   LR 0.000100
INFO - Training [48][  140/  196]   Loss 0.020516   Top1 99.344308   Top5 100.000000   BatchTime 0.138327   LR 0.000100
INFO - Training [48][  160/  196]   Loss 0.020299   Top1 99.360352   Top5 100.000000   BatchTime 0.136440   LR 0.000100
INFO - Training [48][  180/  196]   Loss 0.021147   Top1 99.331597   Top5 100.000000   BatchTime 0.134954   LR 0.000100
INFO - ==> Top1: 99.312    Top5: 100.000    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.435583   Top1 90.800781   Top5 99.609375   BatchTime 0.148325
INFO - Validation [48][   40/   40]   Loss 0.427517   Top1 90.960000   Top5 99.650000   BatchTime 0.102567
INFO - ==> Top1: 90.960    Top5: 99.650    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 0.022853   Top1 99.355469   Top5 100.000000   BatchTime 0.222054   LR 0.000100
INFO - Training [49][   40/  196]   Loss 0.021660   Top1 99.384766   Top5 100.000000   BatchTime 0.172766   LR 0.000100
INFO - Training [49][   60/  196]   Loss 0.021919   Top1 99.348958   Top5 100.000000   BatchTime 0.156350   LR 0.000100
INFO - Training [49][   80/  196]   Loss 0.022167   Top1 99.350586   Top5 100.000000   BatchTime 0.148733   LR 0.000100
INFO - Training [49][  100/  196]   Loss 0.022653   Top1 99.320312   Top5 100.000000   BatchTime 0.137239   LR 0.000100
INFO - Training [49][  120/  196]   Loss 0.023305   Top1 99.270833   Top5 100.000000   BatchTime 0.131533   LR 0.000100
INFO - Training [49][  140/  196]   Loss 0.023471   Top1 99.266183   Top5 100.000000   BatchTime 0.127259   LR 0.000100
INFO - Training [49][  160/  196]   Loss 0.023155   Top1 99.279785   Top5 100.000000   BatchTime 0.123416   LR 0.000100
INFO - Training [49][  180/  196]   Loss 0.023160   Top1 99.266493   Top5 100.000000   BatchTime 0.120584   LR 0.000100
INFO - ==> Top1: 99.274    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.431519   Top1 90.937500   Top5 99.589844   BatchTime 0.148182
INFO - Validation [49][   40/   40]   Loss 0.424941   Top1 90.930000   Top5 99.640000   BatchTime 0.101617
INFO - ==> Top1: 90.930    Top5: 99.640    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 0.021150   Top1 99.238281   Top5 100.000000   BatchTime 0.224876   LR 0.000010
INFO - Training [50][   40/  196]   Loss 0.020112   Top1 99.287109   Top5 100.000000   BatchTime 0.174454   LR 0.000010
INFO - Training [50][   60/  196]   Loss 0.020702   Top1 99.283854   Top5 100.000000   BatchTime 0.157636   LR 0.000010
INFO - Training [50][   80/  196]   Loss 0.021444   Top1 99.306641   Top5 100.000000   BatchTime 0.149300   LR 0.000010
INFO - Training [50][  100/  196]   Loss 0.022051   Top1 99.289062   Top5 100.000000   BatchTime 0.144240   LR 0.000010
INFO - Training [50][  120/  196]   Loss 0.021572   Top1 99.306641   Top5 100.000000   BatchTime 0.141705   LR 0.000010
INFO - Training [50][  140/  196]   Loss 0.020923   Top1 99.330357   Top5 100.000000   BatchTime 0.139112   LR 0.000010
INFO - Training [50][  160/  196]   Loss 0.021195   Top1 99.313965   Top5 100.000000   BatchTime 0.137145   LR 0.000010
INFO - Training [50][  180/  196]   Loss 0.021576   Top1 99.294705   Top5 100.000000   BatchTime 0.135593   LR 0.000010
INFO - ==> Top1: 99.264    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.431533   Top1 90.839844   Top5 99.609375   BatchTime 0.148787
INFO - Validation [50][   40/   40]   Loss 0.421776   Top1 91.070000   Top5 99.650000   BatchTime 0.102791
INFO - ==> Top1: 91.070    Top5: 99.650    Loss: 0.422
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 0.019042   Top1 99.433594   Top5 100.000000   BatchTime 0.218982   LR 0.000010
INFO - Training [51][   40/  196]   Loss 0.022199   Top1 99.238281   Top5 100.000000   BatchTime 0.154389   LR 0.000010
INFO - Training [51][   60/  196]   Loss 0.022967   Top1 99.166667   Top5 100.000000   BatchTime 0.136793   LR 0.000010
INFO - Training [51][   80/  196]   Loss 0.022494   Top1 99.204102   Top5 100.000000   BatchTime 0.128103   LR 0.000010
INFO - Training [51][  100/  196]   Loss 0.021964   Top1 99.214844   Top5 100.000000   BatchTime 0.121624   LR 0.000010
INFO - Training [51][  120/  196]   Loss 0.021987   Top1 99.225260   Top5 100.000000   BatchTime 0.118703   LR 0.000010
INFO - Training [51][  140/  196]   Loss 0.022237   Top1 99.238281   Top5 100.000000   BatchTime 0.119490   LR 0.000010
INFO - Training [51][  160/  196]   Loss 0.022385   Top1 99.228516   Top5 100.000000   BatchTime 0.119966   LR 0.000010
INFO - Training [51][  180/  196]   Loss 0.022470   Top1 99.227431   Top5 100.000000   BatchTime 0.120374   LR 0.000010
INFO - ==> Top1: 99.228    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.437857   Top1 90.644531   Top5 99.609375   BatchTime 0.149171
INFO - Validation [51][   40/   40]   Loss 0.423992   Top1 90.860000   Top5 99.630000   BatchTime 0.102386
INFO - ==> Top1: 90.860    Top5: 99.630    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 0.022457   Top1 99.335938   Top5 100.000000   BatchTime 0.224617   LR 0.000010
INFO - Training [52][   40/  196]   Loss 0.020436   Top1 99.384766   Top5 100.000000   BatchTime 0.174657   LR 0.000010
INFO - Training [52][   60/  196]   Loss 0.022275   Top1 99.270833   Top5 100.000000   BatchTime 0.157873   LR 0.000010
INFO - Training [52][   80/  196]   Loss 0.022078   Top1 99.277344   Top5 100.000000   BatchTime 0.149343   LR 0.000010
INFO - Training [52][  100/  196]   Loss 0.022710   Top1 99.253906   Top5 100.000000   BatchTime 0.144358   LR 0.000010
INFO - Training [52][  120/  196]   Loss 0.022864   Top1 99.225260   Top5 100.000000   BatchTime 0.140954   LR 0.000010
INFO - Training [52][  140/  196]   Loss 0.022311   Top1 99.266183   Top5 100.000000   BatchTime 0.138513   LR 0.000010
INFO - Training [52][  160/  196]   Loss 0.022253   Top1 99.262695   Top5 100.000000   BatchTime 0.136625   LR 0.000010
INFO - Training [52][  180/  196]   Loss 0.021887   Top1 99.270833   Top5 100.000000   BatchTime 0.135152   LR 0.000010
INFO - ==> Top1: 99.272    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.433076   Top1 90.957031   Top5 99.589844   BatchTime 0.145294
INFO - Validation [52][   40/   40]   Loss 0.424694   Top1 90.980000   Top5 99.680000   BatchTime 0.090137
INFO - ==> Top1: 90.980    Top5: 99.680    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 0.024151   Top1 99.277344   Top5 100.000000   BatchTime 0.206056   LR 0.000010
INFO - Training [53][   40/  196]   Loss 0.021646   Top1 99.306641   Top5 100.000000   BatchTime 0.150383   LR 0.000010
INFO - Training [53][   60/  196]   Loss 0.022529   Top1 99.257812   Top5 100.000000   BatchTime 0.139570   LR 0.000010
INFO - Training [53][   80/  196]   Loss 0.022804   Top1 99.218750   Top5 100.000000   BatchTime 0.135583   LR 0.000010
INFO - Training [53][  100/  196]   Loss 0.023274   Top1 99.210938   Top5 100.000000   BatchTime 0.133285   LR 0.000010
INFO - Training [53][  120/  196]   Loss 0.023016   Top1 99.222005   Top5 100.000000   BatchTime 0.131828   LR 0.000010
INFO - Training [53][  140/  196]   Loss 0.022717   Top1 99.224330   Top5 100.000000   BatchTime 0.130700   LR 0.000010
INFO - Training [53][  160/  196]   Loss 0.022984   Top1 99.233398   Top5 99.997559   BatchTime 0.129795   LR 0.000010
INFO - Training [53][  180/  196]   Loss 0.022827   Top1 99.240451   Top5 99.997830   BatchTime 0.129086   LR 0.000010
INFO - ==> Top1: 99.232    Top5: 99.998    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.438885   Top1 90.898438   Top5 99.609375   BatchTime 0.148466
INFO - Validation [53][   40/   40]   Loss 0.428290   Top1 90.950000   Top5 99.640000   BatchTime 0.102638
INFO - ==> Top1: 90.950    Top5: 99.640    Loss: 0.428
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 0.021766   Top1 99.316406   Top5 100.000000   BatchTime 0.224647   LR 0.000010
INFO - Training [54][   40/  196]   Loss 0.021215   Top1 99.316406   Top5 100.000000   BatchTime 0.174307   LR 0.000010
INFO - Training [54][   60/  196]   Loss 0.021791   Top1 99.283854   Top5 100.000000   BatchTime 0.157380   LR 0.000010
INFO - Training [54][   80/  196]   Loss 0.021352   Top1 99.287109   Top5 100.000000   BatchTime 0.149112   LR 0.000010
INFO - Training [54][  100/  196]   Loss 0.021530   Top1 99.277344   Top5 100.000000   BatchTime 0.144174   LR 0.000010
INFO - Training [54][  120/  196]   Loss 0.021761   Top1 99.248047   Top5 100.000000   BatchTime 0.140713   LR 0.000010
INFO - Training [54][  140/  196]   Loss 0.021595   Top1 99.268973   Top5 100.000000   BatchTime 0.138841   LR 0.000010
INFO - Training [54][  160/  196]   Loss 0.021497   Top1 99.270020   Top5 100.000000   BatchTime 0.136835   LR 0.000010
INFO - Training [54][  180/  196]   Loss 0.022055   Top1 99.255642   Top5 100.000000   BatchTime 0.131712   LR 0.000010
INFO - ==> Top1: 99.242    Top5: 100.000    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.435026   Top1 90.644531   Top5 99.628906   BatchTime 0.133028
INFO - Validation [54][   40/   40]   Loss 0.424341   Top1 90.950000   Top5 99.680000   BatchTime 0.083957
INFO - ==> Top1: 90.950    Top5: 99.680    Loss: 0.424
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 0.020211   Top1 99.375000   Top5 100.000000   BatchTime 0.222724   LR 0.000010
INFO - Training [55][   40/  196]   Loss 0.021986   Top1 99.228516   Top5 100.000000   BatchTime 0.173328   LR 0.000010
INFO - Training [55][   60/  196]   Loss 0.022393   Top1 99.205729   Top5 100.000000   BatchTime 0.156978   LR 0.000010
INFO - Training [55][   80/  196]   Loss 0.023250   Top1 99.208984   Top5 100.000000   BatchTime 0.148686   LR 0.000010
INFO - Training [55][  100/  196]   Loss 0.023136   Top1 99.210938   Top5 100.000000   BatchTime 0.143792   LR 0.000010
INFO - Training [55][  120/  196]   Loss 0.022579   Top1 99.241536   Top5 100.000000   BatchTime 0.140462   LR 0.000010
INFO - Training [55][  140/  196]   Loss 0.022927   Top1 99.235491   Top5 100.000000   BatchTime 0.138052   LR 0.000010
INFO - Training [55][  160/  196]   Loss 0.023443   Top1 99.211426   Top5 100.000000   BatchTime 0.136218   LR 0.000010
INFO - Training [55][  180/  196]   Loss 0.023808   Top1 99.192708   Top5 100.000000   BatchTime 0.134782   LR 0.000010
INFO - ==> Top1: 99.204    Top5: 100.000    Loss: 0.024
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.438399   Top1 90.703125   Top5 99.609375   BatchTime 0.147530
INFO - Validation [55][   40/   40]   Loss 0.424771   Top1 90.970000   Top5 99.680000   BatchTime 0.101362
INFO - ==> Top1: 90.970    Top5: 99.680    Loss: 0.425
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 0.019914   Top1 99.453125   Top5 100.000000   BatchTime 0.223960   LR 0.000010
INFO - Training [56][   40/  196]   Loss 0.022341   Top1 99.287109   Top5 100.000000   BatchTime 0.173791   LR 0.000010
INFO - Training [56][   60/  196]   Loss 0.021181   Top1 99.342448   Top5 100.000000   BatchTime 0.157069   LR 0.000010
INFO - Training [56][   80/  196]   Loss 0.022147   Top1 99.291992   Top5 100.000000   BatchTime 0.148785   LR 0.000010
INFO - Training [56][  100/  196]   Loss 0.022092   Top1 99.261719   Top5 100.000000   BatchTime 0.143075   LR 0.000010
INFO - Training [56][  120/  196]   Loss 0.022174   Top1 99.254557   Top5 100.000000   BatchTime 0.134695   LR 0.000010
INFO - Training [56][  140/  196]   Loss 0.022595   Top1 99.229911   Top5 100.000000   BatchTime 0.130024   LR 0.000010
INFO - Training [56][  160/  196]   Loss 0.022406   Top1 99.235840   Top5 100.000000   BatchTime 0.126286   LR 0.000010
INFO - Training [56][  180/  196]   Loss 0.022202   Top1 99.240451   Top5 100.000000   BatchTime 0.122588   LR 0.000010
INFO - ==> Top1: 99.244    Top5: 100.000    Loss: 0.022
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.432600   Top1 90.859375   Top5 99.628906   BatchTime 0.147475
INFO - Validation [56][   40/   40]   Loss 0.422994   Top1 90.930000   Top5 99.690000   BatchTime 0.101950
INFO - ==> Top1: 90.930    Top5: 99.690    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 0.018543   Top1 99.296875   Top5 100.000000   BatchTime 0.225027   LR 0.000010
INFO - Training [57][   40/  196]   Loss 0.018299   Top1 99.355469   Top5 100.000000   BatchTime 0.174619   LR 0.000010
INFO - Training [57][   60/  196]   Loss 0.018867   Top1 99.348958   Top5 100.000000   BatchTime 0.158151   LR 0.000010
INFO - Training [57][   80/  196]   Loss 0.020129   Top1 99.321289   Top5 100.000000   BatchTime 0.149664   LR 0.000010
INFO - Training [57][  100/  196]   Loss 0.021068   Top1 99.253906   Top5 100.000000   BatchTime 0.144460   LR 0.000010
INFO - Training [57][  120/  196]   Loss 0.020760   Top1 99.277344   Top5 100.000000   BatchTime 0.141062   LR 0.000010
INFO - Training [57][  140/  196]   Loss 0.020899   Top1 99.296875   Top5 100.000000   BatchTime 0.138542   LR 0.000010
INFO - Training [57][  160/  196]   Loss 0.021161   Top1 99.287109   Top5 100.000000   BatchTime 0.136684   LR 0.000010
INFO - Training [57][  180/  196]   Loss 0.021200   Top1 99.283854   Top5 100.000000   BatchTime 0.135222   LR 0.000010
INFO - ==> Top1: 99.274    Top5: 100.000    Loss: 0.021
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.433744   Top1 90.878906   Top5 99.531250   BatchTime 0.148135
INFO - Validation [57][   40/   40]   Loss 0.422811   Top1 90.840000   Top5 99.630000   BatchTime 0.102896
INFO - ==> Top1: 90.840    Top5: 99.630    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 0.020418   Top1 99.414062   Top5 100.000000   BatchTime 0.222240   LR 0.000010
INFO - Training [58][   40/  196]   Loss 0.022134   Top1 99.257812   Top5 100.000000   BatchTime 0.170900   LR 0.000010
INFO - Training [58][   60/  196]   Loss 0.023083   Top1 99.212240   Top5 100.000000   BatchTime 0.144726   LR 0.000010
INFO - Training [58][   80/  196]   Loss 0.022514   Top1 99.218750   Top5 100.000000   BatchTime 0.134085   LR 0.000010
INFO - Training [58][  100/  196]   Loss 0.022571   Top1 99.218750   Top5 99.996094   BatchTime 0.128020   LR 0.000010
INFO - Training [58][  120/  196]   Loss 0.022289   Top1 99.235026   Top5 99.996745   BatchTime 0.122687   LR 0.000010
INFO - Training [58][  140/  196]   Loss 0.022702   Top1 99.232701   Top5 99.997210   BatchTime 0.121736   LR 0.000010
INFO - Training [58][  160/  196]   Loss 0.022827   Top1 99.218750   Top5 99.997559   BatchTime 0.121905   LR 0.000010
INFO - Training [58][  180/  196]   Loss 0.022679   Top1 99.227431   Top5 99.997830   BatchTime 0.122064   LR 0.000010
INFO - ==> Top1: 99.232    Top5: 99.998    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.435743   Top1 90.585938   Top5 99.628906   BatchTime 0.149554
INFO - Validation [58][   40/   40]   Loss 0.426465   Top1 90.740000   Top5 99.650000   BatchTime 0.102892
INFO - ==> Top1: 90.740    Top5: 99.650    Loss: 0.426
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 0.019834   Top1 99.414062   Top5 100.000000   BatchTime 0.226064   LR 0.000010
INFO - Training [59][   40/  196]   Loss 0.020152   Top1 99.384766   Top5 100.000000   BatchTime 0.175210   LR 0.000010
INFO - Training [59][   60/  196]   Loss 0.022005   Top1 99.348958   Top5 99.993490   BatchTime 0.158168   LR 0.000010
INFO - Training [59][   80/  196]   Loss 0.022069   Top1 99.375000   Top5 99.995117   BatchTime 0.149707   LR 0.000010
INFO - Training [59][  100/  196]   Loss 0.022791   Top1 99.316406   Top5 99.996094   BatchTime 0.144913   LR 0.000010
INFO - Training [59][  120/  196]   Loss 0.022697   Top1 99.313151   Top5 99.996745   BatchTime 0.141613   LR 0.000010
INFO - Training [59][  140/  196]   Loss 0.022465   Top1 99.327567   Top5 99.997210   BatchTime 0.139086   LR 0.000010
INFO - Training [59][  160/  196]   Loss 0.022981   Top1 99.299316   Top5 99.997559   BatchTime 0.137148   LR 0.000010
INFO - Training [59][  180/  196]   Loss 0.022991   Top1 99.288194   Top5 99.997830   BatchTime 0.135707   LR 0.000010
INFO - ==> Top1: 99.286    Top5: 99.998    Loss: 0.023
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.432156   Top1 90.898438   Top5 99.589844   BatchTime 0.148815
INFO - Validation [59][   40/   40]   Loss 0.423042   Top1 90.880000   Top5 99.650000   BatchTime 0.098007
INFO - ==> Top1: 90.880    Top5: 99.650    Loss: 0.423
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
INFO - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
INFO - >>>>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.432156   Top1 90.898438   Top5 99.589844   BatchTime 0.138520
INFO - Validation [   40/   40]   Loss 0.423042   Top1 90.880000   Top5 99.650000   BatchTime 0.090507
INFO - ==> Top1: 90.880    Top5: 99.650    Loss: 0.423
INFO - Program completed successfully ... exiting ...
INFO - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net