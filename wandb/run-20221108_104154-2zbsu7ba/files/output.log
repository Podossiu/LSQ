INFO - Log file for this run: /home/ilena7440/LSQ/out/MobileNetv2_imagenet_a8w8_10_epoch80_20221108-104154/MobileNetv2_imagenet_a8w8_10_epoch80_20221108-104154.log
INFO - TensorBoard data directory: /home/ilena7440/LSQ/out/MobileNetv2_imagenet_a8w8_10_epoch80_20221108-104154/tb_runs
INFO - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
********************pre-trained*****************
INFO - Created `MobileNetv2` model for `imagenet` dataset
          Use pre-trained model = True
/home/ilena7440/LSQ/quan/quantizer/lsq.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (len(x.shape) == 4 and x.shape[1] != 1):
/home/ilena7440/LSQ/quan/quantizer/lsq.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x_reshape = x.reshape(co // self.block_size, self.block_size, ci, kh, kw)
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
127
INFO - Inserted quantizers into the original model
INFO - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.005
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.005
INFO - >>>>>>>> Epoch -1 (pre-trained model evaluation)
INFO - Validation: 50000 samples (128 per mini-batch)
Munch({'update_per_batch': True, 'mode': 'multi_step', 'milestones': [20, 40, 60], 'gamma': 0.1})
multi_step
INFO - Validation [   20/  391]   Loss 27.491910   Top1 0.000000   Top5 0.195312   BatchTime 0.796130
INFO - Validation [   40/  391]   Loss 28.447756   Top1 0.000000   Top5 0.097656   BatchTime 0.466395
INFO - Validation [   60/  391]   Loss 27.423508   Top1 0.000000   Top5 0.325521   BatchTime 0.359930
INFO - Validation [   80/  391]   Loss 24.824432   Top1 0.000000   Top5 0.302734   BatchTime 0.308232
INFO - Validation [  100/  391]   Loss 23.227272   Top1 0.000000   Top5 0.242188   BatchTime 0.287456
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0cc8ca5d30>
Traceback (most recent call last):
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1510, in __del__
    self._shutdown_workers()
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1474, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
KeyboardInterrupt:
Traceback (most recent call last):
  File "main.py", line 175, in <module>
    main()
  File "main.py", line 118, in main
    top1, top5, _,sparsity = process.validate(val_loader, model, criterion,
  File "/home/ilena7440/LSQ/process.py", line 122, in validate
    outputs = model(inputs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/model/mobilenet.py", line 142, in forward
    x = self.features(x)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/model/mobilenet.py", line 103, in forward
    return x + self.conv(x)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/quan/func.py", line 22, in forward
    quantized_weight = self.quan_w_fn(self.weight)
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ilena7440/LSQ/quan/quantizer/lsq.py", line 119, in forward
    self.p.data.clamp_(0.,self.c.data)
KeyboardInterrupt