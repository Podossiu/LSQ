2022-11-04 03:05:38,462 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538.log
2022-11-04 03:05:39,530 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/tb_runs
2022-11-04 03:05:40,644 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-04 03:05:40,691 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
2022-11-04 03:05:42,884 - INFO  - Inserted quantizers into the original model
2022-11-04 03:05:44,795 - INFO  - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_20_epoch80_checkpoint.pth.tar
2022-11-04 03:05:44,796 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-04 03:05:44,796 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-04 03:05:44,796 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-04 03:05:44,796 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:05:48,869 - INFO  - Validation [   20/   40]   Loss 0.427234   Top1 88.906250   Top5 99.257812   BatchTime 0.203568   
2022-11-04 03:05:50,083 - INFO  - Validation [   40/   40]   Loss 0.421873   Top1 88.880000   Top5 99.300000   BatchTime 0.132142   
2022-11-04 03:05:50,247 - INFO  - ==> Top1: 88.880    Top5: 99.300    Loss: 0.422

2022-11-04 03:05:50,273 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 88.880   Top5: 99.300] Sparsity : 0.892
2022-11-04 03:05:50,273 - INFO  - >>>>>>>> Epoch   0
2022-11-04 03:05:50,273 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:05:55,180 - INFO  - Training [0][   20/  196]   Loss 0.076963   Top1 97.167969   Top5 100.000000   BatchTime 0.245319   LR 0.010000   
2022-11-04 03:05:57,652 - INFO  - Training [0][   40/  196]   Loss 0.083223   Top1 97.001953   Top5 100.000000   BatchTime 0.184464   LR 0.010000   
2022-11-04 03:06:00,136 - INFO  - Training [0][   60/  196]   Loss 0.081400   Top1 97.115885   Top5 99.993490   BatchTime 0.164368   LR 0.010000   
2022-11-04 03:06:02,623 - INFO  - Training [0][   80/  196]   Loss 0.082263   Top1 97.050781   Top5 99.995117   BatchTime 0.154360   LR 0.010000   
2022-11-04 03:06:05,090 - INFO  - Training [0][  100/  196]   Loss 0.085263   Top1 96.949219   Top5 99.996094   BatchTime 0.148162   LR 0.010000   
2022-11-04 03:06:07,570 - INFO  - Training [0][  120/  196]   Loss 0.085850   Top1 96.933594   Top5 99.993490   BatchTime 0.144131   LR 0.010000   
2022-11-04 03:06:10,013 - INFO  - Training [0][  140/  196]   Loss 0.086749   Top1 96.886161   Top5 99.994420   BatchTime 0.140993   LR 0.010000   
2022-11-04 03:06:11,773 - INFO  - Training [0][  160/  196]   Loss 0.088896   Top1 96.789551   Top5 99.995117   BatchTime 0.134367   LR 0.010000   
2022-11-04 03:06:13,807 - INFO  - Training [0][  180/  196]   Loss 0.090771   Top1 96.738281   Top5 99.991319   BatchTime 0.130741   LR 0.010000   
2022-11-04 03:06:15,927 - INFO  - ==> Top1: 96.684    Top5: 99.990    Loss: 0.092

2022-11-04 03:06:15,928 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:06:18,873 - INFO  - Validation [0][   20/   40]   Loss 0.401924   Top1 89.140625   Top5 99.628906   BatchTime 0.147239   
2022-11-04 03:06:19,999 - INFO  - Validation [0][   40/   40]   Loss 0.388427   Top1 89.290000   Top5 99.680000   BatchTime 0.101755   
2022-11-04 03:06:20,249 - INFO  - ==> Top1: 89.290    Top5: 99.680    Loss: 0.388

2022-11-04 03:06:20,281 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 89.290   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:06:20,281 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 88.880   Top5: 99.300] Sparsity : 0.892
2022-11-04 03:06:20,349 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:06:20,410 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:06:20,410 - INFO  - >>>>>>>> Epoch   1
2022-11-04 03:06:20,412 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:06:24,869 - INFO  - Training [1][   20/  196]   Loss 0.089644   Top1 97.070312   Top5 99.980469   BatchTime 0.222829   LR 0.010000   
2022-11-04 03:06:27,367 - INFO  - Training [1][   40/  196]   Loss 0.088608   Top1 96.943359   Top5 99.970703   BatchTime 0.173871   LR 0.010000   
2022-11-04 03:06:29,840 - INFO  - Training [1][   60/  196]   Loss 0.093025   Top1 96.744792   Top5 99.980469   BatchTime 0.157133   LR 0.010000   
2022-11-04 03:06:32,317 - INFO  - Training [1][   80/  196]   Loss 0.093140   Top1 96.767578   Top5 99.980469   BatchTime 0.148805   LR 0.010000   
2022-11-04 03:06:34,792 - INFO  - Training [1][  100/  196]   Loss 0.091671   Top1 96.808594   Top5 99.976562   BatchTime 0.143791   LR 0.010000   
2022-11-04 03:06:37,400 - INFO  - Training [1][  120/  196]   Loss 0.091902   Top1 96.741536   Top5 99.980469   BatchTime 0.141563   LR 0.010000   
2022-11-04 03:06:39,869 - INFO  - Training [1][  140/  196]   Loss 0.094620   Top1 96.629464   Top5 99.983259   BatchTime 0.138973   LR 0.010000   
2022-11-04 03:06:42,335 - INFO  - Training [1][  160/  196]   Loss 0.094156   Top1 96.633301   Top5 99.985352   BatchTime 0.137018   LR 0.010000   
2022-11-04 03:06:44,791 - INFO  - Training [1][  180/  196]   Loss 0.095091   Top1 96.590712   Top5 99.986979   BatchTime 0.135436   LR 0.010000   
2022-11-04 03:06:46,921 - INFO  - ==> Top1: 96.614    Top5: 99.988    Loss: 0.095

2022-11-04 03:06:46,922 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:06:49,811 - INFO  - Validation [1][   20/   40]   Loss 0.389986   Top1 89.550781   Top5 99.628906   BatchTime 0.144365   
2022-11-04 03:06:50,914 - INFO  - Validation [1][   40/   40]   Loss 0.386786   Top1 89.730000   Top5 99.640000   BatchTime 0.099748   
2022-11-04 03:06:51,172 - INFO  - ==> Top1: 89.730    Top5: 99.640    Loss: 0.387

2022-11-04 03:06:51,203 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:06:51,204 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 89.290   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:06:51,204 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 88.880   Top5: 99.300] Sparsity : 0.892
2022-11-04 03:06:51,390 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:06:51,553 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:06:51,553 - INFO  - >>>>>>>> Epoch   2
2022-11-04 03:06:51,554 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:06:55,959 - INFO  - Training [2][   20/  196]   Loss 0.081766   Top1 96.933594   Top5 100.000000   BatchTime 0.220208   LR 0.010000   
2022-11-04 03:06:58,436 - INFO  - Training [2][   40/  196]   Loss 0.087492   Top1 96.757812   Top5 100.000000   BatchTime 0.172036   LR 0.010000   
2022-11-04 03:07:00,906 - INFO  - Training [2][   60/  196]   Loss 0.084757   Top1 96.907552   Top5 100.000000   BatchTime 0.155857   LR 0.010000   
2022-11-04 03:07:03,094 - INFO  - Training [2][   80/  196]   Loss 0.088729   Top1 96.728516   Top5 100.000000   BatchTime 0.144246   LR 0.010000   
2022-11-04 03:07:05,014 - INFO  - Training [2][  100/  196]   Loss 0.089253   Top1 96.753906   Top5 99.992188   BatchTime 0.134588   LR 0.010000   
2022-11-04 03:07:07,066 - INFO  - Training [2][  120/  196]   Loss 0.090532   Top1 96.705729   Top5 99.990234   BatchTime 0.129257   LR 0.010000   
2022-11-04 03:07:09,116 - INFO  - Training [2][  140/  196]   Loss 0.093038   Top1 96.629464   Top5 99.988839   BatchTime 0.125434   LR 0.010000   
2022-11-04 03:07:10,900 - INFO  - Training [2][  160/  196]   Loss 0.093367   Top1 96.604004   Top5 99.985352   BatchTime 0.120906   LR 0.010000   
2022-11-04 03:07:13,240 - INFO  - Training [2][  180/  196]   Loss 0.093142   Top1 96.623264   Top5 99.986979   BatchTime 0.120473   LR 0.010000   
2022-11-04 03:07:15,422 - INFO  - ==> Top1: 96.626    Top5: 99.988    Loss: 0.093

2022-11-04 03:07:15,423 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:07:18,346 - INFO  - Validation [2][   20/   40]   Loss 0.401655   Top1 89.101562   Top5 99.414062   BatchTime 0.146038   
2022-11-04 03:07:19,452 - INFO  - Validation [2][   40/   40]   Loss 0.396351   Top1 89.300000   Top5 99.530000   BatchTime 0.100677   
2022-11-04 03:07:19,707 - INFO  - ==> Top1: 89.300    Top5: 99.530    Loss: 0.396

2022-11-04 03:07:19,736 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:07:19,737 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 89.300   Top5: 99.530] Sparsity : 0.892
2022-11-04 03:07:19,737 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 89.290   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:07:19,843 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:07:19,843 - INFO  - >>>>>>>> Epoch   3
2022-11-04 03:07:19,844 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:07:24,258 - INFO  - Training [3][   20/  196]   Loss 0.076090   Top1 97.070312   Top5 100.000000   BatchTime 0.220677   LR 0.010000   
2022-11-04 03:07:26,731 - INFO  - Training [3][   40/  196]   Loss 0.082310   Top1 96.933594   Top5 100.000000   BatchTime 0.172162   LR 0.010000   
2022-11-04 03:07:29,211 - INFO  - Training [3][   60/  196]   Loss 0.085654   Top1 96.959635   Top5 100.000000   BatchTime 0.156104   LR 0.010000   
2022-11-04 03:07:31,681 - INFO  - Training [3][   80/  196]   Loss 0.089006   Top1 96.850586   Top5 99.990234   BatchTime 0.147952   LR 0.010000   
2022-11-04 03:07:34,169 - INFO  - Training [3][  100/  196]   Loss 0.090843   Top1 96.785156   Top5 99.992188   BatchTime 0.143245   LR 0.010000   
2022-11-04 03:07:36,641 - INFO  - Training [3][  120/  196]   Loss 0.091360   Top1 96.754557   Top5 99.993490   BatchTime 0.139970   LR 0.010000   
2022-11-04 03:07:39,110 - INFO  - Training [3][  140/  196]   Loss 0.091633   Top1 96.727121   Top5 99.994420   BatchTime 0.137610   LR 0.010000   
2022-11-04 03:07:41,570 - INFO  - Training [3][  160/  196]   Loss 0.091355   Top1 96.735840   Top5 99.995117   BatchTime 0.135783   LR 0.010000   
2022-11-04 03:07:44,037 - INFO  - Training [3][  180/  196]   Loss 0.092352   Top1 96.684028   Top5 99.993490   BatchTime 0.134401   LR 0.010000   
2022-11-04 03:07:46,223 - INFO  - ==> Top1: 96.678    Top5: 99.992    Loss: 0.092

2022-11-04 03:07:46,224 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:07:49,143 - INFO  - Validation [3][   20/   40]   Loss 0.402380   Top1 89.824219   Top5 99.550781   BatchTime 0.145908   
2022-11-04 03:07:50,251 - INFO  - Validation [3][   40/   40]   Loss 0.399379   Top1 89.730000   Top5 99.640000   BatchTime 0.100645   
2022-11-04 03:07:50,502 - INFO  - ==> Top1: 89.730    Top5: 99.640    Loss: 0.399

2022-11-04 03:07:50,532 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:07:50,532 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:07:50,532 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 89.300   Top5: 99.530] Sparsity : 0.892
2022-11-04 03:07:50,711 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:07:50,865 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:07:50,865 - INFO  - >>>>>>>> Epoch   4
2022-11-04 03:07:50,866 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:07:55,027 - INFO  - Training [4][   20/  196]   Loss 0.090919   Top1 96.875000   Top5 99.960938   BatchTime 0.208057   LR 0.010000   
2022-11-04 03:07:56,948 - INFO  - Training [4][   40/  196]   Loss 0.084385   Top1 97.070312   Top5 99.980469   BatchTime 0.152040   LR 0.010000   
2022-11-04 03:07:59,008 - INFO  - Training [4][   60/  196]   Loss 0.085833   Top1 97.024740   Top5 99.980469   BatchTime 0.135706   LR 0.010000   
2022-11-04 03:08:01,062 - INFO  - Training [4][   80/  196]   Loss 0.087379   Top1 96.982422   Top5 99.985352   BatchTime 0.127451   LR 0.010000   
2022-11-04 03:08:02,916 - INFO  - Training [4][  100/  196]   Loss 0.086951   Top1 96.996094   Top5 99.988281   BatchTime 0.120500   LR 0.010000   
2022-11-04 03:08:05,275 - INFO  - Training [4][  120/  196]   Loss 0.087046   Top1 97.008464   Top5 99.983724   BatchTime 0.120073   LR 0.010000   
2022-11-04 03:08:07,748 - INFO  - Training [4][  140/  196]   Loss 0.087217   Top1 96.981027   Top5 99.986049   BatchTime 0.120582   LR 0.010000   
2022-11-04 03:08:10,207 - INFO  - Training [4][  160/  196]   Loss 0.087785   Top1 96.889648   Top5 99.987793   BatchTime 0.120881   LR 0.010000   
2022-11-04 03:08:12,673 - INFO  - Training [4][  180/  196]   Loss 0.087970   Top1 96.901042   Top5 99.989149   BatchTime 0.121148   LR 0.010000   
2022-11-04 03:08:14,850 - INFO  - ==> Top1: 96.922    Top5: 99.986    Loss: 0.087

2022-11-04 03:08:14,851 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:08:17,729 - INFO  - Validation [4][   20/   40]   Loss 0.386903   Top1 89.804688   Top5 99.648438   BatchTime 0.143866   
2022-11-04 03:08:18,803 - INFO  - Validation [4][   40/   40]   Loss 0.391297   Top1 89.730000   Top5 99.620000   BatchTime 0.098783   
2022-11-04 03:08:19,061 - INFO  - ==> Top1: 89.730    Top5: 99.620    Loss: 0.391

2022-11-04 03:08:19,093 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:08:19,094 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:08:19,094 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 89.730   Top5: 99.620] Sparsity : 0.892
2022-11-04 03:08:19,190 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:08:19,190 - INFO  - >>>>>>>> Epoch   5
2022-11-04 03:08:19,191 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:08:23,647 - INFO  - Training [5][   20/  196]   Loss 0.070920   Top1 97.460938   Top5 100.000000   BatchTime 0.222806   LR 0.010000   
2022-11-04 03:08:26,132 - INFO  - Training [5][   40/  196]   Loss 0.076056   Top1 97.373047   Top5 99.990234   BatchTime 0.173530   LR 0.010000   
2022-11-04 03:08:28,611 - INFO  - Training [5][   60/  196]   Loss 0.078682   Top1 97.317708   Top5 99.986979   BatchTime 0.156998   LR 0.010000   
2022-11-04 03:08:31,089 - INFO  - Training [5][   80/  196]   Loss 0.080538   Top1 97.285156   Top5 99.985352   BatchTime 0.148726   LR 0.010000   
2022-11-04 03:08:33,571 - INFO  - Training [5][  100/  196]   Loss 0.081126   Top1 97.218750   Top5 99.988281   BatchTime 0.143795   LR 0.010000   
2022-11-04 03:08:36,013 - INFO  - Training [5][  120/  196]   Loss 0.082095   Top1 97.161458   Top5 99.990234   BatchTime 0.140176   LR 0.010000   
2022-11-04 03:08:38,608 - INFO  - Training [5][  140/  196]   Loss 0.083232   Top1 97.098214   Top5 99.986049   BatchTime 0.138688   LR 0.010000   
2022-11-04 03:08:41,071 - INFO  - Training [5][  160/  196]   Loss 0.082983   Top1 97.067871   Top5 99.987793   BatchTime 0.136744   LR 0.010000   
2022-11-04 03:08:43,529 - INFO  - Training [5][  180/  196]   Loss 0.084193   Top1 97.018229   Top5 99.984809   BatchTime 0.135207   LR 0.010000   
2022-11-04 03:08:45,697 - INFO  - ==> Top1: 96.984    Top5: 99.984    Loss: 0.085

2022-11-04 03:08:45,698 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:08:48,414 - INFO  - Validation [5][   20/   40]   Loss 0.388876   Top1 90.097656   Top5 99.628906   BatchTime 0.135756   
2022-11-04 03:08:49,097 - INFO  - Validation [5][   40/   40]   Loss 0.386485   Top1 89.920000   Top5 99.710000   BatchTime 0.084973   
2022-11-04 03:08:49,362 - INFO  - ==> Top1: 89.920    Top5: 99.710    Loss: 0.386

2022-11-04 03:08:49,387 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:08:49,388 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:08:49,388 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:08:49,571 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:08:49,752 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:08:49,752 - INFO  - >>>>>>>> Epoch   6
2022-11-04 03:08:49,754 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:08:53,795 - INFO  - Training [6][   20/  196]   Loss 0.082007   Top1 96.855469   Top5 100.000000   BatchTime 0.202032   LR 0.010000   
2022-11-04 03:08:55,623 - INFO  - Training [6][   40/  196]   Loss 0.081352   Top1 96.904297   Top5 100.000000   BatchTime 0.146725   LR 0.010000   
2022-11-04 03:08:58,118 - INFO  - Training [6][   60/  196]   Loss 0.083207   Top1 96.940104   Top5 99.993490   BatchTime 0.139396   LR 0.010000   
2022-11-04 03:09:00,598 - INFO  - Training [6][   80/  196]   Loss 0.081352   Top1 96.997070   Top5 99.995117   BatchTime 0.135542   LR 0.010000   
2022-11-04 03:09:03,064 - INFO  - Training [6][  100/  196]   Loss 0.082831   Top1 96.988281   Top5 99.988281   BatchTime 0.133100   LR 0.010000   
2022-11-04 03:09:05,530 - INFO  - Training [6][  120/  196]   Loss 0.084766   Top1 96.927083   Top5 99.990234   BatchTime 0.131465   LR 0.010000   
2022-11-04 03:09:08,000 - INFO  - Training [6][  140/  196]   Loss 0.085398   Top1 96.941964   Top5 99.988839   BatchTime 0.130329   LR 0.010000   
2022-11-04 03:09:10,468 - INFO  - Training [6][  160/  196]   Loss 0.085058   Top1 96.972656   Top5 99.990234   BatchTime 0.129461   LR 0.010000   
2022-11-04 03:09:12,934 - INFO  - Training [6][  180/  196]   Loss 0.085457   Top1 96.931424   Top5 99.991319   BatchTime 0.128774   LR 0.010000   
2022-11-04 03:09:15,109 - INFO  - ==> Top1: 96.930    Top5: 99.992    Loss: 0.086

2022-11-04 03:09:15,110 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:09:17,984 - INFO  - Validation [6][   20/   40]   Loss 0.405752   Top1 89.648438   Top5 99.570312   BatchTime 0.143615   
2022-11-04 03:09:19,075 - INFO  - Validation [6][   40/   40]   Loss 0.397239   Top1 89.620000   Top5 99.640000   BatchTime 0.099076   
2022-11-04 03:09:19,317 - INFO  - ==> Top1: 89.620    Top5: 99.640    Loss: 0.397

2022-11-04 03:09:19,361 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:09:19,362 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:09:19,362 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:09:19,458 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:09:19,458 - INFO  - >>>>>>>> Epoch   7
2022-11-04 03:09:19,460 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:09:23,875 - INFO  - Training [7][   20/  196]   Loss 0.081672   Top1 97.265625   Top5 100.000000   BatchTime 0.220720   LR 0.010000   
2022-11-04 03:09:26,341 - INFO  - Training [7][   40/  196]   Loss 0.082655   Top1 97.148438   Top5 99.990234   BatchTime 0.172012   LR 0.010000   
2022-11-04 03:09:28,815 - INFO  - Training [7][   60/  196]   Loss 0.080900   Top1 97.161458   Top5 99.993490   BatchTime 0.155918   LR 0.010000   
2022-11-04 03:09:31,298 - INFO  - Training [7][   80/  196]   Loss 0.080542   Top1 97.114258   Top5 99.995117   BatchTime 0.147971   LR 0.010000   
2022-11-04 03:09:33,782 - INFO  - Training [7][  100/  196]   Loss 0.080788   Top1 97.156250   Top5 99.996094   BatchTime 0.143219   LR 0.010000   
2022-11-04 03:09:36,252 - INFO  - Training [7][  120/  196]   Loss 0.081114   Top1 97.115885   Top5 99.990234   BatchTime 0.139927   LR 0.010000   
2022-11-04 03:09:38,720 - INFO  - Training [7][  140/  196]   Loss 0.082184   Top1 97.061942   Top5 99.991629   BatchTime 0.137570   LR 0.010000   
2022-11-04 03:09:41,167 - INFO  - Training [7][  160/  196]   Loss 0.082662   Top1 97.058105   Top5 99.985352   BatchTime 0.135665   LR 0.010000   
2022-11-04 03:09:43,072 - INFO  - Training [7][  180/  196]   Loss 0.082245   Top1 97.039931   Top5 99.986979   BatchTime 0.131175   LR 0.010000   
2022-11-04 03:09:44,905 - INFO  - ==> Top1: 97.028    Top5: 99.988    Loss: 0.083

2022-11-04 03:09:44,906 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:09:47,474 - INFO  - Validation [7][   20/   40]   Loss 0.395968   Top1 89.941406   Top5 99.609375   BatchTime 0.128331   
2022-11-04 03:09:48,160 - INFO  - Validation [7][   40/   40]   Loss 0.396742   Top1 89.930000   Top5 99.720000   BatchTime 0.081308   
2022-11-04 03:09:48,432 - INFO  - ==> Top1: 89.930    Top5: 99.720    Loss: 0.397

2022-11-04 03:09:48,458 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:09:48,459 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:09:48,459 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:09:48,639 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:09:48,862 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:09:48,862 - INFO  - >>>>>>>> Epoch   8
2022-11-04 03:09:48,863 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:09:53,276 - INFO  - Training [8][   20/  196]   Loss 0.072513   Top1 97.324219   Top5 99.980469   BatchTime 0.220641   LR 0.010000   
2022-11-04 03:09:55,750 - INFO  - Training [8][   40/  196]   Loss 0.076117   Top1 97.255859   Top5 99.990234   BatchTime 0.172160   LR 0.010000   
2022-11-04 03:09:58,218 - INFO  - Training [8][   60/  196]   Loss 0.078174   Top1 97.161458   Top5 99.993490   BatchTime 0.155911   LR 0.010000   
2022-11-04 03:10:00,695 - INFO  - Training [8][   80/  196]   Loss 0.079005   Top1 97.153320   Top5 99.990234   BatchTime 0.147897   LR 0.010000   
2022-11-04 03:10:03,165 - INFO  - Training [8][  100/  196]   Loss 0.079894   Top1 97.156250   Top5 99.992188   BatchTime 0.143016   LR 0.010000   
2022-11-04 03:10:05,642 - INFO  - Training [8][  120/  196]   Loss 0.079831   Top1 97.151693   Top5 99.993490   BatchTime 0.139818   LR 0.010000   
2022-11-04 03:10:08,112 - INFO  - Training [8][  140/  196]   Loss 0.080266   Top1 97.145647   Top5 99.994420   BatchTime 0.137486   LR 0.010000   
2022-11-04 03:10:10,572 - INFO  - Training [8][  160/  196]   Loss 0.080695   Top1 97.150879   Top5 99.992676   BatchTime 0.135675   LR 0.010000   
2022-11-04 03:10:13,032 - INFO  - Training [8][  180/  196]   Loss 0.080786   Top1 97.126736   Top5 99.989149   BatchTime 0.134266   LR 0.010000   
2022-11-04 03:10:15,207 - INFO  - ==> Top1: 97.142    Top5: 99.988    Loss: 0.081

2022-11-04 03:10:15,208 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:10:18,091 - INFO  - Validation [8][   20/   40]   Loss 0.399601   Top1 89.531250   Top5 99.531250   BatchTime 0.144096   
2022-11-04 03:10:19,183 - INFO  - Validation [8][   40/   40]   Loss 0.396642   Top1 89.600000   Top5 99.570000   BatchTime 0.099362   
2022-11-04 03:10:19,460 - INFO  - ==> Top1: 89.600    Top5: 99.570    Loss: 0.397

2022-11-04 03:10:19,491 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:10:19,492 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:10:19,492 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 89.730   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:10:19,594 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:10:19,595 - INFO  - >>>>>>>> Epoch   9
2022-11-04 03:10:19,596 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:10:24,013 - INFO  - Training [9][   20/  196]   Loss 0.073254   Top1 97.539062   Top5 99.980469   BatchTime 0.220808   LR 0.010000   
2022-11-04 03:10:26,395 - INFO  - Training [9][   40/  196]   Loss 0.074736   Top1 97.353516   Top5 99.990234   BatchTime 0.169951   LR 0.010000   
2022-11-04 03:10:28,864 - INFO  - Training [9][   60/  196]   Loss 0.076111   Top1 97.350260   Top5 99.986979   BatchTime 0.154457   LR 0.010000   
2022-11-04 03:10:31,336 - INFO  - Training [9][   80/  196]   Loss 0.076319   Top1 97.368164   Top5 99.990234   BatchTime 0.146745   LR 0.010000   
2022-11-04 03:10:33,803 - INFO  - Training [9][  100/  196]   Loss 0.076461   Top1 97.351562   Top5 99.992188   BatchTime 0.142060   LR 0.010000   
2022-11-04 03:10:35,583 - INFO  - Training [9][  120/  196]   Loss 0.075687   Top1 97.373047   Top5 99.993490   BatchTime 0.133221   LR 0.010000   
2022-11-04 03:10:37,765 - INFO  - Training [9][  140/  196]   Loss 0.075750   Top1 97.366071   Top5 99.994420   BatchTime 0.129775   LR 0.010000   
2022-11-04 03:10:39,773 - INFO  - Training [9][  160/  196]   Loss 0.076790   Top1 97.312012   Top5 99.992676   BatchTime 0.126102   LR 0.010000   
2022-11-04 03:10:41,729 - INFO  - Training [9][  180/  196]   Loss 0.076801   Top1 97.337240   Top5 99.993490   BatchTime 0.122958   LR 0.010000   
2022-11-04 03:10:43,549 - INFO  - ==> Top1: 97.316    Top5: 99.990    Loss: 0.078

2022-11-04 03:10:43,549 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:10:46,426 - INFO  - Validation [9][   20/   40]   Loss 0.397051   Top1 89.843750   Top5 99.667969   BatchTime 0.143767   
2022-11-04 03:10:47,518 - INFO  - Validation [9][   40/   40]   Loss 0.389503   Top1 89.910000   Top5 99.680000   BatchTime 0.099193   
2022-11-04 03:10:47,792 - INFO  - ==> Top1: 89.910    Top5: 99.680    Loss: 0.390

2022-11-04 03:10:47,834 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:10:47,835 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:10:47,835 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.910   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:10:47,931 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:10:47,931 - INFO  - >>>>>>>> Epoch  10
2022-11-04 03:10:47,932 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:10:52,317 - INFO  - Training [10][   20/  196]   Loss 0.065667   Top1 97.617188   Top5 100.000000   BatchTime 0.219233   LR 0.010000   
2022-11-04 03:10:54,794 - INFO  - Training [10][   40/  196]   Loss 0.069110   Top1 97.568359   Top5 100.000000   BatchTime 0.171563   LR 0.010000   
2022-11-04 03:10:57,269 - INFO  - Training [10][   60/  196]   Loss 0.071744   Top1 97.467448   Top5 99.993490   BatchTime 0.155611   LR 0.010000   
2022-11-04 03:10:59,740 - INFO  - Training [10][   80/  196]   Loss 0.073637   Top1 97.397461   Top5 99.995117   BatchTime 0.147595   LR 0.010000   
2022-11-04 03:11:02,236 - INFO  - Training [10][  100/  196]   Loss 0.074608   Top1 97.367188   Top5 99.992188   BatchTime 0.143038   LR 0.010000   
2022-11-04 03:11:04,714 - INFO  - Training [10][  120/  196]   Loss 0.075447   Top1 97.356771   Top5 99.993490   BatchTime 0.139845   LR 0.010000   
2022-11-04 03:11:07,185 - INFO  - Training [10][  140/  196]   Loss 0.076284   Top1 97.329799   Top5 99.988839   BatchTime 0.137521   LR 0.010000   
2022-11-04 03:11:09,647 - INFO  - Training [10][  160/  196]   Loss 0.076843   Top1 97.292480   Top5 99.990234   BatchTime 0.135718   LR 0.010000   
2022-11-04 03:11:12,112 - INFO  - Training [10][  180/  196]   Loss 0.078202   Top1 97.217882   Top5 99.989149   BatchTime 0.134329   LR 0.010000   
2022-11-04 03:11:14,296 - INFO  - ==> Top1: 97.216    Top5: 99.990    Loss: 0.078

2022-11-04 03:11:14,297 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:11:17,178 - INFO  - Validation [10][   20/   40]   Loss 0.402299   Top1 89.628906   Top5 99.628906   BatchTime 0.143951   
2022-11-04 03:11:18,284 - INFO  - Validation [10][   40/   40]   Loss 0.400620   Top1 89.750000   Top5 99.680000   BatchTime 0.099625   
2022-11-04 03:11:18,565 - INFO  - ==> Top1: 89.750    Top5: 99.680    Loss: 0.401

2022-11-04 03:11:18,602 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:11:18,603 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:11:18,603 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.910   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:11:18,703 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:11:18,704 - INFO  - >>>>>>>> Epoch  11
2022-11-04 03:11:18,705 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:11:23,093 - INFO  - Training [11][   20/  196]   Loss 0.066755   Top1 97.656250   Top5 100.000000   BatchTime 0.219419   LR 0.010000   
2022-11-04 03:11:25,550 - INFO  - Training [11][   40/  196]   Loss 0.067706   Top1 97.714844   Top5 100.000000   BatchTime 0.171116   LR 0.010000   
2022-11-04 03:11:27,325 - INFO  - Training [11][   60/  196]   Loss 0.068806   Top1 97.688802   Top5 100.000000   BatchTime 0.143662   LR 0.010000   
2022-11-04 03:11:29,403 - INFO  - Training [11][   80/  196]   Loss 0.071558   Top1 97.563477   Top5 99.995117   BatchTime 0.133719   LR 0.010000   
2022-11-04 03:11:31,437 - INFO  - Training [11][  100/  196]   Loss 0.073088   Top1 97.445312   Top5 99.996094   BatchTime 0.127319   LR 0.010000   
2022-11-04 03:11:33,506 - INFO  - Training [11][  120/  196]   Loss 0.074202   Top1 97.373047   Top5 99.996745   BatchTime 0.123343   LR 0.010000   
2022-11-04 03:11:35,501 - INFO  - Training [11][  140/  196]   Loss 0.074322   Top1 97.382812   Top5 99.997210   BatchTime 0.119973   LR 0.010000   
2022-11-04 03:11:37,971 - INFO  - Training [11][  160/  196]   Loss 0.074252   Top1 97.365723   Top5 99.997559   BatchTime 0.120414   LR 0.010000   
2022-11-04 03:11:40,441 - INFO  - Training [11][  180/  196]   Loss 0.075538   Top1 97.324219   Top5 99.997830   BatchTime 0.120756   LR 0.010000   
2022-11-04 03:11:42,616 - INFO  - ==> Top1: 97.322    Top5: 99.998    Loss: 0.076

2022-11-04 03:11:42,617 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:11:45,502 - INFO  - Validation [11][   20/   40]   Loss 0.411556   Top1 89.667969   Top5 99.628906   BatchTime 0.144187   
2022-11-04 03:11:46,606 - INFO  - Validation [11][   40/   40]   Loss 0.403545   Top1 89.780000   Top5 99.640000   BatchTime 0.099702   
2022-11-04 03:11:46,852 - INFO  - ==> Top1: 89.780    Top5: 99.640    Loss: 0.404

2022-11-04 03:11:46,880 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:11:46,881 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:11:46,881 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.910   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:11:46,975 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:11:46,976 - INFO  - >>>>>>>> Epoch  12
2022-11-04 03:11:46,977 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:11:51,364 - INFO  - Training [12][   20/  196]   Loss 0.080934   Top1 97.343750   Top5 99.960938   BatchTime 0.219355   LR 0.010000   
2022-11-04 03:11:53,839 - INFO  - Training [12][   40/  196]   Loss 0.075122   Top1 97.539062   Top5 99.980469   BatchTime 0.171564   LR 0.010000   
2022-11-04 03:11:56,325 - INFO  - Training [12][   60/  196]   Loss 0.075897   Top1 97.421875   Top5 99.986979   BatchTime 0.155808   LR 0.010000   
2022-11-04 03:11:58,800 - INFO  - Training [12][   80/  196]   Loss 0.076084   Top1 97.407227   Top5 99.980469   BatchTime 0.147784   LR 0.010000   
2022-11-04 03:12:01,275 - INFO  - Training [12][  100/  196]   Loss 0.076086   Top1 97.335938   Top5 99.984375   BatchTime 0.142983   LR 0.010000   
2022-11-04 03:12:03,759 - INFO  - Training [12][  120/  196]   Loss 0.077101   Top1 97.249349   Top5 99.986979   BatchTime 0.139852   LR 0.010000   
2022-11-04 03:12:06,225 - INFO  - Training [12][  140/  196]   Loss 0.078164   Top1 97.204241   Top5 99.988839   BatchTime 0.137482   LR 0.010000   
2022-11-04 03:12:08,684 - INFO  - Training [12][  160/  196]   Loss 0.077619   Top1 97.250977   Top5 99.990234   BatchTime 0.135668   LR 0.010000   
2022-11-04 03:12:11,150 - INFO  - Training [12][  180/  196]   Loss 0.076350   Top1 97.296007   Top5 99.991319   BatchTime 0.134292   LR 0.010000   
2022-11-04 03:12:13,327 - INFO  - ==> Top1: 97.306    Top5: 99.992    Loss: 0.076

2022-11-04 03:12:13,328 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:12:16,183 - INFO  - Validation [12][   20/   40]   Loss 0.414053   Top1 89.941406   Top5 99.570312   BatchTime 0.142676   
2022-11-04 03:12:17,319 - INFO  - Validation [12][   40/   40]   Loss 0.395072   Top1 90.090000   Top5 99.640000   BatchTime 0.099722   
2022-11-04 03:12:17,566 - INFO  - ==> Top1: 90.090    Top5: 99.640    Loss: 0.395

2022-11-04 03:12:17,598 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:12:17,599 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:12:17,599 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:12:17,803 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:12:17,982 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:12:17,982 - INFO  - >>>>>>>> Epoch  13
2022-11-04 03:12:17,983 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:12:22,182 - INFO  - Training [13][   20/  196]   Loss 0.066754   Top1 97.558594   Top5 100.000000   BatchTime 0.209939   LR 0.010000   
2022-11-04 03:12:24,210 - INFO  - Training [13][   40/  196]   Loss 0.070907   Top1 97.509766   Top5 99.990234   BatchTime 0.155669   LR 0.010000   
2022-11-04 03:12:26,223 - INFO  - Training [13][   60/  196]   Loss 0.073822   Top1 97.363281   Top5 99.993490   BatchTime 0.137328   LR 0.010000   
2022-11-04 03:12:28,163 - INFO  - Training [13][   80/  196]   Loss 0.072962   Top1 97.416992   Top5 99.995117   BatchTime 0.127243   LR 0.010000   
2022-11-04 03:12:30,639 - INFO  - Training [13][  100/  196]   Loss 0.073101   Top1 97.371094   Top5 99.996094   BatchTime 0.126555   LR 0.010000   
2022-11-04 03:12:33,218 - INFO  - Training [13][  120/  196]   Loss 0.072850   Top1 97.373047   Top5 99.993490   BatchTime 0.126957   LR 0.010000   
2022-11-04 03:12:35,698 - INFO  - Training [13][  140/  196]   Loss 0.072351   Top1 97.388393   Top5 99.991629   BatchTime 0.126530   LR 0.010000   
2022-11-04 03:12:38,169 - INFO  - Training [13][  160/  196]   Loss 0.072153   Top1 97.382812   Top5 99.990234   BatchTime 0.126158   LR 0.010000   
2022-11-04 03:12:40,630 - INFO  - Training [13][  180/  196]   Loss 0.071943   Top1 97.384983   Top5 99.991319   BatchTime 0.125811   LR 0.010000   
2022-11-04 03:12:42,813 - INFO  - ==> Top1: 97.382    Top5: 99.992    Loss: 0.072

2022-11-04 03:12:42,813 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:12:45,676 - INFO  - Validation [13][   20/   40]   Loss 0.409129   Top1 89.648438   Top5 99.707031   BatchTime 0.143088   
2022-11-04 03:12:46,802 - INFO  - Validation [13][   40/   40]   Loss 0.400637   Top1 89.850000   Top5 99.690000   BatchTime 0.099684   
2022-11-04 03:12:47,054 - INFO  - ==> Top1: 89.850    Top5: 99.690    Loss: 0.401

2022-11-04 03:12:47,083 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:12:47,083 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:12:47,084 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:12:47,193 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:12:47,193 - INFO  - >>>>>>>> Epoch  14
2022-11-04 03:12:47,195 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:12:51,600 - INFO  - Training [14][   20/  196]   Loss 0.060100   Top1 97.929688   Top5 99.980469   BatchTime 0.220244   LR 0.010000   
2022-11-04 03:12:54,072 - INFO  - Training [14][   40/  196]   Loss 0.063611   Top1 97.910156   Top5 99.990234   BatchTime 0.171932   LR 0.010000   
2022-11-04 03:12:56,548 - INFO  - Training [14][   60/  196]   Loss 0.068476   Top1 97.675781   Top5 99.993490   BatchTime 0.155885   LR 0.010000   
2022-11-04 03:12:59,021 - INFO  - Training [14][   80/  196]   Loss 0.068752   Top1 97.700195   Top5 99.995117   BatchTime 0.147818   LR 0.010000   
2022-11-04 03:13:01,489 - INFO  - Training [14][  100/  196]   Loss 0.068396   Top1 97.703125   Top5 99.996094   BatchTime 0.142936   LR 0.010000   
2022-11-04 03:13:03,969 - INFO  - Training [14][  120/  196]   Loss 0.068792   Top1 97.646484   Top5 99.996745   BatchTime 0.139779   LR 0.010000   
2022-11-04 03:13:06,422 - INFO  - Training [14][  140/  196]   Loss 0.069890   Top1 97.547433   Top5 99.994420   BatchTime 0.137334   LR 0.010000   
2022-11-04 03:13:08,880 - INFO  - Training [14][  160/  196]   Loss 0.070708   Top1 97.502441   Top5 99.992676   BatchTime 0.135528   LR 0.010000   
2022-11-04 03:13:11,334 - INFO  - Training [14][  180/  196]   Loss 0.071358   Top1 97.447917   Top5 99.993490   BatchTime 0.134102   LR 0.010000   
2022-11-04 03:13:13,604 - INFO  - ==> Top1: 97.434    Top5: 99.992    Loss: 0.072

2022-11-04 03:13:13,605 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:13:16,442 - INFO  - Validation [14][   20/   40]   Loss 0.412530   Top1 89.648438   Top5 99.589844   BatchTime 0.141688   
2022-11-04 03:13:17,291 - INFO  - Validation [14][   40/   40]   Loss 0.405428   Top1 89.720000   Top5 99.660000   BatchTime 0.092064   
2022-11-04 03:13:17,537 - INFO  - ==> Top1: 89.720    Top5: 99.660    Loss: 0.405

2022-11-04 03:13:17,567 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:13:17,568 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:13:17,568 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:13:17,676 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:13:17,676 - INFO  - >>>>>>>> Epoch  15
2022-11-04 03:13:17,678 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:13:21,902 - INFO  - Training [15][   20/  196]   Loss 0.065279   Top1 97.539062   Top5 99.980469   BatchTime 0.211183   LR 0.010000   
2022-11-04 03:13:24,387 - INFO  - Training [15][   40/  196]   Loss 0.067893   Top1 97.558594   Top5 99.990234   BatchTime 0.167735   LR 0.010000   
2022-11-04 03:13:26,857 - INFO  - Training [15][   60/  196]   Loss 0.069549   Top1 97.513021   Top5 99.986979   BatchTime 0.152983   LR 0.010000   
2022-11-04 03:13:29,335 - INFO  - Training [15][   80/  196]   Loss 0.069619   Top1 97.519531   Top5 99.990234   BatchTime 0.145718   LR 0.010000   
2022-11-04 03:13:31,817 - INFO  - Training [15][  100/  196]   Loss 0.070639   Top1 97.476562   Top5 99.992188   BatchTime 0.141394   LR 0.010000   
2022-11-04 03:13:34,299 - INFO  - Training [15][  120/  196]   Loss 0.071363   Top1 97.444661   Top5 99.990234   BatchTime 0.138511   LR 0.010000   
2022-11-04 03:13:36,768 - INFO  - Training [15][  140/  196]   Loss 0.072063   Top1 97.421875   Top5 99.991629   BatchTime 0.136357   LR 0.010000   
2022-11-04 03:13:39,228 - INFO  - Training [15][  160/  196]   Loss 0.072851   Top1 97.392578   Top5 99.992676   BatchTime 0.134684   LR 0.010000   
2022-11-04 03:13:41,693 - INFO  - Training [15][  180/  196]   Loss 0.073086   Top1 97.374132   Top5 99.993490   BatchTime 0.133412   LR 0.010000   
2022-11-04 03:13:43,876 - INFO  - ==> Top1: 97.366    Top5: 99.994    Loss: 0.073

2022-11-04 03:13:43,877 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:13:46,769 - INFO  - Validation [15][   20/   40]   Loss 0.423537   Top1 89.765625   Top5 99.570312   BatchTime 0.144516   
2022-11-04 03:13:47,868 - INFO  - Validation [15][   40/   40]   Loss 0.407148   Top1 89.910000   Top5 99.660000   BatchTime 0.099731   
2022-11-04 03:13:48,118 - INFO  - ==> Top1: 89.910    Top5: 99.660    Loss: 0.407

2022-11-04 03:13:48,158 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:13:48,159 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:13:48,159 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.920   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:13:48,256 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:13:48,256 - INFO  - >>>>>>>> Epoch  16
2022-11-04 03:13:48,257 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:13:52,679 - INFO  - Training [16][   20/  196]   Loss 0.072957   Top1 97.519531   Top5 100.000000   BatchTime 0.221082   LR 0.010000   
2022-11-04 03:13:55,152 - INFO  - Training [16][   40/  196]   Loss 0.073778   Top1 97.421875   Top5 99.980469   BatchTime 0.172363   LR 0.010000   
2022-11-04 03:13:57,624 - INFO  - Training [16][   60/  196]   Loss 0.073388   Top1 97.421875   Top5 99.986979   BatchTime 0.156116   LR 0.010000   
2022-11-04 03:14:00,098 - INFO  - Training [16][   80/  196]   Loss 0.072434   Top1 97.465820   Top5 99.990234   BatchTime 0.148008   LR 0.010000   
2022-11-04 03:14:02,563 - INFO  - Training [16][  100/  196]   Loss 0.071583   Top1 97.496094   Top5 99.992188   BatchTime 0.143058   LR 0.010000   
2022-11-04 03:14:05,024 - INFO  - Training [16][  120/  196]   Loss 0.070395   Top1 97.558594   Top5 99.993490   BatchTime 0.139727   LR 0.010000   
2022-11-04 03:14:07,225 - INFO  - Training [16][  140/  196]   Loss 0.071023   Top1 97.511161   Top5 99.991629   BatchTime 0.135482   LR 0.010000   
2022-11-04 03:14:09,093 - INFO  - Training [16][  160/  196]   Loss 0.071581   Top1 97.463379   Top5 99.990234   BatchTime 0.130220   LR 0.010000   
2022-11-04 03:14:11,100 - INFO  - Training [16][  180/  196]   Loss 0.071468   Top1 97.465278   Top5 99.991319   BatchTime 0.126902   LR 0.010000   
2022-11-04 03:14:12,927 - INFO  - ==> Top1: 97.414    Top5: 99.992    Loss: 0.072

2022-11-04 03:14:12,928 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:14:15,780 - INFO  - Validation [16][   20/   40]   Loss 0.421756   Top1 89.667969   Top5 99.589844   BatchTime 0.142480   
2022-11-04 03:14:16,885 - INFO  - Validation [16][   40/   40]   Loss 0.405434   Top1 89.930000   Top5 99.640000   BatchTime 0.098870   
2022-11-04 03:14:17,138 - INFO  - ==> Top1: 89.930    Top5: 99.640    Loss: 0.405

2022-11-04 03:14:17,166 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:14:17,167 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:14:17,167 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.930   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:14:17,253 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:14:17,253 - INFO  - >>>>>>>> Epoch  17
2022-11-04 03:14:17,254 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:14:21,670 - INFO  - Training [17][   20/  196]   Loss 0.073140   Top1 97.285156   Top5 100.000000   BatchTime 0.220775   LR 0.010000   
2022-11-04 03:14:24,095 - INFO  - Training [17][   40/  196]   Loss 0.070598   Top1 97.314453   Top5 100.000000   BatchTime 0.171016   LR 0.010000   
2022-11-04 03:14:26,562 - INFO  - Training [17][   60/  196]   Loss 0.070945   Top1 97.265625   Top5 100.000000   BatchTime 0.155128   LR 0.010000   
2022-11-04 03:14:29,043 - INFO  - Training [17][   80/  196]   Loss 0.072047   Top1 97.285156   Top5 100.000000   BatchTime 0.147347   LR 0.010000   
2022-11-04 03:14:31,516 - INFO  - Training [17][  100/  196]   Loss 0.071117   Top1 97.386719   Top5 100.000000   BatchTime 0.142614   LR 0.010000   
2022-11-04 03:14:33,988 - INFO  - Training [17][  120/  196]   Loss 0.071669   Top1 97.376302   Top5 100.000000   BatchTime 0.139446   LR 0.010000   
2022-11-04 03:14:36,456 - INFO  - Training [17][  140/  196]   Loss 0.071087   Top1 97.444196   Top5 100.000000   BatchTime 0.137153   LR 0.010000   
2022-11-04 03:14:38,924 - INFO  - Training [17][  160/  196]   Loss 0.070441   Top1 97.456055   Top5 100.000000   BatchTime 0.135430   LR 0.010000   
2022-11-04 03:14:41,399 - INFO  - Training [17][  180/  196]   Loss 0.070090   Top1 97.491319   Top5 100.000000   BatchTime 0.134133   LR 0.010000   
2022-11-04 03:14:43,690 - INFO  - ==> Top1: 97.494    Top5: 100.000    Loss: 0.070

2022-11-04 03:14:43,691 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:14:46,568 - INFO  - Validation [17][   20/   40]   Loss 0.414587   Top1 89.785156   Top5 99.570312   BatchTime 0.143762   
2022-11-04 03:14:47,688 - INFO  - Validation [17][   40/   40]   Loss 0.408457   Top1 89.820000   Top5 99.610000   BatchTime 0.099871   
2022-11-04 03:14:47,947 - INFO  - ==> Top1: 89.820    Top5: 99.610    Loss: 0.408

2022-11-04 03:14:47,987 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:14:47,988 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:14:47,988 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.930   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:14:48,087 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:14:48,087 - INFO  - >>>>>>>> Epoch  18
2022-11-04 03:14:48,088 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:14:52,495 - INFO  - Training [18][   20/  196]   Loss 0.063254   Top1 97.812500   Top5 100.000000   BatchTime 0.220318   LR 0.010000   
2022-11-04 03:14:54,966 - INFO  - Training [18][   40/  196]   Loss 0.064494   Top1 97.724609   Top5 100.000000   BatchTime 0.171930   LR 0.010000   
2022-11-04 03:14:57,429 - INFO  - Training [18][   60/  196]   Loss 0.063245   Top1 97.760417   Top5 100.000000   BatchTime 0.155681   LR 0.010000   
2022-11-04 03:14:59,879 - INFO  - Training [18][   80/  196]   Loss 0.065539   Top1 97.636719   Top5 100.000000   BatchTime 0.147383   LR 0.010000   
2022-11-04 03:15:01,688 - INFO  - Training [18][  100/  196]   Loss 0.066408   Top1 97.613281   Top5 99.996094   BatchTime 0.135995   LR 0.010000   
2022-11-04 03:15:03,763 - INFO  - Training [18][  120/  196]   Loss 0.067936   Top1 97.548828   Top5 99.990234   BatchTime 0.130616   LR 0.010000   
2022-11-04 03:15:05,798 - INFO  - Training [18][  140/  196]   Loss 0.068214   Top1 97.541853   Top5 99.991629   BatchTime 0.126498   LR 0.010000   
2022-11-04 03:15:07,758 - INFO  - Training [18][  160/  196]   Loss 0.068238   Top1 97.551270   Top5 99.992676   BatchTime 0.122934   LR 0.010000   
2022-11-04 03:15:09,837 - INFO  - Training [18][  180/  196]   Loss 0.068597   Top1 97.534722   Top5 99.993490   BatchTime 0.120823   LR 0.010000   
2022-11-04 03:15:12,018 - INFO  - ==> Top1: 97.526    Top5: 99.994    Loss: 0.069

2022-11-04 03:15:12,019 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:15:14,874 - INFO  - Validation [18][   20/   40]   Loss 0.402839   Top1 89.785156   Top5 99.726562   BatchTime 0.142658   
2022-11-04 03:15:15,979 - INFO  - Validation [18][   40/   40]   Loss 0.398942   Top1 90.030000   Top5 99.720000   BatchTime 0.098966   
2022-11-04 03:15:16,230 - INFO  - ==> Top1: 90.030    Top5: 99.720    Loss: 0.399

2022-11-04 03:15:16,258 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:15:16,258 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:15:16,258 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:15:16,360 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:15:16,360 - INFO  - >>>>>>>> Epoch  19
2022-11-04 03:15:16,362 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:15:20,748 - INFO  - Training [19][   20/  196]   Loss 0.066703   Top1 97.734375   Top5 99.980469   BatchTime 0.219293   LR 0.010000   
2022-11-04 03:15:23,209 - INFO  - Training [19][   40/  196]   Loss 0.064508   Top1 97.714844   Top5 99.990234   BatchTime 0.171178   LR 0.010000   
2022-11-04 03:15:25,670 - INFO  - Training [19][   60/  196]   Loss 0.065353   Top1 97.669271   Top5 99.986979   BatchTime 0.155131   LR 0.010000   
2022-11-04 03:15:28,152 - INFO  - Training [19][   80/  196]   Loss 0.063963   Top1 97.773438   Top5 99.990234   BatchTime 0.147375   LR 0.010000   
2022-11-04 03:15:30,614 - INFO  - Training [19][  100/  196]   Loss 0.063932   Top1 97.781250   Top5 99.992188   BatchTime 0.142524   LR 0.010000   
2022-11-04 03:15:33,086 - INFO  - Training [19][  120/  196]   Loss 0.065024   Top1 97.766927   Top5 99.990234   BatchTime 0.139364   LR 0.010000   
2022-11-04 03:15:35,554 - INFO  - Training [19][  140/  196]   Loss 0.065050   Top1 97.773438   Top5 99.991629   BatchTime 0.137082   LR 0.010000   
2022-11-04 03:15:38,009 - INFO  - Training [19][  160/  196]   Loss 0.065139   Top1 97.775879   Top5 99.992676   BatchTime 0.135290   LR 0.010000   
2022-11-04 03:15:40,465 - INFO  - Training [19][  180/  196]   Loss 0.065531   Top1 97.753906   Top5 99.993490   BatchTime 0.133903   LR 0.010000   
2022-11-04 03:15:42,645 - INFO  - ==> Top1: 97.722    Top5: 99.992    Loss: 0.066

2022-11-04 03:15:42,646 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:15:45,511 - INFO  - Validation [19][   20/   40]   Loss 0.455195   Top1 89.218750   Top5 99.492188   BatchTime 0.143195   
2022-11-04 03:15:46,629 - INFO  - Validation [19][   40/   40]   Loss 0.426278   Top1 89.570000   Top5 99.600000   BatchTime 0.099556   
2022-11-04 03:15:46,876 - INFO  - ==> Top1: 89.570    Top5: 99.600    Loss: 0.426

2022-11-04 03:15:46,909 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:15:46,910 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:15:46,910 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.930   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:15:47,007 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:15:47,008 - INFO  - >>>>>>>> Epoch  20
2022-11-04 03:15:47,009 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:15:51,372 - INFO  - Training [20][   20/  196]   Loss 0.068440   Top1 97.500000   Top5 99.980469   BatchTime 0.218150   LR 0.010000   
2022-11-04 03:15:53,268 - INFO  - Training [20][   40/  196]   Loss 0.066276   Top1 97.519531   Top5 99.990234   BatchTime 0.156479   LR 0.010000   
2022-11-04 03:15:55,307 - INFO  - Training [20][   60/  196]   Loss 0.069017   Top1 97.460938   Top5 99.993490   BatchTime 0.138288   LR 0.010000   
2022-11-04 03:15:57,352 - INFO  - Training [20][   80/  196]   Loss 0.068920   Top1 97.495117   Top5 99.995117   BatchTime 0.129281   LR 0.010000   
2022-11-04 03:15:59,426 - INFO  - Training [20][  100/  196]   Loss 0.068440   Top1 97.539062   Top5 99.996094   BatchTime 0.124161   LR 0.010000   
2022-11-04 03:16:01,396 - INFO  - Training [20][  120/  196]   Loss 0.068061   Top1 97.561849   Top5 99.996745   BatchTime 0.119886   LR 0.010000   
2022-11-04 03:16:03,884 - INFO  - Training [20][  140/  196]   Loss 0.068688   Top1 97.519531   Top5 99.994420   BatchTime 0.120528   LR 0.010000   
2022-11-04 03:16:06,342 - INFO  - Training [20][  160/  196]   Loss 0.067904   Top1 97.563477   Top5 99.995117   BatchTime 0.120827   LR 0.010000   
2022-11-04 03:16:08,799 - INFO  - Training [20][  180/  196]   Loss 0.068424   Top1 97.526042   Top5 99.995660   BatchTime 0.121050   LR 0.010000   
2022-11-04 03:16:10,976 - INFO  - ==> Top1: 97.514    Top5: 99.996    Loss: 0.069

2022-11-04 03:16:10,976 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:16:13,887 - INFO  - Validation [20][   20/   40]   Loss 0.426163   Top1 89.804688   Top5 99.609375   BatchTime 0.145492   
2022-11-04 03:16:15,025 - INFO  - Validation [20][   40/   40]   Loss 0.411114   Top1 89.960000   Top5 99.650000   BatchTime 0.101190   
2022-11-04 03:16:15,288 - INFO  - ==> Top1: 89.960    Top5: 99.650    Loss: 0.411

2022-11-04 03:16:15,330 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:16:15,331 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:16:15,331 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
2022-11-04 03:16:15,415 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:16:15,415 - INFO  - >>>>>>>> Epoch  21
2022-11-04 03:16:15,416 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:16:19,814 - INFO  - Training [21][   20/  196]   Loss 0.056221   Top1 97.968750   Top5 100.000000   BatchTime 0.219879   LR 0.010000   
2022-11-04 03:16:22,301 - INFO  - Training [21][   40/  196]   Loss 0.061213   Top1 97.880859   Top5 100.000000   BatchTime 0.172126   LR 0.010000   
2022-11-04 03:16:24,770 - INFO  - Training [21][   60/  196]   Loss 0.065377   Top1 97.695312   Top5 99.993490   BatchTime 0.155886   LR 0.010000   
2022-11-04 03:16:27,235 - INFO  - Training [21][   80/  196]   Loss 0.066114   Top1 97.636719   Top5 99.995117   BatchTime 0.147730   LR 0.010000   
2022-11-04 03:16:29,691 - INFO  - Training [21][  100/  196]   Loss 0.065793   Top1 97.652344   Top5 99.996094   BatchTime 0.142743   LR 0.010000   
2022-11-04 03:16:32,162 - INFO  - Training [21][  120/  196]   Loss 0.065019   Top1 97.698568   Top5 99.996745   BatchTime 0.139544   LR 0.010000   
2022-11-04 03:16:34,620 - INFO  - Training [21][  140/  196]   Loss 0.064038   Top1 97.728795   Top5 99.997210   BatchTime 0.137165   LR 0.010000   
2022-11-04 03:16:37,085 - INFO  - Training [21][  160/  196]   Loss 0.064122   Top1 97.739258   Top5 99.997559   BatchTime 0.135429   LR 0.010000   
2022-11-04 03:16:39,539 - INFO  - Training [21][  180/  196]   Loss 0.064408   Top1 97.719184   Top5 99.995660   BatchTime 0.134011   LR 0.010000   
2022-11-04 03:16:41,713 - INFO  - ==> Top1: 97.720    Top5: 99.996    Loss: 0.065

2022-11-04 03:16:41,714 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:16:44,590 - INFO  - Validation [21][   20/   40]   Loss 0.420133   Top1 89.667969   Top5 99.726562   BatchTime 0.143741   
2022-11-04 03:16:45,448 - INFO  - Validation [21][   40/   40]   Loss 0.406379   Top1 89.870000   Top5 99.730000   BatchTime 0.093326   
2022-11-04 03:16:45,695 - INFO  - ==> Top1: 89.870    Top5: 99.730    Loss: 0.406

2022-11-04 03:16:45,718 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:16:45,719 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:16:45,719 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
2022-11-04 03:16:45,824 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:16:45,824 - INFO  - >>>>>>>> Epoch  22
2022-11-04 03:16:45,826 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:16:49,867 - INFO  - Training [22][   20/  196]   Loss 0.056018   Top1 97.910156   Top5 100.000000   BatchTime 0.202049   LR 0.010000   
2022-11-04 03:16:51,906 - INFO  - Training [22][   40/  196]   Loss 0.057177   Top1 97.900391   Top5 100.000000   BatchTime 0.152016   LR 0.010000   
2022-11-04 03:16:53,968 - INFO  - Training [22][   60/  196]   Loss 0.058288   Top1 97.955729   Top5 100.000000   BatchTime 0.135696   LR 0.010000   
2022-11-04 03:16:56,440 - INFO  - Training [22][   80/  196]   Loss 0.059909   Top1 97.841797   Top5 100.000000   BatchTime 0.132681   LR 0.010000   
2022-11-04 03:16:58,906 - INFO  - Training [22][  100/  196]   Loss 0.061113   Top1 97.792969   Top5 99.996094   BatchTime 0.130804   LR 0.010000   
2022-11-04 03:17:01,378 - INFO  - Training [22][  120/  196]   Loss 0.060816   Top1 97.822266   Top5 99.993490   BatchTime 0.129600   LR 0.010000   
2022-11-04 03:17:03,845 - INFO  - Training [22][  140/  196]   Loss 0.061146   Top1 97.829241   Top5 99.994420   BatchTime 0.128704   LR 0.010000   
2022-11-04 03:17:06,299 - INFO  - Training [22][  160/  196]   Loss 0.061524   Top1 97.824707   Top5 99.995117   BatchTime 0.127954   LR 0.010000   
2022-11-04 03:17:08,754 - INFO  - Training [22][  180/  196]   Loss 0.061930   Top1 97.816840   Top5 99.995660   BatchTime 0.127375   LR 0.010000   
2022-11-04 03:17:10,929 - INFO  - ==> Top1: 97.752    Top5: 99.996    Loss: 0.064

2022-11-04 03:17:10,930 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:17:13,775 - INFO  - Validation [22][   20/   40]   Loss 0.428081   Top1 89.472656   Top5 99.589844   BatchTime 0.142183   
2022-11-04 03:17:14,865 - INFO  - Validation [22][   40/   40]   Loss 0.410041   Top1 89.810000   Top5 99.680000   BatchTime 0.098351   
2022-11-04 03:17:15,118 - INFO  - ==> Top1: 89.810    Top5: 99.680    Loss: 0.410

2022-11-04 03:17:15,152 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:17:15,153 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:17:15,153 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
2022-11-04 03:17:15,253 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:17:15,254 - INFO  - >>>>>>>> Epoch  23
2022-11-04 03:17:15,255 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:17:19,650 - INFO  - Training [23][   20/  196]   Loss 0.064665   Top1 97.792969   Top5 99.980469   BatchTime 0.219723   LR 0.010000   
2022-11-04 03:17:22,126 - INFO  - Training [23][   40/  196]   Loss 0.064138   Top1 97.871094   Top5 99.990234   BatchTime 0.171760   LR 0.010000   
2022-11-04 03:17:24,598 - INFO  - Training [23][   60/  196]   Loss 0.061850   Top1 97.890625   Top5 99.993490   BatchTime 0.155714   LR 0.010000   
2022-11-04 03:17:27,075 - INFO  - Training [23][   80/  196]   Loss 0.063306   Top1 97.788086   Top5 99.990234   BatchTime 0.147738   LR 0.010000   
2022-11-04 03:17:29,544 - INFO  - Training [23][  100/  196]   Loss 0.065097   Top1 97.660156   Top5 99.992188   BatchTime 0.142880   LR 0.010000   
2022-11-04 03:17:32,022 - INFO  - Training [23][  120/  196]   Loss 0.064483   Top1 97.666016   Top5 99.993490   BatchTime 0.139723   LR 0.010000   
2022-11-04 03:17:34,488 - INFO  - Training [23][  140/  196]   Loss 0.064692   Top1 97.650670   Top5 99.994420   BatchTime 0.137372   LR 0.010000   
2022-11-04 03:17:36,946 - INFO  - Training [23][  160/  196]   Loss 0.063876   Top1 97.700195   Top5 99.995117   BatchTime 0.135565   LR 0.010000   
2022-11-04 03:17:39,231 - INFO  - Training [23][  180/  196]   Loss 0.064144   Top1 97.690972   Top5 99.995660   BatchTime 0.133195   LR 0.010000   
2022-11-04 03:17:40,879 - INFO  - ==> Top1: 97.672    Top5: 99.996    Loss: 0.064

2022-11-04 03:17:40,880 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:17:43,487 - INFO  - Validation [23][   20/   40]   Loss 0.437174   Top1 89.511719   Top5 99.628906   BatchTime 0.130298   
2022-11-04 03:17:44,171 - INFO  - Validation [23][   40/   40]   Loss 0.414496   Top1 89.690000   Top5 99.640000   BatchTime 0.082233   
2022-11-04 03:17:44,437 - INFO  - ==> Top1: 89.690    Top5: 99.640    Loss: 0.414

2022-11-04 03:17:44,462 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:17:44,463 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:17:44,463 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 89.960   Top5: 99.650] Sparsity : 0.892
2022-11-04 03:17:44,557 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:17:44,557 - INFO  - >>>>>>>> Epoch  24
2022-11-04 03:17:44,558 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:17:49,105 - INFO  - Training [24][   20/  196]   Loss 0.060908   Top1 97.812500   Top5 100.000000   BatchTime 0.227312   LR 0.010000   
2022-11-04 03:17:51,606 - INFO  - Training [24][   40/  196]   Loss 0.058685   Top1 97.919922   Top5 100.000000   BatchTime 0.176189   LR 0.010000   
2022-11-04 03:17:54,075 - INFO  - Training [24][   60/  196]   Loss 0.059720   Top1 97.916667   Top5 100.000000   BatchTime 0.158606   LR 0.010000   
2022-11-04 03:17:56,546 - INFO  - Training [24][   80/  196]   Loss 0.058762   Top1 97.939453   Top5 100.000000   BatchTime 0.149849   LR 0.010000   
2022-11-04 03:17:59,032 - INFO  - Training [24][  100/  196]   Loss 0.060288   Top1 97.878906   Top5 100.000000   BatchTime 0.144732   LR 0.010000   
2022-11-04 03:18:01,512 - INFO  - Training [24][  120/  196]   Loss 0.060532   Top1 97.851562   Top5 99.996745   BatchTime 0.141276   LR 0.010000   
2022-11-04 03:18:03,982 - INFO  - Training [24][  140/  196]   Loss 0.060222   Top1 97.862723   Top5 99.997210   BatchTime 0.138741   LR 0.010000   
2022-11-04 03:18:06,449 - INFO  - Training [24][  160/  196]   Loss 0.059964   Top1 97.875977   Top5 99.997559   BatchTime 0.136814   LR 0.010000   
2022-11-04 03:18:08,876 - INFO  - Training [24][  180/  196]   Loss 0.060194   Top1 97.875434   Top5 99.997830   BatchTime 0.135097   LR 0.010000   
2022-11-04 03:18:11,061 - INFO  - ==> Top1: 97.874    Top5: 99.998    Loss: 0.060

2022-11-04 03:18:11,062 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:18:13,933 - INFO  - Validation [24][   20/   40]   Loss 0.417285   Top1 90.058594   Top5 99.628906   BatchTime 0.143485   
2022-11-04 03:18:15,026 - INFO  - Validation [24][   40/   40]   Loss 0.406834   Top1 89.990000   Top5 99.640000   BatchTime 0.099074   
2022-11-04 03:18:15,295 - INFO  - ==> Top1: 89.990    Top5: 99.640    Loss: 0.407

2022-11-04 03:18:15,337 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:18:15,338 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:18:15,338 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:18:15,440 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:18:15,441 - INFO  - >>>>>>>> Epoch  25
2022-11-04 03:18:15,442 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:18:19,843 - INFO  - Training [25][   20/  196]   Loss 0.059390   Top1 98.046875   Top5 100.000000   BatchTime 0.220050   LR 0.010000   
2022-11-04 03:18:22,320 - INFO  - Training [25][   40/  196]   Loss 0.058792   Top1 98.037109   Top5 100.000000   BatchTime 0.171944   LR 0.010000   
2022-11-04 03:18:24,782 - INFO  - Training [25][   60/  196]   Loss 0.058380   Top1 98.053385   Top5 99.993490   BatchTime 0.155665   LR 0.010000   
2022-11-04 03:18:27,237 - INFO  - Training [25][   80/  196]   Loss 0.058401   Top1 98.061523   Top5 99.995117   BatchTime 0.147434   LR 0.010000   
2022-11-04 03:18:29,694 - INFO  - Training [25][  100/  196]   Loss 0.058842   Top1 98.015625   Top5 99.996094   BatchTime 0.142520   LR 0.010000   
2022-11-04 03:18:31,801 - INFO  - Training [25][  120/  196]   Loss 0.059417   Top1 97.978516   Top5 99.996745   BatchTime 0.136322   LR 0.010000   
2022-11-04 03:18:33,732 - INFO  - Training [25][  140/  196]   Loss 0.059140   Top1 97.960379   Top5 99.997210   BatchTime 0.130644   LR 0.010000   
2022-11-04 03:18:35,736 - INFO  - Training [25][  160/  196]   Loss 0.059538   Top1 97.929688   Top5 99.997559   BatchTime 0.126835   LR 0.010000   
2022-11-04 03:18:37,738 - INFO  - Training [25][  180/  196]   Loss 0.060028   Top1 97.899306   Top5 99.997830   BatchTime 0.123866   LR 0.010000   
2022-11-04 03:18:39,410 - INFO  - ==> Top1: 97.882    Top5: 99.998    Loss: 0.061

2022-11-04 03:18:39,411 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:18:42,378 - INFO  - Validation [25][   20/   40]   Loss 0.424810   Top1 89.785156   Top5 99.609375   BatchTime 0.148293   
2022-11-04 03:18:43,503 - INFO  - Validation [25][   40/   40]   Loss 0.412109   Top1 89.950000   Top5 99.630000   BatchTime 0.102263   
2022-11-04 03:18:43,755 - INFO  - ==> Top1: 89.950    Top5: 99.630    Loss: 0.412

2022-11-04 03:18:43,787 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:18:43,787 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:18:43,787 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:18:43,888 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:18:43,888 - INFO  - >>>>>>>> Epoch  26
2022-11-04 03:18:43,889 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:18:48,303 - INFO  - Training [26][   20/  196]   Loss 0.053987   Top1 98.066406   Top5 100.000000   BatchTime 0.220679   LR 0.010000   
2022-11-04 03:18:50,780 - INFO  - Training [26][   40/  196]   Loss 0.057193   Top1 97.900391   Top5 100.000000   BatchTime 0.172266   LR 0.010000   
2022-11-04 03:18:53,266 - INFO  - Training [26][   60/  196]   Loss 0.056624   Top1 97.936198   Top5 99.986979   BatchTime 0.156268   LR 0.010000   
2022-11-04 03:18:55,743 - INFO  - Training [26][   80/  196]   Loss 0.059507   Top1 97.783203   Top5 99.985352   BatchTime 0.148169   LR 0.010000   
2022-11-04 03:18:58,315 - INFO  - Training [26][  100/  196]   Loss 0.059979   Top1 97.781250   Top5 99.988281   BatchTime 0.144249   LR 0.010000   
2022-11-04 03:19:00,780 - INFO  - Training [26][  120/  196]   Loss 0.060862   Top1 97.776693   Top5 99.990234   BatchTime 0.140749   LR 0.010000   
2022-11-04 03:19:03,253 - INFO  - Training [26][  140/  196]   Loss 0.060948   Top1 97.804129   Top5 99.991629   BatchTime 0.138312   LR 0.010000   
2022-11-04 03:19:05,709 - INFO  - Training [26][  160/  196]   Loss 0.060864   Top1 97.790527   Top5 99.992676   BatchTime 0.136368   LR 0.010000   
2022-11-04 03:19:08,160 - INFO  - Training [26][  180/  196]   Loss 0.062478   Top1 97.719184   Top5 99.993490   BatchTime 0.134833   LR 0.010000   
2022-11-04 03:19:10,336 - INFO  - ==> Top1: 97.698    Top5: 99.994    Loss: 0.063

2022-11-04 03:19:10,337 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:19:13,213 - INFO  - Validation [26][   20/   40]   Loss 0.423916   Top1 89.453125   Top5 99.531250   BatchTime 0.143723   
2022-11-04 03:19:14,310 - INFO  - Validation [26][   40/   40]   Loss 0.420057   Top1 89.640000   Top5 99.570000   BatchTime 0.099296   
2022-11-04 03:19:14,572 - INFO  - ==> Top1: 89.640    Top5: 99.570    Loss: 0.420

2022-11-04 03:19:14,618 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:19:14,618 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:19:14,618 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:19:14,724 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:19:14,724 - INFO  - >>>>>>>> Epoch  27
2022-11-04 03:19:14,725 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:19:19,112 - INFO  - Training [27][   20/  196]   Loss 0.062545   Top1 97.675781   Top5 100.000000   BatchTime 0.219330   LR 0.010000   
2022-11-04 03:19:21,572 - INFO  - Training [27][   40/  196]   Loss 0.058296   Top1 97.910156   Top5 100.000000   BatchTime 0.171150   LR 0.010000   
2022-11-04 03:19:23,983 - INFO  - Training [27][   60/  196]   Loss 0.060039   Top1 97.858073   Top5 100.000000   BatchTime 0.154280   LR 0.010000   
2022-11-04 03:19:25,753 - INFO  - Training [27][   80/  196]   Loss 0.060697   Top1 97.875977   Top5 100.000000   BatchTime 0.137834   LR 0.010000   
2022-11-04 03:19:27,792 - INFO  - Training [27][  100/  196]   Loss 0.060110   Top1 97.851562   Top5 100.000000   BatchTime 0.130657   LR 0.010000   
2022-11-04 03:19:29,811 - INFO  - Training [27][  120/  196]   Loss 0.060935   Top1 97.828776   Top5 100.000000   BatchTime 0.125712   LR 0.010000   
2022-11-04 03:19:31,736 - INFO  - Training [27][  140/  196]   Loss 0.060973   Top1 97.826451   Top5 100.000000   BatchTime 0.121498   LR 0.010000   
2022-11-04 03:19:33,717 - INFO  - Training [27][  160/  196]   Loss 0.061907   Top1 97.792969   Top5 99.995117   BatchTime 0.118690   LR 0.010000   
2022-11-04 03:19:36,180 - INFO  - Training [27][  180/  196]   Loss 0.061483   Top1 97.808160   Top5 99.995660   BatchTime 0.119188   LR 0.010000   
2022-11-04 03:19:38,345 - INFO  - ==> Top1: 97.796    Top5: 99.996    Loss: 0.062

2022-11-04 03:19:38,345 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:19:41,259 - INFO  - Validation [27][   20/   40]   Loss 0.450972   Top1 89.492188   Top5 99.609375   BatchTime 0.145653   
2022-11-04 03:19:42,363 - INFO  - Validation [27][   40/   40]   Loss 0.427793   Top1 89.870000   Top5 99.660000   BatchTime 0.100426   
2022-11-04 03:19:42,604 - INFO  - ==> Top1: 89.870    Top5: 99.660    Loss: 0.428

2022-11-04 03:19:42,641 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:19:42,642 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:19:42,642 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:19:42,746 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:19:42,746 - INFO  - >>>>>>>> Epoch  28
2022-11-04 03:19:42,748 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:19:47,148 - INFO  - Training [28][   20/  196]   Loss 0.059305   Top1 97.753906   Top5 100.000000   BatchTime 0.220018   LR 0.010000   
2022-11-04 03:19:49,620 - INFO  - Training [28][   40/  196]   Loss 0.057830   Top1 97.890625   Top5 100.000000   BatchTime 0.171815   LR 0.010000   
2022-11-04 03:19:52,086 - INFO  - Training [28][   60/  196]   Loss 0.057304   Top1 97.884115   Top5 100.000000   BatchTime 0.155628   LR 0.010000   
2022-11-04 03:19:54,548 - INFO  - Training [28][   80/  196]   Loss 0.057542   Top1 97.890625   Top5 100.000000   BatchTime 0.147504   LR 0.010000   
2022-11-04 03:19:57,030 - INFO  - Training [28][  100/  196]   Loss 0.057349   Top1 97.945312   Top5 100.000000   BatchTime 0.142817   LR 0.010000   
2022-11-04 03:19:59,464 - INFO  - Training [28][  120/  196]   Loss 0.057434   Top1 97.939453   Top5 99.996745   BatchTime 0.139300   LR 0.010000   
2022-11-04 03:20:01,935 - INFO  - Training [28][  140/  196]   Loss 0.057864   Top1 97.887835   Top5 99.997210   BatchTime 0.137046   LR 0.010000   
2022-11-04 03:20:04,386 - INFO  - Training [28][  160/  196]   Loss 0.058549   Top1 97.875977   Top5 99.997559   BatchTime 0.135238   LR 0.010000   
2022-11-04 03:20:06,847 - INFO  - Training [28][  180/  196]   Loss 0.059209   Top1 97.829861   Top5 99.997830   BatchTime 0.133880   LR 0.010000   
2022-11-04 03:20:09,024 - INFO  - ==> Top1: 97.788    Top5: 99.998    Loss: 0.060

2022-11-04 03:20:09,025 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:20:11,932 - INFO  - Validation [28][   20/   40]   Loss 0.453962   Top1 89.531250   Top5 99.628906   BatchTime 0.145297   
2022-11-04 03:20:13,057 - INFO  - Validation [28][   40/   40]   Loss 0.431439   Top1 89.720000   Top5 99.700000   BatchTime 0.100767   
2022-11-04 03:20:13,305 - INFO  - ==> Top1: 89.720    Top5: 99.700    Loss: 0.431

2022-11-04 03:20:13,337 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:20:13,338 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:20:13,338 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:20:13,433 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:20:13,433 - INFO  - >>>>>>>> Epoch  29
2022-11-04 03:20:13,434 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:20:17,275 - INFO  - Training [29][   20/  196]   Loss 0.050679   Top1 98.203125   Top5 100.000000   BatchTime 0.192034   LR 0.010000   
2022-11-04 03:20:19,299 - INFO  - Training [29][   40/  196]   Loss 0.052193   Top1 98.125000   Top5 100.000000   BatchTime 0.146632   LR 0.010000   
2022-11-04 03:20:21,362 - INFO  - Training [29][   60/  196]   Loss 0.052748   Top1 98.125000   Top5 100.000000   BatchTime 0.132135   LR 0.010000   
2022-11-04 03:20:23,406 - INFO  - Training [29][   80/  196]   Loss 0.054038   Top1 98.032227   Top5 100.000000   BatchTime 0.124652   LR 0.010000   
2022-11-04 03:20:25,273 - INFO  - Training [29][  100/  196]   Loss 0.055197   Top1 97.992188   Top5 99.996094   BatchTime 0.118385   LR 0.010000   
2022-11-04 03:20:27,736 - INFO  - Training [29][  120/  196]   Loss 0.055933   Top1 97.962240   Top5 99.993490   BatchTime 0.119183   LR 0.010000   
2022-11-04 03:20:30,204 - INFO  - Training [29][  140/  196]   Loss 0.055964   Top1 97.968750   Top5 99.988839   BatchTime 0.119781   LR 0.010000   
2022-11-04 03:20:32,666 - INFO  - Training [29][  160/  196]   Loss 0.055872   Top1 97.983398   Top5 99.990234   BatchTime 0.120199   LR 0.010000   
2022-11-04 03:20:35,123 - INFO  - Training [29][  180/  196]   Loss 0.056293   Top1 97.977431   Top5 99.991319   BatchTime 0.120492   LR 0.010000   
2022-11-04 03:20:37,290 - INFO  - ==> Top1: 97.970    Top5: 99.990    Loss: 0.057

2022-11-04 03:20:37,291 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:20:40,174 - INFO  - Validation [29][   20/   40]   Loss 0.461514   Top1 89.511719   Top5 99.550781   BatchTime 0.144141   
2022-11-04 03:20:41,272 - INFO  - Validation [29][   40/   40]   Loss 0.442576   Top1 89.740000   Top5 99.620000   BatchTime 0.099516   
2022-11-04 03:20:41,543 - INFO  - ==> Top1: 89.740    Top5: 99.620    Loss: 0.443

2022-11-04 03:20:41,573 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:20:41,574 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:20:41,574 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.990   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:20:41,676 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:20:41,676 - INFO  - >>>>>>>> Epoch  30
2022-11-04 03:20:41,677 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:20:46,069 - INFO  - Training [30][   20/  196]   Loss 0.059238   Top1 98.066406   Top5 100.000000   BatchTime 0.219608   LR 0.001000   
2022-11-04 03:20:48,522 - INFO  - Training [30][   40/  196]   Loss 0.053937   Top1 98.173828   Top5 99.990234   BatchTime 0.171121   LR 0.001000   
2022-11-04 03:20:50,996 - INFO  - Training [30][   60/  196]   Loss 0.052449   Top1 98.248698   Top5 99.993490   BatchTime 0.155318   LR 0.001000   
2022-11-04 03:20:53,473 - INFO  - Training [30][   80/  196]   Loss 0.052623   Top1 98.168945   Top5 99.995117   BatchTime 0.147452   LR 0.001000   
2022-11-04 03:20:55,946 - INFO  - Training [30][  100/  196]   Loss 0.052886   Top1 98.140625   Top5 99.988281   BatchTime 0.142683   LR 0.001000   
2022-11-04 03:20:58,410 - INFO  - Training [30][  120/  196]   Loss 0.052745   Top1 98.147786   Top5 99.990234   BatchTime 0.139439   LR 0.001000   
2022-11-04 03:21:00,864 - INFO  - Training [30][  140/  196]   Loss 0.052230   Top1 98.144531   Top5 99.991629   BatchTime 0.137050   LR 0.001000   
2022-11-04 03:21:03,319 - INFO  - Training [30][  160/  196]   Loss 0.052308   Top1 98.159180   Top5 99.992676   BatchTime 0.135258   LR 0.001000   
2022-11-04 03:21:05,851 - INFO  - Training [30][  180/  196]   Loss 0.052916   Top1 98.142361   Top5 99.993490   BatchTime 0.134299   LR 0.001000   
2022-11-04 03:21:08,016 - INFO  - ==> Top1: 98.166    Top5: 99.994    Loss: 0.053

2022-11-04 03:21:08,017 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:21:10,627 - INFO  - Validation [30][   20/   40]   Loss 0.423754   Top1 89.902344   Top5 99.628906   BatchTime 0.130475   
2022-11-04 03:21:11,312 - INFO  - Validation [30][   40/   40]   Loss 0.411422   Top1 90.090000   Top5 99.680000   BatchTime 0.082369   
2022-11-04 03:21:11,576 - INFO  - ==> Top1: 90.090    Top5: 99.680    Loss: 0.411

2022-11-04 03:21:11,599 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.090   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:21:11,600 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:21:11,600 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 90.030   Top5: 99.720] Sparsity : 0.892
2022-11-04 03:21:11,810 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:21:11,979 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:21:11,979 - INFO  - >>>>>>>> Epoch  31
2022-11-04 03:21:11,980 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:21:15,830 - INFO  - Training [31][   20/  196]   Loss 0.050303   Top1 98.300781   Top5 100.000000   BatchTime 0.192455   LR 0.001000   
2022-11-04 03:21:18,041 - INFO  - Training [31][   40/  196]   Loss 0.051166   Top1 98.193359   Top5 100.000000   BatchTime 0.151502   LR 0.001000   
2022-11-04 03:21:20,530 - INFO  - Training [31][   60/  196]   Loss 0.050360   Top1 98.209635   Top5 100.000000   BatchTime 0.142493   LR 0.001000   
2022-11-04 03:21:23,000 - INFO  - Training [31][   80/  196]   Loss 0.050710   Top1 98.139648   Top5 100.000000   BatchTime 0.137746   LR 0.001000   
2022-11-04 03:21:25,466 - INFO  - Training [31][  100/  196]   Loss 0.051184   Top1 98.132812   Top5 100.000000   BatchTime 0.134851   LR 0.001000   
2022-11-04 03:21:27,944 - INFO  - Training [31][  120/  196]   Loss 0.050325   Top1 98.186849   Top5 100.000000   BatchTime 0.133023   LR 0.001000   
2022-11-04 03:21:30,419 - INFO  - Training [31][  140/  196]   Loss 0.049665   Top1 98.214286   Top5 100.000000   BatchTime 0.131700   LR 0.001000   
2022-11-04 03:21:32,878 - INFO  - Training [31][  160/  196]   Loss 0.049580   Top1 98.234863   Top5 100.000000   BatchTime 0.130607   LR 0.001000   
2022-11-04 03:21:35,363 - INFO  - Training [31][  180/  196]   Loss 0.049717   Top1 98.229167   Top5 100.000000   BatchTime 0.129900   LR 0.001000   
2022-11-04 03:21:37,531 - INFO  - ==> Top1: 98.234    Top5: 100.000    Loss: 0.049

2022-11-04 03:21:37,532 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:21:40,383 - INFO  - Validation [31][   20/   40]   Loss 0.419674   Top1 89.902344   Top5 99.609375   BatchTime 0.142516   
2022-11-04 03:21:41,533 - INFO  - Validation [31][   40/   40]   Loss 0.406517   Top1 90.160000   Top5 99.630000   BatchTime 0.100020   
2022-11-04 03:21:41,794 - INFO  - ==> Top1: 90.160    Top5: 99.630    Loss: 0.407

2022-11-04 03:21:41,823 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
2022-11-04 03:21:41,824 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.090   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:21:41,824 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.090   Top5: 99.640] Sparsity : 0.892
2022-11-04 03:21:41,985 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:21:42,130 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:21:42,131 - INFO  - >>>>>>>> Epoch  32
2022-11-04 03:21:42,131 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:21:46,517 - INFO  - Training [32][   20/  196]   Loss 0.041048   Top1 98.476562   Top5 100.000000   BatchTime 0.219275   LR 0.001000   
2022-11-04 03:21:48,960 - INFO  - Training [32][   40/  196]   Loss 0.042237   Top1 98.515625   Top5 100.000000   BatchTime 0.170717   LR 0.001000   
2022-11-04 03:21:51,424 - INFO  - Training [32][   60/  196]   Loss 0.043724   Top1 98.457031   Top5 100.000000   BatchTime 0.154876   LR 0.001000   
2022-11-04 03:21:53,895 - INFO  - Training [32][   80/  196]   Loss 0.044337   Top1 98.457031   Top5 100.000000   BatchTime 0.147034   LR 0.001000   
2022-11-04 03:21:56,348 - INFO  - Training [32][  100/  196]   Loss 0.045031   Top1 98.429688   Top5 99.996094   BatchTime 0.142166   LR 0.001000   
2022-11-04 03:21:58,806 - INFO  - Training [32][  120/  196]   Loss 0.045222   Top1 98.450521   Top5 99.996745   BatchTime 0.138952   LR 0.001000   
2022-11-04 03:22:01,263 - INFO  - Training [32][  140/  196]   Loss 0.045821   Top1 98.404018   Top5 99.997210   BatchTime 0.136652   LR 0.001000   
2022-11-04 03:22:03,314 - INFO  - Training [32][  160/  196]   Loss 0.046758   Top1 98.388672   Top5 99.997559   BatchTime 0.132390   LR 0.001000   
2022-11-04 03:22:05,222 - INFO  - Training [32][  180/  196]   Loss 0.046925   Top1 98.398438   Top5 99.997830   BatchTime 0.128276   LR 0.001000   
2022-11-04 03:22:07,043 - INFO  - ==> Top1: 98.390    Top5: 99.998    Loss: 0.047

2022-11-04 03:22:07,044 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:22:09,614 - INFO  - Validation [32][   20/   40]   Loss 0.418308   Top1 89.707031   Top5 99.707031   BatchTime 0.128451   
2022-11-04 03:22:10,529 - INFO  - Validation [32][   40/   40]   Loss 0.406254   Top1 90.100000   Top5 99.670000   BatchTime 0.087103   
2022-11-04 03:22:10,797 - INFO  - ==> Top1: 90.100    Top5: 99.670    Loss: 0.406

2022-11-04 03:22:10,837 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
2022-11-04 03:22:10,837 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 90.100   Top5: 99.670] Sparsity : 0.892
2022-11-04 03:22:10,838 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.090   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:22:10,940 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:22:10,940 - INFO  - >>>>>>>> Epoch  33
2022-11-04 03:22:10,942 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:22:15,363 - INFO  - Training [33][   20/  196]   Loss 0.039259   Top1 98.710938   Top5 100.000000   BatchTime 0.221045   LR 0.001000   
2022-11-04 03:22:17,832 - INFO  - Training [33][   40/  196]   Loss 0.042104   Top1 98.603516   Top5 100.000000   BatchTime 0.172258   LR 0.001000   
2022-11-04 03:22:20,295 - INFO  - Training [33][   60/  196]   Loss 0.042349   Top1 98.619792   Top5 100.000000   BatchTime 0.155879   LR 0.001000   
2022-11-04 03:22:22,761 - INFO  - Training [33][   80/  196]   Loss 0.044371   Top1 98.540039   Top5 100.000000   BatchTime 0.147739   LR 0.001000   
2022-11-04 03:22:25,230 - INFO  - Training [33][  100/  196]   Loss 0.044472   Top1 98.507812   Top5 100.000000   BatchTime 0.142876   LR 0.001000   
2022-11-04 03:22:27,702 - INFO  - Training [33][  120/  196]   Loss 0.044761   Top1 98.463542   Top5 100.000000   BatchTime 0.139668   LR 0.001000   
2022-11-04 03:22:30,182 - INFO  - Training [33][  140/  196]   Loss 0.044607   Top1 98.473772   Top5 100.000000   BatchTime 0.137425   LR 0.001000   
2022-11-04 03:22:32,635 - INFO  - Training [33][  160/  196]   Loss 0.044689   Top1 98.471680   Top5 100.000000   BatchTime 0.135583   LR 0.001000   
2022-11-04 03:22:35,100 - INFO  - Training [33][  180/  196]   Loss 0.045721   Top1 98.428819   Top5 100.000000   BatchTime 0.134209   LR 0.001000   
2022-11-04 03:22:37,275 - INFO  - ==> Top1: 98.424    Top5: 100.000    Loss: 0.046

2022-11-04 03:22:37,276 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:22:40,128 - INFO  - Validation [33][   20/   40]   Loss 0.408693   Top1 90.253906   Top5 99.667969   BatchTime 0.142540   
2022-11-04 03:22:41,235 - INFO  - Validation [33][   40/   40]   Loss 0.399583   Top1 90.470000   Top5 99.700000   BatchTime 0.098931   
2022-11-04 03:22:41,494 - INFO  - ==> Top1: 90.470    Top5: 99.700    Loss: 0.400

2022-11-04 03:22:41,538 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:22:41,539 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
2022-11-04 03:22:41,539 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.100   Top5: 99.670] Sparsity : 0.892
2022-11-04 03:22:41,733 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:22:41,908 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:22:41,908 - INFO  - >>>>>>>> Epoch  34
2022-11-04 03:22:41,909 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:22:46,282 - INFO  - Training [34][   20/  196]   Loss 0.037296   Top1 98.730469   Top5 99.980469   BatchTime 0.218646   LR 0.001000   
2022-11-04 03:22:48,743 - INFO  - Training [34][   40/  196]   Loss 0.042600   Top1 98.593750   Top5 99.990234   BatchTime 0.170837   LR 0.001000   
2022-11-04 03:22:51,215 - INFO  - Training [34][   60/  196]   Loss 0.041961   Top1 98.606771   Top5 99.993490   BatchTime 0.155095   LR 0.001000   
2022-11-04 03:22:53,675 - INFO  - Training [34][   80/  196]   Loss 0.041470   Top1 98.623047   Top5 99.995117   BatchTime 0.147072   LR 0.001000   
2022-11-04 03:22:55,746 - INFO  - Training [34][  100/  196]   Loss 0.042587   Top1 98.562500   Top5 99.996094   BatchTime 0.138366   LR 0.001000   
2022-11-04 03:22:57,695 - INFO  - Training [34][  120/  196]   Loss 0.042989   Top1 98.531901   Top5 99.996745   BatchTime 0.131549   LR 0.001000   
2022-11-04 03:22:59,841 - INFO  - Training [34][  140/  196]   Loss 0.044086   Top1 98.484933   Top5 99.997210   BatchTime 0.128083   LR 0.001000   
2022-11-04 03:23:01,927 - INFO  - Training [34][  160/  196]   Loss 0.044347   Top1 98.454590   Top5 99.997559   BatchTime 0.125107   LR 0.001000   
2022-11-04 03:23:03,584 - INFO  - Training [34][  180/  196]   Loss 0.045079   Top1 98.448351   Top5 99.997830   BatchTime 0.120414   LR 0.001000   
2022-11-04 03:23:05,831 - INFO  - ==> Top1: 98.446    Top5: 99.998    Loss: 0.045

2022-11-04 03:23:05,831 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:23:08,711 - INFO  - Validation [34][   20/   40]   Loss 0.424013   Top1 89.941406   Top5 99.667969   BatchTime 0.143891   
2022-11-04 03:23:09,800 - INFO  - Validation [34][   40/   40]   Loss 0.410851   Top1 90.170000   Top5 99.680000   BatchTime 0.099161   
2022-11-04 03:23:10,053 - INFO  - ==> Top1: 90.170    Top5: 99.680    Loss: 0.411

2022-11-04 03:23:10,083 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:23:10,084 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 90.170   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:23:10,084 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.160   Top5: 99.630] Sparsity : 0.892
2022-11-04 03:23:10,194 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:23:10,194 - INFO  - >>>>>>>> Epoch  35
2022-11-04 03:23:10,196 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:23:14,579 - INFO  - Training [35][   20/  196]   Loss 0.037425   Top1 98.828125   Top5 100.000000   BatchTime 0.219163   LR 0.001000   
2022-11-04 03:23:17,058 - INFO  - Training [35][   40/  196]   Loss 0.039792   Top1 98.710938   Top5 100.000000   BatchTime 0.171548   LR 0.001000   
2022-11-04 03:23:19,538 - INFO  - Training [35][   60/  196]   Loss 0.042508   Top1 98.515625   Top5 100.000000   BatchTime 0.155696   LR 0.001000   
2022-11-04 03:23:22,028 - INFO  - Training [35][   80/  196]   Loss 0.041944   Top1 98.549805   Top5 100.000000   BatchTime 0.147903   LR 0.001000   
2022-11-04 03:23:24,499 - INFO  - Training [35][  100/  196]   Loss 0.042336   Top1 98.546875   Top5 99.996094   BatchTime 0.143025   LR 0.001000   
2022-11-04 03:23:26,964 - INFO  - Training [35][  120/  196]   Loss 0.042990   Top1 98.525391   Top5 99.996745   BatchTime 0.139730   LR 0.001000   
2022-11-04 03:23:29,424 - INFO  - Training [35][  140/  196]   Loss 0.043449   Top1 98.507254   Top5 99.997210   BatchTime 0.137340   LR 0.001000   
2022-11-04 03:23:31,880 - INFO  - Training [35][  160/  196]   Loss 0.043770   Top1 98.488770   Top5 99.992676   BatchTime 0.135526   LR 0.001000   
2022-11-04 03:23:34,340 - INFO  - Training [35][  180/  196]   Loss 0.043822   Top1 98.489583   Top5 99.993490   BatchTime 0.134131   LR 0.001000   
2022-11-04 03:23:36,505 - INFO  - ==> Top1: 98.490    Top5: 99.994    Loss: 0.044

2022-11-04 03:23:36,506 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:23:39,391 - INFO  - Validation [35][   20/   40]   Loss 0.413152   Top1 90.058594   Top5 99.628906   BatchTime 0.144233   
2022-11-04 03:23:40,502 - INFO  - Validation [35][   40/   40]   Loss 0.402102   Top1 90.320000   Top5 99.690000   BatchTime 0.099876   
2022-11-04 03:23:40,754 - INFO  - ==> Top1: 90.320    Top5: 99.690    Loss: 0.402

2022-11-04 03:23:40,785 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:23:40,786 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
2022-11-04 03:23:40,786 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.170   Top5: 99.680] Sparsity : 0.892
2022-11-04 03:23:40,910 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:23:40,910 - INFO  - >>>>>>>> Epoch  36
2022-11-04 03:23:40,912 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:23:45,319 - INFO  - Training [36][   20/  196]   Loss 0.045218   Top1 98.320312   Top5 100.000000   BatchTime 0.220342   LR 0.001000   
2022-11-04 03:23:47,556 - INFO  - Training [36][   40/  196]   Loss 0.042566   Top1 98.457031   Top5 100.000000   BatchTime 0.166098   LR 0.001000   
2022-11-04 03:23:49,462 - INFO  - Training [36][   60/  196]   Loss 0.042857   Top1 98.509115   Top5 100.000000   BatchTime 0.142496   LR 0.001000   
2022-11-04 03:23:51,480 - INFO  - Training [36][   80/  196]   Loss 0.042657   Top1 98.530273   Top5 100.000000   BatchTime 0.132101   LR 0.001000   
2022-11-04 03:23:53,514 - INFO  - Training [36][  100/  196]   Loss 0.042230   Top1 98.527344   Top5 100.000000   BatchTime 0.126016   LR 0.001000   
2022-11-04 03:23:55,361 - INFO  - Training [36][  120/  196]   Loss 0.043805   Top1 98.479818   Top5 100.000000   BatchTime 0.120406   LR 0.001000   
2022-11-04 03:23:57,602 - INFO  - Training [36][  140/  196]   Loss 0.043571   Top1 98.493304   Top5 100.000000   BatchTime 0.119213   LR 0.001000   
2022-11-04 03:24:00,060 - INFO  - Training [36][  160/  196]   Loss 0.043831   Top1 98.481445   Top5 100.000000   BatchTime 0.119670   LR 0.001000   
2022-11-04 03:24:02,517 - INFO  - Training [36][  180/  196]   Loss 0.043794   Top1 98.472222   Top5 100.000000   BatchTime 0.120027   LR 0.001000   
2022-11-04 03:24:04,696 - INFO  - ==> Top1: 98.460    Top5: 100.000    Loss: 0.044

2022-11-04 03:24:04,697 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:24:07,569 - INFO  - Validation [36][   20/   40]   Loss 0.422426   Top1 90.078125   Top5 99.628906   BatchTime 0.143541   
2022-11-04 03:24:08,662 - INFO  - Validation [36][   40/   40]   Loss 0.406728   Top1 90.300000   Top5 99.650000   BatchTime 0.099081   
2022-11-04 03:24:08,923 - INFO  - ==> Top1: 90.300    Top5: 99.650    Loss: 0.407

2022-11-04 03:24:08,962 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:24:08,962 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
2022-11-04 03:24:08,962 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 90.300   Top5: 99.650] Sparsity : 0.892
2022-11-04 03:24:09,052 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:24:09,053 - INFO  - >>>>>>>> Epoch  37
2022-11-04 03:24:09,054 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:24:13,462 - INFO  - Training [37][   20/  196]   Loss 0.045928   Top1 98.437500   Top5 100.000000   BatchTime 0.220391   LR 0.001000   
2022-11-04 03:24:15,931 - INFO  - Training [37][   40/  196]   Loss 0.043530   Top1 98.466797   Top5 100.000000   BatchTime 0.171932   LR 0.001000   
2022-11-04 03:24:18,416 - INFO  - Training [37][   60/  196]   Loss 0.043970   Top1 98.463542   Top5 100.000000   BatchTime 0.156035   LR 0.001000   
2022-11-04 03:24:20,888 - INFO  - Training [37][   80/  196]   Loss 0.044302   Top1 98.481445   Top5 100.000000   BatchTime 0.147923   LR 0.001000   
2022-11-04 03:24:23,359 - INFO  - Training [37][  100/  196]   Loss 0.043707   Top1 98.492188   Top5 100.000000   BatchTime 0.143052   LR 0.001000   
2022-11-04 03:24:25,838 - INFO  - Training [37][  120/  196]   Loss 0.043380   Top1 98.499349   Top5 100.000000   BatchTime 0.139866   LR 0.001000   
2022-11-04 03:24:28,301 - INFO  - Training [37][  140/  196]   Loss 0.043440   Top1 98.515625   Top5 99.997210   BatchTime 0.137479   LR 0.001000   
2022-11-04 03:24:30,759 - INFO  - Training [37][  160/  196]   Loss 0.044152   Top1 98.505859   Top5 99.997559   BatchTime 0.135655   LR 0.001000   
2022-11-04 03:24:33,213 - INFO  - Training [37][  180/  196]   Loss 0.044338   Top1 98.504774   Top5 99.997830   BatchTime 0.134217   LR 0.001000   
2022-11-04 03:24:35,371 - INFO  - ==> Top1: 98.472    Top5: 99.996    Loss: 0.045

2022-11-04 03:24:35,371 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:24:38,234 - INFO  - Validation [37][   20/   40]   Loss 0.413926   Top1 90.351562   Top5 99.589844   BatchTime 0.143104   
2022-11-04 03:24:39,353 - INFO  - Validation [37][   40/   40]   Loss 0.402404   Top1 90.300000   Top5 99.640000   BatchTime 0.099527   
2022-11-04 03:24:39,599 - INFO  - ==> Top1: 90.300    Top5: 99.640    Loss: 0.402

2022-11-04 03:24:39,628 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:24:39,629 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
2022-11-04 03:24:39,629 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 90.300   Top5: 99.650] Sparsity : 0.892
2022-11-04 03:24:39,740 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:24:39,740 - INFO  - >>>>>>>> Epoch  38
2022-11-04 03:24:39,742 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:24:43,972 - INFO  - Training [38][   20/  196]   Loss 0.044806   Top1 98.437500   Top5 100.000000   BatchTime 0.211523   LR 0.001000   
2022-11-04 03:24:46,007 - INFO  - Training [38][   40/  196]   Loss 0.045014   Top1 98.417969   Top5 100.000000   BatchTime 0.156632   LR 0.001000   
2022-11-04 03:24:48,013 - INFO  - Training [38][   60/  196]   Loss 0.044852   Top1 98.385417   Top5 100.000000   BatchTime 0.137857   LR 0.001000   
2022-11-04 03:24:50,024 - INFO  - Training [38][   80/  196]   Loss 0.045477   Top1 98.359375   Top5 100.000000   BatchTime 0.128528   LR 0.001000   
2022-11-04 03:24:52,504 - INFO  - Training [38][  100/  196]   Loss 0.045432   Top1 98.378906   Top5 100.000000   BatchTime 0.127617   LR 0.001000   
2022-11-04 03:24:54,982 - INFO  - Training [38][  120/  196]   Loss 0.045291   Top1 98.362630   Top5 100.000000   BatchTime 0.126998   LR 0.001000   
2022-11-04 03:24:57,445 - INFO  - Training [38][  140/  196]   Loss 0.045400   Top1 98.362165   Top5 99.997210   BatchTime 0.126446   LR 0.001000   
2022-11-04 03:24:59,912 - INFO  - Training [38][  160/  196]   Loss 0.045376   Top1 98.344727   Top5 99.997559   BatchTime 0.126061   LR 0.001000   
2022-11-04 03:25:02,508 - INFO  - Training [38][  180/  196]   Loss 0.045017   Top1 98.357205   Top5 99.997830   BatchTime 0.126474   LR 0.001000   
2022-11-04 03:25:04,702 - INFO  - ==> Top1: 98.388    Top5: 99.998    Loss: 0.045

2022-11-04 03:25:04,703 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:25:07,572 - INFO  - Validation [38][   20/   40]   Loss 0.413021   Top1 90.429688   Top5 99.570312   BatchTime 0.143345   
2022-11-04 03:25:08,695 - INFO  - Validation [38][   40/   40]   Loss 0.403527   Top1 90.500000   Top5 99.660000   BatchTime 0.099755   
2022-11-04 03:25:08,953 - INFO  - ==> Top1: 90.500    Top5: 99.660    Loss: 0.404

2022-11-04 03:25:08,983 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:25:08,984 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:25:08,984 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.320   Top5: 99.690] Sparsity : 0.892
2022-11-04 03:25:09,188 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:25:09,354 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:25:09,354 - INFO  - >>>>>>>> Epoch  39
2022-11-04 03:25:09,355 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:25:13,733 - INFO  - Training [39][   20/  196]   Loss 0.038176   Top1 98.652344   Top5 100.000000   BatchTime 0.218877   LR 0.001000   
2022-11-04 03:25:16,189 - INFO  - Training [39][   40/  196]   Loss 0.041369   Top1 98.496094   Top5 100.000000   BatchTime 0.170832   LR 0.001000   
2022-11-04 03:25:18,649 - INFO  - Training [39][   60/  196]   Loss 0.042657   Top1 98.457031   Top5 100.000000   BatchTime 0.154894   LR 0.001000   
2022-11-04 03:25:21,135 - INFO  - Training [39][   80/  196]   Loss 0.043097   Top1 98.442383   Top5 100.000000   BatchTime 0.147238   LR 0.001000   
2022-11-04 03:25:23,630 - INFO  - Training [39][  100/  196]   Loss 0.043000   Top1 98.445312   Top5 100.000000   BatchTime 0.142745   LR 0.001000   
2022-11-04 03:25:26,100 - INFO  - Training [39][  120/  196]   Loss 0.043373   Top1 98.421224   Top5 100.000000   BatchTime 0.139531   LR 0.001000   
2022-11-04 03:25:28,560 - INFO  - Training [39][  140/  196]   Loss 0.043603   Top1 98.434710   Top5 100.000000   BatchTime 0.137168   LR 0.001000   
2022-11-04 03:25:31,011 - INFO  - Training [39][  160/  196]   Loss 0.043929   Top1 98.422852   Top5 99.997559   BatchTime 0.135341   LR 0.001000   
2022-11-04 03:25:33,454 - INFO  - Training [39][  180/  196]   Loss 0.044413   Top1 98.398438   Top5 99.997830   BatchTime 0.133875   LR 0.001000   
2022-11-04 03:25:35,538 - INFO  - ==> Top1: 98.394    Top5: 99.998    Loss: 0.045

2022-11-04 03:25:35,539 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:25:38,273 - INFO  - Validation [39][   20/   40]   Loss 0.419078   Top1 90.097656   Top5 99.628906   BatchTime 0.136620   
2022-11-04 03:25:39,126 - INFO  - Validation [39][   40/   40]   Loss 0.406950   Top1 90.330000   Top5 99.670000   BatchTime 0.089623   
2022-11-04 03:25:39,388 - INFO  - ==> Top1: 90.330    Top5: 99.670    Loss: 0.407

2022-11-04 03:25:39,421 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:25:39,422 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:25:39,422 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.330   Top5: 99.670] Sparsity : 0.892
2022-11-04 03:25:39,524 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:25:39,524 - INFO  - >>>>>>>> Epoch  40
2022-11-04 03:25:39,525 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:25:43,950 - INFO  - Training [40][   20/  196]   Loss 0.044146   Top1 98.437500   Top5 100.000000   BatchTime 0.221194   LR 0.001000   
2022-11-04 03:25:46,428 - INFO  - Training [40][   40/  196]   Loss 0.044786   Top1 98.378906   Top5 100.000000   BatchTime 0.172556   LR 0.001000   
2022-11-04 03:25:48,902 - INFO  - Training [40][   60/  196]   Loss 0.046918   Top1 98.346354   Top5 100.000000   BatchTime 0.156270   LR 0.001000   
2022-11-04 03:25:51,376 - INFO  - Training [40][   80/  196]   Loss 0.045371   Top1 98.403320   Top5 100.000000   BatchTime 0.148123   LR 0.001000   
2022-11-04 03:25:53,854 - INFO  - Training [40][  100/  196]   Loss 0.044974   Top1 98.441406   Top5 100.000000   BatchTime 0.143277   LR 0.001000   
2022-11-04 03:25:56,335 - INFO  - Training [40][  120/  196]   Loss 0.044619   Top1 98.421224   Top5 100.000000   BatchTime 0.140073   LR 0.001000   
2022-11-04 03:25:58,801 - INFO  - Training [40][  140/  196]   Loss 0.045101   Top1 98.412388   Top5 100.000000   BatchTime 0.137676   LR 0.001000   
2022-11-04 03:26:01,271 - INFO  - Training [40][  160/  196]   Loss 0.044726   Top1 98.420410   Top5 100.000000   BatchTime 0.135904   LR 0.001000   
2022-11-04 03:26:03,727 - INFO  - Training [40][  180/  196]   Loss 0.045249   Top1 98.404948   Top5 100.000000   BatchTime 0.134450   LR 0.001000   
2022-11-04 03:26:05,907 - INFO  - ==> Top1: 98.402    Top5: 100.000    Loss: 0.045

2022-11-04 03:26:05,908 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:26:08,781 - INFO  - Validation [40][   20/   40]   Loss 0.414171   Top1 90.332031   Top5 99.667969   BatchTime 0.143597   
2022-11-04 03:26:09,910 - INFO  - Validation [40][   40/   40]   Loss 0.403302   Top1 90.290000   Top5 99.690000   BatchTime 0.100007   
2022-11-04 03:26:10,180 - INFO  - ==> Top1: 90.290    Top5: 99.690    Loss: 0.403

2022-11-04 03:26:10,212 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:26:10,213 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:26:10,213 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.330   Top5: 99.670] Sparsity : 0.892
2022-11-04 03:26:10,320 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:26:10,321 - INFO  - >>>>>>>> Epoch  41
2022-11-04 03:26:10,323 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:26:14,668 - INFO  - Training [41][   20/  196]   Loss 0.046609   Top1 98.300781   Top5 100.000000   BatchTime 0.217253   LR 0.001000   
2022-11-04 03:26:17,152 - INFO  - Training [41][   40/  196]   Loss 0.043243   Top1 98.457031   Top5 99.990234   BatchTime 0.170719   LR 0.001000   
2022-11-04 03:26:19,621 - INFO  - Training [41][   60/  196]   Loss 0.044162   Top1 98.437500   Top5 99.993490   BatchTime 0.154971   LR 0.001000   
2022-11-04 03:26:22,087 - INFO  - Training [41][   80/  196]   Loss 0.043109   Top1 98.496094   Top5 99.995117   BatchTime 0.147043   LR 0.001000   
2022-11-04 03:26:24,543 - INFO  - Training [41][  100/  196]   Loss 0.043300   Top1 98.476562   Top5 99.996094   BatchTime 0.142202   LR 0.001000   
2022-11-04 03:26:26,991 - INFO  - Training [41][  120/  196]   Loss 0.043456   Top1 98.492839   Top5 99.996745   BatchTime 0.138900   LR 0.001000   
2022-11-04 03:26:29,059 - INFO  - Training [41][  140/  196]   Loss 0.043226   Top1 98.515625   Top5 99.997210   BatchTime 0.133826   LR 0.001000   
2022-11-04 03:26:31,006 - INFO  - Training [41][  160/  196]   Loss 0.044047   Top1 98.491211   Top5 99.997559   BatchTime 0.129264   LR 0.001000   
2022-11-04 03:26:33,004 - INFO  - Training [41][  180/  196]   Loss 0.043967   Top1 98.493924   Top5 99.997830   BatchTime 0.126002   LR 0.001000   
2022-11-04 03:26:34,812 - INFO  - ==> Top1: 98.494    Top5: 99.998    Loss: 0.044

2022-11-04 03:26:34,812 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:26:37,777 - INFO  - Validation [41][   20/   40]   Loss 0.420463   Top1 90.253906   Top5 99.667969   BatchTime 0.148187   
2022-11-04 03:26:38,903 - INFO  - Validation [41][   40/   40]   Loss 0.408594   Top1 90.380000   Top5 99.710000   BatchTime 0.102254   
2022-11-04 03:26:39,154 - INFO  - ==> Top1: 90.380    Top5: 99.710    Loss: 0.409

2022-11-04 03:26:39,197 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:26:39,198 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:26:39,198 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.380   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:26:39,306 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:26:39,306 - INFO  - >>>>>>>> Epoch  42
2022-11-04 03:26:39,308 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:26:43,658 - INFO  - Training [42][   20/  196]   Loss 0.037550   Top1 98.847656   Top5 100.000000   BatchTime 0.217479   LR 0.001000   
2022-11-04 03:26:46,134 - INFO  - Training [42][   40/  196]   Loss 0.041227   Top1 98.554688   Top5 100.000000   BatchTime 0.170638   LR 0.001000   
2022-11-04 03:26:48,627 - INFO  - Training [42][   60/  196]   Loss 0.039374   Top1 98.567708   Top5 100.000000   BatchTime 0.155314   LR 0.001000   
2022-11-04 03:26:51,115 - INFO  - Training [42][   80/  196]   Loss 0.039482   Top1 98.549805   Top5 100.000000   BatchTime 0.147582   LR 0.001000   
2022-11-04 03:26:53,580 - INFO  - Training [42][  100/  196]   Loss 0.039718   Top1 98.585938   Top5 100.000000   BatchTime 0.142720   LR 0.001000   
2022-11-04 03:26:56,058 - INFO  - Training [42][  120/  196]   Loss 0.040595   Top1 98.570964   Top5 100.000000   BatchTime 0.139579   LR 0.001000   
2022-11-04 03:26:58,539 - INFO  - Training [42][  140/  196]   Loss 0.040460   Top1 98.563058   Top5 100.000000   BatchTime 0.137362   LR 0.001000   
2022-11-04 03:27:00,996 - INFO  - Training [42][  160/  196]   Loss 0.040588   Top1 98.574219   Top5 100.000000   BatchTime 0.135549   LR 0.001000   
2022-11-04 03:27:03,449 - INFO  - Training [42][  180/  196]   Loss 0.040278   Top1 98.576389   Top5 99.997830   BatchTime 0.134115   LR 0.001000   
2022-11-04 03:27:05,629 - INFO  - ==> Top1: 98.590    Top5: 99.998    Loss: 0.040

2022-11-04 03:27:05,630 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:27:08,521 - INFO  - Validation [42][   20/   40]   Loss 0.405838   Top1 90.332031   Top5 99.667969   BatchTime 0.144444   
2022-11-04 03:27:09,627 - INFO  - Validation [42][   40/   40]   Loss 0.397913   Top1 90.660000   Top5 99.730000   BatchTime 0.099867   
2022-11-04 03:27:09,872 - INFO  - ==> Top1: 90.660    Top5: 99.730    Loss: 0.398

2022-11-04 03:27:09,916 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:27:09,916 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:27:09,917 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:27:10,180 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:27:10,341 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_best.pth.tar

2022-11-04 03:27:10,341 - INFO  - >>>>>>>> Epoch  43
2022-11-04 03:27:10,342 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:27:14,682 - INFO  - Training [43][   20/  196]   Loss 0.044915   Top1 98.437500   Top5 99.980469   BatchTime 0.216996   LR 0.001000   
2022-11-04 03:27:17,138 - INFO  - Training [43][   40/  196]   Loss 0.043497   Top1 98.378906   Top5 99.990234   BatchTime 0.169904   LR 0.001000   
2022-11-04 03:27:19,600 - INFO  - Training [43][   60/  196]   Loss 0.043631   Top1 98.391927   Top5 99.993490   BatchTime 0.154294   LR 0.001000   
2022-11-04 03:27:21,813 - INFO  - Training [43][   80/  196]   Loss 0.042366   Top1 98.500977   Top5 99.995117   BatchTime 0.143381   LR 0.001000   
2022-11-04 03:27:23,717 - INFO  - Training [43][  100/  196]   Loss 0.042612   Top1 98.503906   Top5 99.996094   BatchTime 0.133747   LR 0.001000   
2022-11-04 03:27:25,771 - INFO  - Training [43][  120/  196]   Loss 0.042097   Top1 98.505859   Top5 99.996745   BatchTime 0.128568   LR 0.001000   
2022-11-04 03:27:27,814 - INFO  - Training [43][  140/  196]   Loss 0.042151   Top1 98.518415   Top5 99.997210   BatchTime 0.124800   LR 0.001000   
2022-11-04 03:27:29,657 - INFO  - Training [43][  160/  196]   Loss 0.042668   Top1 98.510742   Top5 99.997559   BatchTime 0.120716   LR 0.001000   
2022-11-04 03:27:31,870 - INFO  - Training [43][  180/  196]   Loss 0.042687   Top1 98.500434   Top5 99.997830   BatchTime 0.119595   LR 0.001000   
2022-11-04 03:27:34,040 - INFO  - ==> Top1: 98.506    Top5: 99.998    Loss: 0.043

2022-11-04 03:27:34,041 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:27:36,909 - INFO  - Validation [43][   20/   40]   Loss 0.417792   Top1 90.214844   Top5 99.687500   BatchTime 0.143322   
2022-11-04 03:27:38,015 - INFO  - Validation [43][   40/   40]   Loss 0.407998   Top1 90.270000   Top5 99.720000   BatchTime 0.099305   
2022-11-04 03:27:38,280 - INFO  - ==> Top1: 90.270    Top5: 99.720    Loss: 0.408

2022-11-04 03:27:38,321 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:27:38,322 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:27:38,322 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:27:38,425 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:27:38,425 - INFO  - >>>>>>>> Epoch  44
2022-11-04 03:27:38,427 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:27:42,801 - INFO  - Training [44][   20/  196]   Loss 0.041999   Top1 98.476562   Top5 99.980469   BatchTime 0.218735   LR 0.001000   
2022-11-04 03:27:45,272 - INFO  - Training [44][   40/  196]   Loss 0.042433   Top1 98.427734   Top5 99.990234   BatchTime 0.171139   LR 0.001000   
2022-11-04 03:27:47,755 - INFO  - Training [44][   60/  196]   Loss 0.042413   Top1 98.444010   Top5 99.993490   BatchTime 0.155474   LR 0.001000   
2022-11-04 03:27:50,250 - INFO  - Training [44][   80/  196]   Loss 0.041986   Top1 98.486328   Top5 99.995117   BatchTime 0.147783   LR 0.001000   
2022-11-04 03:27:52,738 - INFO  - Training [44][  100/  196]   Loss 0.043152   Top1 98.457031   Top5 99.996094   BatchTime 0.143112   LR 0.001000   
2022-11-04 03:27:55,211 - INFO  - Training [44][  120/  196]   Loss 0.041827   Top1 98.505859   Top5 99.996745   BatchTime 0.139864   LR 0.001000   
2022-11-04 03:27:57,688 - INFO  - Training [44][  140/  196]   Loss 0.041483   Top1 98.512835   Top5 99.994420   BatchTime 0.137577   LR 0.001000   
2022-11-04 03:28:00,143 - INFO  - Training [44][  160/  196]   Loss 0.040977   Top1 98.525391   Top5 99.995117   BatchTime 0.135722   LR 0.001000   
2022-11-04 03:28:02,606 - INFO  - Training [44][  180/  196]   Loss 0.041766   Top1 98.489583   Top5 99.995660   BatchTime 0.134325   LR 0.001000   
2022-11-04 03:28:04,796 - INFO  - ==> Top1: 98.504    Top5: 99.996    Loss: 0.042

2022-11-04 03:28:04,797 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:28:07,681 - INFO  - Validation [44][   20/   40]   Loss 0.416142   Top1 90.371094   Top5 99.648438   BatchTime 0.144141   
2022-11-04 03:28:08,803 - INFO  - Validation [44][   40/   40]   Loss 0.402628   Top1 90.340000   Top5 99.670000   BatchTime 0.100125   
2022-11-04 03:28:09,060 - INFO  - ==> Top1: 90.340    Top5: 99.670    Loss: 0.403

2022-11-04 03:28:09,096 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:28:09,097 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:28:09,097 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:28:09,195 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:28:09,196 - INFO  - >>>>>>>> Epoch  45
2022-11-04 03:28:09,197 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:28:13,516 - INFO  - Training [45][   20/  196]   Loss 0.037336   Top1 98.554688   Top5 100.000000   BatchTime 0.215918   LR 0.001000   
2022-11-04 03:28:15,280 - INFO  - Training [45][   40/  196]   Loss 0.039363   Top1 98.505859   Top5 100.000000   BatchTime 0.152070   LR 0.001000   
2022-11-04 03:28:17,326 - INFO  - Training [45][   60/  196]   Loss 0.040382   Top1 98.580729   Top5 100.000000   BatchTime 0.135470   LR 0.001000   
2022-11-04 03:28:19,355 - INFO  - Training [45][   80/  196]   Loss 0.041232   Top1 98.505859   Top5 100.000000   BatchTime 0.126964   LR 0.001000   
2022-11-04 03:28:21,356 - INFO  - Training [45][  100/  196]   Loss 0.041307   Top1 98.566406   Top5 100.000000   BatchTime 0.121589   LR 0.001000   
2022-11-04 03:28:23,462 - INFO  - Training [45][  120/  196]   Loss 0.040523   Top1 98.600260   Top5 100.000000   BatchTime 0.118874   LR 0.001000   
2022-11-04 03:28:25,932 - INFO  - Training [45][  140/  196]   Loss 0.039898   Top1 98.604911   Top5 100.000000   BatchTime 0.119531   LR 0.001000   
2022-11-04 03:28:28,391 - INFO  - Training [45][  160/  196]   Loss 0.040411   Top1 98.562012   Top5 100.000000   BatchTime 0.119961   LR 0.001000   
2022-11-04 03:28:30,846 - INFO  - Training [45][  180/  196]   Loss 0.040664   Top1 98.563368   Top5 100.000000   BatchTime 0.120271   LR 0.001000   
2022-11-04 03:28:33,006 - INFO  - ==> Top1: 98.552    Top5: 100.000    Loss: 0.041

2022-11-04 03:28:33,007 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:28:35,899 - INFO  - Validation [45][   20/   40]   Loss 0.419574   Top1 90.175781   Top5 99.628906   BatchTime 0.144510   
2022-11-04 03:28:37,034 - INFO  - Validation [45][   40/   40]   Loss 0.407823   Top1 90.200000   Top5 99.700000   BatchTime 0.100643   
2022-11-04 03:28:37,292 - INFO  - ==> Top1: 90.200    Top5: 99.700    Loss: 0.408

2022-11-04 03:28:37,333 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:28:37,333 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:28:37,333 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.470   Top5: 99.700] Sparsity : 0.892
2022-11-04 03:28:37,544 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:28:37,544 - INFO  - >>>>>>>> Epoch  46
2022-11-04 03:28:37,546 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:28:41,901 - INFO  - Training [46][   20/  196]   Loss 0.038750   Top1 98.632812   Top5 100.000000   BatchTime 0.217750   LR 0.001000   
2022-11-04 03:28:44,373 - INFO  - Training [46][   40/  196]   Loss 0.039962   Top1 98.583984   Top5 100.000000   BatchTime 0.170677   LR 0.001000   
2022-11-04 03:28:46,841 - INFO  - Training [46][   60/  196]   Loss 0.040036   Top1 98.554688   Top5 100.000000   BatchTime 0.154909   LR 0.001000   
2022-11-04 03:28:49,303 - INFO  - Training [46][   80/  196]   Loss 0.040878   Top1 98.554688   Top5 100.000000   BatchTime 0.146956   LR 0.001000   
2022-11-04 03:28:51,786 - INFO  - Training [46][  100/  196]   Loss 0.040657   Top1 98.593750   Top5 100.000000   BatchTime 0.142401   LR 0.001000   
2022-11-04 03:28:54,246 - INFO  - Training [46][  120/  196]   Loss 0.041127   Top1 98.593750   Top5 100.000000   BatchTime 0.139168   LR 0.001000   
2022-11-04 03:28:56,724 - INFO  - Training [46][  140/  196]   Loss 0.040575   Top1 98.610491   Top5 99.997210   BatchTime 0.136980   LR 0.001000   
2022-11-04 03:28:59,170 - INFO  - Training [46][  160/  196]   Loss 0.041034   Top1 98.608398   Top5 99.997559   BatchTime 0.135145   LR 0.001000   
2022-11-04 03:29:01,719 - INFO  - Training [46][  180/  196]   Loss 0.040998   Top1 98.600260   Top5 99.997830   BatchTime 0.134290   LR 0.001000   
2022-11-04 03:29:03,887 - INFO  - ==> Top1: 98.582    Top5: 99.998    Loss: 0.041

2022-11-04 03:29:03,888 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:29:06,734 - INFO  - Validation [46][   20/   40]   Loss 0.416817   Top1 90.449219   Top5 99.687500   BatchTime 0.142208   
2022-11-04 03:29:07,415 - INFO  - Validation [46][   40/   40]   Loss 0.405572   Top1 90.480000   Top5 99.710000   BatchTime 0.088150   
2022-11-04 03:29:07,664 - INFO  - ==> Top1: 90.480    Top5: 99.710    Loss: 0.406

2022-11-04 03:29:07,688 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:29:07,689 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:29:07,689 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:29:07,792 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:29:07,792 - INFO  - >>>>>>>> Epoch  47
2022-11-04 03:29:07,794 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:29:11,815 - INFO  - Training [47][   20/  196]   Loss 0.037769   Top1 98.632812   Top5 100.000000   BatchTime 0.201051   LR 0.001000   
2022-11-04 03:29:13,773 - INFO  - Training [47][   40/  196]   Loss 0.040358   Top1 98.701172   Top5 100.000000   BatchTime 0.149464   LR 0.001000   
2022-11-04 03:29:15,956 - INFO  - Training [47][   60/  196]   Loss 0.039743   Top1 98.684896   Top5 100.000000   BatchTime 0.136031   LR 0.001000   
2022-11-04 03:29:18,445 - INFO  - Training [47][   80/  196]   Loss 0.040216   Top1 98.623047   Top5 100.000000   BatchTime 0.133138   LR 0.001000   
2022-11-04 03:29:20,929 - INFO  - Training [47][  100/  196]   Loss 0.041400   Top1 98.593750   Top5 100.000000   BatchTime 0.131344   LR 0.001000   
2022-11-04 03:29:23,408 - INFO  - Training [47][  120/  196]   Loss 0.040070   Top1 98.649089   Top5 100.000000   BatchTime 0.130113   LR 0.001000   
2022-11-04 03:29:25,858 - INFO  - Training [47][  140/  196]   Loss 0.039724   Top1 98.646763   Top5 100.000000   BatchTime 0.129030   LR 0.001000   
2022-11-04 03:29:28,328 - INFO  - Training [47][  160/  196]   Loss 0.040248   Top1 98.637695   Top5 99.995117   BatchTime 0.128334   LR 0.001000   
2022-11-04 03:29:30,791 - INFO  - Training [47][  180/  196]   Loss 0.040534   Top1 98.619792   Top5 99.995660   BatchTime 0.127759   LR 0.001000   
2022-11-04 03:29:32,960 - INFO  - ==> Top1: 98.616    Top5: 99.996    Loss: 0.041

2022-11-04 03:29:32,960 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:29:35,846 - INFO  - Validation [47][   20/   40]   Loss 0.423563   Top1 90.292969   Top5 99.648438   BatchTime 0.144211   
2022-11-04 03:29:36,942 - INFO  - Validation [47][   40/   40]   Loss 0.409820   Top1 90.460000   Top5 99.710000   BatchTime 0.099498   
2022-11-04 03:29:37,193 - INFO  - ==> Top1: 90.460    Top5: 99.710    Loss: 0.410

2022-11-04 03:29:37,235 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:29:37,236 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:29:37,236 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:29:37,332 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:29:37,332 - INFO  - >>>>>>>> Epoch  48
2022-11-04 03:29:37,333 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:29:41,699 - INFO  - Training [48][   20/  196]   Loss 0.042023   Top1 98.750000   Top5 100.000000   BatchTime 0.218283   LR 0.001000   
2022-11-04 03:29:44,177 - INFO  - Training [48][   40/  196]   Loss 0.038574   Top1 98.818359   Top5 100.000000   BatchTime 0.171088   LR 0.001000   
2022-11-04 03:29:46,644 - INFO  - Training [48][   60/  196]   Loss 0.038488   Top1 98.789062   Top5 100.000000   BatchTime 0.155173   LR 0.001000   
2022-11-04 03:29:49,100 - INFO  - Training [48][   80/  196]   Loss 0.037210   Top1 98.808594   Top5 100.000000   BatchTime 0.147091   LR 0.001000   
2022-11-04 03:29:51,566 - INFO  - Training [48][  100/  196]   Loss 0.037906   Top1 98.789062   Top5 100.000000   BatchTime 0.142327   LR 0.001000   
2022-11-04 03:29:54,024 - INFO  - Training [48][  120/  196]   Loss 0.037269   Top1 98.811849   Top5 100.000000   BatchTime 0.139090   LR 0.001000   
2022-11-04 03:29:56,499 - INFO  - Training [48][  140/  196]   Loss 0.037467   Top1 98.822545   Top5 100.000000   BatchTime 0.136897   LR 0.001000   
2022-11-04 03:29:58,946 - INFO  - Training [48][  160/  196]   Loss 0.037275   Top1 98.813477   Top5 100.000000   BatchTime 0.135078   LR 0.001000   
2022-11-04 03:30:01,199 - INFO  - Training [48][  180/  196]   Loss 0.037225   Top1 98.808594   Top5 99.997830   BatchTime 0.132583   LR 0.001000   
2022-11-04 03:30:02,893 - INFO  - ==> Top1: 98.792    Top5: 99.998    Loss: 0.038

2022-11-04 03:30:02,894 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:30:05,432 - INFO  - Validation [48][   20/   40]   Loss 0.422687   Top1 90.214844   Top5 99.648438   BatchTime 0.126819   
2022-11-04 03:30:06,114 - INFO  - Validation [48][   40/   40]   Loss 0.410798   Top1 90.260000   Top5 99.710000   BatchTime 0.080483   
2022-11-04 03:30:06,382 - INFO  - ==> Top1: 90.260    Top5: 99.710    Loss: 0.411

2022-11-04 03:30:06,404 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:30:06,405 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:30:06,405 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:30:06,500 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:30:06,500 - INFO  - >>>>>>>> Epoch  49
2022-11-04 03:30:06,502 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:30:10,996 - INFO  - Training [49][   20/  196]   Loss 0.034143   Top1 98.964844   Top5 100.000000   BatchTime 0.224732   LR 0.001000   
2022-11-04 03:30:13,476 - INFO  - Training [49][   40/  196]   Loss 0.037661   Top1 98.798828   Top5 99.990234   BatchTime 0.174351   LR 0.001000   
2022-11-04 03:30:15,954 - INFO  - Training [49][   60/  196]   Loss 0.037921   Top1 98.697917   Top5 99.993490   BatchTime 0.157544   LR 0.001000   
2022-11-04 03:30:18,416 - INFO  - Training [49][   80/  196]   Loss 0.039192   Top1 98.623047   Top5 99.995117   BatchTime 0.148926   LR 0.001000   
2022-11-04 03:30:20,888 - INFO  - Training [49][  100/  196]   Loss 0.039658   Top1 98.636719   Top5 99.996094   BatchTime 0.143861   LR 0.001000   
2022-11-04 03:30:23,357 - INFO  - Training [49][  120/  196]   Loss 0.040738   Top1 98.580729   Top5 99.996745   BatchTime 0.140458   LR 0.001000   
2022-11-04 03:30:25,808 - INFO  - Training [49][  140/  196]   Loss 0.040378   Top1 98.574219   Top5 99.997210   BatchTime 0.137902   LR 0.001000   
2022-11-04 03:30:28,264 - INFO  - Training [49][  160/  196]   Loss 0.040480   Top1 98.569336   Top5 99.997559   BatchTime 0.136014   LR 0.001000   
2022-11-04 03:30:30,724 - INFO  - Training [49][  180/  196]   Loss 0.040974   Top1 98.543837   Top5 99.997830   BatchTime 0.134564   LR 0.001000   
2022-11-04 03:30:32,889 - INFO  - ==> Top1: 98.566    Top5: 99.998    Loss: 0.041

2022-11-04 03:30:32,890 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:30:35,778 - INFO  - Validation [49][   20/   40]   Loss 0.418246   Top1 90.195312   Top5 99.589844   BatchTime 0.144300   
2022-11-04 03:30:36,865 - INFO  - Validation [49][   40/   40]   Loss 0.407488   Top1 90.350000   Top5 99.660000   BatchTime 0.099335   
2022-11-04 03:30:37,131 - INFO  - ==> Top1: 90.350    Top5: 99.660    Loss: 0.407

2022-11-04 03:30:37,164 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:30:37,164 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:30:37,165 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:30:37,276 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:30:37,276 - INFO  - >>>>>>>> Epoch  50
2022-11-04 03:30:37,278 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:30:41,670 - INFO  - Training [50][   20/  196]   Loss 0.040660   Top1 98.515625   Top5 100.000000   BatchTime 0.219627   LR 0.001000   
2022-11-04 03:30:44,151 - INFO  - Training [50][   40/  196]   Loss 0.039940   Top1 98.505859   Top5 100.000000   BatchTime 0.171832   LR 0.001000   
2022-11-04 03:30:46,610 - INFO  - Training [50][   60/  196]   Loss 0.038563   Top1 98.606771   Top5 100.000000   BatchTime 0.155541   LR 0.001000   
2022-11-04 03:30:49,069 - INFO  - Training [50][   80/  196]   Loss 0.039049   Top1 98.549805   Top5 100.000000   BatchTime 0.147390   LR 0.001000   
2022-11-04 03:30:51,529 - INFO  - Training [50][  100/  196]   Loss 0.039813   Top1 98.511719   Top5 100.000000   BatchTime 0.142511   LR 0.001000   
2022-11-04 03:30:53,531 - INFO  - Training [50][  120/  196]   Loss 0.039552   Top1 98.548177   Top5 100.000000   BatchTime 0.135443   LR 0.001000   
2022-11-04 03:30:55,493 - INFO  - Training [50][  140/  196]   Loss 0.038698   Top1 98.593750   Top5 100.000000   BatchTime 0.130108   LR 0.001000   
2022-11-04 03:30:57,482 - INFO  - Training [50][  160/  196]   Loss 0.039334   Top1 98.574219   Top5 100.000000   BatchTime 0.126275   LR 0.001000   
2022-11-04 03:30:59,640 - INFO  - Training [50][  180/  196]   Loss 0.039489   Top1 98.578559   Top5 100.000000   BatchTime 0.124230   LR 0.001000   
2022-11-04 03:31:01,205 - INFO  - ==> Top1: 98.542    Top5: 100.000    Loss: 0.040

2022-11-04 03:31:01,206 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:31:04,110 - INFO  - Validation [50][   20/   40]   Loss 0.419219   Top1 90.097656   Top5 99.609375   BatchTime 0.145165   
2022-11-04 03:31:05,260 - INFO  - Validation [50][   40/   40]   Loss 0.411201   Top1 90.240000   Top5 99.690000   BatchTime 0.101322   
2022-11-04 03:31:05,514 - INFO  - ==> Top1: 90.240    Top5: 99.690    Loss: 0.411

2022-11-04 03:31:05,551 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:31:05,552 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:31:05,552 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:31:05,648 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:31:05,649 - INFO  - >>>>>>>> Epoch  51
2022-11-04 03:31:05,650 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:31:10,055 - INFO  - Training [51][   20/  196]   Loss 0.038732   Top1 98.652344   Top5 100.000000   BatchTime 0.220254   LR 0.001000   
2022-11-04 03:31:12,527 - INFO  - Training [51][   40/  196]   Loss 0.038973   Top1 98.681641   Top5 100.000000   BatchTime 0.171917   LR 0.001000   
2022-11-04 03:31:14,938 - INFO  - Training [51][   60/  196]   Loss 0.039287   Top1 98.671875   Top5 100.000000   BatchTime 0.154800   LR 0.001000   
2022-11-04 03:31:17,431 - INFO  - Training [51][   80/  196]   Loss 0.038640   Top1 98.681641   Top5 100.000000   BatchTime 0.147258   LR 0.001000   
2022-11-04 03:31:19,908 - INFO  - Training [51][  100/  196]   Loss 0.039131   Top1 98.660156   Top5 100.000000   BatchTime 0.142571   LR 0.001000   
2022-11-04 03:31:22,377 - INFO  - Training [51][  120/  196]   Loss 0.039603   Top1 98.642578   Top5 100.000000   BatchTime 0.139384   LR 0.001000   
2022-11-04 03:31:24,852 - INFO  - Training [51][  140/  196]   Loss 0.040067   Top1 98.624442   Top5 100.000000   BatchTime 0.137156   LR 0.001000   
2022-11-04 03:31:27,317 - INFO  - Training [51][  160/  196]   Loss 0.040083   Top1 98.605957   Top5 100.000000   BatchTime 0.135412   LR 0.001000   
2022-11-04 03:31:29,778 - INFO  - Training [51][  180/  196]   Loss 0.040176   Top1 98.600260   Top5 100.000000   BatchTime 0.134041   LR 0.001000   
2022-11-04 03:31:31,957 - INFO  - ==> Top1: 98.596    Top5: 100.000    Loss: 0.040

2022-11-04 03:31:31,958 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:31:34,805 - INFO  - Validation [51][   20/   40]   Loss 0.422050   Top1 90.253906   Top5 99.667969   BatchTime 0.142304   
2022-11-04 03:31:35,919 - INFO  - Validation [51][   40/   40]   Loss 0.413627   Top1 90.220000   Top5 99.700000   BatchTime 0.099007   
2022-11-04 03:31:36,171 - INFO  - ==> Top1: 90.220    Top5: 99.700    Loss: 0.414

2022-11-04 03:31:36,209 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:31:36,210 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:31:36,210 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:31:36,315 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:31:36,315 - INFO  - >>>>>>>> Epoch  52
2022-11-04 03:31:36,317 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:31:40,713 - INFO  - Training [52][   20/  196]   Loss 0.037442   Top1 98.632812   Top5 100.000000   BatchTime 0.219790   LR 0.001000   
2022-11-04 03:31:43,179 - INFO  - Training [52][   40/  196]   Loss 0.039967   Top1 98.564453   Top5 100.000000   BatchTime 0.171547   LR 0.001000   
2022-11-04 03:31:45,374 - INFO  - Training [52][   60/  196]   Loss 0.038853   Top1 98.626302   Top5 100.000000   BatchTime 0.150951   LR 0.001000   
2022-11-04 03:31:47,287 - INFO  - Training [52][   80/  196]   Loss 0.037812   Top1 98.657227   Top5 100.000000   BatchTime 0.137122   LR 0.001000   
2022-11-04 03:31:49,315 - INFO  - Training [52][  100/  196]   Loss 0.039346   Top1 98.617188   Top5 100.000000   BatchTime 0.129977   LR 0.001000   
2022-11-04 03:31:51,346 - INFO  - Training [52][  120/  196]   Loss 0.039208   Top1 98.626302   Top5 100.000000   BatchTime 0.125245   LR 0.001000   
2022-11-04 03:31:53,249 - INFO  - Training [52][  140/  196]   Loss 0.038425   Top1 98.671875   Top5 100.000000   BatchTime 0.120940   LR 0.001000   
2022-11-04 03:31:55,480 - INFO  - Training [52][  160/  196]   Loss 0.039368   Top1 98.645020   Top5 100.000000   BatchTime 0.119766   LR 0.001000   
2022-11-04 03:31:57,943 - INFO  - Training [52][  180/  196]   Loss 0.039332   Top1 98.652344   Top5 100.000000   BatchTime 0.120143   LR 0.001000   
2022-11-04 03:32:00,119 - INFO  - ==> Top1: 98.620    Top5: 100.000    Loss: 0.040

2022-11-04 03:32:00,119 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:32:02,994 - INFO  - Validation [52][   20/   40]   Loss 0.420699   Top1 90.175781   Top5 99.707031   BatchTime 0.143694   
2022-11-04 03:32:04,113 - INFO  - Validation [52][   40/   40]   Loss 0.412922   Top1 90.360000   Top5 99.730000   BatchTime 0.099809   
2022-11-04 03:32:04,372 - INFO  - ==> Top1: 90.360    Top5: 99.730    Loss: 0.413

2022-11-04 03:32:04,411 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:32:04,412 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:32:04,412 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:32:04,518 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:32:04,519 - INFO  - >>>>>>>> Epoch  53
2022-11-04 03:32:04,520 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:32:08,884 - INFO  - Training [53][   20/  196]   Loss 0.038144   Top1 98.515625   Top5 100.000000   BatchTime 0.218195   LR 0.001000   
2022-11-04 03:32:11,353 - INFO  - Training [53][   40/  196]   Loss 0.035113   Top1 98.710938   Top5 100.000000   BatchTime 0.170821   LR 0.001000   
2022-11-04 03:32:13,824 - INFO  - Training [53][   60/  196]   Loss 0.037225   Top1 98.652344   Top5 100.000000   BatchTime 0.155050   LR 0.001000   
2022-11-04 03:32:16,297 - INFO  - Training [53][   80/  196]   Loss 0.038633   Top1 98.613281   Top5 100.000000   BatchTime 0.147208   LR 0.001000   
2022-11-04 03:32:18,761 - INFO  - Training [53][  100/  196]   Loss 0.039263   Top1 98.597656   Top5 100.000000   BatchTime 0.142405   LR 0.001000   
2022-11-04 03:32:21,224 - INFO  - Training [53][  120/  196]   Loss 0.038508   Top1 98.600260   Top5 100.000000   BatchTime 0.139193   LR 0.001000   
2022-11-04 03:32:23,691 - INFO  - Training [53][  140/  196]   Loss 0.038344   Top1 98.604911   Top5 100.000000   BatchTime 0.136933   LR 0.001000   
2022-11-04 03:32:26,143 - INFO  - Training [53][  160/  196]   Loss 0.038563   Top1 98.613281   Top5 100.000000   BatchTime 0.135139   LR 0.001000   
2022-11-04 03:32:28,597 - INFO  - Training [53][  180/  196]   Loss 0.038264   Top1 98.630642   Top5 100.000000   BatchTime 0.133758   LR 0.001000   
2022-11-04 03:32:30,766 - INFO  - ==> Top1: 98.620    Top5: 100.000    Loss: 0.038

2022-11-04 03:32:30,767 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:32:33,634 - INFO  - Validation [53][   20/   40]   Loss 0.420265   Top1 90.449219   Top5 99.687500   BatchTime 0.143319   
2022-11-04 03:32:34,756 - INFO  - Validation [53][   40/   40]   Loss 0.413411   Top1 90.300000   Top5 99.670000   BatchTime 0.099693   
2022-11-04 03:32:35,008 - INFO  - ==> Top1: 90.300    Top5: 99.670    Loss: 0.413

2022-11-04 03:32:35,038 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:32:35,039 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:32:35,039 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:32:35,140 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:32:35,140 - INFO  - >>>>>>>> Epoch  54
2022-11-04 03:32:35,141 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:32:38,998 - INFO  - Training [54][   20/  196]   Loss 0.044738   Top1 98.378906   Top5 100.000000   BatchTime 0.192811   LR 0.001000   
2022-11-04 03:32:41,030 - INFO  - Training [54][   40/  196]   Loss 0.043387   Top1 98.515625   Top5 100.000000   BatchTime 0.147209   LR 0.001000   
2022-11-04 03:32:43,078 - INFO  - Training [54][   60/  196]   Loss 0.041088   Top1 98.619792   Top5 100.000000   BatchTime 0.132279   LR 0.001000   
2022-11-04 03:32:45,048 - INFO  - Training [54][   80/  196]   Loss 0.039290   Top1 98.662109   Top5 100.000000   BatchTime 0.123829   LR 0.001000   
2022-11-04 03:32:47,197 - INFO  - Training [54][  100/  196]   Loss 0.041590   Top1 98.562500   Top5 100.000000   BatchTime 0.120546   LR 0.001000   
2022-11-04 03:32:49,659 - INFO  - Training [54][  120/  196]   Loss 0.040648   Top1 98.606771   Top5 99.996745   BatchTime 0.120976   LR 0.001000   
2022-11-04 03:32:52,139 - INFO  - Training [54][  140/  196]   Loss 0.040740   Top1 98.596540   Top5 99.997210   BatchTime 0.121408   LR 0.001000   
2022-11-04 03:32:54,594 - INFO  - Training [54][  160/  196]   Loss 0.040412   Top1 98.610840   Top5 99.997559   BatchTime 0.121576   LR 0.001000   
2022-11-04 03:32:57,061 - INFO  - Training [54][  180/  196]   Loss 0.039706   Top1 98.650174   Top5 99.997830   BatchTime 0.121769   LR 0.001000   
2022-11-04 03:32:59,243 - INFO  - ==> Top1: 98.630    Top5: 99.998    Loss: 0.040

2022-11-04 03:32:59,243 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:33:02,167 - INFO  - Validation [54][   20/   40]   Loss 0.428403   Top1 90.195312   Top5 99.667969   BatchTime 0.146087   
2022-11-04 03:33:03,235 - INFO  - Validation [54][   40/   40]   Loss 0.408911   Top1 90.430000   Top5 99.720000   BatchTime 0.099751   
2022-11-04 03:33:03,490 - INFO  - ==> Top1: 90.430    Top5: 99.720    Loss: 0.409

2022-11-04 03:33:03,519 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:33:03,519 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:33:03,519 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:33:03,622 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:33:03,623 - INFO  - >>>>>>>> Epoch  55
2022-11-04 03:33:03,624 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:33:08,078 - INFO  - Training [55][   20/  196]   Loss 0.045549   Top1 98.339844   Top5 100.000000   BatchTime 0.222686   LR 0.001000   
2022-11-04 03:33:10,568 - INFO  - Training [55][   40/  196]   Loss 0.043087   Top1 98.437500   Top5 100.000000   BatchTime 0.173582   LR 0.001000   
2022-11-04 03:33:13,064 - INFO  - Training [55][   60/  196]   Loss 0.041282   Top1 98.561198   Top5 100.000000   BatchTime 0.157320   LR 0.001000   
2022-11-04 03:33:15,542 - INFO  - Training [55][   80/  196]   Loss 0.040952   Top1 98.564453   Top5 100.000000   BatchTime 0.148967   LR 0.001000   
2022-11-04 03:33:18,010 - INFO  - Training [55][  100/  196]   Loss 0.040218   Top1 98.597656   Top5 100.000000   BatchTime 0.143850   LR 0.001000   
2022-11-04 03:33:20,487 - INFO  - Training [55][  120/  196]   Loss 0.039694   Top1 98.632812   Top5 100.000000   BatchTime 0.140523   LR 0.001000   
2022-11-04 03:33:22,956 - INFO  - Training [55][  140/  196]   Loss 0.040291   Top1 98.627232   Top5 100.000000   BatchTime 0.138084   LR 0.001000   
2022-11-04 03:33:25,406 - INFO  - Training [55][  160/  196]   Loss 0.040532   Top1 98.613281   Top5 100.000000   BatchTime 0.136134   LR 0.001000   
2022-11-04 03:33:27,847 - INFO  - Training [55][  180/  196]   Loss 0.040942   Top1 98.621962   Top5 100.000000   BatchTime 0.134568   LR 0.001000   
2022-11-04 03:33:30,026 - INFO  - ==> Top1: 98.634    Top5: 100.000    Loss: 0.041

2022-11-04 03:33:30,027 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:33:32,583 - INFO  - Validation [55][   20/   40]   Loss 0.427068   Top1 89.980469   Top5 99.707031   BatchTime 0.127713   
2022-11-04 03:33:33,347 - INFO  - Validation [55][   40/   40]   Loss 0.414997   Top1 90.010000   Top5 99.700000   BatchTime 0.082957   
2022-11-04 03:33:33,622 - INFO  - ==> Top1: 90.010    Top5: 99.700    Loss: 0.415

2022-11-04 03:33:33,655 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:33:33,655 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:33:33,656 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:33:33,761 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:33:33,762 - INFO  - >>>>>>>> Epoch  56
2022-11-04 03:33:33,763 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:33:37,517 - INFO  - Training [56][   20/  196]   Loss 0.039626   Top1 98.671875   Top5 100.000000   BatchTime 0.187699   LR 0.001000   
2022-11-04 03:33:39,924 - INFO  - Training [56][   40/  196]   Loss 0.038563   Top1 98.662109   Top5 100.000000   BatchTime 0.154024   LR 0.001000   
2022-11-04 03:33:42,406 - INFO  - Training [56][   60/  196]   Loss 0.038053   Top1 98.717448   Top5 100.000000   BatchTime 0.144052   LR 0.001000   
2022-11-04 03:33:44,872 - INFO  - Training [56][   80/  196]   Loss 0.037404   Top1 98.715820   Top5 100.000000   BatchTime 0.138857   LR 0.001000   
2022-11-04 03:33:47,348 - INFO  - Training [56][  100/  196]   Loss 0.037665   Top1 98.695312   Top5 100.000000   BatchTime 0.135844   LR 0.001000   
2022-11-04 03:33:49,826 - INFO  - Training [56][  120/  196]   Loss 0.038984   Top1 98.642578   Top5 100.000000   BatchTime 0.133858   LR 0.001000   
2022-11-04 03:33:52,304 - INFO  - Training [56][  140/  196]   Loss 0.039641   Top1 98.616071   Top5 100.000000   BatchTime 0.132435   LR 0.001000   
2022-11-04 03:33:54,758 - INFO  - Training [56][  160/  196]   Loss 0.039574   Top1 98.615723   Top5 100.000000   BatchTime 0.131217   LR 0.001000   
2022-11-04 03:33:57,217 - INFO  - Training [56][  180/  196]   Loss 0.039624   Top1 98.626302   Top5 100.000000   BatchTime 0.130294   LR 0.001000   
2022-11-04 03:33:59,383 - INFO  - ==> Top1: 98.636    Top5: 100.000    Loss: 0.039

2022-11-04 03:33:59,384 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:34:02,268 - INFO  - Validation [56][   20/   40]   Loss 0.418194   Top1 90.312500   Top5 99.667969   BatchTime 0.144108   
2022-11-04 03:34:03,380 - INFO  - Validation [56][   40/   40]   Loss 0.413063   Top1 90.260000   Top5 99.710000   BatchTime 0.099868   
2022-11-04 03:34:03,637 - INFO  - ==> Top1: 90.260    Top5: 99.710    Loss: 0.413

2022-11-04 03:34:03,673 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:34:03,673 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:34:03,674 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:34:03,780 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:34:03,780 - INFO  - >>>>>>>> Epoch  57
2022-11-04 03:34:03,781 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:34:08,178 - INFO  - Training [57][   20/  196]   Loss 0.034913   Top1 98.828125   Top5 100.000000   BatchTime 0.219800   LR 0.001000   
2022-11-04 03:34:10,643 - INFO  - Training [57][   40/  196]   Loss 0.034749   Top1 98.808594   Top5 100.000000   BatchTime 0.171540   LR 0.001000   
2022-11-04 03:34:13,112 - INFO  - Training [57][   60/  196]   Loss 0.035460   Top1 98.808594   Top5 100.000000   BatchTime 0.155509   LR 0.001000   
2022-11-04 03:34:15,585 - INFO  - Training [57][   80/  196]   Loss 0.037606   Top1 98.701172   Top5 100.000000   BatchTime 0.147547   LR 0.001000   
2022-11-04 03:34:18,044 - INFO  - Training [57][  100/  196]   Loss 0.038761   Top1 98.648438   Top5 100.000000   BatchTime 0.142626   LR 0.001000   
2022-11-04 03:34:20,504 - INFO  - Training [57][  120/  196]   Loss 0.038445   Top1 98.655599   Top5 100.000000   BatchTime 0.139355   LR 0.001000   
2022-11-04 03:34:22,961 - INFO  - Training [57][  140/  196]   Loss 0.038479   Top1 98.663504   Top5 100.000000   BatchTime 0.136996   LR 0.001000   
2022-11-04 03:34:24,904 - INFO  - Training [57][  160/  196]   Loss 0.038747   Top1 98.652344   Top5 100.000000   BatchTime 0.132012   LR 0.001000   
2022-11-04 03:34:26,846 - INFO  - Training [57][  180/  196]   Loss 0.039357   Top1 98.628472   Top5 100.000000   BatchTime 0.128135   LR 0.001000   
2022-11-04 03:34:28,674 - INFO  - ==> Top1: 98.614    Top5: 100.000    Loss: 0.039

2022-11-04 03:34:28,674 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:34:31,313 - INFO  - Validation [57][   20/   40]   Loss 0.416904   Top1 90.136719   Top5 99.687500   BatchTime 0.131898   
2022-11-04 03:34:32,365 - INFO  - Validation [57][   40/   40]   Loss 0.410869   Top1 90.330000   Top5 99.720000   BatchTime 0.092236   
2022-11-04 03:34:32,627 - INFO  - ==> Top1: 90.330    Top5: 99.720    Loss: 0.411

2022-11-04 03:34:32,654 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:34:32,654 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:34:32,655 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:34:32,745 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:34:32,746 - INFO  - >>>>>>>> Epoch  58
2022-11-04 03:34:32,747 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:34:37,176 - INFO  - Training [58][   20/  196]   Loss 0.034288   Top1 98.906250   Top5 99.980469   BatchTime 0.221432   LR 0.001000   
2022-11-04 03:34:39,654 - INFO  - Training [58][   40/  196]   Loss 0.035711   Top1 98.750000   Top5 99.990234   BatchTime 0.172658   LR 0.001000   
2022-11-04 03:34:42,118 - INFO  - Training [58][   60/  196]   Loss 0.037296   Top1 98.730469   Top5 99.993490   BatchTime 0.156175   LR 0.001000   
2022-11-04 03:34:44,598 - INFO  - Training [58][   80/  196]   Loss 0.036887   Top1 98.745117   Top5 99.995117   BatchTime 0.148126   LR 0.001000   
2022-11-04 03:34:47,072 - INFO  - Training [58][  100/  196]   Loss 0.036747   Top1 98.730469   Top5 99.996094   BatchTime 0.143246   LR 0.001000   
2022-11-04 03:34:49,538 - INFO  - Training [58][  120/  196]   Loss 0.036927   Top1 98.681641   Top5 99.996745   BatchTime 0.139921   LR 0.001000   
2022-11-04 03:34:52,007 - INFO  - Training [58][  140/  196]   Loss 0.037617   Top1 98.677455   Top5 99.997210   BatchTime 0.137562   LR 0.001000   
2022-11-04 03:34:54,453 - INFO  - Training [58][  160/  196]   Loss 0.038171   Top1 98.654785   Top5 99.997559   BatchTime 0.135654   LR 0.001000   
2022-11-04 03:34:56,910 - INFO  - Training [58][  180/  196]   Loss 0.038530   Top1 98.658854   Top5 99.997830   BatchTime 0.134234   LR 0.001000   
2022-11-04 03:34:59,069 - INFO  - ==> Top1: 98.644    Top5: 99.998    Loss: 0.039

2022-11-04 03:34:59,070 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:35:01,951 - INFO  - Validation [58][   20/   40]   Loss 0.420231   Top1 90.156250   Top5 99.628906   BatchTime 0.143996   
2022-11-04 03:35:03,006 - INFO  - Validation [58][   40/   40]   Loss 0.407195   Top1 90.300000   Top5 99.700000   BatchTime 0.098376   
2022-11-04 03:35:03,252 - INFO  - ==> Top1: 90.300    Top5: 99.700    Loss: 0.407

2022-11-04 03:35:03,282 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:35:03,282 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:35:03,283 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:35:03,400 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:35:03,400 - INFO  - >>>>>>>> Epoch  59
2022-11-04 03:35:03,402 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:35:07,793 - INFO  - Training [59][   20/  196]   Loss 0.032957   Top1 98.886719   Top5 100.000000   BatchTime 0.219531   LR 0.001000   
2022-11-04 03:35:10,251 - INFO  - Training [59][   40/  196]   Loss 0.036004   Top1 98.779297   Top5 100.000000   BatchTime 0.171215   LR 0.001000   
2022-11-04 03:35:12,848 - INFO  - Training [59][   60/  196]   Loss 0.036128   Top1 98.743490   Top5 100.000000   BatchTime 0.157435   LR 0.001000   
2022-11-04 03:35:15,302 - INFO  - Training [59][   80/  196]   Loss 0.035856   Top1 98.745117   Top5 100.000000   BatchTime 0.148753   LR 0.001000   
2022-11-04 03:35:17,327 - INFO  - Training [59][  100/  196]   Loss 0.037133   Top1 98.746094   Top5 100.000000   BatchTime 0.139246   LR 0.001000   
2022-11-04 03:35:19,324 - INFO  - Training [59][  120/  196]   Loss 0.037487   Top1 98.743490   Top5 100.000000   BatchTime 0.132682   LR 0.001000   
2022-11-04 03:35:21,341 - INFO  - Training [59][  140/  196]   Loss 0.037442   Top1 98.738839   Top5 100.000000   BatchTime 0.128135   LR 0.001000   
2022-11-04 03:35:23,359 - INFO  - Training [59][  160/  196]   Loss 0.038355   Top1 98.696289   Top5 100.000000   BatchTime 0.124730   LR 0.001000   
2022-11-04 03:35:25,038 - INFO  - Training [59][  180/  196]   Loss 0.038615   Top1 98.674045   Top5 100.000000   BatchTime 0.120196   LR 0.001000   
2022-11-04 03:35:27,172 - INFO  - ==> Top1: 98.682    Top5: 100.000    Loss: 0.038

2022-11-04 03:35:27,172 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:35:30,085 - INFO  - Validation [59][   20/   40]   Loss 0.417847   Top1 90.273438   Top5 99.648438   BatchTime 0.145558   
2022-11-04 03:35:31,219 - INFO  - Validation [59][   40/   40]   Loss 0.410295   Top1 90.440000   Top5 99.690000   BatchTime 0.101145   
2022-11-04 03:35:31,482 - INFO  - ==> Top1: 90.440    Top5: 99.690    Loss: 0.410

2022-11-04 03:35:31,513 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:35:31,514 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:35:31,514 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:35:31,624 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:35:31,625 - INFO  - >>>>>>>> Epoch  60
2022-11-04 03:35:31,626 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:35:36,015 - INFO  - Training [60][   20/  196]   Loss 0.038664   Top1 98.652344   Top5 100.000000   BatchTime 0.219401   LR 0.000100   
2022-11-04 03:35:38,482 - INFO  - Training [60][   40/  196]   Loss 0.036266   Top1 98.710938   Top5 100.000000   BatchTime 0.171376   LR 0.000100   
2022-11-04 03:35:40,957 - INFO  - Training [60][   60/  196]   Loss 0.037412   Top1 98.658854   Top5 100.000000   BatchTime 0.155515   LR 0.000100   
2022-11-04 03:35:43,431 - INFO  - Training [60][   80/  196]   Loss 0.038154   Top1 98.637695   Top5 100.000000   BatchTime 0.147556   LR 0.000100   
2022-11-04 03:35:45,894 - INFO  - Training [60][  100/  196]   Loss 0.037206   Top1 98.667969   Top5 100.000000   BatchTime 0.142669   LR 0.000100   
2022-11-04 03:35:48,349 - INFO  - Training [60][  120/  196]   Loss 0.037544   Top1 98.671875   Top5 100.000000   BatchTime 0.139355   LR 0.000100   
2022-11-04 03:35:50,809 - INFO  - Training [60][  140/  196]   Loss 0.038167   Top1 98.663504   Top5 99.994420   BatchTime 0.137014   LR 0.000100   
2022-11-04 03:35:53,272 - INFO  - Training [60][  160/  196]   Loss 0.038104   Top1 98.688965   Top5 99.995117   BatchTime 0.135283   LR 0.000100   
2022-11-04 03:35:55,731 - INFO  - Training [60][  180/  196]   Loss 0.038019   Top1 98.691406   Top5 99.995660   BatchTime 0.133911   LR 0.000100   
2022-11-04 03:35:57,916 - INFO  - ==> Top1: 98.692    Top5: 99.996    Loss: 0.038

2022-11-04 03:35:57,917 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:36:00,786 - INFO  - Validation [60][   20/   40]   Loss 0.419013   Top1 90.273438   Top5 99.687500   BatchTime 0.143416   
2022-11-04 03:36:01,917 - INFO  - Validation [60][   40/   40]   Loss 0.408947   Top1 90.440000   Top5 99.710000   BatchTime 0.099977   
2022-11-04 03:36:02,173 - INFO  - ==> Top1: 90.440    Top5: 99.710    Loss: 0.409

2022-11-04 03:36:02,200 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:36:02,201 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:36:02,201 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:36:02,304 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:36:02,304 - INFO  - >>>>>>>> Epoch  61
2022-11-04 03:36:02,306 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:36:06,651 - INFO  - Training [61][   20/  196]   Loss 0.038584   Top1 98.632812   Top5 100.000000   BatchTime 0.217258   LR 0.000100   
2022-11-04 03:36:08,875 - INFO  - Training [61][   40/  196]   Loss 0.037016   Top1 98.671875   Top5 100.000000   BatchTime 0.164239   LR 0.000100   
2022-11-04 03:36:10,783 - INFO  - Training [61][   60/  196]   Loss 0.036026   Top1 98.736979   Top5 100.000000   BatchTime 0.141290   LR 0.000100   
2022-11-04 03:36:12,818 - INFO  - Training [61][   80/  196]   Loss 0.036272   Top1 98.735352   Top5 100.000000   BatchTime 0.131399   LR 0.000100   
2022-11-04 03:36:14,869 - INFO  - Training [61][  100/  196]   Loss 0.038105   Top1 98.648438   Top5 100.000000   BatchTime 0.125632   LR 0.000100   
2022-11-04 03:36:16,695 - INFO  - Training [61][  120/  196]   Loss 0.037960   Top1 98.668620   Top5 100.000000   BatchTime 0.119907   LR 0.000100   
2022-11-04 03:36:19,009 - INFO  - Training [61][  140/  196]   Loss 0.037974   Top1 98.699777   Top5 100.000000   BatchTime 0.119309   LR 0.000100   
2022-11-04 03:36:21,460 - INFO  - Training [61][  160/  196]   Loss 0.038092   Top1 98.715820   Top5 99.997559   BatchTime 0.119712   LR 0.000100   
2022-11-04 03:36:23,913 - INFO  - Training [61][  180/  196]   Loss 0.038400   Top1 98.704427   Top5 99.997830   BatchTime 0.120038   LR 0.000100   
2022-11-04 03:36:26,074 - INFO  - ==> Top1: 98.706    Top5: 99.998    Loss: 0.038

2022-11-04 03:36:26,075 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:36:28,967 - INFO  - Validation [61][   20/   40]   Loss 0.417956   Top1 90.253906   Top5 99.667969   BatchTime 0.144509   
2022-11-04 03:36:30,066 - INFO  - Validation [61][   40/   40]   Loss 0.408508   Top1 90.360000   Top5 99.720000   BatchTime 0.099731   
2022-11-04 03:36:30,314 - INFO  - ==> Top1: 90.360    Top5: 99.720    Loss: 0.409

2022-11-04 03:36:30,354 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:36:30,355 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:36:30,355 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:36:30,472 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:36:30,472 - INFO  - >>>>>>>> Epoch  62
2022-11-04 03:36:30,473 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:36:34,867 - INFO  - Training [62][   20/  196]   Loss 0.041208   Top1 98.613281   Top5 100.000000   BatchTime 0.219682   LR 0.000100   
2022-11-04 03:36:37,335 - INFO  - Training [62][   40/  196]   Loss 0.040768   Top1 98.593750   Top5 100.000000   BatchTime 0.171545   LR 0.000100   
2022-11-04 03:36:39,802 - INFO  - Training [62][   60/  196]   Loss 0.039793   Top1 98.652344   Top5 100.000000   BatchTime 0.155475   LR 0.000100   
2022-11-04 03:36:42,283 - INFO  - Training [62][   80/  196]   Loss 0.039444   Top1 98.671875   Top5 100.000000   BatchTime 0.147610   LR 0.000100   
2022-11-04 03:36:44,758 - INFO  - Training [62][  100/  196]   Loss 0.039632   Top1 98.636719   Top5 100.000000   BatchTime 0.142845   LR 0.000100   
2022-11-04 03:36:47,226 - INFO  - Training [62][  120/  196]   Loss 0.040026   Top1 98.636068   Top5 100.000000   BatchTime 0.139603   LR 0.000100   
2022-11-04 03:36:49,688 - INFO  - Training [62][  140/  196]   Loss 0.039277   Top1 98.674665   Top5 100.000000   BatchTime 0.137244   LR 0.000100   
2022-11-04 03:36:52,147 - INFO  - Training [62][  160/  196]   Loss 0.038924   Top1 98.684082   Top5 100.000000   BatchTime 0.135458   LR 0.000100   
2022-11-04 03:36:54,604 - INFO  - Training [62][  180/  196]   Loss 0.038612   Top1 98.695747   Top5 100.000000   BatchTime 0.134057   LR 0.000100   
2022-11-04 03:36:56,729 - INFO  - ==> Top1: 98.710    Top5: 100.000    Loss: 0.038

2022-11-04 03:36:56,729 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:36:59,610 - INFO  - Validation [62][   20/   40]   Loss 0.422488   Top1 90.292969   Top5 99.570312   BatchTime 0.143958   
2022-11-04 03:37:00,738 - INFO  - Validation [62][   40/   40]   Loss 0.408844   Top1 90.480000   Top5 99.650000   BatchTime 0.100187   
2022-11-04 03:37:00,982 - INFO  - ==> Top1: 90.480    Top5: 99.650    Loss: 0.409

2022-11-04 03:37:01,014 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:37:01,015 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:37:01,015 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:37:01,123 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:37:01,123 - INFO  - >>>>>>>> Epoch  63
2022-11-04 03:37:01,124 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:37:05,350 - INFO  - Training [63][   20/  196]   Loss 0.035728   Top1 98.906250   Top5 100.000000   BatchTime 0.211250   LR 0.000100   
2022-11-04 03:37:07,381 - INFO  - Training [63][   40/  196]   Loss 0.037513   Top1 98.720703   Top5 100.000000   BatchTime 0.156414   LR 0.000100   
2022-11-04 03:37:09,482 - INFO  - Training [63][   60/  196]   Loss 0.037165   Top1 98.671875   Top5 99.993490   BatchTime 0.139287   LR 0.000100   
2022-11-04 03:37:11,632 - INFO  - Training [63][   80/  196]   Loss 0.036891   Top1 98.720703   Top5 99.995117   BatchTime 0.131340   LR 0.000100   
2022-11-04 03:37:14,097 - INFO  - Training [63][  100/  196]   Loss 0.037935   Top1 98.703125   Top5 99.996094   BatchTime 0.129717   LR 0.000100   
2022-11-04 03:37:16,566 - INFO  - Training [63][  120/  196]   Loss 0.038782   Top1 98.678385   Top5 99.996745   BatchTime 0.128675   LR 0.000100   
2022-11-04 03:37:19,039 - INFO  - Training [63][  140/  196]   Loss 0.038856   Top1 98.660714   Top5 99.997210   BatchTime 0.127960   LR 0.000100   
2022-11-04 03:37:21,497 - INFO  - Training [63][  160/  196]   Loss 0.038991   Top1 98.666992   Top5 99.997559   BatchTime 0.127324   LR 0.000100   
2022-11-04 03:37:23,961 - INFO  - Training [63][  180/  196]   Loss 0.038806   Top1 98.669705   Top5 99.997830   BatchTime 0.126864   LR 0.000100   
2022-11-04 03:37:26,150 - INFO  - ==> Top1: 98.672    Top5: 99.998    Loss: 0.039

2022-11-04 03:37:26,151 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:37:29,013 - INFO  - Validation [63][   20/   40]   Loss 0.418542   Top1 90.390625   Top5 99.687500   BatchTime 0.143017   
2022-11-04 03:37:30,113 - INFO  - Validation [63][   40/   40]   Loss 0.411224   Top1 90.320000   Top5 99.710000   BatchTime 0.099019   
2022-11-04 03:37:30,375 - INFO  - ==> Top1: 90.320    Top5: 99.710    Loss: 0.411

2022-11-04 03:37:30,416 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:37:30,417 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:37:30,417 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.480   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:37:30,534 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:37:30,535 - INFO  - >>>>>>>> Epoch  64
2022-11-04 03:37:30,536 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:37:34,938 - INFO  - Training [64][   20/  196]   Loss 0.034640   Top1 98.710938   Top5 100.000000   BatchTime 0.220061   LR 0.000100   
2022-11-04 03:37:37,402 - INFO  - Training [64][   40/  196]   Loss 0.036177   Top1 98.691406   Top5 100.000000   BatchTime 0.171650   LR 0.000100   
2022-11-04 03:37:39,873 - INFO  - Training [64][   60/  196]   Loss 0.034705   Top1 98.763021   Top5 100.000000   BatchTime 0.155609   LR 0.000100   
2022-11-04 03:37:42,340 - INFO  - Training [64][   80/  196]   Loss 0.035787   Top1 98.759766   Top5 100.000000   BatchTime 0.147549   LR 0.000100   
2022-11-04 03:37:44,810 - INFO  - Training [64][  100/  196]   Loss 0.035639   Top1 98.796875   Top5 99.992188   BatchTime 0.142732   LR 0.000100   
2022-11-04 03:37:47,294 - INFO  - Training [64][  120/  196]   Loss 0.035831   Top1 98.772786   Top5 99.993490   BatchTime 0.139647   LR 0.000100   
2022-11-04 03:37:49,747 - INFO  - Training [64][  140/  196]   Loss 0.035813   Top1 98.780692   Top5 99.994420   BatchTime 0.137214   LR 0.000100   
2022-11-04 03:37:52,192 - INFO  - Training [64][  160/  196]   Loss 0.036580   Top1 98.759766   Top5 99.995117   BatchTime 0.135348   LR 0.000100   
2022-11-04 03:37:54,645 - INFO  - Training [64][  180/  196]   Loss 0.036985   Top1 98.754340   Top5 99.995660   BatchTime 0.133937   LR 0.000100   
2022-11-04 03:37:56,743 - INFO  - ==> Top1: 98.708    Top5: 99.996    Loss: 0.038

2022-11-04 03:37:56,744 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:37:59,472 - INFO  - Validation [64][   20/   40]   Loss 0.417539   Top1 90.429688   Top5 99.589844   BatchTime 0.136299   
2022-11-04 03:38:00,325 - INFO  - Validation [64][   40/   40]   Loss 0.408609   Top1 90.490000   Top5 99.670000   BatchTime 0.089474   
2022-11-04 03:38:00,570 - INFO  - ==> Top1: 90.490    Top5: 99.670    Loss: 0.409

2022-11-04 03:38:00,603 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:38:00,604 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:38:00,604 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 90.490   Top5: 99.670] Sparsity : 0.892
2022-11-04 03:38:00,709 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:38:00,710 - INFO  - >>>>>>>> Epoch  65
2022-11-04 03:38:00,711 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:38:05,092 - INFO  - Training [65][   20/  196]   Loss 0.033540   Top1 99.003906   Top5 100.000000   BatchTime 0.219057   LR 0.000100   
2022-11-04 03:38:07,568 - INFO  - Training [65][   40/  196]   Loss 0.032856   Top1 98.925781   Top5 100.000000   BatchTime 0.171405   LR 0.000100   
2022-11-04 03:38:10,048 - INFO  - Training [65][   60/  196]   Loss 0.034242   Top1 98.880208   Top5 100.000000   BatchTime 0.155613   LR 0.000100   
2022-11-04 03:38:12,528 - INFO  - Training [65][   80/  196]   Loss 0.034243   Top1 98.881836   Top5 100.000000   BatchTime 0.147712   LR 0.000100   
2022-11-04 03:38:15,007 - INFO  - Training [65][  100/  196]   Loss 0.035285   Top1 98.835938   Top5 100.000000   BatchTime 0.142956   LR 0.000100   
2022-11-04 03:38:17,492 - INFO  - Training [65][  120/  196]   Loss 0.036114   Top1 98.802083   Top5 100.000000   BatchTime 0.139834   LR 0.000100   
2022-11-04 03:38:19,962 - INFO  - Training [65][  140/  196]   Loss 0.035410   Top1 98.825335   Top5 100.000000   BatchTime 0.137501   LR 0.000100   
2022-11-04 03:38:22,419 - INFO  - Training [65][  160/  196]   Loss 0.035903   Top1 98.784180   Top5 100.000000   BatchTime 0.135672   LR 0.000100   
2022-11-04 03:38:24,872 - INFO  - Training [65][  180/  196]   Loss 0.036116   Top1 98.767361   Top5 100.000000   BatchTime 0.134226   LR 0.000100   
2022-11-04 03:38:27,040 - INFO  - ==> Top1: 98.764    Top5: 100.000    Loss: 0.036

2022-11-04 03:38:27,041 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:38:29,959 - INFO  - Validation [65][   20/   40]   Loss 0.421326   Top1 90.429688   Top5 99.687500   BatchTime 0.145854   
2022-11-04 03:38:31,073 - INFO  - Validation [65][   40/   40]   Loss 0.410774   Top1 90.470000   Top5 99.730000   BatchTime 0.100776   
2022-11-04 03:38:31,337 - INFO  - ==> Top1: 90.470    Top5: 99.730    Loss: 0.411

2022-11-04 03:38:31,378 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:38:31,379 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:38:31,379 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 90.490   Top5: 99.670] Sparsity : 0.892
2022-11-04 03:38:31,487 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:38:31,487 - INFO  - >>>>>>>> Epoch  66
2022-11-04 03:38:31,488 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:38:35,821 - INFO  - Training [66][   20/  196]   Loss 0.032669   Top1 98.789062   Top5 100.000000   BatchTime 0.216627   LR 0.000100   
2022-11-04 03:38:38,288 - INFO  - Training [66][   40/  196]   Loss 0.034963   Top1 98.867188   Top5 100.000000   BatchTime 0.169997   LR 0.000100   
2022-11-04 03:38:40,758 - INFO  - Training [66][   60/  196]   Loss 0.035578   Top1 98.815104   Top5 100.000000   BatchTime 0.154502   LR 0.000100   
2022-11-04 03:38:43,218 - INFO  - Training [66][   80/  196]   Loss 0.036142   Top1 98.789062   Top5 100.000000   BatchTime 0.146617   LR 0.000100   
2022-11-04 03:38:45,682 - INFO  - Training [66][  100/  196]   Loss 0.036195   Top1 98.804688   Top5 99.996094   BatchTime 0.141934   LR 0.000100   
2022-11-04 03:38:48,141 - INFO  - Training [66][  120/  196]   Loss 0.036156   Top1 98.824870   Top5 99.996745   BatchTime 0.138772   LR 0.000100   
2022-11-04 03:38:50,205 - INFO  - Training [66][  140/  196]   Loss 0.035751   Top1 98.844866   Top5 99.997210   BatchTime 0.133689   LR 0.000100   
2022-11-04 03:38:52,128 - INFO  - Training [66][  160/  196]   Loss 0.035547   Top1 98.837891   Top5 99.997559   BatchTime 0.128998   LR 0.000100   
2022-11-04 03:38:54,134 - INFO  - Training [66][  180/  196]   Loss 0.035944   Top1 98.825955   Top5 99.997830   BatchTime 0.125810   LR 0.000100   
2022-11-04 03:38:56,079 - INFO  - ==> Top1: 98.842    Top5: 99.998    Loss: 0.035

2022-11-04 03:38:56,081 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:38:58,849 - INFO  - Validation [66][   20/   40]   Loss 0.419670   Top1 90.371094   Top5 99.687500   BatchTime 0.138309   
2022-11-04 03:38:59,699 - INFO  - Validation [66][   40/   40]   Loss 0.408838   Top1 90.520000   Top5 99.750000   BatchTime 0.090405   
2022-11-04 03:38:59,955 - INFO  - ==> Top1: 90.520    Top5: 99.750    Loss: 0.409

2022-11-04 03:38:59,986 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:38:59,987 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:38:59,987 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:39:00,098 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:39:00,099 - INFO  - >>>>>>>> Epoch  67
2022-11-04 03:39:00,100 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:39:03,804 - INFO  - Training [67][   20/  196]   Loss 0.035116   Top1 98.750000   Top5 100.000000   BatchTime 0.185170   LR 0.000100   
2022-11-04 03:39:05,491 - INFO  - Training [67][   40/  196]   Loss 0.032762   Top1 98.867188   Top5 100.000000   BatchTime 0.134765   LR 0.000100   
2022-11-04 03:39:07,174 - INFO  - Training [67][   60/  196]   Loss 0.034873   Top1 98.795573   Top5 100.000000   BatchTime 0.117892   LR 0.000100   
2022-11-04 03:39:08,984 - INFO  - Training [67][   80/  196]   Loss 0.035176   Top1 98.759766   Top5 100.000000   BatchTime 0.111046   LR 0.000100   
2022-11-04 03:39:10,715 - INFO  - Training [67][  100/  196]   Loss 0.036057   Top1 98.738281   Top5 99.996094   BatchTime 0.106143   LR 0.000100   
2022-11-04 03:39:12,393 - INFO  - Training [67][  120/  196]   Loss 0.035817   Top1 98.756510   Top5 99.996745   BatchTime 0.102432   LR 0.000100   
2022-11-04 03:39:14,076 - INFO  - Training [67][  140/  196]   Loss 0.035374   Top1 98.777902   Top5 99.997210   BatchTime 0.099822   LR 0.000100   
2022-11-04 03:39:15,742 - INFO  - Training [67][  160/  196]   Loss 0.035640   Top1 98.762207   Top5 99.997559   BatchTime 0.097758   LR 0.000100   
2022-11-04 03:39:17,491 - INFO  - Training [67][  180/  196]   Loss 0.035635   Top1 98.760851   Top5 99.997830   BatchTime 0.096612   LR 0.000100   
2022-11-04 03:39:19,172 - INFO  - ==> Top1: 98.778    Top5: 99.998    Loss: 0.035

2022-11-04 03:39:19,173 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:39:22,124 - INFO  - Validation [67][   20/   40]   Loss 0.424181   Top1 90.253906   Top5 99.628906   BatchTime 0.147521   
2022-11-04 03:39:23,120 - INFO  - Validation [67][   40/   40]   Loss 0.412139   Top1 90.440000   Top5 99.680000   BatchTime 0.098646   
2022-11-04 03:39:23,378 - INFO  - ==> Top1: 90.440    Top5: 99.680    Loss: 0.412

2022-11-04 03:39:23,406 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:39:23,407 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:39:23,407 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:39:23,512 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:39:23,512 - INFO  - >>>>>>>> Epoch  68
2022-11-04 03:39:23,514 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:39:28,654 - INFO  - Training [68][   20/  196]   Loss 0.033344   Top1 98.964844   Top5 100.000000   BatchTime 0.257001   LR 0.000100   
2022-11-04 03:39:31,679 - INFO  - Training [68][   40/  196]   Loss 0.037819   Top1 98.798828   Top5 100.000000   BatchTime 0.204129   LR 0.000100   
2022-11-04 03:39:34,702 - INFO  - Training [68][   60/  196]   Loss 0.038150   Top1 98.717448   Top5 100.000000   BatchTime 0.186461   LR 0.000100   
2022-11-04 03:39:37,733 - INFO  - Training [68][   80/  196]   Loss 0.037642   Top1 98.735352   Top5 100.000000   BatchTime 0.177742   LR 0.000100   
2022-11-04 03:39:40,742 - INFO  - Training [68][  100/  196]   Loss 0.037182   Top1 98.746094   Top5 100.000000   BatchTime 0.172279   LR 0.000100   
2022-11-04 03:39:43,778 - INFO  - Training [68][  120/  196]   Loss 0.038959   Top1 98.665365   Top5 99.996745   BatchTime 0.168861   LR 0.000100   
2022-11-04 03:39:46,777 - INFO  - Training [68][  140/  196]   Loss 0.038856   Top1 98.660714   Top5 99.997210   BatchTime 0.166161   LR 0.000100   
2022-11-04 03:39:49,757 - INFO  - Training [68][  160/  196]   Loss 0.038535   Top1 98.671875   Top5 99.997559   BatchTime 0.164015   LR 0.000100   
2022-11-04 03:39:52,754 - INFO  - Training [68][  180/  196]   Loss 0.038782   Top1 98.667535   Top5 99.997830   BatchTime 0.162443   LR 0.000100   
2022-11-04 03:39:55,343 - INFO  - ==> Top1: 98.666    Top5: 99.998    Loss: 0.039

2022-11-04 03:39:55,344 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:39:58,049 - INFO  - Validation [68][   20/   40]   Loss 0.418660   Top1 90.410156   Top5 99.609375   BatchTime 0.135180   
2022-11-04 03:39:59,059 - INFO  - Validation [68][   40/   40]   Loss 0.413305   Top1 90.420000   Top5 99.710000   BatchTime 0.092852   
2022-11-04 03:39:59,322 - INFO  - ==> Top1: 90.420    Top5: 99.710    Loss: 0.413

2022-11-04 03:39:59,360 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:39:59,361 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:39:59,361 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:39:59,463 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:39:59,464 - INFO  - >>>>>>>> Epoch  69
2022-11-04 03:39:59,465 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:40:04,311 - INFO  - Training [69][   20/  196]   Loss 0.036458   Top1 98.730469   Top5 100.000000   BatchTime 0.242295   LR 0.000100   
2022-11-04 03:40:07,334 - INFO  - Training [69][   40/  196]   Loss 0.035594   Top1 98.691406   Top5 100.000000   BatchTime 0.196709   LR 0.000100   
2022-11-04 03:40:10,367 - INFO  - Training [69][   60/  196]   Loss 0.034653   Top1 98.802083   Top5 100.000000   BatchTime 0.181701   LR 0.000100   
2022-11-04 03:40:13,386 - INFO  - Training [69][   80/  196]   Loss 0.035453   Top1 98.764648   Top5 100.000000   BatchTime 0.174014   LR 0.000100   
2022-11-04 03:40:16,415 - INFO  - Training [69][  100/  196]   Loss 0.035168   Top1 98.781250   Top5 100.000000   BatchTime 0.169494   LR 0.000100   
2022-11-04 03:40:19,323 - INFO  - Training [69][  120/  196]   Loss 0.035510   Top1 98.779297   Top5 100.000000   BatchTime 0.165482   LR 0.000100   
2022-11-04 03:40:22,357 - INFO  - Training [69][  140/  196]   Loss 0.036336   Top1 98.733259   Top5 100.000000   BatchTime 0.163511   LR 0.000100   
2022-11-04 03:40:25,349 - INFO  - Training [69][  160/  196]   Loss 0.036683   Top1 98.730469   Top5 100.000000   BatchTime 0.161770   LR 0.000100   
2022-11-04 03:40:28,344 - INFO  - Training [69][  180/  196]   Loss 0.036350   Top1 98.750000   Top5 100.000000   BatchTime 0.160437   LR 0.000100   
2022-11-04 03:40:30,908 - INFO  - ==> Top1: 98.764    Top5: 100.000    Loss: 0.036

2022-11-04 03:40:30,908 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:40:33,656 - INFO  - Validation [69][   20/   40]   Loss 0.419779   Top1 90.332031   Top5 99.609375   BatchTime 0.137331   
2022-11-04 03:40:34,661 - INFO  - Validation [69][   40/   40]   Loss 0.408472   Top1 90.410000   Top5 99.700000   BatchTime 0.093782   
2022-11-04 03:40:34,916 - INFO  - ==> Top1: 90.410    Top5: 99.700    Loss: 0.408

2022-11-04 03:40:34,957 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:40:34,957 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:40:34,957 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:40:35,096 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:40:35,096 - INFO  - >>>>>>>> Epoch  70
2022-11-04 03:40:35,097 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:40:39,922 - INFO  - Training [70][   20/  196]   Loss 0.033535   Top1 98.945312   Top5 100.000000   BatchTime 0.241221   LR 0.000010   
2022-11-04 03:40:42,948 - INFO  - Training [70][   40/  196]   Loss 0.035088   Top1 98.847656   Top5 100.000000   BatchTime 0.196271   LR 0.000010   
2022-11-04 03:40:45,960 - INFO  - Training [70][   60/  196]   Loss 0.036775   Top1 98.717448   Top5 100.000000   BatchTime 0.181046   LR 0.000010   
2022-11-04 03:40:48,983 - INFO  - Training [70][   80/  196]   Loss 0.037667   Top1 98.715820   Top5 100.000000   BatchTime 0.173561   LR 0.000010   
2022-11-04 03:40:51,999 - INFO  - Training [70][  100/  196]   Loss 0.037916   Top1 98.707031   Top5 100.000000   BatchTime 0.169013   LR 0.000010   
2022-11-04 03:40:55,028 - INFO  - Training [70][  120/  196]   Loss 0.037453   Top1 98.710938   Top5 100.000000   BatchTime 0.166086   LR 0.000010   
2022-11-04 03:40:58,045 - INFO  - Training [70][  140/  196]   Loss 0.037330   Top1 98.736049   Top5 100.000000   BatchTime 0.163909   LR 0.000010   
2022-11-04 03:41:01,044 - INFO  - Training [70][  160/  196]   Loss 0.037557   Top1 98.725586   Top5 99.997559   BatchTime 0.162162   LR 0.000010   
2022-11-04 03:41:04,038 - INFO  - Training [70][  180/  196]   Loss 0.037508   Top1 98.750000   Top5 99.997830   BatchTime 0.160779   LR 0.000010   
2022-11-04 03:41:06,604 - INFO  - ==> Top1: 98.746    Top5: 99.998    Loss: 0.038

2022-11-04 03:41:06,604 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:41:09,298 - INFO  - Validation [70][   20/   40]   Loss 0.420866   Top1 90.234375   Top5 99.648438   BatchTime 0.134605   
2022-11-04 03:41:10,293 - INFO  - Validation [70][   40/   40]   Loss 0.409148   Top1 90.450000   Top5 99.720000   BatchTime 0.092202   
2022-11-04 03:41:10,548 - INFO  - ==> Top1: 90.450    Top5: 99.720    Loss: 0.409

2022-11-04 03:41:10,588 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:41:10,588 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:41:10,589 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:41:10,697 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:41:10,697 - INFO  - >>>>>>>> Epoch  71
2022-11-04 03:41:10,698 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:41:15,298 - INFO  - Training [71][   20/  196]   Loss 0.038427   Top1 98.710938   Top5 100.000000   BatchTime 0.230002   LR 0.000010   
2022-11-04 03:41:18,315 - INFO  - Training [71][   40/  196]   Loss 0.040021   Top1 98.593750   Top5 99.990234   BatchTime 0.190421   LR 0.000010   
2022-11-04 03:41:21,356 - INFO  - Training [71][   60/  196]   Loss 0.038496   Top1 98.652344   Top5 99.993490   BatchTime 0.177623   LR 0.000010   
2022-11-04 03:41:24,372 - INFO  - Training [71][   80/  196]   Loss 0.039126   Top1 98.613281   Top5 99.995117   BatchTime 0.170917   LR 0.000010   
2022-11-04 03:41:27,394 - INFO  - Training [71][  100/  196]   Loss 0.039294   Top1 98.609375   Top5 99.996094   BatchTime 0.166961   LR 0.000010   
2022-11-04 03:41:30,477 - INFO  - Training [71][  120/  196]   Loss 0.038402   Top1 98.652344   Top5 99.996745   BatchTime 0.164825   LR 0.000010   
2022-11-04 03:41:33,501 - INFO  - Training [71][  140/  196]   Loss 0.037909   Top1 98.677455   Top5 99.997210   BatchTime 0.162876   LR 0.000010   
2022-11-04 03:41:36,496 - INFO  - Training [71][  160/  196]   Loss 0.038092   Top1 98.676758   Top5 99.997559   BatchTime 0.161236   LR 0.000010   
2022-11-04 03:41:39,495 - INFO  - Training [71][  180/  196]   Loss 0.038083   Top1 98.669705   Top5 99.997830   BatchTime 0.159979   LR 0.000010   
2022-11-04 03:41:42,077 - INFO  - ==> Top1: 98.692    Top5: 99.998    Loss: 0.038

2022-11-04 03:41:42,078 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:41:44,708 - INFO  - Validation [71][   20/   40]   Loss 0.418342   Top1 90.195312   Top5 99.648438   BatchTime 0.131354   
2022-11-04 03:41:45,724 - INFO  - Validation [71][   40/   40]   Loss 0.408723   Top1 90.360000   Top5 99.710000   BatchTime 0.091084   
2022-11-04 03:41:45,977 - INFO  - ==> Top1: 90.360    Top5: 99.710    Loss: 0.409

2022-11-04 03:41:46,014 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:41:46,015 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:41:46,015 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:41:46,100 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:41:46,100 - INFO  - >>>>>>>> Epoch  72
2022-11-04 03:41:46,101 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:41:50,756 - INFO  - Training [72][   20/  196]   Loss 0.037937   Top1 98.613281   Top5 100.000000   BatchTime 0.232738   LR 0.000010   
2022-11-04 03:41:53,772 - INFO  - Training [72][   40/  196]   Loss 0.037902   Top1 98.652344   Top5 100.000000   BatchTime 0.191750   LR 0.000010   
2022-11-04 03:41:56,790 - INFO  - Training [72][   60/  196]   Loss 0.036802   Top1 98.691406   Top5 100.000000   BatchTime 0.178142   LR 0.000010   
2022-11-04 03:41:59,814 - INFO  - Training [72][   80/  196]   Loss 0.037403   Top1 98.681641   Top5 100.000000   BatchTime 0.171403   LR 0.000010   
2022-11-04 03:42:02,842 - INFO  - Training [72][  100/  196]   Loss 0.036960   Top1 98.707031   Top5 99.996094   BatchTime 0.167402   LR 0.000010   
2022-11-04 03:42:05,865 - INFO  - Training [72][  120/  196]   Loss 0.036550   Top1 98.730469   Top5 99.996745   BatchTime 0.164694   LR 0.000010   
2022-11-04 03:42:08,882 - INFO  - Training [72][  140/  196]   Loss 0.036692   Top1 98.738839   Top5 99.997210   BatchTime 0.162717   LR 0.000010   
2022-11-04 03:42:11,875 - INFO  - Training [72][  160/  196]   Loss 0.037085   Top1 98.703613   Top5 99.997559   BatchTime 0.161083   LR 0.000010   
2022-11-04 03:42:14,879 - INFO  - Training [72][  180/  196]   Loss 0.037280   Top1 98.706597   Top5 99.997830   BatchTime 0.159873   LR 0.000010   
2022-11-04 03:42:17,468 - INFO  - ==> Top1: 98.694    Top5: 99.998    Loss: 0.037

2022-11-04 03:42:17,469 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:42:20,150 - INFO  - Validation [72][   20/   40]   Loss 0.422274   Top1 90.214844   Top5 99.648438   BatchTime 0.133977   
2022-11-04 03:42:21,154 - INFO  - Validation [72][   40/   40]   Loss 0.410019   Top1 90.350000   Top5 99.710000   BatchTime 0.092081   
2022-11-04 03:42:21,396 - INFO  - ==> Top1: 90.350    Top5: 99.710    Loss: 0.410

2022-11-04 03:42:21,434 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:42:21,435 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:42:21,435 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:42:21,546 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:42:21,547 - INFO  - >>>>>>>> Epoch  73
2022-11-04 03:42:21,548 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:42:26,410 - INFO  - Training [73][   20/  196]   Loss 0.034169   Top1 98.789062   Top5 100.000000   BatchTime 0.243069   LR 0.000010   
2022-11-04 03:42:29,431 - INFO  - Training [73][   40/  196]   Loss 0.034714   Top1 98.808594   Top5 100.000000   BatchTime 0.197061   LR 0.000010   
2022-11-04 03:42:32,440 - INFO  - Training [73][   60/  196]   Loss 0.034797   Top1 98.808594   Top5 100.000000   BatchTime 0.181531   LR 0.000010   
2022-11-04 03:42:35,466 - INFO  - Training [73][   80/  196]   Loss 0.035536   Top1 98.759766   Top5 100.000000   BatchTime 0.173973   LR 0.000010   
2022-11-04 03:42:38,477 - INFO  - Training [73][  100/  196]   Loss 0.036296   Top1 98.718750   Top5 100.000000   BatchTime 0.169285   LR 0.000010   
2022-11-04 03:42:41,422 - INFO  - Training [73][  120/  196]   Loss 0.035870   Top1 98.736979   Top5 100.000000   BatchTime 0.165613   LR 0.000010   
2022-11-04 03:42:44,432 - INFO  - Training [73][  140/  196]   Loss 0.036130   Top1 98.741629   Top5 100.000000   BatchTime 0.163455   LR 0.000010   
2022-11-04 03:42:47,423 - INFO  - Training [73][  160/  196]   Loss 0.035708   Top1 98.750000   Top5 99.997559   BatchTime 0.161713   LR 0.000010   
2022-11-04 03:42:50,413 - INFO  - Training [73][  180/  196]   Loss 0.035752   Top1 98.747830   Top5 99.997830   BatchTime 0.160357   LR 0.000010   
2022-11-04 03:42:52,990 - INFO  - ==> Top1: 98.744    Top5: 99.998    Loss: 0.036

2022-11-04 03:42:52,990 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:42:55,643 - INFO  - Validation [73][   20/   40]   Loss 0.420472   Top1 90.351562   Top5 99.648438   BatchTime 0.132574   
2022-11-04 03:42:56,645 - INFO  - Validation [73][   40/   40]   Loss 0.410256   Top1 90.460000   Top5 99.730000   BatchTime 0.091334   
2022-11-04 03:42:56,903 - INFO  - ==> Top1: 90.460    Top5: 99.730    Loss: 0.410

2022-11-04 03:42:56,938 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:42:56,939 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:42:56,939 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:42:57,052 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:42:57,052 - INFO  - >>>>>>>> Epoch  74
2022-11-04 03:42:57,054 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:43:01,747 - INFO  - Training [74][   20/  196]   Loss 0.035903   Top1 98.632812   Top5 100.000000   BatchTime 0.234630   LR 0.000010   
2022-11-04 03:43:04,766 - INFO  - Training [74][   40/  196]   Loss 0.036668   Top1 98.632812   Top5 100.000000   BatchTime 0.192811   LR 0.000010   
2022-11-04 03:43:07,780 - INFO  - Training [74][   60/  196]   Loss 0.036876   Top1 98.652344   Top5 100.000000   BatchTime 0.178757   LR 0.000010   
2022-11-04 03:43:10,800 - INFO  - Training [74][   80/  196]   Loss 0.036425   Top1 98.696289   Top5 100.000000   BatchTime 0.171827   LR 0.000010   
2022-11-04 03:43:13,827 - INFO  - Training [74][  100/  196]   Loss 0.036074   Top1 98.722656   Top5 100.000000   BatchTime 0.167731   LR 0.000010   
2022-11-04 03:43:16,862 - INFO  - Training [74][  120/  196]   Loss 0.036404   Top1 98.714193   Top5 100.000000   BatchTime 0.165065   LR 0.000010   
2022-11-04 03:43:19,883 - INFO  - Training [74][  140/  196]   Loss 0.035782   Top1 98.755580   Top5 100.000000   BatchTime 0.163063   LR 0.000010   
2022-11-04 03:43:22,875 - INFO  - Training [74][  160/  196]   Loss 0.036292   Top1 98.750000   Top5 100.000000   BatchTime 0.161377   LR 0.000010   
2022-11-04 03:43:25,883 - INFO  - Training [74][  180/  196]   Loss 0.036406   Top1 98.741319   Top5 100.000000   BatchTime 0.160160   LR 0.000010   
2022-11-04 03:43:28,447 - INFO  - ==> Top1: 98.694    Top5: 100.000    Loss: 0.037

2022-11-04 03:43:28,448 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:43:31,088 - INFO  - Validation [74][   20/   40]   Loss 0.422309   Top1 90.000000   Top5 99.667969   BatchTime 0.131897   
2022-11-04 03:43:32,105 - INFO  - Validation [74][   40/   40]   Loss 0.412792   Top1 90.290000   Top5 99.720000   BatchTime 0.091394   
2022-11-04 03:43:32,372 - INFO  - ==> Top1: 90.290    Top5: 99.720    Loss: 0.413

2022-11-04 03:43:32,411 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:43:32,412 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:43:32,412 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:43:32,512 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:43:32,512 - INFO  - >>>>>>>> Epoch  75
2022-11-04 03:43:32,513 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:43:37,292 - INFO  - Training [75][   20/  196]   Loss 0.034253   Top1 98.847656   Top5 100.000000   BatchTime 0.238926   LR 0.000010   
2022-11-04 03:43:40,321 - INFO  - Training [75][   40/  196]   Loss 0.036208   Top1 98.740234   Top5 100.000000   BatchTime 0.195205   LR 0.000010   
2022-11-04 03:43:43,337 - INFO  - Training [75][   60/  196]   Loss 0.036460   Top1 98.710938   Top5 100.000000   BatchTime 0.180392   LR 0.000010   
2022-11-04 03:43:46,343 - INFO  - Training [75][   80/  196]   Loss 0.036888   Top1 98.657227   Top5 100.000000   BatchTime 0.172876   LR 0.000010   
2022-11-04 03:43:49,366 - INFO  - Training [75][  100/  196]   Loss 0.036326   Top1 98.699219   Top5 100.000000   BatchTime 0.168528   LR 0.000010   
2022-11-04 03:43:52,391 - INFO  - Training [75][  120/  196]   Loss 0.036250   Top1 98.720703   Top5 100.000000   BatchTime 0.165650   LR 0.000010   
2022-11-04 03:43:55,399 - INFO  - Training [75][  140/  196]   Loss 0.036923   Top1 98.708147   Top5 100.000000   BatchTime 0.163473   LR 0.000010   
2022-11-04 03:43:58,481 - INFO  - Training [75][  160/  196]   Loss 0.037128   Top1 98.693848   Top5 100.000000   BatchTime 0.162300   LR 0.000010   
2022-11-04 03:44:01,469 - INFO  - Training [75][  180/  196]   Loss 0.036904   Top1 98.695747   Top5 100.000000   BatchTime 0.160865   LR 0.000010   
2022-11-04 03:44:04,050 - INFO  - ==> Top1: 98.680    Top5: 100.000    Loss: 0.037

2022-11-04 03:44:04,051 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:44:06,765 - INFO  - Validation [75][   20/   40]   Loss 0.418140   Top1 90.332031   Top5 99.687500   BatchTime 0.135644   
2022-11-04 03:44:07,767 - INFO  - Validation [75][   40/   40]   Loss 0.407207   Top1 90.460000   Top5 99.730000   BatchTime 0.092885   
2022-11-04 03:44:08,035 - INFO  - ==> Top1: 90.460    Top5: 99.730    Loss: 0.407

2022-11-04 03:44:08,073 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:44:08,074 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:44:08,074 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:44:08,155 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:44:08,156 - INFO  - >>>>>>>> Epoch  76
2022-11-04 03:44:08,157 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:44:13,243 - INFO  - Training [76][   20/  196]   Loss 0.035322   Top1 98.847656   Top5 100.000000   BatchTime 0.254297   LR 0.000010   
2022-11-04 03:44:16,270 - INFO  - Training [76][   40/  196]   Loss 0.035679   Top1 98.828125   Top5 100.000000   BatchTime 0.202829   LR 0.000010   
2022-11-04 03:44:19,307 - INFO  - Training [76][   60/  196]   Loss 0.033954   Top1 98.847656   Top5 100.000000   BatchTime 0.185833   LR 0.000010   
2022-11-04 03:44:22,326 - INFO  - Training [76][   80/  196]   Loss 0.035535   Top1 98.808594   Top5 100.000000   BatchTime 0.177115   LR 0.000010   
2022-11-04 03:44:25,350 - INFO  - Training [76][  100/  196]   Loss 0.035282   Top1 98.828125   Top5 100.000000   BatchTime 0.171925   LR 0.000010   
2022-11-04 03:44:28,367 - INFO  - Training [76][  120/  196]   Loss 0.035189   Top1 98.847656   Top5 100.000000   BatchTime 0.168413   LR 0.000010   
2022-11-04 03:44:31,385 - INFO  - Training [76][  140/  196]   Loss 0.035327   Top1 98.842076   Top5 100.000000   BatchTime 0.165912   LR 0.000010   
2022-11-04 03:44:34,374 - INFO  - Training [76][  160/  196]   Loss 0.035836   Top1 98.815918   Top5 100.000000   BatchTime 0.163857   LR 0.000010   
2022-11-04 03:44:37,377 - INFO  - Training [76][  180/  196]   Loss 0.035467   Top1 98.819444   Top5 100.000000   BatchTime 0.162332   LR 0.000010   
2022-11-04 03:44:39,953 - INFO  - ==> Top1: 98.812    Top5: 100.000    Loss: 0.035

2022-11-04 03:44:39,954 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:44:42,827 - INFO  - Validation [76][   20/   40]   Loss 0.419730   Top1 90.371094   Top5 99.707031   BatchTime 0.143564   
2022-11-04 03:44:43,836 - INFO  - Validation [76][   40/   40]   Loss 0.411233   Top1 90.410000   Top5 99.730000   BatchTime 0.097012   
2022-11-04 03:44:44,098 - INFO  - ==> Top1: 90.410    Top5: 99.730    Loss: 0.411

2022-11-04 03:44:44,138 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:44:44,139 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:44:44,139 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:44:44,260 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:44:44,260 - INFO  - >>>>>>>> Epoch  77
2022-11-04 03:44:44,273 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:44:49,467 - INFO  - Training [77][   20/  196]   Loss 0.037566   Top1 98.554688   Top5 100.000000   BatchTime 0.259711   LR 0.000010   
2022-11-04 03:44:52,486 - INFO  - Training [77][   40/  196]   Loss 0.037370   Top1 98.623047   Top5 100.000000   BatchTime 0.205317   LR 0.000010   
2022-11-04 03:44:55,520 - INFO  - Training [77][   60/  196]   Loss 0.038993   Top1 98.580729   Top5 100.000000   BatchTime 0.187445   LR 0.000010   
2022-11-04 03:44:58,543 - INFO  - Training [77][   80/  196]   Loss 0.038139   Top1 98.598633   Top5 100.000000   BatchTime 0.178373   LR 0.000010   
2022-11-04 03:45:01,549 - INFO  - Training [77][  100/  196]   Loss 0.037351   Top1 98.648438   Top5 100.000000   BatchTime 0.172753   LR 0.000010   
2022-11-04 03:45:04,571 - INFO  - Training [77][  120/  196]   Loss 0.037284   Top1 98.662109   Top5 100.000000   BatchTime 0.169148   LR 0.000010   
2022-11-04 03:45:07,516 - INFO  - Training [77][  140/  196]   Loss 0.037191   Top1 98.683036   Top5 100.000000   BatchTime 0.166015   LR 0.000010   
2022-11-04 03:45:10,505 - INFO  - Training [77][  160/  196]   Loss 0.036571   Top1 98.737793   Top5 100.000000   BatchTime 0.163945   LR 0.000010   
2022-11-04 03:45:13,495 - INFO  - Training [77][  180/  196]   Loss 0.036171   Top1 98.758681   Top5 100.000000   BatchTime 0.162343   LR 0.000010   
2022-11-04 03:45:16,058 - INFO  - ==> Top1: 98.738    Top5: 100.000    Loss: 0.037

2022-11-04 03:45:16,059 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:45:18,971 - INFO  - Validation [77][   20/   40]   Loss 0.425536   Top1 90.429688   Top5 99.609375   BatchTime 0.145523   
2022-11-04 03:45:19,980 - INFO  - Validation [77][   40/   40]   Loss 0.412255   Top1 90.490000   Top5 99.710000   BatchTime 0.097992   
2022-11-04 03:45:20,242 - INFO  - ==> Top1: 90.490    Top5: 99.710    Loss: 0.412

2022-11-04 03:45:20,274 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:45:20,275 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:45:20,275 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:45:20,427 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:45:20,427 - INFO  - >>>>>>>> Epoch  78
2022-11-04 03:45:20,429 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:45:25,609 - INFO  - Training [78][   20/  196]   Loss 0.031845   Top1 98.925781   Top5 100.000000   BatchTime 0.258967   LR 0.000010   
2022-11-04 03:45:28,624 - INFO  - Training [78][   40/  196]   Loss 0.032701   Top1 98.925781   Top5 100.000000   BatchTime 0.204861   LR 0.000010   
2022-11-04 03:45:31,633 - INFO  - Training [78][   60/  196]   Loss 0.034465   Top1 98.841146   Top5 100.000000   BatchTime 0.186726   LR 0.000010   
2022-11-04 03:45:34,653 - INFO  - Training [78][   80/  196]   Loss 0.034832   Top1 98.842773   Top5 100.000000   BatchTime 0.177797   LR 0.000010   
2022-11-04 03:45:37,685 - INFO  - Training [78][  100/  196]   Loss 0.034333   Top1 98.867188   Top5 100.000000   BatchTime 0.172556   LR 0.000010   
2022-11-04 03:45:40,717 - INFO  - Training [78][  120/  196]   Loss 0.034927   Top1 98.789062   Top5 100.000000   BatchTime 0.169062   LR 0.000010   
2022-11-04 03:45:43,722 - INFO  - Training [78][  140/  196]   Loss 0.035959   Top1 98.750000   Top5 100.000000   BatchTime 0.166376   LR 0.000010   
2022-11-04 03:45:46,711 - INFO  - Training [78][  160/  196]   Loss 0.035948   Top1 98.754883   Top5 100.000000   BatchTime 0.164260   LR 0.000010   
2022-11-04 03:45:49,708 - INFO  - Training [78][  180/  196]   Loss 0.036312   Top1 98.743490   Top5 100.000000   BatchTime 0.162658   LR 0.000010   
2022-11-04 03:45:52,474 - INFO  - ==> Top1: 98.752    Top5: 100.000    Loss: 0.036

2022-11-04 03:45:52,478 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:45:55,418 - INFO  - Validation [78][   20/   40]   Loss 0.424067   Top1 90.351562   Top5 99.667969   BatchTime 0.146889   
2022-11-04 03:45:56,421 - INFO  - Validation [78][   40/   40]   Loss 0.412324   Top1 90.470000   Top5 99.720000   BatchTime 0.098529   
2022-11-04 03:45:56,877 - INFO  - ==> Top1: 90.470    Top5: 99.720    Loss: 0.412

2022-11-04 03:45:56,902 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:45:56,903 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:45:56,903 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.500   Top5: 99.660] Sparsity : 0.892
2022-11-04 03:45:57,041 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:45:57,041 - INFO  - >>>>>>>> Epoch  79
2022-11-04 03:45:57,042 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:46:02,355 - INFO  - Training [79][   20/  196]   Loss 0.035400   Top1 98.710938   Top5 100.000000   BatchTime 0.265619   LR 0.000010   
2022-11-04 03:46:05,377 - INFO  - Training [79][   40/  196]   Loss 0.035367   Top1 98.662109   Top5 100.000000   BatchTime 0.208351   LR 0.000010   
2022-11-04 03:46:08,399 - INFO  - Training [79][   60/  196]   Loss 0.035835   Top1 98.691406   Top5 100.000000   BatchTime 0.189267   LR 0.000010   
2022-11-04 03:46:11,423 - INFO  - Training [79][   80/  196]   Loss 0.036128   Top1 98.706055   Top5 99.995117   BatchTime 0.179748   LR 0.000010   
2022-11-04 03:46:14,448 - INFO  - Training [79][  100/  196]   Loss 0.036204   Top1 98.726562   Top5 99.996094   BatchTime 0.174047   LR 0.000010   
2022-11-04 03:46:17,474 - INFO  - Training [79][  120/  196]   Loss 0.036479   Top1 98.733724   Top5 99.996745   BatchTime 0.170257   LR 0.000010   
2022-11-04 03:46:20,491 - INFO  - Training [79][  140/  196]   Loss 0.036950   Top1 98.716518   Top5 99.997210   BatchTime 0.167489   LR 0.000010   
2022-11-04 03:46:23,482 - INFO  - Training [79][  160/  196]   Loss 0.036537   Top1 98.715820   Top5 99.997559   BatchTime 0.165242   LR 0.000010   
2022-11-04 03:46:26,484 - INFO  - Training [79][  180/  196]   Loss 0.036983   Top1 98.704427   Top5 99.997830   BatchTime 0.163561   LR 0.000010   
2022-11-04 03:46:29,067 - INFO  - ==> Top1: 98.724    Top5: 99.996    Loss: 0.037

2022-11-04 03:46:29,068 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:46:31,942 - INFO  - Validation [79][   20/   40]   Loss 0.420183   Top1 90.683594   Top5 99.628906   BatchTime 0.143638   
2022-11-04 03:46:32,977 - INFO  - Validation [79][   40/   40]   Loss 0.410325   Top1 90.640000   Top5 99.710000   BatchTime 0.097711   
2022-11-04 03:46:33,230 - INFO  - ==> Top1: 90.640    Top5: 99.710    Loss: 0.410

2022-11-04 03:46:33,254 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.660   Top5: 99.730] Sparsity : 0.892
2022-11-04 03:46:33,255 - INFO  - Scoreboard best 2 ==> Epoch [79][Top1: 90.640   Top5: 99.710] Sparsity : 0.892
2022-11-04 03:46:33,255 - INFO  - Scoreboard best 3 ==> Epoch [66][Top1: 90.520   Top5: 99.750] Sparsity : 0.892
2022-11-04 03:46:33,335 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_20221104-030538/MobileNetv2_cifar10_a8w8_hard_pruning_20_epoch80_checkpoint.pth.tar

2022-11-04 03:46:33,335 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-04 03:46:33,335 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:46:36,852 - INFO  - Validation [   20/   40]   Loss 0.420183   Top1 90.683594   Top5 99.628906   BatchTime 0.175831   
2022-11-04 03:46:38,357 - INFO  - Validation [   40/   40]   Loss 0.410325   Top1 90.640000   Top5 99.710000   BatchTime 0.125529   
2022-11-04 03:46:38,606 - INFO  - ==> Top1: 90.640    Top5: 99.710    Loss: 0.410

2022-11-04 03:46:38,673 - INFO  - Program completed successfully ... exiting ...
2022-11-04 03:46:38,673 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
