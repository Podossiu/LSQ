2022-11-04 01:45:41,134 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541.log
2022-11-04 01:45:42,258 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/tb_runs
2022-11-04 01:45:43,378 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-04 01:45:43,428 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
2022-11-04 01:45:45,612 - INFO  - Inserted quantizers into the original model
2022-11-04 01:45:47,544 - INFO  - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
2022-11-04 01:45:47,545 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-04 01:45:47,545 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-04 01:45:47,545 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-04 01:45:47,545 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:45:51,425 - INFO  - Validation [   20/   40]   Loss 0.428771   Top1 89.902344   Top5 99.531250   BatchTime 0.193965   
2022-11-04 01:45:52,647 - INFO  - Validation [   40/   40]   Loss 0.406859   Top1 90.290000   Top5 99.610000   BatchTime 0.127516   
2022-11-04 01:45:52,820 - INFO  - ==> Top1: 90.290    Top5: 99.610    Loss: 0.407

2022-11-04 01:45:52,861 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:45:52,861 - INFO  - >>>>>>>> Epoch   0
2022-11-04 01:45:52,861 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:45:57,701 - INFO  - Training [0][   20/  196]   Loss 0.030883   Top1 99.042969   Top5 99.980469   BatchTime 0.241954   LR 0.010000   
2022-11-04 01:46:00,194 - INFO  - Training [0][   40/  196]   Loss 0.032406   Top1 98.994141   Top5 99.990234   BatchTime 0.183313   LR 0.010000   
2022-11-04 01:46:02,671 - INFO  - Training [0][   60/  196]   Loss 0.032962   Top1 98.951823   Top5 99.986979   BatchTime 0.163482   LR 0.010000   
2022-11-04 01:46:05,149 - INFO  - Training [0][   80/  196]   Loss 0.033481   Top1 98.876953   Top5 99.990234   BatchTime 0.153589   LR 0.010000   
2022-11-04 01:46:07,640 - INFO  - Training [0][  100/  196]   Loss 0.034038   Top1 98.832031   Top5 99.992188   BatchTime 0.147777   LR 0.010000   
2022-11-04 01:46:10,115 - INFO  - Training [0][  120/  196]   Loss 0.033622   Top1 98.873698   Top5 99.993490   BatchTime 0.143776   LR 0.010000   
2022-11-04 01:46:12,582 - INFO  - Training [0][  140/  196]   Loss 0.033913   Top1 98.856027   Top5 99.994420   BatchTime 0.140855   LR 0.010000   
2022-11-04 01:46:15,043 - INFO  - Training [0][  160/  196]   Loss 0.035028   Top1 98.813477   Top5 99.995117   BatchTime 0.138633   LR 0.010000   
2022-11-04 01:46:17,499 - INFO  - Training [0][  180/  196]   Loss 0.036411   Top1 98.754340   Top5 99.995660   BatchTime 0.136871   LR 0.010000   
2022-11-04 01:46:20,035 - INFO  - ==> Top1: 98.746    Top5: 99.996    Loss: 0.037

2022-11-04 01:46:20,036 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:46:22,638 - INFO  - Validation [0][   20/   40]   Loss 0.443432   Top1 89.667969   Top5 99.511719   BatchTime 0.130045   
2022-11-04 01:46:23,327 - INFO  - Validation [0][   40/   40]   Loss 0.424122   Top1 90.090000   Top5 99.570000   BatchTime 0.082235   
2022-11-04 01:46:23,574 - INFO  - ==> Top1: 90.090    Top5: 99.570    Loss: 0.424

2022-11-04 01:46:23,601 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:46:23,601 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.090   Top5: 99.570] Sparsity : 0.847
2022-11-04 01:46:23,633 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:46:23,634 - INFO  - >>>>>>>> Epoch   1
2022-11-04 01:46:23,635 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:46:27,597 - INFO  - Training [1][   20/  196]   Loss 0.037351   Top1 98.671875   Top5 100.000000   BatchTime 0.198093   LR 0.010000   
2022-11-04 01:46:29,444 - INFO  - Training [1][   40/  196]   Loss 0.042507   Top1 98.466797   Top5 100.000000   BatchTime 0.145221   LR 0.010000   
2022-11-04 01:46:31,914 - INFO  - Training [1][   60/  196]   Loss 0.040985   Top1 98.515625   Top5 100.000000   BatchTime 0.137970   LR 0.010000   
2022-11-04 01:46:34,382 - INFO  - Training [1][   80/  196]   Loss 0.040021   Top1 98.554688   Top5 100.000000   BatchTime 0.134328   LR 0.010000   
2022-11-04 01:46:36,861 - INFO  - Training [1][  100/  196]   Loss 0.039331   Top1 98.570312   Top5 100.000000   BatchTime 0.132256   LR 0.010000   
2022-11-04 01:46:39,427 - INFO  - Training [1][  120/  196]   Loss 0.039111   Top1 98.564453   Top5 100.000000   BatchTime 0.131597   LR 0.010000   
2022-11-04 01:46:41,888 - INFO  - Training [1][  140/  196]   Loss 0.039419   Top1 98.554688   Top5 100.000000   BatchTime 0.130370   LR 0.010000   
2022-11-04 01:46:44,355 - INFO  - Training [1][  160/  196]   Loss 0.039254   Top1 98.562012   Top5 100.000000   BatchTime 0.129498   LR 0.010000   
2022-11-04 01:46:46,813 - INFO  - Training [1][  180/  196]   Loss 0.039490   Top1 98.546007   Top5 100.000000   BatchTime 0.128760   LR 0.010000   
2022-11-04 01:46:48,978 - INFO  - ==> Top1: 98.542    Top5: 100.000    Loss: 0.040

2022-11-04 01:46:48,979 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:46:51,840 - INFO  - Validation [1][   20/   40]   Loss 0.429537   Top1 89.882812   Top5 99.550781   BatchTime 0.142966   
2022-11-04 01:46:52,979 - INFO  - Validation [1][   40/   40]   Loss 0.419554   Top1 90.170000   Top5 99.610000   BatchTime 0.099957   
2022-11-04 01:46:53,236 - INFO  - ==> Top1: 90.170    Top5: 99.610    Loss: 0.420

2022-11-04 01:46:53,285 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:46:53,286 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 90.170   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:46:53,286 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 90.090   Top5: 99.570] Sparsity : 0.847
2022-11-04 01:46:53,375 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:46:53,376 - INFO  - >>>>>>>> Epoch   2
2022-11-04 01:46:53,377 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:46:57,752 - INFO  - Training [2][   20/  196]   Loss 0.034160   Top1 98.808594   Top5 100.000000   BatchTime 0.218772   LR 0.010000   
2022-11-04 01:47:00,223 - INFO  - Training [2][   40/  196]   Loss 0.037098   Top1 98.740234   Top5 100.000000   BatchTime 0.171149   LR 0.010000   
2022-11-04 01:47:02,696 - INFO  - Training [2][   60/  196]   Loss 0.036184   Top1 98.789062   Top5 100.000000   BatchTime 0.155313   LR 0.010000   
2022-11-04 01:47:05,188 - INFO  - Training [2][   80/  196]   Loss 0.036917   Top1 98.710938   Top5 100.000000   BatchTime 0.147636   LR 0.010000   
2022-11-04 01:47:07,652 - INFO  - Training [2][  100/  196]   Loss 0.036439   Top1 98.726562   Top5 100.000000   BatchTime 0.142754   LR 0.010000   
2022-11-04 01:47:10,109 - INFO  - Training [2][  120/  196]   Loss 0.037377   Top1 98.704427   Top5 100.000000   BatchTime 0.139433   LR 0.010000   
2022-11-04 01:47:12,575 - INFO  - Training [2][  140/  196]   Loss 0.039036   Top1 98.660714   Top5 100.000000   BatchTime 0.137130   LR 0.010000   
2022-11-04 01:47:15,032 - INFO  - Training [2][  160/  196]   Loss 0.039064   Top1 98.664551   Top5 100.000000   BatchTime 0.135346   LR 0.010000   
2022-11-04 01:47:16,811 - INFO  - Training [2][  180/  196]   Loss 0.039218   Top1 98.648003   Top5 100.000000   BatchTime 0.130186   LR 0.010000   
2022-11-04 01:47:18,669 - INFO  - ==> Top1: 98.634    Top5: 100.000    Loss: 0.039

2022-11-04 01:47:18,669 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:47:21,248 - INFO  - Validation [2][   20/   40]   Loss 0.437987   Top1 90.195312   Top5 99.531250   BatchTime 0.128847   
2022-11-04 01:47:21,932 - INFO  - Validation [2][   40/   40]   Loss 0.425587   Top1 90.390000   Top5 99.610000   BatchTime 0.081537   
2022-11-04 01:47:22,181 - INFO  - ==> Top1: 90.390    Top5: 99.610    Loss: 0.426

2022-11-04 01:47:22,206 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:47:22,207 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:47:22,207 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 90.170   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:47:22,356 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 01:47:22,505 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 01:47:22,505 - INFO  - >>>>>>>> Epoch   3
2022-11-04 01:47:22,507 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:47:26,877 - INFO  - Training [3][   20/  196]   Loss 0.033557   Top1 98.652344   Top5 100.000000   BatchTime 0.218484   LR 0.010000   
2022-11-04 01:47:29,376 - INFO  - Training [3][   40/  196]   Loss 0.034278   Top1 98.710938   Top5 100.000000   BatchTime 0.171732   LR 0.010000   
2022-11-04 01:47:31,852 - INFO  - Training [3][   60/  196]   Loss 0.037968   Top1 98.567708   Top5 100.000000   BatchTime 0.155746   LR 0.010000   
2022-11-04 01:47:34,330 - INFO  - Training [3][   80/  196]   Loss 0.038911   Top1 98.540039   Top5 100.000000   BatchTime 0.147781   LR 0.010000   
2022-11-04 01:47:36,805 - INFO  - Training [3][  100/  196]   Loss 0.039247   Top1 98.562500   Top5 100.000000   BatchTime 0.142977   LR 0.010000   
2022-11-04 01:47:39,276 - INFO  - Training [3][  120/  196]   Loss 0.039822   Top1 98.590495   Top5 100.000000   BatchTime 0.139740   LR 0.010000   
2022-11-04 01:47:41,752 - INFO  - Training [3][  140/  196]   Loss 0.039876   Top1 98.602121   Top5 100.000000   BatchTime 0.137460   LR 0.010000   
2022-11-04 01:47:44,226 - INFO  - Training [3][  160/  196]   Loss 0.039667   Top1 98.627930   Top5 100.000000   BatchTime 0.135745   LR 0.010000   
2022-11-04 01:47:46,684 - INFO  - Training [3][  180/  196]   Loss 0.039629   Top1 98.628472   Top5 100.000000   BatchTime 0.134316   LR 0.010000   
2022-11-04 01:47:48,874 - INFO  - ==> Top1: 98.630    Top5: 100.000    Loss: 0.040

2022-11-04 01:47:48,874 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:47:51,718 - INFO  - Validation [3][   20/   40]   Loss 0.435744   Top1 90.410156   Top5 99.531250   BatchTime 0.142150   
2022-11-04 01:47:52,829 - INFO  - Validation [3][   40/   40]   Loss 0.426056   Top1 90.490000   Top5 99.610000   BatchTime 0.098830   
2022-11-04 01:47:53,080 - INFO  - ==> Top1: 90.490    Top5: 99.610    Loss: 0.426

2022-11-04 01:47:53,122 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:47:53,123 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:47:53,123 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:47:53,317 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 01:47:53,479 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 01:47:53,479 - INFO  - >>>>>>>> Epoch   4
2022-11-04 01:47:53,480 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:47:57,849 - INFO  - Training [4][   20/  196]   Loss 0.035181   Top1 98.750000   Top5 100.000000   BatchTime 0.218413   LR 0.010000   
2022-11-04 01:48:00,333 - INFO  - Training [4][   40/  196]   Loss 0.034881   Top1 98.681641   Top5 100.000000   BatchTime 0.171318   LR 0.010000   
2022-11-04 01:48:02,804 - INFO  - Training [4][   60/  196]   Loss 0.035994   Top1 98.697917   Top5 99.993490   BatchTime 0.155394   LR 0.010000   
2022-11-04 01:48:05,273 - INFO  - Training [4][   80/  196]   Loss 0.037283   Top1 98.632812   Top5 99.995117   BatchTime 0.147407   LR 0.010000   
2022-11-04 01:48:07,622 - INFO  - Training [4][  100/  196]   Loss 0.038390   Top1 98.640625   Top5 99.992188   BatchTime 0.141409   LR 0.010000   
2022-11-04 01:48:09,416 - INFO  - Training [4][  120/  196]   Loss 0.038468   Top1 98.658854   Top5 99.993490   BatchTime 0.132793   LR 0.010000   
2022-11-04 01:48:11,433 - INFO  - Training [4][  140/  196]   Loss 0.040092   Top1 98.604911   Top5 99.991629   BatchTime 0.128228   LR 0.010000   
2022-11-04 01:48:13,430 - INFO  - Training [4][  160/  196]   Loss 0.040836   Top1 98.583984   Top5 99.992676   BatchTime 0.124684   LR 0.010000   
2022-11-04 01:48:15,349 - INFO  - Training [4][  180/  196]   Loss 0.040878   Top1 98.578559   Top5 99.993490   BatchTime 0.121487   LR 0.010000   
2022-11-04 01:48:17,115 - INFO  - ==> Top1: 98.586    Top5: 99.994    Loss: 0.041

2022-11-04 01:48:17,116 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:48:19,981 - INFO  - Validation [4][   20/   40]   Loss 0.445881   Top1 90.273438   Top5 99.433594   BatchTime 0.143160   
2022-11-04 01:48:21,112 - INFO  - Validation [4][   40/   40]   Loss 0.431353   Top1 90.250000   Top5 99.570000   BatchTime 0.099861   
2022-11-04 01:48:21,368 - INFO  - ==> Top1: 90.250    Top5: 99.570    Loss: 0.431

2022-11-04 01:48:21,400 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:48:21,401 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:48:21,401 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.290   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:48:21,504 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:48:21,504 - INFO  - >>>>>>>> Epoch   5
2022-11-04 01:48:21,506 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:48:25,845 - INFO  - Training [5][   20/  196]   Loss 0.039981   Top1 98.515625   Top5 100.000000   BatchTime 0.216975   LR 0.010000   
2022-11-04 01:48:28,317 - INFO  - Training [5][   40/  196]   Loss 0.040475   Top1 98.593750   Top5 99.990234   BatchTime 0.170272   LR 0.010000   
2022-11-04 01:48:30,883 - INFO  - Training [5][   60/  196]   Loss 0.040244   Top1 98.613281   Top5 99.993490   BatchTime 0.156281   LR 0.010000   
2022-11-04 01:48:33,351 - INFO  - Training [5][   80/  196]   Loss 0.038894   Top1 98.662109   Top5 99.995117   BatchTime 0.148067   LR 0.010000   
2022-11-04 01:48:35,823 - INFO  - Training [5][  100/  196]   Loss 0.038879   Top1 98.632812   Top5 99.996094   BatchTime 0.143168   LR 0.010000   
2022-11-04 01:48:38,289 - INFO  - Training [5][  120/  196]   Loss 0.038286   Top1 98.652344   Top5 99.996745   BatchTime 0.139858   LR 0.010000   
2022-11-04 01:48:40,749 - INFO  - Training [5][  140/  196]   Loss 0.039080   Top1 98.610491   Top5 99.997210   BatchTime 0.137447   LR 0.010000   
2022-11-04 01:48:43,216 - INFO  - Training [5][  160/  196]   Loss 0.038663   Top1 98.652344   Top5 99.997559   BatchTime 0.135686   LR 0.010000   
2022-11-04 01:48:45,669 - INFO  - Training [5][  180/  196]   Loss 0.039114   Top1 98.624132   Top5 99.997830   BatchTime 0.134238   LR 0.010000   
2022-11-04 01:48:47,843 - INFO  - ==> Top1: 98.636    Top5: 99.998    Loss: 0.039

2022-11-04 01:48:47,844 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:48:50,623 - INFO  - Validation [5][   20/   40]   Loss 0.440643   Top1 90.527344   Top5 99.492188   BatchTime 0.138860   
2022-11-04 01:48:51,737 - INFO  - Validation [5][   40/   40]   Loss 0.427343   Top1 90.710000   Top5 99.580000   BatchTime 0.097288   
2022-11-04 01:48:51,996 - INFO  - ==> Top1: 90.710    Top5: 99.580    Loss: 0.427

2022-11-04 01:48:52,035 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:48:52,036 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:48:52,036 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.390   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:48:52,242 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 01:48:52,398 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 01:48:52,399 - INFO  - >>>>>>>> Epoch   6
2022-11-04 01:48:52,400 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:48:56,767 - INFO  - Training [6][   20/  196]   Loss 0.039057   Top1 98.710938   Top5 100.000000   BatchTime 0.218369   LR 0.010000   
2022-11-04 01:48:59,281 - INFO  - Training [6][   40/  196]   Loss 0.040087   Top1 98.642578   Top5 100.000000   BatchTime 0.172016   LR 0.010000   
2022-11-04 01:49:01,018 - INFO  - Training [6][   60/  196]   Loss 0.041739   Top1 98.561198   Top5 100.000000   BatchTime 0.143628   LR 0.010000   
2022-11-04 01:49:03,104 - INFO  - Training [6][   80/  196]   Loss 0.039694   Top1 98.652344   Top5 100.000000   BatchTime 0.133802   LR 0.010000   
2022-11-04 01:49:05,133 - INFO  - Training [6][  100/  196]   Loss 0.040155   Top1 98.660156   Top5 100.000000   BatchTime 0.127324   LR 0.010000   
2022-11-04 01:49:07,133 - INFO  - Training [6][  120/  196]   Loss 0.040291   Top1 98.658854   Top5 100.000000   BatchTime 0.122775   LR 0.010000   
2022-11-04 01:49:09,168 - INFO  - Training [6][  140/  196]   Loss 0.040132   Top1 98.652344   Top5 100.000000   BatchTime 0.119771   LR 0.010000   
2022-11-04 01:49:11,640 - INFO  - Training [6][  160/  196]   Loss 0.039495   Top1 98.684082   Top5 100.000000   BatchTime 0.120247   LR 0.010000   
2022-11-04 01:49:14,111 - INFO  - Training [6][  180/  196]   Loss 0.039604   Top1 98.682726   Top5 100.000000   BatchTime 0.120612   LR 0.010000   
2022-11-04 01:49:16,296 - INFO  - ==> Top1: 98.654    Top5: 100.000    Loss: 0.040

2022-11-04 01:49:16,297 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:49:19,169 - INFO  - Validation [6][   20/   40]   Loss 0.442836   Top1 90.468750   Top5 99.531250   BatchTime 0.143506   
2022-11-04 01:49:20,289 - INFO  - Validation [6][   40/   40]   Loss 0.434453   Top1 90.440000   Top5 99.610000   BatchTime 0.099757   
2022-11-04 01:49:20,546 - INFO  - ==> Top1: 90.440    Top5: 99.610    Loss: 0.434

2022-11-04 01:49:20,589 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:49:20,590 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:49:20,590 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.440   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:49:20,703 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:49:20,704 - INFO  - >>>>>>>> Epoch   7
2022-11-04 01:49:20,705 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:49:25,064 - INFO  - Training [7][   20/  196]   Loss 0.034204   Top1 98.867188   Top5 100.000000   BatchTime 0.217913   LR 0.010000   
2022-11-04 01:49:27,531 - INFO  - Training [7][   40/  196]   Loss 0.035197   Top1 98.798828   Top5 100.000000   BatchTime 0.170642   LR 0.010000   
2022-11-04 01:49:30,000 - INFO  - Training [7][   60/  196]   Loss 0.035207   Top1 98.769531   Top5 100.000000   BatchTime 0.154912   LR 0.010000   
2022-11-04 01:49:32,481 - INFO  - Training [7][   80/  196]   Loss 0.035838   Top1 98.759766   Top5 99.995117   BatchTime 0.147196   LR 0.010000   
2022-11-04 01:49:34,945 - INFO  - Training [7][  100/  196]   Loss 0.036160   Top1 98.730469   Top5 99.996094   BatchTime 0.142398   LR 0.010000   
2022-11-04 01:49:37,422 - INFO  - Training [7][  120/  196]   Loss 0.036127   Top1 98.717448   Top5 99.996745   BatchTime 0.139305   LR 0.010000   
2022-11-04 01:49:39,895 - INFO  - Training [7][  140/  196]   Loss 0.036076   Top1 98.727679   Top5 99.997210   BatchTime 0.137069   LR 0.010000   
2022-11-04 01:49:42,367 - INFO  - Training [7][  160/  196]   Loss 0.036817   Top1 98.696289   Top5 99.997559   BatchTime 0.135380   LR 0.010000   
2022-11-04 01:49:44,829 - INFO  - Training [7][  180/  196]   Loss 0.036568   Top1 98.702257   Top5 99.997830   BatchTime 0.134016   LR 0.010000   
2022-11-04 01:49:46,985 - INFO  - ==> Top1: 98.714    Top5: 99.998    Loss: 0.037

2022-11-04 01:49:46,986 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:49:49,836 - INFO  - Validation [7][   20/   40]   Loss 0.443434   Top1 90.253906   Top5 99.472656   BatchTime 0.142423   
2022-11-04 01:49:50,963 - INFO  - Validation [7][   40/   40]   Loss 0.435011   Top1 90.400000   Top5 99.550000   BatchTime 0.099406   
2022-11-04 01:49:51,211 - INFO  - ==> Top1: 90.400    Top5: 99.550    Loss: 0.435

2022-11-04 01:49:51,247 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:49:51,248 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:49:51,248 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.440   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:49:51,352 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:49:51,352 - INFO  - >>>>>>>> Epoch   8
2022-11-04 01:49:51,353 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:49:55,423 - INFO  - Training [8][   20/  196]   Loss 0.032443   Top1 98.828125   Top5 100.000000   BatchTime 0.203484   LR 0.010000   
2022-11-04 01:49:57,475 - INFO  - Training [8][   40/  196]   Loss 0.033900   Top1 98.847656   Top5 100.000000   BatchTime 0.153041   LR 0.010000   
2022-11-04 01:49:59,554 - INFO  - Training [8][   60/  196]   Loss 0.034640   Top1 98.802083   Top5 100.000000   BatchTime 0.136673   LR 0.010000   
2022-11-04 01:50:01,372 - INFO  - Training [8][   80/  196]   Loss 0.034802   Top1 98.789062   Top5 100.000000   BatchTime 0.125234   LR 0.010000   
2022-11-04 01:50:03,857 - INFO  - Training [8][  100/  196]   Loss 0.033571   Top1 98.851562   Top5 100.000000   BatchTime 0.125039   LR 0.010000   
2022-11-04 01:50:06,338 - INFO  - Training [8][  120/  196]   Loss 0.034219   Top1 98.831380   Top5 100.000000   BatchTime 0.124873   LR 0.010000   
2022-11-04 01:50:08,800 - INFO  - Training [8][  140/  196]   Loss 0.034603   Top1 98.803013   Top5 100.000000   BatchTime 0.124622   LR 0.010000   
2022-11-04 01:50:11,264 - INFO  - Training [8][  160/  196]   Loss 0.035121   Top1 98.781738   Top5 100.000000   BatchTime 0.124443   LR 0.010000   
2022-11-04 01:50:13,728 - INFO  - Training [8][  180/  196]   Loss 0.035748   Top1 98.765191   Top5 100.000000   BatchTime 0.124300   LR 0.010000   
2022-11-04 01:50:15,895 - INFO  - ==> Top1: 98.764    Top5: 100.000    Loss: 0.036

2022-11-04 01:50:15,895 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:50:18,769 - INFO  - Validation [8][   20/   40]   Loss 0.448289   Top1 90.078125   Top5 99.433594   BatchTime 0.143605   
2022-11-04 01:50:19,886 - INFO  - Validation [8][   40/   40]   Loss 0.435918   Top1 90.290000   Top5 99.540000   BatchTime 0.099742   
2022-11-04 01:50:20,140 - INFO  - ==> Top1: 90.290    Top5: 99.540    Loss: 0.436

2022-11-04 01:50:20,187 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:50:20,188 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:50:20,188 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.440   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:50:20,293 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:50:20,293 - INFO  - >>>>>>>> Epoch   9
2022-11-04 01:50:20,294 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:50:24,639 - INFO  - Training [9][   20/  196]   Loss 0.035072   Top1 98.789062   Top5 99.980469   BatchTime 0.217234   LR 0.010000   
2022-11-04 01:50:27,116 - INFO  - Training [9][   40/  196]   Loss 0.036125   Top1 98.779297   Top5 99.990234   BatchTime 0.170538   LR 0.010000   
2022-11-04 01:50:29,692 - INFO  - Training [9][   60/  196]   Loss 0.037315   Top1 98.756510   Top5 99.993490   BatchTime 0.156628   LR 0.010000   
2022-11-04 01:50:32,154 - INFO  - Training [9][   80/  196]   Loss 0.037025   Top1 98.769531   Top5 99.995117   BatchTime 0.148242   LR 0.010000   
2022-11-04 01:50:34,629 - INFO  - Training [9][  100/  196]   Loss 0.037700   Top1 98.746094   Top5 99.996094   BatchTime 0.143340   LR 0.010000   
2022-11-04 01:50:37,112 - INFO  - Training [9][  120/  196]   Loss 0.037497   Top1 98.750000   Top5 99.996745   BatchTime 0.140147   LR 0.010000   
2022-11-04 01:50:39,591 - INFO  - Training [9][  140/  196]   Loss 0.036978   Top1 98.766741   Top5 99.997210   BatchTime 0.137830   LR 0.010000   
2022-11-04 01:50:42,002 - INFO  - Training [9][  160/  196]   Loss 0.036171   Top1 98.793945   Top5 99.997559   BatchTime 0.135668   LR 0.010000   
2022-11-04 01:50:44,452 - INFO  - Training [9][  180/  196]   Loss 0.035691   Top1 98.817274   Top5 99.997830   BatchTime 0.134208   LR 0.010000   
2022-11-04 01:50:46,611 - INFO  - ==> Top1: 98.810    Top5: 99.998    Loss: 0.036

2022-11-04 01:50:46,612 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:50:49,331 - INFO  - Validation [9][   20/   40]   Loss 0.452233   Top1 90.351562   Top5 99.511719   BatchTime 0.135895   
2022-11-04 01:50:50,186 - INFO  - Validation [9][   40/   40]   Loss 0.433553   Top1 90.460000   Top5 99.600000   BatchTime 0.089311   
2022-11-04 01:50:50,432 - INFO  - ==> Top1: 90.460    Top5: 99.600    Loss: 0.434

2022-11-04 01:50:50,461 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:50:50,462 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:50:50,462 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.460   Top5: 99.600] Sparsity : 0.847
2022-11-04 01:50:50,544 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:50:50,544 - INFO  - >>>>>>>> Epoch  10
2022-11-04 01:50:50,545 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:50:54,578 - INFO  - Training [10][   20/  196]   Loss 0.033538   Top1 98.730469   Top5 100.000000   BatchTime 0.201648   LR 0.010000   
2022-11-04 01:50:57,059 - INFO  - Training [10][   40/  196]   Loss 0.032217   Top1 98.837891   Top5 100.000000   BatchTime 0.162839   LR 0.010000   
2022-11-04 01:50:59,528 - INFO  - Training [10][   60/  196]   Loss 0.034252   Top1 98.808594   Top5 100.000000   BatchTime 0.149706   LR 0.010000   
2022-11-04 01:51:02,002 - INFO  - Training [10][   80/  196]   Loss 0.036621   Top1 98.754883   Top5 100.000000   BatchTime 0.143216   LR 0.010000   
2022-11-04 01:51:04,482 - INFO  - Training [10][  100/  196]   Loss 0.036637   Top1 98.730469   Top5 100.000000   BatchTime 0.139363   LR 0.010000   
2022-11-04 01:51:06,959 - INFO  - Training [10][  120/  196]   Loss 0.036554   Top1 98.733724   Top5 100.000000   BatchTime 0.136783   LR 0.010000   
2022-11-04 01:51:09,446 - INFO  - Training [10][  140/  196]   Loss 0.036318   Top1 98.744420   Top5 100.000000   BatchTime 0.135007   LR 0.010000   
2022-11-04 01:51:11,906 - INFO  - Training [10][  160/  196]   Loss 0.036137   Top1 98.735352   Top5 100.000000   BatchTime 0.133505   LR 0.010000   
2022-11-04 01:51:14,359 - INFO  - Training [10][  180/  196]   Loss 0.036504   Top1 98.721788   Top5 100.000000   BatchTime 0.132300   LR 0.010000   
2022-11-04 01:51:16,521 - INFO  - ==> Top1: 98.718    Top5: 100.000    Loss: 0.037

2022-11-04 01:51:16,522 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:51:19,421 - INFO  - Validation [10][   20/   40]   Loss 0.447884   Top1 90.058594   Top5 99.492188   BatchTime 0.144929   
2022-11-04 01:51:20,541 - INFO  - Validation [10][   40/   40]   Loss 0.436141   Top1 90.280000   Top5 99.590000   BatchTime 0.100449   
2022-11-04 01:51:20,783 - INFO  - ==> Top1: 90.280    Top5: 99.590    Loss: 0.436

2022-11-04 01:51:20,823 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:51:20,824 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:51:20,824 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.460   Top5: 99.600] Sparsity : 0.847
2022-11-04 01:51:20,931 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:51:20,932 - INFO  - >>>>>>>> Epoch  11
2022-11-04 01:51:20,933 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:51:25,308 - INFO  - Training [11][   20/  196]   Loss 0.035348   Top1 98.730469   Top5 100.000000   BatchTime 0.218763   LR 0.010000   
2022-11-04 01:51:27,776 - INFO  - Training [11][   40/  196]   Loss 0.034937   Top1 98.779297   Top5 100.000000   BatchTime 0.171084   LR 0.010000   
2022-11-04 01:51:30,248 - INFO  - Training [11][   60/  196]   Loss 0.034700   Top1 98.795573   Top5 100.000000   BatchTime 0.155259   LR 0.010000   
2022-11-04 01:51:32,717 - INFO  - Training [11][   80/  196]   Loss 0.034703   Top1 98.793945   Top5 100.000000   BatchTime 0.147301   LR 0.010000   
2022-11-04 01:51:35,169 - INFO  - Training [11][  100/  196]   Loss 0.035721   Top1 98.765625   Top5 100.000000   BatchTime 0.142364   LR 0.010000   
2022-11-04 01:51:37,637 - INFO  - Training [11][  120/  196]   Loss 0.035924   Top1 98.736979   Top5 100.000000   BatchTime 0.139202   LR 0.010000   
2022-11-04 01:51:39,991 - INFO  - Training [11][  140/  196]   Loss 0.035599   Top1 98.736049   Top5 100.000000   BatchTime 0.136129   LR 0.010000   
2022-11-04 01:51:41,807 - INFO  - Training [11][  160/  196]   Loss 0.034858   Top1 98.789062   Top5 100.000000   BatchTime 0.130460   LR 0.010000   
2022-11-04 01:51:43,835 - INFO  - Training [11][  180/  196]   Loss 0.035510   Top1 98.743490   Top5 100.000000   BatchTime 0.127231   LR 0.010000   
2022-11-04 01:51:45,646 - INFO  - ==> Top1: 98.750    Top5: 100.000    Loss: 0.035

2022-11-04 01:51:45,646 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:51:48,312 - INFO  - Validation [11][   20/   40]   Loss 0.450426   Top1 90.097656   Top5 99.550781   BatchTime 0.133185   
2022-11-04 01:51:49,449 - INFO  - Validation [11][   40/   40]   Loss 0.441413   Top1 90.260000   Top5 99.600000   BatchTime 0.095037   
2022-11-04 01:51:49,701 - INFO  - ==> Top1: 90.260    Top5: 99.600    Loss: 0.441

2022-11-04 01:51:49,746 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:51:49,746 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:51:49,747 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.460   Top5: 99.600] Sparsity : 0.847
2022-11-04 01:51:49,852 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:51:49,852 - INFO  - >>>>>>>> Epoch  12
2022-11-04 01:51:49,853 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:51:54,260 - INFO  - Training [12][   20/  196]   Loss 0.038802   Top1 98.671875   Top5 99.980469   BatchTime 0.220300   LR 0.010000   
2022-11-04 01:51:56,735 - INFO  - Training [12][   40/  196]   Loss 0.035047   Top1 98.798828   Top5 99.990234   BatchTime 0.172041   LR 0.010000   
2022-11-04 01:51:59,201 - INFO  - Training [12][   60/  196]   Loss 0.036153   Top1 98.750000   Top5 99.993490   BatchTime 0.155785   LR 0.010000   
2022-11-04 01:52:01,672 - INFO  - Training [12][   80/  196]   Loss 0.036249   Top1 98.759766   Top5 99.990234   BatchTime 0.147733   LR 0.010000   
2022-11-04 01:52:04,151 - INFO  - Training [12][  100/  196]   Loss 0.034537   Top1 98.863281   Top5 99.992188   BatchTime 0.142972   LR 0.010000   
2022-11-04 01:52:06,634 - INFO  - Training [12][  120/  196]   Loss 0.035930   Top1 98.792318   Top5 99.993490   BatchTime 0.139835   LR 0.010000   
2022-11-04 01:52:09,102 - INFO  - Training [12][  140/  196]   Loss 0.036318   Top1 98.772321   Top5 99.994420   BatchTime 0.137484   LR 0.010000   
2022-11-04 01:52:11,565 - INFO  - Training [12][  160/  196]   Loss 0.035985   Top1 98.774414   Top5 99.995117   BatchTime 0.135694   LR 0.010000   
2022-11-04 01:52:14,018 - INFO  - Training [12][  180/  196]   Loss 0.035805   Top1 98.763021   Top5 99.995660   BatchTime 0.134244   LR 0.010000   
2022-11-04 01:52:16,193 - INFO  - ==> Top1: 98.752    Top5: 99.996    Loss: 0.036

2022-11-04 01:52:16,193 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:52:19,078 - INFO  - Validation [12][   20/   40]   Loss 0.447702   Top1 90.292969   Top5 99.531250   BatchTime 0.144153   
2022-11-04 01:52:20,183 - INFO  - Validation [12][   40/   40]   Loss 0.427656   Top1 90.490000   Top5 99.630000   BatchTime 0.099711   
2022-11-04 01:52:20,431 - INFO  - ==> Top1: 90.490    Top5: 99.630    Loss: 0.428

2022-11-04 01:52:20,476 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:52:20,477 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:52:20,477 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:52:20,594 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:52:20,594 - INFO  - >>>>>>>> Epoch  13
2022-11-04 01:52:20,596 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:52:24,947 - INFO  - Training [13][   20/  196]   Loss 0.028067   Top1 99.003906   Top5 100.000000   BatchTime 0.217542   LR 0.010000   
2022-11-04 01:52:27,419 - INFO  - Training [13][   40/  196]   Loss 0.029725   Top1 98.906250   Top5 100.000000   BatchTime 0.170581   LR 0.010000   
2022-11-04 01:52:29,970 - INFO  - Training [13][   60/  196]   Loss 0.032731   Top1 98.776042   Top5 100.000000   BatchTime 0.156236   LR 0.010000   
2022-11-04 01:52:32,442 - INFO  - Training [13][   80/  196]   Loss 0.033022   Top1 98.750000   Top5 100.000000   BatchTime 0.148073   LR 0.010000   
2022-11-04 01:52:34,261 - INFO  - Training [13][  100/  196]   Loss 0.034506   Top1 98.714844   Top5 100.000000   BatchTime 0.136644   LR 0.010000   
2022-11-04 01:52:36,347 - INFO  - Training [13][  120/  196]   Loss 0.034459   Top1 98.740234   Top5 100.000000   BatchTime 0.131254   LR 0.010000   
2022-11-04 01:52:38,373 - INFO  - Training [13][  140/  196]   Loss 0.033797   Top1 98.783482   Top5 100.000000   BatchTime 0.126976   LR 0.010000   
2022-11-04 01:52:40,351 - INFO  - Training [13][  160/  196]   Loss 0.034394   Top1 98.769531   Top5 100.000000   BatchTime 0.123469   LR 0.010000   
2022-11-04 01:52:42,186 - INFO  - Training [13][  180/  196]   Loss 0.034962   Top1 98.765191   Top5 100.000000   BatchTime 0.119942   LR 0.010000   
2022-11-04 01:52:44,375 - INFO  - ==> Top1: 98.750    Top5: 100.000    Loss: 0.035

2022-11-04 01:52:44,376 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:52:47,220 - INFO  - Validation [13][   20/   40]   Loss 0.452017   Top1 90.234375   Top5 99.531250   BatchTime 0.142132   
2022-11-04 01:52:48,326 - INFO  - Validation [13][   40/   40]   Loss 0.438522   Top1 90.490000   Top5 99.590000   BatchTime 0.098722   
2022-11-04 01:52:48,579 - INFO  - ==> Top1: 90.490    Top5: 99.590    Loss: 0.439

2022-11-04 01:52:48,618 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:52:48,619 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:52:48,619 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:52:48,725 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:52:48,725 - INFO  - >>>>>>>> Epoch  14
2022-11-04 01:52:48,727 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:52:53,119 - INFO  - Training [14][   20/  196]   Loss 0.031665   Top1 98.925781   Top5 100.000000   BatchTime 0.219620   LR 0.010000   
2022-11-04 01:52:55,574 - INFO  - Training [14][   40/  196]   Loss 0.031836   Top1 98.886719   Top5 100.000000   BatchTime 0.171183   LR 0.010000   
2022-11-04 01:52:58,045 - INFO  - Training [14][   60/  196]   Loss 0.032669   Top1 98.854167   Top5 100.000000   BatchTime 0.155293   LR 0.010000   
2022-11-04 01:53:00,517 - INFO  - Training [14][   80/  196]   Loss 0.032638   Top1 98.842773   Top5 100.000000   BatchTime 0.147369   LR 0.010000   
2022-11-04 01:53:02,987 - INFO  - Training [14][  100/  196]   Loss 0.033373   Top1 98.781250   Top5 100.000000   BatchTime 0.142596   LR 0.010000   
2022-11-04 01:53:05,455 - INFO  - Training [14][  120/  196]   Loss 0.033057   Top1 98.798828   Top5 100.000000   BatchTime 0.139402   LR 0.010000   
2022-11-04 01:53:07,936 - INFO  - Training [14][  140/  196]   Loss 0.032965   Top1 98.836496   Top5 100.000000   BatchTime 0.137202   LR 0.010000   
2022-11-04 01:53:10,390 - INFO  - Training [14][  160/  196]   Loss 0.033318   Top1 98.840332   Top5 100.000000   BatchTime 0.135393   LR 0.010000   
2022-11-04 01:53:12,853 - INFO  - Training [14][  180/  196]   Loss 0.033822   Top1 98.819444   Top5 99.997830   BatchTime 0.134031   LR 0.010000   
2022-11-04 01:53:15,017 - INFO  - ==> Top1: 98.810    Top5: 99.998    Loss: 0.034

2022-11-04 01:53:15,018 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:53:17,876 - INFO  - Validation [14][   20/   40]   Loss 0.464042   Top1 89.824219   Top5 99.433594   BatchTime 0.142847   
2022-11-04 01:53:18,971 - INFO  - Validation [14][   40/   40]   Loss 0.448392   Top1 90.180000   Top5 99.520000   BatchTime 0.098805   
2022-11-04 01:53:19,222 - INFO  - ==> Top1: 90.180    Top5: 99.520    Loss: 0.448

2022-11-04 01:53:19,265 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:53:19,266 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:53:19,266 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:53:19,344 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:53:19,344 - INFO  - >>>>>>>> Epoch  15
2022-11-04 01:53:19,346 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:53:23,695 - INFO  - Training [15][   20/  196]   Loss 0.030246   Top1 99.101562   Top5 100.000000   BatchTime 0.217473   LR 0.010000   
2022-11-04 01:53:25,855 - INFO  - Training [15][   40/  196]   Loss 0.031888   Top1 98.964844   Top5 100.000000   BatchTime 0.162739   LR 0.010000   
2022-11-04 01:53:27,791 - INFO  - Training [15][   60/  196]   Loss 0.031434   Top1 98.886719   Top5 100.000000   BatchTime 0.140755   LR 0.010000   
2022-11-04 01:53:29,834 - INFO  - Training [15][   80/  196]   Loss 0.031298   Top1 98.906250   Top5 100.000000   BatchTime 0.131095   LR 0.010000   
2022-11-04 01:53:31,868 - INFO  - Training [15][  100/  196]   Loss 0.031459   Top1 98.933594   Top5 100.000000   BatchTime 0.125220   LR 0.010000   
2022-11-04 01:53:33,694 - INFO  - Training [15][  120/  196]   Loss 0.032455   Top1 98.883464   Top5 100.000000   BatchTime 0.119566   LR 0.010000   
2022-11-04 01:53:36,122 - INFO  - Training [15][  140/  196]   Loss 0.033025   Top1 98.861607   Top5 100.000000   BatchTime 0.119825   LR 0.010000   
2022-11-04 01:53:38,586 - INFO  - Training [15][  160/  196]   Loss 0.033572   Top1 98.833008   Top5 100.000000   BatchTime 0.120248   LR 0.010000   
2022-11-04 01:53:41,051 - INFO  - Training [15][  180/  196]   Loss 0.033397   Top1 98.847656   Top5 100.000000   BatchTime 0.120580   LR 0.010000   
2022-11-04 01:53:43,251 - INFO  - ==> Top1: 98.840    Top5: 100.000    Loss: 0.033

2022-11-04 01:53:43,252 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:53:46,137 - INFO  - Validation [15][   20/   40]   Loss 0.466704   Top1 90.039062   Top5 99.453125   BatchTime 0.144193   
2022-11-04 01:53:47,295 - INFO  - Validation [15][   40/   40]   Loss 0.447945   Top1 90.370000   Top5 99.520000   BatchTime 0.101032   
2022-11-04 01:53:47,544 - INFO  - ==> Top1: 90.370    Top5: 99.520    Loss: 0.448

2022-11-04 01:53:47,579 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:53:47,580 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:53:47,580 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:53:47,690 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:53:47,691 - INFO  - >>>>>>>> Epoch  16
2022-11-04 01:53:47,692 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:53:52,032 - INFO  - Training [16][   20/  196]   Loss 0.033567   Top1 98.925781   Top5 100.000000   BatchTime 0.217002   LR 0.010000   
2022-11-04 01:53:54,500 - INFO  - Training [16][   40/  196]   Loss 0.034974   Top1 98.876953   Top5 99.990234   BatchTime 0.170186   LR 0.010000   
2022-11-04 01:53:56,971 - INFO  - Training [16][   60/  196]   Loss 0.034139   Top1 98.854167   Top5 99.993490   BatchTime 0.154641   LR 0.010000   
2022-11-04 01:53:59,457 - INFO  - Training [16][   80/  196]   Loss 0.035834   Top1 98.779297   Top5 99.995117   BatchTime 0.147063   LR 0.010000   
2022-11-04 01:54:01,934 - INFO  - Training [16][  100/  196]   Loss 0.037097   Top1 98.714844   Top5 99.996094   BatchTime 0.142418   LR 0.010000   
2022-11-04 01:54:04,407 - INFO  - Training [16][  120/  196]   Loss 0.036720   Top1 98.740234   Top5 99.996745   BatchTime 0.139291   LR 0.010000   
2022-11-04 01:54:06,877 - INFO  - Training [16][  140/  196]   Loss 0.036506   Top1 98.741629   Top5 99.997210   BatchTime 0.137028   LR 0.010000   
2022-11-04 01:54:09,335 - INFO  - Training [16][  160/  196]   Loss 0.035778   Top1 98.774414   Top5 99.997559   BatchTime 0.135264   LR 0.010000   
2022-11-04 01:54:11,798 - INFO  - Training [16][  180/  196]   Loss 0.035987   Top1 98.778212   Top5 99.997830   BatchTime 0.133916   LR 0.010000   
2022-11-04 01:54:13,964 - INFO  - ==> Top1: 98.796    Top5: 99.998    Loss: 0.036

2022-11-04 01:54:13,965 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:54:16,820 - INFO  - Validation [16][   20/   40]   Loss 0.477535   Top1 89.472656   Top5 99.589844   BatchTime 0.142713   
2022-11-04 01:54:17,869 - INFO  - Validation [16][   40/   40]   Loss 0.453381   Top1 90.070000   Top5 99.620000   BatchTime 0.097587   
2022-11-04 01:54:18,131 - INFO  - ==> Top1: 90.070    Top5: 99.620    Loss: 0.453

2022-11-04 01:54:18,156 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:54:18,157 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:54:18,157 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:54:18,266 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:54:18,266 - INFO  - >>>>>>>> Epoch  17
2022-11-04 01:54:18,268 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:54:22,321 - INFO  - Training [17][   20/  196]   Loss 0.032903   Top1 98.808594   Top5 100.000000   BatchTime 0.202640   LR 0.010000   
2022-11-04 01:54:24,352 - INFO  - Training [17][   40/  196]   Loss 0.033888   Top1 98.779297   Top5 100.000000   BatchTime 0.152095   LR 0.010000   
2022-11-04 01:54:26,198 - INFO  - Training [17][   60/  196]   Loss 0.031846   Top1 98.912760   Top5 100.000000   BatchTime 0.132164   LR 0.010000   
2022-11-04 01:54:28,518 - INFO  - Training [17][   80/  196]   Loss 0.033534   Top1 98.833008   Top5 100.000000   BatchTime 0.128129   LR 0.010000   
2022-11-04 01:54:31,089 - INFO  - Training [17][  100/  196]   Loss 0.032874   Top1 98.863281   Top5 100.000000   BatchTime 0.128209   LR 0.010000   
2022-11-04 01:54:33,562 - INFO  - Training [17][  120/  196]   Loss 0.033093   Top1 98.876953   Top5 100.000000   BatchTime 0.127446   LR 0.010000   
2022-11-04 01:54:36,035 - INFO  - Training [17][  140/  196]   Loss 0.032786   Top1 98.903460   Top5 100.000000   BatchTime 0.126903   LR 0.010000   
2022-11-04 01:54:38,503 - INFO  - Training [17][  160/  196]   Loss 0.032659   Top1 98.913574   Top5 100.000000   BatchTime 0.126463   LR 0.010000   
2022-11-04 01:54:40,965 - INFO  - Training [17][  180/  196]   Loss 0.032126   Top1 98.936632   Top5 100.000000   BatchTime 0.126094   LR 0.010000   
2022-11-04 01:54:43,139 - INFO  - ==> Top1: 98.922    Top5: 100.000    Loss: 0.032

2022-11-04 01:54:43,140 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:54:45,978 - INFO  - Validation [17][   20/   40]   Loss 0.466033   Top1 89.687500   Top5 99.394531   BatchTime 0.141815   
2022-11-04 01:54:47,116 - INFO  - Validation [17][   40/   40]   Loss 0.451392   Top1 90.240000   Top5 99.510000   BatchTime 0.099367   
2022-11-04 01:54:47,368 - INFO  - ==> Top1: 90.240    Top5: 99.510    Loss: 0.451

2022-11-04 01:54:47,397 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:54:47,398 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:54:47,398 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:54:47,500 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:54:47,500 - INFO  - >>>>>>>> Epoch  18
2022-11-04 01:54:47,502 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:54:51,849 - INFO  - Training [18][   20/  196]   Loss 0.035696   Top1 98.789062   Top5 100.000000   BatchTime 0.217339   LR 0.010000   
2022-11-04 01:54:54,324 - INFO  - Training [18][   40/  196]   Loss 0.033335   Top1 98.886719   Top5 100.000000   BatchTime 0.170543   LR 0.010000   
2022-11-04 01:54:56,821 - INFO  - Training [18][   60/  196]   Loss 0.031907   Top1 98.906250   Top5 100.000000   BatchTime 0.155323   LR 0.010000   
2022-11-04 01:54:59,280 - INFO  - Training [18][   80/  196]   Loss 0.032086   Top1 98.886719   Top5 100.000000   BatchTime 0.147219   LR 0.010000   
2022-11-04 01:55:01,755 - INFO  - Training [18][  100/  196]   Loss 0.032881   Top1 98.867188   Top5 100.000000   BatchTime 0.142531   LR 0.010000   
2022-11-04 01:55:04,233 - INFO  - Training [18][  120/  196]   Loss 0.033079   Top1 98.821615   Top5 100.000000   BatchTime 0.139427   LR 0.010000   
2022-11-04 01:55:06,692 - INFO  - Training [18][  140/  196]   Loss 0.033268   Top1 98.830915   Top5 100.000000   BatchTime 0.137073   LR 0.010000   
2022-11-04 01:55:09,135 - INFO  - Training [18][  160/  196]   Loss 0.032914   Top1 98.842773   Top5 99.997559   BatchTime 0.135204   LR 0.010000   
2022-11-04 01:55:11,583 - INFO  - Training [18][  180/  196]   Loss 0.032477   Top1 98.867188   Top5 99.997830   BatchTime 0.133785   LR 0.010000   
2022-11-04 01:55:13,559 - INFO  - ==> Top1: 98.870    Top5: 99.998    Loss: 0.032

2022-11-04 01:55:13,559 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:55:16,232 - INFO  - Validation [18][   20/   40]   Loss 0.465007   Top1 89.882812   Top5 99.492188   BatchTime 0.133582   
2022-11-04 01:55:17,084 - INFO  - Validation [18][   40/   40]   Loss 0.448706   Top1 90.380000   Top5 99.610000   BatchTime 0.088085   
2022-11-04 01:55:17,339 - INFO  - ==> Top1: 90.380    Top5: 99.610    Loss: 0.449

2022-11-04 01:55:17,372 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:55:17,373 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:55:17,373 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:55:17,476 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:55:17,476 - INFO  - >>>>>>>> Epoch  19
2022-11-04 01:55:17,478 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:55:22,044 - INFO  - Training [19][   20/  196]   Loss 0.029661   Top1 98.925781   Top5 100.000000   BatchTime 0.228282   LR 0.010000   
2022-11-04 01:55:24,525 - INFO  - Training [19][   40/  196]   Loss 0.027248   Top1 99.033203   Top5 100.000000   BatchTime 0.176169   LR 0.010000   
2022-11-04 01:55:26,997 - INFO  - Training [19][   60/  196]   Loss 0.030007   Top1 98.951823   Top5 100.000000   BatchTime 0.158640   LR 0.010000   
2022-11-04 01:55:29,468 - INFO  - Training [19][   80/  196]   Loss 0.028607   Top1 99.062500   Top5 100.000000   BatchTime 0.149862   LR 0.010000   
2022-11-04 01:55:31,970 - INFO  - Training [19][  100/  196]   Loss 0.028596   Top1 99.039062   Top5 100.000000   BatchTime 0.144908   LR 0.010000   
2022-11-04 01:55:34,446 - INFO  - Training [19][  120/  196]   Loss 0.029100   Top1 99.023438   Top5 100.000000   BatchTime 0.141388   LR 0.010000   
2022-11-04 01:55:36,925 - INFO  - Training [19][  140/  196]   Loss 0.028838   Top1 99.023438   Top5 100.000000   BatchTime 0.138902   LR 0.010000   
2022-11-04 01:55:39,391 - INFO  - Training [19][  160/  196]   Loss 0.029534   Top1 99.001465   Top5 100.000000   BatchTime 0.136947   LR 0.010000   
2022-11-04 01:55:41,849 - INFO  - Training [19][  180/  196]   Loss 0.030349   Top1 98.977865   Top5 100.000000   BatchTime 0.135387   LR 0.010000   
2022-11-04 01:55:44,027 - INFO  - ==> Top1: 98.984    Top5: 100.000    Loss: 0.030

2022-11-04 01:55:44,028 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:55:46,851 - INFO  - Validation [19][   20/   40]   Loss 0.460573   Top1 90.175781   Top5 99.472656   BatchTime 0.141114   
2022-11-04 01:55:47,978 - INFO  - Validation [19][   40/   40]   Loss 0.454406   Top1 90.270000   Top5 99.560000   BatchTime 0.098733   
2022-11-04 01:55:48,238 - INFO  - ==> Top1: 90.270    Top5: 99.560    Loss: 0.454

2022-11-04 01:55:48,272 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:55:48,273 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:55:48,273 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:55:48,375 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:55:48,376 - INFO  - >>>>>>>> Epoch  20
2022-11-04 01:55:48,377 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:55:52,787 - INFO  - Training [20][   20/  196]   Loss 0.027084   Top1 99.062500   Top5 100.000000   BatchTime 0.220492   LR 0.010000   
2022-11-04 01:55:55,283 - INFO  - Training [20][   40/  196]   Loss 0.028055   Top1 98.945312   Top5 100.000000   BatchTime 0.172645   LR 0.010000   
2022-11-04 01:55:57,790 - INFO  - Training [20][   60/  196]   Loss 0.031037   Top1 98.886719   Top5 100.000000   BatchTime 0.156880   LR 0.010000   
2022-11-04 01:56:00,261 - INFO  - Training [20][   80/  196]   Loss 0.032746   Top1 98.828125   Top5 100.000000   BatchTime 0.148545   LR 0.010000   
2022-11-04 01:56:02,729 - INFO  - Training [20][  100/  196]   Loss 0.031158   Top1 98.882812   Top5 100.000000   BatchTime 0.143510   LR 0.010000   
2022-11-04 01:56:05,195 - INFO  - Training [20][  120/  196]   Loss 0.031367   Top1 98.876953   Top5 99.996745   BatchTime 0.140140   LR 0.010000   
2022-11-04 01:56:07,093 - INFO  - Training [20][  140/  196]   Loss 0.032011   Top1 98.864397   Top5 99.997210   BatchTime 0.133677   LR 0.010000   
2022-11-04 01:56:09,072 - INFO  - Training [20][  160/  196]   Loss 0.031652   Top1 98.894043   Top5 99.997559   BatchTime 0.129339   LR 0.010000   
2022-11-04 01:56:11,081 - INFO  - Training [20][  180/  196]   Loss 0.031920   Top1 98.882378   Top5 99.997830   BatchTime 0.126129   LR 0.010000   
2022-11-04 01:56:13,105 - INFO  - ==> Top1: 98.872    Top5: 99.998    Loss: 0.032

2022-11-04 01:56:13,106 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:56:15,931 - INFO  - Validation [20][   20/   40]   Loss 0.475492   Top1 89.746094   Top5 99.433594   BatchTime 0.141221   
2022-11-04 01:56:17,077 - INFO  - Validation [20][   40/   40]   Loss 0.453262   Top1 90.110000   Top5 99.550000   BatchTime 0.099260   
2022-11-04 01:56:17,337 - INFO  - ==> Top1: 90.110    Top5: 99.550    Loss: 0.453

2022-11-04 01:56:17,365 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:56:17,366 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:56:17,366 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:56:17,473 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:56:17,474 - INFO  - >>>>>>>> Epoch  21
2022-11-04 01:56:17,475 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:56:21,811 - INFO  - Training [21][   20/  196]   Loss 0.030876   Top1 99.101562   Top5 100.000000   BatchTime 0.216769   LR 0.010000   
2022-11-04 01:56:24,276 - INFO  - Training [21][   40/  196]   Loss 0.032583   Top1 98.955078   Top5 100.000000   BatchTime 0.170013   LR 0.010000   
2022-11-04 01:56:26,734 - INFO  - Training [21][   60/  196]   Loss 0.031984   Top1 98.912760   Top5 100.000000   BatchTime 0.154302   LR 0.010000   
2022-11-04 01:56:29,199 - INFO  - Training [21][   80/  196]   Loss 0.031462   Top1 98.906250   Top5 100.000000   BatchTime 0.146547   LR 0.010000   
2022-11-04 01:56:31,672 - INFO  - Training [21][  100/  196]   Loss 0.031341   Top1 98.906250   Top5 100.000000   BatchTime 0.141961   LR 0.010000   
2022-11-04 01:56:34,152 - INFO  - Training [21][  120/  196]   Loss 0.030640   Top1 98.925781   Top5 100.000000   BatchTime 0.138968   LR 0.010000   
2022-11-04 01:56:36,708 - INFO  - Training [21][  140/  196]   Loss 0.029848   Top1 98.962054   Top5 100.000000   BatchTime 0.137377   LR 0.010000   
2022-11-04 01:56:39,168 - INFO  - Training [21][  160/  196]   Loss 0.030266   Top1 98.928223   Top5 100.000000   BatchTime 0.135579   LR 0.010000   
2022-11-04 01:56:41,631 - INFO  - Training [21][  180/  196]   Loss 0.030406   Top1 98.925781   Top5 100.000000   BatchTime 0.134194   LR 0.010000   
2022-11-04 01:56:43,814 - INFO  - ==> Top1: 98.894    Top5: 100.000    Loss: 0.031

2022-11-04 01:56:43,815 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:56:46,656 - INFO  - Validation [21][   20/   40]   Loss 0.489961   Top1 90.136719   Top5 99.394531   BatchTime 0.142008   
2022-11-04 01:56:47,780 - INFO  - Validation [21][   40/   40]   Loss 0.467026   Top1 90.320000   Top5 99.540000   BatchTime 0.099105   
2022-11-04 01:56:48,032 - INFO  - ==> Top1: 90.320    Top5: 99.540    Loss: 0.467

2022-11-04 01:56:48,060 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:56:48,061 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:56:48,061 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:56:48,168 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:56:48,168 - INFO  - >>>>>>>> Epoch  22
2022-11-04 01:56:48,170 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:56:52,549 - INFO  - Training [22][   20/  196]   Loss 0.029385   Top1 99.023438   Top5 100.000000   BatchTime 0.218950   LR 0.010000   
2022-11-04 01:56:55,020 - INFO  - Training [22][   40/  196]   Loss 0.027623   Top1 99.033203   Top5 100.000000   BatchTime 0.171263   LR 0.010000   
2022-11-04 01:56:57,475 - INFO  - Training [22][   60/  196]   Loss 0.027115   Top1 99.055990   Top5 100.000000   BatchTime 0.155088   LR 0.010000   
2022-11-04 01:56:59,866 - INFO  - Training [22][   80/  196]   Loss 0.028389   Top1 98.974609   Top5 100.000000   BatchTime 0.146197   LR 0.010000   
2022-11-04 01:57:01,719 - INFO  - Training [22][  100/  196]   Loss 0.028883   Top1 98.968750   Top5 100.000000   BatchTime 0.135486   LR 0.010000   
2022-11-04 01:57:03,766 - INFO  - Training [22][  120/  196]   Loss 0.028149   Top1 99.013672   Top5 100.000000   BatchTime 0.129969   LR 0.010000   
2022-11-04 01:57:05,798 - INFO  - Training [22][  140/  196]   Loss 0.028564   Top1 99.001116   Top5 100.000000   BatchTime 0.125914   LR 0.010000   
2022-11-04 01:57:07,687 - INFO  - Training [22][  160/  196]   Loss 0.029154   Top1 98.984375   Top5 100.000000   BatchTime 0.121979   LR 0.010000   
2022-11-04 01:57:09,789 - INFO  - Training [22][  180/  196]   Loss 0.029641   Top1 98.962674   Top5 100.000000   BatchTime 0.120102   LR 0.010000   
2022-11-04 01:57:11,988 - INFO  - ==> Top1: 98.918    Top5: 100.000    Loss: 0.030

2022-11-04 01:57:11,989 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:57:14,851 - INFO  - Validation [22][   20/   40]   Loss 0.478536   Top1 89.765625   Top5 99.531250   BatchTime 0.143018   
2022-11-04 01:57:15,955 - INFO  - Validation [22][   40/   40]   Loss 0.456180   Top1 90.250000   Top5 99.610000   BatchTime 0.099105   
2022-11-04 01:57:16,215 - INFO  - ==> Top1: 90.250    Top5: 99.610    Loss: 0.456

2022-11-04 01:57:16,252 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:57:16,253 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:57:16,253 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:57:16,361 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:57:16,362 - INFO  - >>>>>>>> Epoch  23
2022-11-04 01:57:16,363 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:57:20,767 - INFO  - Training [23][   20/  196]   Loss 0.033639   Top1 98.886719   Top5 100.000000   BatchTime 0.220192   LR 0.010000   
2022-11-04 01:57:23,246 - INFO  - Training [23][   40/  196]   Loss 0.033858   Top1 98.886719   Top5 100.000000   BatchTime 0.172078   LR 0.010000   
2022-11-04 01:57:25,730 - INFO  - Training [23][   60/  196]   Loss 0.031415   Top1 98.964844   Top5 100.000000   BatchTime 0.156109   LR 0.010000   
2022-11-04 01:57:28,227 - INFO  - Training [23][   80/  196]   Loss 0.030582   Top1 98.994141   Top5 99.995117   BatchTime 0.148298   LR 0.010000   
2022-11-04 01:57:30,692 - INFO  - Training [23][  100/  196]   Loss 0.029807   Top1 99.031250   Top5 99.996094   BatchTime 0.143291   LR 0.010000   
2022-11-04 01:57:33,154 - INFO  - Training [23][  120/  196]   Loss 0.030722   Top1 99.007161   Top5 99.996745   BatchTime 0.139920   LR 0.010000   
2022-11-04 01:57:35,623 - INFO  - Training [23][  140/  196]   Loss 0.030723   Top1 98.973214   Top5 99.997210   BatchTime 0.137569   LR 0.010000   
2022-11-04 01:57:38,076 - INFO  - Training [23][  160/  196]   Loss 0.030575   Top1 98.977051   Top5 99.995117   BatchTime 0.135701   LR 0.010000   
2022-11-04 01:57:40,535 - INFO  - Training [23][  180/  196]   Loss 0.030894   Top1 98.962674   Top5 99.995660   BatchTime 0.134284   LR 0.010000   
2022-11-04 01:57:42,713 - INFO  - ==> Top1: 98.940    Top5: 99.996    Loss: 0.031

2022-11-04 01:57:42,714 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:57:45,581 - INFO  - Validation [23][   20/   40]   Loss 0.463593   Top1 89.921875   Top5 99.453125   BatchTime 0.143300   
2022-11-04 01:57:46,699 - INFO  - Validation [23][   40/   40]   Loss 0.449620   Top1 90.320000   Top5 99.590000   BatchTime 0.099608   
2022-11-04 01:57:46,933 - INFO  - ==> Top1: 90.320    Top5: 99.590    Loss: 0.450

2022-11-04 01:57:46,966 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:57:46,967 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:57:46,967 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:57:47,072 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:57:47,072 - INFO  - >>>>>>>> Epoch  24
2022-11-04 01:57:47,073 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:57:51,384 - INFO  - Training [24][   20/  196]   Loss 0.025383   Top1 99.082031   Top5 100.000000   BatchTime 0.215528   LR 0.010000   
2022-11-04 01:57:53,279 - INFO  - Training [24][   40/  196]   Loss 0.023869   Top1 99.179688   Top5 100.000000   BatchTime 0.155147   LR 0.010000   
2022-11-04 01:57:55,303 - INFO  - Training [24][   60/  196]   Loss 0.025568   Top1 99.108073   Top5 100.000000   BatchTime 0.137158   LR 0.010000   
2022-11-04 01:57:57,346 - INFO  - Training [24][   80/  196]   Loss 0.026802   Top1 99.067383   Top5 100.000000   BatchTime 0.128403   LR 0.010000   
2022-11-04 01:57:59,398 - INFO  - Training [24][  100/  196]   Loss 0.027533   Top1 99.031250   Top5 100.000000   BatchTime 0.123246   LR 0.010000   
2022-11-04 01:58:01,289 - INFO  - Training [24][  120/  196]   Loss 0.028397   Top1 99.020182   Top5 99.996745   BatchTime 0.118459   LR 0.010000   
2022-11-04 01:58:03,775 - INFO  - Training [24][  140/  196]   Loss 0.027856   Top1 99.034598   Top5 99.997210   BatchTime 0.119294   LR 0.010000   
2022-11-04 01:58:06,229 - INFO  - Training [24][  160/  196]   Loss 0.028331   Top1 99.018555   Top5 99.997559   BatchTime 0.119723   LR 0.010000   
2022-11-04 01:58:08,689 - INFO  - Training [24][  180/  196]   Loss 0.028873   Top1 98.993056   Top5 99.997830   BatchTime 0.120083   LR 0.010000   
2022-11-04 01:58:10,857 - INFO  - ==> Top1: 98.988    Top5: 99.998    Loss: 0.029

2022-11-04 01:58:10,858 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:58:13,696 - INFO  - Validation [24][   20/   40]   Loss 0.464884   Top1 90.117188   Top5 99.492188   BatchTime 0.141827   
2022-11-04 01:58:14,788 - INFO  - Validation [24][   40/   40]   Loss 0.447492   Top1 90.480000   Top5 99.610000   BatchTime 0.098238   
2022-11-04 01:58:15,033 - INFO  - ==> Top1: 90.480    Top5: 99.610    Loss: 0.447

2022-11-04 01:58:15,067 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:58:15,067 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:58:15,067 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:58:15,180 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:58:15,181 - INFO  - >>>>>>>> Epoch  25
2022-11-04 01:58:15,182 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:58:19,538 - INFO  - Training [25][   20/  196]   Loss 0.028452   Top1 99.062500   Top5 100.000000   BatchTime 0.217774   LR 0.010000   
2022-11-04 01:58:22,010 - INFO  - Training [25][   40/  196]   Loss 0.027489   Top1 99.082031   Top5 100.000000   BatchTime 0.170700   LR 0.010000   
2022-11-04 01:58:24,499 - INFO  - Training [25][   60/  196]   Loss 0.030105   Top1 98.951823   Top5 100.000000   BatchTime 0.155271   LR 0.010000   
2022-11-04 01:58:26,972 - INFO  - Training [25][   80/  196]   Loss 0.029755   Top1 98.940430   Top5 100.000000   BatchTime 0.147377   LR 0.010000   
2022-11-04 01:58:29,443 - INFO  - Training [25][  100/  196]   Loss 0.029538   Top1 98.972656   Top5 100.000000   BatchTime 0.142608   LR 0.010000   
2022-11-04 01:58:31,922 - INFO  - Training [25][  120/  196]   Loss 0.029413   Top1 98.987630   Top5 100.000000   BatchTime 0.139493   LR 0.010000   
2022-11-04 01:58:34,389 - INFO  - Training [25][  140/  196]   Loss 0.028931   Top1 98.998326   Top5 100.000000   BatchTime 0.137192   LR 0.010000   
2022-11-04 01:58:36,846 - INFO  - Training [25][  160/  196]   Loss 0.029390   Top1 98.977051   Top5 100.000000   BatchTime 0.135398   LR 0.010000   
2022-11-04 01:58:39,314 - INFO  - Training [25][  180/  196]   Loss 0.029292   Top1 98.980035   Top5 100.000000   BatchTime 0.134064   LR 0.010000   
2022-11-04 01:58:41,494 - INFO  - ==> Top1: 98.972    Top5: 100.000    Loss: 0.029

2022-11-04 01:58:41,495 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:58:44,365 - INFO  - Validation [25][   20/   40]   Loss 0.477746   Top1 89.941406   Top5 99.531250   BatchTime 0.143390   
2022-11-04 01:58:45,365 - INFO  - Validation [25][   40/   40]   Loss 0.464094   Top1 90.320000   Top5 99.600000   BatchTime 0.096708   
2022-11-04 01:58:45,611 - INFO  - ==> Top1: 90.320    Top5: 99.600    Loss: 0.464

2022-11-04 01:58:45,634 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:58:45,635 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:58:45,635 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:58:45,716 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:58:45,716 - INFO  - >>>>>>>> Epoch  26
2022-11-04 01:58:45,717 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:58:49,888 - INFO  - Training [26][   20/  196]   Loss 0.026424   Top1 99.042969   Top5 100.000000   BatchTime 0.208537   LR 0.010000   
2022-11-04 01:58:51,986 - INFO  - Training [26][   40/  196]   Loss 0.025325   Top1 99.091797   Top5 100.000000   BatchTime 0.156707   LR 0.010000   
2022-11-04 01:58:53,772 - INFO  - Training [26][   60/  196]   Loss 0.024799   Top1 99.134115   Top5 100.000000   BatchTime 0.134242   LR 0.010000   
2022-11-04 01:58:56,201 - INFO  - Training [26][   80/  196]   Loss 0.026649   Top1 99.057617   Top5 100.000000   BatchTime 0.131039   LR 0.010000   
2022-11-04 01:58:58,672 - INFO  - Training [26][  100/  196]   Loss 0.026517   Top1 99.085938   Top5 100.000000   BatchTime 0.129538   LR 0.010000   
2022-11-04 01:59:01,140 - INFO  - Training [26][  120/  196]   Loss 0.027229   Top1 99.049479   Top5 100.000000   BatchTime 0.128515   LR 0.010000   
2022-11-04 01:59:03,606 - INFO  - Training [26][  140/  196]   Loss 0.027549   Top1 99.031808   Top5 100.000000   BatchTime 0.127773   LR 0.010000   
2022-11-04 01:59:06,071 - INFO  - Training [26][  160/  196]   Loss 0.027918   Top1 99.025879   Top5 100.000000   BatchTime 0.127205   LR 0.010000   
2022-11-04 01:59:08,546 - INFO  - Training [26][  180/  196]   Loss 0.027976   Top1 99.012587   Top5 100.000000   BatchTime 0.126821   LR 0.010000   
2022-11-04 01:59:10,720 - INFO  - ==> Top1: 99.008    Top5: 100.000    Loss: 0.028

2022-11-04 01:59:10,721 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:59:13,596 - INFO  - Validation [26][   20/   40]   Loss 0.463764   Top1 90.449219   Top5 99.453125   BatchTime 0.143659   
2022-11-04 01:59:14,696 - INFO  - Validation [26][   40/   40]   Loss 0.459129   Top1 90.480000   Top5 99.560000   BatchTime 0.099337   
2022-11-04 01:59:14,956 - INFO  - ==> Top1: 90.480    Top5: 99.560    Loss: 0.459

2022-11-04 01:59:15,006 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:59:15,007 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:59:15,007 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:59:15,121 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:59:15,122 - INFO  - >>>>>>>> Epoch  27
2022-11-04 01:59:15,123 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:59:19,517 - INFO  - Training [27][   20/  196]   Loss 0.027537   Top1 98.984375   Top5 100.000000   BatchTime 0.219686   LR 0.010000   
2022-11-04 01:59:21,995 - INFO  - Training [27][   40/  196]   Loss 0.025075   Top1 99.082031   Top5 100.000000   BatchTime 0.171809   LR 0.010000   
2022-11-04 01:59:24,465 - INFO  - Training [27][   60/  196]   Loss 0.027760   Top1 99.003906   Top5 100.000000   BatchTime 0.155704   LR 0.010000   
2022-11-04 01:59:26,933 - INFO  - Training [27][   80/  196]   Loss 0.027625   Top1 99.003906   Top5 100.000000   BatchTime 0.147621   LR 0.010000   
2022-11-04 01:59:29,405 - INFO  - Training [27][  100/  196]   Loss 0.026625   Top1 99.035156   Top5 100.000000   BatchTime 0.142818   LR 0.010000   
2022-11-04 01:59:31,877 - INFO  - Training [27][  120/  196]   Loss 0.027639   Top1 99.020182   Top5 100.000000   BatchTime 0.139613   LR 0.010000   
2022-11-04 01:59:34,334 - INFO  - Training [27][  140/  196]   Loss 0.027156   Top1 99.040179   Top5 100.000000   BatchTime 0.137221   LR 0.010000   
2022-11-04 01:59:36,783 - INFO  - Training [27][  160/  196]   Loss 0.027637   Top1 99.035645   Top5 100.000000   BatchTime 0.135372   LR 0.010000   
2022-11-04 01:59:39,238 - INFO  - Training [27][  180/  196]   Loss 0.027251   Top1 99.042969   Top5 100.000000   BatchTime 0.133971   LR 0.010000   
2022-11-04 01:59:41,040 - INFO  - ==> Top1: 99.024    Top5: 100.000    Loss: 0.028

2022-11-04 01:59:41,041 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:59:43,700 - INFO  - Validation [27][   20/   40]   Loss 0.481411   Top1 90.078125   Top5 99.394531   BatchTime 0.132858   
2022-11-04 01:59:44,560 - INFO  - Validation [27][   40/   40]   Loss 0.466874   Top1 90.430000   Top5 99.500000   BatchTime 0.087950   
2022-11-04 01:59:44,968 - INFO  - ==> Top1: 90.430    Top5: 99.500    Loss: 0.467

2022-11-04 01:59:45,005 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 01:59:45,008 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 01:59:45,008 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 01:59:45,116 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 01:59:45,116 - INFO  - >>>>>>>> Epoch  28
2022-11-04 01:59:45,118 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:59:49,598 - INFO  - Training [28][   20/  196]   Loss 0.027531   Top1 98.984375   Top5 100.000000   BatchTime 0.224014   LR 0.010000   
2022-11-04 01:59:52,064 - INFO  - Training [28][   40/  196]   Loss 0.028661   Top1 98.994141   Top5 100.000000   BatchTime 0.173658   LR 0.010000   
2022-11-04 01:59:54,540 - INFO  - Training [28][   60/  196]   Loss 0.028901   Top1 98.984375   Top5 100.000000   BatchTime 0.157034   LR 0.010000   
2022-11-04 01:59:57,012 - INFO  - Training [28][   80/  196]   Loss 0.028902   Top1 98.989258   Top5 100.000000   BatchTime 0.148679   LR 0.010000   
2022-11-04 01:59:59,487 - INFO  - Training [28][  100/  196]   Loss 0.028866   Top1 98.945312   Top5 100.000000   BatchTime 0.143694   LR 0.010000   
2022-11-04 02:00:01,966 - INFO  - Training [28][  120/  196]   Loss 0.030224   Top1 98.896484   Top5 100.000000   BatchTime 0.140401   LR 0.010000   
2022-11-04 02:00:04,451 - INFO  - Training [28][  140/  196]   Loss 0.030055   Top1 98.889509   Top5 100.000000   BatchTime 0.138090   LR 0.010000   
2022-11-04 02:00:06,918 - INFO  - Training [28][  160/  196]   Loss 0.029405   Top1 98.925781   Top5 100.000000   BatchTime 0.136247   LR 0.010000   
2022-11-04 02:00:09,384 - INFO  - Training [28][  180/  196]   Loss 0.029647   Top1 98.912760   Top5 99.997830   BatchTime 0.134812   LR 0.010000   
2022-11-04 02:00:11,499 - INFO  - ==> Top1: 98.928    Top5: 99.998    Loss: 0.030

2022-11-04 02:00:11,499 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:00:14,382 - INFO  - Validation [28][   20/   40]   Loss 0.474316   Top1 89.960938   Top5 99.355469   BatchTime 0.144042   
2022-11-04 02:00:15,505 - INFO  - Validation [28][   40/   40]   Loss 0.459344   Top1 90.400000   Top5 99.500000   BatchTime 0.100116   
2022-11-04 02:00:15,757 - INFO  - ==> Top1: 90.400    Top5: 99.500    Loss: 0.459

2022-11-04 02:00:15,795 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 02:00:15,796 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 02:00:15,796 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.490   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:00:15,899 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:00:15,900 - INFO  - >>>>>>>> Epoch  29
2022-11-04 02:00:15,901 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:00:20,291 - INFO  - Training [29][   20/  196]   Loss 0.024823   Top1 99.082031   Top5 100.000000   BatchTime 0.219489   LR 0.010000   
2022-11-04 02:00:22,770 - INFO  - Training [29][   40/  196]   Loss 0.025960   Top1 99.013672   Top5 100.000000   BatchTime 0.171721   LR 0.010000   
2022-11-04 02:00:25,251 - INFO  - Training [29][   60/  196]   Loss 0.025230   Top1 99.055990   Top5 100.000000   BatchTime 0.155829   LR 0.010000   
2022-11-04 02:00:27,722 - INFO  - Training [29][   80/  196]   Loss 0.025490   Top1 99.042969   Top5 100.000000   BatchTime 0.147760   LR 0.010000   
2022-11-04 02:00:30,198 - INFO  - Training [29][  100/  196]   Loss 0.026416   Top1 99.035156   Top5 100.000000   BatchTime 0.142965   LR 0.010000   
2022-11-04 02:00:32,659 - INFO  - Training [29][  120/  196]   Loss 0.026460   Top1 99.059245   Top5 100.000000   BatchTime 0.139646   LR 0.010000   
2022-11-04 02:00:34,560 - INFO  - Training [29][  140/  196]   Loss 0.026629   Top1 99.054129   Top5 100.000000   BatchTime 0.133280   LR 0.010000   
2022-11-04 02:00:36,558 - INFO  - Training [29][  160/  196]   Loss 0.026141   Top1 99.086914   Top5 100.000000   BatchTime 0.129108   LR 0.010000   
2022-11-04 02:00:38,563 - INFO  - Training [29][  180/  196]   Loss 0.026402   Top1 99.082031   Top5 100.000000   BatchTime 0.125898   LR 0.010000   
2022-11-04 02:00:40,601 - INFO  - ==> Top1: 99.080    Top5: 100.000    Loss: 0.027

2022-11-04 02:00:40,602 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:00:43,404 - INFO  - Validation [29][   20/   40]   Loss 0.481493   Top1 90.195312   Top5 99.335938   BatchTime 0.140046   
2022-11-04 02:00:44,491 - INFO  - Validation [29][   40/   40]   Loss 0.464011   Top1 90.570000   Top5 99.470000   BatchTime 0.097219   
2022-11-04 02:00:44,735 - INFO  - ==> Top1: 90.570    Top5: 99.470    Loss: 0.464

2022-11-04 02:00:44,777 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 02:00:44,777 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 90.570   Top5: 99.470] Sparsity : 0.847
2022-11-04 02:00:44,778 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.490   Top5: 99.630] Sparsity : 0.847
2022-11-04 02:00:44,862 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:00:44,862 - INFO  - >>>>>>>> Epoch  30
2022-11-04 02:00:44,863 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:00:49,257 - INFO  - Training [30][   20/  196]   Loss 0.028533   Top1 99.023438   Top5 100.000000   BatchTime 0.219712   LR 0.001000   
2022-11-04 02:00:51,823 - INFO  - Training [30][   40/  196]   Loss 0.027068   Top1 99.042969   Top5 100.000000   BatchTime 0.174003   LR 0.001000   
2022-11-04 02:00:54,292 - INFO  - Training [30][   60/  196]   Loss 0.028456   Top1 98.997396   Top5 100.000000   BatchTime 0.157146   LR 0.001000   
2022-11-04 02:00:56,756 - INFO  - Training [30][   80/  196]   Loss 0.027923   Top1 99.033203   Top5 100.000000   BatchTime 0.148663   LR 0.001000   
2022-11-04 02:00:59,227 - INFO  - Training [30][  100/  196]   Loss 0.028880   Top1 99.011719   Top5 99.996094   BatchTime 0.143637   LR 0.001000   
2022-11-04 02:01:01,695 - INFO  - Training [30][  120/  196]   Loss 0.028264   Top1 99.039714   Top5 99.996745   BatchTime 0.140262   LR 0.001000   
2022-11-04 02:01:04,162 - INFO  - Training [30][  140/  196]   Loss 0.028327   Top1 99.059710   Top5 99.994420   BatchTime 0.137850   LR 0.001000   
2022-11-04 02:01:06,622 - INFO  - Training [30][  160/  196]   Loss 0.027763   Top1 99.074707   Top5 99.995117   BatchTime 0.135991   LR 0.001000   
2022-11-04 02:01:09,081 - INFO  - Training [30][  180/  196]   Loss 0.027719   Top1 99.058160   Top5 99.995660   BatchTime 0.134541   LR 0.001000   
2022-11-04 02:01:11,252 - INFO  - ==> Top1: 99.078    Top5: 99.996    Loss: 0.027

2022-11-04 02:01:11,252 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:01:14,115 - INFO  - Validation [30][   20/   40]   Loss 0.463391   Top1 90.546875   Top5 99.335938   BatchTime 0.143054   
2022-11-04 02:01:15,211 - INFO  - Validation [30][   40/   40]   Loss 0.450204   Top1 90.780000   Top5 99.530000   BatchTime 0.098940   
2022-11-04 02:01:15,453 - INFO  - ==> Top1: 90.780    Top5: 99.530    Loss: 0.450

2022-11-04 02:01:15,492 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
2022-11-04 02:01:15,493 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 02:01:15,493 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.570   Top5: 99.470] Sparsity : 0.847
2022-11-04 02:01:15,676 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 02:01:15,828 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 02:01:15,829 - INFO  - >>>>>>>> Epoch  31
2022-11-04 02:01:15,830 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:01:20,129 - INFO  - Training [31][   20/  196]   Loss 0.029329   Top1 98.984375   Top5 100.000000   BatchTime 0.214929   LR 0.001000   
2022-11-04 02:01:22,597 - INFO  - Training [31][   40/  196]   Loss 0.026528   Top1 99.091797   Top5 100.000000   BatchTime 0.169174   LR 0.001000   
2022-11-04 02:01:25,061 - INFO  - Training [31][   60/  196]   Loss 0.024227   Top1 99.160156   Top5 100.000000   BatchTime 0.153845   LR 0.001000   
2022-11-04 02:01:27,320 - INFO  - Training [31][   80/  196]   Loss 0.023984   Top1 99.174805   Top5 100.000000   BatchTime 0.143630   LR 0.001000   
2022-11-04 02:01:29,220 - INFO  - Training [31][  100/  196]   Loss 0.023711   Top1 99.179688   Top5 100.000000   BatchTime 0.133894   LR 0.001000   
2022-11-04 02:01:31,246 - INFO  - Training [31][  120/  196]   Loss 0.022958   Top1 99.205729   Top5 100.000000   BatchTime 0.128467   LR 0.001000   
2022-11-04 02:01:33,265 - INFO  - Training [31][  140/  196]   Loss 0.022624   Top1 99.204799   Top5 100.000000   BatchTime 0.124530   LR 0.001000   
2022-11-04 02:01:35,120 - INFO  - Training [31][  160/  196]   Loss 0.022461   Top1 99.189453   Top5 100.000000   BatchTime 0.120562   LR 0.001000   
2022-11-04 02:01:37,284 - INFO  - Training [31][  180/  196]   Loss 0.022916   Top1 99.181858   Top5 100.000000   BatchTime 0.119187   LR 0.001000   
2022-11-04 02:01:39,468 - INFO  - ==> Top1: 99.184    Top5: 100.000    Loss: 0.023

2022-11-04 02:01:39,469 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:01:42,311 - INFO  - Validation [31][   20/   40]   Loss 0.461916   Top1 90.800781   Top5 99.414062   BatchTime 0.142039   
2022-11-04 02:01:43,453 - INFO  - Validation [31][   40/   40]   Loss 0.447801   Top1 91.050000   Top5 99.560000   BatchTime 0.099572   
2022-11-04 02:01:43,706 - INFO  - ==> Top1: 91.050    Top5: 99.560    Loss: 0.448

2022-11-04 02:01:43,745 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:01:43,745 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
2022-11-04 02:01:43,746 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 02:01:43,928 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 02:01:44,085 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_best.pth.tar

2022-11-04 02:01:44,085 - INFO  - >>>>>>>> Epoch  32
2022-11-04 02:01:44,086 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:01:48,446 - INFO  - Training [32][   20/  196]   Loss 0.020276   Top1 99.296875   Top5 100.000000   BatchTime 0.217955   LR 0.001000   
2022-11-04 02:01:50,914 - INFO  - Training [32][   40/  196]   Loss 0.021671   Top1 99.267578   Top5 100.000000   BatchTime 0.170696   LR 0.001000   
2022-11-04 02:01:53,389 - INFO  - Training [32][   60/  196]   Loss 0.022663   Top1 99.205729   Top5 99.993490   BatchTime 0.155041   LR 0.001000   
2022-11-04 02:01:55,872 - INFO  - Training [32][   80/  196]   Loss 0.022639   Top1 99.218750   Top5 99.995117   BatchTime 0.147314   LR 0.001000   
2022-11-04 02:01:58,359 - INFO  - Training [32][  100/  196]   Loss 0.022180   Top1 99.250000   Top5 99.996094   BatchTime 0.142720   LR 0.001000   
2022-11-04 02:02:00,845 - INFO  - Training [32][  120/  196]   Loss 0.021809   Top1 99.270833   Top5 99.996745   BatchTime 0.139651   LR 0.001000   
2022-11-04 02:02:03,266 - INFO  - Training [32][  140/  196]   Loss 0.022334   Top1 99.241071   Top5 99.997210   BatchTime 0.136993   LR 0.001000   
2022-11-04 02:02:05,736 - INFO  - Training [32][  160/  196]   Loss 0.022264   Top1 99.257812   Top5 99.997559   BatchTime 0.135307   LR 0.001000   
2022-11-04 02:02:08,193 - INFO  - Training [32][  180/  196]   Loss 0.022425   Top1 99.259983   Top5 99.997830   BatchTime 0.133921   LR 0.001000   
2022-11-04 02:02:10,364 - INFO  - ==> Top1: 99.270    Top5: 99.998    Loss: 0.022

2022-11-04 02:02:10,365 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:02:13,225 - INFO  - Validation [32][   20/   40]   Loss 0.464956   Top1 90.351562   Top5 99.453125   BatchTime 0.142922   
2022-11-04 02:02:14,346 - INFO  - Validation [32][   40/   40]   Loss 0.449856   Top1 90.630000   Top5 99.560000   BatchTime 0.099484   
2022-11-04 02:02:14,596 - INFO  - ==> Top1: 90.630    Top5: 99.560    Loss: 0.450

2022-11-04 02:02:14,634 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:02:14,635 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
2022-11-04 02:02:14,635 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 90.710   Top5: 99.580] Sparsity : 0.847
2022-11-04 02:02:14,736 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:02:14,736 - INFO  - >>>>>>>> Epoch  33
2022-11-04 02:02:14,737 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:02:19,015 - INFO  - Training [33][   20/  196]   Loss 0.020359   Top1 99.335938   Top5 100.000000   BatchTime 0.213911   LR 0.001000   
2022-11-04 02:02:20,813 - INFO  - Training [33][   40/  196]   Loss 0.018739   Top1 99.296875   Top5 100.000000   BatchTime 0.151899   LR 0.001000   
2022-11-04 02:02:22,862 - INFO  - Training [33][   60/  196]   Loss 0.020357   Top1 99.199219   Top5 100.000000   BatchTime 0.135414   LR 0.001000   
2022-11-04 02:02:24,879 - INFO  - Training [33][   80/  196]   Loss 0.022383   Top1 99.145508   Top5 100.000000   BatchTime 0.126770   LR 0.001000   
2022-11-04 02:02:26,893 - INFO  - Training [33][  100/  196]   Loss 0.022165   Top1 99.199219   Top5 100.000000   BatchTime 0.121557   LR 0.001000   
2022-11-04 02:02:28,952 - INFO  - Training [33][  120/  196]   Loss 0.021678   Top1 99.222005   Top5 100.000000   BatchTime 0.118452   LR 0.001000   
2022-11-04 02:02:31,416 - INFO  - Training [33][  140/  196]   Loss 0.021417   Top1 99.238281   Top5 100.000000   BatchTime 0.119129   LR 0.001000   
2022-11-04 02:02:33,885 - INFO  - Training [33][  160/  196]   Loss 0.021693   Top1 99.228516   Top5 100.000000   BatchTime 0.119670   LR 0.001000   
2022-11-04 02:02:36,352 - INFO  - Training [33][  180/  196]   Loss 0.022028   Top1 99.227431   Top5 100.000000   BatchTime 0.120080   LR 0.001000   
2022-11-04 02:02:38,531 - INFO  - ==> Top1: 99.234    Top5: 100.000    Loss: 0.022

2022-11-04 02:02:38,532 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:02:41,376 - INFO  - Validation [33][   20/   40]   Loss 0.459805   Top1 90.781250   Top5 99.472656   BatchTime 0.142164   
2022-11-04 02:02:42,448 - INFO  - Validation [33][   40/   40]   Loss 0.447397   Top1 90.900000   Top5 99.610000   BatchTime 0.097875   
2022-11-04 02:02:42,708 - INFO  - ==> Top1: 90.900    Top5: 99.610    Loss: 0.447

2022-11-04 02:02:42,750 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:02:42,750 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:02:42,750 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.780   Top5: 99.530] Sparsity : 0.847
2022-11-04 02:02:42,865 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:02:42,866 - INFO  - >>>>>>>> Epoch  34
2022-11-04 02:02:42,867 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:02:47,223 - INFO  - Training [34][   20/  196]   Loss 0.019758   Top1 99.414062   Top5 100.000000   BatchTime 0.217774   LR 0.001000   
2022-11-04 02:02:49,697 - INFO  - Training [34][   40/  196]   Loss 0.019464   Top1 99.414062   Top5 100.000000   BatchTime 0.170740   LR 0.001000   
2022-11-04 02:02:52,302 - INFO  - Training [34][   60/  196]   Loss 0.019280   Top1 99.394531   Top5 100.000000   BatchTime 0.157234   LR 0.001000   
2022-11-04 02:02:54,783 - INFO  - Training [34][   80/  196]   Loss 0.020343   Top1 99.370117   Top5 100.000000   BatchTime 0.148935   LR 0.001000   
2022-11-04 02:02:57,254 - INFO  - Training [34][  100/  196]   Loss 0.020952   Top1 99.343750   Top5 100.000000   BatchTime 0.143861   LR 0.001000   
2022-11-04 02:02:59,725 - INFO  - Training [34][  120/  196]   Loss 0.020112   Top1 99.378255   Top5 100.000000   BatchTime 0.140477   LR 0.001000   
2022-11-04 02:03:02,196 - INFO  - Training [34][  140/  196]   Loss 0.020951   Top1 99.327567   Top5 100.000000   BatchTime 0.138055   LR 0.001000   
2022-11-04 02:03:04,659 - INFO  - Training [34][  160/  196]   Loss 0.021204   Top1 99.318848   Top5 100.000000   BatchTime 0.136194   LR 0.001000   
2022-11-04 02:03:07,115 - INFO  - Training [34][  180/  196]   Loss 0.020906   Top1 99.325087   Top5 100.000000   BatchTime 0.134708   LR 0.001000   
2022-11-04 02:03:09,261 - INFO  - ==> Top1: 99.328    Top5: 100.000    Loss: 0.021

2022-11-04 02:03:09,262 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:03:12,096 - INFO  - Validation [34][   20/   40]   Loss 0.465314   Top1 90.507812   Top5 99.375000   BatchTime 0.141652   
2022-11-04 02:03:12,830 - INFO  - Validation [34][   40/   40]   Loss 0.450541   Top1 90.840000   Top5 99.510000   BatchTime 0.089177   
2022-11-04 02:03:13,086 - INFO  - ==> Top1: 90.840    Top5: 99.510    Loss: 0.451

2022-11-04 02:03:13,110 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:03:13,111 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:03:13,111 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:03:13,214 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:03:13,214 - INFO  - >>>>>>>> Epoch  35
2022-11-04 02:03:13,216 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:03:17,229 - INFO  - Training [35][   20/  196]   Loss 0.024515   Top1 99.257812   Top5 100.000000   BatchTime 0.200655   LR 0.001000   
2022-11-04 02:03:19,240 - INFO  - Training [35][   40/  196]   Loss 0.023037   Top1 99.267578   Top5 100.000000   BatchTime 0.150597   LR 0.001000   
2022-11-04 02:03:21,153 - INFO  - Training [35][   60/  196]   Loss 0.023680   Top1 99.212240   Top5 100.000000   BatchTime 0.132284   LR 0.001000   
2022-11-04 02:03:23,636 - INFO  - Training [35][   80/  196]   Loss 0.023038   Top1 99.223633   Top5 100.000000   BatchTime 0.130247   LR 0.001000   
2022-11-04 02:03:26,114 - INFO  - Training [35][  100/  196]   Loss 0.022491   Top1 99.218750   Top5 100.000000   BatchTime 0.128974   LR 0.001000   
2022-11-04 02:03:28,588 - INFO  - Training [35][  120/  196]   Loss 0.022567   Top1 99.218750   Top5 100.000000   BatchTime 0.128094   LR 0.001000   
2022-11-04 02:03:31,056 - INFO  - Training [35][  140/  196]   Loss 0.021915   Top1 99.249442   Top5 100.000000   BatchTime 0.127429   LR 0.001000   
2022-11-04 02:03:33,527 - INFO  - Training [35][  160/  196]   Loss 0.022182   Top1 99.240723   Top5 100.000000   BatchTime 0.126939   LR 0.001000   
2022-11-04 02:03:35,992 - INFO  - Training [35][  180/  196]   Loss 0.021894   Top1 99.253472   Top5 100.000000   BatchTime 0.126533   LR 0.001000   
2022-11-04 02:03:38,163 - INFO  - ==> Top1: 99.256    Top5: 100.000    Loss: 0.022

2022-11-04 02:03:38,164 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:03:41,032 - INFO  - Validation [35][   20/   40]   Loss 0.459945   Top1 90.253906   Top5 99.453125   BatchTime 0.143351   
2022-11-04 02:03:42,151 - INFO  - Validation [35][   40/   40]   Loss 0.448185   Top1 90.700000   Top5 99.610000   BatchTime 0.099653   
2022-11-04 02:03:42,422 - INFO  - ==> Top1: 90.700    Top5: 99.610    Loss: 0.448

2022-11-04 02:03:42,450 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:03:42,451 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:03:42,451 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:03:42,556 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:03:42,556 - INFO  - >>>>>>>> Epoch  36
2022-11-04 02:03:42,557 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:03:46,872 - INFO  - Training [36][   20/  196]   Loss 0.019598   Top1 99.355469   Top5 100.000000   BatchTime 0.215754   LR 0.001000   
2022-11-04 02:03:49,342 - INFO  - Training [36][   40/  196]   Loss 0.021788   Top1 99.267578   Top5 100.000000   BatchTime 0.169613   LR 0.001000   
2022-11-04 02:03:51,812 - INFO  - Training [36][   60/  196]   Loss 0.021949   Top1 99.212240   Top5 100.000000   BatchTime 0.154250   LR 0.001000   
2022-11-04 02:03:54,283 - INFO  - Training [36][   80/  196]   Loss 0.022179   Top1 99.233398   Top5 100.000000   BatchTime 0.146573   LR 0.001000   
2022-11-04 02:03:56,712 - INFO  - Training [36][  100/  196]   Loss 0.021551   Top1 99.257812   Top5 100.000000   BatchTime 0.141551   LR 0.001000   
2022-11-04 02:03:59,179 - INFO  - Training [36][  120/  196]   Loss 0.021306   Top1 99.280599   Top5 100.000000   BatchTime 0.138514   LR 0.001000   
2022-11-04 02:04:01,638 - INFO  - Training [36][  140/  196]   Loss 0.021511   Top1 99.271763   Top5 100.000000   BatchTime 0.136289   LR 0.001000   
2022-11-04 02:04:04,082 - INFO  - Training [36][  160/  196]   Loss 0.021162   Top1 99.279785   Top5 100.000000   BatchTime 0.134531   LR 0.001000   
2022-11-04 02:04:06,563 - INFO  - Training [36][  180/  196]   Loss 0.020970   Top1 99.286024   Top5 100.000000   BatchTime 0.133365   LR 0.001000   
2022-11-04 02:04:08,115 - INFO  - ==> Top1: 99.280    Top5: 100.000    Loss: 0.021

2022-11-04 02:04:08,116 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:04:10,758 - INFO  - Validation [36][   20/   40]   Loss 0.459182   Top1 90.449219   Top5 99.433594   BatchTime 0.132053   
2022-11-04 02:04:11,601 - INFO  - Validation [36][   40/   40]   Loss 0.447006   Top1 90.670000   Top5 99.550000   BatchTime 0.087101   
2022-11-04 02:04:11,842 - INFO  - ==> Top1: 90.670    Top5: 99.550    Loss: 0.447

2022-11-04 02:04:11,868 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:04:11,869 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:04:11,869 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:04:11,949 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:04:11,950 - INFO  - >>>>>>>> Epoch  37
2022-11-04 02:04:11,951 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:04:16,415 - INFO  - Training [37][   20/  196]   Loss 0.021570   Top1 99.355469   Top5 100.000000   BatchTime 0.223175   LR 0.001000   
2022-11-04 02:04:18,894 - INFO  - Training [37][   40/  196]   Loss 0.021662   Top1 99.267578   Top5 100.000000   BatchTime 0.173580   LR 0.001000   
2022-11-04 02:04:21,374 - INFO  - Training [37][   60/  196]   Loss 0.019985   Top1 99.290365   Top5 100.000000   BatchTime 0.157053   LR 0.001000   
2022-11-04 02:04:23,853 - INFO  - Training [37][   80/  196]   Loss 0.020568   Top1 99.282227   Top5 100.000000   BatchTime 0.148771   LR 0.001000   
2022-11-04 02:04:26,344 - INFO  - Training [37][  100/  196]   Loss 0.020131   Top1 99.296875   Top5 100.000000   BatchTime 0.143925   LR 0.001000   
2022-11-04 02:04:28,816 - INFO  - Training [37][  120/  196]   Loss 0.020025   Top1 99.309896   Top5 100.000000   BatchTime 0.140542   LR 0.001000   
2022-11-04 02:04:31,292 - INFO  - Training [37][  140/  196]   Loss 0.020614   Top1 99.296875   Top5 100.000000   BatchTime 0.138146   LR 0.001000   
2022-11-04 02:04:33,763 - INFO  - Training [37][  160/  196]   Loss 0.020379   Top1 99.313965   Top5 100.000000   BatchTime 0.136319   LR 0.001000   
2022-11-04 02:04:36,226 - INFO  - Training [37][  180/  196]   Loss 0.020311   Top1 99.318576   Top5 100.000000   BatchTime 0.134855   LR 0.001000   
2022-11-04 02:04:38,390 - INFO  - ==> Top1: 99.320    Top5: 100.000    Loss: 0.021

2022-11-04 02:04:38,391 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:04:41,284 - INFO  - Validation [37][   20/   40]   Loss 0.462820   Top1 90.292969   Top5 99.472656   BatchTime 0.144553   
2022-11-04 02:04:42,447 - INFO  - Validation [37][   40/   40]   Loss 0.451193   Top1 90.620000   Top5 99.590000   BatchTime 0.101364   
2022-11-04 02:04:42,705 - INFO  - ==> Top1: 90.620    Top5: 99.590    Loss: 0.451

2022-11-04 02:04:42,746 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:04:42,747 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:04:42,747 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:04:42,857 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:04:42,857 - INFO  - >>>>>>>> Epoch  38
2022-11-04 02:04:42,859 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:04:47,186 - INFO  - Training [38][   20/  196]   Loss 0.016520   Top1 99.394531   Top5 100.000000   BatchTime 0.216330   LR 0.001000   
2022-11-04 02:04:49,658 - INFO  - Training [38][   40/  196]   Loss 0.017980   Top1 99.384766   Top5 100.000000   BatchTime 0.169963   LR 0.001000   
2022-11-04 02:04:52,156 - INFO  - Training [38][   60/  196]   Loss 0.018345   Top1 99.361979   Top5 100.000000   BatchTime 0.154953   LR 0.001000   
2022-11-04 02:04:54,760 - INFO  - Training [38][   80/  196]   Loss 0.019484   Top1 99.316406   Top5 100.000000   BatchTime 0.148764   LR 0.001000   
2022-11-04 02:04:57,221 - INFO  - Training [38][  100/  196]   Loss 0.019536   Top1 99.339844   Top5 100.000000   BatchTime 0.143620   LR 0.001000   
2022-11-04 02:04:59,532 - INFO  - Training [38][  120/  196]   Loss 0.019162   Top1 99.355469   Top5 100.000000   BatchTime 0.138938   LR 0.001000   
2022-11-04 02:05:01,384 - INFO  - Training [38][  140/  196]   Loss 0.019389   Top1 99.355469   Top5 100.000000   BatchTime 0.132320   LR 0.001000   
2022-11-04 02:05:03,396 - INFO  - Training [38][  160/  196]   Loss 0.019230   Top1 99.375000   Top5 100.000000   BatchTime 0.128355   LR 0.001000   
2022-11-04 02:05:05,399 - INFO  - Training [38][  180/  196]   Loss 0.019101   Top1 99.370660   Top5 100.000000   BatchTime 0.125218   LR 0.001000   
2022-11-04 02:05:07,205 - INFO  - ==> Top1: 99.366    Top5: 100.000    Loss: 0.019

2022-11-04 02:05:07,206 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:05:10,112 - INFO  - Validation [38][   20/   40]   Loss 0.464872   Top1 90.312500   Top5 99.453125   BatchTime 0.145244   
2022-11-04 02:05:11,211 - INFO  - Validation [38][   40/   40]   Loss 0.448126   Top1 90.610000   Top5 99.590000   BatchTime 0.100079   
2022-11-04 02:05:11,476 - INFO  - ==> Top1: 90.610    Top5: 99.590    Loss: 0.448

2022-11-04 02:05:11,508 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:05:11,509 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:05:11,509 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:05:11,610 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:05:11,611 - INFO  - >>>>>>>> Epoch  39
2022-11-04 02:05:11,612 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:05:15,940 - INFO  - Training [39][   20/  196]   Loss 0.017085   Top1 99.453125   Top5 100.000000   BatchTime 0.216379   LR 0.001000   
2022-11-04 02:05:18,408 - INFO  - Training [39][   40/  196]   Loss 0.018691   Top1 99.335938   Top5 100.000000   BatchTime 0.169901   LR 0.001000   
2022-11-04 02:05:20,885 - INFO  - Training [39][   60/  196]   Loss 0.019198   Top1 99.329427   Top5 100.000000   BatchTime 0.154548   LR 0.001000   
2022-11-04 02:05:23,358 - INFO  - Training [39][   80/  196]   Loss 0.019467   Top1 99.360352   Top5 100.000000   BatchTime 0.146825   LR 0.001000   
2022-11-04 02:05:25,832 - INFO  - Training [39][  100/  196]   Loss 0.020379   Top1 99.316406   Top5 99.996094   BatchTime 0.142192   LR 0.001000   
2022-11-04 02:05:28,302 - INFO  - Training [39][  120/  196]   Loss 0.020436   Top1 99.309896   Top5 99.996745   BatchTime 0.139077   LR 0.001000   
2022-11-04 02:05:30,767 - INFO  - Training [39][  140/  196]   Loss 0.020831   Top1 99.302455   Top5 99.997210   BatchTime 0.136819   LR 0.001000   
2022-11-04 02:05:33,228 - INFO  - Training [39][  160/  196]   Loss 0.020758   Top1 99.291992   Top5 99.995117   BatchTime 0.135093   LR 0.001000   
2022-11-04 02:05:35,693 - INFO  - Training [39][  180/  196]   Loss 0.020835   Top1 99.279514   Top5 99.995660   BatchTime 0.133777   LR 0.001000   
2022-11-04 02:05:37,853 - INFO  - ==> Top1: 99.268    Top5: 99.996    Loss: 0.021

2022-11-04 02:05:37,854 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:05:40,725 - INFO  - Validation [39][   20/   40]   Loss 0.462321   Top1 90.332031   Top5 99.511719   BatchTime 0.143499   
2022-11-04 02:05:41,826 - INFO  - Validation [39][   40/   40]   Loss 0.447399   Top1 90.760000   Top5 99.630000   BatchTime 0.099287   
2022-11-04 02:05:42,081 - INFO  - ==> Top1: 90.760    Top5: 99.630    Loss: 0.447

2022-11-04 02:05:42,114 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:05:42,115 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:05:42,115 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:05:42,216 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:05:42,216 - INFO  - >>>>>>>> Epoch  40
2022-11-04 02:05:42,217 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:05:46,555 - INFO  - Training [40][   20/  196]   Loss 0.022088   Top1 99.414062   Top5 100.000000   BatchTime 0.216872   LR 0.001000   
2022-11-04 02:05:48,981 - INFO  - Training [40][   40/  196]   Loss 0.021890   Top1 99.345703   Top5 100.000000   BatchTime 0.169071   LR 0.001000   
2022-11-04 02:05:51,453 - INFO  - Training [40][   60/  196]   Loss 0.020881   Top1 99.355469   Top5 100.000000   BatchTime 0.153926   LR 0.001000   
2022-11-04 02:05:53,466 - INFO  - Training [40][   80/  196]   Loss 0.020590   Top1 99.360352   Top5 100.000000   BatchTime 0.140600   LR 0.001000   
2022-11-04 02:05:55,472 - INFO  - Training [40][  100/  196]   Loss 0.020363   Top1 99.363281   Top5 100.000000   BatchTime 0.132541   LR 0.001000   
2022-11-04 02:05:57,529 - INFO  - Training [40][  120/  196]   Loss 0.020529   Top1 99.355469   Top5 100.000000   BatchTime 0.127591   LR 0.001000   
2022-11-04 02:05:59,622 - INFO  - Training [40][  140/  196]   Loss 0.020524   Top1 99.338728   Top5 100.000000   BatchTime 0.124313   LR 0.001000   
2022-11-04 02:06:01,407 - INFO  - Training [40][  160/  196]   Loss 0.020243   Top1 99.353027   Top5 100.000000   BatchTime 0.119930   LR 0.001000   
2022-11-04 02:06:03,903 - INFO  - Training [40][  180/  196]   Loss 0.019911   Top1 99.359809   Top5 100.000000   BatchTime 0.120473   LR 0.001000   
2022-11-04 02:06:06,089 - INFO  - ==> Top1: 99.356    Top5: 100.000    Loss: 0.020

2022-11-04 02:06:06,089 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:06:08,934 - INFO  - Validation [40][   20/   40]   Loss 0.459816   Top1 90.312500   Top5 99.433594   BatchTime 0.142170   
2022-11-04 02:06:10,033 - INFO  - Validation [40][   40/   40]   Loss 0.444359   Top1 90.730000   Top5 99.570000   BatchTime 0.098542   
2022-11-04 02:06:10,282 - INFO  - ==> Top1: 90.730    Top5: 99.570    Loss: 0.444

2022-11-04 02:06:10,313 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:06:10,314 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:06:10,314 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.840   Top5: 99.510] Sparsity : 0.847
2022-11-04 02:06:10,401 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:06:10,401 - INFO  - >>>>>>>> Epoch  41
2022-11-04 02:06:10,402 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:06:14,787 - INFO  - Training [41][   20/  196]   Loss 0.024416   Top1 99.238281   Top5 100.000000   BatchTime 0.219246   LR 0.001000   
2022-11-04 02:06:17,262 - INFO  - Training [41][   40/  196]   Loss 0.022571   Top1 99.316406   Top5 100.000000   BatchTime 0.171494   LR 0.001000   
2022-11-04 02:06:19,749 - INFO  - Training [41][   60/  196]   Loss 0.023790   Top1 99.238281   Top5 100.000000   BatchTime 0.155783   LR 0.001000   
2022-11-04 02:06:22,228 - INFO  - Training [41][   80/  196]   Loss 0.022560   Top1 99.267578   Top5 100.000000   BatchTime 0.147824   LR 0.001000   
2022-11-04 02:06:24,708 - INFO  - Training [41][  100/  196]   Loss 0.021833   Top1 99.281250   Top5 100.000000   BatchTime 0.143053   LR 0.001000   
2022-11-04 02:06:27,190 - INFO  - Training [41][  120/  196]   Loss 0.021893   Top1 99.251302   Top5 100.000000   BatchTime 0.139895   LR 0.001000   
2022-11-04 02:06:29,651 - INFO  - Training [41][  140/  196]   Loss 0.021541   Top1 99.282924   Top5 100.000000   BatchTime 0.137492   LR 0.001000   
2022-11-04 02:06:32,109 - INFO  - Training [41][  160/  196]   Loss 0.021917   Top1 99.270020   Top5 100.000000   BatchTime 0.135667   LR 0.001000   
2022-11-04 02:06:34,574 - INFO  - Training [41][  180/  196]   Loss 0.022393   Top1 99.251302   Top5 100.000000   BatchTime 0.134285   LR 0.001000   
2022-11-04 02:06:36,749 - INFO  - ==> Top1: 99.264    Top5: 100.000    Loss: 0.022

2022-11-04 02:06:36,749 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:06:39,601 - INFO  - Validation [41][   20/   40]   Loss 0.454415   Top1 90.429688   Top5 99.433594   BatchTime 0.142544   
2022-11-04 02:06:40,729 - INFO  - Validation [41][   40/   40]   Loss 0.441744   Top1 90.880000   Top5 99.540000   BatchTime 0.099478   
2022-11-04 02:06:40,970 - INFO  - ==> Top1: 90.880    Top5: 99.540    Loss: 0.442

2022-11-04 02:06:41,012 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:06:41,013 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:06:41,013 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.880   Top5: 99.540] Sparsity : 0.847
2022-11-04 02:06:41,109 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:06:41,109 - INFO  - >>>>>>>> Epoch  42
2022-11-04 02:06:41,110 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:06:45,090 - INFO  - Training [42][   20/  196]   Loss 0.014688   Top1 99.609375   Top5 100.000000   BatchTime 0.199007   LR 0.001000   
2022-11-04 02:06:47,038 - INFO  - Training [42][   40/  196]   Loss 0.017571   Top1 99.384766   Top5 100.000000   BatchTime 0.148205   LR 0.001000   
2022-11-04 02:06:49,100 - INFO  - Training [42][   60/  196]   Loss 0.017761   Top1 99.394531   Top5 100.000000   BatchTime 0.133158   LR 0.001000   
2022-11-04 02:06:51,238 - INFO  - Training [42][   80/  196]   Loss 0.017960   Top1 99.365234   Top5 100.000000   BatchTime 0.126592   LR 0.001000   
2022-11-04 02:06:52,974 - INFO  - Training [42][  100/  196]   Loss 0.017707   Top1 99.386719   Top5 100.000000   BatchTime 0.118641   LR 0.001000   
2022-11-04 02:06:55,534 - INFO  - Training [42][  120/  196]   Loss 0.018270   Top1 99.365234   Top5 100.000000   BatchTime 0.120201   LR 0.001000   
2022-11-04 02:06:58,011 - INFO  - Training [42][  140/  196]   Loss 0.018075   Top1 99.377790   Top5 100.000000   BatchTime 0.120720   LR 0.001000   
2022-11-04 02:07:00,471 - INFO  - Training [42][  160/  196]   Loss 0.018183   Top1 99.370117   Top5 100.000000   BatchTime 0.121003   LR 0.001000   
2022-11-04 02:07:02,930 - INFO  - Training [42][  180/  196]   Loss 0.018026   Top1 99.390191   Top5 100.000000   BatchTime 0.121218   LR 0.001000   
2022-11-04 02:07:05,109 - INFO  - ==> Top1: 99.390    Top5: 100.000    Loss: 0.018

2022-11-04 02:07:05,109 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:07:07,992 - INFO  - Validation [42][   20/   40]   Loss 0.460122   Top1 90.449219   Top5 99.453125   BatchTime 0.144079   
2022-11-04 02:07:09,114 - INFO  - Validation [42][   40/   40]   Loss 0.446955   Top1 90.780000   Top5 99.600000   BatchTime 0.100070   
2022-11-04 02:07:09,365 - INFO  - ==> Top1: 90.780    Top5: 99.600    Loss: 0.447

2022-11-04 02:07:09,403 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:07:09,404 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:07:09,404 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.880   Top5: 99.540] Sparsity : 0.847
2022-11-04 02:07:09,506 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:07:09,507 - INFO  - >>>>>>>> Epoch  43
2022-11-04 02:07:09,508 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:07:13,894 - INFO  - Training [43][   20/  196]   Loss 0.018556   Top1 99.394531   Top5 100.000000   BatchTime 0.219302   LR 0.001000   
2022-11-04 02:07:16,360 - INFO  - Training [43][   40/  196]   Loss 0.018502   Top1 99.355469   Top5 100.000000   BatchTime 0.171298   LR 0.001000   
2022-11-04 02:07:18,841 - INFO  - Training [43][   60/  196]   Loss 0.018827   Top1 99.394531   Top5 100.000000   BatchTime 0.155542   LR 0.001000   
2022-11-04 02:07:21,315 - INFO  - Training [43][   80/  196]   Loss 0.019694   Top1 99.375000   Top5 100.000000   BatchTime 0.147581   LR 0.001000   
2022-11-04 02:07:23,796 - INFO  - Training [43][  100/  196]   Loss 0.019779   Top1 99.367188   Top5 100.000000   BatchTime 0.142877   LR 0.001000   
2022-11-04 02:07:26,281 - INFO  - Training [43][  120/  196]   Loss 0.019588   Top1 99.348958   Top5 100.000000   BatchTime 0.139766   LR 0.001000   
2022-11-04 02:07:28,751 - INFO  - Training [43][  140/  196]   Loss 0.019716   Top1 99.335938   Top5 100.000000   BatchTime 0.137446   LR 0.001000   
2022-11-04 02:07:31,214 - INFO  - Training [43][  160/  196]   Loss 0.020098   Top1 99.333496   Top5 100.000000   BatchTime 0.135661   LR 0.001000   
2022-11-04 02:07:33,661 - INFO  - Training [43][  180/  196]   Loss 0.020173   Top1 99.338108   Top5 100.000000   BatchTime 0.134178   LR 0.001000   
2022-11-04 02:07:35,815 - INFO  - ==> Top1: 99.336    Top5: 100.000    Loss: 0.020

2022-11-04 02:07:35,816 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:07:38,373 - INFO  - Validation [43][   20/   40]   Loss 0.466644   Top1 90.546875   Top5 99.433594   BatchTime 0.127770   
2022-11-04 02:07:39,073 - INFO  - Validation [43][   40/   40]   Loss 0.450326   Top1 90.730000   Top5 99.540000   BatchTime 0.081381   
2022-11-04 02:07:39,330 - INFO  - ==> Top1: 90.730    Top5: 99.540    Loss: 0.450

2022-11-04 02:07:39,355 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:07:39,355 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:07:39,355 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.880   Top5: 99.540] Sparsity : 0.847
2022-11-04 02:07:39,462 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:07:39,463 - INFO  - >>>>>>>> Epoch  44
2022-11-04 02:07:39,464 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:07:43,488 - INFO  - Training [44][   20/  196]   Loss 0.015043   Top1 99.492188   Top5 100.000000   BatchTime 0.201185   LR 0.001000   
2022-11-04 02:07:45,299 - INFO  - Training [44][   40/  196]   Loss 0.017716   Top1 99.404297   Top5 100.000000   BatchTime 0.145871   LR 0.001000   
2022-11-04 02:07:47,770 - INFO  - Training [44][   60/  196]   Loss 0.019627   Top1 99.368490   Top5 100.000000   BatchTime 0.138425   LR 0.001000   
2022-11-04 02:07:50,253 - INFO  - Training [44][   80/  196]   Loss 0.019933   Top1 99.321289   Top5 100.000000   BatchTime 0.134854   LR 0.001000   
2022-11-04 02:07:52,726 - INFO  - Training [44][  100/  196]   Loss 0.020254   Top1 99.343750   Top5 100.000000   BatchTime 0.132611   LR 0.001000   
2022-11-04 02:07:55,206 - INFO  - Training [44][  120/  196]   Loss 0.019713   Top1 99.345703   Top5 100.000000   BatchTime 0.131177   LR 0.001000   
2022-11-04 02:07:57,665 - INFO  - Training [44][  140/  196]   Loss 0.019772   Top1 99.355469   Top5 100.000000   BatchTime 0.129999   LR 0.001000   
2022-11-04 02:08:00,121 - INFO  - Training [44][  160/  196]   Loss 0.019817   Top1 99.353027   Top5 100.000000   BatchTime 0.129104   LR 0.001000   
2022-11-04 02:08:02,586 - INFO  - Training [44][  180/  196]   Loss 0.020013   Top1 99.335938   Top5 100.000000   BatchTime 0.128449   LR 0.001000   
2022-11-04 02:08:04,763 - INFO  - ==> Top1: 99.340    Top5: 100.000    Loss: 0.020

2022-11-04 02:08:04,764 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:08:07,599 - INFO  - Validation [44][   20/   40]   Loss 0.458927   Top1 90.781250   Top5 99.472656   BatchTime 0.141685   
2022-11-04 02:08:08,681 - INFO  - Validation [44][   40/   40]   Loss 0.445720   Top1 90.920000   Top5 99.610000   BatchTime 0.097906   
2022-11-04 02:08:08,928 - INFO  - ==> Top1: 90.920    Top5: 99.610    Loss: 0.446

2022-11-04 02:08:08,960 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:08:08,961 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:08:08,961 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:08:09,070 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:08:09,071 - INFO  - >>>>>>>> Epoch  45
2022-11-04 02:08:09,072 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:08:13,438 - INFO  - Training [45][   20/  196]   Loss 0.021074   Top1 99.296875   Top5 100.000000   BatchTime 0.218308   LR 0.001000   
2022-11-04 02:08:15,917 - INFO  - Training [45][   40/  196]   Loss 0.021017   Top1 99.316406   Top5 100.000000   BatchTime 0.171129   LR 0.001000   
2022-11-04 02:08:18,396 - INFO  - Training [45][   60/  196]   Loss 0.020500   Top1 99.309896   Top5 100.000000   BatchTime 0.155397   LR 0.001000   
2022-11-04 02:08:20,863 - INFO  - Training [45][   80/  196]   Loss 0.019879   Top1 99.335938   Top5 100.000000   BatchTime 0.147393   LR 0.001000   
2022-11-04 02:08:23,346 - INFO  - Training [45][  100/  196]   Loss 0.019394   Top1 99.332031   Top5 100.000000   BatchTime 0.142745   LR 0.001000   
2022-11-04 02:08:25,809 - INFO  - Training [45][  120/  196]   Loss 0.018986   Top1 99.378255   Top5 100.000000   BatchTime 0.139477   LR 0.001000   
2022-11-04 02:08:28,262 - INFO  - Training [45][  140/  196]   Loss 0.018804   Top1 99.377790   Top5 100.000000   BatchTime 0.137071   LR 0.001000   
2022-11-04 02:08:30,714 - INFO  - Training [45][  160/  196]   Loss 0.018751   Top1 99.394531   Top5 100.000000   BatchTime 0.135259   LR 0.001000   
2022-11-04 02:08:32,575 - INFO  - Training [45][  180/  196]   Loss 0.018707   Top1 99.390191   Top5 100.000000   BatchTime 0.130572   LR 0.001000   
2022-11-04 02:08:34,420 - INFO  - ==> Top1: 99.388    Top5: 100.000    Loss: 0.019

2022-11-04 02:08:34,421 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:08:36,990 - INFO  - Validation [45][   20/   40]   Loss 0.464469   Top1 90.664062   Top5 99.492188   BatchTime 0.128361   
2022-11-04 02:08:37,676 - INFO  - Validation [45][   40/   40]   Loss 0.449046   Top1 90.900000   Top5 99.550000   BatchTime 0.081342   
2022-11-04 02:08:37,926 - INFO  - ==> Top1: 90.900    Top5: 99.550    Loss: 0.449

2022-11-04 02:08:37,953 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:08:37,953 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:08:37,953 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:08:38,044 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:08:38,044 - INFO  - >>>>>>>> Epoch  46
2022-11-04 02:08:38,046 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:08:42,454 - INFO  - Training [46][   20/  196]   Loss 0.015988   Top1 99.511719   Top5 100.000000   BatchTime 0.220396   LR 0.001000   
2022-11-04 02:08:44,923 - INFO  - Training [46][   40/  196]   Loss 0.016377   Top1 99.482422   Top5 100.000000   BatchTime 0.171911   LR 0.001000   
2022-11-04 02:08:47,415 - INFO  - Training [46][   60/  196]   Loss 0.016186   Top1 99.466146   Top5 100.000000   BatchTime 0.156150   LR 0.001000   
2022-11-04 02:08:49,901 - INFO  - Training [46][   80/  196]   Loss 0.016241   Top1 99.467773   Top5 100.000000   BatchTime 0.148180   LR 0.001000   
2022-11-04 02:08:52,368 - INFO  - Training [46][  100/  196]   Loss 0.016293   Top1 99.476562   Top5 100.000000   BatchTime 0.143219   LR 0.001000   
2022-11-04 02:08:54,848 - INFO  - Training [46][  120/  196]   Loss 0.016739   Top1 99.440104   Top5 100.000000   BatchTime 0.140018   LR 0.001000   
2022-11-04 02:08:57,315 - INFO  - Training [46][  140/  196]   Loss 0.016604   Top1 99.439174   Top5 100.000000   BatchTime 0.137633   LR 0.001000   
2022-11-04 02:08:59,911 - INFO  - Training [46][  160/  196]   Loss 0.017394   Top1 99.409180   Top5 100.000000   BatchTime 0.136652   LR 0.001000   
2022-11-04 02:09:02,367 - INFO  - Training [46][  180/  196]   Loss 0.017537   Top1 99.396701   Top5 100.000000   BatchTime 0.135114   LR 0.001000   
2022-11-04 02:09:04,532 - INFO  - ==> Top1: 99.386    Top5: 100.000    Loss: 0.018

2022-11-04 02:09:04,533 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:09:07,408 - INFO  - Validation [46][   20/   40]   Loss 0.464011   Top1 90.566406   Top5 99.531250   BatchTime 0.143657   
2022-11-04 02:09:08,523 - INFO  - Validation [46][   40/   40]   Loss 0.450095   Top1 90.830000   Top5 99.640000   BatchTime 0.099695   
2022-11-04 02:09:08,774 - INFO  - ==> Top1: 90.830    Top5: 99.640    Loss: 0.450

2022-11-04 02:09:08,816 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:09:08,817 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:09:08,817 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:09:08,920 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:09:08,920 - INFO  - >>>>>>>> Epoch  47
2022-11-04 02:09:08,922 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:09:13,299 - INFO  - Training [47][   20/  196]   Loss 0.014256   Top1 99.589844   Top5 100.000000   BatchTime 0.218858   LR 0.001000   
2022-11-04 02:09:15,763 - INFO  - Training [47][   40/  196]   Loss 0.016951   Top1 99.423828   Top5 100.000000   BatchTime 0.171023   LR 0.001000   
2022-11-04 02:09:18,228 - INFO  - Training [47][   60/  196]   Loss 0.018556   Top1 99.388021   Top5 100.000000   BatchTime 0.155104   LR 0.001000   
2022-11-04 02:09:20,688 - INFO  - Training [47][   80/  196]   Loss 0.019043   Top1 99.355469   Top5 100.000000   BatchTime 0.147082   LR 0.001000   
2022-11-04 02:09:23,225 - INFO  - Training [47][  100/  196]   Loss 0.018528   Top1 99.406250   Top5 100.000000   BatchTime 0.143031   LR 0.001000   
2022-11-04 02:09:24,946 - INFO  - Training [47][  120/  196]   Loss 0.018062   Top1 99.420573   Top5 100.000000   BatchTime 0.133535   LR 0.001000   
2022-11-04 02:09:27,043 - INFO  - Training [47][  140/  196]   Loss 0.018108   Top1 99.416853   Top5 100.000000   BatchTime 0.129437   LR 0.001000   
2022-11-04 02:09:29,047 - INFO  - Training [47][  160/  196]   Loss 0.018533   Top1 99.399414   Top5 100.000000   BatchTime 0.125782   LR 0.001000   
2022-11-04 02:09:30,973 - INFO  - Training [47][  180/  196]   Loss 0.018472   Top1 99.405382   Top5 99.997830   BatchTime 0.122506   LR 0.001000   
2022-11-04 02:09:32,651 - INFO  - ==> Top1: 99.398    Top5: 99.998    Loss: 0.019

2022-11-04 02:09:32,652 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:09:35,505 - INFO  - Validation [47][   20/   40]   Loss 0.456862   Top1 90.351562   Top5 99.511719   BatchTime 0.142612   
2022-11-04 02:09:36,644 - INFO  - Validation [47][   40/   40]   Loss 0.448107   Top1 90.710000   Top5 99.600000   BatchTime 0.099765   
2022-11-04 02:09:36,905 - INFO  - ==> Top1: 90.710    Top5: 99.600    Loss: 0.448

2022-11-04 02:09:36,936 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:09:36,937 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:09:36,937 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:09:37,047 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:09:37,048 - INFO  - >>>>>>>> Epoch  48
2022-11-04 02:09:37,049 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:09:41,394 - INFO  - Training [48][   20/  196]   Loss 0.015961   Top1 99.492188   Top5 100.000000   BatchTime 0.217224   LR 0.001000   
2022-11-04 02:09:43,868 - INFO  - Training [48][   40/  196]   Loss 0.018442   Top1 99.326172   Top5 100.000000   BatchTime 0.170458   LR 0.001000   
2022-11-04 02:09:46,349 - INFO  - Training [48][   60/  196]   Loss 0.017257   Top1 99.414062   Top5 100.000000   BatchTime 0.154992   LR 0.001000   
2022-11-04 02:09:48,824 - INFO  - Training [48][   80/  196]   Loss 0.017691   Top1 99.404297   Top5 100.000000   BatchTime 0.147185   LR 0.001000   
2022-11-04 02:09:51,291 - INFO  - Training [48][  100/  196]   Loss 0.017719   Top1 99.414062   Top5 100.000000   BatchTime 0.142414   LR 0.001000   
2022-11-04 02:09:53,768 - INFO  - Training [48][  120/  196]   Loss 0.017090   Top1 99.446615   Top5 100.000000   BatchTime 0.139321   LR 0.001000   
2022-11-04 02:09:56,237 - INFO  - Training [48][  140/  196]   Loss 0.017471   Top1 99.447545   Top5 100.000000   BatchTime 0.137054   LR 0.001000   
2022-11-04 02:09:58,701 - INFO  - Training [48][  160/  196]   Loss 0.017046   Top1 99.450684   Top5 100.000000   BatchTime 0.135319   LR 0.001000   
2022-11-04 02:10:01,156 - INFO  - Training [48][  180/  196]   Loss 0.017666   Top1 99.424913   Top5 100.000000   BatchTime 0.133924   LR 0.001000   
2022-11-04 02:10:03,317 - INFO  - ==> Top1: 99.420    Top5: 100.000    Loss: 0.018

2022-11-04 02:10:03,318 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:10:06,184 - INFO  - Validation [48][   20/   40]   Loss 0.462342   Top1 90.332031   Top5 99.453125   BatchTime 0.143215   
2022-11-04 02:10:07,331 - INFO  - Validation [48][   40/   40]   Loss 0.451522   Top1 90.630000   Top5 99.610000   BatchTime 0.100280   
2022-11-04 02:10:07,588 - INFO  - ==> Top1: 90.630    Top5: 99.610    Loss: 0.452

2022-11-04 02:10:07,621 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:10:07,622 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:10:07,622 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.900   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:10:07,703 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:10:07,703 - INFO  - >>>>>>>> Epoch  49
2022-11-04 02:10:07,704 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:10:12,035 - INFO  - Training [49][   20/  196]   Loss 0.015934   Top1 99.570312   Top5 100.000000   BatchTime 0.216528   LR 0.001000   
2022-11-04 02:10:14,495 - INFO  - Training [49][   40/  196]   Loss 0.017815   Top1 99.511719   Top5 100.000000   BatchTime 0.169770   LR 0.001000   
2022-11-04 02:10:16,566 - INFO  - Training [49][   60/  196]   Loss 0.018216   Top1 99.466146   Top5 100.000000   BatchTime 0.147695   LR 0.001000   
2022-11-04 02:10:18,544 - INFO  - Training [49][   80/  196]   Loss 0.017992   Top1 99.467773   Top5 100.000000   BatchTime 0.135494   LR 0.001000   
2022-11-04 02:10:20,598 - INFO  - Training [49][  100/  196]   Loss 0.017760   Top1 99.464844   Top5 100.000000   BatchTime 0.128935   LR 0.001000   
2022-11-04 02:10:22,688 - INFO  - Training [49][  120/  196]   Loss 0.017790   Top1 99.453125   Top5 100.000000   BatchTime 0.124863   LR 0.001000   
2022-11-04 02:10:24,391 - INFO  - Training [49][  140/  196]   Loss 0.018353   Top1 99.430804   Top5 100.000000   BatchTime 0.119192   LR 0.001000   
2022-11-04 02:10:26,897 - INFO  - Training [49][  160/  196]   Loss 0.018426   Top1 99.418945   Top5 100.000000   BatchTime 0.119955   LR 0.001000   
2022-11-04 02:10:29,357 - INFO  - Training [49][  180/  196]   Loss 0.018957   Top1 99.401042   Top5 100.000000   BatchTime 0.120291   LR 0.001000   
2022-11-04 02:10:31,517 - INFO  - ==> Top1: 99.406    Top5: 100.000    Loss: 0.019

2022-11-04 02:10:31,518 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:10:34,384 - INFO  - Validation [49][   20/   40]   Loss 0.455580   Top1 90.664062   Top5 99.511719   BatchTime 0.143251   
2022-11-04 02:10:35,485 - INFO  - Validation [49][   40/   40]   Loss 0.448918   Top1 90.940000   Top5 99.590000   BatchTime 0.099154   
2022-11-04 02:10:35,732 - INFO  - ==> Top1: 90.940    Top5: 99.590    Loss: 0.449

2022-11-04 02:10:35,778 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:10:35,779 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:10:35,779 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:10:35,879 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:10:35,880 - INFO  - >>>>>>>> Epoch  50
2022-11-04 02:10:35,881 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:10:40,213 - INFO  - Training [50][   20/  196]   Loss 0.016996   Top1 99.472656   Top5 100.000000   BatchTime 0.216588   LR 0.001000   
2022-11-04 02:10:42,685 - INFO  - Training [50][   40/  196]   Loss 0.016963   Top1 99.404297   Top5 100.000000   BatchTime 0.170107   LR 0.001000   
2022-11-04 02:10:45,179 - INFO  - Training [50][   60/  196]   Loss 0.017594   Top1 99.388021   Top5 100.000000   BatchTime 0.154975   LR 0.001000   
2022-11-04 02:10:47,665 - INFO  - Training [50][   80/  196]   Loss 0.018162   Top1 99.384766   Top5 100.000000   BatchTime 0.147305   LR 0.001000   
2022-11-04 02:10:50,149 - INFO  - Training [50][  100/  196]   Loss 0.018578   Top1 99.339844   Top5 100.000000   BatchTime 0.142680   LR 0.001000   
2022-11-04 02:10:52,621 - INFO  - Training [50][  120/  196]   Loss 0.018615   Top1 99.322917   Top5 100.000000   BatchTime 0.139496   LR 0.001000   
2022-11-04 02:10:55,087 - INFO  - Training [50][  140/  196]   Loss 0.018286   Top1 99.344308   Top5 100.000000   BatchTime 0.137181   LR 0.001000   
2022-11-04 02:10:57,632 - INFO  - Training [50][  160/  196]   Loss 0.017884   Top1 99.372559   Top5 100.000000   BatchTime 0.135939   LR 0.001000   
2022-11-04 02:11:00,095 - INFO  - Training [50][  180/  196]   Loss 0.017932   Top1 99.355469   Top5 100.000000   BatchTime 0.134523   LR 0.001000   
2022-11-04 02:11:02,271 - INFO  - ==> Top1: 99.348    Top5: 100.000    Loss: 0.018

2022-11-04 02:11:02,272 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:11:05,136 - INFO  - Validation [50][   20/   40]   Loss 0.463700   Top1 90.566406   Top5 99.531250   BatchTime 0.143132   
2022-11-04 02:11:06,265 - INFO  - Validation [50][   40/   40]   Loss 0.450397   Top1 90.790000   Top5 99.630000   BatchTime 0.099794   
2022-11-04 02:11:06,507 - INFO  - ==> Top1: 90.790    Top5: 99.630    Loss: 0.450

2022-11-04 02:11:06,549 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:11:06,550 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:11:06,550 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:11:06,645 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:11:06,645 - INFO  - >>>>>>>> Epoch  51
2022-11-04 02:11:06,646 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:11:10,576 - INFO  - Training [51][   20/  196]   Loss 0.017648   Top1 99.394531   Top5 100.000000   BatchTime 0.196524   LR 0.001000   
2022-11-04 02:11:12,616 - INFO  - Training [51][   40/  196]   Loss 0.017455   Top1 99.375000   Top5 100.000000   BatchTime 0.149256   LR 0.001000   
2022-11-04 02:11:14,679 - INFO  - Training [51][   60/  196]   Loss 0.017048   Top1 99.420573   Top5 100.000000   BatchTime 0.133886   LR 0.001000   
2022-11-04 02:11:16,535 - INFO  - Training [51][   80/  196]   Loss 0.017204   Top1 99.394531   Top5 100.000000   BatchTime 0.123609   LR 0.001000   
2022-11-04 02:11:18,927 - INFO  - Training [51][  100/  196]   Loss 0.017238   Top1 99.398438   Top5 100.000000   BatchTime 0.122806   LR 0.001000   
2022-11-04 02:11:21,422 - INFO  - Training [51][  120/  196]   Loss 0.017301   Top1 99.394531   Top5 100.000000   BatchTime 0.123132   LR 0.001000   
2022-11-04 02:11:23,892 - INFO  - Training [51][  140/  196]   Loss 0.017340   Top1 99.397321   Top5 100.000000   BatchTime 0.123182   LR 0.001000   
2022-11-04 02:11:26,359 - INFO  - Training [51][  160/  196]   Loss 0.017453   Top1 99.392090   Top5 100.000000   BatchTime 0.123206   LR 0.001000   
2022-11-04 02:11:28,820 - INFO  - Training [51][  180/  196]   Loss 0.017671   Top1 99.392361   Top5 100.000000   BatchTime 0.123186   LR 0.001000   
2022-11-04 02:11:31,004 - INFO  - ==> Top1: 99.388    Top5: 100.000    Loss: 0.018

2022-11-04 02:11:31,004 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:11:33,875 - INFO  - Validation [51][   20/   40]   Loss 0.464870   Top1 90.488281   Top5 99.472656   BatchTime 0.143483   
2022-11-04 02:11:34,979 - INFO  - Validation [51][   40/   40]   Loss 0.453911   Top1 90.760000   Top5 99.570000   BatchTime 0.099335   
2022-11-04 02:11:35,229 - INFO  - ==> Top1: 90.760    Top5: 99.570    Loss: 0.454

2022-11-04 02:11:35,275 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:11:35,276 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:11:35,276 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:11:35,376 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:11:35,377 - INFO  - >>>>>>>> Epoch  52
2022-11-04 02:11:35,378 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:11:39,771 - INFO  - Training [52][   20/  196]   Loss 0.016290   Top1 99.511719   Top5 100.000000   BatchTime 0.219636   LR 0.001000   
2022-11-04 02:11:42,237 - INFO  - Training [52][   40/  196]   Loss 0.016236   Top1 99.521484   Top5 100.000000   BatchTime 0.171466   LR 0.001000   
2022-11-04 02:11:44,717 - INFO  - Training [52][   60/  196]   Loss 0.017590   Top1 99.453125   Top5 100.000000   BatchTime 0.155651   LR 0.001000   
2022-11-04 02:11:47,190 - INFO  - Training [52][   80/  196]   Loss 0.017913   Top1 99.423828   Top5 100.000000   BatchTime 0.147641   LR 0.001000   
2022-11-04 02:11:49,657 - INFO  - Training [52][  100/  196]   Loss 0.018266   Top1 99.414062   Top5 100.000000   BatchTime 0.142783   LR 0.001000   
2022-11-04 02:11:52,132 - INFO  - Training [52][  120/  196]   Loss 0.018695   Top1 99.404297   Top5 100.000000   BatchTime 0.139613   LR 0.001000   
2022-11-04 02:11:54,603 - INFO  - Training [52][  140/  196]   Loss 0.018533   Top1 99.414062   Top5 100.000000   BatchTime 0.137314   LR 0.001000   
2022-11-04 02:11:57,055 - INFO  - Training [52][  160/  196]   Loss 0.018384   Top1 99.418945   Top5 100.000000   BatchTime 0.135479   LR 0.001000   
2022-11-04 02:11:59,508 - INFO  - Training [52][  180/  196]   Loss 0.018344   Top1 99.409722   Top5 100.000000   BatchTime 0.134050   LR 0.001000   
2022-11-04 02:12:01,657 - INFO  - ==> Top1: 99.414    Top5: 100.000    Loss: 0.018

2022-11-04 02:12:01,657 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:12:04,263 - INFO  - Validation [52][   20/   40]   Loss 0.467412   Top1 90.429688   Top5 99.511719   BatchTime 0.130237   
2022-11-04 02:12:05,167 - INFO  - Validation [52][   40/   40]   Loss 0.454293   Top1 90.670000   Top5 99.620000   BatchTime 0.087714   
2022-11-04 02:12:05,428 - INFO  - ==> Top1: 90.670    Top5: 99.620    Loss: 0.454

2022-11-04 02:12:05,462 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:12:05,462 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:12:05,462 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:12:05,565 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:12:05,565 - INFO  - >>>>>>>> Epoch  53
2022-11-04 02:12:05,567 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:12:09,569 - INFO  - Training [53][   20/  196]   Loss 0.018399   Top1 99.355469   Top5 100.000000   BatchTime 0.200088   LR 0.001000   
2022-11-04 02:12:12,045 - INFO  - Training [53][   40/  196]   Loss 0.017278   Top1 99.423828   Top5 100.000000   BatchTime 0.161966   LR 0.001000   
2022-11-04 02:12:14,521 - INFO  - Training [53][   60/  196]   Loss 0.016906   Top1 99.427083   Top5 100.000000   BatchTime 0.149229   LR 0.001000   
2022-11-04 02:12:16,984 - INFO  - Training [53][   80/  196]   Loss 0.017455   Top1 99.438477   Top5 100.000000   BatchTime 0.142719   LR 0.001000   
2022-11-04 02:12:19,462 - INFO  - Training [53][  100/  196]   Loss 0.018064   Top1 99.410156   Top5 100.000000   BatchTime 0.138946   LR 0.001000   
2022-11-04 02:12:21,937 - INFO  - Training [53][  120/  196]   Loss 0.017591   Top1 99.410807   Top5 100.000000   BatchTime 0.136416   LR 0.001000   
2022-11-04 02:12:24,403 - INFO  - Training [53][  140/  196]   Loss 0.017976   Top1 99.402902   Top5 100.000000   BatchTime 0.134542   LR 0.001000   
2022-11-04 02:12:26,867 - INFO  - Training [53][  160/  196]   Loss 0.017890   Top1 99.406738   Top5 100.000000   BatchTime 0.133123   LR 0.001000   
2022-11-04 02:12:29,322 - INFO  - Training [53][  180/  196]   Loss 0.017654   Top1 99.420573   Top5 100.000000   BatchTime 0.131972   LR 0.001000   
2022-11-04 02:12:31,496 - INFO  - ==> Top1: 99.400    Top5: 100.000    Loss: 0.018

2022-11-04 02:12:31,497 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:12:34,374 - INFO  - Validation [53][   20/   40]   Loss 0.461574   Top1 90.468750   Top5 99.472656   BatchTime 0.143766   
2022-11-04 02:12:35,499 - INFO  - Validation [53][   40/   40]   Loss 0.450203   Top1 90.860000   Top5 99.560000   BatchTime 0.100009   
2022-11-04 02:12:35,758 - INFO  - ==> Top1: 90.860    Top5: 99.560    Loss: 0.450

2022-11-04 02:12:35,788 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:12:35,789 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:12:35,789 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:12:35,943 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:12:35,944 - INFO  - >>>>>>>> Epoch  54
2022-11-04 02:12:35,944 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:12:40,326 - INFO  - Training [54][   20/  196]   Loss 0.016738   Top1 99.453125   Top5 100.000000   BatchTime 0.219072   LR 0.001000   
2022-11-04 02:12:42,799 - INFO  - Training [54][   40/  196]   Loss 0.017147   Top1 99.462891   Top5 100.000000   BatchTime 0.171361   LR 0.001000   
2022-11-04 02:12:45,270 - INFO  - Training [54][   60/  196]   Loss 0.017026   Top1 99.492188   Top5 100.000000   BatchTime 0.155415   LR 0.001000   
2022-11-04 02:12:47,729 - INFO  - Training [54][   80/  196]   Loss 0.017279   Top1 99.467773   Top5 100.000000   BatchTime 0.147298   LR 0.001000   
2022-11-04 02:12:50,206 - INFO  - Training [54][  100/  196]   Loss 0.017476   Top1 99.457031   Top5 99.996094   BatchTime 0.142609   LR 0.001000   
2022-11-04 02:12:52,670 - INFO  - Training [54][  120/  196]   Loss 0.017278   Top1 99.466146   Top5 99.996745   BatchTime 0.139374   LR 0.001000   
2022-11-04 02:12:55,031 - INFO  - Training [54][  140/  196]   Loss 0.017013   Top1 99.461496   Top5 99.997210   BatchTime 0.136328   LR 0.001000   
2022-11-04 02:12:56,805 - INFO  - Training [54][  160/  196]   Loss 0.016495   Top1 99.482422   Top5 99.997559   BatchTime 0.130378   LR 0.001000   
2022-11-04 02:12:58,915 - INFO  - Training [54][  180/  196]   Loss 0.016813   Top1 99.463976   Top5 99.997830   BatchTime 0.127611   LR 0.001000   
2022-11-04 02:13:00,730 - INFO  - ==> Top1: 99.456    Top5: 99.998    Loss: 0.017

2022-11-04 02:13:00,731 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:13:03,406 - INFO  - Validation [54][   20/   40]   Loss 0.469030   Top1 90.429688   Top5 99.531250   BatchTime 0.133668   
2022-11-04 02:13:04,534 - INFO  - Validation [54][   40/   40]   Loss 0.459324   Top1 90.650000   Top5 99.590000   BatchTime 0.095049   
2022-11-04 02:13:04,788 - INFO  - ==> Top1: 90.650    Top5: 99.590    Loss: 0.459

2022-11-04 02:13:04,830 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:13:04,830 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:13:04,830 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:13:04,941 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:13:04,942 - INFO  - >>>>>>>> Epoch  55
2022-11-04 02:13:04,943 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:13:09,279 - INFO  - Training [55][   20/  196]   Loss 0.017761   Top1 99.453125   Top5 100.000000   BatchTime 0.216821   LR 0.001000   
2022-11-04 02:13:11,776 - INFO  - Training [55][   40/  196]   Loss 0.016996   Top1 99.433594   Top5 100.000000   BatchTime 0.170836   LR 0.001000   
2022-11-04 02:13:14,256 - INFO  - Training [55][   60/  196]   Loss 0.016319   Top1 99.446615   Top5 100.000000   BatchTime 0.155218   LR 0.001000   
2022-11-04 02:13:16,730 - INFO  - Training [55][   80/  196]   Loss 0.016355   Top1 99.448242   Top5 100.000000   BatchTime 0.147342   LR 0.001000   
2022-11-04 02:13:19,205 - INFO  - Training [55][  100/  196]   Loss 0.016521   Top1 99.453125   Top5 100.000000   BatchTime 0.142622   LR 0.001000   
2022-11-04 02:13:21,675 - INFO  - Training [55][  120/  196]   Loss 0.017133   Top1 99.427083   Top5 100.000000   BatchTime 0.139434   LR 0.001000   
2022-11-04 02:13:24,145 - INFO  - Training [55][  140/  196]   Loss 0.017262   Top1 99.419643   Top5 100.000000   BatchTime 0.137157   LR 0.001000   
2022-11-04 02:13:26,610 - INFO  - Training [55][  160/  196]   Loss 0.017738   Top1 99.406738   Top5 100.000000   BatchTime 0.135415   LR 0.001000   
2022-11-04 02:13:29,034 - INFO  - Training [55][  180/  196]   Loss 0.017851   Top1 99.398872   Top5 100.000000   BatchTime 0.133836   LR 0.001000   
2022-11-04 02:13:31,209 - INFO  - ==> Top1: 99.402    Top5: 100.000    Loss: 0.018

2022-11-04 02:13:31,210 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:13:34,118 - INFO  - Validation [55][   20/   40]   Loss 0.469343   Top1 90.683594   Top5 99.472656   BatchTime 0.145312   
2022-11-04 02:13:35,238 - INFO  - Validation [55][   40/   40]   Loss 0.457411   Top1 90.670000   Top5 99.580000   BatchTime 0.100659   
2022-11-04 02:13:35,489 - INFO  - ==> Top1: 90.670    Top5: 99.580    Loss: 0.457

2022-11-04 02:13:35,529 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:13:35,530 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:13:35,530 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:13:35,637 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:13:35,638 - INFO  - >>>>>>>> Epoch  56
2022-11-04 02:13:35,639 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:13:40,013 - INFO  - Training [56][   20/  196]   Loss 0.016360   Top1 99.414062   Top5 100.000000   BatchTime 0.218693   LR 0.001000   
2022-11-04 02:13:42,482 - INFO  - Training [56][   40/  196]   Loss 0.017727   Top1 99.443359   Top5 100.000000   BatchTime 0.171068   LR 0.001000   
2022-11-04 02:13:44,953 - INFO  - Training [56][   60/  196]   Loss 0.018003   Top1 99.401042   Top5 100.000000   BatchTime 0.155240   LR 0.001000   
2022-11-04 02:13:47,407 - INFO  - Training [56][   80/  196]   Loss 0.017501   Top1 99.423828   Top5 100.000000   BatchTime 0.147100   LR 0.001000   
2022-11-04 02:13:49,228 - INFO  - Training [56][  100/  196]   Loss 0.017550   Top1 99.425781   Top5 100.000000   BatchTime 0.135889   LR 0.001000   
2022-11-04 02:13:51,285 - INFO  - Training [56][  120/  196]   Loss 0.017389   Top1 99.453125   Top5 100.000000   BatchTime 0.130380   LR 0.001000   
2022-11-04 02:13:53,310 - INFO  - Training [56][  140/  196]   Loss 0.017853   Top1 99.419643   Top5 100.000000   BatchTime 0.126219   LR 0.001000   
2022-11-04 02:13:55,308 - INFO  - Training [56][  160/  196]   Loss 0.018168   Top1 99.396973   Top5 100.000000   BatchTime 0.122928   LR 0.001000   
2022-11-04 02:13:57,123 - INFO  - Training [56][  180/  196]   Loss 0.018142   Top1 99.414062   Top5 100.000000   BatchTime 0.119352   LR 0.001000   
2022-11-04 02:13:59,299 - INFO  - ==> Top1: 99.424    Top5: 100.000    Loss: 0.018

2022-11-04 02:13:59,300 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:14:02,181 - INFO  - Validation [56][   20/   40]   Loss 0.463272   Top1 90.273438   Top5 99.394531   BatchTime 0.143966   
2022-11-04 02:14:03,326 - INFO  - Validation [56][   40/   40]   Loss 0.451790   Top1 90.660000   Top5 99.530000   BatchTime 0.100625   
2022-11-04 02:14:03,571 - INFO  - ==> Top1: 90.660    Top5: 99.530    Loss: 0.452

2022-11-04 02:14:03,610 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:14:03,610 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:14:03,611 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:14:03,708 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:14:03,708 - INFO  - >>>>>>>> Epoch  57
2022-11-04 02:14:03,709 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:14:08,099 - INFO  - Training [57][   20/  196]   Loss 0.015460   Top1 99.570312   Top5 100.000000   BatchTime 0.219496   LR 0.001000   
2022-11-04 02:14:10,583 - INFO  - Training [57][   40/  196]   Loss 0.014949   Top1 99.531250   Top5 100.000000   BatchTime 0.171844   LR 0.001000   
2022-11-04 02:14:13,069 - INFO  - Training [57][   60/  196]   Loss 0.015975   Top1 99.485677   Top5 100.000000   BatchTime 0.155986   LR 0.001000   
2022-11-04 02:14:15,547 - INFO  - Training [57][   80/  196]   Loss 0.016659   Top1 99.477539   Top5 100.000000   BatchTime 0.147970   LR 0.001000   
2022-11-04 02:14:18,032 - INFO  - Training [57][  100/  196]   Loss 0.016890   Top1 99.464844   Top5 100.000000   BatchTime 0.143226   LR 0.001000   
2022-11-04 02:14:20,523 - INFO  - Training [57][  120/  196]   Loss 0.016651   Top1 99.469401   Top5 100.000000   BatchTime 0.140113   LR 0.001000   
2022-11-04 02:14:23,008 - INFO  - Training [57][  140/  196]   Loss 0.016731   Top1 99.455915   Top5 100.000000   BatchTime 0.137845   LR 0.001000   
2022-11-04 02:14:25,473 - INFO  - Training [57][  160/  196]   Loss 0.016747   Top1 99.460449   Top5 100.000000   BatchTime 0.136019   LR 0.001000   
2022-11-04 02:14:27,925 - INFO  - Training [57][  180/  196]   Loss 0.016592   Top1 99.459635   Top5 100.000000   BatchTime 0.134529   LR 0.001000   
2022-11-04 02:14:30,108 - INFO  - ==> Top1: 99.456    Top5: 100.000    Loss: 0.017

2022-11-04 02:14:30,109 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:14:32,974 - INFO  - Validation [57][   20/   40]   Loss 0.465578   Top1 90.644531   Top5 99.394531   BatchTime 0.143173   
2022-11-04 02:14:34,073 - INFO  - Validation [57][   40/   40]   Loss 0.452675   Top1 90.910000   Top5 99.530000   BatchTime 0.099062   
2022-11-04 02:14:34,340 - INFO  - ==> Top1: 90.910    Top5: 99.530    Loss: 0.453

2022-11-04 02:14:34,387 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:14:34,388 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:14:34,388 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:14:34,493 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:14:34,493 - INFO  - >>>>>>>> Epoch  58
2022-11-04 02:14:34,494 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:14:38,805 - INFO  - Training [58][   20/  196]   Loss 0.018945   Top1 99.394531   Top5 100.000000   BatchTime 0.215514   LR 0.001000   
2022-11-04 02:14:40,942 - INFO  - Training [58][   40/  196]   Loss 0.018305   Top1 99.384766   Top5 100.000000   BatchTime 0.161191   LR 0.001000   
2022-11-04 02:14:42,900 - INFO  - Training [58][   60/  196]   Loss 0.019442   Top1 99.322917   Top5 100.000000   BatchTime 0.140091   LR 0.001000   
2022-11-04 02:14:44,938 - INFO  - Training [58][   80/  196]   Loss 0.018163   Top1 99.384766   Top5 100.000000   BatchTime 0.130537   LR 0.001000   
2022-11-04 02:14:46,998 - INFO  - Training [58][  100/  196]   Loss 0.017122   Top1 99.437500   Top5 100.000000   BatchTime 0.125034   LR 0.001000   
2022-11-04 02:14:48,769 - INFO  - Training [58][  120/  196]   Loss 0.016988   Top1 99.430339   Top5 100.000000   BatchTime 0.118950   LR 0.001000   
2022-11-04 02:14:51,255 - INFO  - Training [58][  140/  196]   Loss 0.017147   Top1 99.416853   Top5 100.000000   BatchTime 0.119718   LR 0.001000   
2022-11-04 02:14:53,721 - INFO  - Training [58][  160/  196]   Loss 0.017624   Top1 99.392090   Top5 100.000000   BatchTime 0.120160   LR 0.001000   
2022-11-04 02:14:56,186 - INFO  - Training [58][  180/  196]   Loss 0.017393   Top1 99.405382   Top5 100.000000   BatchTime 0.120503   LR 0.001000   
2022-11-04 02:14:58,365 - INFO  - ==> Top1: 99.368    Top5: 100.000    Loss: 0.018

2022-11-04 02:14:58,366 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:15:01,227 - INFO  - Validation [58][   20/   40]   Loss 0.462911   Top1 90.527344   Top5 99.570312   BatchTime 0.142971   
2022-11-04 02:15:02,342 - INFO  - Validation [58][   40/   40]   Loss 0.451529   Top1 90.800000   Top5 99.640000   BatchTime 0.099374   
2022-11-04 02:15:02,615 - INFO  - ==> Top1: 90.800    Top5: 99.640    Loss: 0.452

2022-11-04 02:15:02,651 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:15:02,652 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:15:02,652 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:15:02,720 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:15:02,720 - INFO  - >>>>>>>> Epoch  59
2022-11-04 02:15:02,722 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:15:07,229 - INFO  - Training [59][   20/  196]   Loss 0.013620   Top1 99.550781   Top5 100.000000   BatchTime 0.225386   LR 0.001000   
2022-11-04 02:15:09,707 - INFO  - Training [59][   40/  196]   Loss 0.014759   Top1 99.531250   Top5 100.000000   BatchTime 0.174623   LR 0.001000   
2022-11-04 02:15:12,203 - INFO  - Training [59][   60/  196]   Loss 0.015694   Top1 99.479167   Top5 100.000000   BatchTime 0.158022   LR 0.001000   
2022-11-04 02:15:14,689 - INFO  - Training [59][   80/  196]   Loss 0.015595   Top1 99.501953   Top5 100.000000   BatchTime 0.149593   LR 0.001000   
2022-11-04 02:15:17,196 - INFO  - Training [59][  100/  196]   Loss 0.016632   Top1 99.457031   Top5 100.000000   BatchTime 0.144743   LR 0.001000   
2022-11-04 02:15:19,674 - INFO  - Training [59][  120/  196]   Loss 0.016685   Top1 99.459635   Top5 100.000000   BatchTime 0.141265   LR 0.001000   
2022-11-04 02:15:22,122 - INFO  - Training [59][  140/  196]   Loss 0.016373   Top1 99.481027   Top5 100.000000   BatchTime 0.138570   LR 0.001000   
2022-11-04 02:15:24,587 - INFO  - Training [59][  160/  196]   Loss 0.016567   Top1 99.470215   Top5 100.000000   BatchTime 0.136658   LR 0.001000   
2022-11-04 02:15:27,057 - INFO  - Training [59][  180/  196]   Loss 0.016707   Top1 99.461806   Top5 100.000000   BatchTime 0.135193   LR 0.001000   
2022-11-04 02:15:29,239 - INFO  - ==> Top1: 99.450    Top5: 100.000    Loss: 0.017

2022-11-04 02:15:29,239 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:15:32,072 - INFO  - Validation [59][   20/   40]   Loss 0.465670   Top1 90.605469   Top5 99.492188   BatchTime 0.141571   
2022-11-04 02:15:33,230 - INFO  - Validation [59][   40/   40]   Loss 0.455527   Top1 90.640000   Top5 99.630000   BatchTime 0.099741   
2022-11-04 02:15:33,544 - INFO  - ==> Top1: 90.640    Top5: 99.630    Loss: 0.456

2022-11-04 02:15:33,570 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:15:33,571 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:15:33,571 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:15:33,680 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:15:33,680 - INFO  - >>>>>>>> Epoch  60
2022-11-04 02:15:33,682 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:15:37,749 - INFO  - Training [60][   20/  196]   Loss 0.014287   Top1 99.531250   Top5 100.000000   BatchTime 0.203335   LR 0.000100   
2022-11-04 02:15:39,815 - INFO  - Training [60][   40/  196]   Loss 0.015071   Top1 99.521484   Top5 100.000000   BatchTime 0.153329   LR 0.000100   
2022-11-04 02:15:41,719 - INFO  - Training [60][   60/  196]   Loss 0.015557   Top1 99.472656   Top5 100.000000   BatchTime 0.133951   LR 0.000100   
2022-11-04 02:15:43,944 - INFO  - Training [60][   80/  196]   Loss 0.016744   Top1 99.409180   Top5 100.000000   BatchTime 0.128272   LR 0.000100   
2022-11-04 02:15:46,423 - INFO  - Training [60][  100/  196]   Loss 0.016353   Top1 99.445312   Top5 100.000000   BatchTime 0.127407   LR 0.000100   
2022-11-04 02:15:48,896 - INFO  - Training [60][  120/  196]   Loss 0.016972   Top1 99.436849   Top5 100.000000   BatchTime 0.126781   LR 0.000100   
2022-11-04 02:15:51,367 - INFO  - Training [60][  140/  196]   Loss 0.017166   Top1 99.444754   Top5 100.000000   BatchTime 0.126319   LR 0.000100   
2022-11-04 02:15:53,827 - INFO  - Training [60][  160/  196]   Loss 0.017335   Top1 99.436035   Top5 100.000000   BatchTime 0.125903   LR 0.000100   
2022-11-04 02:15:56,299 - INFO  - Training [60][  180/  196]   Loss 0.017361   Top1 99.431424   Top5 100.000000   BatchTime 0.125649   LR 0.000100   
2022-11-04 02:15:58,488 - INFO  - ==> Top1: 99.432    Top5: 100.000    Loss: 0.017

2022-11-04 02:15:58,489 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:16:01,374 - INFO  - Validation [60][   20/   40]   Loss 0.459109   Top1 90.605469   Top5 99.531250   BatchTime 0.144172   
2022-11-04 02:16:02,480 - INFO  - Validation [60][   40/   40]   Loss 0.447254   Top1 90.730000   Top5 99.620000   BatchTime 0.099749   
2022-11-04 02:16:02,732 - INFO  - ==> Top1: 90.730    Top5: 99.620    Loss: 0.447

2022-11-04 02:16:02,779 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:16:02,780 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:16:02,780 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:16:02,867 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:16:02,867 - INFO  - >>>>>>>> Epoch  61
2022-11-04 02:16:02,868 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:16:07,253 - INFO  - Training [61][   20/  196]   Loss 0.013038   Top1 99.531250   Top5 100.000000   BatchTime 0.219257   LR 0.000100   
2022-11-04 02:16:09,716 - INFO  - Training [61][   40/  196]   Loss 0.014273   Top1 99.541016   Top5 100.000000   BatchTime 0.171199   LR 0.000100   
2022-11-04 02:16:12,195 - INFO  - Training [61][   60/  196]   Loss 0.014205   Top1 99.531250   Top5 100.000000   BatchTime 0.155444   LR 0.000100   
2022-11-04 02:16:14,666 - INFO  - Training [61][   80/  196]   Loss 0.014568   Top1 99.506836   Top5 100.000000   BatchTime 0.147476   LR 0.000100   
2022-11-04 02:16:17,141 - INFO  - Training [61][  100/  196]   Loss 0.016131   Top1 99.472656   Top5 100.000000   BatchTime 0.142728   LR 0.000100   
2022-11-04 02:16:19,621 - INFO  - Training [61][  120/  196]   Loss 0.016996   Top1 99.433594   Top5 100.000000   BatchTime 0.139605   LR 0.000100   
2022-11-04 02:16:22,094 - INFO  - Training [61][  140/  196]   Loss 0.016920   Top1 99.430804   Top5 100.000000   BatchTime 0.137327   LR 0.000100   
2022-11-04 02:16:24,551 - INFO  - Training [61][  160/  196]   Loss 0.017460   Top1 99.433594   Top5 100.000000   BatchTime 0.135516   LR 0.000100   
2022-11-04 02:16:27,005 - INFO  - Training [61][  180/  196]   Loss 0.017264   Top1 99.440104   Top5 100.000000   BatchTime 0.134094   LR 0.000100   
2022-11-04 02:16:29,071 - INFO  - ==> Top1: 99.442    Top5: 100.000    Loss: 0.017

2022-11-04 02:16:29,072 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:16:31,768 - INFO  - Validation [61][   20/   40]   Loss 0.469534   Top1 90.527344   Top5 99.472656   BatchTime 0.134767   
2022-11-04 02:16:32,631 - INFO  - Validation [61][   40/   40]   Loss 0.454906   Top1 90.680000   Top5 99.640000   BatchTime 0.088949   
2022-11-04 02:16:32,878 - INFO  - ==> Top1: 90.680    Top5: 99.640    Loss: 0.455

2022-11-04 02:16:32,908 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:16:32,909 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:16:32,909 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:16:33,011 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:16:33,012 - INFO  - >>>>>>>> Epoch  62
2022-11-04 02:16:33,013 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:16:37,276 - INFO  - Training [62][   20/  196]   Loss 0.015695   Top1 99.550781   Top5 100.000000   BatchTime 0.213151   LR 0.000100   
2022-11-04 02:16:39,757 - INFO  - Training [62][   40/  196]   Loss 0.016601   Top1 99.462891   Top5 100.000000   BatchTime 0.168584   LR 0.000100   
2022-11-04 02:16:42,246 - INFO  - Training [62][   60/  196]   Loss 0.015779   Top1 99.485677   Top5 100.000000   BatchTime 0.153882   LR 0.000100   
2022-11-04 02:16:44,733 - INFO  - Training [62][   80/  196]   Loss 0.016344   Top1 99.462891   Top5 100.000000   BatchTime 0.146489   LR 0.000100   
2022-11-04 02:16:47,211 - INFO  - Training [62][  100/  196]   Loss 0.017195   Top1 99.425781   Top5 100.000000   BatchTime 0.141969   LR 0.000100   
2022-11-04 02:16:49,705 - INFO  - Training [62][  120/  196]   Loss 0.017497   Top1 99.407552   Top5 100.000000   BatchTime 0.139098   LR 0.000100   
2022-11-04 02:16:52,182 - INFO  - Training [62][  140/  196]   Loss 0.017449   Top1 99.419643   Top5 100.000000   BatchTime 0.136917   LR 0.000100   
2022-11-04 02:16:54,652 - INFO  - Training [62][  160/  196]   Loss 0.016885   Top1 99.440918   Top5 100.000000   BatchTime 0.135242   LR 0.000100   
2022-11-04 02:16:57,118 - INFO  - Training [62][  180/  196]   Loss 0.016411   Top1 99.461806   Top5 100.000000   BatchTime 0.133910   LR 0.000100   
2022-11-04 02:16:59,305 - INFO  - ==> Top1: 99.472    Top5: 100.000    Loss: 0.016

2022-11-04 02:16:59,306 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:17:02,196 - INFO  - Validation [62][   20/   40]   Loss 0.464845   Top1 90.468750   Top5 99.511719   BatchTime 0.144440   
2022-11-04 02:17:03,322 - INFO  - Validation [62][   40/   40]   Loss 0.454329   Top1 90.700000   Top5 99.600000   BatchTime 0.100373   
2022-11-04 02:17:03,574 - INFO  - ==> Top1: 90.700    Top5: 99.600    Loss: 0.454

2022-11-04 02:17:03,607 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:17:03,608 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:17:03,608 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:17:03,706 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:17:03,707 - INFO  - >>>>>>>> Epoch  63
2022-11-04 02:17:03,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:17:08,076 - INFO  - Training [63][   20/  196]   Loss 0.010882   Top1 99.687500   Top5 100.000000   BatchTime 0.218365   LR 0.000100   
2022-11-04 02:17:10,556 - INFO  - Training [63][   40/  196]   Loss 0.012320   Top1 99.687500   Top5 100.000000   BatchTime 0.171198   LR 0.000100   
2022-11-04 02:17:13,165 - INFO  - Training [63][   60/  196]   Loss 0.014804   Top1 99.563802   Top5 100.000000   BatchTime 0.157612   LR 0.000100   
2022-11-04 02:17:15,634 - INFO  - Training [63][   80/  196]   Loss 0.016105   Top1 99.511719   Top5 100.000000   BatchTime 0.149068   LR 0.000100   
2022-11-04 02:17:18,069 - INFO  - Training [63][  100/  196]   Loss 0.016060   Top1 99.492188   Top5 100.000000   BatchTime 0.143606   LR 0.000100   
2022-11-04 02:17:20,544 - INFO  - Training [63][  120/  196]   Loss 0.016099   Top1 99.485677   Top5 100.000000   BatchTime 0.140296   LR 0.000100   
2022-11-04 02:17:22,709 - INFO  - Training [63][  140/  196]   Loss 0.016439   Top1 99.475446   Top5 100.000000   BatchTime 0.135717   LR 0.000100   
2022-11-04 02:17:24,600 - INFO  - Training [63][  160/  196]   Loss 0.016592   Top1 99.470215   Top5 100.000000   BatchTime 0.130571   LR 0.000100   
2022-11-04 02:17:26,644 - INFO  - Training [63][  180/  196]   Loss 0.016214   Top1 99.485677   Top5 100.000000   BatchTime 0.127416   LR 0.000100   
2022-11-04 02:17:28,568 - INFO  - ==> Top1: 99.476    Top5: 100.000    Loss: 0.017

2022-11-04 02:17:28,569 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:17:31,343 - INFO  - Validation [63][   20/   40]   Loss 0.468958   Top1 90.312500   Top5 99.550781   BatchTime 0.138629   
2022-11-04 02:17:32,485 - INFO  - Validation [63][   40/   40]   Loss 0.454926   Top1 90.490000   Top5 99.670000   BatchTime 0.097867   
2022-11-04 02:17:32,742 - INFO  - ==> Top1: 90.490    Top5: 99.670    Loss: 0.455

2022-11-04 02:17:32,779 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:17:32,779 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:17:32,780 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:17:32,884 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:17:32,885 - INFO  - >>>>>>>> Epoch  64
2022-11-04 02:17:32,887 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:17:37,277 - INFO  - Training [64][   20/  196]   Loss 0.014762   Top1 99.570312   Top5 100.000000   BatchTime 0.219511   LR 0.000100   
2022-11-04 02:17:39,750 - INFO  - Training [64][   40/  196]   Loss 0.016526   Top1 99.472656   Top5 100.000000   BatchTime 0.171588   LR 0.000100   
2022-11-04 02:17:42,228 - INFO  - Training [64][   60/  196]   Loss 0.015810   Top1 99.537760   Top5 100.000000   BatchTime 0.155681   LR 0.000100   
2022-11-04 02:17:44,698 - INFO  - Training [64][   80/  196]   Loss 0.016405   Top1 99.492188   Top5 100.000000   BatchTime 0.147633   LR 0.000100   
2022-11-04 02:17:47,171 - INFO  - Training [64][  100/  196]   Loss 0.015864   Top1 99.519531   Top5 100.000000   BatchTime 0.142843   LR 0.000100   
2022-11-04 02:17:49,647 - INFO  - Training [64][  120/  196]   Loss 0.015585   Top1 99.524740   Top5 100.000000   BatchTime 0.139664   LR 0.000100   
2022-11-04 02:17:52,114 - INFO  - Training [64][  140/  196]   Loss 0.015545   Top1 99.520089   Top5 100.000000   BatchTime 0.137337   LR 0.000100   
2022-11-04 02:17:54,573 - INFO  - Training [64][  160/  196]   Loss 0.016209   Top1 99.497070   Top5 100.000000   BatchTime 0.135535   LR 0.000100   
2022-11-04 02:17:57,050 - INFO  - Training [64][  180/  196]   Loss 0.016347   Top1 99.505208   Top5 100.000000   BatchTime 0.134238   LR 0.000100   
2022-11-04 02:17:59,239 - INFO  - ==> Top1: 99.488    Top5: 100.000    Loss: 0.017

2022-11-04 02:17:59,240 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:18:02,081 - INFO  - Validation [64][   20/   40]   Loss 0.469178   Top1 90.488281   Top5 99.531250   BatchTime 0.141994   
2022-11-04 02:18:03,183 - INFO  - Validation [64][   40/   40]   Loss 0.453470   Top1 90.610000   Top5 99.630000   BatchTime 0.098540   
2022-11-04 02:18:03,448 - INFO  - ==> Top1: 90.610    Top5: 99.630    Loss: 0.453

2022-11-04 02:18:03,480 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:18:03,481 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:18:03,481 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:18:03,589 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:18:03,589 - INFO  - >>>>>>>> Epoch  65
2022-11-04 02:18:03,590 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:18:07,950 - INFO  - Training [65][   20/  196]   Loss 0.011737   Top1 99.687500   Top5 100.000000   BatchTime 0.217960   LR 0.000100   
2022-11-04 02:18:10,414 - INFO  - Training [65][   40/  196]   Loss 0.014397   Top1 99.550781   Top5 100.000000   BatchTime 0.170596   LR 0.000100   
2022-11-04 02:18:12,884 - INFO  - Training [65][   60/  196]   Loss 0.015620   Top1 99.485677   Top5 100.000000   BatchTime 0.154892   LR 0.000100   
2022-11-04 02:18:15,356 - INFO  - Training [65][   80/  196]   Loss 0.016085   Top1 99.482422   Top5 100.000000   BatchTime 0.147066   LR 0.000100   
2022-11-04 02:18:17,279 - INFO  - Training [65][  100/  196]   Loss 0.016330   Top1 99.449219   Top5 100.000000   BatchTime 0.136883   LR 0.000100   
2022-11-04 02:18:19,368 - INFO  - Training [65][  120/  196]   Loss 0.016588   Top1 99.449870   Top5 100.000000   BatchTime 0.131475   LR 0.000100   
2022-11-04 02:18:21,425 - INFO  - Training [65][  140/  196]   Loss 0.016807   Top1 99.453125   Top5 100.000000   BatchTime 0.127389   LR 0.000100   
2022-11-04 02:18:23,417 - INFO  - Training [65][  160/  196]   Loss 0.016996   Top1 99.448242   Top5 100.000000   BatchTime 0.123912   LR 0.000100   
2022-11-04 02:18:25,392 - INFO  - Training [65][  180/  196]   Loss 0.017138   Top1 99.442274   Top5 100.000000   BatchTime 0.121118   LR 0.000100   
2022-11-04 02:18:27,570 - INFO  - ==> Top1: 99.440    Top5: 100.000    Loss: 0.017

2022-11-04 02:18:27,570 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:18:30,440 - INFO  - Validation [65][   20/   40]   Loss 0.471253   Top1 90.527344   Top5 99.550781   BatchTime 0.143385   
2022-11-04 02:18:31,545 - INFO  - Validation [65][   40/   40]   Loss 0.456351   Top1 90.820000   Top5 99.660000   BatchTime 0.099312   
2022-11-04 02:18:31,782 - INFO  - ==> Top1: 90.820    Top5: 99.660    Loss: 0.456

2022-11-04 02:18:31,811 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:18:31,812 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:18:31,812 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:18:31,914 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:18:31,914 - INFO  - >>>>>>>> Epoch  66
2022-11-04 02:18:31,915 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:18:36,276 - INFO  - Training [66][   20/  196]   Loss 0.014806   Top1 99.453125   Top5 100.000000   BatchTime 0.218025   LR 0.000100   
2022-11-04 02:18:38,751 - INFO  - Training [66][   40/  196]   Loss 0.017466   Top1 99.375000   Top5 100.000000   BatchTime 0.170887   LR 0.000100   
2022-11-04 02:18:41,245 - INFO  - Training [66][   60/  196]   Loss 0.016638   Top1 99.427083   Top5 100.000000   BatchTime 0.155494   LR 0.000100   
2022-11-04 02:18:43,724 - INFO  - Training [66][   80/  196]   Loss 0.016737   Top1 99.404297   Top5 100.000000   BatchTime 0.147602   LR 0.000100   
2022-11-04 02:18:46,211 - INFO  - Training [66][  100/  196]   Loss 0.016357   Top1 99.429688   Top5 100.000000   BatchTime 0.142955   LR 0.000100   
2022-11-04 02:18:48,674 - INFO  - Training [66][  120/  196]   Loss 0.016463   Top1 99.433594   Top5 100.000000   BatchTime 0.139649   LR 0.000100   
2022-11-04 02:18:51,156 - INFO  - Training [66][  140/  196]   Loss 0.016929   Top1 99.428013   Top5 100.000000   BatchTime 0.137429   LR 0.000100   
2022-11-04 02:18:53,623 - INFO  - Training [66][  160/  196]   Loss 0.016461   Top1 99.448242   Top5 100.000000   BatchTime 0.135669   LR 0.000100   
2022-11-04 02:18:56,095 - INFO  - Training [66][  180/  196]   Loss 0.016748   Top1 99.440104   Top5 100.000000   BatchTime 0.134326   LR 0.000100   
2022-11-04 02:18:58,285 - INFO  - ==> Top1: 99.448    Top5: 100.000    Loss: 0.017

2022-11-04 02:18:58,286 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:19:01,127 - INFO  - Validation [66][   20/   40]   Loss 0.473861   Top1 90.175781   Top5 99.511719   BatchTime 0.141984   
2022-11-04 02:19:02,252 - INFO  - Validation [66][   40/   40]   Loss 0.458582   Top1 90.510000   Top5 99.640000   BatchTime 0.099119   
2022-11-04 02:19:02,508 - INFO  - ==> Top1: 90.510    Top5: 99.640    Loss: 0.459

2022-11-04 02:19:02,537 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:19:02,538 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:19:02,538 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:19:02,638 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:19:02,638 - INFO  - >>>>>>>> Epoch  67
2022-11-04 02:19:02,639 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:19:06,964 - INFO  - Training [67][   20/  196]   Loss 0.012602   Top1 99.609375   Top5 100.000000   BatchTime 0.216232   LR 0.000100   
2022-11-04 02:19:09,026 - INFO  - Training [67][   40/  196]   Loss 0.013859   Top1 99.570312   Top5 100.000000   BatchTime 0.159672   LR 0.000100   
2022-11-04 02:19:11,039 - INFO  - Training [67][   60/  196]   Loss 0.015650   Top1 99.511719   Top5 100.000000   BatchTime 0.139990   LR 0.000100   
2022-11-04 02:19:13,099 - INFO  - Training [67][   80/  196]   Loss 0.015695   Top1 99.506836   Top5 100.000000   BatchTime 0.130747   LR 0.000100   
2022-11-04 02:19:15,177 - INFO  - Training [67][  100/  196]   Loss 0.015969   Top1 99.488281   Top5 100.000000   BatchTime 0.125382   LR 0.000100   
2022-11-04 02:19:16,972 - INFO  - Training [67][  120/  196]   Loss 0.016337   Top1 99.475911   Top5 100.000000   BatchTime 0.119440   LR 0.000100   
2022-11-04 02:19:19,527 - INFO  - Training [67][  140/  196]   Loss 0.015962   Top1 99.497768   Top5 100.000000   BatchTime 0.120625   LR 0.000100   
2022-11-04 02:19:21,995 - INFO  - Training [67][  160/  196]   Loss 0.016312   Top1 99.482422   Top5 100.000000   BatchTime 0.120975   LR 0.000100   
2022-11-04 02:19:24,459 - INFO  - Training [67][  180/  196]   Loss 0.016234   Top1 99.485677   Top5 100.000000   BatchTime 0.121222   LR 0.000100   
2022-11-04 02:19:26,629 - INFO  - ==> Top1: 99.476    Top5: 100.000    Loss: 0.016

2022-11-04 02:19:26,629 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:19:29,531 - INFO  - Validation [67][   20/   40]   Loss 0.474380   Top1 90.253906   Top5 99.492188   BatchTime 0.145039   
2022-11-04 02:19:30,638 - INFO  - Validation [67][   40/   40]   Loss 0.457162   Top1 90.580000   Top5 99.630000   BatchTime 0.100197   
2022-11-04 02:19:30,890 - INFO  - ==> Top1: 90.580    Top5: 99.630    Loss: 0.457

2022-11-04 02:19:30,930 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:19:30,931 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:19:30,931 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:19:31,036 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:19:31,036 - INFO  - >>>>>>>> Epoch  68
2022-11-04 02:19:31,038 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:19:35,445 - INFO  - Training [68][   20/  196]   Loss 0.015413   Top1 99.550781   Top5 100.000000   BatchTime 0.220362   LR 0.000100   
2022-11-04 02:19:37,926 - INFO  - Training [68][   40/  196]   Loss 0.017188   Top1 99.511719   Top5 100.000000   BatchTime 0.172205   LR 0.000100   
2022-11-04 02:19:40,407 - INFO  - Training [68][   60/  196]   Loss 0.017278   Top1 99.498698   Top5 100.000000   BatchTime 0.156153   LR 0.000100   
2022-11-04 02:19:42,880 - INFO  - Training [68][   80/  196]   Loss 0.016593   Top1 99.506836   Top5 100.000000   BatchTime 0.148027   LR 0.000100   
2022-11-04 02:19:45,356 - INFO  - Training [68][  100/  196]   Loss 0.016673   Top1 99.484375   Top5 100.000000   BatchTime 0.143183   LR 0.000100   
2022-11-04 02:19:47,840 - INFO  - Training [68][  120/  196]   Loss 0.017806   Top1 99.427083   Top5 100.000000   BatchTime 0.140018   LR 0.000100   
2022-11-04 02:19:50,302 - INFO  - Training [68][  140/  196]   Loss 0.017713   Top1 99.428013   Top5 100.000000   BatchTime 0.137600   LR 0.000100   
2022-11-04 02:19:52,759 - INFO  - Training [68][  160/  196]   Loss 0.017714   Top1 99.428711   Top5 100.000000   BatchTime 0.135756   LR 0.000100   
2022-11-04 02:19:55,220 - INFO  - Training [68][  180/  196]   Loss 0.017544   Top1 99.433594   Top5 100.000000   BatchTime 0.134346   LR 0.000100   
2022-11-04 02:19:57,383 - INFO  - ==> Top1: 99.452    Top5: 100.000    Loss: 0.017

2022-11-04 02:19:57,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:20:00,221 - INFO  - Validation [68][   20/   40]   Loss 0.469829   Top1 90.410156   Top5 99.550781   BatchTime 0.141819   
2022-11-04 02:20:01,224 - INFO  - Validation [68][   40/   40]   Loss 0.455291   Top1 90.680000   Top5 99.610000   BatchTime 0.095991   
2022-11-04 02:20:01,487 - INFO  - ==> Top1: 90.680    Top5: 99.610    Loss: 0.455

2022-11-04 02:20:01,513 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:20:01,513 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:20:01,513 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:20:01,618 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:20:01,618 - INFO  - >>>>>>>> Epoch  69
2022-11-04 02:20:01,620 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:20:05,689 - INFO  - Training [69][   20/  196]   Loss 0.017982   Top1 99.375000   Top5 100.000000   BatchTime 0.203463   LR 0.000100   
2022-11-04 02:20:07,729 - INFO  - Training [69][   40/  196]   Loss 0.018364   Top1 99.384766   Top5 100.000000   BatchTime 0.152735   LR 0.000100   
2022-11-04 02:20:09,598 - INFO  - Training [69][   60/  196]   Loss 0.017276   Top1 99.401042   Top5 100.000000   BatchTime 0.132974   LR 0.000100   
2022-11-04 02:20:11,877 - INFO  - Training [69][   80/  196]   Loss 0.015762   Top1 99.492188   Top5 100.000000   BatchTime 0.128215   LR 0.000100   
2022-11-04 02:20:14,354 - INFO  - Training [69][  100/  196]   Loss 0.015299   Top1 99.496094   Top5 100.000000   BatchTime 0.127334   LR 0.000100   
2022-11-04 02:20:16,839 - INFO  - Training [69][  120/  196]   Loss 0.015481   Top1 99.492188   Top5 100.000000   BatchTime 0.126825   LR 0.000100   
2022-11-04 02:20:19,310 - INFO  - Training [69][  140/  196]   Loss 0.016245   Top1 99.458705   Top5 100.000000   BatchTime 0.126355   LR 0.000100   
2022-11-04 02:20:21,773 - INFO  - Training [69][  160/  196]   Loss 0.016381   Top1 99.462891   Top5 100.000000   BatchTime 0.125956   LR 0.000100   
2022-11-04 02:20:24,226 - INFO  - Training [69][  180/  196]   Loss 0.016375   Top1 99.463976   Top5 100.000000   BatchTime 0.125585   LR 0.000100   
2022-11-04 02:20:26,392 - INFO  - ==> Top1: 99.462    Top5: 100.000    Loss: 0.017

2022-11-04 02:20:26,393 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:20:29,231 - INFO  - Validation [69][   20/   40]   Loss 0.473780   Top1 90.371094   Top5 99.531250   BatchTime 0.141836   
2022-11-04 02:20:30,336 - INFO  - Validation [69][   40/   40]   Loss 0.456006   Top1 90.720000   Top5 99.650000   BatchTime 0.098537   
2022-11-04 02:20:30,594 - INFO  - ==> Top1: 90.720    Top5: 99.650    Loss: 0.456

2022-11-04 02:20:30,640 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:20:30,640 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:20:30,640 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:20:30,716 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:20:30,717 - INFO  - >>>>>>>> Epoch  70
2022-11-04 02:20:30,718 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:20:35,093 - INFO  - Training [70][   20/  196]   Loss 0.013943   Top1 99.550781   Top5 100.000000   BatchTime 0.218778   LR 0.000010   
2022-11-04 02:20:37,570 - INFO  - Training [70][   40/  196]   Loss 0.016744   Top1 99.453125   Top5 100.000000   BatchTime 0.171304   LR 0.000010   
2022-11-04 02:20:40,037 - INFO  - Training [70][   60/  196]   Loss 0.016773   Top1 99.459635   Top5 100.000000   BatchTime 0.155318   LR 0.000010   
2022-11-04 02:20:42,519 - INFO  - Training [70][   80/  196]   Loss 0.016696   Top1 99.477539   Top5 100.000000   BatchTime 0.147519   LR 0.000010   
2022-11-04 02:20:44,997 - INFO  - Training [70][  100/  196]   Loss 0.017207   Top1 99.445312   Top5 100.000000   BatchTime 0.142787   LR 0.000010   
2022-11-04 02:20:47,478 - INFO  - Training [70][  120/  196]   Loss 0.016625   Top1 99.472656   Top5 100.000000   BatchTime 0.139669   LR 0.000010   
2022-11-04 02:20:49,943 - INFO  - Training [70][  140/  196]   Loss 0.016396   Top1 99.492188   Top5 100.000000   BatchTime 0.137319   LR 0.000010   
2022-11-04 02:20:52,393 - INFO  - Training [70][  160/  196]   Loss 0.016559   Top1 99.492188   Top5 100.000000   BatchTime 0.135468   LR 0.000010   
2022-11-04 02:20:54,845 - INFO  - Training [70][  180/  196]   Loss 0.016388   Top1 99.498698   Top5 100.000000   BatchTime 0.134037   LR 0.000010   
2022-11-04 02:20:56,775 - INFO  - ==> Top1: 99.488    Top5: 100.000    Loss: 0.017

2022-11-04 02:20:56,776 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:20:59,461 - INFO  - Validation [70][   20/   40]   Loss 0.469385   Top1 90.390625   Top5 99.550781   BatchTime 0.134215   
2022-11-04 02:21:00,320 - INFO  - Validation [70][   40/   40]   Loss 0.451553   Top1 90.780000   Top5 99.650000   BatchTime 0.088565   
2022-11-04 02:21:00,568 - INFO  - ==> Top1: 90.780    Top5: 99.650    Loss: 0.452

2022-11-04 02:21:00,600 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:21:00,601 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:21:00,601 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:21:00,705 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:21:00,705 - INFO  - >>>>>>>> Epoch  71
2022-11-04 02:21:00,707 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:21:05,060 - INFO  - Training [71][   20/  196]   Loss 0.013782   Top1 99.648438   Top5 100.000000   BatchTime 0.217649   LR 0.000010   
2022-11-04 02:21:07,530 - INFO  - Training [71][   40/  196]   Loss 0.014118   Top1 99.580078   Top5 100.000000   BatchTime 0.170581   LR 0.000010   
2022-11-04 02:21:09,997 - INFO  - Training [71][   60/  196]   Loss 0.014418   Top1 99.570312   Top5 100.000000   BatchTime 0.154839   LR 0.000010   
2022-11-04 02:21:12,475 - INFO  - Training [71][   80/  196]   Loss 0.014820   Top1 99.560547   Top5 100.000000   BatchTime 0.147097   LR 0.000010   
2022-11-04 02:21:14,903 - INFO  - Training [71][  100/  196]   Loss 0.015298   Top1 99.542969   Top5 100.000000   BatchTime 0.141957   LR 0.000010   
2022-11-04 02:21:17,373 - INFO  - Training [71][  120/  196]   Loss 0.016028   Top1 99.508464   Top5 100.000000   BatchTime 0.138880   LR 0.000010   
2022-11-04 02:21:19,842 - INFO  - Training [71][  140/  196]   Loss 0.016410   Top1 99.494978   Top5 100.000000   BatchTime 0.136675   LR 0.000010   
2022-11-04 02:21:22,300 - INFO  - Training [71][  160/  196]   Loss 0.016386   Top1 99.489746   Top5 100.000000   BatchTime 0.134958   LR 0.000010   
2022-11-04 02:21:24,757 - INFO  - Training [71][  180/  196]   Loss 0.016281   Top1 99.492188   Top5 100.000000   BatchTime 0.133609   LR 0.000010   
2022-11-04 02:21:27,016 - INFO  - ==> Top1: 99.490    Top5: 100.000    Loss: 0.016

2022-11-04 02:21:27,016 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:21:29,868 - INFO  - Validation [71][   20/   40]   Loss 0.458481   Top1 90.507812   Top5 99.550781   BatchTime 0.142542   
2022-11-04 02:21:30,970 - INFO  - Validation [71][   40/   40]   Loss 0.450133   Top1 90.860000   Top5 99.650000   BatchTime 0.098799   
2022-11-04 02:21:31,214 - INFO  - ==> Top1: 90.860    Top5: 99.650    Loss: 0.450

2022-11-04 02:21:31,244 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:21:31,244 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:21:31,244 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:21:31,323 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:21:31,323 - INFO  - >>>>>>>> Epoch  72
2022-11-04 02:21:31,324 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:21:35,662 - INFO  - Training [72][   20/  196]   Loss 0.020344   Top1 99.355469   Top5 100.000000   BatchTime 0.216843   LR 0.000010   
2022-11-04 02:21:38,138 - INFO  - Training [72][   40/  196]   Loss 0.019038   Top1 99.306641   Top5 100.000000   BatchTime 0.170330   LR 0.000010   
2022-11-04 02:21:40,605 - INFO  - Training [72][   60/  196]   Loss 0.017867   Top1 99.381510   Top5 100.000000   BatchTime 0.154666   LR 0.000010   
2022-11-04 02:21:43,075 - INFO  - Training [72][   80/  196]   Loss 0.017367   Top1 99.409180   Top5 100.000000   BatchTime 0.146874   LR 0.000010   
2022-11-04 02:21:45,544 - INFO  - Training [72][  100/  196]   Loss 0.017724   Top1 99.406250   Top5 99.996094   BatchTime 0.142191   LR 0.000010   
2022-11-04 02:21:48,006 - INFO  - Training [72][  120/  196]   Loss 0.017154   Top1 99.420573   Top5 99.996745   BatchTime 0.139006   LR 0.000010   
2022-11-04 02:21:50,137 - INFO  - Training [72][  140/  196]   Loss 0.017137   Top1 99.425223   Top5 99.997210   BatchTime 0.134374   LR 0.000010   
2022-11-04 02:21:52,015 - INFO  - Training [72][  160/  196]   Loss 0.017309   Top1 99.406738   Top5 99.997559   BatchTime 0.129315   LR 0.000010   
2022-11-04 02:21:54,029 - INFO  - Training [72][  180/  196]   Loss 0.017234   Top1 99.414062   Top5 99.997830   BatchTime 0.126132   LR 0.000010   
2022-11-04 02:21:55,859 - INFO  - ==> Top1: 99.428    Top5: 99.998    Loss: 0.017

2022-11-04 02:21:55,859 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:21:58,801 - INFO  - Validation [72][   20/   40]   Loss 0.467318   Top1 90.371094   Top5 99.492188   BatchTime 0.147026   
2022-11-04 02:21:59,894 - INFO  - Validation [72][   40/   40]   Loss 0.454404   Top1 90.600000   Top5 99.600000   BatchTime 0.100849   
2022-11-04 02:22:00,142 - INFO  - ==> Top1: 90.600    Top5: 99.600    Loss: 0.454

2022-11-04 02:22:00,181 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:22:00,182 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:22:00,182 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:22:00,285 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:22:00,285 - INFO  - >>>>>>>> Epoch  73
2022-11-04 02:22:00,286 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:22:04,635 - INFO  - Training [73][   20/  196]   Loss 0.012877   Top1 99.589844   Top5 100.000000   BatchTime 0.217414   LR 0.000010   
2022-11-04 02:22:07,123 - INFO  - Training [73][   40/  196]   Loss 0.014996   Top1 99.541016   Top5 100.000000   BatchTime 0.170917   LR 0.000010   
2022-11-04 02:22:09,599 - INFO  - Training [73][   60/  196]   Loss 0.016679   Top1 99.440104   Top5 100.000000   BatchTime 0.155212   LR 0.000010   
2022-11-04 02:22:12,103 - INFO  - Training [73][   80/  196]   Loss 0.017236   Top1 99.414062   Top5 100.000000   BatchTime 0.147702   LR 0.000010   
2022-11-04 02:22:14,577 - INFO  - Training [73][  100/  196]   Loss 0.017599   Top1 99.394531   Top5 100.000000   BatchTime 0.142905   LR 0.000010   
2022-11-04 02:22:17,056 - INFO  - Training [73][  120/  196]   Loss 0.017173   Top1 99.433594   Top5 100.000000   BatchTime 0.139743   LR 0.000010   
2022-11-04 02:22:19,538 - INFO  - Training [73][  140/  196]   Loss 0.017064   Top1 99.441964   Top5 100.000000   BatchTime 0.137507   LR 0.000010   
2022-11-04 02:22:22,001 - INFO  - Training [73][  160/  196]   Loss 0.017185   Top1 99.443359   Top5 100.000000   BatchTime 0.135711   LR 0.000010   
2022-11-04 02:22:24,464 - INFO  - Training [73][  180/  196]   Loss 0.017106   Top1 99.433594   Top5 100.000000   BatchTime 0.134315   LR 0.000010   
2022-11-04 02:22:26,643 - INFO  - ==> Top1: 99.436    Top5: 100.000    Loss: 0.017

2022-11-04 02:22:26,643 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:22:29,496 - INFO  - Validation [73][   20/   40]   Loss 0.470263   Top1 90.371094   Top5 99.472656   BatchTime 0.142588   
2022-11-04 02:22:30,597 - INFO  - Validation [73][   40/   40]   Loss 0.457271   Top1 90.680000   Top5 99.610000   BatchTime 0.098814   
2022-11-04 02:22:30,859 - INFO  - ==> Top1: 90.680    Top5: 99.610    Loss: 0.457

2022-11-04 02:22:30,907 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:22:30,907 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:22:30,907 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:22:31,005 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:22:31,005 - INFO  - >>>>>>>> Epoch  74
2022-11-04 02:22:31,007 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:22:35,371 - INFO  - Training [74][   20/  196]   Loss 0.014287   Top1 99.648438   Top5 100.000000   BatchTime 0.218176   LR 0.000010   
2022-11-04 02:22:37,835 - INFO  - Training [74][   40/  196]   Loss 0.016644   Top1 99.541016   Top5 100.000000   BatchTime 0.170694   LR 0.000010   
2022-11-04 02:22:40,315 - INFO  - Training [74][   60/  196]   Loss 0.017117   Top1 99.472656   Top5 100.000000   BatchTime 0.155130   LR 0.000010   
2022-11-04 02:22:42,678 - INFO  - Training [74][   80/  196]   Loss 0.015768   Top1 99.526367   Top5 100.000000   BatchTime 0.145888   LR 0.000010   
2022-11-04 02:22:44,501 - INFO  - Training [74][  100/  196]   Loss 0.015637   Top1 99.531250   Top5 100.000000   BatchTime 0.134932   LR 0.000010   
2022-11-04 02:22:46,531 - INFO  - Training [74][  120/  196]   Loss 0.015898   Top1 99.511719   Top5 100.000000   BatchTime 0.129362   LR 0.000010   
2022-11-04 02:22:48,535 - INFO  - Training [74][  140/  196]   Loss 0.015814   Top1 99.522879   Top5 100.000000   BatchTime 0.125198   LR 0.000010   
2022-11-04 02:22:50,479 - INFO  - Training [74][  160/  196]   Loss 0.015757   Top1 99.523926   Top5 100.000000   BatchTime 0.121695   LR 0.000010   
2022-11-04 02:22:52,490 - INFO  - Training [74][  180/  196]   Loss 0.015858   Top1 99.524740   Top5 100.000000   BatchTime 0.119345   LR 0.000010   
2022-11-04 02:22:54,670 - INFO  - ==> Top1: 99.516    Top5: 100.000    Loss: 0.016

2022-11-04 02:22:54,670 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:22:57,539 - INFO  - Validation [74][   20/   40]   Loss 0.474758   Top1 90.253906   Top5 99.453125   BatchTime 0.143362   
2022-11-04 02:22:58,680 - INFO  - Validation [74][   40/   40]   Loss 0.459340   Top1 90.600000   Top5 99.580000   BatchTime 0.100217   
2022-11-04 02:22:58,934 - INFO  - ==> Top1: 90.600    Top5: 99.580    Loss: 0.459

2022-11-04 02:22:58,972 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:22:58,972 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:22:58,973 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:22:59,076 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:22:59,076 - INFO  - >>>>>>>> Epoch  75
2022-11-04 02:22:59,077 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:23:03,441 - INFO  - Training [75][   20/  196]   Loss 0.019451   Top1 99.316406   Top5 100.000000   BatchTime 0.218161   LR 0.000010   
2022-11-04 02:23:05,910 - INFO  - Training [75][   40/  196]   Loss 0.019292   Top1 99.316406   Top5 100.000000   BatchTime 0.170817   LR 0.000010   
2022-11-04 02:23:08,357 - INFO  - Training [75][   60/  196]   Loss 0.017673   Top1 99.368490   Top5 100.000000   BatchTime 0.154659   LR 0.000010   
2022-11-04 02:23:10,829 - INFO  - Training [75][   80/  196]   Loss 0.017352   Top1 99.399414   Top5 100.000000   BatchTime 0.146889   LR 0.000010   
2022-11-04 02:23:13,306 - INFO  - Training [75][  100/  196]   Loss 0.017042   Top1 99.417969   Top5 100.000000   BatchTime 0.142286   LR 0.000010   
2022-11-04 02:23:15,790 - INFO  - Training [75][  120/  196]   Loss 0.016812   Top1 99.423828   Top5 100.000000   BatchTime 0.139269   LR 0.000010   
2022-11-04 02:23:18,255 - INFO  - Training [75][  140/  196]   Loss 0.016613   Top1 99.428013   Top5 100.000000   BatchTime 0.136978   LR 0.000010   
2022-11-04 02:23:20,727 - INFO  - Training [75][  160/  196]   Loss 0.016717   Top1 99.433594   Top5 100.000000   BatchTime 0.135309   LR 0.000010   
2022-11-04 02:23:23,192 - INFO  - Training [75][  180/  196]   Loss 0.016458   Top1 99.446615   Top5 100.000000   BatchTime 0.133968   LR 0.000010   
2022-11-04 02:23:25,395 - INFO  - ==> Top1: 99.438    Top5: 100.000    Loss: 0.017

2022-11-04 02:23:25,396 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:23:28,250 - INFO  - Validation [75][   20/   40]   Loss 0.465711   Top1 90.410156   Top5 99.531250   BatchTime 0.142647   
2022-11-04 02:23:29,374 - INFO  - Validation [75][   40/   40]   Loss 0.454809   Top1 90.650000   Top5 99.650000   BatchTime 0.099415   
2022-11-04 02:23:29,626 - INFO  - ==> Top1: 90.650    Top5: 99.650    Loss: 0.455

2022-11-04 02:23:29,658 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:23:29,659 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:23:29,659 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:23:29,758 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:23:29,759 - INFO  - >>>>>>>> Epoch  76
2022-11-04 02:23:29,760 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:23:34,180 - INFO  - Training [76][   20/  196]   Loss 0.016096   Top1 99.472656   Top5 100.000000   BatchTime 0.220989   LR 0.000010   
2022-11-04 02:23:35,939 - INFO  - Training [76][   40/  196]   Loss 0.015485   Top1 99.511719   Top5 100.000000   BatchTime 0.154467   LR 0.000010   
2022-11-04 02:23:38,018 - INFO  - Training [76][   60/  196]   Loss 0.015102   Top1 99.544271   Top5 100.000000   BatchTime 0.137628   LR 0.000010   
2022-11-04 02:23:40,034 - INFO  - Training [76][   80/  196]   Loss 0.015062   Top1 99.536133   Top5 100.000000   BatchTime 0.128423   LR 0.000010   
2022-11-04 02:23:42,053 - INFO  - Training [76][  100/  196]   Loss 0.014661   Top1 99.550781   Top5 100.000000   BatchTime 0.122921   LR 0.000010   
2022-11-04 02:23:44,058 - INFO  - Training [76][  120/  196]   Loss 0.015138   Top1 99.537760   Top5 100.000000   BatchTime 0.119145   LR 0.000010   
2022-11-04 02:23:46,538 - INFO  - Training [76][  140/  196]   Loss 0.015338   Top1 99.534040   Top5 100.000000   BatchTime 0.119839   LR 0.000010   
2022-11-04 02:23:48,999 - INFO  - Training [76][  160/  196]   Loss 0.016654   Top1 99.484863   Top5 100.000000   BatchTime 0.120239   LR 0.000010   
2022-11-04 02:23:51,459 - INFO  - Training [76][  180/  196]   Loss 0.016591   Top1 99.476997   Top5 100.000000   BatchTime 0.120545   LR 0.000010   
2022-11-04 02:23:53,632 - INFO  - ==> Top1: 99.474    Top5: 100.000    Loss: 0.017

2022-11-04 02:23:53,633 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:23:56,456 - INFO  - Validation [76][   20/   40]   Loss 0.469583   Top1 90.390625   Top5 99.531250   BatchTime 0.141094   
2022-11-04 02:23:57,574 - INFO  - Validation [76][   40/   40]   Loss 0.456106   Top1 90.730000   Top5 99.640000   BatchTime 0.098484   
2022-11-04 02:23:57,827 - INFO  - ==> Top1: 90.730    Top5: 99.640    Loss: 0.456

2022-11-04 02:23:57,860 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:23:57,861 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:23:57,861 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:23:57,954 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:23:57,955 - INFO  - >>>>>>>> Epoch  77
2022-11-04 02:23:57,956 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:24:02,326 - INFO  - Training [77][   20/  196]   Loss 0.015608   Top1 99.570312   Top5 100.000000   BatchTime 0.218497   LR 0.000010   
2022-11-04 02:24:04,796 - INFO  - Training [77][   40/  196]   Loss 0.016744   Top1 99.492188   Top5 100.000000   BatchTime 0.170994   LR 0.000010   
2022-11-04 02:24:07,270 - INFO  - Training [77][   60/  196]   Loss 0.017085   Top1 99.446615   Top5 100.000000   BatchTime 0.155238   LR 0.000010   
2022-11-04 02:24:09,744 - INFO  - Training [77][   80/  196]   Loss 0.016420   Top1 99.472656   Top5 100.000000   BatchTime 0.147343   LR 0.000010   
2022-11-04 02:24:12,225 - INFO  - Training [77][  100/  196]   Loss 0.016014   Top1 99.480469   Top5 100.000000   BatchTime 0.142692   LR 0.000010   
2022-11-04 02:24:14,700 - INFO  - Training [77][  120/  196]   Loss 0.015819   Top1 99.495443   Top5 100.000000   BatchTime 0.139530   LR 0.000010   
2022-11-04 02:24:17,173 - INFO  - Training [77][  140/  196]   Loss 0.016310   Top1 99.478237   Top5 100.000000   BatchTime 0.137263   LR 0.000010   
2022-11-04 02:24:19,641 - INFO  - Training [77][  160/  196]   Loss 0.016165   Top1 99.482422   Top5 100.000000   BatchTime 0.135532   LR 0.000010   
2022-11-04 02:24:22,097 - INFO  - Training [77][  180/  196]   Loss 0.016276   Top1 99.483507   Top5 100.000000   BatchTime 0.134113   LR 0.000010   
2022-11-04 02:24:24,258 - INFO  - ==> Top1: 99.488    Top5: 100.000    Loss: 0.016

2022-11-04 02:24:24,259 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:24:27,124 - INFO  - Validation [77][   20/   40]   Loss 0.470061   Top1 90.507812   Top5 99.472656   BatchTime 0.143156   
2022-11-04 02:24:27,964 - INFO  - Validation [77][   40/   40]   Loss 0.457941   Top1 90.790000   Top5 99.580000   BatchTime 0.092595   
2022-11-04 02:24:28,220 - INFO  - ==> Top1: 90.790    Top5: 99.580    Loss: 0.458

2022-11-04 02:24:28,246 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:24:28,246 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:24:28,246 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:24:28,345 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:24:28,346 - INFO  - >>>>>>>> Epoch  78
2022-11-04 02:24:28,347 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:24:32,370 - INFO  - Training [78][   20/  196]   Loss 0.012658   Top1 99.609375   Top5 100.000000   BatchTime 0.201177   LR 0.000010   
2022-11-04 02:24:34,437 - INFO  - Training [78][   40/  196]   Loss 0.013501   Top1 99.560547   Top5 100.000000   BatchTime 0.152266   LR 0.000010   
2022-11-04 02:24:36,318 - INFO  - Training [78][   60/  196]   Loss 0.014294   Top1 99.550781   Top5 100.000000   BatchTime 0.132855   LR 0.000010   
2022-11-04 02:24:38,791 - INFO  - Training [78][   80/  196]   Loss 0.014958   Top1 99.492188   Top5 100.000000   BatchTime 0.130548   LR 0.000010   
2022-11-04 02:24:41,259 - INFO  - Training [78][  100/  196]   Loss 0.014505   Top1 99.527344   Top5 100.000000   BatchTime 0.129116   LR 0.000010   
2022-11-04 02:24:43,733 - INFO  - Training [78][  120/  196]   Loss 0.014934   Top1 99.514974   Top5 100.000000   BatchTime 0.128216   LR 0.000010   
2022-11-04 02:24:46,201 - INFO  - Training [78][  140/  196]   Loss 0.015332   Top1 99.503348   Top5 100.000000   BatchTime 0.127528   LR 0.000010   
2022-11-04 02:24:48,665 - INFO  - Training [78][  160/  196]   Loss 0.015681   Top1 99.499512   Top5 100.000000   BatchTime 0.126984   LR 0.000010   
2022-11-04 02:24:51,128 - INFO  - Training [78][  180/  196]   Loss 0.015845   Top1 99.503038   Top5 99.997830   BatchTime 0.126557   LR 0.000010   
2022-11-04 02:24:53,293 - INFO  - ==> Top1: 99.490    Top5: 99.998    Loss: 0.016

2022-11-04 02:24:53,293 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:24:56,165 - INFO  - Validation [78][   20/   40]   Loss 0.459752   Top1 90.644531   Top5 99.511719   BatchTime 0.143473   
2022-11-04 02:24:57,304 - INFO  - Validation [78][   40/   40]   Loss 0.453736   Top1 90.760000   Top5 99.620000   BatchTime 0.100215   
2022-11-04 02:24:57,551 - INFO  - ==> Top1: 90.760    Top5: 99.620    Loss: 0.454

2022-11-04 02:24:57,581 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:24:57,582 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:24:57,582 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:24:57,686 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:24:57,686 - INFO  - >>>>>>>> Epoch  79
2022-11-04 02:24:57,688 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:25:02,034 - INFO  - Training [79][   20/  196]   Loss 0.015122   Top1 99.472656   Top5 100.000000   BatchTime 0.217300   LR 0.000010   
2022-11-04 02:25:04,506 - INFO  - Training [79][   40/  196]   Loss 0.013846   Top1 99.550781   Top5 100.000000   BatchTime 0.170461   LR 0.000010   
2022-11-04 02:25:06,968 - INFO  - Training [79][   60/  196]   Loss 0.016147   Top1 99.440104   Top5 100.000000   BatchTime 0.154666   LR 0.000010   
2022-11-04 02:25:09,436 - INFO  - Training [79][   80/  196]   Loss 0.016572   Top1 99.433594   Top5 100.000000   BatchTime 0.146851   LR 0.000010   
2022-11-04 02:25:11,917 - INFO  - Training [79][  100/  196]   Loss 0.016209   Top1 99.457031   Top5 100.000000   BatchTime 0.142292   LR 0.000010   
2022-11-04 02:25:14,398 - INFO  - Training [79][  120/  196]   Loss 0.015995   Top1 99.479167   Top5 100.000000   BatchTime 0.139244   LR 0.000010   
2022-11-04 02:25:16,867 - INFO  - Training [79][  140/  196]   Loss 0.016409   Top1 99.453125   Top5 100.000000   BatchTime 0.136988   LR 0.000010   
2022-11-04 02:25:19,327 - INFO  - Training [79][  160/  196]   Loss 0.016303   Top1 99.450684   Top5 100.000000   BatchTime 0.135242   LR 0.000010   
2022-11-04 02:25:21,789 - INFO  - Training [79][  180/  196]   Loss 0.016233   Top1 99.450955   Top5 100.000000   BatchTime 0.133891   LR 0.000010   
2022-11-04 02:25:23,373 - INFO  - ==> Top1: 99.466    Top5: 100.000    Loss: 0.016

2022-11-04 02:25:23,374 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:25:25,999 - INFO  - Validation [79][   20/   40]   Loss 0.468345   Top1 90.664062   Top5 99.492188   BatchTime 0.131224   
2022-11-04 02:25:26,789 - INFO  - Validation [79][   40/   40]   Loss 0.453618   Top1 90.830000   Top5 99.650000   BatchTime 0.085354   
2022-11-04 02:25:27,052 - INFO  - ==> Top1: 90.830    Top5: 99.650    Loss: 0.454

2022-11-04 02:25:27,075 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 91.050   Top5: 99.560] Sparsity : 0.847
2022-11-04 02:25:27,076 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.940   Top5: 99.590] Sparsity : 0.847
2022-11-04 02:25:27,076 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.920   Top5: 99.610] Sparsity : 0.847
2022-11-04 02:25:27,150 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_20221104-014541/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch80_checkpoint.pth.tar

2022-11-04 02:25:27,150 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-04 02:25:27,150 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:25:30,163 - INFO  - Validation [   20/   40]   Loss 0.468345   Top1 90.664062   Top5 99.492188   BatchTime 0.150577   
2022-11-04 02:25:31,264 - INFO  - Validation [   40/   40]   Loss 0.453618   Top1 90.830000   Top5 99.650000   BatchTime 0.102809   
2022-11-04 02:25:31,512 - INFO  - ==> Top1: 90.830    Top5: 99.650    Loss: 0.454

2022-11-04 02:25:31,554 - INFO  - Program completed successfully ... exiting ...
2022-11-04 02:25:31,555 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
