2022-11-03 20:38:54,943 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854.log
2022-11-03 20:38:55,971 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/tb_runs
2022-11-03 20:38:57,047 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (391)
        Validation Set = 10000 (79)
              Test Set = 10000 (79)
2022-11-03 20:38:58,748 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = True
2022-11-03 20:39:00,905 - INFO  - Inserted quantizers into the original model
2022-11-03 20:39:01,162 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 20:39:01,162 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 20:39:01,162 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 20:39:01,162 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:39:04,500 - INFO  - Validation [   20/   79]   Loss 2.545371   Top1 10.429688   Top5 49.101562   BatchTime 0.166882   
2022-11-03 20:39:05,180 - INFO  - Validation [   40/   79]   Loss 2.549466   Top1 10.175781   Top5 49.941406   BatchTime 0.100428   
2022-11-03 20:39:05,840 - INFO  - Validation [   60/   79]   Loss 2.541519   Top1 10.117188   Top5 50.377604   BatchTime 0.077954   
2022-11-03 20:39:06,799 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.546

2022-11-03 20:39:06,828 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 20:39:06,828 - INFO  - >>>>>>>> Epoch   0
2022-11-03 20:39:06,829 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:39:10,916 - INFO  - Training [0][   20/  391]   Loss 1.609825   Top1 68.593750   Top5 96.289062   BatchTime 0.204312   LR 0.010000   
2022-11-03 20:39:12,879 - INFO  - Training [0][   40/  391]   Loss 1.340406   Top1 70.078125   Top5 96.914062   BatchTime 0.151237   LR 0.010000   
2022-11-03 20:39:14,860 - INFO  - Training [0][   60/  391]   Loss 1.158603   Top1 71.640625   Top5 97.317708   BatchTime 0.133839   LR 0.010000   
2022-11-03 20:39:16,800 - INFO  - Training [0][   80/  391]   Loss 1.021951   Top1 73.320312   Top5 97.753906   BatchTime 0.124630   LR 0.010000   
2022-11-03 20:39:18,784 - INFO  - Training [0][  100/  391]   Loss 0.926273   Top1 74.929688   Top5 98.007812   BatchTime 0.119537   LR 0.010000   
2022-11-03 20:39:20,737 - INFO  - Training [0][  120/  391]   Loss 0.853287   Top1 76.100260   Top5 98.248698   BatchTime 0.115893   LR 0.010000   
2022-11-03 20:39:22,721 - INFO  - Training [0][  140/  391]   Loss 0.798571   Top1 77.198661   Top5 98.398438   BatchTime 0.113504   LR 0.010000   
2022-11-03 20:39:24,695 - INFO  - Training [0][  160/  391]   Loss 0.756398   Top1 78.076172   Top5 98.520508   BatchTime 0.111657   LR 0.010000   
2022-11-03 20:39:26,672 - INFO  - Training [0][  180/  391]   Loss 0.716463   Top1 78.971354   Top5 98.632812   BatchTime 0.110233   LR 0.010000   
2022-11-03 20:39:28,651 - INFO  - Training [0][  200/  391]   Loss 0.690449   Top1 79.394531   Top5 98.718750   BatchTime 0.109106   LR 0.010000   
2022-11-03 20:39:30,620 - INFO  - Training [0][  220/  391]   Loss 0.667362   Top1 79.825994   Top5 98.785511   BatchTime 0.108136   LR 0.010000   
2022-11-03 20:39:32,574 - INFO  - Training [0][  240/  391]   Loss 0.645425   Top1 80.322266   Top5 98.844401   BatchTime 0.107267   LR 0.010000   
2022-11-03 20:39:34,540 - INFO  - Training [0][  260/  391]   Loss 0.625117   Top1 80.766226   Top5 98.924279   BatchTime 0.106575   LR 0.010000   
2022-11-03 20:39:36,511 - INFO  - Training [0][  280/  391]   Loss 0.608360   Top1 81.130022   Top5 98.978795   BatchTime 0.106002   LR 0.010000   
2022-11-03 20:39:38,464 - INFO  - Training [0][  300/  391]   Loss 0.593001   Top1 81.500000   Top5 99.020833   BatchTime 0.105446   LR 0.010000   
2022-11-03 20:39:40,430 - INFO  - Training [0][  320/  391]   Loss 0.578693   Top1 81.857910   Top5 99.060059   BatchTime 0.105001   LR 0.010000   
2022-11-03 20:39:42,356 - INFO  - Training [0][  340/  391]   Loss 0.565754   Top1 82.173713   Top5 99.085478   BatchTime 0.104486   LR 0.010000   
2022-11-03 20:39:44,262 - INFO  - Training [0][  360/  391]   Loss 0.552444   Top1 82.567274   Top5 99.127604   BatchTime 0.103976   LR 0.010000   
2022-11-03 20:39:46,293 - INFO  - Training [0][  380/  391]   Loss 0.541470   Top1 82.845395   Top5 99.148849   BatchTime 0.103848   LR 0.010000   
2022-11-03 20:39:47,868 - INFO  - ==> Top1: 82.974    Top5: 99.162    Loss: 0.536

2022-11-03 20:39:47,869 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:39:50,367 - INFO  - Validation [0][   20/   79]   Loss 0.457257   Top1 84.296875   Top5 99.375000   BatchTime 0.124818   
2022-11-03 20:39:51,045 - INFO  - Validation [0][   40/   79]   Loss 0.460853   Top1 84.414062   Top5 99.121094   BatchTime 0.079361   
2022-11-03 20:39:51,734 - INFO  - Validation [0][   60/   79]   Loss 0.457164   Top1 84.583333   Top5 99.166667   BatchTime 0.064395   
2022-11-03 20:39:52,757 - INFO  - ==> Top1: 84.440    Top5: 99.290    Loss: 0.455

2022-11-03 20:39:52,786 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.440   Top5: 99.290] Sparsity : 0.312
2022-11-03 20:39:52,786 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 20:39:52,848 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:39:52,849 - INFO  - >>>>>>>> Epoch   1
2022-11-03 20:39:52,849 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:39:56,703 - INFO  - Training [1][   20/  391]   Loss 0.305028   Top1 89.804688   Top5 99.843750   BatchTime 0.192667   LR 0.010000   
2022-11-03 20:39:58,667 - INFO  - Training [1][   40/  391]   Loss 0.297974   Top1 89.628906   Top5 99.746094   BatchTime 0.145423   LR 0.010000   
2022-11-03 20:40:00,621 - INFO  - Training [1][   60/  391]   Loss 0.299732   Top1 89.466146   Top5 99.817708   BatchTime 0.129528   LR 0.010000   
2022-11-03 20:40:02,577 - INFO  - Training [1][   80/  391]   Loss 0.299293   Top1 89.541016   Top5 99.824219   BatchTime 0.121586   LR 0.010000   
2022-11-03 20:40:04,543 - INFO  - Training [1][  100/  391]   Loss 0.293634   Top1 89.789062   Top5 99.820312   BatchTime 0.116932   LR 0.010000   
2022-11-03 20:40:06,510 - INFO  - Training [1][  120/  391]   Loss 0.291124   Top1 89.778646   Top5 99.804688   BatchTime 0.113832   LR 0.010000   
2022-11-03 20:40:08,479 - INFO  - Training [1][  140/  391]   Loss 0.287359   Top1 89.871652   Top5 99.810268   BatchTime 0.111635   LR 0.010000   
2022-11-03 20:40:10,441 - INFO  - Training [1][  160/  391]   Loss 0.285582   Top1 89.936523   Top5 99.819336   BatchTime 0.109945   LR 0.010000   
2022-11-03 20:40:12,409 - INFO  - Training [1][  180/  391]   Loss 0.284921   Top1 89.939236   Top5 99.813368   BatchTime 0.108660   LR 0.010000   
2022-11-03 20:40:14,381 - INFO  - Training [1][  200/  391]   Loss 0.284304   Top1 90.007812   Top5 99.816406   BatchTime 0.107654   LR 0.010000   
2022-11-03 20:40:16,356 - INFO  - Training [1][  220/  391]   Loss 0.284694   Top1 90.003551   Top5 99.801136   BatchTime 0.106845   LR 0.010000   
2022-11-03 20:40:18,323 - INFO  - Training [1][  240/  391]   Loss 0.282457   Top1 90.091146   Top5 99.811198   BatchTime 0.106136   LR 0.010000   
2022-11-03 20:40:20,300 - INFO  - Training [1][  260/  391]   Loss 0.280942   Top1 90.141226   Top5 99.804688   BatchTime 0.105576   LR 0.010000   
2022-11-03 20:40:22,266 - INFO  - Training [1][  280/  391]   Loss 0.277678   Top1 90.270647   Top5 99.807478   BatchTime 0.105057   LR 0.010000   
2022-11-03 20:40:24,239 - INFO  - Training [1][  300/  391]   Loss 0.274737   Top1 90.328125   Top5 99.812500   BatchTime 0.104631   LR 0.010000   
2022-11-03 20:40:26,198 - INFO  - Training [1][  320/  391]   Loss 0.272120   Top1 90.427246   Top5 99.807129   BatchTime 0.104211   LR 0.010000   
2022-11-03 20:40:28,151 - INFO  - Training [1][  340/  391]   Loss 0.270783   Top1 90.475643   Top5 99.806985   BatchTime 0.103826   LR 0.010000   
2022-11-03 20:40:30,074 - INFO  - Training [1][  360/  391]   Loss 0.268988   Top1 90.536024   Top5 99.811198   BatchTime 0.103399   LR 0.010000   
2022-11-03 20:40:32,010 - INFO  - Training [1][  380/  391]   Loss 0.267148   Top1 90.592105   Top5 99.814967   BatchTime 0.103051   LR 0.010000   
2022-11-03 20:40:33,284 - INFO  - ==> Top1: 90.632    Top5: 99.816    Loss: 0.266

2022-11-03 20:40:33,285 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:40:35,788 - INFO  - Validation [1][   20/   79]   Loss 0.435289   Top1 85.859375   Top5 99.375000   BatchTime 0.125052   
2022-11-03 20:40:36,474 - INFO  - Validation [1][   40/   79]   Loss 0.435762   Top1 85.976562   Top5 99.179688   BatchTime 0.079699   
2022-11-03 20:40:37,152 - INFO  - Validation [1][   60/   79]   Loss 0.425537   Top1 86.315104   Top5 99.283854   BatchTime 0.064433   
2022-11-03 20:40:38,025 - INFO  - ==> Top1: 86.580    Top5: 99.380    Loss: 0.419

2022-11-03 20:40:38,057 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.580   Top5: 99.380] Sparsity : 0.553
2022-11-03 20:40:38,058 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.440   Top5: 99.290] Sparsity : 0.312
2022-11-03 20:40:38,058 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 20:40:38,254 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:40:38,255 - INFO  - >>>>>>>> Epoch   2
2022-11-03 20:40:38,255 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:40:42,175 - INFO  - Training [2][   20/  391]   Loss 0.217454   Top1 92.187500   Top5 99.843750   BatchTime 0.195974   LR 0.010000   
2022-11-03 20:40:44,155 - INFO  - Training [2][   40/  391]   Loss 0.221698   Top1 92.011719   Top5 99.765625   BatchTime 0.147492   LR 0.010000   
2022-11-03 20:40:46,147 - INFO  - Training [2][   60/  391]   Loss 0.215159   Top1 92.265625   Top5 99.778646   BatchTime 0.131528   LR 0.010000   
2022-11-03 20:40:48,146 - INFO  - Training [2][   80/  391]   Loss 0.208888   Top1 92.587891   Top5 99.794922   BatchTime 0.123635   LR 0.010000   
2022-11-03 20:40:50,128 - INFO  - Training [2][  100/  391]   Loss 0.206257   Top1 92.679688   Top5 99.820312   BatchTime 0.118728   LR 0.010000   
2022-11-03 20:40:52,110 - INFO  - Training [2][  120/  391]   Loss 0.205782   Top1 92.610677   Top5 99.837240   BatchTime 0.115453   LR 0.010000   
2022-11-03 20:40:54,118 - INFO  - Training [2][  140/  391]   Loss 0.205449   Top1 92.594866   Top5 99.854911   BatchTime 0.113300   LR 0.010000   
2022-11-03 20:40:56,113 - INFO  - Training [2][  160/  391]   Loss 0.206820   Top1 92.558594   Top5 99.853516   BatchTime 0.111610   LR 0.010000   
2022-11-03 20:40:58,113 - INFO  - Training [2][  180/  391]   Loss 0.207663   Top1 92.560764   Top5 99.869792   BatchTime 0.110319   LR 0.010000   
2022-11-03 20:41:00,088 - INFO  - Training [2][  200/  391]   Loss 0.207259   Top1 92.566406   Top5 99.878906   BatchTime 0.109159   LR 0.010000   
2022-11-03 20:41:02,056 - INFO  - Training [2][  220/  391]   Loss 0.208546   Top1 92.549716   Top5 99.886364   BatchTime 0.108185   LR 0.010000   
2022-11-03 20:41:04,040 - INFO  - Training [2][  240/  391]   Loss 0.208643   Top1 92.535807   Top5 99.892578   BatchTime 0.107435   LR 0.010000   
2022-11-03 20:41:06,026 - INFO  - Training [2][  260/  391]   Loss 0.208516   Top1 92.569111   Top5 99.894832   BatchTime 0.106806   LR 0.010000   
2022-11-03 20:41:08,034 - INFO  - Training [2][  280/  391]   Loss 0.208900   Top1 92.586496   Top5 99.899554   BatchTime 0.106350   LR 0.010000   
2022-11-03 20:41:10,021 - INFO  - Training [2][  300/  391]   Loss 0.208549   Top1 92.609375   Top5 99.890625   BatchTime 0.105883   LR 0.010000   
2022-11-03 20:41:11,994 - INFO  - Training [2][  320/  391]   Loss 0.207273   Top1 92.658691   Top5 99.892578   BatchTime 0.105432   LR 0.010000   
2022-11-03 20:41:13,945 - INFO  - Training [2][  340/  391]   Loss 0.206439   Top1 92.690717   Top5 99.894301   BatchTime 0.104968   LR 0.010000   
2022-11-03 20:41:15,870 - INFO  - Training [2][  360/  391]   Loss 0.205420   Top1 92.719184   Top5 99.891493   BatchTime 0.104484   LR 0.010000   
2022-11-03 20:41:17,801 - INFO  - Training [2][  380/  391]   Loss 0.205028   Top1 92.722039   Top5 99.891036   BatchTime 0.104065   LR 0.010000   
2022-11-03 20:41:19,083 - INFO  - ==> Top1: 92.750    Top5: 99.892    Loss: 0.204

2022-11-03 20:41:19,084 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:41:21,517 - INFO  - Validation [2][   20/   79]   Loss 0.408738   Top1 87.421875   Top5 99.609375   BatchTime 0.121557   
2022-11-03 20:41:22,233 - INFO  - Validation [2][   40/   79]   Loss 0.412832   Top1 87.636719   Top5 99.492188   BatchTime 0.078680   
2022-11-03 20:41:22,914 - INFO  - Validation [2][   60/   79]   Loss 0.407369   Top1 87.656250   Top5 99.492188   BatchTime 0.063809   
2022-11-03 20:41:23,806 - INFO  - ==> Top1: 87.490    Top5: 99.540    Loss: 0.407

2022-11-03 20:41:23,838 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.490   Top5: 99.540] Sparsity : 0.573
2022-11-03 20:41:23,839 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.580   Top5: 99.380] Sparsity : 0.553
2022-11-03 20:41:23,839 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 84.440   Top5: 99.290] Sparsity : 0.312
2022-11-03 20:41:24,120 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:41:24,120 - INFO  - >>>>>>>> Epoch   3
2022-11-03 20:41:24,122 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:41:27,820 - INFO  - Training [3][   20/  391]   Loss 0.154155   Top1 94.609375   Top5 99.960938   BatchTime 0.184925   LR 0.010000   
2022-11-03 20:41:29,804 - INFO  - Training [3][   40/  391]   Loss 0.144200   Top1 94.882812   Top5 99.980469   BatchTime 0.142064   LR 0.010000   
2022-11-03 20:41:31,823 - INFO  - Training [3][   60/  391]   Loss 0.152493   Top1 94.765625   Top5 99.973958   BatchTime 0.128352   LR 0.010000   
2022-11-03 20:41:33,821 - INFO  - Training [3][   80/  391]   Loss 0.154526   Top1 94.638672   Top5 99.970703   BatchTime 0.121244   LR 0.010000   
2022-11-03 20:41:35,820 - INFO  - Training [3][  100/  391]   Loss 0.160125   Top1 94.507812   Top5 99.968750   BatchTime 0.116977   LR 0.010000   
2022-11-03 20:41:37,807 - INFO  - Training [3][  120/  391]   Loss 0.163823   Top1 94.388021   Top5 99.967448   BatchTime 0.114039   LR 0.010000   
2022-11-03 20:41:39,783 - INFO  - Training [3][  140/  391]   Loss 0.163247   Top1 94.397321   Top5 99.960938   BatchTime 0.111865   LR 0.010000   
2022-11-03 20:41:41,761 - INFO  - Training [3][  160/  391]   Loss 0.164331   Top1 94.331055   Top5 99.956055   BatchTime 0.110246   LR 0.010000   
2022-11-03 20:41:43,762 - INFO  - Training [3][  180/  391]   Loss 0.164981   Top1 94.270833   Top5 99.960938   BatchTime 0.109111   LR 0.010000   
2022-11-03 20:41:45,749 - INFO  - Training [3][  200/  391]   Loss 0.164800   Top1 94.226562   Top5 99.957031   BatchTime 0.108133   LR 0.010000   
2022-11-03 20:41:47,721 - INFO  - Training [3][  220/  391]   Loss 0.164995   Top1 94.204545   Top5 99.960938   BatchTime 0.107268   LR 0.010000   
2022-11-03 20:41:49,699 - INFO  - Training [3][  240/  391]   Loss 0.164126   Top1 94.212240   Top5 99.960938   BatchTime 0.106569   LR 0.010000   
2022-11-03 20:41:51,681 - INFO  - Training [3][  260/  391]   Loss 0.164969   Top1 94.182692   Top5 99.963942   BatchTime 0.105997   LR 0.010000   
2022-11-03 20:41:53,642 - INFO  - Training [3][  280/  391]   Loss 0.165653   Top1 94.160156   Top5 99.958147   BatchTime 0.105426   LR 0.010000   
2022-11-03 20:41:55,626 - INFO  - Training [3][  300/  391]   Loss 0.164622   Top1 94.205729   Top5 99.955729   BatchTime 0.105012   LR 0.010000   
2022-11-03 20:41:57,621 - INFO  - Training [3][  320/  391]   Loss 0.164245   Top1 94.223633   Top5 99.956055   BatchTime 0.104682   LR 0.010000   
2022-11-03 20:41:59,577 - INFO  - Training [3][  340/  391]   Loss 0.163466   Top1 94.230239   Top5 99.956342   BatchTime 0.104279   LR 0.010000   
2022-11-03 20:42:01,510 - INFO  - Training [3][  360/  391]   Loss 0.163210   Top1 94.214410   Top5 99.958767   BatchTime 0.103855   LR 0.010000   
2022-11-03 20:42:03,432 - INFO  - Training [3][  380/  391]   Loss 0.162270   Top1 94.245477   Top5 99.960938   BatchTime 0.103445   LR 0.010000   
2022-11-03 20:42:04,725 - INFO  - ==> Top1: 94.250    Top5: 99.962    Loss: 0.162

2022-11-03 20:42:04,726 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:42:07,162 - INFO  - Validation [3][   20/   79]   Loss 0.427533   Top1 88.125000   Top5 99.492188   BatchTime 0.121673   
2022-11-03 20:42:07,858 - INFO  - Validation [3][   40/   79]   Loss 0.420574   Top1 88.125000   Top5 99.492188   BatchTime 0.078248   
2022-11-03 20:42:08,547 - INFO  - Validation [3][   60/   79]   Loss 0.410509   Top1 88.359375   Top5 99.544271   BatchTime 0.063645   
2022-11-03 20:42:09,442 - INFO  - ==> Top1: 88.260    Top5: 99.600    Loss: 0.411

2022-11-03 20:42:09,475 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 88.260   Top5: 99.600] Sparsity : 0.581
2022-11-03 20:42:09,476 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.490   Top5: 99.540] Sparsity : 0.573
2022-11-03 20:42:09,476 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.580   Top5: 99.380] Sparsity : 0.553
2022-11-03 20:42:09,683 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:42:09,684 - INFO  - >>>>>>>> Epoch   4
2022-11-03 20:42:09,685 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:42:13,354 - INFO  - Training [4][   20/  391]   Loss 0.136950   Top1 94.804688   Top5 100.000000   BatchTime 0.183420   LR 0.010000   
2022-11-03 20:42:15,333 - INFO  - Training [4][   40/  391]   Loss 0.145553   Top1 94.531250   Top5 99.980469   BatchTime 0.141196   LR 0.010000   
2022-11-03 20:42:17,310 - INFO  - Training [4][   60/  391]   Loss 0.141464   Top1 94.635417   Top5 99.986979   BatchTime 0.127084   LR 0.010000   
2022-11-03 20:42:19,298 - INFO  - Training [4][   80/  391]   Loss 0.138899   Top1 94.765625   Top5 99.980469   BatchTime 0.120156   LR 0.010000   
2022-11-03 20:42:21,255 - INFO  - Training [4][  100/  391]   Loss 0.142200   Top1 94.656250   Top5 99.976562   BatchTime 0.115699   LR 0.010000   
2022-11-03 20:42:23,236 - INFO  - Training [4][  120/  391]   Loss 0.142015   Top1 94.733073   Top5 99.973958   BatchTime 0.112918   LR 0.010000   
2022-11-03 20:42:25,217 - INFO  - Training [4][  140/  391]   Loss 0.142733   Top1 94.760045   Top5 99.972098   BatchTime 0.110938   LR 0.010000   
2022-11-03 20:42:27,200 - INFO  - Training [4][  160/  391]   Loss 0.140332   Top1 94.907227   Top5 99.970703   BatchTime 0.109465   LR 0.010000   
2022-11-03 20:42:29,189 - INFO  - Training [4][  180/  391]   Loss 0.139920   Top1 94.895833   Top5 99.969618   BatchTime 0.108355   LR 0.010000   
2022-11-03 20:42:31,185 - INFO  - Training [4][  200/  391]   Loss 0.139004   Top1 94.941406   Top5 99.968750   BatchTime 0.107499   LR 0.010000   
2022-11-03 20:42:33,169 - INFO  - Training [4][  220/  391]   Loss 0.138855   Top1 94.946733   Top5 99.971591   BatchTime 0.106744   LR 0.010000   
2022-11-03 20:42:35,162 - INFO  - Training [4][  240/  391]   Loss 0.136963   Top1 95.029297   Top5 99.970703   BatchTime 0.106150   LR 0.010000   
2022-11-03 20:42:37,138 - INFO  - Training [4][  260/  391]   Loss 0.136576   Top1 95.090144   Top5 99.969952   BatchTime 0.105587   LR 0.010000   
2022-11-03 20:42:39,121 - INFO  - Training [4][  280/  391]   Loss 0.137435   Top1 95.058594   Top5 99.960938   BatchTime 0.105127   LR 0.010000   
2022-11-03 20:42:41,099 - INFO  - Training [4][  300/  391]   Loss 0.137054   Top1 95.075521   Top5 99.963542   BatchTime 0.104710   LR 0.010000   
2022-11-03 20:42:43,104 - INFO  - Training [4][  320/  391]   Loss 0.136556   Top1 95.085449   Top5 99.963379   BatchTime 0.104432   LR 0.010000   
2022-11-03 20:42:45,077 - INFO  - Training [4][  340/  391]   Loss 0.136064   Top1 95.103401   Top5 99.963235   BatchTime 0.104092   LR 0.010000   
2022-11-03 20:42:47,016 - INFO  - Training [4][  360/  391]   Loss 0.136149   Top1 95.075955   Top5 99.965278   BatchTime 0.103695   LR 0.010000   
2022-11-03 20:42:48,952 - INFO  - Training [4][  380/  391]   Loss 0.136097   Top1 95.065789   Top5 99.967105   BatchTime 0.103330   LR 0.010000   
2022-11-03 20:42:50,236 - INFO  - ==> Top1: 95.068    Top5: 99.968    Loss: 0.136

2022-11-03 20:42:50,237 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:42:52,676 - INFO  - Validation [4][   20/   79]   Loss 0.381071   Top1 88.593750   Top5 99.531250   BatchTime 0.121831   
2022-11-03 20:42:53,251 - INFO  - Validation [4][   40/   79]   Loss 0.399101   Top1 88.457031   Top5 99.492188   BatchTime 0.075307   
2022-11-03 20:42:53,961 - INFO  - Validation [4][   60/   79]   Loss 0.388080   Top1 88.723958   Top5 99.518229   BatchTime 0.062040   
2022-11-03 20:42:54,846 - INFO  - ==> Top1: 88.690    Top5: 99.570    Loss: 0.386

2022-11-03 20:42:54,880 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.690   Top5: 99.570] Sparsity : 0.587
2022-11-03 20:42:54,881 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 88.260   Top5: 99.600] Sparsity : 0.581
2022-11-03 20:42:54,881 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.490   Top5: 99.540] Sparsity : 0.573
2022-11-03 20:42:55,065 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:42:55,065 - INFO  - >>>>>>>> Epoch   5
2022-11-03 20:42:55,066 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:42:58,733 - INFO  - Training [5][   20/  391]   Loss 0.120600   Top1 95.898438   Top5 100.000000   BatchTime 0.183364   LR 0.010000   
2022-11-03 20:43:00,725 - INFO  - Training [5][   40/  391]   Loss 0.119465   Top1 95.703125   Top5 100.000000   BatchTime 0.141476   LR 0.010000   
2022-11-03 20:43:02,713 - INFO  - Training [5][   60/  391]   Loss 0.115450   Top1 95.768229   Top5 100.000000   BatchTime 0.127454   LR 0.010000   
2022-11-03 20:43:04,704 - INFO  - Training [5][   80/  391]   Loss 0.114381   Top1 95.830078   Top5 99.990234   BatchTime 0.120473   LR 0.010000   
2022-11-03 20:43:06,675 - INFO  - Training [5][  100/  391]   Loss 0.113956   Top1 95.953125   Top5 99.984375   BatchTime 0.116086   LR 0.010000   
2022-11-03 20:43:08,671 - INFO  - Training [5][  120/  391]   Loss 0.116976   Top1 95.898438   Top5 99.980469   BatchTime 0.113368   LR 0.010000   
2022-11-03 20:43:10,672 - INFO  - Training [5][  140/  391]   Loss 0.114201   Top1 95.993304   Top5 99.983259   BatchTime 0.111465   LR 0.010000   
2022-11-03 20:43:12,671 - INFO  - Training [5][  160/  391]   Loss 0.114655   Top1 95.981445   Top5 99.985352   BatchTime 0.110027   LR 0.010000   
2022-11-03 20:43:14,652 - INFO  - Training [5][  180/  391]   Loss 0.114268   Top1 95.933160   Top5 99.986979   BatchTime 0.108808   LR 0.010000   
2022-11-03 20:43:16,654 - INFO  - Training [5][  200/  391]   Loss 0.113606   Top1 95.992188   Top5 99.980469   BatchTime 0.107935   LR 0.010000   
2022-11-03 20:43:18,646 - INFO  - Training [5][  220/  391]   Loss 0.114611   Top1 95.955256   Top5 99.978693   BatchTime 0.107180   LR 0.010000   
2022-11-03 20:43:20,626 - INFO  - Training [5][  240/  391]   Loss 0.113927   Top1 95.973307   Top5 99.980469   BatchTime 0.106498   LR 0.010000   
2022-11-03 20:43:22,620 - INFO  - Training [5][  260/  391]   Loss 0.113028   Top1 96.009615   Top5 99.981971   BatchTime 0.105976   LR 0.010000   
2022-11-03 20:43:24,596 - INFO  - Training [5][  280/  391]   Loss 0.112743   Top1 95.993304   Top5 99.980469   BatchTime 0.105461   LR 0.010000   
2022-11-03 20:43:26,601 - INFO  - Training [5][  300/  391]   Loss 0.112446   Top1 95.994792   Top5 99.981771   BatchTime 0.105114   LR 0.010000   
2022-11-03 20:43:28,588 - INFO  - Training [5][  320/  391]   Loss 0.111841   Top1 96.025391   Top5 99.982910   BatchTime 0.104754   LR 0.010000   
2022-11-03 20:43:30,542 - INFO  - Training [5][  340/  391]   Loss 0.113025   Top1 95.985754   Top5 99.979320   BatchTime 0.104338   LR 0.010000   
2022-11-03 20:43:32,481 - INFO  - Training [5][  360/  391]   Loss 0.112022   Top1 96.032986   Top5 99.978299   BatchTime 0.103929   LR 0.010000   
2022-11-03 20:43:34,412 - INFO  - Training [5][  380/  391]   Loss 0.113326   Top1 95.976562   Top5 99.979441   BatchTime 0.103540   LR 0.010000   
2022-11-03 20:43:35,696 - INFO  - ==> Top1: 95.960    Top5: 99.980    Loss: 0.114

2022-11-03 20:43:35,697 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:43:38,057 - INFO  - Validation [5][   20/   79]   Loss 0.383690   Top1 88.750000   Top5 99.765625   BatchTime 0.117914   
2022-11-03 20:43:38,570 - INFO  - Validation [5][   40/   79]   Loss 0.399325   Top1 88.632812   Top5 99.511719   BatchTime 0.071796   
2022-11-03 20:43:39,274 - INFO  - Validation [5][   60/   79]   Loss 0.395717   Top1 88.880208   Top5 99.531250   BatchTime 0.059597   
2022-11-03 20:43:40,171 - INFO  - ==> Top1: 88.750    Top5: 99.570    Loss: 0.397

2022-11-03 20:43:40,202 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 88.750   Top5: 99.570] Sparsity : 0.592
2022-11-03 20:43:40,203 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.690   Top5: 99.570] Sparsity : 0.587
2022-11-03 20:43:40,203 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 88.260   Top5: 99.600] Sparsity : 0.581
2022-11-03 20:43:40,395 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:43:40,395 - INFO  - >>>>>>>> Epoch   6
2022-11-03 20:43:40,396 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:43:44,020 - INFO  - Training [6][   20/  391]   Loss 0.109599   Top1 96.210938   Top5 99.960938   BatchTime 0.181189   LR 0.010000   
2022-11-03 20:43:46,028 - INFO  - Training [6][   40/  391]   Loss 0.106346   Top1 96.269531   Top5 99.980469   BatchTime 0.140796   LR 0.010000   
2022-11-03 20:43:47,947 - INFO  - Training [6][   60/  391]   Loss 0.103157   Top1 96.341146   Top5 99.986979   BatchTime 0.125846   LR 0.010000   
2022-11-03 20:43:49,979 - INFO  - Training [6][   80/  391]   Loss 0.100952   Top1 96.455078   Top5 99.970703   BatchTime 0.119790   LR 0.010000   
2022-11-03 20:43:51,993 - INFO  - Training [6][  100/  391]   Loss 0.102008   Top1 96.375000   Top5 99.968750   BatchTime 0.115968   LR 0.010000   
2022-11-03 20:43:54,008 - INFO  - Training [6][  120/  391]   Loss 0.101597   Top1 96.399740   Top5 99.973958   BatchTime 0.113432   LR 0.010000   
2022-11-03 20:43:55,996 - INFO  - Training [6][  140/  391]   Loss 0.101968   Top1 96.411830   Top5 99.972098   BatchTime 0.111430   LR 0.010000   
2022-11-03 20:43:57,986 - INFO  - Training [6][  160/  391]   Loss 0.101052   Top1 96.406250   Top5 99.975586   BatchTime 0.109936   LR 0.010000   
2022-11-03 20:43:59,978 - INFO  - Training [6][  180/  391]   Loss 0.101732   Top1 96.371528   Top5 99.973958   BatchTime 0.108785   LR 0.010000   
2022-11-03 20:44:01,944 - INFO  - Training [6][  200/  391]   Loss 0.101653   Top1 96.390625   Top5 99.976562   BatchTime 0.107739   LR 0.010000   
2022-11-03 20:44:03,910 - INFO  - Training [6][  220/  391]   Loss 0.100596   Top1 96.424006   Top5 99.978693   BatchTime 0.106878   LR 0.010000   
2022-11-03 20:44:05,902 - INFO  - Training [6][  240/  391]   Loss 0.099729   Top1 96.425781   Top5 99.980469   BatchTime 0.106271   LR 0.010000   
2022-11-03 20:44:07,879 - INFO  - Training [6][  260/  391]   Loss 0.099865   Top1 96.418269   Top5 99.981971   BatchTime 0.105701   LR 0.010000   
2022-11-03 20:44:09,867 - INFO  - Training [6][  280/  391]   Loss 0.099118   Top1 96.459263   Top5 99.983259   BatchTime 0.105252   LR 0.010000   
2022-11-03 20:44:11,872 - INFO  - Training [6][  300/  391]   Loss 0.099108   Top1 96.442708   Top5 99.984375   BatchTime 0.104919   LR 0.010000   
2022-11-03 20:44:13,838 - INFO  - Training [6][  320/  391]   Loss 0.098990   Top1 96.445312   Top5 99.985352   BatchTime 0.104504   LR 0.010000   
2022-11-03 20:44:15,792 - INFO  - Training [6][  340/  391]   Loss 0.099284   Top1 96.429228   Top5 99.986213   BatchTime 0.104104   LR 0.010000   
2022-11-03 20:44:17,732 - INFO  - Training [6][  360/  391]   Loss 0.099027   Top1 96.430122   Top5 99.986979   BatchTime 0.103710   LR 0.010000   
2022-11-03 20:44:19,670 - INFO  - Training [6][  380/  391]   Loss 0.099010   Top1 96.430921   Top5 99.985609   BatchTime 0.103351   LR 0.010000   
2022-11-03 20:44:20,961 - INFO  - ==> Top1: 96.436    Top5: 99.986    Loss: 0.099

2022-11-03 20:44:20,962 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:44:23,353 - INFO  - Validation [6][   20/   79]   Loss 0.383507   Top1 88.789062   Top5 99.570312   BatchTime 0.119504   
2022-11-03 20:44:23,860 - INFO  - Validation [6][   40/   79]   Loss 0.400020   Top1 89.140625   Top5 99.531250   BatchTime 0.072435   
2022-11-03 20:44:24,480 - INFO  - Validation [6][   60/   79]   Loss 0.394653   Top1 89.322917   Top5 99.570312   BatchTime 0.058621   
2022-11-03 20:44:25,386 - INFO  - ==> Top1: 89.330    Top5: 99.590    Loss: 0.393

2022-11-03 20:44:25,419 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.330   Top5: 99.590] Sparsity : 0.606
2022-11-03 20:44:25,419 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.750   Top5: 99.570] Sparsity : 0.592
2022-11-03 20:44:25,419 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.690   Top5: 99.570] Sparsity : 0.587
2022-11-03 20:44:25,625 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:44:25,626 - INFO  - >>>>>>>> Epoch   7
2022-11-03 20:44:25,627 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:44:29,216 - INFO  - Training [7][   20/  391]   Loss 0.079856   Top1 97.187500   Top5 100.000000   BatchTime 0.179439   LR 0.010000   
2022-11-03 20:44:31,197 - INFO  - Training [7][   40/  391]   Loss 0.086817   Top1 96.894531   Top5 100.000000   BatchTime 0.139244   LR 0.010000   
2022-11-03 20:44:33,190 - INFO  - Training [7][   60/  391]   Loss 0.088994   Top1 96.848958   Top5 100.000000   BatchTime 0.126045   LR 0.010000   
2022-11-03 20:44:35,284 - INFO  - Training [7][   80/  391]   Loss 0.087271   Top1 96.904297   Top5 100.000000   BatchTime 0.120711   LR 0.010000   
2022-11-03 20:44:37,280 - INFO  - Training [7][  100/  391]   Loss 0.087127   Top1 96.898438   Top5 100.000000   BatchTime 0.116524   LR 0.010000   
2022-11-03 20:44:39,276 - INFO  - Training [7][  120/  391]   Loss 0.087545   Top1 96.927083   Top5 99.993490   BatchTime 0.113739   LR 0.010000   
2022-11-03 20:44:41,281 - INFO  - Training [7][  140/  391]   Loss 0.089137   Top1 96.886161   Top5 99.994420   BatchTime 0.111812   LR 0.010000   
2022-11-03 20:44:43,273 - INFO  - Training [7][  160/  391]   Loss 0.088432   Top1 96.865234   Top5 99.995117   BatchTime 0.110285   LR 0.010000   
2022-11-03 20:44:45,284 - INFO  - Training [7][  180/  391]   Loss 0.089088   Top1 96.857639   Top5 99.995660   BatchTime 0.109202   LR 0.010000   
2022-11-03 20:44:47,284 - INFO  - Training [7][  200/  391]   Loss 0.090723   Top1 96.820312   Top5 99.992188   BatchTime 0.108282   LR 0.010000   
2022-11-03 20:44:49,292 - INFO  - Training [7][  220/  391]   Loss 0.091658   Top1 96.775568   Top5 99.992898   BatchTime 0.107567   LR 0.010000   
2022-11-03 20:44:51,279 - INFO  - Training [7][  240/  391]   Loss 0.092157   Top1 96.767578   Top5 99.993490   BatchTime 0.106880   LR 0.010000   
2022-11-03 20:44:53,277 - INFO  - Training [7][  260/  391]   Loss 0.092745   Top1 96.775841   Top5 99.990986   BatchTime 0.106343   LR 0.010000   
2022-11-03 20:44:55,266 - INFO  - Training [7][  280/  391]   Loss 0.094118   Top1 96.715960   Top5 99.991629   BatchTime 0.105850   LR 0.010000   
2022-11-03 20:44:57,253 - INFO  - Training [7][  300/  391]   Loss 0.094635   Top1 96.682292   Top5 99.992188   BatchTime 0.105416   LR 0.010000   
2022-11-03 20:44:59,236 - INFO  - Training [7][  320/  391]   Loss 0.094553   Top1 96.691895   Top5 99.990234   BatchTime 0.105025   LR 0.010000   
2022-11-03 20:45:01,211 - INFO  - Training [7][  340/  391]   Loss 0.094831   Top1 96.700368   Top5 99.988511   BatchTime 0.104655   LR 0.010000   
2022-11-03 20:45:03,154 - INFO  - Training [7][  360/  391]   Loss 0.094062   Top1 96.723090   Top5 99.989149   BatchTime 0.104239   LR 0.010000   
2022-11-03 20:45:05,085 - INFO  - Training [7][  380/  391]   Loss 0.093911   Top1 96.731086   Top5 99.989720   BatchTime 0.103834   LR 0.010000   
2022-11-03 20:45:06,384 - INFO  - ==> Top1: 96.712    Top5: 99.990    Loss: 0.094

2022-11-03 20:45:06,385 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:45:08,814 - INFO  - Validation [7][   20/   79]   Loss 0.388258   Top1 89.531250   Top5 99.453125   BatchTime 0.121397   
2022-11-03 20:45:09,336 - INFO  - Validation [7][   40/   79]   Loss 0.394273   Top1 89.453125   Top5 99.375000   BatchTime 0.073738   
2022-11-03 20:45:10,040 - INFO  - Validation [7][   60/   79]   Loss 0.394130   Top1 89.531250   Top5 99.453125   BatchTime 0.060899   
2022-11-03 20:45:10,935 - INFO  - ==> Top1: 89.470    Top5: 99.540    Loss: 0.392

2022-11-03 20:45:10,968 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.470   Top5: 99.540] Sparsity : 0.618
2022-11-03 20:45:10,968 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 89.330   Top5: 99.590] Sparsity : 0.606
2022-11-03 20:45:10,968 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.750   Top5: 99.570] Sparsity : 0.592
2022-11-03 20:45:11,145 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:45:11,145 - INFO  - >>>>>>>> Epoch   8
2022-11-03 20:45:11,146 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:45:14,688 - INFO  - Training [8][   20/  391]   Loss 0.081521   Top1 97.343750   Top5 100.000000   BatchTime 0.177062   LR 0.010000   
2022-11-03 20:45:16,682 - INFO  - Training [8][   40/  391]   Loss 0.081875   Top1 97.285156   Top5 100.000000   BatchTime 0.138389   LR 0.010000   
2022-11-03 20:45:18,681 - INFO  - Training [8][   60/  391]   Loss 0.083566   Top1 97.187500   Top5 99.973958   BatchTime 0.125575   LR 0.010000   
2022-11-03 20:45:20,670 - INFO  - Training [8][   80/  391]   Loss 0.082940   Top1 97.167969   Top5 99.980469   BatchTime 0.119041   LR 0.010000   
2022-11-03 20:45:22,673 - INFO  - Training [8][  100/  391]   Loss 0.083013   Top1 97.164062   Top5 99.984375   BatchTime 0.115261   LR 0.010000   
2022-11-03 20:45:24,661 - INFO  - Training [8][  120/  391]   Loss 0.083931   Top1 97.102865   Top5 99.986979   BatchTime 0.112622   LR 0.010000   
2022-11-03 20:45:26,635 - INFO  - Training [8][  140/  391]   Loss 0.084754   Top1 97.087054   Top5 99.983259   BatchTime 0.110628   LR 0.010000   
2022-11-03 20:45:28,634 - INFO  - Training [8][  160/  391]   Loss 0.085469   Top1 97.036133   Top5 99.985352   BatchTime 0.109295   LR 0.010000   
2022-11-03 20:45:30,643 - INFO  - Training [8][  180/  391]   Loss 0.084975   Top1 97.026910   Top5 99.986979   BatchTime 0.108311   LR 0.010000   
2022-11-03 20:45:32,632 - INFO  - Training [8][  200/  391]   Loss 0.085258   Top1 97.003906   Top5 99.988281   BatchTime 0.107425   LR 0.010000   
2022-11-03 20:45:34,613 - INFO  - Training [8][  220/  391]   Loss 0.085127   Top1 97.002841   Top5 99.989347   BatchTime 0.106664   LR 0.010000   
2022-11-03 20:45:36,621 - INFO  - Training [8][  240/  391]   Loss 0.085286   Top1 96.998698   Top5 99.990234   BatchTime 0.106140   LR 0.010000   
2022-11-03 20:45:38,618 - INFO  - Training [8][  260/  391]   Loss 0.085223   Top1 97.034255   Top5 99.987981   BatchTime 0.105658   LR 0.010000   
2022-11-03 20:45:40,615 - INFO  - Training [8][  280/  391]   Loss 0.085577   Top1 97.022879   Top5 99.988839   BatchTime 0.105241   LR 0.010000   
2022-11-03 20:45:42,610 - INFO  - Training [8][  300/  391]   Loss 0.085705   Top1 97.028646   Top5 99.989583   BatchTime 0.104875   LR 0.010000   
2022-11-03 20:45:44,611 - INFO  - Training [8][  320/  391]   Loss 0.087213   Top1 96.984863   Top5 99.987793   BatchTime 0.104574   LR 0.010000   
2022-11-03 20:45:46,598 - INFO  - Training [8][  340/  391]   Loss 0.086432   Top1 97.003676   Top5 99.988511   BatchTime 0.104267   LR 0.010000   
2022-11-03 20:45:48,543 - INFO  - Training [8][  360/  391]   Loss 0.087440   Top1 96.948785   Top5 99.989149   BatchTime 0.103876   LR 0.010000   
2022-11-03 20:45:50,484 - INFO  - Training [8][  380/  391]   Loss 0.087393   Top1 96.961349   Top5 99.989720   BatchTime 0.103516   LR 0.010000   
2022-11-03 20:45:51,788 - INFO  - ==> Top1: 96.968    Top5: 99.990    Loss: 0.087

2022-11-03 20:45:51,789 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:45:54,176 - INFO  - Validation [8][   20/   79]   Loss 0.373863   Top1 90.078125   Top5 99.570312   BatchTime 0.119255   
2022-11-03 20:45:54,695 - INFO  - Validation [8][   40/   79]   Loss 0.401041   Top1 89.511719   Top5 99.453125   BatchTime 0.072612   
2022-11-03 20:45:55,300 - INFO  - Validation [8][   60/   79]   Loss 0.390465   Top1 89.635417   Top5 99.505208   BatchTime 0.058489   
2022-11-03 20:45:56,224 - INFO  - ==> Top1: 89.600    Top5: 99.560    Loss: 0.388

2022-11-03 20:45:56,256 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.600   Top5: 99.560] Sparsity : 0.629
2022-11-03 20:45:56,257 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.470   Top5: 99.540] Sparsity : 0.618
2022-11-03 20:45:56,257 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 89.330   Top5: 99.590] Sparsity : 0.606
2022-11-03 20:45:56,446 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:45:56,446 - INFO  - >>>>>>>> Epoch   9
2022-11-03 20:45:56,447 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:45:59,757 - INFO  - Training [9][   20/  391]   Loss 0.073297   Top1 97.226562   Top5 100.000000   BatchTime 0.165492   LR 0.010000   
2022-11-03 20:46:01,864 - INFO  - Training [9][   40/  391]   Loss 0.078217   Top1 97.265625   Top5 100.000000   BatchTime 0.135439   LR 0.010000   
2022-11-03 20:46:03,878 - INFO  - Training [9][   60/  391]   Loss 0.075167   Top1 97.317708   Top5 100.000000   BatchTime 0.123842   LR 0.010000   
2022-11-03 20:46:05,877 - INFO  - Training [9][   80/  391]   Loss 0.076060   Top1 97.294922   Top5 99.990234   BatchTime 0.117875   LR 0.010000   
2022-11-03 20:46:07,947 - INFO  - Training [9][  100/  391]   Loss 0.075794   Top1 97.281250   Top5 99.984375   BatchTime 0.115001   LR 0.010000   
2022-11-03 20:46:09,946 - INFO  - Training [9][  120/  391]   Loss 0.077671   Top1 97.167969   Top5 99.980469   BatchTime 0.112487   LR 0.010000   
2022-11-03 20:46:11,925 - INFO  - Training [9][  140/  391]   Loss 0.076921   Top1 97.248884   Top5 99.983259   BatchTime 0.110558   LR 0.010000   
2022-11-03 20:46:13,941 - INFO  - Training [9][  160/  391]   Loss 0.075887   Top1 97.255859   Top5 99.985352   BatchTime 0.109333   LR 0.010000   
2022-11-03 20:46:15,935 - INFO  - Training [9][  180/  391]   Loss 0.076067   Top1 97.248264   Top5 99.986979   BatchTime 0.108263   LR 0.010000   
2022-11-03 20:46:17,948 - INFO  - Training [9][  200/  391]   Loss 0.075309   Top1 97.265625   Top5 99.988281   BatchTime 0.107505   LR 0.010000   
2022-11-03 20:46:19,946 - INFO  - Training [9][  220/  391]   Loss 0.075562   Top1 97.258523   Top5 99.989347   BatchTime 0.106814   LR 0.010000   
2022-11-03 20:46:21,944 - INFO  - Training [9][  240/  391]   Loss 0.074863   Top1 97.298177   Top5 99.990234   BatchTime 0.106234   LR 0.010000   
2022-11-03 20:46:23,942 - INFO  - Training [9][  260/  391]   Loss 0.076089   Top1 97.265625   Top5 99.990986   BatchTime 0.105746   LR 0.010000   
2022-11-03 20:46:25,925 - INFO  - Training [9][  280/  391]   Loss 0.076453   Top1 97.262835   Top5 99.991629   BatchTime 0.105277   LR 0.010000   
2022-11-03 20:46:27,939 - INFO  - Training [9][  300/  391]   Loss 0.075801   Top1 97.296875   Top5 99.992188   BatchTime 0.104972   LR 0.010000   
2022-11-03 20:46:29,921 - INFO  - Training [9][  320/  391]   Loss 0.077295   Top1 97.258301   Top5 99.992676   BatchTime 0.104606   LR 0.010000   
2022-11-03 20:46:31,879 - INFO  - Training [9][  340/  391]   Loss 0.077810   Top1 97.228860   Top5 99.993107   BatchTime 0.104210   LR 0.010000   
2022-11-03 20:46:33,831 - INFO  - Training [9][  360/  391]   Loss 0.078210   Top1 97.220052   Top5 99.993490   BatchTime 0.103844   LR 0.010000   
2022-11-03 20:46:35,761 - INFO  - Training [9][  380/  391]   Loss 0.078733   Top1 97.177220   Top5 99.991776   BatchTime 0.103455   LR 0.010000   
2022-11-03 20:46:37,067 - INFO  - ==> Top1: 97.160    Top5: 99.992    Loss: 0.079

2022-11-03 20:46:37,068 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:46:39,455 - INFO  - Validation [9][   20/   79]   Loss 0.358979   Top1 89.960938   Top5 99.765625   BatchTime 0.119315   
2022-11-03 20:46:39,970 - INFO  - Validation [9][   40/   79]   Loss 0.381805   Top1 89.687500   Top5 99.531250   BatchTime 0.072535   
2022-11-03 20:46:40,563 - INFO  - Validation [9][   60/   79]   Loss 0.386671   Top1 89.648438   Top5 99.583333   BatchTime 0.058228   
2022-11-03 20:46:41,466 - INFO  - ==> Top1: 89.640    Top5: 99.620    Loss: 0.384

2022-11-03 20:46:41,498 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.640   Top5: 99.620] Sparsity : 0.672
2022-11-03 20:46:41,499 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.600   Top5: 99.560] Sparsity : 0.629
2022-11-03 20:46:41,499 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.470   Top5: 99.540] Sparsity : 0.618
2022-11-03 20:46:41,691 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:46:41,692 - INFO  - >>>>>>>> Epoch  10
2022-11-03 20:46:41,693 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:46:45,139 - INFO  - Training [10][   20/  391]   Loss 0.082076   Top1 96.992188   Top5 100.000000   BatchTime 0.172301   LR 0.010000   
2022-11-03 20:46:47,218 - INFO  - Training [10][   40/  391]   Loss 0.074084   Top1 97.519531   Top5 100.000000   BatchTime 0.138107   LR 0.010000   
2022-11-03 20:46:49,221 - INFO  - Training [10][   60/  391]   Loss 0.074461   Top1 97.473958   Top5 100.000000   BatchTime 0.125455   LR 0.010000   
2022-11-03 20:46:51,215 - INFO  - Training [10][   80/  391]   Loss 0.071641   Top1 97.578125   Top5 100.000000   BatchTime 0.119024   LR 0.010000   
2022-11-03 20:46:53,215 - INFO  - Training [10][  100/  391]   Loss 0.072943   Top1 97.531250   Top5 100.000000   BatchTime 0.115216   LR 0.010000   
2022-11-03 20:46:55,201 - INFO  - Training [10][  120/  391]   Loss 0.073592   Top1 97.571615   Top5 100.000000   BatchTime 0.112565   LR 0.010000   
2022-11-03 20:46:57,197 - INFO  - Training [10][  140/  391]   Loss 0.076191   Top1 97.460938   Top5 100.000000   BatchTime 0.110739   LR 0.010000   
2022-11-03 20:46:59,208 - INFO  - Training [10][  160/  391]   Loss 0.076333   Top1 97.421875   Top5 100.000000   BatchTime 0.109462   LR 0.010000   
2022-11-03 20:47:01,187 - INFO  - Training [10][  180/  391]   Loss 0.075761   Top1 97.434896   Top5 99.995660   BatchTime 0.108297   LR 0.010000   
2022-11-03 20:47:03,167 - INFO  - Training [10][  200/  391]   Loss 0.076579   Top1 97.378906   Top5 99.996094   BatchTime 0.107366   LR 0.010000   
2022-11-03 20:47:05,150 - INFO  - Training [10][  220/  391]   Loss 0.079077   Top1 97.276278   Top5 99.996449   BatchTime 0.106621   LR 0.010000   
2022-11-03 20:47:07,127 - INFO  - Training [10][  240/  391]   Loss 0.078496   Top1 97.294922   Top5 99.996745   BatchTime 0.105971   LR 0.010000   
2022-11-03 20:47:09,144 - INFO  - Training [10][  260/  391]   Loss 0.078853   Top1 97.277644   Top5 99.996995   BatchTime 0.105577   LR 0.010000   
2022-11-03 20:47:11,137 - INFO  - Training [10][  280/  391]   Loss 0.079847   Top1 97.234933   Top5 99.997210   BatchTime 0.105152   LR 0.010000   
2022-11-03 20:47:13,146 - INFO  - Training [10][  300/  391]   Loss 0.080912   Top1 97.203125   Top5 99.997396   BatchTime 0.104841   LR 0.010000   
2022-11-03 20:47:15,137 - INFO  - Training [10][  320/  391]   Loss 0.081442   Top1 97.167969   Top5 99.995117   BatchTime 0.104511   LR 0.010000   
2022-11-03 20:47:17,109 - INFO  - Training [10][  340/  391]   Loss 0.082339   Top1 97.125460   Top5 99.995404   BatchTime 0.104161   LR 0.010000   
2022-11-03 20:47:19,064 - INFO  - Training [10][  360/  391]   Loss 0.082908   Top1 97.092014   Top5 99.995660   BatchTime 0.103806   LR 0.010000   
2022-11-03 20:47:21,011 - INFO  - Training [10][  380/  391]   Loss 0.083601   Top1 97.068257   Top5 99.995888   BatchTime 0.103465   LR 0.010000   
2022-11-03 20:47:22,303 - INFO  - ==> Top1: 97.022    Top5: 99.996    Loss: 0.085

2022-11-03 20:47:22,304 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:47:24,653 - INFO  - Validation [10][   20/   79]   Loss 0.380946   Top1 89.570312   Top5 99.726562   BatchTime 0.117401   
2022-11-03 20:47:25,165 - INFO  - Validation [10][   40/   79]   Loss 0.394408   Top1 89.453125   Top5 99.492188   BatchTime 0.071505   
2022-11-03 20:47:25,699 - INFO  - Validation [10][   60/   79]   Loss 0.390821   Top1 89.661458   Top5 99.505208   BatchTime 0.056568   
2022-11-03 20:47:26,689 - INFO  - ==> Top1: 89.740    Top5: 99.550    Loss: 0.387

2022-11-03 20:47:26,722 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.740   Top5: 99.550] Sparsity : 0.688
2022-11-03 20:47:26,723 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.640   Top5: 99.620] Sparsity : 0.672
2022-11-03 20:47:26,723 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.600   Top5: 99.560] Sparsity : 0.629
2022-11-03 20:47:26,913 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:47:26,913 - INFO  - >>>>>>>> Epoch  11
2022-11-03 20:47:26,914 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:47:30,305 - INFO  - Training [11][   20/  391]   Loss 0.081434   Top1 97.031250   Top5 100.000000   BatchTime 0.169518   LR 0.010000   
2022-11-03 20:47:32,395 - INFO  - Training [11][   40/  391]   Loss 0.077464   Top1 97.207031   Top5 100.000000   BatchTime 0.137005   LR 0.010000   
2022-11-03 20:47:34,403 - INFO  - Training [11][   60/  391]   Loss 0.077390   Top1 97.135417   Top5 100.000000   BatchTime 0.124815   LR 0.010000   
2022-11-03 20:47:36,411 - INFO  - Training [11][   80/  391]   Loss 0.081064   Top1 96.962891   Top5 100.000000   BatchTime 0.118701   LR 0.010000   
2022-11-03 20:47:38,395 - INFO  - Training [11][  100/  391]   Loss 0.080229   Top1 96.968750   Top5 100.000000   BatchTime 0.114801   LR 0.010000   
2022-11-03 20:47:40,406 - INFO  - Training [11][  120/  391]   Loss 0.081080   Top1 96.933594   Top5 100.000000   BatchTime 0.112429   LR 0.010000   
2022-11-03 20:47:42,413 - INFO  - Training [11][  140/  391]   Loss 0.081521   Top1 96.930804   Top5 100.000000   BatchTime 0.110701   LR 0.010000   
2022-11-03 20:47:44,547 - INFO  - Training [11][  160/  391]   Loss 0.082504   Top1 96.889648   Top5 100.000000   BatchTime 0.110201   LR 0.010000   
2022-11-03 20:47:46,540 - INFO  - Training [11][  180/  391]   Loss 0.082051   Top1 96.927083   Top5 99.995660   BatchTime 0.109030   LR 0.010000   
2022-11-03 20:47:48,568 - INFO  - Training [11][  200/  391]   Loss 0.081702   Top1 96.933594   Top5 99.992188   BatchTime 0.108264   LR 0.010000   
2022-11-03 20:47:50,569 - INFO  - Training [11][  220/  391]   Loss 0.081722   Top1 96.960227   Top5 99.992898   BatchTime 0.107517   LR 0.010000   
2022-11-03 20:47:52,574 - INFO  - Training [11][  240/  391]   Loss 0.082622   Top1 96.959635   Top5 99.993490   BatchTime 0.106912   LR 0.010000   
2022-11-03 20:47:54,572 - INFO  - Training [11][  260/  391]   Loss 0.082539   Top1 96.995192   Top5 99.993990   BatchTime 0.106374   LR 0.010000   
2022-11-03 20:47:56,595 - INFO  - Training [11][  280/  391]   Loss 0.082474   Top1 96.992188   Top5 99.994420   BatchTime 0.105998   LR 0.010000   
2022-11-03 20:47:58,592 - INFO  - Training [11][  300/  391]   Loss 0.081945   Top1 97.036458   Top5 99.994792   BatchTime 0.105588   LR 0.010000   
2022-11-03 20:48:00,595 - INFO  - Training [11][  320/  391]   Loss 0.081817   Top1 97.045898   Top5 99.995117   BatchTime 0.105249   LR 0.010000   
2022-11-03 20:48:02,595 - INFO  - Training [11][  340/  391]   Loss 0.081770   Top1 97.068015   Top5 99.995404   BatchTime 0.104940   LR 0.010000   
2022-11-03 20:48:04,550 - INFO  - Training [11][  360/  391]   Loss 0.082391   Top1 97.042101   Top5 99.993490   BatchTime 0.104540   LR 0.010000   
2022-11-03 20:48:06,491 - INFO  - Training [11][  380/  391]   Loss 0.083289   Top1 97.023026   Top5 99.993832   BatchTime 0.104145   LR 0.010000   
2022-11-03 20:48:07,784 - INFO  - ==> Top1: 97.026    Top5: 99.992    Loss: 0.083

2022-11-03 20:48:07,785 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:48:10,197 - INFO  - Validation [11][   20/   79]   Loss 0.389760   Top1 89.882812   Top5 99.609375   BatchTime 0.120544   
2022-11-03 20:48:10,708 - INFO  - Validation [11][   40/   79]   Loss 0.394084   Top1 89.863281   Top5 99.472656   BatchTime 0.073049   
2022-11-03 20:48:11,278 - INFO  - Validation [11][   60/   79]   Loss 0.387710   Top1 90.000000   Top5 99.505208   BatchTime 0.058199   
2022-11-03 20:48:12,179 - INFO  - ==> Top1: 89.760    Top5: 99.540    Loss: 0.389

2022-11-03 20:48:12,209 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.760   Top5: 99.540] Sparsity : 0.692
2022-11-03 20:48:12,209 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.740   Top5: 99.550] Sparsity : 0.688
2022-11-03 20:48:12,210 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.640   Top5: 99.620] Sparsity : 0.672
2022-11-03 20:48:12,392 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:48:12,393 - INFO  - >>>>>>>> Epoch  12
2022-11-03 20:48:12,393 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:48:15,726 - INFO  - Training [12][   20/  391]   Loss 0.071940   Top1 97.500000   Top5 100.000000   BatchTime 0.166598   LR 0.010000   
2022-11-03 20:48:17,796 - INFO  - Training [12][   40/  391]   Loss 0.074878   Top1 97.480469   Top5 100.000000   BatchTime 0.135071   LR 0.010000   
2022-11-03 20:48:19,813 - INFO  - Training [12][   60/  391]   Loss 0.073861   Top1 97.500000   Top5 100.000000   BatchTime 0.123648   LR 0.010000   
2022-11-03 20:48:21,842 - INFO  - Training [12][   80/  391]   Loss 0.072009   Top1 97.558594   Top5 100.000000   BatchTime 0.118107   LR 0.010000   
2022-11-03 20:48:23,874 - INFO  - Training [12][  100/  391]   Loss 0.071592   Top1 97.570312   Top5 100.000000   BatchTime 0.114800   LR 0.010000   
2022-11-03 20:48:25,897 - INFO  - Training [12][  120/  391]   Loss 0.074040   Top1 97.454427   Top5 100.000000   BatchTime 0.112523   LR 0.010000   
2022-11-03 20:48:27,911 - INFO  - Training [12][  140/  391]   Loss 0.074869   Top1 97.416295   Top5 99.994420   BatchTime 0.110840   LR 0.010000   
2022-11-03 20:48:29,923 - INFO  - Training [12][  160/  391]   Loss 0.074117   Top1 97.392578   Top5 99.995117   BatchTime 0.109556   LR 0.010000   
2022-11-03 20:48:31,921 - INFO  - Training [12][  180/  391]   Loss 0.074194   Top1 97.374132   Top5 99.995660   BatchTime 0.108483   LR 0.010000   
2022-11-03 20:48:33,937 - INFO  - Training [12][  200/  391]   Loss 0.074632   Top1 97.367188   Top5 99.996094   BatchTime 0.107713   LR 0.010000   
2022-11-03 20:48:35,945 - INFO  - Training [12][  220/  391]   Loss 0.075594   Top1 97.301136   Top5 99.996449   BatchTime 0.107048   LR 0.010000   
2022-11-03 20:48:37,942 - INFO  - Training [12][  240/  391]   Loss 0.075449   Top1 97.317708   Top5 99.996745   BatchTime 0.106449   LR 0.010000   
2022-11-03 20:48:39,983 - INFO  - Training [12][  260/  391]   Loss 0.075703   Top1 97.301683   Top5 99.996995   BatchTime 0.106111   LR 0.010000   
2022-11-03 20:48:41,962 - INFO  - Training [12][  280/  391]   Loss 0.077219   Top1 97.254464   Top5 99.991629   BatchTime 0.105600   LR 0.010000   
2022-11-03 20:48:43,944 - INFO  - Training [12][  300/  391]   Loss 0.077379   Top1 97.257812   Top5 99.992188   BatchTime 0.105166   LR 0.010000   
2022-11-03 20:48:45,927 - INFO  - Training [12][  320/  391]   Loss 0.077549   Top1 97.260742   Top5 99.992676   BatchTime 0.104788   LR 0.010000   
2022-11-03 20:48:47,898 - INFO  - Training [12][  340/  391]   Loss 0.077700   Top1 97.263327   Top5 99.993107   BatchTime 0.104423   LR 0.010000   
2022-11-03 20:48:49,850 - INFO  - Training [12][  360/  391]   Loss 0.078109   Top1 97.263455   Top5 99.991319   BatchTime 0.104045   LR 0.010000   
2022-11-03 20:48:51,794 - INFO  - Training [12][  380/  391]   Loss 0.078297   Top1 97.253289   Top5 99.989720   BatchTime 0.103683   LR 0.010000   
2022-11-03 20:48:53,099 - INFO  - ==> Top1: 97.252    Top5: 99.988    Loss: 0.078

2022-11-03 20:48:53,100 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:48:55,559 - INFO  - Validation [12][   20/   79]   Loss 0.392813   Top1 89.648438   Top5 99.531250   BatchTime 0.122876   
2022-11-03 20:48:56,074 - INFO  - Validation [12][   40/   79]   Loss 0.404980   Top1 89.414062   Top5 99.414062   BatchTime 0.074302   
2022-11-03 20:48:56,587 - INFO  - Validation [12][   60/   79]   Loss 0.401910   Top1 89.752604   Top5 99.414062   BatchTime 0.058090   
2022-11-03 20:48:57,520 - INFO  - ==> Top1: 89.720    Top5: 99.460    Loss: 0.396

2022-11-03 20:48:57,555 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.760   Top5: 99.540] Sparsity : 0.692
2022-11-03 20:48:57,556 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.740   Top5: 99.550] Sparsity : 0.688
2022-11-03 20:48:57,556 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.720   Top5: 99.460] Sparsity : 0.695
2022-11-03 20:48:57,657 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:48:57,658 - INFO  - >>>>>>>> Epoch  13
2022-11-03 20:48:57,659 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:49:00,996 - INFO  - Training [13][   20/  391]   Loss 0.062299   Top1 97.968750   Top5 100.000000   BatchTime 0.166882   LR 0.010000   
2022-11-03 20:49:03,027 - INFO  - Training [13][   40/  391]   Loss 0.064047   Top1 97.949219   Top5 100.000000   BatchTime 0.134196   LR 0.010000   
2022-11-03 20:49:05,041 - INFO  - Training [13][   60/  391]   Loss 0.064759   Top1 97.877604   Top5 99.986979   BatchTime 0.123031   LR 0.010000   
2022-11-03 20:49:07,052 - INFO  - Training [13][   80/  391]   Loss 0.069342   Top1 97.705078   Top5 99.990234   BatchTime 0.117415   LR 0.010000   
2022-11-03 20:49:09,066 - INFO  - Training [13][  100/  391]   Loss 0.069115   Top1 97.703125   Top5 99.992188   BatchTime 0.114067   LR 0.010000   
2022-11-03 20:49:11,062 - INFO  - Training [13][  120/  391]   Loss 0.070763   Top1 97.610677   Top5 99.993490   BatchTime 0.111693   LR 0.010000   
2022-11-03 20:49:13,046 - INFO  - Training [13][  140/  391]   Loss 0.070705   Top1 97.594866   Top5 99.994420   BatchTime 0.109906   LR 0.010000   
2022-11-03 20:49:15,040 - INFO  - Training [13][  160/  391]   Loss 0.072608   Top1 97.500000   Top5 99.995117   BatchTime 0.108633   LR 0.010000   
2022-11-03 20:49:17,024 - INFO  - Training [13][  180/  391]   Loss 0.073061   Top1 97.465278   Top5 99.995660   BatchTime 0.107582   LR 0.010000   
2022-11-03 20:49:18,999 - INFO  - Training [13][  200/  391]   Loss 0.072670   Top1 97.496094   Top5 99.996094   BatchTime 0.106700   LR 0.010000   
2022-11-03 20:49:21,086 - INFO  - Training [13][  220/  391]   Loss 0.072290   Top1 97.485795   Top5 99.996449   BatchTime 0.106484   LR 0.010000   
2022-11-03 20:49:23,078 - INFO  - Training [13][  240/  391]   Loss 0.071792   Top1 97.503255   Top5 99.993490   BatchTime 0.105912   LR 0.010000   
2022-11-03 20:49:25,082 - INFO  - Training [13][  260/  391]   Loss 0.071689   Top1 97.493990   Top5 99.993990   BatchTime 0.105471   LR 0.010000   
2022-11-03 20:49:27,071 - INFO  - Training [13][  280/  391]   Loss 0.072301   Top1 97.466518   Top5 99.994420   BatchTime 0.105041   LR 0.010000   
2022-11-03 20:49:29,070 - INFO  - Training [13][  300/  391]   Loss 0.073306   Top1 97.450521   Top5 99.994792   BatchTime 0.104701   LR 0.010000   
2022-11-03 20:49:31,064 - INFO  - Training [13][  320/  391]   Loss 0.073924   Top1 97.429199   Top5 99.995117   BatchTime 0.104391   LR 0.010000   
2022-11-03 20:49:33,037 - INFO  - Training [13][  340/  391]   Loss 0.073997   Top1 97.410386   Top5 99.993107   BatchTime 0.104052   LR 0.010000   
2022-11-03 20:49:34,996 - INFO  - Training [13][  360/  391]   Loss 0.074641   Top1 97.398003   Top5 99.991319   BatchTime 0.103712   LR 0.010000   
2022-11-03 20:49:36,945 - INFO  - Training [13][  380/  391]   Loss 0.074748   Top1 97.409539   Top5 99.991776   BatchTime 0.103382   LR 0.010000   
2022-11-03 20:49:38,267 - INFO  - ==> Top1: 97.408    Top5: 99.992    Loss: 0.075

2022-11-03 20:49:38,268 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:49:40,666 - INFO  - Validation [13][   20/   79]   Loss 0.418372   Top1 89.453125   Top5 99.492188   BatchTime 0.119842   
2022-11-03 20:49:41,189 - INFO  - Validation [13][   40/   79]   Loss 0.420413   Top1 89.531250   Top5 99.394531   BatchTime 0.073004   
2022-11-03 20:49:41,703 - INFO  - Validation [13][   60/   79]   Loss 0.412714   Top1 89.791667   Top5 99.505208   BatchTime 0.057238   
2022-11-03 20:49:42,626 - INFO  - ==> Top1: 89.750    Top5: 99.570    Loss: 0.407

2022-11-03 20:49:42,657 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.760   Top5: 99.540] Sparsity : 0.692
2022-11-03 20:49:42,658 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 89.750   Top5: 99.570] Sparsity : 0.699
2022-11-03 20:49:42,658 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.740   Top5: 99.550] Sparsity : 0.688
2022-11-03 20:49:42,745 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:49:42,745 - INFO  - >>>>>>>> Epoch  14
2022-11-03 20:49:42,746 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:49:46,171 - INFO  - Training [14][   20/  391]   Loss 0.062635   Top1 97.890625   Top5 100.000000   BatchTime 0.171268   LR 0.010000   
2022-11-03 20:49:48,154 - INFO  - Training [14][   40/  391]   Loss 0.059824   Top1 97.988281   Top5 99.980469   BatchTime 0.135204   LR 0.010000   
2022-11-03 20:49:50,172 - INFO  - Training [14][   60/  391]   Loss 0.063433   Top1 97.838542   Top5 99.986979   BatchTime 0.123764   LR 0.010000   
2022-11-03 20:49:52,188 - INFO  - Training [14][   80/  391]   Loss 0.063817   Top1 97.792969   Top5 99.990234   BatchTime 0.118021   LR 0.010000   
2022-11-03 20:49:54,187 - INFO  - Training [14][  100/  391]   Loss 0.066075   Top1 97.664062   Top5 99.992188   BatchTime 0.114412   LR 0.010000   
2022-11-03 20:49:56,201 - INFO  - Training [14][  120/  391]   Loss 0.064968   Top1 97.688802   Top5 99.993490   BatchTime 0.112120   LR 0.010000   
2022-11-03 20:49:58,219 - INFO  - Training [14][  140/  391]   Loss 0.065867   Top1 97.661830   Top5 99.994420   BatchTime 0.110517   LR 0.010000   
2022-11-03 20:50:00,214 - INFO  - Training [14][  160/  391]   Loss 0.066472   Top1 97.631836   Top5 99.990234   BatchTime 0.109174   LR 0.010000   
2022-11-03 20:50:02,227 - INFO  - Training [14][  180/  391]   Loss 0.066308   Top1 97.660590   Top5 99.991319   BatchTime 0.108228   LR 0.010000   
2022-11-03 20:50:04,224 - INFO  - Training [14][  200/  391]   Loss 0.066388   Top1 97.664062   Top5 99.992188   BatchTime 0.107387   LR 0.010000   
2022-11-03 20:50:06,204 - INFO  - Training [14][  220/  391]   Loss 0.066514   Top1 97.666903   Top5 99.992898   BatchTime 0.106624   LR 0.010000   
2022-11-03 20:50:08,199 - INFO  - Training [14][  240/  391]   Loss 0.066106   Top1 97.682292   Top5 99.993490   BatchTime 0.106051   LR 0.010000   
2022-11-03 20:50:10,201 - INFO  - Training [14][  260/  391]   Loss 0.066491   Top1 97.662260   Top5 99.993990   BatchTime 0.105594   LR 0.010000   
2022-11-03 20:50:12,200 - INFO  - Training [14][  280/  391]   Loss 0.066426   Top1 97.672991   Top5 99.994420   BatchTime 0.105190   LR 0.010000   
2022-11-03 20:50:14,210 - INFO  - Training [14][  300/  391]   Loss 0.066623   Top1 97.677083   Top5 99.994792   BatchTime 0.104877   LR 0.010000   
2022-11-03 20:50:16,190 - INFO  - Training [14][  320/  391]   Loss 0.067195   Top1 97.644043   Top5 99.995117   BatchTime 0.104512   LR 0.010000   
2022-11-03 20:50:18,178 - INFO  - Training [14][  340/  391]   Loss 0.068738   Top1 97.598805   Top5 99.990809   BatchTime 0.104211   LR 0.010000   
2022-11-03 20:50:20,161 - INFO  - Training [14][  360/  391]   Loss 0.069834   Top1 97.565104   Top5 99.989149   BatchTime 0.103928   LR 0.010000   
2022-11-03 20:50:22,105 - INFO  - Training [14][  380/  391]   Loss 0.070322   Top1 97.545230   Top5 99.989720   BatchTime 0.103574   LR 0.010000   
2022-11-03 20:50:23,404 - INFO  - ==> Top1: 97.510    Top5: 99.990    Loss: 0.071

2022-11-03 20:50:23,405 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:50:25,823 - INFO  - Validation [14][   20/   79]   Loss 0.375978   Top1 90.546875   Top5 99.765625   BatchTime 0.120835   
2022-11-03 20:50:26,338 - INFO  - Validation [14][   40/   79]   Loss 0.381341   Top1 90.253906   Top5 99.628906   BatchTime 0.073284   
2022-11-03 20:50:26,852 - INFO  - Validation [14][   60/   79]   Loss 0.381126   Top1 90.338542   Top5 99.648438   BatchTime 0.057434   
2022-11-03 20:50:27,676 - INFO  - ==> Top1: 90.170    Top5: 99.650    Loss: 0.380

2022-11-03 20:50:27,708 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:50:27,709 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 89.760   Top5: 99.540] Sparsity : 0.692
2022-11-03 20:50:27,709 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 89.750   Top5: 99.570] Sparsity : 0.699
2022-11-03 20:50:27,913 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:50:27,913 - INFO  - >>>>>>>> Epoch  15
2022-11-03 20:50:27,915 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:50:31,340 - INFO  - Training [15][   20/  391]   Loss 0.061750   Top1 97.812500   Top5 100.000000   BatchTime 0.171262   LR 0.010000   
2022-11-03 20:50:33,204 - INFO  - Training [15][   40/  391]   Loss 0.064652   Top1 97.617188   Top5 100.000000   BatchTime 0.132231   LR 0.010000   
2022-11-03 20:50:35,208 - INFO  - Training [15][   60/  391]   Loss 0.060959   Top1 97.760417   Top5 100.000000   BatchTime 0.121547   LR 0.010000   
2022-11-03 20:50:37,206 - INFO  - Training [15][   80/  391]   Loss 0.061087   Top1 97.812500   Top5 100.000000   BatchTime 0.116130   LR 0.010000   
2022-11-03 20:50:39,199 - INFO  - Training [15][  100/  391]   Loss 0.061886   Top1 97.750000   Top5 100.000000   BatchTime 0.112843   LR 0.010000   
2022-11-03 20:50:41,208 - INFO  - Training [15][  120/  391]   Loss 0.061451   Top1 97.766927   Top5 100.000000   BatchTime 0.110771   LR 0.010000   
2022-11-03 20:50:43,250 - INFO  - Training [15][  140/  391]   Loss 0.062837   Top1 97.745536   Top5 100.000000   BatchTime 0.109531   LR 0.010000   
2022-11-03 20:50:45,247 - INFO  - Training [15][  160/  391]   Loss 0.064017   Top1 97.690430   Top5 100.000000   BatchTime 0.108321   LR 0.010000   
2022-11-03 20:50:47,253 - INFO  - Training [15][  180/  391]   Loss 0.065290   Top1 97.634549   Top5 100.000000   BatchTime 0.107429   LR 0.010000   
2022-11-03 20:50:49,263 - INFO  - Training [15][  200/  391]   Loss 0.065403   Top1 97.628906   Top5 100.000000   BatchTime 0.106737   LR 0.010000   
2022-11-03 20:50:51,258 - INFO  - Training [15][  220/  391]   Loss 0.066522   Top1 97.585227   Top5 100.000000   BatchTime 0.106105   LR 0.010000   
2022-11-03 20:50:53,258 - INFO  - Training [15][  240/  391]   Loss 0.066190   Top1 97.604167   Top5 100.000000   BatchTime 0.105595   LR 0.010000   
2022-11-03 20:50:55,255 - INFO  - Training [15][  260/  391]   Loss 0.065879   Top1 97.617188   Top5 100.000000   BatchTime 0.105153   LR 0.010000   
2022-11-03 20:50:57,256 - INFO  - Training [15][  280/  391]   Loss 0.066153   Top1 97.603237   Top5 100.000000   BatchTime 0.104789   LR 0.010000   
2022-11-03 20:50:59,383 - INFO  - Training [15][  300/  391]   Loss 0.066888   Top1 97.580729   Top5 100.000000   BatchTime 0.104891   LR 0.010000   
2022-11-03 20:51:01,382 - INFO  - Training [15][  320/  391]   Loss 0.067118   Top1 97.580566   Top5 100.000000   BatchTime 0.104583   LR 0.010000   
2022-11-03 20:51:03,352 - INFO  - Training [15][  340/  391]   Loss 0.067136   Top1 97.587316   Top5 100.000000   BatchTime 0.104226   LR 0.010000   
2022-11-03 20:51:05,326 - INFO  - Training [15][  360/  391]   Loss 0.067770   Top1 97.562934   Top5 100.000000   BatchTime 0.103917   LR 0.010000   
2022-11-03 20:51:07,267 - INFO  - Training [15][  380/  391]   Loss 0.068252   Top1 97.534951   Top5 100.000000   BatchTime 0.103555   LR 0.010000   
2022-11-03 20:51:08,565 - INFO  - ==> Top1: 97.522    Top5: 100.000    Loss: 0.069

2022-11-03 20:51:08,565 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:51:11,021 - INFO  - Validation [15][   20/   79]   Loss 0.409785   Top1 89.726562   Top5 99.570312   BatchTime 0.122715   
2022-11-03 20:51:11,539 - INFO  - Validation [15][   40/   79]   Loss 0.407366   Top1 89.589844   Top5 99.492188   BatchTime 0.074301   
2022-11-03 20:51:12,056 - INFO  - Validation [15][   60/   79]   Loss 0.405600   Top1 89.531250   Top5 99.531250   BatchTime 0.058149   
2022-11-03 20:51:12,897 - INFO  - ==> Top1: 89.630    Top5: 99.560    Loss: 0.398

2022-11-03 20:51:12,928 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:51:12,929 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 89.760   Top5: 99.540] Sparsity : 0.692
2022-11-03 20:51:12,929 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 89.750   Top5: 99.570] Sparsity : 0.699
2022-11-03 20:51:13,022 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:51:13,022 - INFO  - >>>>>>>> Epoch  16
2022-11-03 20:51:13,023 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:51:16,443 - INFO  - Training [16][   20/  391]   Loss 0.080101   Top1 96.953125   Top5 100.000000   BatchTime 0.170984   LR 0.010000   
2022-11-03 20:51:18,337 - INFO  - Training [16][   40/  391]   Loss 0.073627   Top1 97.187500   Top5 100.000000   BatchTime 0.132844   LR 0.010000   
2022-11-03 20:51:20,329 - INFO  - Training [16][   60/  391]   Loss 0.070507   Top1 97.369792   Top5 100.000000   BatchTime 0.121769   LR 0.010000   
2022-11-03 20:51:22,341 - INFO  - Training [16][   80/  391]   Loss 0.069756   Top1 97.460938   Top5 99.990234   BatchTime 0.116475   LR 0.010000   
2022-11-03 20:51:24,349 - INFO  - Training [16][  100/  391]   Loss 0.069331   Top1 97.546875   Top5 99.992188   BatchTime 0.113255   LR 0.010000   
2022-11-03 20:51:26,347 - INFO  - Training [16][  120/  391]   Loss 0.071050   Top1 97.473958   Top5 99.993490   BatchTime 0.111028   LR 0.010000   
2022-11-03 20:51:28,352 - INFO  - Training [16][  140/  391]   Loss 0.070206   Top1 97.533482   Top5 99.994420   BatchTime 0.109489   LR 0.010000   
2022-11-03 20:51:30,350 - INFO  - Training [16][  160/  391]   Loss 0.070492   Top1 97.500000   Top5 99.995117   BatchTime 0.108288   LR 0.010000   
2022-11-03 20:51:32,347 - INFO  - Training [16][  180/  391]   Loss 0.071168   Top1 97.456597   Top5 99.991319   BatchTime 0.107355   LR 0.010000   
2022-11-03 20:51:34,351 - INFO  - Training [16][  200/  391]   Loss 0.071671   Top1 97.425781   Top5 99.992188   BatchTime 0.106639   LR 0.010000   
2022-11-03 20:51:36,367 - INFO  - Training [16][  220/  391]   Loss 0.071271   Top1 97.404119   Top5 99.992898   BatchTime 0.106105   LR 0.010000   
2022-11-03 20:51:38,340 - INFO  - Training [16][  240/  391]   Loss 0.071329   Top1 97.382812   Top5 99.993490   BatchTime 0.105483   LR 0.010000   
2022-11-03 20:51:40,337 - INFO  - Training [16][  260/  391]   Loss 0.071677   Top1 97.391827   Top5 99.993990   BatchTime 0.105053   LR 0.010000   
2022-11-03 20:51:42,327 - INFO  - Training [16][  280/  391]   Loss 0.072152   Top1 97.377232   Top5 99.991629   BatchTime 0.104654   LR 0.010000   
2022-11-03 20:51:44,324 - INFO  - Training [16][  300/  391]   Loss 0.072390   Top1 97.395833   Top5 99.992188   BatchTime 0.104335   LR 0.010000   
2022-11-03 20:51:46,336 - INFO  - Training [16][  320/  391]   Loss 0.072291   Top1 97.409668   Top5 99.992676   BatchTime 0.104100   LR 0.010000   
2022-11-03 20:51:48,323 - INFO  - Training [16][  340/  391]   Loss 0.072524   Top1 97.398897   Top5 99.993107   BatchTime 0.103819   LR 0.010000   
2022-11-03 20:51:50,301 - INFO  - Training [16][  360/  391]   Loss 0.072481   Top1 97.393663   Top5 99.993490   BatchTime 0.103547   LR 0.010000   
2022-11-03 20:51:52,183 - INFO  - Training [16][  380/  391]   Loss 0.072052   Top1 97.409539   Top5 99.993832   BatchTime 0.103050   LR 0.010000   
2022-11-03 20:51:53,486 - INFO  - ==> Top1: 97.404    Top5: 99.994    Loss: 0.072

2022-11-03 20:51:53,487 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:51:56,084 - INFO  - Validation [16][   20/   79]   Loss 0.398041   Top1 90.429688   Top5 99.492188   BatchTime 0.129746   
2022-11-03 20:51:56,603 - INFO  - Validation [16][   40/   79]   Loss 0.401730   Top1 90.214844   Top5 99.375000   BatchTime 0.077862   
2022-11-03 20:51:57,121 - INFO  - Validation [16][   60/   79]   Loss 0.405787   Top1 90.078125   Top5 99.466146   BatchTime 0.060539   
2022-11-03 20:51:57,847 - INFO  - ==> Top1: 90.080    Top5: 99.510    Loss: 0.404

2022-11-03 20:51:57,886 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:51:57,887 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:51:57,887 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.760   Top5: 99.540] Sparsity : 0.692
2022-11-03 20:51:57,984 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:51:57,985 - INFO  - >>>>>>>> Epoch  17
2022-11-03 20:51:57,987 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:52:01,473 - INFO  - Training [17][   20/  391]   Loss 0.072374   Top1 97.695312   Top5 99.960938   BatchTime 0.174314   LR 0.010000   
2022-11-03 20:52:03,147 - INFO  - Training [17][   40/  391]   Loss 0.072775   Top1 97.675781   Top5 99.960938   BatchTime 0.129011   LR 0.010000   
2022-11-03 20:52:05,136 - INFO  - Training [17][   60/  391]   Loss 0.069456   Top1 97.721354   Top5 99.973958   BatchTime 0.119141   LR 0.010000   
2022-11-03 20:52:07,130 - INFO  - Training [17][   80/  391]   Loss 0.069564   Top1 97.656250   Top5 99.980469   BatchTime 0.114285   LR 0.010000   
2022-11-03 20:52:09,135 - INFO  - Training [17][  100/  391]   Loss 0.068627   Top1 97.648438   Top5 99.984375   BatchTime 0.111476   LR 0.010000   
2022-11-03 20:52:11,138 - INFO  - Training [17][  120/  391]   Loss 0.071936   Top1 97.532552   Top5 99.986979   BatchTime 0.109592   LR 0.010000   
2022-11-03 20:52:13,129 - INFO  - Training [17][  140/  391]   Loss 0.072144   Top1 97.516741   Top5 99.988839   BatchTime 0.108153   LR 0.010000   
2022-11-03 20:52:15,124 - INFO  - Training [17][  160/  391]   Loss 0.071785   Top1 97.534180   Top5 99.990234   BatchTime 0.107106   LR 0.010000   
2022-11-03 20:52:17,111 - INFO  - Training [17][  180/  391]   Loss 0.071522   Top1 97.517361   Top5 99.991319   BatchTime 0.106243   LR 0.010000   
2022-11-03 20:52:19,109 - INFO  - Training [17][  200/  391]   Loss 0.072642   Top1 97.480469   Top5 99.988281   BatchTime 0.105608   LR 0.010000   
2022-11-03 20:52:21,130 - INFO  - Training [17][  220/  391]   Loss 0.072698   Top1 97.468040   Top5 99.985795   BatchTime 0.105193   LR 0.010000   
2022-11-03 20:52:23,132 - INFO  - Training [17][  240/  391]   Loss 0.072971   Top1 97.457682   Top5 99.986979   BatchTime 0.104770   LR 0.010000   
2022-11-03 20:52:25,129 - INFO  - Training [17][  260/  391]   Loss 0.073314   Top1 97.457933   Top5 99.984976   BatchTime 0.104390   LR 0.010000   
2022-11-03 20:52:27,137 - INFO  - Training [17][  280/  391]   Loss 0.073212   Top1 97.455357   Top5 99.986049   BatchTime 0.104104   LR 0.010000   
2022-11-03 20:52:29,162 - INFO  - Training [17][  300/  391]   Loss 0.073106   Top1 97.460938   Top5 99.984375   BatchTime 0.103913   LR 0.010000   
2022-11-03 20:52:31,175 - INFO  - Training [17][  320/  391]   Loss 0.073274   Top1 97.451172   Top5 99.982910   BatchTime 0.103709   LR 0.010000   
2022-11-03 20:52:33,153 - INFO  - Training [17][  340/  391]   Loss 0.073026   Top1 97.447151   Top5 99.983915   BatchTime 0.103426   LR 0.010000   
2022-11-03 20:52:35,136 - INFO  - Training [17][  360/  391]   Loss 0.072612   Top1 97.456597   Top5 99.984809   BatchTime 0.103191   LR 0.010000   
2022-11-03 20:52:37,172 - INFO  - Training [17][  380/  391]   Loss 0.072622   Top1 97.450658   Top5 99.985609   BatchTime 0.103117   LR 0.010000   
2022-11-03 20:52:38,472 - INFO  - ==> Top1: 97.440    Top5: 99.986    Loss: 0.073

2022-11-03 20:52:38,473 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:52:41,069 - INFO  - Validation [17][   20/   79]   Loss 0.395868   Top1 89.726562   Top5 99.570312   BatchTime 0.129769   
2022-11-03 20:52:41,718 - INFO  - Validation [17][   40/   79]   Loss 0.399269   Top1 89.921875   Top5 99.433594   BatchTime 0.081091   
2022-11-03 20:52:42,231 - INFO  - Validation [17][   60/   79]   Loss 0.400072   Top1 90.052083   Top5 99.466146   BatchTime 0.062622   
2022-11-03 20:52:42,957 - INFO  - ==> Top1: 90.060    Top5: 99.490    Loss: 0.394

2022-11-03 20:52:42,983 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:52:42,983 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:52:42,983 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.060   Top5: 99.490] Sparsity : 0.732
2022-11-03 20:52:43,075 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:52:43,075 - INFO  - >>>>>>>> Epoch  18
2022-11-03 20:52:43,076 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:52:46,543 - INFO  - Training [18][   20/  391]   Loss 0.064691   Top1 97.695312   Top5 99.960938   BatchTime 0.173345   LR 0.010000   
2022-11-03 20:52:48,006 - INFO  - Training [18][   40/  391]   Loss 0.071535   Top1 97.519531   Top5 99.980469   BatchTime 0.123241   LR 0.010000   
2022-11-03 20:52:50,061 - INFO  - Training [18][   60/  391]   Loss 0.068028   Top1 97.643229   Top5 99.986979   BatchTime 0.116414   LR 0.010000   
2022-11-03 20:52:52,068 - INFO  - Training [18][   80/  391]   Loss 0.066382   Top1 97.636719   Top5 99.990234   BatchTime 0.112400   LR 0.010000   
2022-11-03 20:52:54,060 - INFO  - Training [18][  100/  391]   Loss 0.065139   Top1 97.601562   Top5 99.992188   BatchTime 0.109836   LR 0.010000   
2022-11-03 20:52:56,064 - INFO  - Training [18][  120/  391]   Loss 0.064101   Top1 97.604167   Top5 99.993490   BatchTime 0.108235   LR 0.010000   
2022-11-03 20:52:58,062 - INFO  - Training [18][  140/  391]   Loss 0.065606   Top1 97.594866   Top5 99.994420   BatchTime 0.107037   LR 0.010000   
2022-11-03 20:53:00,055 - INFO  - Training [18][  160/  391]   Loss 0.065772   Top1 97.607422   Top5 99.995117   BatchTime 0.106113   LR 0.010000   
2022-11-03 20:53:02,055 - INFO  - Training [18][  180/  391]   Loss 0.065876   Top1 97.625868   Top5 99.991319   BatchTime 0.105434   LR 0.010000   
2022-11-03 20:53:04,052 - INFO  - Training [18][  200/  391]   Loss 0.065956   Top1 97.621094   Top5 99.992188   BatchTime 0.104877   LR 0.010000   
2022-11-03 20:53:06,059 - INFO  - Training [18][  220/  391]   Loss 0.067099   Top1 97.613636   Top5 99.992898   BatchTime 0.104464   LR 0.010000   
2022-11-03 20:53:08,053 - INFO  - Training [18][  240/  391]   Loss 0.067979   Top1 97.581380   Top5 99.993490   BatchTime 0.104069   LR 0.010000   
2022-11-03 20:53:10,029 - INFO  - Training [18][  260/  391]   Loss 0.067357   Top1 97.590144   Top5 99.993990   BatchTime 0.103664   LR 0.010000   
2022-11-03 20:53:12,024 - INFO  - Training [18][  280/  391]   Loss 0.067699   Top1 97.600446   Top5 99.991629   BatchTime 0.103382   LR 0.010000   
2022-11-03 20:53:14,020 - INFO  - Training [18][  300/  391]   Loss 0.067040   Top1 97.606771   Top5 99.992188   BatchTime 0.103145   LR 0.010000   
2022-11-03 20:53:16,001 - INFO  - Training [18][  320/  391]   Loss 0.066740   Top1 97.624512   Top5 99.992676   BatchTime 0.102890   LR 0.010000   
2022-11-03 20:53:17,967 - INFO  - Training [18][  340/  391]   Loss 0.067288   Top1 97.594210   Top5 99.993107   BatchTime 0.102619   LR 0.010000   
2022-11-03 20:53:19,925 - INFO  - Training [18][  360/  391]   Loss 0.067761   Top1 97.575955   Top5 99.993490   BatchTime 0.102356   LR 0.010000   
2022-11-03 20:53:21,904 - INFO  - Training [18][  380/  391]   Loss 0.067785   Top1 97.561678   Top5 99.993832   BatchTime 0.102176   LR 0.010000   
2022-11-03 20:53:23,212 - INFO  - ==> Top1: 97.560    Top5: 99.994    Loss: 0.068

2022-11-03 20:53:23,213 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:53:25,768 - INFO  - Validation [18][   20/   79]   Loss 0.440090   Top1 89.140625   Top5 99.531250   BatchTime 0.127694   
2022-11-03 20:53:26,596 - INFO  - Validation [18][   40/   79]   Loss 0.431575   Top1 89.277344   Top5 99.414062   BatchTime 0.084527   
2022-11-03 20:53:27,117 - INFO  - Validation [18][   60/   79]   Loss 0.417821   Top1 89.596354   Top5 99.505208   BatchTime 0.065041   
2022-11-03 20:53:27,857 - INFO  - ==> Top1: 89.660    Top5: 99.530    Loss: 0.413

2022-11-03 20:53:27,882 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:53:27,883 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:53:27,883 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.060   Top5: 99.490] Sparsity : 0.732
2022-11-03 20:53:27,978 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:53:27,978 - INFO  - >>>>>>>> Epoch  19
2022-11-03 20:53:27,979 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:53:31,417 - INFO  - Training [19][   20/  391]   Loss 0.074352   Top1 97.265625   Top5 100.000000   BatchTime 0.171858   LR 0.010000   
2022-11-03 20:53:33,027 - INFO  - Training [19][   40/  391]   Loss 0.064650   Top1 97.597656   Top5 100.000000   BatchTime 0.126185   LR 0.010000   
2022-11-03 20:53:34,863 - INFO  - Training [19][   60/  391]   Loss 0.067159   Top1 97.539062   Top5 100.000000   BatchTime 0.114715   LR 0.010000   
2022-11-03 20:53:36,865 - INFO  - Training [19][   80/  391]   Loss 0.065047   Top1 97.685547   Top5 100.000000   BatchTime 0.111063   LR 0.010000   
2022-11-03 20:53:38,861 - INFO  - Training [19][  100/  391]   Loss 0.064094   Top1 97.664062   Top5 100.000000   BatchTime 0.108812   LR 0.010000   
2022-11-03 20:53:40,864 - INFO  - Training [19][  120/  391]   Loss 0.063221   Top1 97.708333   Top5 100.000000   BatchTime 0.107370   LR 0.010000   
2022-11-03 20:53:42,894 - INFO  - Training [19][  140/  391]   Loss 0.063059   Top1 97.712054   Top5 100.000000   BatchTime 0.106529   LR 0.010000   
2022-11-03 20:53:44,895 - INFO  - Training [19][  160/  391]   Loss 0.062257   Top1 97.778320   Top5 100.000000   BatchTime 0.105718   LR 0.010000   
2022-11-03 20:53:46,876 - INFO  - Training [19][  180/  391]   Loss 0.061603   Top1 97.808160   Top5 99.995660   BatchTime 0.104978   LR 0.010000   
2022-11-03 20:53:48,881 - INFO  - Training [19][  200/  391]   Loss 0.060442   Top1 97.863281   Top5 99.996094   BatchTime 0.104503   LR 0.010000   
2022-11-03 20:53:50,873 - INFO  - Training [19][  220/  391]   Loss 0.060505   Top1 97.851562   Top5 99.992898   BatchTime 0.104059   LR 0.010000   
2022-11-03 20:53:52,876 - INFO  - Training [19][  240/  391]   Loss 0.061354   Top1 97.822266   Top5 99.990234   BatchTime 0.103733   LR 0.010000   
2022-11-03 20:53:54,872 - INFO  - Training [19][  260/  391]   Loss 0.061863   Top1 97.794471   Top5 99.990986   BatchTime 0.103429   LR 0.010000   
2022-11-03 20:53:56,877 - INFO  - Training [19][  280/  391]   Loss 0.061728   Top1 97.795759   Top5 99.991629   BatchTime 0.103204   LR 0.010000   
2022-11-03 20:53:58,878 - INFO  - Training [19][  300/  391]   Loss 0.061609   Top1 97.807292   Top5 99.992188   BatchTime 0.102994   LR 0.010000   
2022-11-03 20:54:00,868 - INFO  - Training [19][  320/  391]   Loss 0.062146   Top1 97.790527   Top5 99.992676   BatchTime 0.102776   LR 0.010000   
2022-11-03 20:54:02,835 - INFO  - Training [19][  340/  391]   Loss 0.062816   Top1 97.764246   Top5 99.993107   BatchTime 0.102513   LR 0.010000   
2022-11-03 20:54:04,795 - INFO  - Training [19][  360/  391]   Loss 0.063205   Top1 97.743056   Top5 99.991319   BatchTime 0.102263   LR 0.010000   
2022-11-03 20:54:06,754 - INFO  - Training [19][  380/  391]   Loss 0.062726   Top1 97.767270   Top5 99.991776   BatchTime 0.102037   LR 0.010000   
2022-11-03 20:54:08,047 - INFO  - ==> Top1: 97.758    Top5: 99.992    Loss: 0.063

2022-11-03 20:54:08,048 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:54:10,667 - INFO  - Validation [19][   20/   79]   Loss 0.423873   Top1 89.570312   Top5 99.375000   BatchTime 0.130923   
2022-11-03 20:54:11,594 - INFO  - Validation [19][   40/   79]   Loss 0.426242   Top1 89.882812   Top5 99.375000   BatchTime 0.088630   
2022-11-03 20:54:12,234 - INFO  - Validation [19][   60/   79]   Loss 0.420598   Top1 89.986979   Top5 99.401042   BatchTime 0.069748   
2022-11-03 20:54:12,977 - INFO  - ==> Top1: 90.040    Top5: 99.450    Loss: 0.412

2022-11-03 20:54:13,002 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:54:13,003 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:54:13,003 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.060   Top5: 99.490] Sparsity : 0.732
2022-11-03 20:54:13,107 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:54:13,108 - INFO  - >>>>>>>> Epoch  20
2022-11-03 20:54:13,109 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:54:16,696 - INFO  - Training [20][   20/  391]   Loss 0.059719   Top1 97.890625   Top5 100.000000   BatchTime 0.179298   LR 0.010000   
2022-11-03 20:54:18,405 - INFO  - Training [20][   40/  391]   Loss 0.054405   Top1 98.144531   Top5 100.000000   BatchTime 0.132371   LR 0.010000   
2022-11-03 20:54:20,289 - INFO  - Training [20][   60/  391]   Loss 0.051535   Top1 98.111979   Top5 100.000000   BatchTime 0.119653   LR 0.010000   
2022-11-03 20:54:22,292 - INFO  - Training [20][   80/  391]   Loss 0.052422   Top1 98.037109   Top5 100.000000   BatchTime 0.114782   LR 0.010000   
2022-11-03 20:54:24,306 - INFO  - Training [20][  100/  391]   Loss 0.053037   Top1 98.000000   Top5 100.000000   BatchTime 0.111956   LR 0.010000   
2022-11-03 20:54:26,311 - INFO  - Training [20][  120/  391]   Loss 0.053386   Top1 97.994792   Top5 100.000000   BatchTime 0.110005   LR 0.010000   
2022-11-03 20:54:28,327 - INFO  - Training [20][  140/  391]   Loss 0.056248   Top1 97.912946   Top5 100.000000   BatchTime 0.108690   LR 0.010000   
2022-11-03 20:54:30,322 - INFO  - Training [20][  160/  391]   Loss 0.057938   Top1 97.890625   Top5 100.000000   BatchTime 0.107571   LR 0.010000   
2022-11-03 20:54:32,315 - INFO  - Training [20][  180/  391]   Loss 0.058193   Top1 97.886285   Top5 100.000000   BatchTime 0.106694   LR 0.010000   
2022-11-03 20:54:34,312 - INFO  - Training [20][  200/  391]   Loss 0.056698   Top1 97.933594   Top5 100.000000   BatchTime 0.106008   LR 0.010000   
2022-11-03 20:54:36,317 - INFO  - Training [20][  220/  391]   Loss 0.057156   Top1 97.922585   Top5 100.000000   BatchTime 0.105487   LR 0.010000   
2022-11-03 20:54:38,326 - INFO  - Training [20][  240/  391]   Loss 0.057820   Top1 97.893880   Top5 100.000000   BatchTime 0.105066   LR 0.010000   
2022-11-03 20:54:40,318 - INFO  - Training [20][  260/  391]   Loss 0.059508   Top1 97.866587   Top5 100.000000   BatchTime 0.104643   LR 0.010000   
2022-11-03 20:54:42,308 - INFO  - Training [20][  280/  391]   Loss 0.059262   Top1 97.873884   Top5 100.000000   BatchTime 0.104278   LR 0.010000   
2022-11-03 20:54:44,308 - INFO  - Training [20][  300/  391]   Loss 0.058977   Top1 97.875000   Top5 99.997396   BatchTime 0.103994   LR 0.010000   
2022-11-03 20:54:46,302 - INFO  - Training [20][  320/  391]   Loss 0.059490   Top1 97.844238   Top5 99.997559   BatchTime 0.103725   LR 0.010000   
2022-11-03 20:54:48,275 - INFO  - Training [20][  340/  391]   Loss 0.059583   Top1 97.856158   Top5 99.997702   BatchTime 0.103424   LR 0.010000   
2022-11-03 20:54:50,251 - INFO  - Training [20][  360/  391]   Loss 0.059562   Top1 97.853733   Top5 99.997830   BatchTime 0.103167   LR 0.010000   
2022-11-03 20:54:52,219 - INFO  - Training [20][  380/  391]   Loss 0.059472   Top1 97.857730   Top5 99.997944   BatchTime 0.102918   LR 0.010000   
2022-11-03 20:54:53,504 - INFO  - ==> Top1: 97.832    Top5: 99.998    Loss: 0.060

2022-11-03 20:54:53,505 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:54:56,112 - INFO  - Validation [20][   20/   79]   Loss 0.399882   Top1 90.000000   Top5 99.492188   BatchTime 0.130324   
2022-11-03 20:54:57,013 - INFO  - Validation [20][   40/   79]   Loss 0.410305   Top1 90.039062   Top5 99.433594   BatchTime 0.087675   
2022-11-03 20:54:57,776 - INFO  - Validation [20][   60/   79]   Loss 0.411122   Top1 90.052083   Top5 99.479167   BatchTime 0.071163   
2022-11-03 20:54:58,505 - INFO  - ==> Top1: 90.070    Top5: 99.550    Loss: 0.405

2022-11-03 20:54:58,527 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:54:58,528 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:54:58,528 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.070   Top5: 99.550] Sparsity : 0.737
2022-11-03 20:54:58,629 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:54:58,630 - INFO  - >>>>>>>> Epoch  21
2022-11-03 20:54:58,631 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:55:02,148 - INFO  - Training [21][   20/  391]   Loss 0.053609   Top1 98.046875   Top5 100.000000   BatchTime 0.175843   LR 0.010000   
2022-11-03 20:55:03,888 - INFO  - Training [21][   40/  391]   Loss 0.051114   Top1 98.203125   Top5 99.960938   BatchTime 0.131437   LR 0.010000   
2022-11-03 20:55:05,676 - INFO  - Training [21][   60/  391]   Loss 0.052654   Top1 98.164062   Top5 99.973958   BatchTime 0.117419   LR 0.010000   
2022-11-03 20:55:07,676 - INFO  - Training [21][   80/  391]   Loss 0.053486   Top1 98.115234   Top5 99.980469   BatchTime 0.113061   LR 0.010000   
2022-11-03 20:55:09,678 - INFO  - Training [21][  100/  391]   Loss 0.053718   Top1 98.125000   Top5 99.984375   BatchTime 0.110467   LR 0.010000   
2022-11-03 20:55:11,658 - INFO  - Training [21][  120/  391]   Loss 0.054312   Top1 98.125000   Top5 99.986979   BatchTime 0.108560   LR 0.010000   
2022-11-03 20:55:13,666 - INFO  - Training [21][  140/  391]   Loss 0.053377   Top1 98.136161   Top5 99.988839   BatchTime 0.107395   LR 0.010000   
2022-11-03 20:55:15,667 - INFO  - Training [21][  160/  391]   Loss 0.054473   Top1 98.066406   Top5 99.990234   BatchTime 0.106476   LR 0.010000   
2022-11-03 20:55:17,679 - INFO  - Training [21][  180/  391]   Loss 0.054169   Top1 98.077257   Top5 99.991319   BatchTime 0.105823   LR 0.010000   
2022-11-03 20:55:19,697 - INFO  - Training [21][  200/  391]   Loss 0.054475   Top1 98.078125   Top5 99.992188   BatchTime 0.105331   LR 0.010000   
2022-11-03 20:55:21,720 - INFO  - Training [21][  220/  391]   Loss 0.055615   Top1 98.071733   Top5 99.992898   BatchTime 0.104947   LR 0.010000   
2022-11-03 20:55:23,723 - INFO  - Training [21][  240/  391]   Loss 0.055066   Top1 98.076172   Top5 99.993490   BatchTime 0.104547   LR 0.010000   
2022-11-03 20:55:25,728 - INFO  - Training [21][  260/  391]   Loss 0.054454   Top1 98.082933   Top5 99.993990   BatchTime 0.104218   LR 0.010000   
2022-11-03 20:55:27,729 - INFO  - Training [21][  280/  391]   Loss 0.055680   Top1 98.024554   Top5 99.994420   BatchTime 0.103921   LR 0.010000   
2022-11-03 20:55:29,730 - INFO  - Training [21][  300/  391]   Loss 0.055158   Top1 98.054688   Top5 99.989583   BatchTime 0.103662   LR 0.010000   
2022-11-03 20:55:31,728 - INFO  - Training [21][  320/  391]   Loss 0.055073   Top1 98.039551   Top5 99.990234   BatchTime 0.103426   LR 0.010000   
2022-11-03 20:55:33,711 - INFO  - Training [21][  340/  391]   Loss 0.055176   Top1 98.042279   Top5 99.990809   BatchTime 0.103175   LR 0.010000   
2022-11-03 20:55:35,684 - INFO  - Training [21][  360/  391]   Loss 0.056066   Top1 98.016493   Top5 99.991319   BatchTime 0.102923   LR 0.010000   
2022-11-03 20:55:37,653 - INFO  - Training [21][  380/  391]   Loss 0.056307   Top1 98.005757   Top5 99.991776   BatchTime 0.102687   LR 0.010000   
2022-11-03 20:55:38,962 - INFO  - ==> Top1: 98.000    Top5: 99.992    Loss: 0.057

2022-11-03 20:55:38,963 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:55:41,577 - INFO  - Validation [21][   20/   79]   Loss 0.415908   Top1 90.000000   Top5 99.609375   BatchTime 0.130621   
2022-11-03 20:55:42,463 - INFO  - Validation [21][   40/   79]   Loss 0.420130   Top1 90.156250   Top5 99.453125   BatchTime 0.087449   
2022-11-03 20:55:43,386 - INFO  - Validation [21][   60/   79]   Loss 0.426967   Top1 90.130208   Top5 99.440104   BatchTime 0.073680   
2022-11-03 20:55:44,115 - INFO  - ==> Top1: 89.990    Top5: 99.520    Loss: 0.422

2022-11-03 20:55:44,140 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:55:44,140 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:55:44,140 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.070   Top5: 99.550] Sparsity : 0.737
2022-11-03 20:55:44,243 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:55:44,244 - INFO  - >>>>>>>> Epoch  22
2022-11-03 20:55:44,244 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:55:47,754 - INFO  - Training [22][   20/  391]   Loss 0.053371   Top1 98.203125   Top5 99.960938   BatchTime 0.175461   LR 0.010000   
2022-11-03 20:55:49,510 - INFO  - Training [22][   40/  391]   Loss 0.055950   Top1 98.105469   Top5 99.980469   BatchTime 0.131629   LR 0.010000   
2022-11-03 20:55:50,968 - INFO  - Training [22][   60/  391]   Loss 0.055209   Top1 98.138021   Top5 99.986979   BatchTime 0.112058   LR 0.010000   
2022-11-03 20:55:53,204 - INFO  - Training [22][   80/  391]   Loss 0.056334   Top1 98.144531   Top5 99.990234   BatchTime 0.111987   LR 0.010000   
2022-11-03 20:55:55,224 - INFO  - Training [22][  100/  391]   Loss 0.055473   Top1 98.148438   Top5 99.992188   BatchTime 0.109789   LR 0.010000   
2022-11-03 20:55:57,248 - INFO  - Training [22][  120/  391]   Loss 0.058495   Top1 98.040365   Top5 99.993490   BatchTime 0.108358   LR 0.010000   
2022-11-03 20:55:59,274 - INFO  - Training [22][  140/  391]   Loss 0.059576   Top1 97.979911   Top5 99.994420   BatchTime 0.107354   LR 0.010000   
2022-11-03 20:56:01,283 - INFO  - Training [22][  160/  391]   Loss 0.059560   Top1 97.998047   Top5 99.995117   BatchTime 0.106486   LR 0.010000   
2022-11-03 20:56:03,281 - INFO  - Training [22][  180/  391]   Loss 0.059461   Top1 98.007812   Top5 99.995660   BatchTime 0.105755   LR 0.010000   
2022-11-03 20:56:05,286 - INFO  - Training [22][  200/  391]   Loss 0.059756   Top1 98.003906   Top5 99.996094   BatchTime 0.105205   LR 0.010000   
2022-11-03 20:56:07,292 - INFO  - Training [22][  220/  391]   Loss 0.059278   Top1 97.993608   Top5 99.996449   BatchTime 0.104760   LR 0.010000   
2022-11-03 20:56:09,322 - INFO  - Training [22][  240/  391]   Loss 0.058703   Top1 98.017578   Top5 99.996745   BatchTime 0.104488   LR 0.010000   
2022-11-03 20:56:11,343 - INFO  - Training [22][  260/  391]   Loss 0.058336   Top1 98.040865   Top5 99.996995   BatchTime 0.104224   LR 0.010000   
2022-11-03 20:56:13,351 - INFO  - Training [22][  280/  391]   Loss 0.057799   Top1 98.052455   Top5 99.997210   BatchTime 0.103950   LR 0.010000   
2022-11-03 20:56:15,361 - INFO  - Training [22][  300/  391]   Loss 0.058239   Top1 98.028646   Top5 99.994792   BatchTime 0.103718   LR 0.010000   
2022-11-03 20:56:17,364 - INFO  - Training [22][  320/  391]   Loss 0.058095   Top1 98.029785   Top5 99.995117   BatchTime 0.103495   LR 0.010000   
2022-11-03 20:56:19,364 - INFO  - Training [22][  340/  391]   Loss 0.057746   Top1 98.035386   Top5 99.995404   BatchTime 0.103289   LR 0.010000   
2022-11-03 20:56:21,358 - INFO  - Training [22][  360/  391]   Loss 0.057471   Top1 98.038194   Top5 99.995660   BatchTime 0.103090   LR 0.010000   
2022-11-03 20:56:23,343 - INFO  - Training [22][  380/  391]   Loss 0.058454   Top1 97.983141   Top5 99.995888   BatchTime 0.102888   LR 0.010000   
2022-11-03 20:56:24,660 - INFO  - ==> Top1: 97.984    Top5: 99.996    Loss: 0.059

2022-11-03 20:56:24,660 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:56:27,240 - INFO  - Validation [22][   20/   79]   Loss 0.406278   Top1 89.453125   Top5 99.726562   BatchTime 0.128902   
2022-11-03 20:56:28,167 - INFO  - Validation [22][   40/   79]   Loss 0.415356   Top1 89.687500   Top5 99.589844   BatchTime 0.087636   
2022-11-03 20:56:29,064 - INFO  - Validation [22][   60/   79]   Loss 0.419145   Top1 89.596354   Top5 99.557292   BatchTime 0.073373   
2022-11-03 20:56:29,942 - INFO  - ==> Top1: 89.740    Top5: 99.590    Loss: 0.414

2022-11-03 20:56:29,969 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:56:29,969 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:56:29,969 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.070   Top5: 99.550] Sparsity : 0.737
2022-11-03 20:56:30,053 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:56:30,053 - INFO  - >>>>>>>> Epoch  23
2022-11-03 20:56:30,055 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:56:33,587 - INFO  - Training [23][   20/  391]   Loss 0.045360   Top1 98.359375   Top5 100.000000   BatchTime 0.176604   LR 0.010000   
2022-11-03 20:56:35,317 - INFO  - Training [23][   40/  391]   Loss 0.052516   Top1 98.164062   Top5 100.000000   BatchTime 0.131558   LR 0.010000   
2022-11-03 20:56:36,855 - INFO  - Training [23][   60/  391]   Loss 0.054263   Top1 98.138021   Top5 100.000000   BatchTime 0.113338   LR 0.010000   
2022-11-03 20:56:38,880 - INFO  - Training [23][   80/  391]   Loss 0.052090   Top1 98.232422   Top5 100.000000   BatchTime 0.110312   LR 0.010000   
2022-11-03 20:56:40,895 - INFO  - Training [23][  100/  391]   Loss 0.051890   Top1 98.257812   Top5 100.000000   BatchTime 0.108401   LR 0.010000   
2022-11-03 20:56:42,913 - INFO  - Training [23][  120/  391]   Loss 0.052884   Top1 98.248698   Top5 100.000000   BatchTime 0.107151   LR 0.010000   
2022-11-03 20:56:44,899 - INFO  - Training [23][  140/  391]   Loss 0.053740   Top1 98.197545   Top5 100.000000   BatchTime 0.106030   LR 0.010000   
2022-11-03 20:56:46,919 - INFO  - Training [23][  160/  391]   Loss 0.054371   Top1 98.134766   Top5 100.000000   BatchTime 0.105401   LR 0.010000   
2022-11-03 20:56:48,919 - INFO  - Training [23][  180/  391]   Loss 0.053818   Top1 98.151042   Top5 100.000000   BatchTime 0.104800   LR 0.010000   
2022-11-03 20:56:50,928 - INFO  - Training [23][  200/  391]   Loss 0.054749   Top1 98.128906   Top5 99.996094   BatchTime 0.104361   LR 0.010000   
2022-11-03 20:56:52,933 - INFO  - Training [23][  220/  391]   Loss 0.054294   Top1 98.135653   Top5 99.996449   BatchTime 0.103991   LR 0.010000   
2022-11-03 20:56:54,957 - INFO  - Training [23][  240/  391]   Loss 0.053692   Top1 98.160807   Top5 99.996745   BatchTime 0.103756   LR 0.010000   
2022-11-03 20:56:56,989 - INFO  - Training [23][  260/  391]   Loss 0.053750   Top1 98.155048   Top5 99.996995   BatchTime 0.103588   LR 0.010000   
2022-11-03 20:56:58,989 - INFO  - Training [23][  280/  391]   Loss 0.054387   Top1 98.147321   Top5 99.997210   BatchTime 0.103334   LR 0.010000   
2022-11-03 20:57:01,007 - INFO  - Training [23][  300/  391]   Loss 0.054581   Top1 98.127604   Top5 99.997396   BatchTime 0.103170   LR 0.010000   
2022-11-03 20:57:03,031 - INFO  - Training [23][  320/  391]   Loss 0.054530   Top1 98.125000   Top5 99.997559   BatchTime 0.103049   LR 0.010000   
2022-11-03 20:57:05,028 - INFO  - Training [23][  340/  391]   Loss 0.054057   Top1 98.138787   Top5 99.997702   BatchTime 0.102859   LR 0.010000   
2022-11-03 20:57:07,000 - INFO  - Training [23][  360/  391]   Loss 0.054051   Top1 98.140191   Top5 99.997830   BatchTime 0.102622   LR 0.010000   
2022-11-03 20:57:08,973 - INFO  - Training [23][  380/  391]   Loss 0.053617   Top1 98.153783   Top5 99.995888   BatchTime 0.102413   LR 0.010000   
2022-11-03 20:57:10,327 - INFO  - ==> Top1: 98.144    Top5: 99.996    Loss: 0.054

2022-11-03 20:57:10,328 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:57:12,921 - INFO  - Validation [23][   20/   79]   Loss 0.401657   Top1 90.156250   Top5 99.609375   BatchTime 0.129607   
2022-11-03 20:57:13,845 - INFO  - Validation [23][   40/   79]   Loss 0.416558   Top1 90.566406   Top5 99.453125   BatchTime 0.087898   
2022-11-03 20:57:14,768 - INFO  - Validation [23][   60/   79]   Loss 0.424034   Top1 90.455729   Top5 99.492188   BatchTime 0.073986   
2022-11-03 20:57:15,842 - INFO  - ==> Top1: 90.400    Top5: 99.550    Loss: 0.420

2022-11-03 20:57:15,867 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 20:57:15,868 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:57:15,868 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 90.080   Top5: 99.510] Sparsity : 0.730
2022-11-03 20:57:16,032 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 20:57:16,032 - INFO  - >>>>>>>> Epoch  24
2022-11-03 20:57:16,034 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:57:19,569 - INFO  - Training [24][   20/  391]   Loss 0.051583   Top1 98.164062   Top5 100.000000   BatchTime 0.176737   LR 0.010000   
2022-11-03 20:57:21,403 - INFO  - Training [24][   40/  391]   Loss 0.049311   Top1 98.242188   Top5 100.000000   BatchTime 0.134222   LR 0.010000   
2022-11-03 20:57:22,877 - INFO  - Training [24][   60/  391]   Loss 0.051677   Top1 98.098958   Top5 100.000000   BatchTime 0.114045   LR 0.010000   
2022-11-03 20:57:24,778 - INFO  - Training [24][   80/  391]   Loss 0.050222   Top1 98.183594   Top5 100.000000   BatchTime 0.109306   LR 0.010000   
2022-11-03 20:57:26,798 - INFO  - Training [24][  100/  391]   Loss 0.050438   Top1 98.195312   Top5 100.000000   BatchTime 0.107639   LR 0.010000   
2022-11-03 20:57:28,805 - INFO  - Training [24][  120/  391]   Loss 0.050184   Top1 98.190104   Top5 100.000000   BatchTime 0.106428   LR 0.010000   
2022-11-03 20:57:30,938 - INFO  - Training [24][  140/  391]   Loss 0.049904   Top1 98.175223   Top5 100.000000   BatchTime 0.106458   LR 0.010000   
2022-11-03 20:57:32,940 - INFO  - Training [24][  160/  391]   Loss 0.050561   Top1 98.188477   Top5 100.000000   BatchTime 0.105662   LR 0.010000   
2022-11-03 20:57:34,950 - INFO  - Training [24][  180/  391]   Loss 0.050946   Top1 98.181424   Top5 100.000000   BatchTime 0.105087   LR 0.010000   
2022-11-03 20:57:36,962 - INFO  - Training [24][  200/  391]   Loss 0.051019   Top1 98.175781   Top5 100.000000   BatchTime 0.104637   LR 0.010000   
2022-11-03 20:57:38,969 - INFO  - Training [24][  220/  391]   Loss 0.050726   Top1 98.196023   Top5 100.000000   BatchTime 0.104246   LR 0.010000   
2022-11-03 20:57:40,975 - INFO  - Training [24][  240/  391]   Loss 0.050289   Top1 98.206380   Top5 100.000000   BatchTime 0.103919   LR 0.010000   
2022-11-03 20:57:42,967 - INFO  - Training [24][  260/  391]   Loss 0.050447   Top1 98.194111   Top5 100.000000   BatchTime 0.103588   LR 0.010000   
2022-11-03 20:57:44,974 - INFO  - Training [24][  280/  391]   Loss 0.050059   Top1 98.214286   Top5 100.000000   BatchTime 0.103354   LR 0.010000   
2022-11-03 20:57:46,986 - INFO  - Training [24][  300/  391]   Loss 0.050948   Top1 98.190104   Top5 99.997396   BatchTime 0.103172   LR 0.010000   
2022-11-03 20:57:48,998 - INFO  - Training [24][  320/  391]   Loss 0.051265   Top1 98.183594   Top5 99.997559   BatchTime 0.103011   LR 0.010000   
2022-11-03 20:57:51,017 - INFO  - Training [24][  340/  391]   Loss 0.051113   Top1 98.198529   Top5 99.997702   BatchTime 0.102890   LR 0.010000   
2022-11-03 20:57:52,980 - INFO  - Training [24][  360/  391]   Loss 0.051518   Top1 98.172743   Top5 99.997830   BatchTime 0.102626   LR 0.010000   
2022-11-03 20:57:54,963 - INFO  - Training [24][  380/  391]   Loss 0.051823   Top1 98.168174   Top5 99.997944   BatchTime 0.102443   LR 0.010000   
2022-11-03 20:57:56,276 - INFO  - ==> Top1: 98.176    Top5: 99.998    Loss: 0.052

2022-11-03 20:57:56,277 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:57:58,891 - INFO  - Validation [24][   20/   79]   Loss 0.403979   Top1 90.390625   Top5 99.648438   BatchTime 0.130639   
2022-11-03 20:57:59,789 - INFO  - Validation [24][   40/   79]   Loss 0.416892   Top1 90.332031   Top5 99.492188   BatchTime 0.087778   
2022-11-03 20:58:00,649 - INFO  - Validation [24][   60/   79]   Loss 0.415642   Top1 90.416667   Top5 99.557292   BatchTime 0.072837   
2022-11-03 20:58:01,813 - INFO  - ==> Top1: 90.310    Top5: 99.620    Loss: 0.411

2022-11-03 20:58:01,836 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 20:58:01,837 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 20:58:01,837 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 90.170   Top5: 99.650] Sparsity : 0.709
2022-11-03 20:58:01,934 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:58:01,934 - INFO  - >>>>>>>> Epoch  25
2022-11-03 20:58:01,935 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:58:05,515 - INFO  - Training [25][   20/  391]   Loss 0.046295   Top1 98.398438   Top5 100.000000   BatchTime 0.178981   LR 0.010000   
2022-11-03 20:58:07,178 - INFO  - Training [25][   40/  391]   Loss 0.046664   Top1 98.378906   Top5 100.000000   BatchTime 0.131085   LR 0.010000   
2022-11-03 20:58:08,818 - INFO  - Training [25][   60/  391]   Loss 0.045168   Top1 98.385417   Top5 100.000000   BatchTime 0.114710   LR 0.010000   
2022-11-03 20:58:10,632 - INFO  - Training [25][   80/  391]   Loss 0.048216   Top1 98.320312   Top5 100.000000   BatchTime 0.108710   LR 0.010000   
2022-11-03 20:58:12,645 - INFO  - Training [25][  100/  391]   Loss 0.049114   Top1 98.257812   Top5 100.000000   BatchTime 0.107103   LR 0.010000   
2022-11-03 20:58:14,654 - INFO  - Training [25][  120/  391]   Loss 0.048143   Top1 98.242188   Top5 100.000000   BatchTime 0.105986   LR 0.010000   
2022-11-03 20:58:16,668 - INFO  - Training [25][  140/  391]   Loss 0.048898   Top1 98.236607   Top5 100.000000   BatchTime 0.105233   LR 0.010000   
2022-11-03 20:58:18,680 - INFO  - Training [25][  160/  391]   Loss 0.048732   Top1 98.261719   Top5 100.000000   BatchTime 0.104656   LR 0.010000   
2022-11-03 20:58:20,685 - INFO  - Training [25][  180/  391]   Loss 0.048646   Top1 98.233507   Top5 100.000000   BatchTime 0.104166   LR 0.010000   
2022-11-03 20:58:22,694 - INFO  - Training [25][  200/  391]   Loss 0.048927   Top1 98.250000   Top5 100.000000   BatchTime 0.103794   LR 0.010000   
2022-11-03 20:58:24,623 - INFO  - Training [25][  220/  391]   Loss 0.049562   Top1 98.238636   Top5 100.000000   BatchTime 0.103126   LR 0.010000   
2022-11-03 20:58:26,642 - INFO  - Training [25][  240/  391]   Loss 0.049365   Top1 98.238932   Top5 100.000000   BatchTime 0.102945   LR 0.010000   
2022-11-03 20:58:28,666 - INFO  - Training [25][  260/  391]   Loss 0.048487   Top1 98.266226   Top5 100.000000   BatchTime 0.102808   LR 0.010000   
2022-11-03 20:58:30,668 - INFO  - Training [25][  280/  391]   Loss 0.048832   Top1 98.256138   Top5 100.000000   BatchTime 0.102616   LR 0.010000   
2022-11-03 20:58:32,666 - INFO  - Training [25][  300/  391]   Loss 0.048888   Top1 98.250000   Top5 100.000000   BatchTime 0.102434   LR 0.010000   
2022-11-03 20:58:34,680 - INFO  - Training [25][  320/  391]   Loss 0.049551   Top1 98.232422   Top5 100.000000   BatchTime 0.102325   LR 0.010000   
2022-11-03 20:58:36,656 - INFO  - Training [25][  340/  391]   Loss 0.049600   Top1 98.249081   Top5 100.000000   BatchTime 0.102119   LR 0.010000   
2022-11-03 20:58:38,628 - INFO  - Training [25][  360/  391]   Loss 0.049708   Top1 98.244358   Top5 99.997830   BatchTime 0.101923   LR 0.010000   
2022-11-03 20:58:40,603 - INFO  - Training [25][  380/  391]   Loss 0.049830   Top1 98.250411   Top5 99.997944   BatchTime 0.101756   LR 0.010000   
2022-11-03 20:58:41,960 - INFO  - ==> Top1: 98.248    Top5: 99.998    Loss: 0.050

2022-11-03 20:58:41,961 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:58:44,570 - INFO  - Validation [25][   20/   79]   Loss 0.428937   Top1 90.000000   Top5 99.531250   BatchTime 0.130412   
2022-11-03 20:58:45,472 - INFO  - Validation [25][   40/   79]   Loss 0.430137   Top1 89.843750   Top5 99.453125   BatchTime 0.087754   
2022-11-03 20:58:46,369 - INFO  - Validation [25][   60/   79]   Loss 0.421764   Top1 90.195312   Top5 99.466146   BatchTime 0.073449   
2022-11-03 20:58:47,470 - INFO  - ==> Top1: 90.310    Top5: 99.510    Loss: 0.417

2022-11-03 20:58:47,509 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 20:58:47,510 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 20:58:47,510 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.310   Top5: 99.510] Sparsity : 0.749
2022-11-03 20:58:47,640 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:58:47,640 - INFO  - >>>>>>>> Epoch  26
2022-11-03 20:58:47,642 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:58:51,299 - INFO  - Training [26][   20/  391]   Loss 0.044695   Top1 98.359375   Top5 100.000000   BatchTime 0.182850   LR 0.010000   
2022-11-03 20:58:52,897 - INFO  - Training [26][   40/  391]   Loss 0.045053   Top1 98.339844   Top5 100.000000   BatchTime 0.131371   LR 0.010000   
2022-11-03 20:58:54,632 - INFO  - Training [26][   60/  391]   Loss 0.047172   Top1 98.307292   Top5 100.000000   BatchTime 0.116498   LR 0.010000   
2022-11-03 20:58:56,294 - INFO  - Training [26][   80/  391]   Loss 0.048132   Top1 98.251953   Top5 100.000000   BatchTime 0.108147   LR 0.010000   
2022-11-03 20:58:58,296 - INFO  - Training [26][  100/  391]   Loss 0.047050   Top1 98.312500   Top5 100.000000   BatchTime 0.106536   LR 0.010000   
2022-11-03 20:59:00,309 - INFO  - Training [26][  120/  391]   Loss 0.048815   Top1 98.242188   Top5 100.000000   BatchTime 0.105558   LR 0.010000   
2022-11-03 20:59:02,310 - INFO  - Training [26][  140/  391]   Loss 0.049379   Top1 98.231027   Top5 100.000000   BatchTime 0.104768   LR 0.010000   
2022-11-03 20:59:04,319 - INFO  - Training [26][  160/  391]   Loss 0.049597   Top1 98.222656   Top5 100.000000   BatchTime 0.104232   LR 0.010000   
2022-11-03 20:59:06,422 - INFO  - Training [26][  180/  391]   Loss 0.050087   Top1 98.207465   Top5 100.000000   BatchTime 0.104332   LR 0.010000   
2022-11-03 20:59:08,425 - INFO  - Training [26][  200/  391]   Loss 0.048930   Top1 98.257812   Top5 100.000000   BatchTime 0.103915   LR 0.010000   
2022-11-03 20:59:10,430 - INFO  - Training [26][  220/  391]   Loss 0.048851   Top1 98.274148   Top5 100.000000   BatchTime 0.103579   LR 0.010000   
2022-11-03 20:59:12,432 - INFO  - Training [26][  240/  391]   Loss 0.049000   Top1 98.271484   Top5 100.000000   BatchTime 0.103289   LR 0.010000   
2022-11-03 20:59:14,457 - INFO  - Training [26][  260/  391]   Loss 0.049237   Top1 98.263221   Top5 100.000000   BatchTime 0.103134   LR 0.010000   
2022-11-03 20:59:16,443 - INFO  - Training [26][  280/  391]   Loss 0.049302   Top1 98.261719   Top5 100.000000   BatchTime 0.102860   LR 0.010000   
2022-11-03 20:59:18,465 - INFO  - Training [26][  300/  391]   Loss 0.049736   Top1 98.247396   Top5 100.000000   BatchTime 0.102743   LR 0.010000   
2022-11-03 20:59:20,492 - INFO  - Training [26][  320/  391]   Loss 0.050480   Top1 98.217773   Top5 100.000000   BatchTime 0.102653   LR 0.010000   
2022-11-03 20:59:22,472 - INFO  - Training [26][  340/  391]   Loss 0.050862   Top1 98.203125   Top5 100.000000   BatchTime 0.102440   LR 0.010000   
2022-11-03 20:59:24,438 - INFO  - Training [26][  360/  391]   Loss 0.051385   Top1 98.200955   Top5 100.000000   BatchTime 0.102209   LR 0.010000   
2022-11-03 20:59:26,428 - INFO  - Training [26][  380/  391]   Loss 0.051866   Top1 98.192845   Top5 99.997944   BatchTime 0.102067   LR 0.010000   
2022-11-03 20:59:27,747 - INFO  - ==> Top1: 98.192    Top5: 99.998    Loss: 0.052

2022-11-03 20:59:27,748 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:59:30,368 - INFO  - Validation [26][   20/   79]   Loss 0.418364   Top1 89.531250   Top5 99.531250   BatchTime 0.130960   
2022-11-03 20:59:31,237 - INFO  - Validation [26][   40/   79]   Loss 0.429948   Top1 89.921875   Top5 99.433594   BatchTime 0.087187   
2022-11-03 20:59:32,125 - INFO  - Validation [26][   60/   79]   Loss 0.425277   Top1 90.104167   Top5 99.466146   BatchTime 0.072940   
2022-11-03 20:59:33,224 - INFO  - ==> Top1: 90.230    Top5: 99.530    Loss: 0.418

2022-11-03 20:59:33,252 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 20:59:33,253 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 20:59:33,253 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.310   Top5: 99.510] Sparsity : 0.749
2022-11-03 20:59:33,322 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 20:59:33,323 - INFO  - >>>>>>>> Epoch  27
2022-11-03 20:59:33,324 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:59:36,921 - INFO  - Training [27][   20/  391]   Loss 0.043109   Top1 98.476562   Top5 100.000000   BatchTime 0.179862   LR 0.010000   
2022-11-03 20:59:38,513 - INFO  - Training [27][   40/  391]   Loss 0.052689   Top1 98.183594   Top5 100.000000   BatchTime 0.129733   LR 0.010000   
2022-11-03 20:59:40,219 - INFO  - Training [27][   60/  391]   Loss 0.051731   Top1 98.255208   Top5 100.000000   BatchTime 0.114910   LR 0.010000   
2022-11-03 20:59:41,729 - INFO  - Training [27][   80/  391]   Loss 0.050754   Top1 98.261719   Top5 100.000000   BatchTime 0.105065   LR 0.010000   
2022-11-03 20:59:43,830 - INFO  - Training [27][  100/  391]   Loss 0.051857   Top1 98.171875   Top5 100.000000   BatchTime 0.105060   LR 0.010000   
2022-11-03 20:59:45,871 - INFO  - Training [27][  120/  391]   Loss 0.052445   Top1 98.111979   Top5 100.000000   BatchTime 0.104558   LR 0.010000   
2022-11-03 20:59:47,903 - INFO  - Training [27][  140/  391]   Loss 0.054439   Top1 98.069196   Top5 99.983259   BatchTime 0.104131   LR 0.010000   
2022-11-03 20:59:49,913 - INFO  - Training [27][  160/  391]   Loss 0.054633   Top1 98.071289   Top5 99.985352   BatchTime 0.103680   LR 0.010000   
2022-11-03 20:59:51,906 - INFO  - Training [27][  180/  391]   Loss 0.055388   Top1 98.077257   Top5 99.986979   BatchTime 0.103228   LR 0.010000   
2022-11-03 20:59:53,920 - INFO  - Training [27][  200/  391]   Loss 0.056639   Top1 98.000000   Top5 99.984375   BatchTime 0.102977   LR 0.010000   
2022-11-03 20:59:55,920 - INFO  - Training [27][  220/  391]   Loss 0.056633   Top1 98.014915   Top5 99.985795   BatchTime 0.102707   LR 0.010000   
2022-11-03 20:59:57,953 - INFO  - Training [27][  240/  391]   Loss 0.056874   Top1 98.011068   Top5 99.986979   BatchTime 0.102619   LR 0.010000   
2022-11-03 20:59:59,952 - INFO  - Training [27][  260/  391]   Loss 0.056992   Top1 98.007812   Top5 99.987981   BatchTime 0.102414   LR 0.010000   
2022-11-03 21:00:01,936 - INFO  - Training [27][  280/  391]   Loss 0.057914   Top1 97.977121   Top5 99.988839   BatchTime 0.102183   LR 0.010000   
2022-11-03 21:00:03,938 - INFO  - Training [27][  300/  391]   Loss 0.058549   Top1 97.958333   Top5 99.989583   BatchTime 0.102044   LR 0.010000   
2022-11-03 21:00:05,937 - INFO  - Training [27][  320/  391]   Loss 0.058584   Top1 97.949219   Top5 99.987793   BatchTime 0.101914   LR 0.010000   
2022-11-03 21:00:07,932 - INFO  - Training [27][  340/  391]   Loss 0.058364   Top1 97.954963   Top5 99.988511   BatchTime 0.101785   LR 0.010000   
2022-11-03 21:00:09,931 - INFO  - Training [27][  360/  391]   Loss 0.059195   Top1 97.914497   Top5 99.989149   BatchTime 0.101684   LR 0.010000   
2022-11-03 21:00:11,913 - INFO  - Training [27][  380/  391]   Loss 0.059598   Top1 97.902961   Top5 99.989720   BatchTime 0.101548   LR 0.010000   
2022-11-03 21:00:13,240 - INFO  - ==> Top1: 97.902    Top5: 99.990    Loss: 0.060

2022-11-03 21:00:13,241 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:00:15,870 - INFO  - Validation [27][   20/   79]   Loss 0.420073   Top1 89.804688   Top5 99.609375   BatchTime 0.131414   
2022-11-03 21:00:16,771 - INFO  - Validation [27][   40/   79]   Loss 0.424118   Top1 89.863281   Top5 99.472656   BatchTime 0.088230   
2022-11-03 21:00:17,692 - INFO  - Validation [27][   60/   79]   Loss 0.416495   Top1 89.973958   Top5 99.505208   BatchTime 0.074173   
2022-11-03 21:00:18,810 - INFO  - ==> Top1: 89.940    Top5: 99.570    Loss: 0.410

2022-11-03 21:00:18,841 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 21:00:18,842 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 21:00:18,842 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.310   Top5: 99.510] Sparsity : 0.749
2022-11-03 21:00:18,935 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:00:18,936 - INFO  - >>>>>>>> Epoch  28
2022-11-03 21:00:18,937 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:00:22,570 - INFO  - Training [28][   20/  391]   Loss 0.061227   Top1 97.734375   Top5 100.000000   BatchTime 0.181684   LR 0.010000   
2022-11-03 21:00:24,185 - INFO  - Training [28][   40/  391]   Loss 0.054560   Top1 97.929688   Top5 100.000000   BatchTime 0.131214   LR 0.010000   
2022-11-03 21:00:25,837 - INFO  - Training [28][   60/  391]   Loss 0.060026   Top1 97.786458   Top5 100.000000   BatchTime 0.114999   LR 0.010000   
2022-11-03 21:00:27,307 - INFO  - Training [28][   80/  391]   Loss 0.059721   Top1 97.880859   Top5 100.000000   BatchTime 0.104626   LR 0.010000   
2022-11-03 21:00:29,315 - INFO  - Training [28][  100/  391]   Loss 0.059128   Top1 97.945312   Top5 100.000000   BatchTime 0.103781   LR 0.010000   
2022-11-03 21:00:31,341 - INFO  - Training [28][  120/  391]   Loss 0.062060   Top1 97.864583   Top5 99.993490   BatchTime 0.103365   LR 0.010000   
2022-11-03 21:00:33,347 - INFO  - Training [28][  140/  391]   Loss 0.061587   Top1 97.862723   Top5 99.994420   BatchTime 0.102932   LR 0.010000   
2022-11-03 21:00:35,357 - INFO  - Training [28][  160/  391]   Loss 0.063100   Top1 97.778320   Top5 99.995117   BatchTime 0.102623   LR 0.010000   
2022-11-03 21:00:37,371 - INFO  - Training [28][  180/  391]   Loss 0.063739   Top1 97.738715   Top5 99.995660   BatchTime 0.102411   LR 0.010000   
2022-11-03 21:00:39,391 - INFO  - Training [28][  200/  391]   Loss 0.064487   Top1 97.726562   Top5 99.996094   BatchTime 0.102268   LR 0.010000   
2022-11-03 21:00:41,488 - INFO  - Training [28][  220/  391]   Loss 0.064049   Top1 97.780540   Top5 99.992898   BatchTime 0.102502   LR 0.010000   
2022-11-03 21:00:43,517 - INFO  - Training [28][  240/  391]   Loss 0.064570   Top1 97.770182   Top5 99.993490   BatchTime 0.102417   LR 0.010000   
2022-11-03 21:00:45,525 - INFO  - Training [28][  260/  391]   Loss 0.065404   Top1 97.734375   Top5 99.993990   BatchTime 0.102262   LR 0.010000   
2022-11-03 21:00:47,530 - INFO  - Training [28][  280/  391]   Loss 0.066166   Top1 97.706473   Top5 99.988839   BatchTime 0.102117   LR 0.010000   
2022-11-03 21:00:49,555 - INFO  - Training [28][  300/  391]   Loss 0.065803   Top1 97.718750   Top5 99.989583   BatchTime 0.102059   LR 0.010000   
2022-11-03 21:00:51,562 - INFO  - Training [28][  320/  391]   Loss 0.066343   Top1 97.685547   Top5 99.990234   BatchTime 0.101952   LR 0.010000   
2022-11-03 21:00:53,532 - INFO  - Training [28][  340/  391]   Loss 0.067173   Top1 97.674632   Top5 99.988511   BatchTime 0.101750   LR 0.010000   
2022-11-03 21:00:55,501 - INFO  - Training [28][  360/  391]   Loss 0.067258   Top1 97.656250   Top5 99.989149   BatchTime 0.101564   LR 0.010000   
2022-11-03 21:00:57,484 - INFO  - Training [28][  380/  391]   Loss 0.068108   Top1 97.621299   Top5 99.989720   BatchTime 0.101437   LR 0.010000   
2022-11-03 21:00:58,826 - INFO  - ==> Top1: 97.610    Top5: 99.990    Loss: 0.068

2022-11-03 21:00:58,827 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:01:01,438 - INFO  - Validation [28][   20/   79]   Loss 0.423354   Top1 89.687500   Top5 99.414062   BatchTime 0.130470   
2022-11-03 21:01:02,319 - INFO  - Validation [28][   40/   79]   Loss 0.433960   Top1 89.824219   Top5 99.375000   BatchTime 0.087270   
2022-11-03 21:01:03,228 - INFO  - Validation [28][   60/   79]   Loss 0.417551   Top1 90.026042   Top5 99.492188   BatchTime 0.073327   
2022-11-03 21:01:04,318 - INFO  - ==> Top1: 89.930    Top5: 99.540    Loss: 0.413

2022-11-03 21:01:04,360 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 21:01:04,361 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 21:01:04,361 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.310   Top5: 99.510] Sparsity : 0.749
2022-11-03 21:01:04,469 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:01:04,470 - INFO  - >>>>>>>> Epoch  29
2022-11-03 21:01:04,471 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:01:08,029 - INFO  - Training [29][   20/  391]   Loss 0.059287   Top1 97.695312   Top5 99.960938   BatchTime 0.177896   LR 0.010000   
2022-11-03 21:01:09,638 - INFO  - Training [29][   40/  391]   Loss 0.067025   Top1 97.578125   Top5 99.980469   BatchTime 0.129168   LR 0.010000   
2022-11-03 21:01:11,435 - INFO  - Training [29][   60/  391]   Loss 0.064367   Top1 97.708333   Top5 99.986979   BatchTime 0.116066   LR 0.010000   
2022-11-03 21:01:12,899 - INFO  - Training [29][   80/  391]   Loss 0.063510   Top1 97.695312   Top5 99.990234   BatchTime 0.105340   LR 0.010000   
2022-11-03 21:01:14,865 - INFO  - Training [29][  100/  391]   Loss 0.064691   Top1 97.687500   Top5 99.992188   BatchTime 0.103937   LR 0.010000   
2022-11-03 21:01:16,870 - INFO  - Training [29][  120/  391]   Loss 0.063948   Top1 97.695312   Top5 99.993490   BatchTime 0.103318   LR 0.010000   
2022-11-03 21:01:18,875 - INFO  - Training [29][  140/  391]   Loss 0.064632   Top1 97.672991   Top5 99.994420   BatchTime 0.102882   LR 0.010000   
2022-11-03 21:01:20,894 - INFO  - Training [29][  160/  391]   Loss 0.066194   Top1 97.636719   Top5 99.995117   BatchTime 0.102640   LR 0.010000   
2022-11-03 21:01:22,900 - INFO  - Training [29][  180/  391]   Loss 0.067667   Top1 97.591146   Top5 99.995660   BatchTime 0.102380   LR 0.010000   
2022-11-03 21:01:24,911 - INFO  - Training [29][  200/  391]   Loss 0.068670   Top1 97.566406   Top5 99.996094   BatchTime 0.102197   LR 0.010000   
2022-11-03 21:01:26,926 - INFO  - Training [29][  220/  391]   Loss 0.069139   Top1 97.560369   Top5 99.996449   BatchTime 0.102064   LR 0.010000   
2022-11-03 21:01:28,919 - INFO  - Training [29][  240/  391]   Loss 0.068458   Top1 97.604167   Top5 99.996745   BatchTime 0.101862   LR 0.010000   
2022-11-03 21:01:30,914 - INFO  - Training [29][  260/  391]   Loss 0.068562   Top1 97.587139   Top5 99.996995   BatchTime 0.101703   LR 0.010000   
2022-11-03 21:01:32,903 - INFO  - Training [29][  280/  391]   Loss 0.069110   Top1 97.564174   Top5 99.991629   BatchTime 0.101540   LR 0.010000   
2022-11-03 21:01:34,903 - INFO  - Training [29][  300/  391]   Loss 0.069031   Top1 97.578125   Top5 99.992188   BatchTime 0.101438   LR 0.010000   
2022-11-03 21:01:36,901 - INFO  - Training [29][  320/  391]   Loss 0.069092   Top1 97.568359   Top5 99.992676   BatchTime 0.101340   LR 0.010000   
2022-11-03 21:01:38,866 - INFO  - Training [29][  340/  391]   Loss 0.069182   Top1 97.573529   Top5 99.993107   BatchTime 0.101158   LR 0.010000   
2022-11-03 21:01:40,848 - INFO  - Training [29][  360/  391]   Loss 0.069846   Top1 97.556424   Top5 99.993490   BatchTime 0.101045   LR 0.010000   
2022-11-03 21:01:42,835 - INFO  - Training [29][  380/  391]   Loss 0.070343   Top1 97.549342   Top5 99.993832   BatchTime 0.100954   LR 0.010000   
2022-11-03 21:01:44,171 - INFO  - ==> Top1: 97.524    Top5: 99.994    Loss: 0.071

2022-11-03 21:01:44,172 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:01:46,780 - INFO  - Validation [29][   20/   79]   Loss 0.425591   Top1 90.195312   Top5 99.570312   BatchTime 0.130282   
2022-11-03 21:01:47,684 - INFO  - Validation [29][   40/   79]   Loss 0.438726   Top1 89.824219   Top5 99.375000   BatchTime 0.087759   
2022-11-03 21:01:48,550 - INFO  - Validation [29][   60/   79]   Loss 0.423894   Top1 89.973958   Top5 99.440104   BatchTime 0.072925   
2022-11-03 21:01:49,671 - INFO  - ==> Top1: 90.010    Top5: 99.490    Loss: 0.421

2022-11-03 21:01:49,700 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 21:01:49,700 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 21:01:49,700 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.310   Top5: 99.510] Sparsity : 0.749
2022-11-03 21:01:49,813 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:01:49,813 - INFO  - >>>>>>>> Epoch  30
2022-11-03 21:01:49,815 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:01:53,267 - INFO  - Training [30][   20/  391]   Loss 0.067143   Top1 97.617188   Top5 100.000000   BatchTime 0.172566   LR 0.001000   
2022-11-03 21:01:54,940 - INFO  - Training [30][   40/  391]   Loss 0.060506   Top1 97.949219   Top5 100.000000   BatchTime 0.128129   LR 0.001000   
2022-11-03 21:01:56,607 - INFO  - Training [30][   60/  391]   Loss 0.059230   Top1 97.942708   Top5 100.000000   BatchTime 0.113201   LR 0.001000   
2022-11-03 21:01:58,322 - INFO  - Training [30][   80/  391]   Loss 0.060688   Top1 97.841797   Top5 100.000000   BatchTime 0.106331   LR 0.001000   
2022-11-03 21:02:00,212 - INFO  - Training [30][  100/  391]   Loss 0.062242   Top1 97.796875   Top5 100.000000   BatchTime 0.103963   LR 0.001000   
2022-11-03 21:02:02,234 - INFO  - Training [30][  120/  391]   Loss 0.061854   Top1 97.819010   Top5 99.993490   BatchTime 0.103487   LR 0.001000   
2022-11-03 21:02:04,230 - INFO  - Training [30][  140/  391]   Loss 0.060848   Top1 97.851562   Top5 99.994420   BatchTime 0.102959   LR 0.001000   
2022-11-03 21:02:06,238 - INFO  - Training [30][  160/  391]   Loss 0.059515   Top1 97.871094   Top5 99.995117   BatchTime 0.102637   LR 0.001000   
2022-11-03 21:02:08,228 - INFO  - Training [30][  180/  391]   Loss 0.058750   Top1 97.925347   Top5 99.995660   BatchTime 0.102293   LR 0.001000   
2022-11-03 21:02:10,220 - INFO  - Training [30][  200/  391]   Loss 0.059286   Top1 97.882812   Top5 99.996094   BatchTime 0.102022   LR 0.001000   
2022-11-03 21:02:12,237 - INFO  - Training [30][  220/  391]   Loss 0.059133   Top1 97.890625   Top5 99.996449   BatchTime 0.101916   LR 0.001000   
2022-11-03 21:02:14,260 - INFO  - Training [30][  240/  391]   Loss 0.058510   Top1 97.906901   Top5 99.996745   BatchTime 0.101852   LR 0.001000   
2022-11-03 21:02:16,386 - INFO  - Training [30][  260/  391]   Loss 0.058230   Top1 97.935697   Top5 99.996995   BatchTime 0.102194   LR 0.001000   
2022-11-03 21:02:18,396 - INFO  - Training [30][  280/  391]   Loss 0.057778   Top1 97.957589   Top5 99.997210   BatchTime 0.102071   LR 0.001000   
2022-11-03 21:02:20,412 - INFO  - Training [30][  300/  391]   Loss 0.057251   Top1 97.971354   Top5 99.997396   BatchTime 0.101986   LR 0.001000   
2022-11-03 21:02:22,439 - INFO  - Training [30][  320/  391]   Loss 0.057055   Top1 97.976074   Top5 99.997559   BatchTime 0.101947   LR 0.001000   
2022-11-03 21:02:24,413 - INFO  - Training [30][  340/  391]   Loss 0.057207   Top1 97.964154   Top5 99.997702   BatchTime 0.101757   LR 0.001000   
2022-11-03 21:02:26,388 - INFO  - Training [30][  360/  391]   Loss 0.057715   Top1 97.936198   Top5 99.997830   BatchTime 0.101589   LR 0.001000   
2022-11-03 21:02:28,353 - INFO  - Training [30][  380/  391]   Loss 0.057474   Top1 97.958470   Top5 99.997944   BatchTime 0.101413   LR 0.001000   
2022-11-03 21:02:29,687 - INFO  - ==> Top1: 97.972    Top5: 99.998    Loss: 0.057

2022-11-03 21:02:29,688 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:02:32,346 - INFO  - Validation [30][   20/   79]   Loss 0.382452   Top1 90.937500   Top5 99.726562   BatchTime 0.132811   
2022-11-03 21:02:33,253 - INFO  - Validation [30][   40/   79]   Loss 0.400046   Top1 90.625000   Top5 99.589844   BatchTime 0.089070   
2022-11-03 21:02:34,165 - INFO  - Validation [30][   60/   79]   Loss 0.390546   Top1 90.651042   Top5 99.622396   BatchTime 0.074582   
2022-11-03 21:02:35,271 - INFO  - ==> Top1: 90.560    Top5: 99.640    Loss: 0.384

2022-11-03 21:02:35,302 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.560   Top5: 99.640] Sparsity : 0.773
2022-11-03 21:02:35,303 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 21:02:35,303 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.310   Top5: 99.620] Sparsity : 0.745
2022-11-03 21:02:35,493 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 21:02:35,494 - INFO  - >>>>>>>> Epoch  31
2022-11-03 21:02:35,494 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:02:39,043 - INFO  - Training [31][   20/  391]   Loss 0.054912   Top1 98.203125   Top5 100.000000   BatchTime 0.177439   LR 0.001000   
2022-11-03 21:02:40,650 - INFO  - Training [31][   40/  391]   Loss 0.052882   Top1 98.222656   Top5 100.000000   BatchTime 0.128875   LR 0.001000   
2022-11-03 21:02:42,294 - INFO  - Training [31][   60/  391]   Loss 0.051548   Top1 98.190104   Top5 100.000000   BatchTime 0.113314   LR 0.001000   
2022-11-03 21:02:43,876 - INFO  - Training [31][   80/  391]   Loss 0.052141   Top1 98.193359   Top5 100.000000   BatchTime 0.104761   LR 0.001000   
2022-11-03 21:02:45,763 - INFO  - Training [31][  100/  391]   Loss 0.051799   Top1 98.187500   Top5 100.000000   BatchTime 0.102678   LR 0.001000   
2022-11-03 21:02:47,768 - INFO  - Training [31][  120/  391]   Loss 0.050669   Top1 98.235677   Top5 100.000000   BatchTime 0.102279   LR 0.001000   
2022-11-03 21:02:49,761 - INFO  - Training [31][  140/  391]   Loss 0.050855   Top1 98.242188   Top5 100.000000   BatchTime 0.101903   LR 0.001000   
2022-11-03 21:02:51,760 - INFO  - Training [31][  160/  391]   Loss 0.051161   Top1 98.193359   Top5 100.000000   BatchTime 0.101659   LR 0.001000   
2022-11-03 21:02:53,778 - INFO  - Training [31][  180/  391]   Loss 0.051043   Top1 98.224826   Top5 100.000000   BatchTime 0.101574   LR 0.001000   
2022-11-03 21:02:55,784 - INFO  - Training [31][  200/  391]   Loss 0.050973   Top1 98.214844   Top5 100.000000   BatchTime 0.101443   LR 0.001000   
2022-11-03 21:02:57,793 - INFO  - Training [31][  220/  391]   Loss 0.051040   Top1 98.213778   Top5 100.000000   BatchTime 0.101354   LR 0.001000   
2022-11-03 21:02:59,795 - INFO  - Training [31][  240/  391]   Loss 0.050788   Top1 98.225911   Top5 100.000000   BatchTime 0.101251   LR 0.001000   
2022-11-03 21:03:01,793 - INFO  - Training [31][  260/  391]   Loss 0.050233   Top1 98.239183   Top5 100.000000   BatchTime 0.101146   LR 0.001000   
2022-11-03 21:03:03,790 - INFO  - Training [31][  280/  391]   Loss 0.050834   Top1 98.214286   Top5 100.000000   BatchTime 0.101052   LR 0.001000   
2022-11-03 21:03:05,805 - INFO  - Training [31][  300/  391]   Loss 0.050612   Top1 98.223958   Top5 100.000000   BatchTime 0.101033   LR 0.001000   
2022-11-03 21:03:07,812 - INFO  - Training [31][  320/  391]   Loss 0.049902   Top1 98.242188   Top5 100.000000   BatchTime 0.100989   LR 0.001000   
2022-11-03 21:03:09,825 - INFO  - Training [31][  340/  391]   Loss 0.049571   Top1 98.253676   Top5 100.000000   BatchTime 0.100969   LR 0.001000   
2022-11-03 21:03:11,801 - INFO  - Training [31][  360/  391]   Loss 0.049885   Top1 98.246528   Top5 100.000000   BatchTime 0.100849   LR 0.001000   
2022-11-03 21:03:13,778 - INFO  - Training [31][  380/  391]   Loss 0.050142   Top1 98.225740   Top5 100.000000   BatchTime 0.100742   LR 0.001000   
2022-11-03 21:03:15,055 - INFO  - ==> Top1: 98.238    Top5: 100.000    Loss: 0.050

2022-11-03 21:03:15,056 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:03:17,667 - INFO  - Validation [31][   20/   79]   Loss 0.374470   Top1 90.703125   Top5 99.687500   BatchTime 0.130497   
2022-11-03 21:03:18,560 - INFO  - Validation [31][   40/   79]   Loss 0.400543   Top1 90.332031   Top5 99.472656   BatchTime 0.087584   
2022-11-03 21:03:19,460 - INFO  - Validation [31][   60/   79]   Loss 0.390636   Top1 90.403646   Top5 99.531250   BatchTime 0.073383   
2022-11-03 21:03:20,567 - INFO  - ==> Top1: 90.340    Top5: 99.560    Loss: 0.386

2022-11-03 21:03:20,599 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.560   Top5: 99.640] Sparsity : 0.773
2022-11-03 21:03:20,600 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 21:03:20,600 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.340   Top5: 99.560] Sparsity : 0.774
2022-11-03 21:03:20,668 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:03:20,668 - INFO  - >>>>>>>> Epoch  32
2022-11-03 21:03:20,669 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:03:24,010 - INFO  - Training [32][   20/  391]   Loss 0.045021   Top1 98.554688   Top5 100.000000   BatchTime 0.167046   LR 0.001000   
2022-11-03 21:03:25,734 - INFO  - Training [32][   40/  391]   Loss 0.045991   Top1 98.437500   Top5 100.000000   BatchTime 0.126617   LR 0.001000   
2022-11-03 21:03:27,369 - INFO  - Training [32][   60/  391]   Loss 0.047379   Top1 98.359375   Top5 100.000000   BatchTime 0.111671   LR 0.001000   
2022-11-03 21:03:29,120 - INFO  - Training [32][   80/  391]   Loss 0.048488   Top1 98.310547   Top5 100.000000   BatchTime 0.105638   LR 0.001000   
2022-11-03 21:03:30,913 - INFO  - Training [32][  100/  391]   Loss 0.049335   Top1 98.304688   Top5 100.000000   BatchTime 0.102443   LR 0.001000   
2022-11-03 21:03:32,931 - INFO  - Training [32][  120/  391]   Loss 0.048104   Top1 98.359375   Top5 99.993490   BatchTime 0.102179   LR 0.001000   
2022-11-03 21:03:34,949 - INFO  - Training [32][  140/  391]   Loss 0.047373   Top1 98.398438   Top5 99.994420   BatchTime 0.101997   LR 0.001000   
2022-11-03 21:03:36,964 - INFO  - Training [32][  160/  391]   Loss 0.048311   Top1 98.334961   Top5 99.995117   BatchTime 0.101845   LR 0.001000   
2022-11-03 21:03:38,963 - INFO  - Training [32][  180/  391]   Loss 0.048975   Top1 98.328993   Top5 99.995660   BatchTime 0.101633   LR 0.001000   
2022-11-03 21:03:40,981 - INFO  - Training [32][  200/  391]   Loss 0.049109   Top1 98.343750   Top5 99.996094   BatchTime 0.101556   LR 0.001000   
2022-11-03 21:03:42,982 - INFO  - Training [32][  220/  391]   Loss 0.048906   Top1 98.362926   Top5 99.996449   BatchTime 0.101420   LR 0.001000   
2022-11-03 21:03:44,984 - INFO  - Training [32][  240/  391]   Loss 0.048773   Top1 98.362630   Top5 99.996745   BatchTime 0.101310   LR 0.001000   
2022-11-03 21:03:47,000 - INFO  - Training [32][  260/  391]   Loss 0.048534   Top1 98.362380   Top5 99.996995   BatchTime 0.101272   LR 0.001000   
2022-11-03 21:03:49,002 - INFO  - Training [32][  280/  391]   Loss 0.047688   Top1 98.392857   Top5 99.997210   BatchTime 0.101186   LR 0.001000   
2022-11-03 21:03:51,010 - INFO  - Training [32][  300/  391]   Loss 0.047686   Top1 98.401042   Top5 99.997396   BatchTime 0.101134   LR 0.001000   
2022-11-03 21:03:53,114 - INFO  - Training [32][  320/  391]   Loss 0.047344   Top1 98.400879   Top5 99.997559   BatchTime 0.101387   LR 0.001000   
2022-11-03 21:03:55,104 - INFO  - Training [32][  340/  391]   Loss 0.047845   Top1 98.375460   Top5 99.993107   BatchTime 0.101279   LR 0.001000   
2022-11-03 21:03:57,073 - INFO  - Training [32][  360/  391]   Loss 0.048026   Top1 98.372396   Top5 99.991319   BatchTime 0.101121   LR 0.001000   
2022-11-03 21:03:59,061 - INFO  - Training [32][  380/  391]   Loss 0.047992   Top1 98.359375   Top5 99.991776   BatchTime 0.101028   LR 0.001000   
2022-11-03 21:04:00,387 - INFO  - ==> Top1: 98.372    Top5: 99.992    Loss: 0.048

2022-11-03 21:04:00,388 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:04:03,023 - INFO  - Validation [32][   20/   79]   Loss 0.364879   Top1 90.507812   Top5 99.570312   BatchTime 0.131686   
2022-11-03 21:04:03,937 - INFO  - Validation [32][   40/   79]   Loss 0.389947   Top1 90.585938   Top5 99.531250   BatchTime 0.088702   
2022-11-03 21:04:04,800 - INFO  - Validation [32][   60/   79]   Loss 0.387309   Top1 90.572917   Top5 99.609375   BatchTime 0.073509   
2022-11-03 21:04:05,894 - INFO  - ==> Top1: 90.670    Top5: 99.630    Loss: 0.383

2022-11-03 21:04:05,935 - INFO  - Scoreboard best 1 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:04:05,936 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.560   Top5: 99.640] Sparsity : 0.773
2022-11-03 21:04:05,936 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.400   Top5: 99.550] Sparsity : 0.742
2022-11-03 21:04:06,186 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 21:04:06,187 - INFO  - >>>>>>>> Epoch  33
2022-11-03 21:04:06,188 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:04:09,617 - INFO  - Training [33][   20/  391]   Loss 0.053940   Top1 98.007812   Top5 100.000000   BatchTime 0.171438   LR 0.001000   
2022-11-03 21:04:11,339 - INFO  - Training [33][   40/  391]   Loss 0.049708   Top1 98.261719   Top5 99.960938   BatchTime 0.128774   LR 0.001000   
2022-11-03 21:04:12,998 - INFO  - Training [33][   60/  391]   Loss 0.047650   Top1 98.333333   Top5 99.973958   BatchTime 0.113502   LR 0.001000   
2022-11-03 21:04:14,632 - INFO  - Training [33][   80/  391]   Loss 0.048417   Top1 98.320312   Top5 99.980469   BatchTime 0.105544   LR 0.001000   
2022-11-03 21:04:16,455 - INFO  - Training [33][  100/  391]   Loss 0.046986   Top1 98.312500   Top5 99.984375   BatchTime 0.102662   LR 0.001000   
2022-11-03 21:04:18,474 - INFO  - Training [33][  120/  391]   Loss 0.047391   Top1 98.261719   Top5 99.986979   BatchTime 0.102383   LR 0.001000   
2022-11-03 21:04:20,503 - INFO  - Training [33][  140/  391]   Loss 0.046504   Top1 98.314732   Top5 99.983259   BatchTime 0.102248   LR 0.001000   
2022-11-03 21:04:22,509 - INFO  - Training [33][  160/  391]   Loss 0.046249   Top1 98.359375   Top5 99.985352   BatchTime 0.102004   LR 0.001000   
2022-11-03 21:04:24,517 - INFO  - Training [33][  180/  391]   Loss 0.045996   Top1 98.359375   Top5 99.986979   BatchTime 0.101823   LR 0.001000   
2022-11-03 21:04:26,529 - INFO  - Training [33][  200/  391]   Loss 0.045873   Top1 98.378906   Top5 99.988281   BatchTime 0.101703   LR 0.001000   
2022-11-03 21:04:28,535 - INFO  - Training [33][  220/  391]   Loss 0.044787   Top1 98.405540   Top5 99.989347   BatchTime 0.101573   LR 0.001000   
2022-11-03 21:04:30,547 - INFO  - Training [33][  240/  391]   Loss 0.044780   Top1 98.398438   Top5 99.990234   BatchTime 0.101493   LR 0.001000   
2022-11-03 21:04:32,556 - INFO  - Training [33][  260/  391]   Loss 0.044938   Top1 98.380409   Top5 99.990986   BatchTime 0.101411   LR 0.001000   
2022-11-03 21:04:34,568 - INFO  - Training [33][  280/  391]   Loss 0.046034   Top1 98.339844   Top5 99.991629   BatchTime 0.101354   LR 0.001000   
2022-11-03 21:04:36,587 - INFO  - Training [33][  300/  391]   Loss 0.045557   Top1 98.351562   Top5 99.992188   BatchTime 0.101327   LR 0.001000   
2022-11-03 21:04:38,603 - INFO  - Training [33][  320/  391]   Loss 0.046122   Top1 98.342285   Top5 99.992676   BatchTime 0.101294   LR 0.001000   
2022-11-03 21:04:40,595 - INFO  - Training [33][  340/  391]   Loss 0.045960   Top1 98.352482   Top5 99.993107   BatchTime 0.101195   LR 0.001000   
2022-11-03 21:04:42,564 - INFO  - Training [33][  360/  391]   Loss 0.045965   Top1 98.352865   Top5 99.993490   BatchTime 0.101041   LR 0.001000   
2022-11-03 21:04:44,535 - INFO  - Training [33][  380/  391]   Loss 0.046164   Top1 98.353207   Top5 99.993832   BatchTime 0.100910   LR 0.001000   
2022-11-03 21:04:45,871 - INFO  - ==> Top1: 98.346    Top5: 99.994    Loss: 0.046

2022-11-03 21:04:45,872 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:04:48,507 - INFO  - Validation [33][   20/   79]   Loss 0.364607   Top1 91.328125   Top5 99.492188   BatchTime 0.131687   
2022-11-03 21:04:49,399 - INFO  - Validation [33][   40/   79]   Loss 0.392297   Top1 90.683594   Top5 99.453125   BatchTime 0.088149   
2022-11-03 21:04:50,310 - INFO  - Validation [33][   60/   79]   Loss 0.386506   Top1 90.781250   Top5 99.531250   BatchTime 0.073941   
2022-11-03 21:04:51,324 - INFO  - ==> Top1: 90.700    Top5: 99.580    Loss: 0.382

2022-11-03 21:04:51,355 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:04:51,356 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:04:51,356 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.560   Top5: 99.640] Sparsity : 0.773
2022-11-03 21:04:51,555 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 21:04:51,556 - INFO  - >>>>>>>> Epoch  34
2022-11-03 21:04:51,557 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:04:55,030 - INFO  - Training [34][   20/  391]   Loss 0.044934   Top1 98.398438   Top5 100.000000   BatchTime 0.173655   LR 0.001000   
2022-11-03 21:04:56,712 - INFO  - Training [34][   40/  391]   Loss 0.045948   Top1 98.378906   Top5 100.000000   BatchTime 0.128879   LR 0.001000   
2022-11-03 21:04:58,399 - INFO  - Training [34][   60/  391]   Loss 0.043569   Top1 98.476562   Top5 100.000000   BatchTime 0.114040   LR 0.001000   
2022-11-03 21:05:00,092 - INFO  - Training [34][   80/  391]   Loss 0.043871   Top1 98.457031   Top5 100.000000   BatchTime 0.106691   LR 0.001000   
2022-11-03 21:05:01,846 - INFO  - Training [34][  100/  391]   Loss 0.044239   Top1 98.437500   Top5 100.000000   BatchTime 0.102894   LR 0.001000   
2022-11-03 21:05:03,889 - INFO  - Training [34][  120/  391]   Loss 0.044479   Top1 98.424479   Top5 100.000000   BatchTime 0.102762   LR 0.001000   
2022-11-03 21:05:05,934 - INFO  - Training [34][  140/  391]   Loss 0.044689   Top1 98.443080   Top5 100.000000   BatchTime 0.102690   LR 0.001000   
2022-11-03 21:05:07,957 - INFO  - Training [34][  160/  391]   Loss 0.044341   Top1 98.447266   Top5 100.000000   BatchTime 0.102500   LR 0.001000   
2022-11-03 21:05:09,951 - INFO  - Training [34][  180/  391]   Loss 0.043780   Top1 98.485243   Top5 100.000000   BatchTime 0.102190   LR 0.001000   
2022-11-03 21:05:11,979 - INFO  - Training [34][  200/  391]   Loss 0.043648   Top1 98.484375   Top5 100.000000   BatchTime 0.102107   LR 0.001000   
2022-11-03 21:05:14,001 - INFO  - Training [34][  220/  391]   Loss 0.044040   Top1 98.473011   Top5 100.000000   BatchTime 0.102015   LR 0.001000   
2022-11-03 21:05:16,023 - INFO  - Training [34][  240/  391]   Loss 0.043683   Top1 98.483073   Top5 100.000000   BatchTime 0.101940   LR 0.001000   
2022-11-03 21:05:18,040 - INFO  - Training [34][  260/  391]   Loss 0.043784   Top1 98.491587   Top5 100.000000   BatchTime 0.101858   LR 0.001000   
2022-11-03 21:05:20,046 - INFO  - Training [34][  280/  391]   Loss 0.043540   Top1 98.496094   Top5 100.000000   BatchTime 0.101746   LR 0.001000   
2022-11-03 21:05:22,088 - INFO  - Training [34][  300/  391]   Loss 0.043659   Top1 98.479167   Top5 100.000000   BatchTime 0.101767   LR 0.001000   
2022-11-03 21:05:24,093 - INFO  - Training [34][  320/  391]   Loss 0.043685   Top1 98.496094   Top5 100.000000   BatchTime 0.101673   LR 0.001000   
2022-11-03 21:05:26,087 - INFO  - Training [34][  340/  391]   Loss 0.043937   Top1 98.467371   Top5 100.000000   BatchTime 0.101558   LR 0.001000   
2022-11-03 21:05:28,076 - INFO  - Training [34][  360/  391]   Loss 0.044614   Top1 98.428819   Top5 100.000000   BatchTime 0.101439   LR 0.001000   
2022-11-03 21:05:30,070 - INFO  - Training [34][  380/  391]   Loss 0.044630   Top1 98.435444   Top5 100.000000   BatchTime 0.101348   LR 0.001000   
2022-11-03 21:05:31,389 - INFO  - ==> Top1: 98.432    Top5: 100.000    Loss: 0.045

2022-11-03 21:05:31,390 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:05:34,167 - INFO  - Validation [34][   20/   79]   Loss 0.377163   Top1 90.585938   Top5 99.687500   BatchTime 0.138799   
2022-11-03 21:05:35,052 - INFO  - Validation [34][   40/   79]   Loss 0.395640   Top1 90.507812   Top5 99.550781   BatchTime 0.091523   
2022-11-03 21:05:35,942 - INFO  - Validation [34][   60/   79]   Loss 0.389219   Top1 90.546875   Top5 99.622396   BatchTime 0.075837   
2022-11-03 21:05:37,023 - INFO  - ==> Top1: 90.580    Top5: 99.650    Loss: 0.385

2022-11-03 21:05:37,067 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:05:37,068 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:05:37,068 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.580   Top5: 99.650] Sparsity : 0.774
2022-11-03 21:05:37,165 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:05:37,165 - INFO  - >>>>>>>> Epoch  35
2022-11-03 21:05:37,166 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:05:40,679 - INFO  - Training [35][   20/  391]   Loss 0.036463   Top1 98.945312   Top5 100.000000   BatchTime 0.175678   LR 0.001000   
2022-11-03 21:05:42,383 - INFO  - Training [35][   40/  391]   Loss 0.039079   Top1 98.769531   Top5 100.000000   BatchTime 0.130429   LR 0.001000   
2022-11-03 21:05:44,001 - INFO  - Training [35][   60/  391]   Loss 0.039054   Top1 98.671875   Top5 100.000000   BatchTime 0.113910   LR 0.001000   
2022-11-03 21:05:45,705 - INFO  - Training [35][   80/  391]   Loss 0.037925   Top1 98.769531   Top5 100.000000   BatchTime 0.106740   LR 0.001000   
2022-11-03 21:05:47,338 - INFO  - Training [35][  100/  391]   Loss 0.039292   Top1 98.718750   Top5 99.992188   BatchTime 0.101722   LR 0.001000   
2022-11-03 21:05:49,346 - INFO  - Training [35][  120/  391]   Loss 0.040981   Top1 98.626302   Top5 99.993490   BatchTime 0.101496   LR 0.001000   
2022-11-03 21:05:51,352 - INFO  - Training [35][  140/  391]   Loss 0.041091   Top1 98.655134   Top5 99.994420   BatchTime 0.101328   LR 0.001000   
2022-11-03 21:05:53,380 - INFO  - Training [35][  160/  391]   Loss 0.041070   Top1 98.608398   Top5 99.995117   BatchTime 0.101334   LR 0.001000   
2022-11-03 21:05:55,388 - INFO  - Training [35][  180/  391]   Loss 0.040569   Top1 98.650174   Top5 99.995660   BatchTime 0.101233   LR 0.001000   
2022-11-03 21:05:57,402 - INFO  - Training [35][  200/  391]   Loss 0.040106   Top1 98.671875   Top5 99.996094   BatchTime 0.101178   LR 0.001000   
2022-11-03 21:05:59,419 - INFO  - Training [35][  220/  391]   Loss 0.040277   Top1 98.654119   Top5 99.996449   BatchTime 0.101150   LR 0.001000   
2022-11-03 21:06:01,433 - INFO  - Training [35][  240/  391]   Loss 0.040796   Top1 98.616536   Top5 99.996745   BatchTime 0.101111   LR 0.001000   
2022-11-03 21:06:03,426 - INFO  - Training [35][  260/  391]   Loss 0.040822   Top1 98.617788   Top5 99.996995   BatchTime 0.100999   LR 0.001000   
2022-11-03 21:06:05,431 - INFO  - Training [35][  280/  391]   Loss 0.040901   Top1 98.630022   Top5 99.997210   BatchTime 0.100945   LR 0.001000   
2022-11-03 21:06:07,442 - INFO  - Training [35][  300/  391]   Loss 0.040773   Top1 98.638021   Top5 99.997396   BatchTime 0.100917   LR 0.001000   
2022-11-03 21:06:09,449 - INFO  - Training [35][  320/  391]   Loss 0.040862   Top1 98.645020   Top5 99.997559   BatchTime 0.100882   LR 0.001000   
2022-11-03 21:06:11,425 - INFO  - Training [35][  340/  391]   Loss 0.040651   Top1 98.658088   Top5 99.997702   BatchTime 0.100761   LR 0.001000   
2022-11-03 21:06:13,415 - INFO  - Training [35][  360/  391]   Loss 0.041276   Top1 98.628472   Top5 99.997830   BatchTime 0.100691   LR 0.001000   
2022-11-03 21:06:15,404 - INFO  - Training [35][  380/  391]   Loss 0.041185   Top1 98.628701   Top5 99.997944   BatchTime 0.100625   LR 0.001000   
2022-11-03 21:06:16,714 - INFO  - ==> Top1: 98.628    Top5: 99.998    Loss: 0.041

2022-11-03 21:06:16,715 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:06:19,322 - INFO  - Validation [35][   20/   79]   Loss 0.379110   Top1 90.781250   Top5 99.687500   BatchTime 0.130237   
2022-11-03 21:06:20,185 - INFO  - Validation [35][   40/   79]   Loss 0.399720   Top1 90.625000   Top5 99.550781   BatchTime 0.086708   
2022-11-03 21:06:21,102 - INFO  - Validation [35][   60/   79]   Loss 0.388504   Top1 90.898438   Top5 99.622396   BatchTime 0.073077   
2022-11-03 21:06:22,203 - INFO  - ==> Top1: 90.830    Top5: 99.660    Loss: 0.382

2022-11-03 21:06:22,242 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:06:22,243 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:06:22,243 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:06:22,417 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 21:06:22,417 - INFO  - >>>>>>>> Epoch  36
2022-11-03 21:06:22,418 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:06:25,905 - INFO  - Training [36][   20/  391]   Loss 0.043593   Top1 98.320312   Top5 100.000000   BatchTime 0.174359   LR 0.001000   
2022-11-03 21:06:27,530 - INFO  - Training [36][   40/  391]   Loss 0.040606   Top1 98.554688   Top5 100.000000   BatchTime 0.127802   LR 0.001000   
2022-11-03 21:06:29,169 - INFO  - Training [36][   60/  391]   Loss 0.038144   Top1 98.684896   Top5 100.000000   BatchTime 0.112517   LR 0.001000   
2022-11-03 21:06:30,937 - INFO  - Training [36][   80/  391]   Loss 0.039035   Top1 98.632812   Top5 100.000000   BatchTime 0.106481   LR 0.001000   
2022-11-03 21:06:32,404 - INFO  - Training [36][  100/  391]   Loss 0.038312   Top1 98.710938   Top5 100.000000   BatchTime 0.099862   LR 0.001000   
2022-11-03 21:06:34,410 - INFO  - Training [36][  120/  391]   Loss 0.038117   Top1 98.717448   Top5 100.000000   BatchTime 0.099934   LR 0.001000   
2022-11-03 21:06:36,423 - INFO  - Training [36][  140/  391]   Loss 0.040326   Top1 98.632812   Top5 100.000000   BatchTime 0.100036   LR 0.001000   
2022-11-03 21:06:38,438 - INFO  - Training [36][  160/  391]   Loss 0.041021   Top1 98.608398   Top5 100.000000   BatchTime 0.100121   LR 0.001000   
2022-11-03 21:06:40,439 - INFO  - Training [36][  180/  391]   Loss 0.040793   Top1 98.637153   Top5 100.000000   BatchTime 0.100116   LR 0.001000   
2022-11-03 21:06:42,476 - INFO  - Training [36][  200/  391]   Loss 0.041720   Top1 98.582031   Top5 100.000000   BatchTime 0.100287   LR 0.001000   
2022-11-03 21:06:44,481 - INFO  - Training [36][  220/  391]   Loss 0.041217   Top1 98.597301   Top5 100.000000   BatchTime 0.100285   LR 0.001000   
2022-11-03 21:06:46,473 - INFO  - Training [36][  240/  391]   Loss 0.040983   Top1 98.606771   Top5 100.000000   BatchTime 0.100226   LR 0.001000   
2022-11-03 21:06:48,488 - INFO  - Training [36][  260/  391]   Loss 0.041517   Top1 98.590745   Top5 100.000000   BatchTime 0.100269   LR 0.001000   
2022-11-03 21:06:50,481 - INFO  - Training [36][  280/  391]   Loss 0.041254   Top1 98.613281   Top5 100.000000   BatchTime 0.100224   LR 0.001000   
2022-11-03 21:06:52,490 - INFO  - Training [36][  300/  391]   Loss 0.041966   Top1 98.583333   Top5 100.000000   BatchTime 0.100239   LR 0.001000   
2022-11-03 21:06:54,503 - INFO  - Training [36][  320/  391]   Loss 0.042318   Top1 98.566895   Top5 100.000000   BatchTime 0.100263   LR 0.001000   
2022-11-03 21:06:56,495 - INFO  - Training [36][  340/  391]   Loss 0.042558   Top1 98.554688   Top5 100.000000   BatchTime 0.100224   LR 0.001000   
2022-11-03 21:06:58,456 - INFO  - Training [36][  360/  391]   Loss 0.042431   Top1 98.563368   Top5 100.000000   BatchTime 0.100104   LR 0.001000   
2022-11-03 21:07:00,433 - INFO  - Training [36][  380/  391]   Loss 0.042616   Top1 98.546464   Top5 100.000000   BatchTime 0.100038   LR 0.001000   
2022-11-03 21:07:01,740 - INFO  - ==> Top1: 98.548    Top5: 100.000    Loss: 0.043

2022-11-03 21:07:01,741 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:07:04,357 - INFO  - Validation [36][   20/   79]   Loss 0.378340   Top1 90.742188   Top5 99.570312   BatchTime 0.130733   
2022-11-03 21:07:05,256 - INFO  - Validation [36][   40/   79]   Loss 0.399663   Top1 90.566406   Top5 99.511719   BatchTime 0.087855   
2022-11-03 21:07:06,144 - INFO  - Validation [36][   60/   79]   Loss 0.390419   Top1 90.781250   Top5 99.596354   BatchTime 0.073372   
2022-11-03 21:07:07,226 - INFO  - ==> Top1: 90.660    Top5: 99.630    Loss: 0.387

2022-11-03 21:07:07,259 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:07:07,260 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:07:07,260 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:07:07,358 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:07:07,358 - INFO  - >>>>>>>> Epoch  37
2022-11-03 21:07:07,360 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:07:11,098 - INFO  - Training [37][   20/  391]   Loss 0.054746   Top1 97.890625   Top5 100.000000   BatchTime 0.186911   LR 0.001000   
2022-11-03 21:07:12,692 - INFO  - Training [37][   40/  391]   Loss 0.044870   Top1 98.378906   Top5 100.000000   BatchTime 0.133298   LR 0.001000   
2022-11-03 21:07:14,377 - INFO  - Training [37][   60/  391]   Loss 0.043301   Top1 98.528646   Top5 100.000000   BatchTime 0.116946   LR 0.001000   
2022-11-03 21:07:16,061 - INFO  - Training [37][   80/  391]   Loss 0.044732   Top1 98.476562   Top5 100.000000   BatchTime 0.108764   LR 0.001000   
2022-11-03 21:07:17,668 - INFO  - Training [37][  100/  391]   Loss 0.043134   Top1 98.539062   Top5 100.000000   BatchTime 0.103082   LR 0.001000   
2022-11-03 21:07:19,613 - INFO  - Training [37][  120/  391]   Loss 0.042325   Top1 98.567708   Top5 100.000000   BatchTime 0.102102   LR 0.001000   
2022-11-03 21:07:21,623 - INFO  - Training [37][  140/  391]   Loss 0.041649   Top1 98.582589   Top5 100.000000   BatchTime 0.101875   LR 0.001000   
2022-11-03 21:07:23,618 - INFO  - Training [37][  160/  391]   Loss 0.042170   Top1 98.549805   Top5 100.000000   BatchTime 0.101608   LR 0.001000   
2022-11-03 21:07:25,616 - INFO  - Training [37][  180/  391]   Loss 0.041677   Top1 98.554688   Top5 100.000000   BatchTime 0.101419   LR 0.001000   
2022-11-03 21:07:27,626 - INFO  - Training [37][  200/  391]   Loss 0.041517   Top1 98.550781   Top5 100.000000   BatchTime 0.101328   LR 0.001000   
2022-11-03 21:07:29,649 - INFO  - Training [37][  220/  391]   Loss 0.042208   Top1 98.536932   Top5 99.996449   BatchTime 0.101312   LR 0.001000   
2022-11-03 21:07:31,657 - INFO  - Training [37][  240/  391]   Loss 0.042282   Top1 98.548177   Top5 99.996745   BatchTime 0.101235   LR 0.001000   
2022-11-03 21:07:33,674 - INFO  - Training [37][  260/  391]   Loss 0.042100   Top1 98.557692   Top5 99.996995   BatchTime 0.101206   LR 0.001000   
2022-11-03 21:07:35,673 - INFO  - Training [37][  280/  391]   Loss 0.042137   Top1 98.554688   Top5 99.997210   BatchTime 0.101114   LR 0.001000   
2022-11-03 21:07:37,679 - INFO  - Training [37][  300/  391]   Loss 0.042357   Top1 98.546875   Top5 99.997396   BatchTime 0.101062   LR 0.001000   
2022-11-03 21:07:39,672 - INFO  - Training [37][  320/  391]   Loss 0.042212   Top1 98.552246   Top5 99.997559   BatchTime 0.100974   LR 0.001000   
2022-11-03 21:07:41,675 - INFO  - Training [37][  340/  391]   Loss 0.041837   Top1 98.566176   Top5 99.997702   BatchTime 0.100923   LR 0.001000   
2022-11-03 21:07:43,646 - INFO  - Training [37][  360/  391]   Loss 0.041662   Top1 98.567708   Top5 99.997830   BatchTime 0.100792   LR 0.001000   
2022-11-03 21:07:45,630 - INFO  - Training [37][  380/  391]   Loss 0.041847   Top1 98.558799   Top5 99.997944   BatchTime 0.100709   LR 0.001000   
2022-11-03 21:07:46,970 - INFO  - ==> Top1: 98.554    Top5: 99.996    Loss: 0.042

2022-11-03 21:07:46,971 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:07:49,627 - INFO  - Validation [37][   20/   79]   Loss 0.390978   Top1 90.703125   Top5 99.687500   BatchTime 0.132683   
2022-11-03 21:07:50,519 - INFO  - Validation [37][   40/   79]   Loss 0.408093   Top1 90.507812   Top5 99.511719   BatchTime 0.088655   
2022-11-03 21:07:51,429 - INFO  - Validation [37][   60/   79]   Loss 0.399444   Top1 90.468750   Top5 99.622396   BatchTime 0.074261   
2022-11-03 21:07:52,517 - INFO  - ==> Top1: 90.520    Top5: 99.670    Loss: 0.391

2022-11-03 21:07:52,552 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:07:52,553 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:07:52,553 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:07:52,678 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:07:52,678 - INFO  - >>>>>>>> Epoch  38
2022-11-03 21:07:52,680 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:07:56,380 - INFO  - Training [38][   20/  391]   Loss 0.040888   Top1 98.789062   Top5 100.000000   BatchTime 0.184995   LR 0.001000   
2022-11-03 21:07:57,934 - INFO  - Training [38][   40/  391]   Loss 0.037948   Top1 98.808594   Top5 100.000000   BatchTime 0.131350   LR 0.001000   
2022-11-03 21:07:59,566 - INFO  - Training [38][   60/  391]   Loss 0.038624   Top1 98.723958   Top5 100.000000   BatchTime 0.114766   LR 0.001000   
2022-11-03 21:08:01,185 - INFO  - Training [38][   80/  391]   Loss 0.041190   Top1 98.632812   Top5 100.000000   BatchTime 0.106312   LR 0.001000   
2022-11-03 21:08:02,771 - INFO  - Training [38][  100/  391]   Loss 0.041032   Top1 98.570312   Top5 100.000000   BatchTime 0.100911   LR 0.001000   
2022-11-03 21:08:04,595 - INFO  - Training [38][  120/  391]   Loss 0.040471   Top1 98.619792   Top5 100.000000   BatchTime 0.099290   LR 0.001000   
2022-11-03 21:08:06,557 - INFO  - Training [38][  140/  391]   Loss 0.041037   Top1 98.604911   Top5 100.000000   BatchTime 0.099120   LR 0.001000   
2022-11-03 21:08:08,592 - INFO  - Training [38][  160/  391]   Loss 0.041424   Top1 98.583984   Top5 100.000000   BatchTime 0.099450   LR 0.001000   
2022-11-03 21:08:10,603 - INFO  - Training [38][  180/  391]   Loss 0.041110   Top1 98.602431   Top5 100.000000   BatchTime 0.099569   LR 0.001000   
2022-11-03 21:08:12,617 - INFO  - Training [38][  200/  391]   Loss 0.042005   Top1 98.570312   Top5 100.000000   BatchTime 0.099681   LR 0.001000   
2022-11-03 21:08:14,629 - INFO  - Training [38][  220/  391]   Loss 0.041691   Top1 98.572443   Top5 100.000000   BatchTime 0.099767   LR 0.001000   
2022-11-03 21:08:16,653 - INFO  - Training [38][  240/  391]   Loss 0.041254   Top1 98.574219   Top5 100.000000   BatchTime 0.099888   LR 0.001000   
2022-11-03 21:08:18,669 - INFO  - Training [38][  260/  391]   Loss 0.040936   Top1 98.596755   Top5 100.000000   BatchTime 0.099958   LR 0.001000   
2022-11-03 21:08:20,692 - INFO  - Training [38][  280/  391]   Loss 0.040807   Top1 98.599330   Top5 100.000000   BatchTime 0.100039   LR 0.001000   
2022-11-03 21:08:22,707 - INFO  - Training [38][  300/  391]   Loss 0.040590   Top1 98.617188   Top5 100.000000   BatchTime 0.100087   LR 0.001000   
2022-11-03 21:08:24,735 - INFO  - Training [38][  320/  391]   Loss 0.040583   Top1 98.618164   Top5 100.000000   BatchTime 0.100171   LR 0.001000   
2022-11-03 21:08:26,730 - INFO  - Training [38][  340/  391]   Loss 0.040777   Top1 98.612132   Top5 100.000000   BatchTime 0.100145   LR 0.001000   
2022-11-03 21:08:28,724 - INFO  - Training [38][  360/  391]   Loss 0.040534   Top1 98.615451   Top5 100.000000   BatchTime 0.100119   LR 0.001000   
2022-11-03 21:08:30,708 - INFO  - Training [38][  380/  391]   Loss 0.040491   Top1 98.608141   Top5 100.000000   BatchTime 0.100072   LR 0.001000   
2022-11-03 21:08:32,045 - INFO  - ==> Top1: 98.608    Top5: 100.000    Loss: 0.040

2022-11-03 21:08:32,046 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:08:34,642 - INFO  - Validation [38][   20/   79]   Loss 0.365080   Top1 90.898438   Top5 99.648438   BatchTime 0.129682   
2022-11-03 21:08:35,539 - INFO  - Validation [38][   40/   79]   Loss 0.388405   Top1 90.761719   Top5 99.511719   BatchTime 0.087274   
2022-11-03 21:08:36,440 - INFO  - Validation [38][   60/   79]   Loss 0.385479   Top1 90.768229   Top5 99.583333   BatchTime 0.073207   
2022-11-03 21:08:37,535 - INFO  - ==> Top1: 90.650    Top5: 99.630    Loss: 0.383

2022-11-03 21:08:37,566 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:08:37,567 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:08:37,567 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.670   Top5: 99.630] Sparsity : 0.774
2022-11-03 21:08:37,672 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:08:37,672 - INFO  - >>>>>>>> Epoch  39
2022-11-03 21:08:37,674 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:08:41,458 - INFO  - Training [39][   20/  391]   Loss 0.049433   Top1 98.046875   Top5 100.000000   BatchTime 0.189212   LR 0.001000   
2022-11-03 21:08:43,104 - INFO  - Training [39][   40/  391]   Loss 0.045712   Top1 98.164062   Top5 100.000000   BatchTime 0.135749   LR 0.001000   
2022-11-03 21:08:44,756 - INFO  - Training [39][   60/  391]   Loss 0.042430   Top1 98.411458   Top5 100.000000   BatchTime 0.118041   LR 0.001000   
2022-11-03 21:08:46,511 - INFO  - Training [39][   80/  391]   Loss 0.044040   Top1 98.330078   Top5 100.000000   BatchTime 0.110461   LR 0.001000   
2022-11-03 21:08:48,189 - INFO  - Training [39][  100/  391]   Loss 0.044923   Top1 98.289062   Top5 100.000000   BatchTime 0.105155   LR 0.001000   
2022-11-03 21:08:49,821 - INFO  - Training [39][  120/  391]   Loss 0.044986   Top1 98.339844   Top5 100.000000   BatchTime 0.101227   LR 0.001000   
2022-11-03 21:08:51,478 - INFO  - Training [39][  140/  391]   Loss 0.043940   Top1 98.387277   Top5 100.000000   BatchTime 0.098597   LR 0.001000   
2022-11-03 21:08:53,247 - INFO  - Training [39][  160/  391]   Loss 0.043420   Top1 98.408203   Top5 100.000000   BatchTime 0.097331   LR 0.001000   
2022-11-03 21:08:54,732 - INFO  - Training [39][  180/  391]   Loss 0.043507   Top1 98.407118   Top5 100.000000   BatchTime 0.094766   LR 0.001000   
2022-11-03 21:08:56,202 - INFO  - Training [39][  200/  391]   Loss 0.043300   Top1 98.410156   Top5 100.000000   BatchTime 0.092641   LR 0.001000   
2022-11-03 21:08:57,662 - INFO  - Training [39][  220/  391]   Loss 0.042926   Top1 98.433949   Top5 100.000000   BatchTime 0.090854   LR 0.001000   
2022-11-03 21:08:59,089 - INFO  - Training [39][  240/  391]   Loss 0.042323   Top1 98.450521   Top5 100.000000   BatchTime 0.089227   LR 0.001000   
2022-11-03 21:09:00,573 - INFO  - Training [39][  260/  391]   Loss 0.043229   Top1 98.413462   Top5 100.000000   BatchTime 0.088073   LR 0.001000   
2022-11-03 21:09:02,119 - INFO  - Training [39][  280/  391]   Loss 0.043467   Top1 98.404018   Top5 100.000000   BatchTime 0.087303   LR 0.001000   
2022-11-03 21:09:03,620 - INFO  - Training [39][  300/  391]   Loss 0.043029   Top1 98.434896   Top5 100.000000   BatchTime 0.086485   LR 0.001000   
2022-11-03 21:09:05,139 - INFO  - Training [39][  320/  391]   Loss 0.042847   Top1 98.447266   Top5 99.997559   BatchTime 0.085825   LR 0.001000   
2022-11-03 21:09:06,566 - INFO  - Training [39][  340/  391]   Loss 0.042576   Top1 98.467371   Top5 99.997702   BatchTime 0.084975   LR 0.001000   
2022-11-03 21:09:07,973 - INFO  - Training [39][  360/  391]   Loss 0.042440   Top1 98.470052   Top5 99.997830   BatchTime 0.084162   LR 0.001000   
2022-11-03 21:09:09,414 - INFO  - Training [39][  380/  391]   Loss 0.042012   Top1 98.486842   Top5 99.997944   BatchTime 0.083526   LR 0.001000   
2022-11-03 21:09:10,415 - INFO  - ==> Top1: 98.490    Top5: 99.998    Loss: 0.042

2022-11-03 21:09:10,416 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:09:12,846 - INFO  - Validation [39][   20/   79]   Loss 0.382432   Top1 90.859375   Top5 99.648438   BatchTime 0.121423   
2022-11-03 21:09:13,500 - INFO  - Validation [39][   40/   79]   Loss 0.397792   Top1 90.722656   Top5 99.589844   BatchTime 0.077062   
2022-11-03 21:09:14,192 - INFO  - Validation [39][   60/   79]   Loss 0.389678   Top1 90.937500   Top5 99.635417   BatchTime 0.062914   
2022-11-03 21:09:15,071 - INFO  - ==> Top1: 90.800    Top5: 99.660    Loss: 0.384

2022-11-03 21:09:15,104 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:09:15,104 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:09:15,104 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:09:15,188 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:09:15,188 - INFO  - >>>>>>>> Epoch  40
2022-11-03 21:09:15,189 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:09:18,888 - INFO  - Training [40][   20/  391]   Loss 0.036025   Top1 98.554688   Top5 100.000000   BatchTime 0.184918   LR 0.001000   
2022-11-03 21:09:20,927 - INFO  - Training [40][   40/  391]   Loss 0.038932   Top1 98.476562   Top5 100.000000   BatchTime 0.143444   LR 0.001000   
2022-11-03 21:09:22,960 - INFO  - Training [40][   60/  391]   Loss 0.038699   Top1 98.632812   Top5 100.000000   BatchTime 0.129509   LR 0.001000   
2022-11-03 21:09:24,974 - INFO  - Training [40][   80/  391]   Loss 0.039458   Top1 98.623047   Top5 99.990234   BatchTime 0.122311   LR 0.001000   
2022-11-03 21:09:26,983 - INFO  - Training [40][  100/  391]   Loss 0.040626   Top1 98.609375   Top5 99.992188   BatchTime 0.117939   LR 0.001000   
2022-11-03 21:09:29,009 - INFO  - Training [40][  120/  391]   Loss 0.039995   Top1 98.665365   Top5 99.993490   BatchTime 0.115161   LR 0.001000   
2022-11-03 21:09:31,022 - INFO  - Training [40][  140/  391]   Loss 0.039557   Top1 98.660714   Top5 99.994420   BatchTime 0.113086   LR 0.001000   
2022-11-03 21:09:33,037 - INFO  - Training [40][  160/  391]   Loss 0.039530   Top1 98.652344   Top5 99.995117   BatchTime 0.111547   LR 0.001000   
2022-11-03 21:09:35,069 - INFO  - Training [40][  180/  391]   Loss 0.039703   Top1 98.632812   Top5 99.995660   BatchTime 0.110441   LR 0.001000   
2022-11-03 21:09:37,102 - INFO  - Training [40][  200/  391]   Loss 0.040604   Top1 98.613281   Top5 99.996094   BatchTime 0.109563   LR 0.001000   
2022-11-03 21:09:39,127 - INFO  - Training [40][  220/  391]   Loss 0.041492   Top1 98.572443   Top5 99.996449   BatchTime 0.108806   LR 0.001000   
2022-11-03 21:09:41,131 - INFO  - Training [40][  240/  391]   Loss 0.041615   Top1 98.574219   Top5 99.996745   BatchTime 0.108089   LR 0.001000   
2022-11-03 21:09:43,147 - INFO  - Training [40][  260/  391]   Loss 0.042133   Top1 98.557692   Top5 99.996995   BatchTime 0.107529   LR 0.001000   
2022-11-03 21:09:45,187 - INFO  - Training [40][  280/  391]   Loss 0.042082   Top1 98.563058   Top5 99.997210   BatchTime 0.107133   LR 0.001000   
2022-11-03 21:09:47,194 - INFO  - Training [40][  300/  391]   Loss 0.042581   Top1 98.536458   Top5 99.997396   BatchTime 0.106680   LR 0.001000   
2022-11-03 21:09:49,207 - INFO  - Training [40][  320/  391]   Loss 0.042493   Top1 98.542480   Top5 99.997559   BatchTime 0.106302   LR 0.001000   
2022-11-03 21:09:51,197 - INFO  - Training [40][  340/  391]   Loss 0.042201   Top1 98.536305   Top5 99.997702   BatchTime 0.105903   LR 0.001000   
2022-11-03 21:09:53,166 - INFO  - Training [40][  360/  391]   Loss 0.042212   Top1 98.537326   Top5 99.997830   BatchTime 0.105488   LR 0.001000   
2022-11-03 21:09:55,113 - INFO  - Training [40][  380/  391]   Loss 0.042222   Top1 98.542352   Top5 99.997944   BatchTime 0.105060   LR 0.001000   
2022-11-03 21:09:56,416 - INFO  - ==> Top1: 98.546    Top5: 99.998    Loss: 0.042

2022-11-03 21:09:56,417 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:09:58,802 - INFO  - Validation [40][   20/   79]   Loss 0.380906   Top1 90.781250   Top5 99.609375   BatchTime 0.119144   
2022-11-03 21:09:59,318 - INFO  - Validation [40][   40/   79]   Loss 0.404827   Top1 90.644531   Top5 99.550781   BatchTime 0.072479   
2022-11-03 21:09:59,851 - INFO  - Validation [40][   60/   79]   Loss 0.394957   Top1 90.742188   Top5 99.622396   BatchTime 0.057209   
2022-11-03 21:10:00,783 - INFO  - ==> Top1: 90.590    Top5: 99.660    Loss: 0.388

2022-11-03 21:10:00,814 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:10:00,815 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:10:00,815 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:10:00,931 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:10:00,931 - INFO  - >>>>>>>> Epoch  41
2022-11-03 21:10:00,933 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:10:04,327 - INFO  - Training [41][   20/  391]   Loss 0.038421   Top1 98.515625   Top5 100.000000   BatchTime 0.169701   LR 0.001000   
2022-11-03 21:10:06,420 - INFO  - Training [41][   40/  391]   Loss 0.040438   Top1 98.554688   Top5 100.000000   BatchTime 0.137186   LR 0.001000   
2022-11-03 21:10:08,434 - INFO  - Training [41][   60/  391]   Loss 0.039161   Top1 98.606771   Top5 100.000000   BatchTime 0.125014   LR 0.001000   
2022-11-03 21:10:10,440 - INFO  - Training [41][   80/  391]   Loss 0.039741   Top1 98.593750   Top5 100.000000   BatchTime 0.118832   LR 0.001000   
2022-11-03 21:10:12,432 - INFO  - Training [41][  100/  391]   Loss 0.040842   Top1 98.539062   Top5 100.000000   BatchTime 0.114993   LR 0.001000   
2022-11-03 21:10:14,458 - INFO  - Training [41][  120/  391]   Loss 0.039991   Top1 98.535156   Top5 100.000000   BatchTime 0.112704   LR 0.001000   
2022-11-03 21:10:16,551 - INFO  - Training [41][  140/  391]   Loss 0.039781   Top1 98.554688   Top5 100.000000   BatchTime 0.111559   LR 0.001000   
2022-11-03 21:10:18,560 - INFO  - Training [41][  160/  391]   Loss 0.039822   Top1 98.569336   Top5 100.000000   BatchTime 0.110169   LR 0.001000   
2022-11-03 21:10:20,568 - INFO  - Training [41][  180/  391]   Loss 0.039905   Top1 98.598090   Top5 99.995660   BatchTime 0.109083   LR 0.001000   
2022-11-03 21:10:22,610 - INFO  - Training [41][  200/  391]   Loss 0.039914   Top1 98.605469   Top5 99.996094   BatchTime 0.108383   LR 0.001000   
2022-11-03 21:10:24,624 - INFO  - Training [41][  220/  391]   Loss 0.041260   Top1 98.551136   Top5 99.996449   BatchTime 0.107684   LR 0.001000   
2022-11-03 21:10:26,627 - INFO  - Training [41][  240/  391]   Loss 0.040915   Top1 98.561198   Top5 99.996745   BatchTime 0.107056   LR 0.001000   
2022-11-03 21:10:28,625 - INFO  - Training [41][  260/  391]   Loss 0.041159   Top1 98.548678   Top5 99.996995   BatchTime 0.106507   LR 0.001000   
2022-11-03 21:10:30,636 - INFO  - Training [41][  280/  391]   Loss 0.040869   Top1 98.557478   Top5 99.997210   BatchTime 0.106080   LR 0.001000   
2022-11-03 21:10:32,627 - INFO  - Training [41][  300/  391]   Loss 0.041094   Top1 98.549479   Top5 99.997396   BatchTime 0.105645   LR 0.001000   
2022-11-03 21:10:34,621 - INFO  - Training [41][  320/  391]   Loss 0.040955   Top1 98.559570   Top5 99.995117   BatchTime 0.105272   LR 0.001000   
2022-11-03 21:10:36,617 - INFO  - Training [41][  340/  391]   Loss 0.040558   Top1 98.575368   Top5 99.995404   BatchTime 0.104952   LR 0.001000   
2022-11-03 21:10:38,611 - INFO  - Training [41][  360/  391]   Loss 0.040669   Top1 98.578559   Top5 99.995660   BatchTime 0.104660   LR 0.001000   
2022-11-03 21:10:40,546 - INFO  - Training [41][  380/  391]   Loss 0.040332   Top1 98.601974   Top5 99.995888   BatchTime 0.104242   LR 0.001000   
2022-11-03 21:10:41,865 - INFO  - ==> Top1: 98.586    Top5: 99.996    Loss: 0.040

2022-11-03 21:10:41,866 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:10:44,290 - INFO  - Validation [41][   20/   79]   Loss 0.376839   Top1 90.625000   Top5 99.648438   BatchTime 0.121141   
2022-11-03 21:10:44,826 - INFO  - Validation [41][   40/   79]   Loss 0.397928   Top1 90.566406   Top5 99.550781   BatchTime 0.073962   
2022-11-03 21:10:45,361 - INFO  - Validation [41][   60/   79]   Loss 0.390328   Top1 90.703125   Top5 99.622396   BatchTime 0.058223   
2022-11-03 21:10:46,306 - INFO  - ==> Top1: 90.590    Top5: 99.630    Loss: 0.387

2022-11-03 21:10:46,340 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:10:46,341 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:10:46,341 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:10:46,444 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:10:46,444 - INFO  - >>>>>>>> Epoch  42
2022-11-03 21:10:46,445 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:10:49,864 - INFO  - Training [42][   20/  391]   Loss 0.044006   Top1 98.476562   Top5 100.000000   BatchTime 0.170944   LR 0.001000   
2022-11-03 21:10:51,968 - INFO  - Training [42][   40/  391]   Loss 0.037020   Top1 98.789062   Top5 100.000000   BatchTime 0.138078   LR 0.001000   
2022-11-03 21:10:53,988 - INFO  - Training [42][   60/  391]   Loss 0.040184   Top1 98.645833   Top5 100.000000   BatchTime 0.125708   LR 0.001000   
2022-11-03 21:10:56,006 - INFO  - Training [42][   80/  391]   Loss 0.040741   Top1 98.642578   Top5 100.000000   BatchTime 0.119512   LR 0.001000   
2022-11-03 21:10:58,008 - INFO  - Training [42][  100/  391]   Loss 0.041588   Top1 98.601562   Top5 100.000000   BatchTime 0.115629   LR 0.001000   
2022-11-03 21:11:00,051 - INFO  - Training [42][  120/  391]   Loss 0.040058   Top1 98.626302   Top5 100.000000   BatchTime 0.113378   LR 0.001000   
2022-11-03 21:11:02,075 - INFO  - Training [42][  140/  391]   Loss 0.039383   Top1 98.655134   Top5 100.000000   BatchTime 0.111641   LR 0.001000   
2022-11-03 21:11:04,113 - INFO  - Training [42][  160/  391]   Loss 0.040129   Top1 98.632812   Top5 100.000000   BatchTime 0.110418   LR 0.001000   
2022-11-03 21:11:06,125 - INFO  - Training [42][  180/  391]   Loss 0.039727   Top1 98.641493   Top5 100.000000   BatchTime 0.109327   LR 0.001000   
2022-11-03 21:11:08,148 - INFO  - Training [42][  200/  391]   Loss 0.040411   Top1 98.625000   Top5 100.000000   BatchTime 0.108509   LR 0.001000   
2022-11-03 21:11:10,143 - INFO  - Training [42][  220/  391]   Loss 0.040583   Top1 98.618608   Top5 99.996449   BatchTime 0.107714   LR 0.001000   
2022-11-03 21:11:12,152 - INFO  - Training [42][  240/  391]   Loss 0.040918   Top1 98.616536   Top5 99.996745   BatchTime 0.107109   LR 0.001000   
2022-11-03 21:11:14,162 - INFO  - Training [42][  260/  391]   Loss 0.040346   Top1 98.638822   Top5 99.996995   BatchTime 0.106599   LR 0.001000   
2022-11-03 21:11:16,188 - INFO  - Training [42][  280/  391]   Loss 0.040156   Top1 98.627232   Top5 99.997210   BatchTime 0.106221   LR 0.001000   
2022-11-03 21:11:18,207 - INFO  - Training [42][  300/  391]   Loss 0.040746   Top1 98.609375   Top5 99.997396   BatchTime 0.105870   LR 0.001000   
2022-11-03 21:11:20,243 - INFO  - Training [42][  320/  391]   Loss 0.040523   Top1 98.608398   Top5 99.997559   BatchTime 0.105615   LR 0.001000   
2022-11-03 21:11:22,267 - INFO  - Training [42][  340/  391]   Loss 0.040474   Top1 98.619026   Top5 99.997702   BatchTime 0.105355   LR 0.001000   
2022-11-03 21:11:24,239 - INFO  - Training [42][  360/  391]   Loss 0.040699   Top1 98.604601   Top5 99.997830   BatchTime 0.104980   LR 0.001000   
2022-11-03 21:11:26,196 - INFO  - Training [42][  380/  391]   Loss 0.040737   Top1 98.583470   Top5 99.997944   BatchTime 0.104604   LR 0.001000   
2022-11-03 21:11:27,489 - INFO  - ==> Top1: 98.580    Top5: 99.998    Loss: 0.041

2022-11-03 21:11:27,490 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:11:29,928 - INFO  - Validation [42][   20/   79]   Loss 0.377084   Top1 90.351562   Top5 99.570312   BatchTime 0.121824   
2022-11-03 21:11:30,461 - INFO  - Validation [42][   40/   79]   Loss 0.406141   Top1 90.449219   Top5 99.472656   BatchTime 0.074233   
2022-11-03 21:11:30,991 - INFO  - Validation [42][   60/   79]   Loss 0.397138   Top1 90.651042   Top5 99.531250   BatchTime 0.058315   
2022-11-03 21:11:32,081 - INFO  - ==> Top1: 90.650    Top5: 99.590    Loss: 0.388

2022-11-03 21:11:32,112 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:11:32,113 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:11:32,113 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:11:32,211 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:11:32,211 - INFO  - >>>>>>>> Epoch  43
2022-11-03 21:11:32,212 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:11:35,735 - INFO  - Training [43][   20/  391]   Loss 0.044505   Top1 98.242188   Top5 100.000000   BatchTime 0.176106   LR 0.001000   
2022-11-03 21:11:37,691 - INFO  - Training [43][   40/  391]   Loss 0.042109   Top1 98.574219   Top5 100.000000   BatchTime 0.136964   LR 0.001000   
2022-11-03 21:11:39,697 - INFO  - Training [43][   60/  391]   Loss 0.043305   Top1 98.502604   Top5 100.000000   BatchTime 0.124731   LR 0.001000   
2022-11-03 21:11:41,725 - INFO  - Training [43][   80/  391]   Loss 0.041961   Top1 98.574219   Top5 100.000000   BatchTime 0.118898   LR 0.001000   
2022-11-03 21:11:43,749 - INFO  - Training [43][  100/  391]   Loss 0.041020   Top1 98.617188   Top5 100.000000   BatchTime 0.115364   LR 0.001000   
2022-11-03 21:11:45,782 - INFO  - Training [43][  120/  391]   Loss 0.040210   Top1 98.665365   Top5 100.000000   BatchTime 0.113072   LR 0.001000   
2022-11-03 21:11:47,786 - INFO  - Training [43][  140/  391]   Loss 0.039165   Top1 98.666295   Top5 100.000000   BatchTime 0.111235   LR 0.001000   
2022-11-03 21:11:49,804 - INFO  - Training [43][  160/  391]   Loss 0.038910   Top1 98.681641   Top5 100.000000   BatchTime 0.109944   LR 0.001000   
2022-11-03 21:11:51,804 - INFO  - Training [43][  180/  391]   Loss 0.039021   Top1 98.654514   Top5 100.000000   BatchTime 0.108838   LR 0.001000   
2022-11-03 21:11:53,954 - INFO  - Training [43][  200/  391]   Loss 0.038096   Top1 98.691406   Top5 100.000000   BatchTime 0.108706   LR 0.001000   
2022-11-03 21:11:55,959 - INFO  - Training [43][  220/  391]   Loss 0.038350   Top1 98.689631   Top5 100.000000   BatchTime 0.107938   LR 0.001000   
2022-11-03 21:11:57,989 - INFO  - Training [43][  240/  391]   Loss 0.038476   Top1 98.681641   Top5 100.000000   BatchTime 0.107400   LR 0.001000   
2022-11-03 21:11:59,987 - INFO  - Training [43][  260/  391]   Loss 0.038803   Top1 98.662861   Top5 100.000000   BatchTime 0.106824   LR 0.001000   
2022-11-03 21:12:01,986 - INFO  - Training [43][  280/  391]   Loss 0.039016   Top1 98.666295   Top5 100.000000   BatchTime 0.106332   LR 0.001000   
2022-11-03 21:12:03,980 - INFO  - Training [43][  300/  391]   Loss 0.038891   Top1 98.661458   Top5 100.000000   BatchTime 0.105887   LR 0.001000   
2022-11-03 21:12:05,982 - INFO  - Training [43][  320/  391]   Loss 0.039533   Top1 98.625488   Top5 100.000000   BatchTime 0.105526   LR 0.001000   
2022-11-03 21:12:07,964 - INFO  - Training [43][  340/  391]   Loss 0.039267   Top1 98.644301   Top5 100.000000   BatchTime 0.105148   LR 0.001000   
2022-11-03 21:12:09,935 - INFO  - Training [43][  360/  391]   Loss 0.039409   Top1 98.643663   Top5 100.000000   BatchTime 0.104782   LR 0.001000   
2022-11-03 21:12:11,887 - INFO  - Training [43][  380/  391]   Loss 0.039639   Top1 98.632812   Top5 100.000000   BatchTime 0.104405   LR 0.001000   
2022-11-03 21:12:13,204 - INFO  - ==> Top1: 98.620    Top5: 100.000    Loss: 0.040

2022-11-03 21:12:13,205 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:12:15,720 - INFO  - Validation [43][   20/   79]   Loss 0.379302   Top1 90.820312   Top5 99.648438   BatchTime 0.125660   
2022-11-03 21:12:16,248 - INFO  - Validation [43][   40/   79]   Loss 0.402055   Top1 90.703125   Top5 99.531250   BatchTime 0.076027   
2022-11-03 21:12:16,786 - INFO  - Validation [43][   60/   79]   Loss 0.397076   Top1 90.611979   Top5 99.583333   BatchTime 0.059665   
2022-11-03 21:12:17,729 - INFO  - ==> Top1: 90.500    Top5: 99.620    Loss: 0.390

2022-11-03 21:12:17,761 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:12:17,761 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:12:17,761 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:12:17,865 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:12:17,866 - INFO  - >>>>>>>> Epoch  44
2022-11-03 21:12:17,867 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:12:21,293 - INFO  - Training [44][   20/  391]   Loss 0.040376   Top1 98.437500   Top5 100.000000   BatchTime 0.171298   LR 0.001000   
2022-11-03 21:12:23,327 - INFO  - Training [44][   40/  391]   Loss 0.038252   Top1 98.554688   Top5 100.000000   BatchTime 0.136486   LR 0.001000   
2022-11-03 21:12:25,353 - INFO  - Training [44][   60/  391]   Loss 0.041860   Top1 98.424479   Top5 100.000000   BatchTime 0.124760   LR 0.001000   
2022-11-03 21:12:27,362 - INFO  - Training [44][   80/  391]   Loss 0.040268   Top1 98.603516   Top5 100.000000   BatchTime 0.118688   LR 0.001000   
2022-11-03 21:12:29,397 - INFO  - Training [44][  100/  391]   Loss 0.040038   Top1 98.617188   Top5 100.000000   BatchTime 0.115298   LR 0.001000   
2022-11-03 21:12:31,399 - INFO  - Training [44][  120/  391]   Loss 0.041325   Top1 98.528646   Top5 100.000000   BatchTime 0.112759   LR 0.001000   
2022-11-03 21:12:33,417 - INFO  - Training [44][  140/  391]   Loss 0.039936   Top1 98.565848   Top5 100.000000   BatchTime 0.111067   LR 0.001000   
2022-11-03 21:12:35,445 - INFO  - Training [44][  160/  391]   Loss 0.039403   Top1 98.583984   Top5 100.000000   BatchTime 0.109857   LR 0.001000   
2022-11-03 21:12:37,471 - INFO  - Training [44][  180/  391]   Loss 0.039527   Top1 98.580729   Top5 100.000000   BatchTime 0.108908   LR 0.001000   
2022-11-03 21:12:39,492 - INFO  - Training [44][  200/  391]   Loss 0.039291   Top1 98.582031   Top5 100.000000   BatchTime 0.108122   LR 0.001000   
2022-11-03 21:12:41,523 - INFO  - Training [44][  220/  391]   Loss 0.039046   Top1 98.590199   Top5 100.000000   BatchTime 0.107525   LR 0.001000   
2022-11-03 21:12:43,531 - INFO  - Training [44][  240/  391]   Loss 0.038661   Top1 98.590495   Top5 100.000000   BatchTime 0.106928   LR 0.001000   
2022-11-03 21:12:45,549 - INFO  - Training [44][  260/  391]   Loss 0.038826   Top1 98.608774   Top5 100.000000   BatchTime 0.106466   LR 0.001000   
2022-11-03 21:12:47,555 - INFO  - Training [44][  280/  391]   Loss 0.039516   Top1 98.585379   Top5 100.000000   BatchTime 0.106023   LR 0.001000   
2022-11-03 21:12:49,557 - INFO  - Training [44][  300/  391]   Loss 0.039024   Top1 98.601562   Top5 100.000000   BatchTime 0.105631   LR 0.001000   
2022-11-03 21:12:51,562 - INFO  - Training [44][  320/  391]   Loss 0.039385   Top1 98.583984   Top5 100.000000   BatchTime 0.105293   LR 0.001000   
2022-11-03 21:12:53,558 - INFO  - Training [44][  340/  391]   Loss 0.039546   Top1 98.575368   Top5 100.000000   BatchTime 0.104969   LR 0.001000   
2022-11-03 21:12:55,539 - INFO  - Training [44][  360/  391]   Loss 0.039517   Top1 98.572049   Top5 100.000000   BatchTime 0.104642   LR 0.001000   
2022-11-03 21:12:57,495 - INFO  - Training [44][  380/  391]   Loss 0.039354   Top1 98.585526   Top5 100.000000   BatchTime 0.104280   LR 0.001000   
2022-11-03 21:12:58,814 - INFO  - ==> Top1: 98.580    Top5: 100.000    Loss: 0.040

2022-11-03 21:12:58,815 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:13:01,306 - INFO  - Validation [44][   20/   79]   Loss 0.368021   Top1 91.054688   Top5 99.648438   BatchTime 0.124455   
2022-11-03 21:13:01,827 - INFO  - Validation [44][   40/   79]   Loss 0.403432   Top1 90.859375   Top5 99.570312   BatchTime 0.075252   
2022-11-03 21:13:02,347 - INFO  - Validation [44][   60/   79]   Loss 0.395633   Top1 90.690104   Top5 99.609375   BatchTime 0.058836   
2022-11-03 21:13:03,270 - INFO  - ==> Top1: 90.650    Top5: 99.660    Loss: 0.388

2022-11-03 21:13:03,303 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:13:03,303 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:13:03,304 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:13:03,402 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:13:03,403 - INFO  - >>>>>>>> Epoch  45
2022-11-03 21:13:03,404 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:13:06,810 - INFO  - Training [45][   20/  391]   Loss 0.041430   Top1 98.554688   Top5 100.000000   BatchTime 0.170284   LR 0.001000   
2022-11-03 21:13:08,745 - INFO  - Training [45][   40/  391]   Loss 0.040797   Top1 98.574219   Top5 100.000000   BatchTime 0.133540   LR 0.001000   
2022-11-03 21:13:10,781 - INFO  - Training [45][   60/  391]   Loss 0.039740   Top1 98.645833   Top5 100.000000   BatchTime 0.122946   LR 0.001000   
2022-11-03 21:13:12,817 - INFO  - Training [45][   80/  391]   Loss 0.038511   Top1 98.691406   Top5 100.000000   BatchTime 0.117659   LR 0.001000   
2022-11-03 21:13:14,841 - INFO  - Training [45][  100/  391]   Loss 0.038640   Top1 98.718750   Top5 100.000000   BatchTime 0.114371   LR 0.001000   
2022-11-03 21:13:16,876 - INFO  - Training [45][  120/  391]   Loss 0.037535   Top1 98.717448   Top5 100.000000   BatchTime 0.112265   LR 0.001000   
2022-11-03 21:13:18,897 - INFO  - Training [45][  140/  391]   Loss 0.038245   Top1 98.677455   Top5 100.000000   BatchTime 0.110661   LR 0.001000   
2022-11-03 21:13:20,914 - INFO  - Training [45][  160/  391]   Loss 0.038222   Top1 98.671875   Top5 100.000000   BatchTime 0.109439   LR 0.001000   
2022-11-03 21:13:22,942 - INFO  - Training [45][  180/  391]   Loss 0.038900   Top1 98.667535   Top5 100.000000   BatchTime 0.108545   LR 0.001000   
2022-11-03 21:13:24,956 - INFO  - Training [45][  200/  391]   Loss 0.038896   Top1 98.656250   Top5 100.000000   BatchTime 0.107760   LR 0.001000   
2022-11-03 21:13:26,967 - INFO  - Training [45][  220/  391]   Loss 0.039091   Top1 98.643466   Top5 100.000000   BatchTime 0.107105   LR 0.001000   
2022-11-03 21:13:28,961 - INFO  - Training [45][  240/  391]   Loss 0.039072   Top1 98.658854   Top5 100.000000   BatchTime 0.106487   LR 0.001000   
2022-11-03 21:13:30,966 - INFO  - Training [45][  260/  391]   Loss 0.038823   Top1 98.650841   Top5 100.000000   BatchTime 0.106007   LR 0.001000   
2022-11-03 21:13:33,059 - INFO  - Training [45][  280/  391]   Loss 0.039237   Top1 98.630022   Top5 100.000000   BatchTime 0.105911   LR 0.001000   
2022-11-03 21:13:35,066 - INFO  - Training [45][  300/  391]   Loss 0.039554   Top1 98.622396   Top5 100.000000   BatchTime 0.105537   LR 0.001000   
2022-11-03 21:13:37,074 - INFO  - Training [45][  320/  391]   Loss 0.039516   Top1 98.632812   Top5 100.000000   BatchTime 0.105218   LR 0.001000   
2022-11-03 21:13:39,061 - INFO  - Training [45][  340/  391]   Loss 0.039178   Top1 98.648897   Top5 100.000000   BatchTime 0.104872   LR 0.001000   
2022-11-03 21:13:41,020 - INFO  - Training [45][  360/  391]   Loss 0.039564   Top1 98.626302   Top5 100.000000   BatchTime 0.104488   LR 0.001000   
2022-11-03 21:13:42,986 - INFO  - Training [45][  380/  391]   Loss 0.039298   Top1 98.645148   Top5 100.000000   BatchTime 0.104161   LR 0.001000   
2022-11-03 21:13:44,293 - INFO  - ==> Top1: 98.656    Top5: 100.000    Loss: 0.039

2022-11-03 21:13:44,294 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:13:46,765 - INFO  - Validation [45][   20/   79]   Loss 0.369958   Top1 91.328125   Top5 99.648438   BatchTime 0.123470   
2022-11-03 21:13:47,283 - INFO  - Validation [45][   40/   79]   Loss 0.398906   Top1 90.703125   Top5 99.550781   BatchTime 0.074684   
2022-11-03 21:13:47,800 - INFO  - Validation [45][   60/   79]   Loss 0.389624   Top1 90.729167   Top5 99.557292   BatchTime 0.058408   
2022-11-03 21:13:48,641 - INFO  - ==> Top1: 90.680    Top5: 99.600    Loss: 0.386

2022-11-03 21:13:48,673 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:13:48,673 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:13:48,673 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:13:48,774 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:13:48,774 - INFO  - >>>>>>>> Epoch  46
2022-11-03 21:13:48,775 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:13:52,256 - INFO  - Training [46][   20/  391]   Loss 0.036137   Top1 98.710938   Top5 100.000000   BatchTime 0.174012   LR 0.001000   
2022-11-03 21:13:54,170 - INFO  - Training [46][   40/  391]   Loss 0.035355   Top1 98.769531   Top5 100.000000   BatchTime 0.134864   LR 0.001000   
2022-11-03 21:13:56,233 - INFO  - Training [46][   60/  391]   Loss 0.036541   Top1 98.736979   Top5 100.000000   BatchTime 0.124281   LR 0.001000   
2022-11-03 21:13:58,289 - INFO  - Training [46][   80/  391]   Loss 0.035414   Top1 98.789062   Top5 99.990234   BatchTime 0.118914   LR 0.001000   
2022-11-03 21:14:00,292 - INFO  - Training [46][  100/  391]   Loss 0.035469   Top1 98.773438   Top5 99.992188   BatchTime 0.115167   LR 0.001000   
2022-11-03 21:14:02,302 - INFO  - Training [46][  120/  391]   Loss 0.034821   Top1 98.776042   Top5 99.993490   BatchTime 0.112721   LR 0.001000   
2022-11-03 21:14:04,348 - INFO  - Training [46][  140/  391]   Loss 0.035557   Top1 98.772321   Top5 99.988839   BatchTime 0.111227   LR 0.001000   
2022-11-03 21:14:06,359 - INFO  - Training [46][  160/  391]   Loss 0.034656   Top1 98.813477   Top5 99.990234   BatchTime 0.109895   LR 0.001000   
2022-11-03 21:14:08,382 - INFO  - Training [46][  180/  391]   Loss 0.035049   Top1 98.793403   Top5 99.991319   BatchTime 0.108924   LR 0.001000   
2022-11-03 21:14:10,397 - INFO  - Training [46][  200/  391]   Loss 0.034829   Top1 98.820312   Top5 99.992188   BatchTime 0.108105   LR 0.001000   
2022-11-03 21:14:12,414 - INFO  - Training [46][  220/  391]   Loss 0.035817   Top1 98.781960   Top5 99.992898   BatchTime 0.107446   LR 0.001000   
2022-11-03 21:14:14,377 - INFO  - Training [46][  240/  391]   Loss 0.036043   Top1 98.763021   Top5 99.993490   BatchTime 0.106670   LR 0.001000   
2022-11-03 21:14:16,402 - INFO  - Training [46][  260/  391]   Loss 0.036212   Top1 98.774038   Top5 99.993990   BatchTime 0.106252   LR 0.001000   
2022-11-03 21:14:18,409 - INFO  - Training [46][  280/  391]   Loss 0.035827   Top1 98.783482   Top5 99.994420   BatchTime 0.105831   LR 0.001000   
2022-11-03 21:14:20,420 - INFO  - Training [46][  300/  391]   Loss 0.036448   Top1 98.739583   Top5 99.994792   BatchTime 0.105479   LR 0.001000   
2022-11-03 21:14:22,432 - INFO  - Training [46][  320/  391]   Loss 0.036648   Top1 98.737793   Top5 99.995117   BatchTime 0.105174   LR 0.001000   
2022-11-03 21:14:24,417 - INFO  - Training [46][  340/  391]   Loss 0.036531   Top1 98.743107   Top5 99.995404   BatchTime 0.104826   LR 0.001000   
2022-11-03 21:14:26,406 - INFO  - Training [46][  360/  391]   Loss 0.036649   Top1 98.743490   Top5 99.995660   BatchTime 0.104526   LR 0.001000   
2022-11-03 21:14:28,386 - INFO  - Training [46][  380/  391]   Loss 0.037138   Top1 98.731497   Top5 99.995888   BatchTime 0.104237   LR 0.001000   
2022-11-03 21:14:29,698 - INFO  - ==> Top1: 98.718    Top5: 99.996    Loss: 0.037

2022-11-03 21:14:29,699 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:14:32,241 - INFO  - Validation [46][   20/   79]   Loss 0.370644   Top1 91.054688   Top5 99.687500   BatchTime 0.127056   
2022-11-03 21:14:32,766 - INFO  - Validation [46][   40/   79]   Loss 0.402289   Top1 90.742188   Top5 99.550781   BatchTime 0.076643   
2022-11-03 21:14:33,286 - INFO  - Validation [46][   60/   79]   Loss 0.393816   Top1 90.859375   Top5 99.583333   BatchTime 0.059767   
2022-11-03 21:14:34,040 - INFO  - ==> Top1: 90.690    Top5: 99.630    Loss: 0.388

2022-11-03 21:14:34,072 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:14:34,073 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:14:34,073 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:14:34,227 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:14:34,227 - INFO  - >>>>>>>> Epoch  47
2022-11-03 21:14:34,228 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:14:37,760 - INFO  - Training [47][   20/  391]   Loss 0.031119   Top1 99.101562   Top5 100.000000   BatchTime 0.176560   LR 0.001000   
2022-11-03 21:14:39,463 - INFO  - Training [47][   40/  391]   Loss 0.031193   Top1 99.003906   Top5 100.000000   BatchTime 0.130875   LR 0.001000   
2022-11-03 21:14:41,456 - INFO  - Training [47][   60/  391]   Loss 0.033129   Top1 98.906250   Top5 100.000000   BatchTime 0.120465   LR 0.001000   
2022-11-03 21:14:43,488 - INFO  - Training [47][   80/  391]   Loss 0.034333   Top1 98.828125   Top5 100.000000   BatchTime 0.115746   LR 0.001000   
2022-11-03 21:14:45,428 - INFO  - Training [47][  100/  391]   Loss 0.034852   Top1 98.804688   Top5 100.000000   BatchTime 0.111997   LR 0.001000   
2022-11-03 21:14:47,447 - INFO  - Training [47][  120/  391]   Loss 0.035142   Top1 98.802083   Top5 100.000000   BatchTime 0.110151   LR 0.001000   
2022-11-03 21:14:49,484 - INFO  - Training [47][  140/  391]   Loss 0.036525   Top1 98.744420   Top5 100.000000   BatchTime 0.108969   LR 0.001000   
2022-11-03 21:14:51,533 - INFO  - Training [47][  160/  391]   Loss 0.036905   Top1 98.745117   Top5 100.000000   BatchTime 0.108153   LR 0.001000   
2022-11-03 21:14:53,529 - INFO  - Training [47][  180/  391]   Loss 0.036650   Top1 98.763021   Top5 100.000000   BatchTime 0.107223   LR 0.001000   
2022-11-03 21:14:55,539 - INFO  - Training [47][  200/  391]   Loss 0.036755   Top1 98.769531   Top5 100.000000   BatchTime 0.106552   LR 0.001000   
2022-11-03 21:14:57,544 - INFO  - Training [47][  220/  391]   Loss 0.037524   Top1 98.746449   Top5 100.000000   BatchTime 0.105979   LR 0.001000   
2022-11-03 21:14:59,546 - INFO  - Training [47][  240/  391]   Loss 0.037152   Top1 98.763021   Top5 100.000000   BatchTime 0.105490   LR 0.001000   
2022-11-03 21:15:01,548 - INFO  - Training [47][  260/  391]   Loss 0.036986   Top1 98.771034   Top5 100.000000   BatchTime 0.105073   LR 0.001000   
2022-11-03 21:15:03,544 - INFO  - Training [47][  280/  391]   Loss 0.036806   Top1 98.772321   Top5 100.000000   BatchTime 0.104695   LR 0.001000   
2022-11-03 21:15:05,562 - INFO  - Training [47][  300/  391]   Loss 0.036844   Top1 98.776042   Top5 100.000000   BatchTime 0.104443   LR 0.001000   
2022-11-03 21:15:07,575 - INFO  - Training [47][  320/  391]   Loss 0.036924   Top1 98.762207   Top5 100.000000   BatchTime 0.104205   LR 0.001000   
2022-11-03 21:15:09,555 - INFO  - Training [47][  340/  391]   Loss 0.037098   Top1 98.747702   Top5 100.000000   BatchTime 0.103899   LR 0.001000   
2022-11-03 21:15:11,651 - INFO  - Training [47][  360/  391]   Loss 0.037039   Top1 98.741319   Top5 100.000000   BatchTime 0.103950   LR 0.001000   
2022-11-03 21:15:13,612 - INFO  - Training [47][  380/  391]   Loss 0.036972   Top1 98.743832   Top5 100.000000   BatchTime 0.103639   LR 0.001000   
2022-11-03 21:15:14,922 - INFO  - ==> Top1: 98.746    Top5: 100.000    Loss: 0.037

2022-11-03 21:15:14,923 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:15:17,563 - INFO  - Validation [47][   20/   79]   Loss 0.380799   Top1 90.585938   Top5 99.687500   BatchTime 0.131956   
2022-11-03 21:15:18,287 - INFO  - Validation [47][   40/   79]   Loss 0.406806   Top1 90.507812   Top5 99.492188   BatchTime 0.084073   
2022-11-03 21:15:18,824 - INFO  - Validation [47][   60/   79]   Loss 0.399690   Top1 90.690104   Top5 99.557292   BatchTime 0.065004   
2022-11-03 21:15:19,572 - INFO  - ==> Top1: 90.630    Top5: 99.590    Loss: 0.394

2022-11-03 21:15:19,595 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:15:19,596 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:15:19,596 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.700   Top5: 99.580] Sparsity : 0.774
2022-11-03 21:15:19,704 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:15:19,704 - INFO  - >>>>>>>> Epoch  48
2022-11-03 21:15:19,706 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:15:23,276 - INFO  - Training [48][   20/  391]   Loss 0.038959   Top1 98.789062   Top5 100.000000   BatchTime 0.178511   LR 0.001000   
2022-11-03 21:15:24,746 - INFO  - Training [48][   40/  391]   Loss 0.036546   Top1 98.886719   Top5 100.000000   BatchTime 0.125995   LR 0.001000   
2022-11-03 21:15:26,847 - INFO  - Training [48][   60/  391]   Loss 0.036564   Top1 98.802083   Top5 100.000000   BatchTime 0.119015   LR 0.001000   
2022-11-03 21:15:28,847 - INFO  - Training [48][   80/  391]   Loss 0.037400   Top1 98.769531   Top5 100.000000   BatchTime 0.114262   LR 0.001000   
2022-11-03 21:15:30,868 - INFO  - Training [48][  100/  391]   Loss 0.037009   Top1 98.828125   Top5 100.000000   BatchTime 0.111614   LR 0.001000   
2022-11-03 21:15:32,893 - INFO  - Training [48][  120/  391]   Loss 0.037795   Top1 98.776042   Top5 100.000000   BatchTime 0.109889   LR 0.001000   
2022-11-03 21:15:34,914 - INFO  - Training [48][  140/  391]   Loss 0.037293   Top1 98.777902   Top5 100.000000   BatchTime 0.108626   LR 0.001000   
2022-11-03 21:15:36,943 - INFO  - Training [48][  160/  391]   Loss 0.038159   Top1 98.720703   Top5 100.000000   BatchTime 0.107727   LR 0.001000   
2022-11-03 21:15:38,979 - INFO  - Training [48][  180/  391]   Loss 0.037880   Top1 98.706597   Top5 100.000000   BatchTime 0.107069   LR 0.001000   
2022-11-03 21:15:40,995 - INFO  - Training [48][  200/  391]   Loss 0.037970   Top1 98.703125   Top5 100.000000   BatchTime 0.106440   LR 0.001000   
2022-11-03 21:15:43,025 - INFO  - Training [48][  220/  391]   Loss 0.037622   Top1 98.725142   Top5 100.000000   BatchTime 0.105994   LR 0.001000   
2022-11-03 21:15:45,024 - INFO  - Training [48][  240/  391]   Loss 0.037174   Top1 98.743490   Top5 100.000000   BatchTime 0.105488   LR 0.001000   
2022-11-03 21:15:47,042 - INFO  - Training [48][  260/  391]   Loss 0.036726   Top1 98.750000   Top5 100.000000   BatchTime 0.105136   LR 0.001000   
2022-11-03 21:15:49,062 - INFO  - Training [48][  280/  391]   Loss 0.036720   Top1 98.750000   Top5 100.000000   BatchTime 0.104839   LR 0.001000   
2022-11-03 21:15:51,087 - INFO  - Training [48][  300/  391]   Loss 0.036615   Top1 98.750000   Top5 100.000000   BatchTime 0.104602   LR 0.001000   
2022-11-03 21:15:53,094 - INFO  - Training [48][  320/  391]   Loss 0.036192   Top1 98.767090   Top5 100.000000   BatchTime 0.104336   LR 0.001000   
2022-11-03 21:15:55,098 - INFO  - Training [48][  340/  391]   Loss 0.036376   Top1 98.736213   Top5 100.000000   BatchTime 0.104092   LR 0.001000   
2022-11-03 21:15:57,064 - INFO  - Training [48][  360/  391]   Loss 0.036470   Top1 98.719618   Top5 100.000000   BatchTime 0.103769   LR 0.001000   
2022-11-03 21:15:59,033 - INFO  - Training [48][  380/  391]   Loss 0.036761   Top1 98.725329   Top5 100.000000   BatchTime 0.103490   LR 0.001000   
2022-11-03 21:16:00,331 - INFO  - ==> Top1: 98.724    Top5: 100.000    Loss: 0.037

2022-11-03 21:16:00,332 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:16:02,963 - INFO  - Validation [48][   20/   79]   Loss 0.371464   Top1 91.289062   Top5 99.687500   BatchTime 0.131505   
2022-11-03 21:16:03,797 - INFO  - Validation [48][   40/   79]   Loss 0.405253   Top1 91.035156   Top5 99.511719   BatchTime 0.086594   
2022-11-03 21:16:04,329 - INFO  - Validation [48][   60/   79]   Loss 0.400334   Top1 90.976562   Top5 99.544271   BatchTime 0.066593   
2022-11-03 21:16:05,073 - INFO  - ==> Top1: 90.860    Top5: 99.600    Loss: 0.395

2022-11-03 21:16:05,099 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:16:05,099 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:16:05,099 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:16:05,264 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_best.pth.tar

2022-11-03 21:16:05,265 - INFO  - >>>>>>>> Epoch  49
2022-11-03 21:16:05,266 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:16:08,839 - INFO  - Training [49][   20/  391]   Loss 0.045892   Top1 98.476562   Top5 100.000000   BatchTime 0.178663   LR 0.001000   
2022-11-03 21:16:10,369 - INFO  - Training [49][   40/  391]   Loss 0.044533   Top1 98.457031   Top5 100.000000   BatchTime 0.127585   LR 0.001000   
2022-11-03 21:16:12,414 - INFO  - Training [49][   60/  391]   Loss 0.041049   Top1 98.619792   Top5 100.000000   BatchTime 0.119136   LR 0.001000   
2022-11-03 21:16:14,410 - INFO  - Training [49][   80/  391]   Loss 0.040114   Top1 98.681641   Top5 100.000000   BatchTime 0.114304   LR 0.001000   
2022-11-03 21:16:16,440 - INFO  - Training [49][  100/  391]   Loss 0.041929   Top1 98.570312   Top5 100.000000   BatchTime 0.111738   LR 0.001000   
2022-11-03 21:16:18,437 - INFO  - Training [49][  120/  391]   Loss 0.041800   Top1 98.613281   Top5 100.000000   BatchTime 0.109757   LR 0.001000   
2022-11-03 21:16:20,439 - INFO  - Training [49][  140/  391]   Loss 0.039814   Top1 98.683036   Top5 100.000000   BatchTime 0.108381   LR 0.001000   
2022-11-03 21:16:22,389 - INFO  - Training [49][  160/  391]   Loss 0.039340   Top1 98.681641   Top5 100.000000   BatchTime 0.107021   LR 0.001000   
2022-11-03 21:16:24,372 - INFO  - Training [49][  180/  391]   Loss 0.039227   Top1 98.684896   Top5 100.000000   BatchTime 0.106147   LR 0.001000   
2022-11-03 21:16:26,377 - INFO  - Training [49][  200/  391]   Loss 0.038805   Top1 98.695312   Top5 100.000000   BatchTime 0.105557   LR 0.001000   
2022-11-03 21:16:28,389 - INFO  - Training [49][  220/  391]   Loss 0.039214   Top1 98.678977   Top5 100.000000   BatchTime 0.105104   LR 0.001000   
2022-11-03 21:16:30,405 - INFO  - Training [49][  240/  391]   Loss 0.038505   Top1 98.691406   Top5 100.000000   BatchTime 0.104744   LR 0.001000   
2022-11-03 21:16:32,427 - INFO  - Training [49][  260/  391]   Loss 0.038091   Top1 98.695913   Top5 100.000000   BatchTime 0.104463   LR 0.001000   
2022-11-03 21:16:34,432 - INFO  - Training [49][  280/  391]   Loss 0.037783   Top1 98.719308   Top5 100.000000   BatchTime 0.104165   LR 0.001000   
2022-11-03 21:16:36,457 - INFO  - Training [49][  300/  391]   Loss 0.037332   Top1 98.729167   Top5 100.000000   BatchTime 0.103969   LR 0.001000   
2022-11-03 21:16:38,480 - INFO  - Training [49][  320/  391]   Loss 0.037459   Top1 98.718262   Top5 100.000000   BatchTime 0.103792   LR 0.001000   
2022-11-03 21:16:40,481 - INFO  - Training [49][  340/  391]   Loss 0.037833   Top1 98.710938   Top5 100.000000   BatchTime 0.103572   LR 0.001000   
2022-11-03 21:16:42,468 - INFO  - Training [49][  360/  391]   Loss 0.037506   Top1 98.728299   Top5 100.000000   BatchTime 0.103339   LR 0.001000   
2022-11-03 21:16:44,436 - INFO  - Training [49][  380/  391]   Loss 0.037667   Top1 98.719161   Top5 100.000000   BatchTime 0.103079   LR 0.001000   
2022-11-03 21:16:45,848 - INFO  - ==> Top1: 98.712    Top5: 100.000    Loss: 0.038

2022-11-03 21:16:45,849 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:16:48,466 - INFO  - Validation [49][   20/   79]   Loss 0.378366   Top1 90.429688   Top5 99.804688   BatchTime 0.130753   
2022-11-03 21:16:49,322 - INFO  - Validation [49][   40/   79]   Loss 0.410115   Top1 90.214844   Top5 99.609375   BatchTime 0.086772   
2022-11-03 21:16:49,920 - INFO  - Validation [49][   60/   79]   Loss 0.406498   Top1 90.494792   Top5 99.622396   BatchTime 0.067809   
2022-11-03 21:16:50,649 - INFO  - ==> Top1: 90.520    Top5: 99.670    Loss: 0.399

2022-11-03 21:16:50,678 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:16:50,679 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:16:50,679 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:16:50,780 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:16:50,780 - INFO  - >>>>>>>> Epoch  50
2022-11-03 21:16:50,782 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:16:54,247 - INFO  - Training [50][   20/  391]   Loss 0.026830   Top1 99.062500   Top5 100.000000   BatchTime 0.173233   LR 0.001000   
2022-11-03 21:16:55,851 - INFO  - Training [50][   40/  391]   Loss 0.031120   Top1 98.750000   Top5 100.000000   BatchTime 0.126731   LR 0.001000   
2022-11-03 21:16:57,686 - INFO  - Training [50][   60/  391]   Loss 0.031570   Top1 98.802083   Top5 100.000000   BatchTime 0.115071   LR 0.001000   
2022-11-03 21:16:59,691 - INFO  - Training [50][   80/  391]   Loss 0.034888   Top1 98.701172   Top5 100.000000   BatchTime 0.111368   LR 0.001000   
2022-11-03 21:17:01,698 - INFO  - Training [50][  100/  391]   Loss 0.034026   Top1 98.742188   Top5 100.000000   BatchTime 0.109163   LR 0.001000   
2022-11-03 21:17:03,700 - INFO  - Training [50][  120/  391]   Loss 0.035109   Top1 98.710938   Top5 100.000000   BatchTime 0.107649   LR 0.001000   
2022-11-03 21:17:05,711 - INFO  - Training [50][  140/  391]   Loss 0.035320   Top1 98.710938   Top5 100.000000   BatchTime 0.106637   LR 0.001000   
2022-11-03 21:17:07,737 - INFO  - Training [50][  160/  391]   Loss 0.035544   Top1 98.706055   Top5 100.000000   BatchTime 0.105966   LR 0.001000   
2022-11-03 21:17:09,733 - INFO  - Training [50][  180/  391]   Loss 0.035421   Top1 98.719618   Top5 100.000000   BatchTime 0.105282   LR 0.001000   
2022-11-03 21:17:11,753 - INFO  - Training [50][  200/  391]   Loss 0.035569   Top1 98.710938   Top5 100.000000   BatchTime 0.104854   LR 0.001000   
2022-11-03 21:17:13,775 - INFO  - Training [50][  220/  391]   Loss 0.036093   Top1 98.700284   Top5 100.000000   BatchTime 0.104511   LR 0.001000   
2022-11-03 21:17:15,812 - INFO  - Training [50][  240/  391]   Loss 0.035990   Top1 98.691406   Top5 100.000000   BatchTime 0.104290   LR 0.001000   
2022-11-03 21:17:17,810 - INFO  - Training [50][  260/  391]   Loss 0.036473   Top1 98.677885   Top5 100.000000   BatchTime 0.103952   LR 0.001000   
2022-11-03 21:17:19,837 - INFO  - Training [50][  280/  391]   Loss 0.037242   Top1 98.652344   Top5 100.000000   BatchTime 0.103768   LR 0.001000   
2022-11-03 21:17:21,843 - INFO  - Training [50][  300/  391]   Loss 0.037123   Top1 98.640625   Top5 100.000000   BatchTime 0.103534   LR 0.001000   
2022-11-03 21:17:23,864 - INFO  - Training [50][  320/  391]   Loss 0.036987   Top1 98.652344   Top5 100.000000   BatchTime 0.103381   LR 0.001000   
2022-11-03 21:17:25,848 - INFO  - Training [50][  340/  391]   Loss 0.037256   Top1 98.644301   Top5 100.000000   BatchTime 0.103132   LR 0.001000   
2022-11-03 21:17:27,836 - INFO  - Training [50][  360/  391]   Loss 0.037145   Top1 98.637153   Top5 100.000000   BatchTime 0.102925   LR 0.001000   
2022-11-03 21:17:29,819 - INFO  - Training [50][  380/  391]   Loss 0.036969   Top1 98.645148   Top5 100.000000   BatchTime 0.102727   LR 0.001000   
2022-11-03 21:17:31,146 - INFO  - ==> Top1: 98.642    Top5: 100.000    Loss: 0.037

2022-11-03 21:17:31,146 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:17:33,734 - INFO  - Validation [50][   20/   79]   Loss 0.380777   Top1 90.703125   Top5 99.648438   BatchTime 0.129310   
2022-11-03 21:17:34,625 - INFO  - Validation [50][   40/   79]   Loss 0.409226   Top1 90.527344   Top5 99.550781   BatchTime 0.086946   
2022-11-03 21:17:35,421 - INFO  - Validation [50][   60/   79]   Loss 0.405134   Top1 90.598958   Top5 99.583333   BatchTime 0.071225   
2022-11-03 21:17:36,191 - INFO  - ==> Top1: 90.440    Top5: 99.630    Loss: 0.399

2022-11-03 21:17:36,217 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:17:36,218 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:17:36,218 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:17:36,321 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:17:36,322 - INFO  - >>>>>>>> Epoch  51
2022-11-03 21:17:36,323 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:17:39,811 - INFO  - Training [51][   20/  391]   Loss 0.030507   Top1 99.062500   Top5 100.000000   BatchTime 0.174353   LR 0.001000   
2022-11-03 21:17:41,557 - INFO  - Training [51][   40/  391]   Loss 0.033420   Top1 98.828125   Top5 100.000000   BatchTime 0.130829   LR 0.001000   
2022-11-03 21:17:43,325 - INFO  - Training [51][   60/  391]   Loss 0.032280   Top1 98.880208   Top5 100.000000   BatchTime 0.116690   LR 0.001000   
2022-11-03 21:17:45,337 - INFO  - Training [51][   80/  391]   Loss 0.031555   Top1 98.906250   Top5 100.000000   BatchTime 0.112666   LR 0.001000   
2022-11-03 21:17:47,351 - INFO  - Training [51][  100/  391]   Loss 0.032714   Top1 98.843750   Top5 100.000000   BatchTime 0.110273   LR 0.001000   
2022-11-03 21:17:49,365 - INFO  - Training [51][  120/  391]   Loss 0.033414   Top1 98.873698   Top5 100.000000   BatchTime 0.108677   LR 0.001000   
2022-11-03 21:17:51,404 - INFO  - Training [51][  140/  391]   Loss 0.033070   Top1 98.889509   Top5 100.000000   BatchTime 0.107712   LR 0.001000   
2022-11-03 21:17:53,426 - INFO  - Training [51][  160/  391]   Loss 0.033305   Top1 98.886719   Top5 100.000000   BatchTime 0.106887   LR 0.001000   
2022-11-03 21:17:55,452 - INFO  - Training [51][  180/  391]   Loss 0.034058   Top1 98.871528   Top5 99.995660   BatchTime 0.106267   LR 0.001000   
2022-11-03 21:17:57,479 - INFO  - Training [51][  200/  391]   Loss 0.034039   Top1 98.839844   Top5 99.996094   BatchTime 0.105772   LR 0.001000   
2022-11-03 21:17:59,480 - INFO  - Training [51][  220/  391]   Loss 0.034672   Top1 98.831676   Top5 99.996449   BatchTime 0.105253   LR 0.001000   
2022-11-03 21:18:01,421 - INFO  - Training [51][  240/  391]   Loss 0.034287   Top1 98.844401   Top5 99.996745   BatchTime 0.104571   LR 0.001000   
2022-11-03 21:18:03,418 - INFO  - Training [51][  260/  391]   Loss 0.033984   Top1 98.855168   Top5 99.996995   BatchTime 0.104207   LR 0.001000   
2022-11-03 21:18:05,444 - INFO  - Training [51][  280/  391]   Loss 0.034661   Top1 98.814174   Top5 99.997210   BatchTime 0.103997   LR 0.001000   
2022-11-03 21:18:07,472 - INFO  - Training [51][  300/  391]   Loss 0.034560   Top1 98.817708   Top5 99.997396   BatchTime 0.103825   LR 0.001000   
2022-11-03 21:18:09,502 - INFO  - Training [51][  320/  391]   Loss 0.034401   Top1 98.820801   Top5 99.997559   BatchTime 0.103680   LR 0.001000   
2022-11-03 21:18:11,494 - INFO  - Training [51][  340/  391]   Loss 0.034128   Top1 98.837316   Top5 99.997702   BatchTime 0.103439   LR 0.001000   
2022-11-03 21:18:13,505 - INFO  - Training [51][  360/  391]   Loss 0.034612   Top1 98.819444   Top5 99.997830   BatchTime 0.103280   LR 0.001000   
2022-11-03 21:18:15,486 - INFO  - Training [51][  380/  391]   Loss 0.034879   Top1 98.803454   Top5 99.997944   BatchTime 0.103057   LR 0.001000   
2022-11-03 21:18:16,792 - INFO  - ==> Top1: 98.800    Top5: 99.998    Loss: 0.035

2022-11-03 21:18:16,792 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:18:19,416 - INFO  - Validation [51][   20/   79]   Loss 0.380329   Top1 90.585938   Top5 99.648438   BatchTime 0.131126   
2022-11-03 21:18:20,324 - INFO  - Validation [51][   40/   79]   Loss 0.405335   Top1 90.468750   Top5 99.511719   BatchTime 0.088263   
2022-11-03 21:18:21,208 - INFO  - Validation [51][   60/   79]   Loss 0.402649   Top1 90.455729   Top5 99.557292   BatchTime 0.073577   
2022-11-03 21:18:22,090 - INFO  - ==> Top1: 90.520    Top5: 99.610    Loss: 0.398

2022-11-03 21:18:22,114 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:18:22,115 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:18:22,115 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:18:22,228 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:18:22,228 - INFO  - >>>>>>>> Epoch  52
2022-11-03 21:18:22,229 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:18:25,790 - INFO  - Training [52][   20/  391]   Loss 0.033003   Top1 98.906250   Top5 100.000000   BatchTime 0.178005   LR 0.001000   
2022-11-03 21:18:27,652 - INFO  - Training [52][   40/  391]   Loss 0.035552   Top1 98.789062   Top5 100.000000   BatchTime 0.135570   LR 0.001000   
2022-11-03 21:18:29,388 - INFO  - Training [52][   60/  391]   Loss 0.038496   Top1 98.697917   Top5 100.000000   BatchTime 0.119306   LR 0.001000   
2022-11-03 21:18:31,424 - INFO  - Training [52][   80/  391]   Loss 0.036742   Top1 98.759766   Top5 100.000000   BatchTime 0.114933   LR 0.001000   
2022-11-03 21:18:33,444 - INFO  - Training [52][  100/  391]   Loss 0.039060   Top1 98.671875   Top5 100.000000   BatchTime 0.112138   LR 0.001000   
2022-11-03 21:18:35,454 - INFO  - Training [52][  120/  391]   Loss 0.038616   Top1 98.710938   Top5 100.000000   BatchTime 0.110204   LR 0.001000   
2022-11-03 21:18:37,469 - INFO  - Training [52][  140/  391]   Loss 0.038319   Top1 98.699777   Top5 100.000000   BatchTime 0.108849   LR 0.001000   
2022-11-03 21:18:39,490 - INFO  - Training [52][  160/  391]   Loss 0.038574   Top1 98.691406   Top5 100.000000   BatchTime 0.107875   LR 0.001000   
2022-11-03 21:18:41,493 - INFO  - Training [52][  180/  391]   Loss 0.038198   Top1 98.680556   Top5 100.000000   BatchTime 0.107017   LR 0.001000   
2022-11-03 21:18:43,501 - INFO  - Training [52][  200/  391]   Loss 0.038003   Top1 98.687500   Top5 100.000000   BatchTime 0.106357   LR 0.001000   
2022-11-03 21:18:45,505 - INFO  - Training [52][  220/  391]   Loss 0.038463   Top1 98.668324   Top5 100.000000   BatchTime 0.105797   LR 0.001000   
2022-11-03 21:18:47,494 - INFO  - Training [52][  240/  391]   Loss 0.038727   Top1 98.658854   Top5 100.000000   BatchTime 0.105267   LR 0.001000   
2022-11-03 21:18:49,476 - INFO  - Training [52][  260/  391]   Loss 0.038779   Top1 98.650841   Top5 100.000000   BatchTime 0.104792   LR 0.001000   
2022-11-03 21:18:51,470 - INFO  - Training [52][  280/  391]   Loss 0.037822   Top1 98.694196   Top5 100.000000   BatchTime 0.104427   LR 0.001000   
2022-11-03 21:18:53,452 - INFO  - Training [52][  300/  391]   Loss 0.037272   Top1 98.726562   Top5 100.000000   BatchTime 0.104073   LR 0.001000   
2022-11-03 21:18:55,474 - INFO  - Training [52][  320/  391]   Loss 0.037539   Top1 98.715820   Top5 100.000000   BatchTime 0.103888   LR 0.001000   
2022-11-03 21:18:57,483 - INFO  - Training [52][  340/  391]   Loss 0.037398   Top1 98.715533   Top5 100.000000   BatchTime 0.103684   LR 0.001000   
2022-11-03 21:18:59,462 - INFO  - Training [52][  360/  391]   Loss 0.037221   Top1 98.721788   Top5 100.000000   BatchTime 0.103422   LR 0.001000   
2022-11-03 21:19:01,426 - INFO  - Training [52][  380/  391]   Loss 0.037161   Top1 98.721217   Top5 100.000000   BatchTime 0.103147   LR 0.001000   
2022-11-03 21:19:02,733 - INFO  - ==> Top1: 98.722    Top5: 100.000    Loss: 0.037

2022-11-03 21:19:02,733 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:19:05,340 - INFO  - Validation [52][   20/   79]   Loss 0.384543   Top1 91.015625   Top5 99.687500   BatchTime 0.130284   
2022-11-03 21:19:06,233 - INFO  - Validation [52][   40/   79]   Loss 0.414900   Top1 90.644531   Top5 99.609375   BatchTime 0.087447   
2022-11-03 21:19:07,164 - INFO  - Validation [52][   60/   79]   Loss 0.408909   Top1 90.742188   Top5 99.635417   BatchTime 0.073823   
2022-11-03 21:19:07,949 - INFO  - ==> Top1: 90.710    Top5: 99.670    Loss: 0.400

2022-11-03 21:19:07,976 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:19:07,976 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:19:07,976 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:19:08,058 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:19:08,059 - INFO  - >>>>>>>> Epoch  53
2022-11-03 21:19:08,060 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:19:11,566 - INFO  - Training [53][   20/  391]   Loss 0.033320   Top1 98.828125   Top5 100.000000   BatchTime 0.175308   LR 0.001000   
2022-11-03 21:19:13,311 - INFO  - Training [53][   40/  391]   Loss 0.031848   Top1 98.828125   Top5 100.000000   BatchTime 0.131288   LR 0.001000   
2022-11-03 21:19:14,957 - INFO  - Training [53][   60/  391]   Loss 0.030541   Top1 98.867188   Top5 100.000000   BatchTime 0.114944   LR 0.001000   
2022-11-03 21:19:16,962 - INFO  - Training [53][   80/  391]   Loss 0.028977   Top1 99.003906   Top5 100.000000   BatchTime 0.111274   LR 0.001000   
2022-11-03 21:19:18,963 - INFO  - Training [53][  100/  391]   Loss 0.030268   Top1 98.945312   Top5 100.000000   BatchTime 0.109027   LR 0.001000   
2022-11-03 21:19:20,966 - INFO  - Training [53][  120/  391]   Loss 0.031017   Top1 98.912760   Top5 100.000000   BatchTime 0.107549   LR 0.001000   
2022-11-03 21:19:22,980 - INFO  - Training [53][  140/  391]   Loss 0.032452   Top1 98.850446   Top5 100.000000   BatchTime 0.106570   LR 0.001000   
2022-11-03 21:19:24,990 - INFO  - Training [53][  160/  391]   Loss 0.033573   Top1 98.823242   Top5 100.000000   BatchTime 0.105810   LR 0.001000   
2022-11-03 21:19:26,983 - INFO  - Training [53][  180/  391]   Loss 0.033706   Top1 98.819444   Top5 100.000000   BatchTime 0.105129   LR 0.001000   
2022-11-03 21:19:28,982 - INFO  - Training [53][  200/  391]   Loss 0.033348   Top1 98.816406   Top5 100.000000   BatchTime 0.104608   LR 0.001000   
2022-11-03 21:19:30,991 - INFO  - Training [53][  220/  391]   Loss 0.033599   Top1 98.803267   Top5 100.000000   BatchTime 0.104232   LR 0.001000   
2022-11-03 21:19:32,995 - INFO  - Training [53][  240/  391]   Loss 0.033651   Top1 98.798828   Top5 100.000000   BatchTime 0.103893   LR 0.001000   
2022-11-03 21:19:34,974 - INFO  - Training [53][  260/  391]   Loss 0.033697   Top1 98.810096   Top5 100.000000   BatchTime 0.103514   LR 0.001000   
2022-11-03 21:19:36,917 - INFO  - Training [53][  280/  391]   Loss 0.033893   Top1 98.808594   Top5 100.000000   BatchTime 0.103060   LR 0.001000   
2022-11-03 21:19:38,902 - INFO  - Training [53][  300/  391]   Loss 0.034497   Top1 98.794271   Top5 99.997396   BatchTime 0.102806   LR 0.001000   
2022-11-03 21:19:40,934 - INFO  - Training [53][  320/  391]   Loss 0.034202   Top1 98.813477   Top5 99.997559   BatchTime 0.102731   LR 0.001000   
2022-11-03 21:19:42,923 - INFO  - Training [53][  340/  391]   Loss 0.034996   Top1 98.795956   Top5 99.997702   BatchTime 0.102536   LR 0.001000   
2022-11-03 21:19:44,883 - INFO  - Training [53][  360/  391]   Loss 0.034990   Top1 98.786892   Top5 99.997830   BatchTime 0.102284   LR 0.001000   
2022-11-03 21:19:46,855 - INFO  - Training [53][  380/  391]   Loss 0.035326   Top1 98.770559   Top5 99.997944   BatchTime 0.102090   LR 0.001000   
2022-11-03 21:19:48,169 - INFO  - ==> Top1: 98.762    Top5: 99.998    Loss: 0.036

2022-11-03 21:19:48,170 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:19:50,775 - INFO  - Validation [53][   20/   79]   Loss 0.382791   Top1 90.625000   Top5 99.609375   BatchTime 0.130129   
2022-11-03 21:19:51,676 - INFO  - Validation [53][   40/   79]   Loss 0.413846   Top1 90.585938   Top5 99.531250   BatchTime 0.087597   
2022-11-03 21:19:52,585 - INFO  - Validation [53][   60/   79]   Loss 0.408595   Top1 90.716146   Top5 99.531250   BatchTime 0.073546   
2022-11-03 21:19:53,556 - INFO  - ==> Top1: 90.660    Top5: 99.570    Loss: 0.405

2022-11-03 21:19:53,578 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:19:53,578 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:19:53,578 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:19:53,660 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:19:53,660 - INFO  - >>>>>>>> Epoch  54
2022-11-03 21:19:53,661 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:19:57,169 - INFO  - Training [54][   20/  391]   Loss 0.037901   Top1 98.867188   Top5 100.000000   BatchTime 0.175393   LR 0.001000   
2022-11-03 21:19:58,947 - INFO  - Training [54][   40/  391]   Loss 0.039504   Top1 98.769531   Top5 100.000000   BatchTime 0.132147   LR 0.001000   
2022-11-03 21:20:00,431 - INFO  - Training [54][   60/  391]   Loss 0.038597   Top1 98.736979   Top5 100.000000   BatchTime 0.112830   LR 0.001000   
2022-11-03 21:20:02,535 - INFO  - Training [54][   80/  391]   Loss 0.038103   Top1 98.720703   Top5 100.000000   BatchTime 0.110918   LR 0.001000   
2022-11-03 21:20:04,552 - INFO  - Training [54][  100/  391]   Loss 0.039657   Top1 98.601562   Top5 100.000000   BatchTime 0.108905   LR 0.001000   
2022-11-03 21:20:06,565 - INFO  - Training [54][  120/  391]   Loss 0.040005   Top1 98.613281   Top5 100.000000   BatchTime 0.107534   LR 0.001000   
2022-11-03 21:20:08,556 - INFO  - Training [54][  140/  391]   Loss 0.039468   Top1 98.643973   Top5 100.000000   BatchTime 0.106390   LR 0.001000   
2022-11-03 21:20:10,537 - INFO  - Training [54][  160/  391]   Loss 0.038042   Top1 98.671875   Top5 100.000000   BatchTime 0.105471   LR 0.001000   
2022-11-03 21:20:12,560 - INFO  - Training [54][  180/  391]   Loss 0.038278   Top1 98.680556   Top5 100.000000   BatchTime 0.104992   LR 0.001000   
2022-11-03 21:20:14,568 - INFO  - Training [54][  200/  391]   Loss 0.038769   Top1 98.683594   Top5 100.000000   BatchTime 0.104532   LR 0.001000   
2022-11-03 21:20:16,580 - INFO  - Training [54][  220/  391]   Loss 0.038198   Top1 98.689631   Top5 100.000000   BatchTime 0.104177   LR 0.001000   
2022-11-03 21:20:18,604 - INFO  - Training [54][  240/  391]   Loss 0.037613   Top1 98.717448   Top5 100.000000   BatchTime 0.103927   LR 0.001000   
2022-11-03 21:20:20,611 - INFO  - Training [54][  260/  391]   Loss 0.037038   Top1 98.750000   Top5 100.000000   BatchTime 0.103651   LR 0.001000   
2022-11-03 21:20:22,633 - INFO  - Training [54][  280/  391]   Loss 0.037161   Top1 98.755580   Top5 100.000000   BatchTime 0.103469   LR 0.001000   
2022-11-03 21:20:24,624 - INFO  - Training [54][  300/  391]   Loss 0.037049   Top1 98.755208   Top5 99.997396   BatchTime 0.103207   LR 0.001000   
2022-11-03 21:20:26,627 - INFO  - Training [54][  320/  391]   Loss 0.036702   Top1 98.769531   Top5 99.997559   BatchTime 0.103016   LR 0.001000   
2022-11-03 21:20:28,608 - INFO  - Training [54][  340/  391]   Loss 0.036509   Top1 98.763787   Top5 99.997702   BatchTime 0.102783   LR 0.001000   
2022-11-03 21:20:30,578 - INFO  - Training [54][  360/  391]   Loss 0.036196   Top1 98.786892   Top5 99.997830   BatchTime 0.102545   LR 0.001000   
2022-11-03 21:20:32,548 - INFO  - Training [54][  380/  391]   Loss 0.035933   Top1 98.793174   Top5 99.997944   BatchTime 0.102331   LR 0.001000   
2022-11-03 21:20:33,863 - INFO  - ==> Top1: 98.790    Top5: 99.998    Loss: 0.036

2022-11-03 21:20:33,864 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:20:36,510 - INFO  - Validation [54][   20/   79]   Loss 0.388992   Top1 90.546875   Top5 99.687500   BatchTime 0.132281   
2022-11-03 21:20:37,398 - INFO  - Validation [54][   40/   79]   Loss 0.421902   Top1 90.292969   Top5 99.589844   BatchTime 0.088343   
2022-11-03 21:20:38,320 - INFO  - Validation [54][   60/   79]   Loss 0.416311   Top1 90.429688   Top5 99.622396   BatchTime 0.074255   
2022-11-03 21:20:39,318 - INFO  - ==> Top1: 90.380    Top5: 99.650    Loss: 0.408

2022-11-03 21:20:39,345 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:20:39,345 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:20:39,345 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:20:39,445 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:20:39,446 - INFO  - >>>>>>>> Epoch  55
2022-11-03 21:20:39,447 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:20:43,021 - INFO  - Training [55][   20/  391]   Loss 0.037357   Top1 98.867188   Top5 100.000000   BatchTime 0.178673   LR 0.001000   
2022-11-03 21:20:44,692 - INFO  - Training [55][   40/  391]   Loss 0.036283   Top1 98.750000   Top5 100.000000   BatchTime 0.131106   LR 0.001000   
2022-11-03 21:20:46,239 - INFO  - Training [55][   60/  391]   Loss 0.035924   Top1 98.763021   Top5 100.000000   BatchTime 0.113185   LR 0.001000   
2022-11-03 21:20:48,208 - INFO  - Training [55][   80/  391]   Loss 0.034434   Top1 98.828125   Top5 100.000000   BatchTime 0.109505   LR 0.001000   
2022-11-03 21:20:50,195 - INFO  - Training [55][  100/  391]   Loss 0.034283   Top1 98.835938   Top5 100.000000   BatchTime 0.107476   LR 0.001000   
2022-11-03 21:20:52,208 - INFO  - Training [55][  120/  391]   Loss 0.033100   Top1 98.906250   Top5 100.000000   BatchTime 0.106339   LR 0.001000   
2022-11-03 21:20:54,209 - INFO  - Training [55][  140/  391]   Loss 0.034338   Top1 98.828125   Top5 100.000000   BatchTime 0.105441   LR 0.001000   
2022-11-03 21:20:56,222 - INFO  - Training [55][  160/  391]   Loss 0.034147   Top1 98.852539   Top5 100.000000   BatchTime 0.104842   LR 0.001000   
2022-11-03 21:20:58,226 - INFO  - Training [55][  180/  391]   Loss 0.033890   Top1 98.858507   Top5 100.000000   BatchTime 0.104322   LR 0.001000   
2022-11-03 21:21:00,218 - INFO  - Training [55][  200/  391]   Loss 0.033951   Top1 98.875000   Top5 99.996094   BatchTime 0.103852   LR 0.001000   
2022-11-03 21:21:02,207 - INFO  - Training [55][  220/  391]   Loss 0.034055   Top1 98.863636   Top5 99.996449   BatchTime 0.103449   LR 0.001000   
2022-11-03 21:21:04,203 - INFO  - Training [55][  240/  391]   Loss 0.034541   Top1 98.834635   Top5 99.996745   BatchTime 0.103148   LR 0.001000   
2022-11-03 21:21:06,184 - INFO  - Training [55][  260/  391]   Loss 0.034625   Top1 98.816106   Top5 99.996995   BatchTime 0.102832   LR 0.001000   
2022-11-03 21:21:08,174 - INFO  - Training [55][  280/  391]   Loss 0.034577   Top1 98.808594   Top5 99.997210   BatchTime 0.102591   LR 0.001000   
2022-11-03 21:21:10,165 - INFO  - Training [55][  300/  391]   Loss 0.034782   Top1 98.799479   Top5 99.997396   BatchTime 0.102389   LR 0.001000   
2022-11-03 21:21:12,169 - INFO  - Training [55][  320/  391]   Loss 0.034450   Top1 98.820801   Top5 99.997559   BatchTime 0.102253   LR 0.001000   
2022-11-03 21:21:14,152 - INFO  - Training [55][  340/  391]   Loss 0.034439   Top1 98.818934   Top5 99.997702   BatchTime 0.102070   LR 0.001000   
2022-11-03 21:21:16,101 - INFO  - Training [55][  360/  391]   Loss 0.034438   Top1 98.819444   Top5 99.997830   BatchTime 0.101813   LR 0.001000   
2022-11-03 21:21:18,072 - INFO  - Training [55][  380/  391]   Loss 0.034368   Top1 98.817845   Top5 99.997944   BatchTime 0.101643   LR 0.001000   
2022-11-03 21:21:19,401 - INFO  - ==> Top1: 98.818    Top5: 99.996    Loss: 0.034

2022-11-03 21:21:19,402 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:21:22,029 - INFO  - Validation [55][   20/   79]   Loss 0.370238   Top1 91.289062   Top5 99.687500   BatchTime 0.131301   
2022-11-03 21:21:22,924 - INFO  - Validation [55][   40/   79]   Loss 0.405816   Top1 90.878906   Top5 99.531250   BatchTime 0.088008   
2022-11-03 21:21:23,826 - INFO  - Validation [55][   60/   79]   Loss 0.405004   Top1 90.885417   Top5 99.557292   BatchTime 0.073714   
2022-11-03 21:21:25,046 - INFO  - ==> Top1: 90.780    Top5: 99.620    Loss: 0.396

2022-11-03 21:21:25,071 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:21:25,071 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:21:25,072 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:21:25,170 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:21:25,171 - INFO  - >>>>>>>> Epoch  56
2022-11-03 21:21:25,172 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:21:28,786 - INFO  - Training [56][   20/  391]   Loss 0.041271   Top1 98.671875   Top5 100.000000   BatchTime 0.180683   LR 0.001000   
2022-11-03 21:21:30,405 - INFO  - Training [56][   40/  391]   Loss 0.040726   Top1 98.652344   Top5 100.000000   BatchTime 0.130823   LR 0.001000   
2022-11-03 21:21:32,022 - INFO  - Training [56][   60/  391]   Loss 0.036782   Top1 98.776042   Top5 100.000000   BatchTime 0.114163   LR 0.001000   
2022-11-03 21:21:33,934 - INFO  - Training [56][   80/  391]   Loss 0.037879   Top1 98.740234   Top5 100.000000   BatchTime 0.109515   LR 0.001000   
2022-11-03 21:21:35,936 - INFO  - Training [56][  100/  391]   Loss 0.038075   Top1 98.687500   Top5 100.000000   BatchTime 0.107634   LR 0.001000   
2022-11-03 21:21:37,975 - INFO  - Training [56][  120/  391]   Loss 0.036646   Top1 98.756510   Top5 100.000000   BatchTime 0.106686   LR 0.001000   
2022-11-03 21:21:40,119 - INFO  - Training [56][  140/  391]   Loss 0.036204   Top1 98.755580   Top5 100.000000   BatchTime 0.106760   LR 0.001000   
2022-11-03 21:21:42,118 - INFO  - Training [56][  160/  391]   Loss 0.036398   Top1 98.759766   Top5 100.000000   BatchTime 0.105910   LR 0.001000   
2022-11-03 21:21:44,114 - INFO  - Training [56][  180/  391]   Loss 0.036065   Top1 98.784722   Top5 100.000000   BatchTime 0.105232   LR 0.001000   
2022-11-03 21:21:46,121 - INFO  - Training [56][  200/  391]   Loss 0.035180   Top1 98.835938   Top5 100.000000   BatchTime 0.104744   LR 0.001000   
2022-11-03 21:21:48,136 - INFO  - Training [56][  220/  391]   Loss 0.034487   Top1 98.856534   Top5 100.000000   BatchTime 0.104378   LR 0.001000   
2022-11-03 21:21:50,152 - INFO  - Training [56][  240/  391]   Loss 0.034479   Top1 98.854167   Top5 100.000000   BatchTime 0.104081   LR 0.001000   
2022-11-03 21:21:52,182 - INFO  - Training [56][  260/  391]   Loss 0.034902   Top1 98.846154   Top5 100.000000   BatchTime 0.103881   LR 0.001000   
2022-11-03 21:21:54,176 - INFO  - Training [56][  280/  391]   Loss 0.034976   Top1 98.833705   Top5 100.000000   BatchTime 0.103583   LR 0.001000   
2022-11-03 21:21:56,185 - INFO  - Training [56][  300/  391]   Loss 0.034988   Top1 98.835938   Top5 100.000000   BatchTime 0.103374   LR 0.001000   
2022-11-03 21:21:58,202 - INFO  - Training [56][  320/  391]   Loss 0.035175   Top1 98.815918   Top5 100.000000   BatchTime 0.103216   LR 0.001000   
2022-11-03 21:22:00,179 - INFO  - Training [56][  340/  391]   Loss 0.035283   Top1 98.812040   Top5 100.000000   BatchTime 0.102958   LR 0.001000   
2022-11-03 21:22:02,152 - INFO  - Training [56][  360/  391]   Loss 0.035083   Top1 98.825955   Top5 100.000000   BatchTime 0.102721   LR 0.001000   
2022-11-03 21:22:04,132 - INFO  - Training [56][  380/  391]   Loss 0.034650   Top1 98.838405   Top5 100.000000   BatchTime 0.102523   LR 0.001000   
2022-11-03 21:22:05,464 - INFO  - ==> Top1: 98.820    Top5: 100.000    Loss: 0.035

2022-11-03 21:22:05,465 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:22:08,083 - INFO  - Validation [56][   20/   79]   Loss 0.379882   Top1 91.054688   Top5 99.804688   BatchTime 0.130827   
2022-11-03 21:22:08,962 - INFO  - Validation [56][   40/   79]   Loss 0.416234   Top1 90.527344   Top5 99.687500   BatchTime 0.087376   
2022-11-03 21:22:09,861 - INFO  - Validation [56][   60/   79]   Loss 0.410358   Top1 90.729167   Top5 99.674479   BatchTime 0.073243   
2022-11-03 21:22:10,930 - INFO  - ==> Top1: 90.660    Top5: 99.700    Loss: 0.403

2022-11-03 21:22:10,996 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:22:10,997 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:22:10,997 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:22:11,132 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:22:11,133 - INFO  - >>>>>>>> Epoch  57
2022-11-03 21:22:11,134 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:22:14,708 - INFO  - Training [57][   20/  391]   Loss 0.036380   Top1 98.828125   Top5 100.000000   BatchTime 0.178710   LR 0.001000   
2022-11-03 21:22:16,320 - INFO  - Training [57][   40/  391]   Loss 0.036594   Top1 98.847656   Top5 100.000000   BatchTime 0.129644   LR 0.001000   
2022-11-03 21:22:18,032 - INFO  - Training [57][   60/  391]   Loss 0.033141   Top1 98.880208   Top5 100.000000   BatchTime 0.114969   LR 0.001000   
2022-11-03 21:22:19,866 - INFO  - Training [57][   80/  391]   Loss 0.033211   Top1 98.847656   Top5 100.000000   BatchTime 0.109145   LR 0.001000   
2022-11-03 21:22:21,889 - INFO  - Training [57][  100/  391]   Loss 0.032919   Top1 98.882812   Top5 100.000000   BatchTime 0.107547   LR 0.001000   
2022-11-03 21:22:23,916 - INFO  - Training [57][  120/  391]   Loss 0.033457   Top1 98.873698   Top5 100.000000   BatchTime 0.106513   LR 0.001000   
2022-11-03 21:22:25,918 - INFO  - Training [57][  140/  391]   Loss 0.033525   Top1 98.856027   Top5 100.000000   BatchTime 0.105599   LR 0.001000   
2022-11-03 21:22:27,931 - INFO  - Training [57][  160/  391]   Loss 0.033472   Top1 98.876953   Top5 100.000000   BatchTime 0.104979   LR 0.001000   
2022-11-03 21:22:29,955 - INFO  - Training [57][  180/  391]   Loss 0.033476   Top1 98.862847   Top5 100.000000   BatchTime 0.104557   LR 0.001000   
2022-11-03 21:22:31,951 - INFO  - Training [57][  200/  391]   Loss 0.034407   Top1 98.843750   Top5 100.000000   BatchTime 0.104080   LR 0.001000   
2022-11-03 21:22:33,952 - INFO  - Training [57][  220/  391]   Loss 0.034574   Top1 98.828125   Top5 100.000000   BatchTime 0.103713   LR 0.001000   
2022-11-03 21:22:35,951 - INFO  - Training [57][  240/  391]   Loss 0.035205   Top1 98.792318   Top5 100.000000   BatchTime 0.103400   LR 0.001000   
2022-11-03 21:22:37,946 - INFO  - Training [57][  260/  391]   Loss 0.034373   Top1 98.813101   Top5 100.000000   BatchTime 0.103122   LR 0.001000   
2022-11-03 21:22:39,985 - INFO  - Training [57][  280/  391]   Loss 0.034242   Top1 98.811384   Top5 100.000000   BatchTime 0.103037   LR 0.001000   
2022-11-03 21:22:41,987 - INFO  - Training [57][  300/  391]   Loss 0.034729   Top1 98.796875   Top5 100.000000   BatchTime 0.102841   LR 0.001000   
2022-11-03 21:22:44,000 - INFO  - Training [57][  320/  391]   Loss 0.034717   Top1 98.791504   Top5 100.000000   BatchTime 0.102702   LR 0.001000   
2022-11-03 21:22:45,989 - INFO  - Training [57][  340/  391]   Loss 0.034701   Top1 98.793658   Top5 100.000000   BatchTime 0.102510   LR 0.001000   
2022-11-03 21:22:47,979 - INFO  - Training [57][  360/  391]   Loss 0.034404   Top1 98.799913   Top5 100.000000   BatchTime 0.102344   LR 0.001000   
2022-11-03 21:22:49,954 - INFO  - Training [57][  380/  391]   Loss 0.034558   Top1 98.803454   Top5 100.000000   BatchTime 0.102155   LR 0.001000   
2022-11-03 21:22:51,272 - INFO  - ==> Top1: 98.792    Top5: 100.000    Loss: 0.035

2022-11-03 21:22:51,273 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:22:53,857 - INFO  - Validation [57][   20/   79]   Loss 0.372288   Top1 91.132812   Top5 99.726562   BatchTime 0.129132   
2022-11-03 21:22:54,770 - INFO  - Validation [57][   40/   79]   Loss 0.410137   Top1 90.507812   Top5 99.531250   BatchTime 0.087400   
2022-11-03 21:22:55,668 - INFO  - Validation [57][   60/   79]   Loss 0.406437   Top1 90.585938   Top5 99.557292   BatchTime 0.073234   
2022-11-03 21:22:56,749 - INFO  - ==> Top1: 90.680    Top5: 99.610    Loss: 0.399

2022-11-03 21:22:56,775 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:22:56,776 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:22:56,776 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:22:56,874 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:22:56,875 - INFO  - >>>>>>>> Epoch  58
2022-11-03 21:22:56,876 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:23:00,499 - INFO  - Training [58][   20/  391]   Loss 0.034705   Top1 99.023438   Top5 100.000000   BatchTime 0.181161   LR 0.001000   
2022-11-03 21:23:02,179 - INFO  - Training [58][   40/  391]   Loss 0.034564   Top1 98.925781   Top5 100.000000   BatchTime 0.132571   LR 0.001000   
2022-11-03 21:23:03,905 - INFO  - Training [58][   60/  391]   Loss 0.034012   Top1 98.893229   Top5 100.000000   BatchTime 0.117152   LR 0.001000   
2022-11-03 21:23:05,639 - INFO  - Training [58][   80/  391]   Loss 0.035411   Top1 98.857422   Top5 100.000000   BatchTime 0.109538   LR 0.001000   
2022-11-03 21:23:07,654 - INFO  - Training [58][  100/  391]   Loss 0.034411   Top1 98.867188   Top5 99.992188   BatchTime 0.107773   LR 0.001000   
2022-11-03 21:23:09,677 - INFO  - Training [58][  120/  391]   Loss 0.034809   Top1 98.880208   Top5 99.993490   BatchTime 0.106670   LR 0.001000   
2022-11-03 21:23:11,720 - INFO  - Training [58][  140/  391]   Loss 0.034142   Top1 98.911830   Top5 99.994420   BatchTime 0.106023   LR 0.001000   
2022-11-03 21:23:13,722 - INFO  - Training [58][  160/  391]   Loss 0.034630   Top1 98.891602   Top5 99.995117   BatchTime 0.105285   LR 0.001000   
2022-11-03 21:23:15,741 - INFO  - Training [58][  180/  391]   Loss 0.034310   Top1 98.880208   Top5 99.995660   BatchTime 0.104803   LR 0.001000   
2022-11-03 21:23:17,754 - INFO  - Training [58][  200/  391]   Loss 0.034039   Top1 98.886719   Top5 99.996094   BatchTime 0.104388   LR 0.001000   
2022-11-03 21:23:19,887 - INFO  - Training [58][  220/  391]   Loss 0.033858   Top1 98.884943   Top5 99.996449   BatchTime 0.104592   LR 0.001000   
2022-11-03 21:23:21,871 - INFO  - Training [58][  240/  391]   Loss 0.033748   Top1 98.893229   Top5 99.996745   BatchTime 0.104143   LR 0.001000   
2022-11-03 21:23:23,902 - INFO  - Training [58][  260/  391]   Loss 0.034074   Top1 98.876202   Top5 99.996995   BatchTime 0.103944   LR 0.001000   
2022-11-03 21:23:25,932 - INFO  - Training [58][  280/  391]   Loss 0.034028   Top1 98.875558   Top5 99.997210   BatchTime 0.103768   LR 0.001000   
2022-11-03 21:23:27,947 - INFO  - Training [58][  300/  391]   Loss 0.033901   Top1 98.880208   Top5 99.997396   BatchTime 0.103568   LR 0.001000   
2022-11-03 21:23:29,959 - INFO  - Training [58][  320/  391]   Loss 0.034224   Top1 98.859863   Top5 99.997559   BatchTime 0.103381   LR 0.001000   
2022-11-03 21:23:31,952 - INFO  - Training [58][  340/  391]   Loss 0.034252   Top1 98.862592   Top5 99.997702   BatchTime 0.103163   LR 0.001000   
2022-11-03 21:23:33,919 - INFO  - Training [58][  360/  391]   Loss 0.033810   Top1 98.869358   Top5 99.997830   BatchTime 0.102895   LR 0.001000   
2022-11-03 21:23:35,902 - INFO  - Training [58][  380/  391]   Loss 0.034251   Top1 98.854852   Top5 99.997944   BatchTime 0.102697   LR 0.001000   
2022-11-03 21:23:37,219 - INFO  - ==> Top1: 98.842    Top5: 99.998    Loss: 0.034

2022-11-03 21:23:37,220 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:23:39,843 - INFO  - Validation [58][   20/   79]   Loss 0.385688   Top1 90.742188   Top5 99.687500   BatchTime 0.131115   
2022-11-03 21:23:40,705 - INFO  - Validation [58][   40/   79]   Loss 0.414363   Top1 90.410156   Top5 99.628906   BatchTime 0.087097   
2022-11-03 21:23:41,586 - INFO  - Validation [58][   60/   79]   Loss 0.409921   Top1 90.585938   Top5 99.648438   BatchTime 0.072754   
2022-11-03 21:23:42,665 - INFO  - ==> Top1: 90.510    Top5: 99.670    Loss: 0.404

2022-11-03 21:23:42,709 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:23:42,710 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:23:42,710 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:23:42,816 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:23:42,816 - INFO  - >>>>>>>> Epoch  59
2022-11-03 21:23:42,817 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:23:46,476 - INFO  - Training [59][   20/  391]   Loss 0.033907   Top1 98.828125   Top5 100.000000   BatchTime 0.182924   LR 0.001000   
2022-11-03 21:23:48,124 - INFO  - Training [59][   40/  391]   Loss 0.035574   Top1 98.808594   Top5 100.000000   BatchTime 0.132663   LR 0.001000   
2022-11-03 21:23:49,858 - INFO  - Training [59][   60/  391]   Loss 0.033615   Top1 98.867188   Top5 100.000000   BatchTime 0.117352   LR 0.001000   
2022-11-03 21:23:51,544 - INFO  - Training [59][   80/  391]   Loss 0.032155   Top1 98.867188   Top5 100.000000   BatchTime 0.109084   LR 0.001000   
2022-11-03 21:23:53,556 - INFO  - Training [59][  100/  391]   Loss 0.033597   Top1 98.835938   Top5 100.000000   BatchTime 0.107390   LR 0.001000   
2022-11-03 21:23:55,569 - INFO  - Training [59][  120/  391]   Loss 0.033498   Top1 98.847656   Top5 100.000000   BatchTime 0.106265   LR 0.001000   
2022-11-03 21:23:57,588 - INFO  - Training [59][  140/  391]   Loss 0.032726   Top1 98.872768   Top5 100.000000   BatchTime 0.105507   LR 0.001000   
2022-11-03 21:23:59,607 - INFO  - Training [59][  160/  391]   Loss 0.032781   Top1 98.852539   Top5 100.000000   BatchTime 0.104936   LR 0.001000   
2022-11-03 21:24:01,611 - INFO  - Training [59][  180/  391]   Loss 0.033379   Top1 98.828125   Top5 100.000000   BatchTime 0.104410   LR 0.001000   
2022-11-03 21:24:03,615 - INFO  - Training [59][  200/  391]   Loss 0.034122   Top1 98.792969   Top5 100.000000   BatchTime 0.103990   LR 0.001000   
2022-11-03 21:24:05,624 - INFO  - Training [59][  220/  391]   Loss 0.034780   Top1 98.760653   Top5 100.000000   BatchTime 0.103664   LR 0.001000   
2022-11-03 21:24:07,627 - INFO  - Training [59][  240/  391]   Loss 0.034717   Top1 98.753255   Top5 100.000000   BatchTime 0.103373   LR 0.001000   
2022-11-03 21:24:09,627 - INFO  - Training [59][  260/  391]   Loss 0.035404   Top1 98.731971   Top5 99.996995   BatchTime 0.103114   LR 0.001000   
2022-11-03 21:24:11,648 - INFO  - Training [59][  280/  391]   Loss 0.035353   Top1 98.719308   Top5 99.997210   BatchTime 0.102967   LR 0.001000   
2022-11-03 21:24:13,658 - INFO  - Training [59][  300/  391]   Loss 0.035384   Top1 98.710938   Top5 99.997396   BatchTime 0.102800   LR 0.001000   
2022-11-03 21:24:15,661 - INFO  - Training [59][  320/  391]   Loss 0.035788   Top1 98.688965   Top5 99.997559   BatchTime 0.102636   LR 0.001000   
2022-11-03 21:24:17,674 - INFO  - Training [59][  340/  391]   Loss 0.036153   Top1 98.681066   Top5 99.997702   BatchTime 0.102518   LR 0.001000   
2022-11-03 21:24:19,650 - INFO  - Training [59][  360/  391]   Loss 0.035929   Top1 98.693576   Top5 99.997830   BatchTime 0.102312   LR 0.001000   
2022-11-03 21:24:21,642 - INFO  - Training [59][  380/  391]   Loss 0.035696   Top1 98.704770   Top5 99.997944   BatchTime 0.102170   LR 0.001000   
2022-11-03 21:24:22,985 - INFO  - ==> Top1: 98.708    Top5: 99.998    Loss: 0.036

2022-11-03 21:24:22,986 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:24:25,620 - INFO  - Validation [59][   20/   79]   Loss 0.366358   Top1 90.781250   Top5 99.765625   BatchTime 0.131638   
2022-11-03 21:24:26,511 - INFO  - Validation [59][   40/   79]   Loss 0.411448   Top1 90.507812   Top5 99.609375   BatchTime 0.088107   
2022-11-03 21:24:27,362 - INFO  - Validation [59][   60/   79]   Loss 0.405350   Top1 90.703125   Top5 99.661458   BatchTime 0.072906   
2022-11-03 21:24:28,450 - INFO  - ==> Top1: 90.680    Top5: 99.670    Loss: 0.401

2022-11-03 21:24:28,492 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:24:28,493 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:24:28,493 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:24:28,573 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:24:28,573 - INFO  - >>>>>>>> Epoch  60
2022-11-03 21:24:28,575 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:24:32,235 - INFO  - Training [60][   20/  391]   Loss 0.040000   Top1 98.632812   Top5 100.000000   BatchTime 0.183018   LR 0.000100   
2022-11-03 21:24:33,912 - INFO  - Training [60][   40/  391]   Loss 0.036623   Top1 98.632812   Top5 100.000000   BatchTime 0.133436   LR 0.000100   
2022-11-03 21:24:35,649 - INFO  - Training [60][   60/  391]   Loss 0.036314   Top1 98.619792   Top5 100.000000   BatchTime 0.117897   LR 0.000100   
2022-11-03 21:24:37,127 - INFO  - Training [60][   80/  391]   Loss 0.035621   Top1 98.662109   Top5 100.000000   BatchTime 0.106907   LR 0.000100   
2022-11-03 21:24:39,182 - INFO  - Training [60][  100/  391]   Loss 0.034882   Top1 98.695312   Top5 100.000000   BatchTime 0.106069   LR 0.000100   
2022-11-03 21:24:41,195 - INFO  - Training [60][  120/  391]   Loss 0.035070   Top1 98.691406   Top5 100.000000   BatchTime 0.105165   LR 0.000100   
2022-11-03 21:24:43,221 - INFO  - Training [60][  140/  391]   Loss 0.034459   Top1 98.694196   Top5 100.000000   BatchTime 0.104616   LR 0.000100   
2022-11-03 21:24:45,236 - INFO  - Training [60][  160/  391]   Loss 0.034647   Top1 98.725586   Top5 100.000000   BatchTime 0.104129   LR 0.000100   
2022-11-03 21:24:47,257 - INFO  - Training [60][  180/  391]   Loss 0.034803   Top1 98.706597   Top5 100.000000   BatchTime 0.103786   LR 0.000100   
2022-11-03 21:24:49,274 - INFO  - Training [60][  200/  391]   Loss 0.034427   Top1 98.742188   Top5 100.000000   BatchTime 0.103495   LR 0.000100   
2022-11-03 21:24:51,299 - INFO  - Training [60][  220/  391]   Loss 0.033997   Top1 98.753551   Top5 100.000000   BatchTime 0.103290   LR 0.000100   
2022-11-03 21:24:53,308 - INFO  - Training [60][  240/  391]   Loss 0.033822   Top1 98.763021   Top5 100.000000   BatchTime 0.103054   LR 0.000100   
2022-11-03 21:24:55,331 - INFO  - Training [60][  260/  391]   Loss 0.034242   Top1 98.753005   Top5 100.000000   BatchTime 0.102906   LR 0.000100   
2022-11-03 21:24:57,446 - INFO  - Training [60][  280/  391]   Loss 0.034011   Top1 98.775112   Top5 100.000000   BatchTime 0.103110   LR 0.000100   
2022-11-03 21:24:59,472 - INFO  - Training [60][  300/  391]   Loss 0.033866   Top1 98.794271   Top5 100.000000   BatchTime 0.102990   LR 0.000100   
2022-11-03 21:25:01,495 - INFO  - Training [60][  320/  391]   Loss 0.033586   Top1 98.806152   Top5 100.000000   BatchTime 0.102874   LR 0.000100   
2022-11-03 21:25:03,503 - INFO  - Training [60][  340/  391]   Loss 0.033829   Top1 98.793658   Top5 100.000000   BatchTime 0.102729   LR 0.000100   
2022-11-03 21:25:05,483 - INFO  - Training [60][  360/  391]   Loss 0.033962   Top1 98.789062   Top5 100.000000   BatchTime 0.102521   LR 0.000100   
2022-11-03 21:25:07,462 - INFO  - Training [60][  380/  391]   Loss 0.033850   Top1 98.782895   Top5 100.000000   BatchTime 0.102332   LR 0.000100   
2022-11-03 21:25:08,799 - INFO  - ==> Top1: 98.786    Top5: 100.000    Loss: 0.034

2022-11-03 21:25:08,799 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:25:11,470 - INFO  - Validation [60][   20/   79]   Loss 0.381602   Top1 90.820312   Top5 99.570312   BatchTime 0.133491   
2022-11-03 21:25:12,368 - INFO  - Validation [60][   40/   79]   Loss 0.416434   Top1 90.468750   Top5 99.511719   BatchTime 0.089190   
2022-11-03 21:25:13,272 - INFO  - Validation [60][   60/   79]   Loss 0.410073   Top1 90.638021   Top5 99.583333   BatchTime 0.074528   
2022-11-03 21:25:14,351 - INFO  - ==> Top1: 90.630    Top5: 99.590    Loss: 0.405

2022-11-03 21:25:14,397 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:25:14,398 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:25:14,398 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:25:14,504 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:25:14,504 - INFO  - >>>>>>>> Epoch  61
2022-11-03 21:25:14,506 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:25:18,065 - INFO  - Training [61][   20/  391]   Loss 0.035466   Top1 98.867188   Top5 100.000000   BatchTime 0.177969   LR 0.000100   
2022-11-03 21:25:19,752 - INFO  - Training [61][   40/  391]   Loss 0.034653   Top1 98.828125   Top5 100.000000   BatchTime 0.131149   LR 0.000100   
2022-11-03 21:25:21,489 - INFO  - Training [61][   60/  391]   Loss 0.032621   Top1 98.828125   Top5 100.000000   BatchTime 0.116387   LR 0.000100   
2022-11-03 21:25:22,972 - INFO  - Training [61][   80/  391]   Loss 0.033978   Top1 98.828125   Top5 100.000000   BatchTime 0.105828   LR 0.000100   
2022-11-03 21:25:25,075 - INFO  - Training [61][  100/  391]   Loss 0.032383   Top1 98.906250   Top5 100.000000   BatchTime 0.105689   LR 0.000100   
2022-11-03 21:25:27,073 - INFO  - Training [61][  120/  391]   Loss 0.032636   Top1 98.906250   Top5 100.000000   BatchTime 0.104723   LR 0.000100   
2022-11-03 21:25:29,112 - INFO  - Training [61][  140/  391]   Loss 0.033140   Top1 98.895089   Top5 100.000000   BatchTime 0.104323   LR 0.000100   
2022-11-03 21:25:31,110 - INFO  - Training [61][  160/  391]   Loss 0.032509   Top1 98.906250   Top5 100.000000   BatchTime 0.103774   LR 0.000100   
2022-11-03 21:25:33,133 - INFO  - Training [61][  180/  391]   Loss 0.032937   Top1 98.858507   Top5 100.000000   BatchTime 0.103478   LR 0.000100   
2022-11-03 21:25:35,141 - INFO  - Training [61][  200/  391]   Loss 0.033459   Top1 98.847656   Top5 100.000000   BatchTime 0.103174   LR 0.000100   
2022-11-03 21:25:37,154 - INFO  - Training [61][  220/  391]   Loss 0.033490   Top1 98.856534   Top5 100.000000   BatchTime 0.102944   LR 0.000100   
2022-11-03 21:25:39,159 - INFO  - Training [61][  240/  391]   Loss 0.033564   Top1 98.850911   Top5 100.000000   BatchTime 0.102718   LR 0.000100   
2022-11-03 21:25:41,185 - INFO  - Training [61][  260/  391]   Loss 0.032924   Top1 98.876202   Top5 100.000000   BatchTime 0.102608   LR 0.000100   
2022-11-03 21:25:43,192 - INFO  - Training [61][  280/  391]   Loss 0.033416   Top1 98.864397   Top5 100.000000   BatchTime 0.102447   LR 0.000100   
2022-11-03 21:25:45,199 - INFO  - Training [61][  300/  391]   Loss 0.033635   Top1 98.846354   Top5 100.000000   BatchTime 0.102306   LR 0.000100   
2022-11-03 21:25:47,206 - INFO  - Training [61][  320/  391]   Loss 0.034175   Top1 98.806152   Top5 100.000000   BatchTime 0.102185   LR 0.000100   
2022-11-03 21:25:49,174 - INFO  - Training [61][  340/  391]   Loss 0.034406   Top1 98.805147   Top5 100.000000   BatchTime 0.101962   LR 0.000100   
2022-11-03 21:25:51,161 - INFO  - Training [61][  360/  391]   Loss 0.034393   Top1 98.812934   Top5 100.000000   BatchTime 0.101818   LR 0.000100   
2022-11-03 21:25:53,131 - INFO  - Training [61][  380/  391]   Loss 0.034296   Top1 98.826069   Top5 100.000000   BatchTime 0.101642   LR 0.000100   
2022-11-03 21:25:54,456 - INFO  - ==> Top1: 98.810    Top5: 100.000    Loss: 0.035

2022-11-03 21:25:54,457 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:25:57,093 - INFO  - Validation [61][   20/   79]   Loss 0.376005   Top1 91.093750   Top5 99.609375   BatchTime 0.131715   
2022-11-03 21:25:58,023 - INFO  - Validation [61][   40/   79]   Loss 0.412066   Top1 90.605469   Top5 99.628906   BatchTime 0.089117   
2022-11-03 21:25:58,928 - INFO  - Validation [61][   60/   79]   Loss 0.405690   Top1 90.742188   Top5 99.661458   BatchTime 0.074497   
2022-11-03 21:26:00,050 - INFO  - ==> Top1: 90.630    Top5: 99.670    Loss: 0.401

2022-11-03 21:26:00,088 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:26:00,089 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:26:00,089 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:26:00,196 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:26:00,196 - INFO  - >>>>>>>> Epoch  62
2022-11-03 21:26:00,197 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:26:03,753 - INFO  - Training [62][   20/  391]   Loss 0.034338   Top1 98.945312   Top5 99.960938   BatchTime 0.177819   LR 0.000100   
2022-11-03 21:26:05,390 - INFO  - Training [62][   40/  391]   Loss 0.033839   Top1 98.886719   Top5 99.980469   BatchTime 0.129823   LR 0.000100   
2022-11-03 21:26:07,159 - INFO  - Training [62][   60/  391]   Loss 0.032306   Top1 98.958333   Top5 99.986979   BatchTime 0.116031   LR 0.000100   
2022-11-03 21:26:08,680 - INFO  - Training [62][   80/  391]   Loss 0.033832   Top1 98.964844   Top5 99.990234   BatchTime 0.106036   LR 0.000100   
2022-11-03 21:26:10,649 - INFO  - Training [62][  100/  391]   Loss 0.033592   Top1 98.929688   Top5 99.992188   BatchTime 0.104514   LR 0.000100   
2022-11-03 21:26:12,663 - INFO  - Training [62][  120/  391]   Loss 0.033404   Top1 98.919271   Top5 99.993490   BatchTime 0.103882   LR 0.000100   
2022-11-03 21:26:14,685 - INFO  - Training [62][  140/  391]   Loss 0.033719   Top1 98.883929   Top5 99.994420   BatchTime 0.103486   LR 0.000100   
2022-11-03 21:26:16,720 - INFO  - Training [62][  160/  391]   Loss 0.033378   Top1 98.852539   Top5 99.995117   BatchTime 0.103264   LR 0.000100   
2022-11-03 21:26:18,743 - INFO  - Training [62][  180/  391]   Loss 0.033524   Top1 98.849826   Top5 99.995660   BatchTime 0.103031   LR 0.000100   
2022-11-03 21:26:20,761 - INFO  - Training [62][  200/  391]   Loss 0.033836   Top1 98.828125   Top5 99.996094   BatchTime 0.102818   LR 0.000100   
2022-11-03 21:26:22,774 - INFO  - Training [62][  220/  391]   Loss 0.033965   Top1 98.821023   Top5 99.996449   BatchTime 0.102622   LR 0.000100   
2022-11-03 21:26:24,794 - INFO  - Training [62][  240/  391]   Loss 0.034076   Top1 98.824870   Top5 99.993490   BatchTime 0.102485   LR 0.000100   
2022-11-03 21:26:26,821 - INFO  - Training [62][  260/  391]   Loss 0.034050   Top1 98.834135   Top5 99.993990   BatchTime 0.102397   LR 0.000100   
2022-11-03 21:26:28,849 - INFO  - Training [62][  280/  391]   Loss 0.033644   Top1 98.853237   Top5 99.994420   BatchTime 0.102326   LR 0.000100   
2022-11-03 21:26:30,845 - INFO  - Training [62][  300/  391]   Loss 0.033533   Top1 98.843750   Top5 99.994792   BatchTime 0.102157   LR 0.000100   
2022-11-03 21:26:32,955 - INFO  - Training [62][  320/  391]   Loss 0.033533   Top1 98.845215   Top5 99.995117   BatchTime 0.102368   LR 0.000100   
2022-11-03 21:26:34,961 - INFO  - Training [62][  340/  391]   Loss 0.033455   Top1 98.857996   Top5 99.995404   BatchTime 0.102245   LR 0.000100   
2022-11-03 21:26:36,953 - INFO  - Training [62][  360/  391]   Loss 0.033613   Top1 98.856337   Top5 99.995660   BatchTime 0.102097   LR 0.000100   
2022-11-03 21:26:38,958 - INFO  - Training [62][  380/  391]   Loss 0.033212   Top1 98.871299   Top5 99.995888   BatchTime 0.102001   LR 0.000100   
2022-11-03 21:26:40,279 - INFO  - ==> Top1: 98.866    Top5: 99.996    Loss: 0.033

2022-11-03 21:26:40,280 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:26:42,902 - INFO  - Validation [62][   20/   79]   Loss 0.384498   Top1 90.976562   Top5 99.570312   BatchTime 0.131009   
2022-11-03 21:26:43,785 - INFO  - Validation [62][   40/   79]   Loss 0.417953   Top1 90.722656   Top5 99.511719   BatchTime 0.087582   
2022-11-03 21:26:44,688 - INFO  - Validation [62][   60/   79]   Loss 0.409802   Top1 90.768229   Top5 99.557292   BatchTime 0.073438   
2022-11-03 21:26:45,774 - INFO  - ==> Top1: 90.700    Top5: 99.580    Loss: 0.405

2022-11-03 21:26:45,809 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:26:45,810 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:26:45,810 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:26:45,903 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:26:45,903 - INFO  - >>>>>>>> Epoch  63
2022-11-03 21:26:45,904 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:26:49,469 - INFO  - Training [63][   20/  391]   Loss 0.031978   Top1 98.945312   Top5 100.000000   BatchTime 0.178205   LR 0.000100   
2022-11-03 21:26:51,149 - INFO  - Training [63][   40/  391]   Loss 0.033841   Top1 98.886719   Top5 100.000000   BatchTime 0.131123   LR 0.000100   
2022-11-03 21:26:52,797 - INFO  - Training [63][   60/  391]   Loss 0.035555   Top1 98.789062   Top5 100.000000   BatchTime 0.114867   LR 0.000100   
2022-11-03 21:26:54,432 - INFO  - Training [63][   80/  391]   Loss 0.036142   Top1 98.750000   Top5 100.000000   BatchTime 0.106586   LR 0.000100   
2022-11-03 21:26:56,406 - INFO  - Training [63][  100/  391]   Loss 0.035797   Top1 98.773438   Top5 100.000000   BatchTime 0.105012   LR 0.000100   
2022-11-03 21:26:58,407 - INFO  - Training [63][  120/  391]   Loss 0.035387   Top1 98.769531   Top5 100.000000   BatchTime 0.104181   LR 0.000100   
2022-11-03 21:27:00,444 - INFO  - Training [63][  140/  391]   Loss 0.036184   Top1 98.727679   Top5 100.000000   BatchTime 0.103851   LR 0.000100   
2022-11-03 21:27:02,451 - INFO  - Training [63][  160/  391]   Loss 0.035874   Top1 98.754883   Top5 100.000000   BatchTime 0.103416   LR 0.000100   
2022-11-03 21:27:04,478 - INFO  - Training [63][  180/  391]   Loss 0.035416   Top1 98.758681   Top5 99.995660   BatchTime 0.103183   LR 0.000100   
2022-11-03 21:27:06,491 - INFO  - Training [63][  200/  391]   Loss 0.035355   Top1 98.773438   Top5 99.996094   BatchTime 0.102932   LR 0.000100   
2022-11-03 21:27:08,506 - INFO  - Training [63][  220/  391]   Loss 0.034962   Top1 98.774858   Top5 99.996449   BatchTime 0.102731   LR 0.000100   
2022-11-03 21:27:10,526 - INFO  - Training [63][  240/  391]   Loss 0.034620   Top1 98.789062   Top5 99.996745   BatchTime 0.102587   LR 0.000100   
2022-11-03 21:27:12,533 - INFO  - Training [63][  260/  391]   Loss 0.034738   Top1 98.780048   Top5 99.996995   BatchTime 0.102416   LR 0.000100   
2022-11-03 21:27:14,533 - INFO  - Training [63][  280/  391]   Loss 0.034750   Top1 98.786272   Top5 99.997210   BatchTime 0.102244   LR 0.000100   
2022-11-03 21:27:16,587 - INFO  - Training [63][  300/  391]   Loss 0.034399   Top1 98.799479   Top5 99.997396   BatchTime 0.102273   LR 0.000100   
2022-11-03 21:27:18,596 - INFO  - Training [63][  320/  391]   Loss 0.034311   Top1 98.820801   Top5 99.997559   BatchTime 0.102157   LR 0.000100   
2022-11-03 21:27:20,607 - INFO  - Training [63][  340/  391]   Loss 0.034264   Top1 98.823529   Top5 99.997702   BatchTime 0.102063   LR 0.000100   
2022-11-03 21:27:22,581 - INFO  - Training [63][  360/  391]   Loss 0.034451   Top1 98.810764   Top5 99.997830   BatchTime 0.101876   LR 0.000100   
2022-11-03 21:27:24,558 - INFO  - Training [63][  380/  391]   Loss 0.034724   Top1 98.801398   Top5 99.997944   BatchTime 0.101718   LR 0.000100   
2022-11-03 21:27:25,882 - INFO  - ==> Top1: 98.794    Top5: 99.998    Loss: 0.035

2022-11-03 21:27:25,883 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:27:28,537 - INFO  - Validation [63][   20/   79]   Loss 0.377691   Top1 90.781250   Top5 99.726562   BatchTime 0.132670   
2022-11-03 21:27:29,426 - INFO  - Validation [63][   40/   79]   Loss 0.411730   Top1 90.507812   Top5 99.609375   BatchTime 0.088557   
2022-11-03 21:27:30,324 - INFO  - Validation [63][   60/   79]   Loss 0.405705   Top1 90.611979   Top5 99.635417   BatchTime 0.073997   
2022-11-03 21:27:31,438 - INFO  - ==> Top1: 90.590    Top5: 99.660    Loss: 0.399

2022-11-03 21:27:31,480 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:27:31,481 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:27:31,481 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:27:31,573 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:27:31,573 - INFO  - >>>>>>>> Epoch  64
2022-11-03 21:27:31,574 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:27:35,129 - INFO  - Training [64][   20/  391]   Loss 0.031002   Top1 98.828125   Top5 100.000000   BatchTime 0.177758   LR 0.000100   
2022-11-03 21:27:36,778 - INFO  - Training [64][   40/  391]   Loss 0.032633   Top1 98.925781   Top5 100.000000   BatchTime 0.130110   LR 0.000100   
2022-11-03 21:27:38,405 - INFO  - Training [64][   60/  391]   Loss 0.033487   Top1 98.893229   Top5 100.000000   BatchTime 0.113847   LR 0.000100   
2022-11-03 21:27:40,105 - INFO  - Training [64][   80/  391]   Loss 0.033847   Top1 98.828125   Top5 100.000000   BatchTime 0.106629   LR 0.000100   
2022-11-03 21:27:41,991 - INFO  - Training [64][  100/  391]   Loss 0.034082   Top1 98.828125   Top5 100.000000   BatchTime 0.104169   LR 0.000100   
2022-11-03 21:27:44,022 - INFO  - Training [64][  120/  391]   Loss 0.032925   Top1 98.893229   Top5 100.000000   BatchTime 0.103732   LR 0.000100   
2022-11-03 21:27:46,032 - INFO  - Training [64][  140/  391]   Loss 0.033178   Top1 98.895089   Top5 100.000000   BatchTime 0.103268   LR 0.000100   
2022-11-03 21:27:48,048 - INFO  - Training [64][  160/  391]   Loss 0.032942   Top1 98.901367   Top5 100.000000   BatchTime 0.102960   LR 0.000100   
2022-11-03 21:27:50,058 - INFO  - Training [64][  180/  391]   Loss 0.032991   Top1 98.893229   Top5 100.000000   BatchTime 0.102686   LR 0.000100   
2022-11-03 21:27:52,089 - INFO  - Training [64][  200/  391]   Loss 0.033290   Top1 98.875000   Top5 100.000000   BatchTime 0.102572   LR 0.000100   
2022-11-03 21:27:54,124 - INFO  - Training [64][  220/  391]   Loss 0.033944   Top1 98.856534   Top5 100.000000   BatchTime 0.102496   LR 0.000100   
2022-11-03 21:27:56,160 - INFO  - Training [64][  240/  391]   Loss 0.033937   Top1 98.850911   Top5 100.000000   BatchTime 0.102437   LR 0.000100   
2022-11-03 21:27:58,165 - INFO  - Training [64][  260/  391]   Loss 0.033990   Top1 98.837139   Top5 100.000000   BatchTime 0.102268   LR 0.000100   
2022-11-03 21:28:00,182 - INFO  - Training [64][  280/  391]   Loss 0.034039   Top1 98.822545   Top5 100.000000   BatchTime 0.102170   LR 0.000100   
2022-11-03 21:28:02,212 - INFO  - Training [64][  300/  391]   Loss 0.034203   Top1 98.812500   Top5 99.997396   BatchTime 0.102123   LR 0.000100   
2022-11-03 21:28:04,229 - INFO  - Training [64][  320/  391]   Loss 0.033921   Top1 98.828125   Top5 99.995117   BatchTime 0.102045   LR 0.000100   
2022-11-03 21:28:06,218 - INFO  - Training [64][  340/  391]   Loss 0.034183   Top1 98.814338   Top5 99.995404   BatchTime 0.101892   LR 0.000100   
2022-11-03 21:28:08,199 - INFO  - Training [64][  360/  391]   Loss 0.034192   Top1 98.812934   Top5 99.995660   BatchTime 0.101734   LR 0.000100   
2022-11-03 21:28:10,170 - INFO  - Training [64][  380/  391]   Loss 0.034344   Top1 98.801398   Top5 99.995888   BatchTime 0.101565   LR 0.000100   
2022-11-03 21:28:11,603 - INFO  - ==> Top1: 98.806    Top5: 99.996    Loss: 0.034

2022-11-03 21:28:11,603 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:28:14,238 - INFO  - Validation [64][   20/   79]   Loss 0.383427   Top1 90.664062   Top5 99.687500   BatchTime 0.131653   
2022-11-03 21:28:15,154 - INFO  - Validation [64][   40/   79]   Loss 0.415544   Top1 90.566406   Top5 99.628906   BatchTime 0.088737   
2022-11-03 21:28:16,053 - INFO  - Validation [64][   60/   79]   Loss 0.409964   Top1 90.638021   Top5 99.635417   BatchTime 0.074142   
2022-11-03 21:28:17,124 - INFO  - ==> Top1: 90.640    Top5: 99.650    Loss: 0.404

2022-11-03 21:28:17,162 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:28:17,163 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:28:17,163 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:28:17,261 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:28:17,261 - INFO  - >>>>>>>> Epoch  65
2022-11-03 21:28:17,262 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:28:20,779 - INFO  - Training [65][   20/  391]   Loss 0.032268   Top1 98.710938   Top5 100.000000   BatchTime 0.175810   LR 0.000100   
2022-11-03 21:28:22,529 - INFO  - Training [65][   40/  391]   Loss 0.031516   Top1 98.886719   Top5 100.000000   BatchTime 0.131661   LR 0.000100   
2022-11-03 21:28:24,192 - INFO  - Training [65][   60/  391]   Loss 0.030768   Top1 98.958333   Top5 100.000000   BatchTime 0.115484   LR 0.000100   
2022-11-03 21:28:25,929 - INFO  - Training [65][   80/  391]   Loss 0.033031   Top1 98.867188   Top5 100.000000   BatchTime 0.108334   LR 0.000100   
2022-11-03 21:28:27,759 - INFO  - Training [65][  100/  391]   Loss 0.034012   Top1 98.804688   Top5 100.000000   BatchTime 0.104968   LR 0.000100   
2022-11-03 21:28:29,772 - INFO  - Training [65][  120/  391]   Loss 0.034893   Top1 98.795573   Top5 100.000000   BatchTime 0.104243   LR 0.000100   
2022-11-03 21:28:31,790 - INFO  - Training [65][  140/  391]   Loss 0.034748   Top1 98.805804   Top5 100.000000   BatchTime 0.103765   LR 0.000100   
2022-11-03 21:28:33,810 - INFO  - Training [65][  160/  391]   Loss 0.033630   Top1 98.847656   Top5 100.000000   BatchTime 0.103418   LR 0.000100   
2022-11-03 21:28:35,826 - INFO  - Training [65][  180/  391]   Loss 0.033633   Top1 98.841146   Top5 100.000000   BatchTime 0.103132   LR 0.000100   
2022-11-03 21:28:37,875 - INFO  - Training [65][  200/  391]   Loss 0.033677   Top1 98.839844   Top5 100.000000   BatchTime 0.103063   LR 0.000100   
2022-11-03 21:28:39,899 - INFO  - Training [65][  220/  391]   Loss 0.033323   Top1 98.849432   Top5 100.000000   BatchTime 0.102893   LR 0.000100   
2022-11-03 21:28:41,935 - INFO  - Training [65][  240/  391]   Loss 0.033278   Top1 98.841146   Top5 100.000000   BatchTime 0.102799   LR 0.000100   
2022-11-03 21:28:43,958 - INFO  - Training [65][  260/  391]   Loss 0.033289   Top1 98.825120   Top5 100.000000   BatchTime 0.102673   LR 0.000100   
2022-11-03 21:28:45,982 - INFO  - Training [65][  280/  391]   Loss 0.033833   Top1 98.808594   Top5 100.000000   BatchTime 0.102569   LR 0.000100   
2022-11-03 21:28:48,004 - INFO  - Training [65][  300/  391]   Loss 0.033542   Top1 98.828125   Top5 100.000000   BatchTime 0.102471   LR 0.000100   
2022-11-03 21:28:50,031 - INFO  - Training [65][  320/  391]   Loss 0.033632   Top1 98.825684   Top5 100.000000   BatchTime 0.102401   LR 0.000100   
2022-11-03 21:28:52,021 - INFO  - Training [65][  340/  391]   Loss 0.033568   Top1 98.823529   Top5 100.000000   BatchTime 0.102229   LR 0.000100   
2022-11-03 21:28:54,006 - INFO  - Training [65][  360/  391]   Loss 0.033798   Top1 98.812934   Top5 100.000000   BatchTime 0.102063   LR 0.000100   
2022-11-03 21:28:55,988 - INFO  - Training [65][  380/  391]   Loss 0.033829   Top1 98.805510   Top5 100.000000   BatchTime 0.101906   LR 0.000100   
2022-11-03 21:28:57,309 - INFO  - ==> Top1: 98.820    Top5: 100.000    Loss: 0.034

2022-11-03 21:28:57,310 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:28:59,960 - INFO  - Validation [65][   20/   79]   Loss 0.375758   Top1 90.664062   Top5 99.687500   BatchTime 0.132425   
2022-11-03 21:29:00,880 - INFO  - Validation [65][   40/   79]   Loss 0.419207   Top1 90.156250   Top5 99.589844   BatchTime 0.089213   
2022-11-03 21:29:01,801 - INFO  - Validation [65][   60/   79]   Loss 0.413201   Top1 90.429688   Top5 99.622396   BatchTime 0.074826   
2022-11-03 21:29:02,887 - INFO  - ==> Top1: 90.490    Top5: 99.650    Loss: 0.405

2022-11-03 21:29:02,916 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:29:02,916 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:29:02,916 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:29:02,999 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:29:02,999 - INFO  - >>>>>>>> Epoch  66
2022-11-03 21:29:03,000 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:29:06,420 - INFO  - Training [66][   20/  391]   Loss 0.035459   Top1 98.789062   Top5 100.000000   BatchTime 0.171013   LR 0.000100   
2022-11-03 21:29:08,155 - INFO  - Training [66][   40/  391]   Loss 0.033172   Top1 98.828125   Top5 100.000000   BatchTime 0.128870   LR 0.000100   
2022-11-03 21:29:09,783 - INFO  - Training [66][   60/  391]   Loss 0.032530   Top1 98.893229   Top5 100.000000   BatchTime 0.113043   LR 0.000100   
2022-11-03 21:29:11,458 - INFO  - Training [66][   80/  391]   Loss 0.033208   Top1 98.916016   Top5 100.000000   BatchTime 0.105728   LR 0.000100   
2022-11-03 21:29:13,226 - INFO  - Training [66][  100/  391]   Loss 0.034081   Top1 98.882812   Top5 100.000000   BatchTime 0.102259   LR 0.000100   
2022-11-03 21:29:15,268 - INFO  - Training [66][  120/  391]   Loss 0.033597   Top1 98.847656   Top5 100.000000   BatchTime 0.102231   LR 0.000100   
2022-11-03 21:29:17,308 - INFO  - Training [66][  140/  391]   Loss 0.036164   Top1 98.716518   Top5 99.994420   BatchTime 0.102200   LR 0.000100   
2022-11-03 21:29:19,337 - INFO  - Training [66][  160/  391]   Loss 0.035858   Top1 98.710938   Top5 99.995117   BatchTime 0.102103   LR 0.000100   
2022-11-03 21:29:21,351 - INFO  - Training [66][  180/  391]   Loss 0.034830   Top1 98.758681   Top5 99.995660   BatchTime 0.101947   LR 0.000100   
2022-11-03 21:29:23,369 - INFO  - Training [66][  200/  391]   Loss 0.034306   Top1 98.773438   Top5 99.996094   BatchTime 0.101844   LR 0.000100   
2022-11-03 21:29:25,407 - INFO  - Training [66][  220/  391]   Loss 0.035039   Top1 98.735795   Top5 99.996449   BatchTime 0.101845   LR 0.000100   
2022-11-03 21:29:27,451 - INFO  - Training [66][  240/  391]   Loss 0.034563   Top1 98.750000   Top5 99.996745   BatchTime 0.101875   LR 0.000100   
2022-11-03 21:29:29,483 - INFO  - Training [66][  260/  391]   Loss 0.034716   Top1 98.750000   Top5 99.996995   BatchTime 0.101856   LR 0.000100   
2022-11-03 21:29:31,484 - INFO  - Training [66][  280/  391]   Loss 0.034529   Top1 98.777902   Top5 99.997210   BatchTime 0.101725   LR 0.000100   
2022-11-03 21:29:33,497 - INFO  - Training [66][  300/  391]   Loss 0.034788   Top1 98.776042   Top5 99.997396   BatchTime 0.101653   LR 0.000100   
2022-11-03 21:29:35,494 - INFO  - Training [66][  320/  391]   Loss 0.034511   Top1 98.789062   Top5 99.997559   BatchTime 0.101541   LR 0.000100   
2022-11-03 21:29:37,486 - INFO  - Training [66][  340/  391]   Loss 0.034057   Top1 98.807445   Top5 99.997702   BatchTime 0.101427   LR 0.000100   
2022-11-03 21:29:39,461 - INFO  - Training [66][  360/  391]   Loss 0.034085   Top1 98.797743   Top5 99.997830   BatchTime 0.101277   LR 0.000100   
2022-11-03 21:29:41,446 - INFO  - Training [66][  380/  391]   Loss 0.033859   Top1 98.803454   Top5 99.997944   BatchTime 0.101171   LR 0.000100   
2022-11-03 21:29:42,765 - INFO  - ==> Top1: 98.806    Top5: 99.998    Loss: 0.034

2022-11-03 21:29:42,766 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:29:45,417 - INFO  - Validation [66][   20/   79]   Loss 0.375125   Top1 90.585938   Top5 99.726562   BatchTime 0.132470   
2022-11-03 21:29:46,339 - INFO  - Validation [66][   40/   79]   Loss 0.416724   Top1 90.390625   Top5 99.609375   BatchTime 0.089277   
2022-11-03 21:29:47,233 - INFO  - Validation [66][   60/   79]   Loss 0.408695   Top1 90.598958   Top5 99.609375   BatchTime 0.074428   
2022-11-03 21:29:48,361 - INFO  - ==> Top1: 90.570    Top5: 99.640    Loss: 0.402

2022-11-03 21:29:48,397 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:29:48,398 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:29:48,398 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:29:48,497 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:29:48,497 - INFO  - >>>>>>>> Epoch  67
2022-11-03 21:29:48,499 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:29:51,978 - INFO  - Training [67][   20/  391]   Loss 0.027425   Top1 99.101562   Top5 100.000000   BatchTime 0.173955   LR 0.000100   
2022-11-03 21:29:53,699 - INFO  - Training [67][   40/  391]   Loss 0.026408   Top1 99.160156   Top5 100.000000   BatchTime 0.130006   LR 0.000100   
2022-11-03 21:29:55,358 - INFO  - Training [67][   60/  391]   Loss 0.027905   Top1 99.049479   Top5 100.000000   BatchTime 0.114319   LR 0.000100   
2022-11-03 21:29:57,036 - INFO  - Training [67][   80/  391]   Loss 0.028207   Top1 99.033203   Top5 100.000000   BatchTime 0.106704   LR 0.000100   
2022-11-03 21:29:58,853 - INFO  - Training [67][  100/  391]   Loss 0.029278   Top1 99.031250   Top5 100.000000   BatchTime 0.103533   LR 0.000100   
2022-11-03 21:30:00,877 - INFO  - Training [67][  120/  391]   Loss 0.030130   Top1 98.984375   Top5 100.000000   BatchTime 0.103149   LR 0.000100   
2022-11-03 21:30:02,923 - INFO  - Training [67][  140/  391]   Loss 0.030906   Top1 98.962054   Top5 100.000000   BatchTime 0.103025   LR 0.000100   
2022-11-03 21:30:04,922 - INFO  - Training [67][  160/  391]   Loss 0.030843   Top1 98.955078   Top5 100.000000   BatchTime 0.102643   LR 0.000100   
2022-11-03 21:30:06,942 - INFO  - Training [67][  180/  391]   Loss 0.031135   Top1 98.940972   Top5 100.000000   BatchTime 0.102457   LR 0.000100   
2022-11-03 21:30:08,970 - INFO  - Training [67][  200/  391]   Loss 0.031741   Top1 98.910156   Top5 100.000000   BatchTime 0.102353   LR 0.000100   
2022-11-03 21:30:10,971 - INFO  - Training [67][  220/  391]   Loss 0.031846   Top1 98.899148   Top5 100.000000   BatchTime 0.102142   LR 0.000100   
2022-11-03 21:30:12,972 - INFO  - Training [67][  240/  391]   Loss 0.032856   Top1 98.867188   Top5 99.996745   BatchTime 0.101966   LR 0.000100   
2022-11-03 21:30:14,961 - INFO  - Training [67][  260/  391]   Loss 0.032601   Top1 98.885216   Top5 99.996995   BatchTime 0.101775   LR 0.000100   
2022-11-03 21:30:16,952 - INFO  - Training [67][  280/  391]   Loss 0.032848   Top1 98.853237   Top5 99.997210   BatchTime 0.101614   LR 0.000100   
2022-11-03 21:30:18,963 - INFO  - Training [67][  300/  391]   Loss 0.032800   Top1 98.843750   Top5 99.997396   BatchTime 0.101544   LR 0.000100   
2022-11-03 21:30:20,967 - INFO  - Training [67][  320/  391]   Loss 0.032458   Top1 98.845215   Top5 99.997559   BatchTime 0.101458   LR 0.000100   
2022-11-03 21:30:22,951 - INFO  - Training [67][  340/  391]   Loss 0.032625   Top1 98.839614   Top5 99.997702   BatchTime 0.101325   LR 0.000100   
2022-11-03 21:30:24,916 - INFO  - Training [67][  360/  391]   Loss 0.032471   Top1 98.856337   Top5 99.997830   BatchTime 0.101155   LR 0.000100   
2022-11-03 21:30:26,897 - INFO  - Training [67][  380/  391]   Loss 0.032585   Top1 98.858964   Top5 99.997944   BatchTime 0.101046   LR 0.000100   
2022-11-03 21:30:28,221 - INFO  - ==> Top1: 98.854    Top5: 99.998    Loss: 0.033

2022-11-03 21:30:28,222 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:30:30,894 - INFO  - Validation [67][   20/   79]   Loss 0.379463   Top1 90.625000   Top5 99.648438   BatchTime 0.133545   
2022-11-03 21:30:31,782 - INFO  - Validation [67][   40/   79]   Loss 0.415161   Top1 90.390625   Top5 99.589844   BatchTime 0.088970   
2022-11-03 21:30:32,674 - INFO  - Validation [67][   60/   79]   Loss 0.408835   Top1 90.611979   Top5 99.583333   BatchTime 0.074176   
2022-11-03 21:30:33,752 - INFO  - ==> Top1: 90.640    Top5: 99.590    Loss: 0.402

2022-11-03 21:30:33,787 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:30:33,788 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:30:33,788 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:30:33,911 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:30:33,912 - INFO  - >>>>>>>> Epoch  68
2022-11-03 21:30:33,913 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:30:37,354 - INFO  - Training [68][   20/  391]   Loss 0.030010   Top1 98.867188   Top5 100.000000   BatchTime 0.172052   LR 0.000100   
2022-11-03 21:30:39,068 - INFO  - Training [68][   40/  391]   Loss 0.028106   Top1 98.964844   Top5 100.000000   BatchTime 0.128872   LR 0.000100   
2022-11-03 21:30:40,699 - INFO  - Training [68][   60/  391]   Loss 0.029747   Top1 98.971354   Top5 100.000000   BatchTime 0.113097   LR 0.000100   
2022-11-03 21:30:42,440 - INFO  - Training [68][   80/  391]   Loss 0.031430   Top1 98.896484   Top5 100.000000   BatchTime 0.106588   LR 0.000100   
2022-11-03 21:30:44,239 - INFO  - Training [68][  100/  391]   Loss 0.030971   Top1 98.914062   Top5 100.000000   BatchTime 0.103263   LR 0.000100   
2022-11-03 21:30:46,242 - INFO  - Training [68][  120/  391]   Loss 0.031423   Top1 98.919271   Top5 100.000000   BatchTime 0.102742   LR 0.000100   
2022-11-03 21:30:48,248 - INFO  - Training [68][  140/  391]   Loss 0.030481   Top1 98.950893   Top5 100.000000   BatchTime 0.102391   LR 0.000100   
2022-11-03 21:30:50,255 - INFO  - Training [68][  160/  391]   Loss 0.031614   Top1 98.891602   Top5 100.000000   BatchTime 0.102137   LR 0.000100   
2022-11-03 21:30:52,258 - INFO  - Training [68][  180/  391]   Loss 0.031452   Top1 98.914931   Top5 100.000000   BatchTime 0.101914   LR 0.000100   
2022-11-03 21:30:54,265 - INFO  - Training [68][  200/  391]   Loss 0.031138   Top1 98.945312   Top5 100.000000   BatchTime 0.101757   LR 0.000100   
2022-11-03 21:30:56,269 - INFO  - Training [68][  220/  391]   Loss 0.031695   Top1 98.934659   Top5 100.000000   BatchTime 0.101616   LR 0.000100   
2022-11-03 21:30:58,277 - INFO  - Training [68][  240/  391]   Loss 0.031752   Top1 98.945312   Top5 100.000000   BatchTime 0.101515   LR 0.000100   
2022-11-03 21:31:00,264 - INFO  - Training [68][  260/  391]   Loss 0.032609   Top1 98.912260   Top5 100.000000   BatchTime 0.101349   LR 0.000100   
2022-11-03 21:31:02,330 - INFO  - Training [68][  280/  391]   Loss 0.032493   Top1 98.914621   Top5 100.000000   BatchTime 0.101486   LR 0.000100   
2022-11-03 21:31:04,355 - INFO  - Training [68][  300/  391]   Loss 0.032809   Top1 98.903646   Top5 100.000000   BatchTime 0.101473   LR 0.000100   
2022-11-03 21:31:06,378 - INFO  - Training [68][  320/  391]   Loss 0.033332   Top1 98.876953   Top5 100.000000   BatchTime 0.101451   LR 0.000100   
2022-11-03 21:31:08,405 - INFO  - Training [68][  340/  391]   Loss 0.033789   Top1 98.871783   Top5 100.000000   BatchTime 0.101445   LR 0.000100   
2022-11-03 21:31:10,410 - INFO  - Training [68][  360/  391]   Loss 0.033671   Top1 98.884549   Top5 100.000000   BatchTime 0.101379   LR 0.000100   
2022-11-03 21:31:12,392 - INFO  - Training [68][  380/  391]   Loss 0.034153   Top1 98.858964   Top5 100.000000   BatchTime 0.101257   LR 0.000100   
2022-11-03 21:31:13,727 - INFO  - ==> Top1: 98.860    Top5: 100.000    Loss: 0.034

2022-11-03 21:31:13,728 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:31:16,382 - INFO  - Validation [68][   20/   79]   Loss 0.377089   Top1 90.937500   Top5 99.648438   BatchTime 0.132603   
2022-11-03 21:31:17,280 - INFO  - Validation [68][   40/   79]   Loss 0.413058   Top1 90.605469   Top5 99.589844   BatchTime 0.088760   
2022-11-03 21:31:18,191 - INFO  - Validation [68][   60/   79]   Loss 0.406434   Top1 90.768229   Top5 99.609375   BatchTime 0.074360   
2022-11-03 21:31:19,265 - INFO  - ==> Top1: 90.750    Top5: 99.630    Loss: 0.403

2022-11-03 21:31:19,308 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:31:19,309 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:31:19,309 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:31:19,413 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:31:19,414 - INFO  - >>>>>>>> Epoch  69
2022-11-03 21:31:19,415 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:31:22,836 - INFO  - Training [69][   20/  391]   Loss 0.034739   Top1 98.867188   Top5 100.000000   BatchTime 0.171035   LR 0.000100   
2022-11-03 21:31:24,508 - INFO  - Training [69][   40/  391]   Loss 0.035731   Top1 98.730469   Top5 100.000000   BatchTime 0.127338   LR 0.000100   
2022-11-03 21:31:26,163 - INFO  - Training [69][   60/  391]   Loss 0.034573   Top1 98.723958   Top5 100.000000   BatchTime 0.112475   LR 0.000100   
2022-11-03 21:31:27,961 - INFO  - Training [69][   80/  391]   Loss 0.035006   Top1 98.730469   Top5 100.000000   BatchTime 0.106824   LR 0.000100   
2022-11-03 21:31:29,624 - INFO  - Training [69][  100/  391]   Loss 0.032450   Top1 98.867188   Top5 100.000000   BatchTime 0.102087   LR 0.000100   
2022-11-03 21:31:31,655 - INFO  - Training [69][  120/  391]   Loss 0.033011   Top1 98.834635   Top5 100.000000   BatchTime 0.101999   LR 0.000100   
2022-11-03 21:31:33,649 - INFO  - Training [69][  140/  391]   Loss 0.032593   Top1 98.844866   Top5 100.000000   BatchTime 0.101670   LR 0.000100   
2022-11-03 21:31:35,669 - INFO  - Training [69][  160/  391]   Loss 0.032776   Top1 98.847656   Top5 100.000000   BatchTime 0.101587   LR 0.000100   
2022-11-03 21:31:37,660 - INFO  - Training [69][  180/  391]   Loss 0.032324   Top1 98.871528   Top5 100.000000   BatchTime 0.101360   LR 0.000100   
2022-11-03 21:31:39,674 - INFO  - Training [69][  200/  391]   Loss 0.031933   Top1 98.894531   Top5 100.000000   BatchTime 0.101293   LR 0.000100   
2022-11-03 21:31:41,701 - INFO  - Training [69][  220/  391]   Loss 0.031906   Top1 98.895597   Top5 100.000000   BatchTime 0.101296   LR 0.000100   
2022-11-03 21:31:43,737 - INFO  - Training [69][  240/  391]   Loss 0.032445   Top1 98.880208   Top5 100.000000   BatchTime 0.101340   LR 0.000100   
2022-11-03 21:31:45,744 - INFO  - Training [69][  260/  391]   Loss 0.032592   Top1 98.876202   Top5 100.000000   BatchTime 0.101262   LR 0.000100   
2022-11-03 21:31:47,764 - INFO  - Training [69][  280/  391]   Loss 0.033114   Top1 98.861607   Top5 100.000000   BatchTime 0.101245   LR 0.000100   
2022-11-03 21:31:49,771 - INFO  - Training [69][  300/  391]   Loss 0.033411   Top1 98.846354   Top5 100.000000   BatchTime 0.101185   LR 0.000100   
2022-11-03 21:31:51,775 - INFO  - Training [69][  320/  391]   Loss 0.032987   Top1 98.862305   Top5 100.000000   BatchTime 0.101123   LR 0.000100   
2022-11-03 21:31:53,763 - INFO  - Training [69][  340/  391]   Loss 0.032967   Top1 98.871783   Top5 100.000000   BatchTime 0.101022   LR 0.000100   
2022-11-03 21:31:55,729 - INFO  - Training [69][  360/  391]   Loss 0.033166   Top1 98.862847   Top5 99.997830   BatchTime 0.100869   LR 0.000100   
2022-11-03 21:31:57,721 - INFO  - Training [69][  380/  391]   Loss 0.033340   Top1 98.844572   Top5 99.997944   BatchTime 0.100803   LR 0.000100   
2022-11-03 21:31:59,030 - INFO  - ==> Top1: 98.854    Top5: 99.998    Loss: 0.033

2022-11-03 21:31:59,031 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:32:01,658 - INFO  - Validation [69][   20/   79]   Loss 0.374450   Top1 90.507812   Top5 99.726562   BatchTime 0.131289   
2022-11-03 21:32:02,554 - INFO  - Validation [69][   40/   79]   Loss 0.414608   Top1 90.234375   Top5 99.589844   BatchTime 0.088032   
2022-11-03 21:32:03,445 - INFO  - Validation [69][   60/   79]   Loss 0.406304   Top1 90.677083   Top5 99.609375   BatchTime 0.073542   
2022-11-03 21:32:04,564 - INFO  - ==> Top1: 90.550    Top5: 99.640    Loss: 0.401

2022-11-03 21:32:04,594 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:32:04,595 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:32:04,595 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:32:04,704 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:32:04,705 - INFO  - >>>>>>>> Epoch  70
2022-11-03 21:32:04,706 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:32:08,189 - INFO  - Training [70][   20/  391]   Loss 0.029557   Top1 98.867188   Top5 100.000000   BatchTime 0.174145   LR 0.000010   
2022-11-03 21:32:09,874 - INFO  - Training [70][   40/  391]   Loss 0.030051   Top1 98.847656   Top5 100.000000   BatchTime 0.129209   LR 0.000010   
2022-11-03 21:32:11,526 - INFO  - Training [70][   60/  391]   Loss 0.031328   Top1 98.867188   Top5 100.000000   BatchTime 0.113657   LR 0.000010   
2022-11-03 21:32:13,256 - INFO  - Training [70][   80/  391]   Loss 0.031550   Top1 98.867188   Top5 100.000000   BatchTime 0.106873   LR 0.000010   
2022-11-03 21:32:14,977 - INFO  - Training [70][  100/  391]   Loss 0.030083   Top1 98.929688   Top5 100.000000   BatchTime 0.102707   LR 0.000010   
2022-11-03 21:32:16,999 - INFO  - Training [70][  120/  391]   Loss 0.030277   Top1 98.951823   Top5 100.000000   BatchTime 0.102438   LR 0.000010   
2022-11-03 21:32:19,045 - INFO  - Training [70][  140/  391]   Loss 0.032359   Top1 98.844866   Top5 100.000000   BatchTime 0.102421   LR 0.000010   
2022-11-03 21:32:21,056 - INFO  - Training [70][  160/  391]   Loss 0.032701   Top1 98.842773   Top5 100.000000   BatchTime 0.102185   LR 0.000010   
2022-11-03 21:32:23,054 - INFO  - Training [70][  180/  391]   Loss 0.032950   Top1 98.836806   Top5 99.995660   BatchTime 0.101930   LR 0.000010   
2022-11-03 21:32:25,069 - INFO  - Training [70][  200/  391]   Loss 0.033055   Top1 98.835938   Top5 99.996094   BatchTime 0.101813   LR 0.000010   
2022-11-03 21:32:27,081 - INFO  - Training [70][  220/  391]   Loss 0.032470   Top1 98.856534   Top5 99.996449   BatchTime 0.101701   LR 0.000010   
2022-11-03 21:32:29,115 - INFO  - Training [70][  240/  391]   Loss 0.032419   Top1 98.863932   Top5 99.996745   BatchTime 0.101704   LR 0.000010   
2022-11-03 21:32:31,132 - INFO  - Training [70][  260/  391]   Loss 0.032940   Top1 98.861178   Top5 99.996995   BatchTime 0.101636   LR 0.000010   
2022-11-03 21:32:33,129 - INFO  - Training [70][  280/  391]   Loss 0.032851   Top1 98.864397   Top5 99.997210   BatchTime 0.101508   LR 0.000010   
2022-11-03 21:32:35,116 - INFO  - Training [70][  300/  391]   Loss 0.032994   Top1 98.864583   Top5 99.997396   BatchTime 0.101363   LR 0.000010   
2022-11-03 21:32:37,056 - INFO  - Training [70][  320/  391]   Loss 0.033372   Top1 98.845215   Top5 99.997559   BatchTime 0.101093   LR 0.000010   
2022-11-03 21:32:39,021 - INFO  - Training [70][  340/  391]   Loss 0.033083   Top1 98.860294   Top5 99.997702   BatchTime 0.100925   LR 0.000010   
2022-11-03 21:32:41,004 - INFO  - Training [70][  360/  391]   Loss 0.032929   Top1 98.875868   Top5 99.997830   BatchTime 0.100826   LR 0.000010   
2022-11-03 21:32:42,983 - INFO  - Training [70][  380/  391]   Loss 0.033238   Top1 98.856908   Top5 99.997944   BatchTime 0.100726   LR 0.000010   
2022-11-03 21:32:44,311 - INFO  - ==> Top1: 98.850    Top5: 99.998    Loss: 0.034

2022-11-03 21:32:44,312 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:32:46,927 - INFO  - Validation [70][   20/   79]   Loss 0.376091   Top1 90.781250   Top5 99.726562   BatchTime 0.130652   
2022-11-03 21:32:47,818 - INFO  - Validation [70][   40/   79]   Loss 0.412319   Top1 90.605469   Top5 99.550781   BatchTime 0.087618   
2022-11-03 21:32:48,703 - INFO  - Validation [70][   60/   79]   Loss 0.407773   Top1 90.651042   Top5 99.583333   BatchTime 0.073160   
2022-11-03 21:32:49,802 - INFO  - ==> Top1: 90.550    Top5: 99.620    Loss: 0.401

2022-11-03 21:32:49,843 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:32:49,844 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:32:49,844 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:32:49,948 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:32:49,948 - INFO  - >>>>>>>> Epoch  71
2022-11-03 21:32:49,949 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:32:53,437 - INFO  - Training [71][   20/  391]   Loss 0.027081   Top1 99.062500   Top5 100.000000   BatchTime 0.174395   LR 0.000010   
2022-11-03 21:32:55,104 - INFO  - Training [71][   40/  391]   Loss 0.032040   Top1 98.925781   Top5 100.000000   BatchTime 0.128860   LR 0.000010   
2022-11-03 21:32:56,730 - INFO  - Training [71][   60/  391]   Loss 0.031412   Top1 98.971354   Top5 100.000000   BatchTime 0.113014   LR 0.000010   
2022-11-03 21:32:58,464 - INFO  - Training [71][   80/  391]   Loss 0.032766   Top1 98.906250   Top5 100.000000   BatchTime 0.106438   LR 0.000010   
2022-11-03 21:32:59,957 - INFO  - Training [71][  100/  391]   Loss 0.032551   Top1 98.937500   Top5 100.000000   BatchTime 0.100081   LR 0.000010   
2022-11-03 21:33:02,161 - INFO  - Training [71][  120/  391]   Loss 0.032328   Top1 98.945312   Top5 100.000000   BatchTime 0.101766   LR 0.000010   
2022-11-03 21:33:04,161 - INFO  - Training [71][  140/  391]   Loss 0.033829   Top1 98.900670   Top5 99.994420   BatchTime 0.101511   LR 0.000010   
2022-11-03 21:33:06,169 - INFO  - Training [71][  160/  391]   Loss 0.033363   Top1 98.925781   Top5 99.995117   BatchTime 0.101375   LR 0.000010   
2022-11-03 21:33:08,185 - INFO  - Training [71][  180/  391]   Loss 0.032743   Top1 98.953993   Top5 99.995660   BatchTime 0.101309   LR 0.000010   
2022-11-03 21:33:10,196 - INFO  - Training [71][  200/  391]   Loss 0.032797   Top1 98.937500   Top5 99.996094   BatchTime 0.101231   LR 0.000010   
2022-11-03 21:33:12,206 - INFO  - Training [71][  220/  391]   Loss 0.033191   Top1 98.934659   Top5 99.996449   BatchTime 0.101164   LR 0.000010   
2022-11-03 21:33:14,221 - INFO  - Training [71][  240/  391]   Loss 0.032847   Top1 98.932292   Top5 99.996745   BatchTime 0.101132   LR 0.000010   
2022-11-03 21:33:16,225 - INFO  - Training [71][  260/  391]   Loss 0.033430   Top1 98.906250   Top5 99.996995   BatchTime 0.101057   LR 0.000010   
2022-11-03 21:33:18,238 - INFO  - Training [71][  280/  391]   Loss 0.033351   Top1 98.909040   Top5 99.997210   BatchTime 0.101030   LR 0.000010   
2022-11-03 21:33:20,234 - INFO  - Training [71][  300/  391]   Loss 0.033205   Top1 98.914062   Top5 99.997396   BatchTime 0.100946   LR 0.000010   
2022-11-03 21:33:22,240 - INFO  - Training [71][  320/  391]   Loss 0.033001   Top1 98.923340   Top5 99.997559   BatchTime 0.100906   LR 0.000010   
2022-11-03 21:33:24,230 - INFO  - Training [71][  340/  391]   Loss 0.032944   Top1 98.910846   Top5 99.997702   BatchTime 0.100823   LR 0.000010   
2022-11-03 21:33:26,228 - INFO  - Training [71][  360/  391]   Loss 0.032719   Top1 98.914931   Top5 99.997830   BatchTime 0.100772   LR 0.000010   
2022-11-03 21:33:28,237 - INFO  - Training [71][  380/  391]   Loss 0.032815   Top1 98.918586   Top5 99.997944   BatchTime 0.100756   LR 0.000010   
2022-11-03 21:33:29,595 - INFO  - ==> Top1: 98.920    Top5: 99.998    Loss: 0.033

2022-11-03 21:33:29,595 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:33:32,213 - INFO  - Validation [71][   20/   79]   Loss 0.383838   Top1 90.742188   Top5 99.648438   BatchTime 0.130829   
2022-11-03 21:33:33,090 - INFO  - Validation [71][   40/   79]   Loss 0.415249   Top1 90.527344   Top5 99.550781   BatchTime 0.087350   
2022-11-03 21:33:33,992 - INFO  - Validation [71][   60/   79]   Loss 0.409411   Top1 90.598958   Top5 99.570312   BatchTime 0.073255   
2022-11-03 21:33:35,091 - INFO  - ==> Top1: 90.620    Top5: 99.620    Loss: 0.404

2022-11-03 21:33:35,141 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:33:35,142 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:33:35,142 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:33:35,236 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:33:35,236 - INFO  - >>>>>>>> Epoch  72
2022-11-03 21:33:35,237 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:33:38,783 - INFO  - Training [72][   20/  391]   Loss 0.033721   Top1 98.671875   Top5 100.000000   BatchTime 0.177290   LR 0.000010   
2022-11-03 21:33:40,408 - INFO  - Training [72][   40/  391]   Loss 0.033869   Top1 98.847656   Top5 100.000000   BatchTime 0.129264   LR 0.000010   
2022-11-03 21:33:42,014 - INFO  - Training [72][   60/  391]   Loss 0.034826   Top1 98.815104   Top5 100.000000   BatchTime 0.112951   LR 0.000010   
2022-11-03 21:33:43,727 - INFO  - Training [72][   80/  391]   Loss 0.033894   Top1 98.896484   Top5 100.000000   BatchTime 0.106125   LR 0.000010   
2022-11-03 21:33:45,232 - INFO  - Training [72][  100/  391]   Loss 0.034217   Top1 98.859375   Top5 100.000000   BatchTime 0.099944   LR 0.000010   
2022-11-03 21:33:47,213 - INFO  - Training [72][  120/  391]   Loss 0.034281   Top1 98.847656   Top5 100.000000   BatchTime 0.099796   LR 0.000010   
2022-11-03 21:33:49,217 - INFO  - Training [72][  140/  391]   Loss 0.033777   Top1 98.856027   Top5 99.994420   BatchTime 0.099854   LR 0.000010   
2022-11-03 21:33:51,228 - INFO  - Training [72][  160/  391]   Loss 0.033744   Top1 98.842773   Top5 99.995117   BatchTime 0.099942   LR 0.000010   
2022-11-03 21:33:53,245 - INFO  - Training [72][  180/  391]   Loss 0.034500   Top1 98.832465   Top5 99.995660   BatchTime 0.100041   LR 0.000010   
2022-11-03 21:33:55,238 - INFO  - Training [72][  200/  391]   Loss 0.034685   Top1 98.828125   Top5 99.996094   BatchTime 0.100003   LR 0.000010   
2022-11-03 21:33:57,238 - INFO  - Training [72][  220/  391]   Loss 0.034770   Top1 98.821023   Top5 99.996449   BatchTime 0.100003   LR 0.000010   
2022-11-03 21:33:59,244 - INFO  - Training [72][  240/  391]   Loss 0.034854   Top1 98.805339   Top5 99.996745   BatchTime 0.100026   LR 0.000010   
2022-11-03 21:34:01,242 - INFO  - Training [72][  260/  391]   Loss 0.034468   Top1 98.816106   Top5 99.996995   BatchTime 0.100018   LR 0.000010   
2022-11-03 21:34:03,239 - INFO  - Training [72][  280/  391]   Loss 0.034548   Top1 98.794643   Top5 99.997210   BatchTime 0.100006   LR 0.000010   
2022-11-03 21:34:05,249 - INFO  - Training [72][  300/  391]   Loss 0.034575   Top1 98.796875   Top5 99.997396   BatchTime 0.100039   LR 0.000010   
2022-11-03 21:34:07,252 - INFO  - Training [72][  320/  391]   Loss 0.034687   Top1 98.808594   Top5 99.997559   BatchTime 0.100043   LR 0.000010   
2022-11-03 21:34:09,226 - INFO  - Training [72][  340/  391]   Loss 0.034252   Top1 98.821232   Top5 99.997702   BatchTime 0.099966   LR 0.000010   
2022-11-03 21:34:11,219 - INFO  - Training [72][  360/  391]   Loss 0.034539   Top1 98.815104   Top5 99.997830   BatchTime 0.099949   LR 0.000010   
2022-11-03 21:34:13,191 - INFO  - Training [72][  380/  391]   Loss 0.034577   Top1 98.817845   Top5 99.997944   BatchTime 0.099875   LR 0.000010   
2022-11-03 21:34:14,513 - INFO  - ==> Top1: 98.806    Top5: 99.998    Loss: 0.035

2022-11-03 21:34:14,514 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:34:17,174 - INFO  - Validation [72][   20/   79]   Loss 0.374310   Top1 90.859375   Top5 99.687500   BatchTime 0.132944   
2022-11-03 21:34:18,066 - INFO  - Validation [72][   40/   79]   Loss 0.410199   Top1 90.410156   Top5 99.570312   BatchTime 0.088755   
2022-11-03 21:34:18,975 - INFO  - Validation [72][   60/   79]   Loss 0.408654   Top1 90.429688   Top5 99.622396   BatchTime 0.074318   
2022-11-03 21:34:20,093 - INFO  - ==> Top1: 90.480    Top5: 99.640    Loss: 0.402

2022-11-03 21:34:20,123 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:34:20,124 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:34:20,124 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:34:20,231 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:34:20,231 - INFO  - >>>>>>>> Epoch  73
2022-11-03 21:34:20,233 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:34:23,866 - INFO  - Training [73][   20/  391]   Loss 0.028450   Top1 99.023438   Top5 100.000000   BatchTime 0.181650   LR 0.000010   
2022-11-03 21:34:25,506 - INFO  - Training [73][   40/  391]   Loss 0.032098   Top1 98.867188   Top5 100.000000   BatchTime 0.131831   LR 0.000010   
2022-11-03 21:34:27,199 - INFO  - Training [73][   60/  391]   Loss 0.034679   Top1 98.776042   Top5 100.000000   BatchTime 0.116100   LR 0.000010   
2022-11-03 21:34:29,042 - INFO  - Training [73][   80/  391]   Loss 0.033404   Top1 98.828125   Top5 100.000000   BatchTime 0.110109   LR 0.000010   
2022-11-03 21:34:30,530 - INFO  - Training [73][  100/  391]   Loss 0.031729   Top1 98.835938   Top5 100.000000   BatchTime 0.102969   LR 0.000010   
2022-11-03 21:34:32,618 - INFO  - Training [73][  120/  391]   Loss 0.032561   Top1 98.841146   Top5 100.000000   BatchTime 0.103204   LR 0.000010   
2022-11-03 21:34:34,721 - INFO  - Training [73][  140/  391]   Loss 0.033349   Top1 98.800223   Top5 100.000000   BatchTime 0.103483   LR 0.000010   
2022-11-03 21:34:36,729 - INFO  - Training [73][  160/  391]   Loss 0.033373   Top1 98.803711   Top5 100.000000   BatchTime 0.103101   LR 0.000010   
2022-11-03 21:34:38,764 - INFO  - Training [73][  180/  391]   Loss 0.032623   Top1 98.832465   Top5 100.000000   BatchTime 0.102947   LR 0.000010   
2022-11-03 21:34:40,776 - INFO  - Training [73][  200/  391]   Loss 0.032682   Top1 98.847656   Top5 100.000000   BatchTime 0.102714   LR 0.000010   
2022-11-03 21:34:42,789 - INFO  - Training [73][  220/  391]   Loss 0.033172   Top1 98.842330   Top5 100.000000   BatchTime 0.102526   LR 0.000010   
2022-11-03 21:34:44,791 - INFO  - Training [73][  240/  391]   Loss 0.033542   Top1 98.811849   Top5 100.000000   BatchTime 0.102324   LR 0.000010   
2022-11-03 21:34:46,794 - INFO  - Training [73][  260/  391]   Loss 0.033618   Top1 98.813101   Top5 100.000000   BatchTime 0.102154   LR 0.000010   
2022-11-03 21:34:48,803 - INFO  - Training [73][  280/  391]   Loss 0.033319   Top1 98.830915   Top5 100.000000   BatchTime 0.102035   LR 0.000010   
2022-11-03 21:34:50,806 - INFO  - Training [73][  300/  391]   Loss 0.032959   Top1 98.841146   Top5 100.000000   BatchTime 0.101909   LR 0.000010   
2022-11-03 21:34:52,821 - INFO  - Training [73][  320/  391]   Loss 0.032472   Top1 98.859863   Top5 100.000000   BatchTime 0.101836   LR 0.000010   
2022-11-03 21:34:54,808 - INFO  - Training [73][  340/  391]   Loss 0.032410   Top1 98.860294   Top5 100.000000   BatchTime 0.101689   LR 0.000010   
2022-11-03 21:34:56,791 - INFO  - Training [73][  360/  391]   Loss 0.032308   Top1 98.865017   Top5 100.000000   BatchTime 0.101548   LR 0.000010   
2022-11-03 21:34:58,787 - INFO  - Training [73][  380/  391]   Loss 0.032827   Top1 98.867188   Top5 100.000000   BatchTime 0.101456   LR 0.000010   
2022-11-03 21:35:00,122 - INFO  - ==> Top1: 98.866    Top5: 100.000    Loss: 0.033

2022-11-03 21:35:00,123 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:35:02,733 - INFO  - Validation [73][   20/   79]   Loss 0.380599   Top1 90.859375   Top5 99.687500   BatchTime 0.130418   
2022-11-03 21:35:03,654 - INFO  - Validation [73][   40/   79]   Loss 0.416436   Top1 90.566406   Top5 99.550781   BatchTime 0.088241   
2022-11-03 21:35:04,544 - INFO  - Validation [73][   60/   79]   Loss 0.409819   Top1 90.651042   Top5 99.570312   BatchTime 0.073665   
2022-11-03 21:35:05,667 - INFO  - ==> Top1: 90.620    Top5: 99.610    Loss: 0.406

2022-11-03 21:35:05,707 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:35:05,708 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:35:05,708 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:35:05,814 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:35:05,815 - INFO  - >>>>>>>> Epoch  74
2022-11-03 21:35:05,816 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:35:09,319 - INFO  - Training [74][   20/  391]   Loss 0.035014   Top1 98.671875   Top5 100.000000   BatchTime 0.175145   LR 0.000010   
2022-11-03 21:35:10,997 - INFO  - Training [74][   40/  391]   Loss 0.027611   Top1 99.023438   Top5 100.000000   BatchTime 0.129525   LR 0.000010   
2022-11-03 21:35:12,646 - INFO  - Training [74][   60/  391]   Loss 0.030315   Top1 98.945312   Top5 100.000000   BatchTime 0.113841   LR 0.000010   
2022-11-03 21:35:14,382 - INFO  - Training [74][   80/  391]   Loss 0.030338   Top1 98.984375   Top5 100.000000   BatchTime 0.107081   LR 0.000010   
2022-11-03 21:35:15,905 - INFO  - Training [74][  100/  391]   Loss 0.030882   Top1 98.976562   Top5 100.000000   BatchTime 0.100894   LR 0.000010   
2022-11-03 21:35:18,008 - INFO  - Training [74][  120/  391]   Loss 0.031408   Top1 98.958333   Top5 100.000000   BatchTime 0.101604   LR 0.000010   
2022-11-03 21:35:20,032 - INFO  - Training [74][  140/  391]   Loss 0.031330   Top1 98.973214   Top5 100.000000   BatchTime 0.101539   LR 0.000010   
2022-11-03 21:35:22,062 - INFO  - Training [74][  160/  391]   Loss 0.031237   Top1 98.989258   Top5 100.000000   BatchTime 0.101539   LR 0.000010   
2022-11-03 21:35:24,096 - INFO  - Training [74][  180/  391]   Loss 0.032171   Top1 98.927951   Top5 100.000000   BatchTime 0.101552   LR 0.000010   
2022-11-03 21:35:26,104 - INFO  - Training [74][  200/  391]   Loss 0.032166   Top1 98.906250   Top5 100.000000   BatchTime 0.101440   LR 0.000010   
2022-11-03 21:35:28,120 - INFO  - Training [74][  220/  391]   Loss 0.031922   Top1 98.902699   Top5 100.000000   BatchTime 0.101382   LR 0.000010   
2022-11-03 21:35:30,132 - INFO  - Training [74][  240/  391]   Loss 0.032310   Top1 98.893229   Top5 100.000000   BatchTime 0.101317   LR 0.000010   
2022-11-03 21:35:32,150 - INFO  - Training [74][  260/  391]   Loss 0.032285   Top1 98.903245   Top5 100.000000   BatchTime 0.101283   LR 0.000010   
2022-11-03 21:35:34,160 - INFO  - Training [74][  280/  391]   Loss 0.032318   Top1 98.906250   Top5 100.000000   BatchTime 0.101226   LR 0.000010   
2022-11-03 21:35:36,156 - INFO  - Training [74][  300/  391]   Loss 0.032424   Top1 98.901042   Top5 100.000000   BatchTime 0.101133   LR 0.000010   
2022-11-03 21:35:38,171 - INFO  - Training [74][  320/  391]   Loss 0.031965   Top1 98.913574   Top5 100.000000   BatchTime 0.101106   LR 0.000010   
2022-11-03 21:35:40,150 - INFO  - Training [74][  340/  391]   Loss 0.032359   Top1 98.885570   Top5 100.000000   BatchTime 0.100981   LR 0.000010   
2022-11-03 21:35:42,125 - INFO  - Training [74][  360/  391]   Loss 0.032449   Top1 98.886719   Top5 100.000000   BatchTime 0.100857   LR 0.000010   
2022-11-03 21:35:44,105 - INFO  - Training [74][  380/  391]   Loss 0.032873   Top1 98.873355   Top5 100.000000   BatchTime 0.100760   LR 0.000010   
2022-11-03 21:35:45,430 - INFO  - ==> Top1: 98.868    Top5: 100.000    Loss: 0.033

2022-11-03 21:35:45,431 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:35:48,035 - INFO  - Validation [74][   20/   79]   Loss 0.376177   Top1 90.859375   Top5 99.570312   BatchTime 0.130136   
2022-11-03 21:35:48,872 - INFO  - Validation [74][   40/   79]   Loss 0.410547   Top1 90.683594   Top5 99.531250   BatchTime 0.085987   
2022-11-03 21:35:49,781 - INFO  - Validation [74][   60/   79]   Loss 0.408302   Top1 90.729167   Top5 99.557292   BatchTime 0.072475   
2022-11-03 21:35:50,903 - INFO  - ==> Top1: 90.700    Top5: 99.600    Loss: 0.400

2022-11-03 21:35:50,936 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:35:50,937 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:35:50,937 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:35:51,067 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:35:51,068 - INFO  - >>>>>>>> Epoch  75
2022-11-03 21:35:51,069 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:35:54,635 - INFO  - Training [75][   20/  391]   Loss 0.031973   Top1 98.750000   Top5 100.000000   BatchTime 0.178283   LR 0.000010   
2022-11-03 21:35:56,304 - INFO  - Training [75][   40/  391]   Loss 0.035207   Top1 98.769531   Top5 100.000000   BatchTime 0.130860   LR 0.000010   
2022-11-03 21:35:57,982 - INFO  - Training [75][   60/  391]   Loss 0.033534   Top1 98.841146   Top5 99.986979   BatchTime 0.115215   LR 0.000010   
2022-11-03 21:35:59,757 - INFO  - Training [75][   80/  391]   Loss 0.032844   Top1 98.876953   Top5 99.990234   BatchTime 0.108597   LR 0.000010   
2022-11-03 21:36:01,322 - INFO  - Training [75][  100/  391]   Loss 0.033351   Top1 98.859375   Top5 99.992188   BatchTime 0.102521   LR 0.000010   
2022-11-03 21:36:03,392 - INFO  - Training [75][  120/  391]   Loss 0.032396   Top1 98.886719   Top5 99.993490   BatchTime 0.102688   LR 0.000010   
2022-11-03 21:36:05,385 - INFO  - Training [75][  140/  391]   Loss 0.032721   Top1 98.872768   Top5 99.994420   BatchTime 0.102254   LR 0.000010   
2022-11-03 21:36:07,392 - INFO  - Training [75][  160/  391]   Loss 0.033736   Top1 98.818359   Top5 99.995117   BatchTime 0.102013   LR 0.000010   
2022-11-03 21:36:09,425 - INFO  - Training [75][  180/  391]   Loss 0.032774   Top1 98.845486   Top5 99.995660   BatchTime 0.101973   LR 0.000010   
2022-11-03 21:36:11,530 - INFO  - Training [75][  200/  391]   Loss 0.033752   Top1 98.816406   Top5 99.996094   BatchTime 0.102300   LR 0.000010   
2022-11-03 21:36:13,539 - INFO  - Training [75][  220/  391]   Loss 0.033507   Top1 98.817472   Top5 99.996449   BatchTime 0.102133   LR 0.000010   
2022-11-03 21:36:15,543 - INFO  - Training [75][  240/  391]   Loss 0.033367   Top1 98.837891   Top5 99.996745   BatchTime 0.101969   LR 0.000010   
2022-11-03 21:36:17,549 - INFO  - Training [75][  260/  391]   Loss 0.033209   Top1 98.849159   Top5 99.996995   BatchTime 0.101841   LR 0.000010   
2022-11-03 21:36:19,536 - INFO  - Training [75][  280/  391]   Loss 0.033368   Top1 98.839286   Top5 99.994420   BatchTime 0.101666   LR 0.000010   
2022-11-03 21:36:21,532 - INFO  - Training [75][  300/  391]   Loss 0.033163   Top1 98.848958   Top5 99.994792   BatchTime 0.101541   LR 0.000010   
2022-11-03 21:36:23,557 - INFO  - Training [75][  320/  391]   Loss 0.033406   Top1 98.850098   Top5 99.995117   BatchTime 0.101522   LR 0.000010   
2022-11-03 21:36:25,568 - INFO  - Training [75][  340/  391]   Loss 0.033211   Top1 98.869485   Top5 99.995404   BatchTime 0.101463   LR 0.000010   
2022-11-03 21:36:27,551 - INFO  - Training [75][  360/  391]   Loss 0.033256   Top1 98.869358   Top5 99.993490   BatchTime 0.101336   LR 0.000010   
2022-11-03 21:36:29,541 - INFO  - Training [75][  380/  391]   Loss 0.033429   Top1 98.854852   Top5 99.993832   BatchTime 0.101240   LR 0.000010   
2022-11-03 21:36:30,860 - INFO  - ==> Top1: 98.846    Top5: 99.994    Loss: 0.033

2022-11-03 21:36:30,860 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:36:33,488 - INFO  - Validation [75][   20/   79]   Loss 0.379206   Top1 91.054688   Top5 99.648438   BatchTime 0.131288   
2022-11-03 21:36:34,379 - INFO  - Validation [75][   40/   79]   Loss 0.419069   Top1 90.644531   Top5 99.570312   BatchTime 0.087926   
2022-11-03 21:36:35,282 - INFO  - Validation [75][   60/   79]   Loss 0.411858   Top1 90.794271   Top5 99.570312   BatchTime 0.073669   
2022-11-03 21:36:36,376 - INFO  - ==> Top1: 90.750    Top5: 99.610    Loss: 0.406

2022-11-03 21:36:36,406 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:36:36,407 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:36:36,407 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:36:36,515 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:36:36,516 - INFO  - >>>>>>>> Epoch  76
2022-11-03 21:36:36,517 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:36:40,060 - INFO  - Training [76][   20/  391]   Loss 0.038490   Top1 98.593750   Top5 100.000000   BatchTime 0.177161   LR 0.000010   
2022-11-03 21:36:41,723 - INFO  - Training [76][   40/  391]   Loss 0.040493   Top1 98.574219   Top5 100.000000   BatchTime 0.130146   LR 0.000010   
2022-11-03 21:36:43,341 - INFO  - Training [76][   60/  391]   Loss 0.037612   Top1 98.606771   Top5 100.000000   BatchTime 0.113737   LR 0.000010   
2022-11-03 21:36:45,046 - INFO  - Training [76][   80/  391]   Loss 0.035439   Top1 98.710938   Top5 100.000000   BatchTime 0.106608   LR 0.000010   
2022-11-03 21:36:46,580 - INFO  - Training [76][  100/  391]   Loss 0.033811   Top1 98.804688   Top5 100.000000   BatchTime 0.100622   LR 0.000010   
2022-11-03 21:36:48,700 - INFO  - Training [76][  120/  391]   Loss 0.032928   Top1 98.886719   Top5 100.000000   BatchTime 0.101518   LR 0.000010   
2022-11-03 21:36:50,744 - INFO  - Training [76][  140/  391]   Loss 0.032852   Top1 98.883929   Top5 100.000000   BatchTime 0.101615   LR 0.000010   
2022-11-03 21:36:52,745 - INFO  - Training [76][  160/  391]   Loss 0.032935   Top1 98.857422   Top5 100.000000   BatchTime 0.101423   LR 0.000010   
2022-11-03 21:36:54,749 - INFO  - Training [76][  180/  391]   Loss 0.032677   Top1 98.849826   Top5 100.000000   BatchTime 0.101288   LR 0.000010   
2022-11-03 21:36:56,754 - INFO  - Training [76][  200/  391]   Loss 0.032980   Top1 98.847656   Top5 100.000000   BatchTime 0.101182   LR 0.000010   
2022-11-03 21:36:58,740 - INFO  - Training [76][  220/  391]   Loss 0.033021   Top1 98.835227   Top5 100.000000   BatchTime 0.101011   LR 0.000010   
2022-11-03 21:37:00,735 - INFO  - Training [76][  240/  391]   Loss 0.033201   Top1 98.828125   Top5 100.000000   BatchTime 0.100905   LR 0.000010   
2022-11-03 21:37:02,724 - INFO  - Training [76][  260/  391]   Loss 0.033961   Top1 98.810096   Top5 100.000000   BatchTime 0.100795   LR 0.000010   
2022-11-03 21:37:04,753 - INFO  - Training [76][  280/  391]   Loss 0.033250   Top1 98.833705   Top5 100.000000   BatchTime 0.100840   LR 0.000010   
2022-11-03 21:37:06,776 - INFO  - Training [76][  300/  391]   Loss 0.033103   Top1 98.833333   Top5 100.000000   BatchTime 0.100859   LR 0.000010   
2022-11-03 21:37:08,768 - INFO  - Training [76][  320/  391]   Loss 0.033515   Top1 98.825684   Top5 100.000000   BatchTime 0.100781   LR 0.000010   
2022-11-03 21:37:10,756 - INFO  - Training [76][  340/  391]   Loss 0.033314   Top1 98.839614   Top5 100.000000   BatchTime 0.100699   LR 0.000010   
2022-11-03 21:37:12,750 - INFO  - Training [76][  360/  391]   Loss 0.033297   Top1 98.841146   Top5 100.000000   BatchTime 0.100645   LR 0.000010   
2022-11-03 21:37:14,731 - INFO  - Training [76][  380/  391]   Loss 0.033537   Top1 98.840461   Top5 100.000000   BatchTime 0.100560   LR 0.000010   
2022-11-03 21:37:16,047 - INFO  - ==> Top1: 98.838    Top5: 100.000    Loss: 0.034

2022-11-03 21:37:16,048 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:37:18,677 - INFO  - Validation [76][   20/   79]   Loss 0.373400   Top1 90.546875   Top5 99.648438   BatchTime 0.131368   
2022-11-03 21:37:19,580 - INFO  - Validation [76][   40/   79]   Loss 0.413201   Top1 90.449219   Top5 99.531250   BatchTime 0.088266   
2022-11-03 21:37:20,477 - INFO  - Validation [76][   60/   79]   Loss 0.408669   Top1 90.625000   Top5 99.544271   BatchTime 0.073801   
2022-11-03 21:37:21,598 - INFO  - ==> Top1: 90.600    Top5: 99.580    Loss: 0.403

2022-11-03 21:37:21,639 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:37:21,640 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:37:21,640 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:37:21,744 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:37:21,744 - INFO  - >>>>>>>> Epoch  77
2022-11-03 21:37:21,746 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:37:25,378 - INFO  - Training [77][   20/  391]   Loss 0.031766   Top1 98.945312   Top5 100.000000   BatchTime 0.181606   LR 0.000010   
2022-11-03 21:37:27,049 - INFO  - Training [77][   40/  391]   Loss 0.032034   Top1 98.984375   Top5 100.000000   BatchTime 0.132589   LR 0.000010   
2022-11-03 21:37:28,704 - INFO  - Training [77][   60/  391]   Loss 0.030615   Top1 99.036458   Top5 100.000000   BatchTime 0.115971   LR 0.000010   
2022-11-03 21:37:30,468 - INFO  - Training [77][   80/  391]   Loss 0.033507   Top1 98.925781   Top5 100.000000   BatchTime 0.109027   LR 0.000010   
2022-11-03 21:37:31,964 - INFO  - Training [77][  100/  391]   Loss 0.033440   Top1 98.898438   Top5 100.000000   BatchTime 0.102178   LR 0.000010   
2022-11-03 21:37:34,035 - INFO  - Training [77][  120/  391]   Loss 0.032809   Top1 98.906250   Top5 100.000000   BatchTime 0.102406   LR 0.000010   
2022-11-03 21:37:36,040 - INFO  - Training [77][  140/  391]   Loss 0.032728   Top1 98.895089   Top5 100.000000   BatchTime 0.102099   LR 0.000010   
2022-11-03 21:37:38,073 - INFO  - Training [77][  160/  391]   Loss 0.033458   Top1 98.872070   Top5 100.000000   BatchTime 0.102040   LR 0.000010   
2022-11-03 21:37:40,099 - INFO  - Training [77][  180/  391]   Loss 0.033271   Top1 98.871528   Top5 100.000000   BatchTime 0.101962   LR 0.000010   
2022-11-03 21:37:42,120 - INFO  - Training [77][  200/  391]   Loss 0.033273   Top1 98.863281   Top5 100.000000   BatchTime 0.101867   LR 0.000010   
2022-11-03 21:37:44,119 - INFO  - Training [77][  220/  391]   Loss 0.033221   Top1 98.881392   Top5 100.000000   BatchTime 0.101695   LR 0.000010   
2022-11-03 21:37:46,201 - INFO  - Training [77][  240/  391]   Loss 0.032869   Top1 98.893229   Top5 100.000000   BatchTime 0.101895   LR 0.000010   
2022-11-03 21:37:48,223 - INFO  - Training [77][  260/  391]   Loss 0.032879   Top1 98.891226   Top5 100.000000   BatchTime 0.101832   LR 0.000010   
2022-11-03 21:37:50,207 - INFO  - Training [77][  280/  391]   Loss 0.032677   Top1 98.914621   Top5 100.000000   BatchTime 0.101644   LR 0.000010   
2022-11-03 21:37:52,219 - INFO  - Training [77][  300/  391]   Loss 0.033008   Top1 98.890625   Top5 100.000000   BatchTime 0.101576   LR 0.000010   
2022-11-03 21:37:54,220 - INFO  - Training [77][  320/  391]   Loss 0.032902   Top1 98.891602   Top5 100.000000   BatchTime 0.101479   LR 0.000010   
2022-11-03 21:37:56,209 - INFO  - Training [77][  340/  391]   Loss 0.032859   Top1 98.887868   Top5 100.000000   BatchTime 0.101359   LR 0.000010   
2022-11-03 21:37:58,174 - INFO  - Training [77][  360/  391]   Loss 0.032523   Top1 98.901910   Top5 100.000000   BatchTime 0.101186   LR 0.000010   
2022-11-03 21:38:00,165 - INFO  - Training [77][  380/  391]   Loss 0.032322   Top1 98.908306   Top5 100.000000   BatchTime 0.101100   LR 0.000010   
2022-11-03 21:38:01,474 - INFO  - ==> Top1: 98.916    Top5: 100.000    Loss: 0.032

2022-11-03 21:38:01,475 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:38:04,100 - INFO  - Validation [77][   20/   79]   Loss 0.378906   Top1 90.742188   Top5 99.648438   BatchTime 0.131233   
2022-11-03 21:38:05,019 - INFO  - Validation [77][   40/   79]   Loss 0.418963   Top1 90.234375   Top5 99.531250   BatchTime 0.088589   
2022-11-03 21:38:05,926 - INFO  - Validation [77][   60/   79]   Loss 0.412559   Top1 90.533854   Top5 99.557292   BatchTime 0.074171   
2022-11-03 21:38:07,040 - INFO  - ==> Top1: 90.550    Top5: 99.580    Loss: 0.406

2022-11-03 21:38:07,069 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:38:07,070 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:38:07,070 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:38:07,174 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:38:07,175 - INFO  - >>>>>>>> Epoch  78
2022-11-03 21:38:07,176 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:38:10,756 - INFO  - Training [78][   20/  391]   Loss 0.029615   Top1 98.906250   Top5 100.000000   BatchTime 0.178947   LR 0.000010   
2022-11-03 21:38:12,443 - INFO  - Training [78][   40/  391]   Loss 0.031486   Top1 98.945312   Top5 100.000000   BatchTime 0.131668   LR 0.000010   
2022-11-03 21:38:14,060 - INFO  - Training [78][   60/  391]   Loss 0.031666   Top1 98.997396   Top5 100.000000   BatchTime 0.114731   LR 0.000010   
2022-11-03 21:38:15,762 - INFO  - Training [78][   80/  391]   Loss 0.032207   Top1 98.945312   Top5 100.000000   BatchTime 0.107322   LR 0.000010   
2022-11-03 21:38:17,229 - INFO  - Training [78][  100/  391]   Loss 0.032533   Top1 98.921875   Top5 100.000000   BatchTime 0.100527   LR 0.000010   
2022-11-03 21:38:19,302 - INFO  - Training [78][  120/  391]   Loss 0.032774   Top1 98.873698   Top5 100.000000   BatchTime 0.101040   LR 0.000010   
2022-11-03 21:38:21,317 - INFO  - Training [78][  140/  391]   Loss 0.034107   Top1 98.828125   Top5 100.000000   BatchTime 0.101004   LR 0.000010   
2022-11-03 21:38:23,314 - INFO  - Training [78][  160/  391]   Loss 0.034317   Top1 98.837891   Top5 100.000000   BatchTime 0.100855   LR 0.000010   
2022-11-03 21:38:25,326 - INFO  - Training [78][  180/  391]   Loss 0.033733   Top1 98.858507   Top5 100.000000   BatchTime 0.100828   LR 0.000010   
2022-11-03 21:38:27,353 - INFO  - Training [78][  200/  391]   Loss 0.032949   Top1 98.882812   Top5 100.000000   BatchTime 0.100880   LR 0.000010   
2022-11-03 21:38:29,372 - INFO  - Training [78][  220/  391]   Loss 0.033324   Top1 98.881392   Top5 100.000000   BatchTime 0.100886   LR 0.000010   
2022-11-03 21:38:31,373 - INFO  - Training [78][  240/  391]   Loss 0.033049   Top1 98.896484   Top5 100.000000   BatchTime 0.100818   LR 0.000010   
2022-11-03 21:38:33,380 - INFO  - Training [78][  260/  391]   Loss 0.033461   Top1 98.858173   Top5 100.000000   BatchTime 0.100779   LR 0.000010   
2022-11-03 21:38:35,386 - INFO  - Training [78][  280/  391]   Loss 0.033497   Top1 98.867188   Top5 100.000000   BatchTime 0.100745   LR 0.000010   
2022-11-03 21:38:37,380 - INFO  - Training [78][  300/  391]   Loss 0.033855   Top1 98.854167   Top5 99.997396   BatchTime 0.100675   LR 0.000010   
2022-11-03 21:38:39,393 - INFO  - Training [78][  320/  391]   Loss 0.034097   Top1 98.842773   Top5 99.997559   BatchTime 0.100673   LR 0.000010   
2022-11-03 21:38:41,366 - INFO  - Training [78][  340/  391]   Loss 0.034240   Top1 98.839614   Top5 99.997702   BatchTime 0.100556   LR 0.000010   
2022-11-03 21:38:43,335 - INFO  - Training [78][  360/  391]   Loss 0.034294   Top1 98.847656   Top5 99.997830   BatchTime 0.100439   LR 0.000010   
2022-11-03 21:38:45,324 - INFO  - Training [78][  380/  391]   Loss 0.033966   Top1 98.852796   Top5 99.997944   BatchTime 0.100385   LR 0.000010   
2022-11-03 21:38:46,649 - INFO  - ==> Top1: 98.848    Top5: 99.998    Loss: 0.034

2022-11-03 21:38:46,650 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:38:49,271 - INFO  - Validation [78][   20/   79]   Loss 0.371136   Top1 90.898438   Top5 99.726562   BatchTime 0.131023   
2022-11-03 21:38:50,145 - INFO  - Validation [78][   40/   79]   Loss 0.412189   Top1 90.664062   Top5 99.589844   BatchTime 0.087360   
2022-11-03 21:38:51,045 - INFO  - Validation [78][   60/   79]   Loss 0.409895   Top1 90.690104   Top5 99.596354   BatchTime 0.073244   
2022-11-03 21:38:52,164 - INFO  - ==> Top1: 90.730    Top5: 99.630    Loss: 0.401

2022-11-03 21:38:52,204 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:38:52,205 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:38:52,205 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:38:52,311 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:38:52,311 - INFO  - >>>>>>>> Epoch  79
2022-11-03 21:38:52,313 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:38:55,862 - INFO  - Training [79][   20/  391]   Loss 0.031729   Top1 99.023438   Top5 100.000000   BatchTime 0.177452   LR 0.000010   
2022-11-03 21:38:57,500 - INFO  - Training [79][   40/  391]   Loss 0.036332   Top1 98.632812   Top5 100.000000   BatchTime 0.129674   LR 0.000010   
2022-11-03 21:38:59,129 - INFO  - Training [79][   60/  391]   Loss 0.035278   Top1 98.645833   Top5 100.000000   BatchTime 0.113599   LR 0.000010   
2022-11-03 21:39:00,887 - INFO  - Training [79][   80/  391]   Loss 0.033729   Top1 98.740234   Top5 100.000000   BatchTime 0.107179   LR 0.000010   
2022-11-03 21:39:02,421 - INFO  - Training [79][  100/  391]   Loss 0.034444   Top1 98.695312   Top5 100.000000   BatchTime 0.101083   LR 0.000010   
2022-11-03 21:39:04,392 - INFO  - Training [79][  120/  391]   Loss 0.035073   Top1 98.678385   Top5 100.000000   BatchTime 0.100658   LR 0.000010   
2022-11-03 21:39:06,416 - INFO  - Training [79][  140/  391]   Loss 0.034360   Top1 98.699777   Top5 100.000000   BatchTime 0.100731   LR 0.000010   
2022-11-03 21:39:08,410 - INFO  - Training [79][  160/  391]   Loss 0.034476   Top1 98.681641   Top5 100.000000   BatchTime 0.100608   LR 0.000010   
2022-11-03 21:39:10,419 - INFO  - Training [79][  180/  391]   Loss 0.034340   Top1 98.693576   Top5 100.000000   BatchTime 0.100590   LR 0.000010   
2022-11-03 21:39:12,418 - INFO  - Training [79][  200/  391]   Loss 0.033744   Top1 98.722656   Top5 100.000000   BatchTime 0.100524   LR 0.000010   
2022-11-03 21:39:14,438 - INFO  - Training [79][  220/  391]   Loss 0.034194   Top1 98.721591   Top5 100.000000   BatchTime 0.100565   LR 0.000010   
2022-11-03 21:39:16,445 - INFO  - Training [79][  240/  391]   Loss 0.034209   Top1 98.727214   Top5 100.000000   BatchTime 0.100549   LR 0.000010   
2022-11-03 21:39:18,451 - INFO  - Training [79][  260/  391]   Loss 0.034217   Top1 98.731971   Top5 100.000000   BatchTime 0.100528   LR 0.000010   
2022-11-03 21:39:20,459 - INFO  - Training [79][  280/  391]   Loss 0.034337   Top1 98.730469   Top5 99.997210   BatchTime 0.100520   LR 0.000010   
2022-11-03 21:39:22,473 - INFO  - Training [79][  300/  391]   Loss 0.034170   Top1 98.747396   Top5 99.997396   BatchTime 0.100531   LR 0.000010   
2022-11-03 21:39:24,580 - INFO  - Training [79][  320/  391]   Loss 0.033702   Top1 98.767090   Top5 99.997559   BatchTime 0.100831   LR 0.000010   
2022-11-03 21:39:26,559 - INFO  - Training [79][  340/  391]   Loss 0.033746   Top1 98.766085   Top5 99.997702   BatchTime 0.100723   LR 0.000010   
2022-11-03 21:39:28,531 - INFO  - Training [79][  360/  391]   Loss 0.033872   Top1 98.754340   Top5 99.997830   BatchTime 0.100604   LR 0.000010   
2022-11-03 21:39:30,524 - INFO  - Training [79][  380/  391]   Loss 0.034161   Top1 98.750000   Top5 99.997944   BatchTime 0.100553   LR 0.000010   
2022-11-03 21:39:31,840 - INFO  - ==> Top1: 98.762    Top5: 99.998    Loss: 0.034

2022-11-03 21:39:31,841 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:39:34,446 - INFO  - Validation [79][   20/   79]   Loss 0.376343   Top1 90.703125   Top5 99.726562   BatchTime 0.130216   
2022-11-03 21:39:35,345 - INFO  - Validation [79][   40/   79]   Loss 0.415548   Top1 90.585938   Top5 99.609375   BatchTime 0.087585   
2022-11-03 21:39:36,269 - INFO  - Validation [79][   60/   79]   Loss 0.410331   Top1 90.664062   Top5 99.622396   BatchTime 0.073784   
2022-11-03 21:39:37,365 - INFO  - ==> Top1: 90.650    Top5: 99.660    Loss: 0.403

2022-11-03 21:39:37,397 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.860   Top5: 99.600] Sparsity : 0.779
2022-11-03 21:39:37,398 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.830   Top5: 99.660] Sparsity : 0.775
2022-11-03 21:39:37,398 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.800   Top5: 99.660] Sparsity : 0.776
2022-11-03 21:39:37,506 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch80_20221103-203854/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:39:37,507 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 21:39:37,507 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:39:40,093 - INFO  - Validation [   20/   79]   Loss 0.376343   Top1 90.703125   Top5 99.726562   BatchTime 0.129225   
2022-11-03 21:39:40,750 - INFO  - Validation [   40/   79]   Loss 0.415548   Top1 90.585938   Top5 99.609375   BatchTime 0.081052   
2022-11-03 21:39:41,288 - INFO  - Validation [   60/   79]   Loss 0.410331   Top1 90.664062   Top5 99.622396   BatchTime 0.063004   
2022-11-03 21:39:42,051 - INFO  - ==> Top1: 90.650    Top5: 99.660    Loss: 0.403

2022-11-03 21:39:42,108 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar

2022-11-03 21:39:42,109 - INFO  - Program completed successfully ... exiting ...
2022-11-03 21:39:42,109 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
