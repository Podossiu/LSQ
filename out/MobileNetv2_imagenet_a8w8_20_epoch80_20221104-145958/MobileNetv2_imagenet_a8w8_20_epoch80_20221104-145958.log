2022-11-04 14:59:58,805 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_20_epoch80_20221104-145958/MobileNetv2_imagenet_a8w8_20_epoch80_20221104-145958.log
2022-11-04 14:59:59,971 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_20_epoch80_20221104-145958/tb_runs
2022-11-04 15:00:02,387 - INFO  - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
2022-11-04 15:00:03,993 - INFO  - Created `MobileNetv2` model for `imagenet` dataset
          Use pre-trained model = True
2022-11-04 15:00:06,558 - INFO  - Inserted quantizers into the original model
2022-11-04 15:00:06,766 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-04 15:00:06,767 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-04 15:00:06,767 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-04 15:00:06,767 - INFO  - Validation: 50000 samples (128 per mini-batch)
2022-11-04 15:00:24,258 - INFO  - Validation [   20/  391]   Loss 27.609890   Top1 0.000000   Top5 0.117188   BatchTime 0.874510   
2022-11-04 15:00:27,912 - INFO  - Validation [   40/  391]   Loss 28.591004   Top1 0.000000   Top5 0.058594   BatchTime 0.528620   
2022-11-04 15:00:31,603 - INFO  - Validation [   60/  391]   Loss 27.567062   Top1 0.000000   Top5 0.403646   BatchTime 0.413926   
2022-11-04 15:00:35,156 - INFO  - Validation [   80/  391]   Loss 24.924523   Top1 0.000000   Top5 0.419922   BatchTime 0.354861   
2022-11-04 15:00:38,942 - INFO  - Validation [  100/  391]   Loss 23.307600   Top1 0.000000   Top5 0.335938   BatchTime 0.321743   
2022-11-04 15:00:42,814 - INFO  - Validation [  120/  391]   Loss 23.457049   Top1 0.312500   Top5 0.657552   BatchTime 0.300384   
2022-11-04 15:00:46,954 - INFO  - Validation [  140/  391]   Loss 24.179314   Top1 0.267857   Top5 0.563616   BatchTime 0.287047   
2022-11-04 15:00:51,028 - INFO  - Validation [  160/  391]   Loss 24.201449   Top1 0.234375   Top5 0.493164   BatchTime 0.276627   
2022-11-04 15:00:55,341 - INFO  - Validation [  180/  391]   Loss 24.038137   Top1 0.208333   Top5 0.438368   BatchTime 0.269851   
2022-11-04 15:00:59,345 - INFO  - Validation [  200/  391]   Loss 24.115841   Top1 0.187500   Top5 0.394531   BatchTime 0.262884   
2022-11-04 15:01:03,375 - INFO  - Validation [  220/  391]   Loss 24.233748   Top1 0.184659   Top5 0.529119   BatchTime 0.257304   
2022-11-04 15:01:07,410 - INFO  - Validation [  240/  391]   Loss 24.254343   Top1 0.169271   Top5 0.488281   BatchTime 0.252673   
2022-11-04 15:01:11,705 - INFO  - Validation [  260/  391]   Loss 24.264850   Top1 0.156250   Top5 0.450721   BatchTime 0.249758   
2022-11-04 15:01:15,743 - INFO  - Validation [  280/  391]   Loss 24.328493   Top1 0.145089   Top5 0.502232   BatchTime 0.246339   
2022-11-04 15:01:24,043 - INFO  - Validation [  300/  391]   Loss 24.268197   Top1 0.135417   Top5 0.611979   BatchTime 0.257584   
2022-11-04 15:01:32,972 - INFO  - Validation [  320/  391]   Loss 24.314753   Top1 0.126953   Top5 0.573730   BatchTime 0.269386   
2022-11-04 15:01:36,187 - INFO  - Validation [  340/  391]   Loss 24.194326   Top1 0.119485   Top5 0.562960   BatchTime 0.262996   
2022-11-04 15:01:39,182 - INFO  - Validation [  360/  391]   Loss 24.101134   Top1 0.112847   Top5 0.531684   BatchTime 0.256704   
2022-11-04 15:01:42,216 - INFO  - Validation [  380/  391]   Loss 24.285498   Top1 0.106908   Top5 0.503701   BatchTime 0.251179   
2022-11-04 15:01:46,490 - INFO  - ==> Top1: 0.104    Top5: 0.490    Loss: 24.380

2022-11-04 15:01:46,554 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 0.104   Top5: 0.490] Sparsity : 0.060
2022-11-04 15:01:46,555 - INFO  - >>>>>>>> Epoch   0
2022-11-04 15:01:46,557 - INFO  - Training: 1281167 samples (128 per mini-batch)
2022-11-04 15:02:08,705 - INFO  - Training [0][   20/10010]   Loss 5.860760   Top1 6.367188   Top5 16.914062   BatchTime 1.107323   LR 0.010000   
2022-11-04 15:02:24,107 - INFO  - Training [0][   40/10010]   Loss 5.720156   Top1 6.777344   Top5 18.242188   BatchTime 0.938714   LR 0.010000   
2022-11-04 15:02:39,552 - INFO  - Training [0][   60/10010]   Loss 5.514934   Top1 8.046875   Top5 21.041667   BatchTime 0.883223   LR 0.010000   
2022-11-04 15:02:55,103 - INFO  - Training [0][   80/10010]   Loss 5.272532   Top1 9.794922   Top5 24.150391   BatchTime 0.856811   LR 0.010000   
2022-11-04 15:03:10,730 - INFO  - Training [0][  100/10010]   Loss 5.055317   Top1 11.773438   Top5 27.414062   BatchTime 0.841713   LR 0.010000   
2022-11-04 15:03:26,464 - INFO  - Training [0][  120/10010]   Loss 4.859805   Top1 13.574219   Top5 30.520833   BatchTime 0.832545   LR 0.010000   
2022-11-04 15:03:42,313 - INFO  - Training [0][  140/10010]   Loss 4.683927   Top1 15.161830   Top5 33.214286   BatchTime 0.826814   LR 0.010000   
2022-11-04 15:03:57,701 - INFO  - Training [0][  160/10010]   Loss 4.547140   Top1 16.831055   Top5 35.429688   BatchTime 0.819637   LR 0.010000   
2022-11-04 15:04:08,821 - INFO  - Training [0][  180/10010]   Loss 4.435951   Top1 17.990451   Top5 37.204861   BatchTime 0.790342   LR 0.010000   
2022-11-04 15:04:18,784 - INFO  - Training [0][  200/10010]   Loss 4.337227   Top1 19.074219   Top5 38.863281   BatchTime 0.761124   LR 0.010000   
2022-11-04 15:04:29,215 - INFO  - Training [0][  220/10010]   Loss 4.234546   Top1 20.394176   Top5 40.561080   BatchTime 0.739346   LR 0.010000   
2022-11-04 15:04:38,212 - INFO  - Training [0][  240/10010]   Loss 4.147936   Top1 21.500651   Top5 42.037760   BatchTime 0.715221   LR 0.010000   
2022-11-04 15:04:47,206 - INFO  - Training [0][  260/10010]   Loss 4.072842   Top1 22.530048   Top5 43.287260   BatchTime 0.694795   LR 0.010000   
2022-11-04 15:04:56,419 - INFO  - Training [0][  280/10010]   Loss 4.013182   Top1 23.376116   Top5 44.249442   BatchTime 0.678071   LR 0.010000   
2022-11-04 15:05:05,435 - INFO  - Training [0][  300/10010]   Loss 3.944062   Top1 24.205729   Top5 45.411458   BatchTime 0.662918   LR 0.010000   
2022-11-04 15:05:14,444 - INFO  - Training [0][  320/10010]   Loss 3.883365   Top1 24.941406   Top5 46.462402   BatchTime 0.649637   LR 0.010000   
2022-11-04 15:05:23,459 - INFO  - Training [0][  340/10010]   Loss 3.837028   Top1 25.549173   Top5 47.249540   BatchTime 0.637938   LR 0.010000   
2022-11-04 15:05:32,519 - INFO  - Training [0][  360/10010]   Loss 3.793970   Top1 26.085069   Top5 47.936198   BatchTime 0.627665   LR 0.010000   
2022-11-04 15:05:41,626 - INFO  - Training [0][  380/10010]   Loss 3.760989   Top1 26.492599   Top5 48.464227   BatchTime 0.618594   LR 0.010000   
2022-11-04 15:05:50,687 - INFO  - Training [0][  400/10010]   Loss 3.726131   Top1 26.943359   Top5 49.037109   BatchTime 0.610318   LR 0.010000   
2022-11-04 15:05:59,677 - INFO  - Training [0][  420/10010]   Loss 3.691659   Top1 27.354911   Top5 49.657738   BatchTime 0.602658   LR 0.010000   
2022-11-04 15:06:08,631 - INFO  - Training [0][  440/10010]   Loss 3.660965   Top1 27.778764   Top5 50.179332   BatchTime 0.595617   LR 0.010000   
2022-11-04 15:06:17,598 - INFO  - Training [0][  460/10010]   Loss 3.634286   Top1 28.082541   Top5 50.675951   BatchTime 0.589213   LR 0.010000   
2022-11-04 15:06:26,558 - INFO  - Training [0][  480/10010]   Loss 3.607814   Top1 28.440755   Top5 51.126302   BatchTime 0.583329   LR 0.010000   
2022-11-04 15:06:35,532 - INFO  - Training [0][  500/10010]   Loss 3.581784   Top1 28.740625   Top5 51.540625   BatchTime 0.577943   LR 0.010000   
2022-11-04 15:06:44,512 - INFO  - Training [0][  520/10010]   Loss 3.561630   Top1 28.994892   Top5 51.873498   BatchTime 0.572983   LR 0.010000   
2022-11-04 15:06:53,455 - INFO  - Training [0][  540/10010]   Loss 3.543718   Top1 29.240451   Top5 52.165799   BatchTime 0.568323   LR 0.010000   
2022-11-04 15:07:02,388 - INFO  - Training [0][  560/10010]   Loss 3.526316   Top1 29.426618   Top5 52.453962   BatchTime 0.563977   LR 0.010000   
2022-11-04 15:07:11,302 - INFO  - Training [0][  580/10010]   Loss 3.507836   Top1 29.686153   Top5 52.772091   BatchTime 0.559899   LR 0.010000   
