2022-11-06 16:37:19,304 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-163719/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-163719.log
2022-11-06 16:37:20,288 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-163719/tb_runs
2022-11-06 16:37:22,513 - INFO  - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
2022-11-06 16:37:24,053 - INFO  - Created `MobileNetv2` model for `imagenet` dataset
          Use pre-trained model = True
2022-11-06 16:37:26,281 - INFO  - Inserted quantizers into the original model
2022-11-06 16:37:26,448 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.05
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-06 16:37:26,448 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.05

2022-11-06 16:37:26,448 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-06 16:37:26,448 - INFO  - Validation: 50000 samples (128 per mini-batch)
2022-11-06 16:37:38,871 - INFO  - Validation [   20/  391]   Loss 27.609890   Top1 0.000000   Top5 0.117188   BatchTime 0.621104   
2022-11-06 16:37:42,420 - INFO  - Validation [   40/  391]   Loss 28.591004   Top1 0.000000   Top5 0.058594   BatchTime 0.399286   
2022-11-06 16:37:45,979 - INFO  - Validation [   60/  391]   Loss 27.567062   Top1 0.000000   Top5 0.403646   BatchTime 0.325496   
2022-11-06 16:37:49,525 - INFO  - Validation [   80/  391]   Loss 24.924523   Top1 0.000000   Top5 0.419922   BatchTime 0.288452   
2022-11-06 16:37:53,067 - INFO  - Validation [  100/  391]   Loss 23.307600   Top1 0.000000   Top5 0.335938   BatchTime 0.266186   
2022-11-06 16:37:56,640 - INFO  - Validation [  120/  391]   Loss 23.457049   Top1 0.312500   Top5 0.657552   BatchTime 0.251590   
2022-11-06 16:38:00,227 - INFO  - Validation [  140/  391]   Loss 24.179314   Top1 0.267857   Top5 0.563616   BatchTime 0.241273   
2022-11-06 16:38:03,904 - INFO  - Validation [  160/  391]   Loss 24.201449   Top1 0.234375   Top5 0.493164   BatchTime 0.234094   
2022-11-06 16:38:10,679 - INFO  - Validation [  180/  391]   Loss 24.038137   Top1 0.208333   Top5 0.438368   BatchTime 0.245722   
2022-11-06 16:38:14,341 - INFO  - Validation [  200/  391]   Loss 24.115841   Top1 0.187500   Top5 0.394531   BatchTime 0.239462   
2022-11-06 16:38:18,120 - INFO  - Validation [  220/  391]   Loss 24.233748   Top1 0.184659   Top5 0.529119   BatchTime 0.234869   
2022-11-06 16:38:21,974 - INFO  - Validation [  240/  391]   Loss 24.254343   Top1 0.169271   Top5 0.488281   BatchTime 0.231355   
2022-11-06 16:38:25,718 - INFO  - Validation [  260/  391]   Loss 24.264850   Top1 0.156250   Top5 0.450721   BatchTime 0.227959   
2022-11-06 16:38:29,571 - INFO  - Validation [  280/  391]   Loss 24.328493   Top1 0.145089   Top5 0.502232   BatchTime 0.225434   
2022-11-06 16:38:33,382 - INFO  - Validation [  300/  391]   Loss 24.268197   Top1 0.135417   Top5 0.611979   BatchTime 0.223111   
2022-11-06 16:38:37,145 - INFO  - Validation [  320/  391]   Loss 24.314753   Top1 0.126953   Top5 0.573730   BatchTime 0.220923   
2022-11-06 16:38:40,729 - INFO  - Validation [  340/  391]   Loss 24.194326   Top1 0.119485   Top5 0.562960   BatchTime 0.218471   
2022-11-06 16:38:44,129 - INFO  - Validation [  360/  391]   Loss 24.101134   Top1 0.112847   Top5 0.531684   BatchTime 0.215778   
2022-11-06 16:38:47,524 - INFO  - Validation [  380/  391]   Loss 24.285498   Top1 0.106908   Top5 0.503701   BatchTime 0.213354   
2022-11-06 16:38:49,897 - INFO  - ==> Top1: 0.104    Top5: 0.490    Loss: 24.380

2022-11-06 16:38:49,926 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 0.104   Top5: 0.490] Sparsity : 0.060
2022-11-06 16:38:49,926 - INFO  - >>>>>>>> Epoch   0
2022-11-06 16:38:49,928 - INFO  - Training: 1281167 samples (128 per mini-batch)
2022-11-06 16:39:05,997 - INFO  - Training [0][   20/10010]   Loss 7.322179   Top1 0.976562   Top5 4.101562   BatchTime 0.803460   LR 0.050000   
2022-11-06 16:39:15,029 - INFO  - Training [0][   40/10010]   Loss 7.076063   Top1 0.644531   Top5 3.183594   BatchTime 0.627522   LR 0.050000   
2022-11-06 16:39:25,581 - INFO  - Training [0][   60/10010]   Loss 6.921548   Top1 0.690104   Top5 3.164062   BatchTime 0.594216   LR 0.050000   
2022-11-06 16:39:34,838 - INFO  - Training [0][   80/10010]   Loss 6.807557   Top1 0.664062   Top5 3.349609   BatchTime 0.561371   LR 0.050000   
2022-11-06 16:39:43,792 - INFO  - Training [0][  100/10010]   Loss 6.708951   Top1 0.773438   Top5 3.539062   BatchTime 0.538636   LR 0.050000   
2022-11-06 16:39:52,773 - INFO  - Training [0][  120/10010]   Loss 6.635946   Top1 0.891927   Top5 3.886719   BatchTime 0.523710   LR 0.049999   
2022-11-06 16:40:01,731 - INFO  - Training [0][  140/10010]   Loss 6.569352   Top1 1.010045   Top5 4.241071   BatchTime 0.512878   LR 0.049999   
2022-11-06 16:40:10,691 - INFO  - Training [0][  160/10010]   Loss 6.515060   Top1 1.157227   Top5 4.624023   BatchTime 0.504767   LR 0.049999   
