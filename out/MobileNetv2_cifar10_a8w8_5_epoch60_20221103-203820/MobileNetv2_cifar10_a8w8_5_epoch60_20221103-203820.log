2022-11-03 20:38:20,640 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820.log
2022-11-03 20:38:21,607 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/tb_runs
2022-11-03 20:38:22,667 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (391)
        Validation Set = 10000 (79)
              Test Set = 10000 (79)
2022-11-03 20:38:24,239 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = True
2022-11-03 20:38:26,287 - INFO  - Inserted quantizers into the original model
2022-11-03 20:38:26,454 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 20:38:26,454 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 20:38:26,454 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 20:38:26,454 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:38:29,514 - INFO  - Validation [   20/   79]   Loss 2.545371   Top1 10.429688   Top5 49.101562   BatchTime 0.152936   
2022-11-03 20:38:30,004 - INFO  - Validation [   40/   79]   Loss 2.549466   Top1 10.175781   Top5 49.941406   BatchTime 0.088738   
2022-11-03 20:38:30,492 - INFO  - Validation [   60/   79]   Loss 2.541519   Top1 10.117188   Top5 50.377604   BatchTime 0.067291   
2022-11-03 20:38:31,183 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.546

2022-11-03 20:38:31,204 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 20:38:31,205 - INFO  - >>>>>>>> Epoch   0
2022-11-03 20:38:31,205 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:38:34,679 - INFO  - Training [0][   20/  391]   Loss 1.617645   Top1 67.929688   Top5 96.523438   BatchTime 0.173694   LR 0.010000   
2022-11-03 20:38:36,098 - INFO  - Training [0][   40/  391]   Loss 1.342365   Top1 69.277344   Top5 97.343750   BatchTime 0.122323   LR 0.010000   
2022-11-03 20:38:37,510 - INFO  - Training [0][   60/  391]   Loss 1.154562   Top1 71.119792   Top5 97.682292   BatchTime 0.105074   LR 0.010000   
2022-11-03 20:38:38,924 - INFO  - Training [0][   80/  391]   Loss 1.035326   Top1 72.773438   Top5 97.998047   BatchTime 0.096487   LR 0.010000   
2022-11-03 20:38:40,318 - INFO  - Training [0][  100/  391]   Loss 0.941873   Top1 74.242188   Top5 98.187500   BatchTime 0.091129   LR 0.010000   
2022-11-03 20:38:41,701 - INFO  - Training [0][  120/  391]   Loss 0.868743   Top1 75.572917   Top5 98.417969   BatchTime 0.087466   LR 0.010000   
2022-11-03 20:38:43,131 - INFO  - Training [0][  140/  391]   Loss 0.811275   Top1 76.785714   Top5 98.565848   BatchTime 0.085182   LR 0.010000   
2022-11-03 20:38:44,566 - INFO  - Training [0][  160/  391]   Loss 0.768765   Top1 77.617188   Top5 98.662109   BatchTime 0.083505   LR 0.010000   
2022-11-03 20:38:46,004 - INFO  - Training [0][  180/  391]   Loss 0.731386   Top1 78.424479   Top5 98.754340   BatchTime 0.082214   LR 0.010000   
2022-11-03 20:38:47,461 - INFO  - Training [0][  200/  391]   Loss 0.704414   Top1 78.937500   Top5 98.792969   BatchTime 0.081278   LR 0.010000   
2022-11-03 20:38:48,882 - INFO  - Training [0][  220/  391]   Loss 0.681659   Top1 79.399858   Top5 98.831676   BatchTime 0.080349   LR 0.010000   
2022-11-03 20:38:50,287 - INFO  - Training [0][  240/  391]   Loss 0.658928   Top1 79.921875   Top5 98.893229   BatchTime 0.079505   LR 0.010000   
2022-11-03 20:38:51,742 - INFO  - Training [0][  260/  391]   Loss 0.639124   Top1 80.393630   Top5 98.960337   BatchTime 0.078984   LR 0.010000   
2022-11-03 20:38:53,243 - INFO  - Training [0][  280/  391]   Loss 0.621343   Top1 80.764509   Top5 99.012277   BatchTime 0.078705   LR 0.010000   
2022-11-03 20:38:54,769 - INFO  - Training [0][  300/  391]   Loss 0.606617   Top1 81.057292   Top5 99.049479   BatchTime 0.078544   LR 0.010000   
2022-11-03 20:38:56,253 - INFO  - Training [0][  320/  391]   Loss 0.590840   Top1 81.477051   Top5 99.091797   BatchTime 0.078271   LR 0.010000   
2022-11-03 20:38:57,689 - INFO  - Training [0][  340/  391]   Loss 0.576930   Top1 81.858915   Top5 99.131434   BatchTime 0.077893   LR 0.010000   
2022-11-03 20:38:59,193 - INFO  - Training [0][  360/  391]   Loss 0.563446   Top1 82.211372   Top5 99.164497   BatchTime 0.077743   LR 0.010000   
2022-11-03 20:39:00,706 - INFO  - Training [0][  380/  391]   Loss 0.551706   Top1 82.547286   Top5 99.187911   BatchTime 0.077632   LR 0.010000   
2022-11-03 20:39:01,957 - INFO  - ==> Top1: 82.700    Top5: 99.202    Loss: 0.546

2022-11-03 20:39:01,958 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:39:04,591 - INFO  - Validation [0][   20/   79]   Loss 0.454939   Top1 84.726562   Top5 99.257812   BatchTime 0.131615   
2022-11-03 20:39:05,272 - INFO  - Validation [0][   40/   79]   Loss 0.458713   Top1 84.667969   Top5 99.199219   BatchTime 0.082834   
2022-11-03 20:39:05,952 - INFO  - Validation [0][   60/   79]   Loss 0.459039   Top1 84.947917   Top5 99.244792   BatchTime 0.066558   
2022-11-03 20:39:06,954 - INFO  - ==> Top1: 84.870    Top5: 99.290    Loss: 0.461

2022-11-03 20:39:06,981 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.870   Top5: 99.290] Sparsity : 0.292
2022-11-03 20:39:06,981 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 20:39:07,049 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:39:07,049 - INFO  - >>>>>>>> Epoch   1
2022-11-03 20:39:07,050 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:39:11,015 - INFO  - Training [1][   20/  391]   Loss 0.293181   Top1 89.531250   Top5 99.843750   BatchTime 0.198231   LR 0.010000   
2022-11-03 20:39:12,979 - INFO  - Training [1][   40/  391]   Loss 0.288222   Top1 89.882812   Top5 99.726562   BatchTime 0.148224   LR 0.010000   
2022-11-03 20:39:14,955 - INFO  - Training [1][   60/  391]   Loss 0.294849   Top1 89.648438   Top5 99.778646   BatchTime 0.131750   LR 0.010000   
2022-11-03 20:39:16,903 - INFO  - Training [1][   80/  391]   Loss 0.295424   Top1 89.462891   Top5 99.746094   BatchTime 0.123157   LR 0.010000   
2022-11-03 20:39:18,883 - INFO  - Training [1][  100/  391]   Loss 0.291575   Top1 89.679688   Top5 99.781250   BatchTime 0.118327   LR 0.010000   
2022-11-03 20:39:20,836 - INFO  - Training [1][  120/  391]   Loss 0.289980   Top1 89.674479   Top5 99.778646   BatchTime 0.114881   LR 0.010000   
2022-11-03 20:39:22,815 - INFO  - Training [1][  140/  391]   Loss 0.286326   Top1 89.754464   Top5 99.787946   BatchTime 0.112609   LR 0.010000   
2022-11-03 20:39:24,792 - INFO  - Training [1][  160/  391]   Loss 0.285892   Top1 89.794922   Top5 99.804688   BatchTime 0.110885   LR 0.010000   
2022-11-03 20:39:26,777 - INFO  - Training [1][  180/  391]   Loss 0.285560   Top1 89.835069   Top5 99.804688   BatchTime 0.109594   LR 0.010000   
2022-11-03 20:39:28,752 - INFO  - Training [1][  200/  391]   Loss 0.285912   Top1 89.855469   Top5 99.792969   BatchTime 0.108510   LR 0.010000   
2022-11-03 20:39:30,711 - INFO  - Training [1][  220/  391]   Loss 0.284330   Top1 89.939631   Top5 99.790483   BatchTime 0.107547   LR 0.010000   
2022-11-03 20:39:32,668 - INFO  - Training [1][  240/  391]   Loss 0.282419   Top1 89.980469   Top5 99.798177   BatchTime 0.106741   LR 0.010000   
2022-11-03 20:39:34,641 - INFO  - Training [1][  260/  391]   Loss 0.282503   Top1 89.990986   Top5 99.798678   BatchTime 0.106117   LR 0.010000   
2022-11-03 20:39:36,595 - INFO  - Training [1][  280/  391]   Loss 0.280001   Top1 90.097656   Top5 99.796317   BatchTime 0.105517   LR 0.010000   
2022-11-03 20:39:38,553 - INFO  - Training [1][  300/  391]   Loss 0.278553   Top1 90.171875   Top5 99.804688   BatchTime 0.105007   LR 0.010000   
2022-11-03 20:39:40,526 - INFO  - Training [1][  320/  391]   Loss 0.276452   Top1 90.253906   Top5 99.802246   BatchTime 0.104610   LR 0.010000   
2022-11-03 20:39:42,452 - INFO  - Training [1][  340/  391]   Loss 0.275485   Top1 90.317096   Top5 99.800092   BatchTime 0.104123   LR 0.010000   
2022-11-03 20:39:44,360 - INFO  - Training [1][  360/  391]   Loss 0.273378   Top1 90.414497   Top5 99.802517   BatchTime 0.103637   LR 0.010000   
2022-11-03 20:39:46,209 - INFO  - Training [1][  380/  391]   Loss 0.271763   Top1 90.493421   Top5 99.806743   BatchTime 0.103049   LR 0.010000   
2022-11-03 20:39:47,511 - INFO  - ==> Top1: 90.548    Top5: 99.812    Loss: 0.270

2022-11-03 20:39:47,512 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:39:50,278 - INFO  - Validation [1][   20/   79]   Loss 0.403013   Top1 86.367188   Top5 99.531250   BatchTime 0.138233   
2022-11-03 20:39:50,954 - INFO  - Validation [1][   40/   79]   Loss 0.414152   Top1 86.445312   Top5 99.394531   BatchTime 0.086030   
2022-11-03 20:39:51,633 - INFO  - Validation [1][   60/   79]   Loss 0.410035   Top1 86.718750   Top5 99.427083   BatchTime 0.068660   
2022-11-03 20:39:52,753 - INFO  - ==> Top1: 86.880    Top5: 99.480    Loss: 0.408

2022-11-03 20:39:52,777 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.880   Top5: 99.480] Sparsity : 0.550
2022-11-03 20:39:52,778 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.870   Top5: 99.290] Sparsity : 0.292
2022-11-03 20:39:52,778 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 20:39:53,042 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:39:53,042 - INFO  - >>>>>>>> Epoch   2
2022-11-03 20:39:53,043 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:39:57,007 - INFO  - Training [2][   20/  391]   Loss 0.214333   Top1 92.539062   Top5 99.960938   BatchTime 0.198179   LR 0.010000   
2022-11-03 20:39:58,967 - INFO  - Training [2][   40/  391]   Loss 0.219838   Top1 92.285156   Top5 99.902344   BatchTime 0.148095   LR 0.010000   
2022-11-03 20:40:00,925 - INFO  - Training [2][   60/  391]   Loss 0.215578   Top1 92.382812   Top5 99.869792   BatchTime 0.131366   LR 0.010000   
2022-11-03 20:40:02,872 - INFO  - Training [2][   80/  391]   Loss 0.211351   Top1 92.519531   Top5 99.882812   BatchTime 0.122862   LR 0.010000   
2022-11-03 20:40:04,838 - INFO  - Training [2][  100/  391]   Loss 0.211096   Top1 92.531250   Top5 99.882812   BatchTime 0.117945   LR 0.010000   
2022-11-03 20:40:06,802 - INFO  - Training [2][  120/  391]   Loss 0.211632   Top1 92.532552   Top5 99.889323   BatchTime 0.114657   LR 0.010000   
2022-11-03 20:40:08,780 - INFO  - Training [2][  140/  391]   Loss 0.209424   Top1 92.656250   Top5 99.893973   BatchTime 0.112407   LR 0.010000   
2022-11-03 20:40:10,740 - INFO  - Training [2][  160/  391]   Loss 0.209126   Top1 92.675781   Top5 99.887695   BatchTime 0.110606   LR 0.010000   
2022-11-03 20:40:12,703 - INFO  - Training [2][  180/  391]   Loss 0.211690   Top1 92.578125   Top5 99.891493   BatchTime 0.109223   LR 0.010000   
2022-11-03 20:40:14,683 - INFO  - Training [2][  200/  391]   Loss 0.210294   Top1 92.644531   Top5 99.894531   BatchTime 0.108199   LR 0.010000   
2022-11-03 20:40:16,649 - INFO  - Training [2][  220/  391]   Loss 0.211144   Top1 92.606534   Top5 99.900568   BatchTime 0.107301   LR 0.010000   
2022-11-03 20:40:18,617 - INFO  - Training [2][  240/  391]   Loss 0.208945   Top1 92.669271   Top5 99.908854   BatchTime 0.106558   LR 0.010000   
2022-11-03 20:40:20,594 - INFO  - Training [2][  260/  391]   Loss 0.209080   Top1 92.668269   Top5 99.903846   BatchTime 0.105965   LR 0.010000   
2022-11-03 20:40:22,570 - INFO  - Training [2][  280/  391]   Loss 0.207481   Top1 92.745536   Top5 99.905134   BatchTime 0.105453   LR 0.010000   
2022-11-03 20:40:24,534 - INFO  - Training [2][  300/  391]   Loss 0.207153   Top1 92.781250   Top5 99.898438   BatchTime 0.104968   LR 0.010000   
2022-11-03 20:40:26,496 - INFO  - Training [2][  320/  391]   Loss 0.205696   Top1 92.861328   Top5 99.897461   BatchTime 0.104537   LR 0.010000   
2022-11-03 20:40:28,442 - INFO  - Training [2][  340/  391]   Loss 0.204844   Top1 92.874540   Top5 99.894301   BatchTime 0.104114   LR 0.010000   
2022-11-03 20:40:30,358 - INFO  - Training [2][  360/  391]   Loss 0.204291   Top1 92.877604   Top5 99.895833   BatchTime 0.103652   LR 0.010000   
2022-11-03 20:40:32,294 - INFO  - Training [2][  380/  391]   Loss 0.202977   Top1 92.921464   Top5 99.893092   BatchTime 0.103290   LR 0.010000   
2022-11-03 20:40:33,799 - INFO  - ==> Top1: 92.936    Top5: 99.896    Loss: 0.202

2022-11-03 20:40:33,800 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:40:36,419 - INFO  - Validation [2][   20/   79]   Loss 0.403929   Top1 87.890625   Top5 99.570312   BatchTime 0.130877   
2022-11-03 20:40:37,098 - INFO  - Validation [2][   40/   79]   Loss 0.406900   Top1 87.812500   Top5 99.414062   BatchTime 0.082394   
2022-11-03 20:40:37,774 - INFO  - Validation [2][   60/   79]   Loss 0.407893   Top1 87.773438   Top5 99.414062   BatchTime 0.066199   
2022-11-03 20:40:38,622 - INFO  - ==> Top1: 87.930    Top5: 99.470    Loss: 0.405

2022-11-03 20:40:38,649 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.930   Top5: 99.470] Sparsity : 0.573
2022-11-03 20:40:38,649 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.880   Top5: 99.480] Sparsity : 0.550
2022-11-03 20:40:38,649 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 84.870   Top5: 99.290] Sparsity : 0.292
2022-11-03 20:40:38,806 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:40:38,806 - INFO  - >>>>>>>> Epoch   3
2022-11-03 20:40:38,808 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:40:42,770 - INFO  - Training [3][   20/  391]   Loss 0.164901   Top1 94.023438   Top5 99.960938   BatchTime 0.198090   LR 0.010000   
2022-11-03 20:40:44,755 - INFO  - Training [3][   40/  391]   Loss 0.155328   Top1 94.414062   Top5 99.980469   BatchTime 0.148679   LR 0.010000   
2022-11-03 20:40:46,748 - INFO  - Training [3][   60/  391]   Loss 0.161082   Top1 94.140625   Top5 99.986979   BatchTime 0.132326   LR 0.010000   
2022-11-03 20:40:48,744 - INFO  - Training [3][   80/  391]   Loss 0.160035   Top1 94.160156   Top5 99.951172   BatchTime 0.124194   LR 0.010000   
2022-11-03 20:40:50,726 - INFO  - Training [3][  100/  391]   Loss 0.162194   Top1 94.046875   Top5 99.945312   BatchTime 0.119181   LR 0.010000   
2022-11-03 20:40:52,730 - INFO  - Training [3][  120/  391]   Loss 0.161902   Top1 94.153646   Top5 99.954427   BatchTime 0.116013   LR 0.010000   
2022-11-03 20:40:54,719 - INFO  - Training [3][  140/  391]   Loss 0.161602   Top1 94.168527   Top5 99.955357   BatchTime 0.113645   LR 0.010000   
2022-11-03 20:40:56,711 - INFO  - Training [3][  160/  391]   Loss 0.163865   Top1 94.121094   Top5 99.951172   BatchTime 0.111893   LR 0.010000   
2022-11-03 20:40:58,717 - INFO  - Training [3][  180/  391]   Loss 0.165406   Top1 94.023438   Top5 99.952257   BatchTime 0.110604   LR 0.010000   
2022-11-03 20:41:00,682 - INFO  - Training [3][  200/  391]   Loss 0.163955   Top1 94.117188   Top5 99.953125   BatchTime 0.109367   LR 0.010000   
2022-11-03 20:41:02,644 - INFO  - Training [3][  220/  391]   Loss 0.165238   Top1 94.066051   Top5 99.957386   BatchTime 0.108344   LR 0.010000   
2022-11-03 20:41:04,640 - INFO  - Training [3][  240/  391]   Loss 0.164554   Top1 94.098307   Top5 99.960938   BatchTime 0.107631   LR 0.010000   
2022-11-03 20:41:06,624 - INFO  - Training [3][  260/  391]   Loss 0.164997   Top1 94.068510   Top5 99.960938   BatchTime 0.106984   LR 0.010000   
2022-11-03 20:41:08,626 - INFO  - Training [3][  280/  391]   Loss 0.164509   Top1 94.090402   Top5 99.963728   BatchTime 0.106491   LR 0.010000   
2022-11-03 20:41:10,614 - INFO  - Training [3][  300/  391]   Loss 0.164353   Top1 94.111979   Top5 99.963542   BatchTime 0.106018   LR 0.010000   
2022-11-03 20:41:12,573 - INFO  - Training [3][  320/  391]   Loss 0.164303   Top1 94.130859   Top5 99.960938   BatchTime 0.105514   LR 0.010000   
2022-11-03 20:41:14,522 - INFO  - Training [3][  340/  391]   Loss 0.163976   Top1 94.156710   Top5 99.960938   BatchTime 0.105039   LR 0.010000   
2022-11-03 20:41:16,444 - INFO  - Training [3][  360/  391]   Loss 0.164176   Top1 94.140625   Top5 99.960938   BatchTime 0.104543   LR 0.010000   
2022-11-03 20:41:18,384 - INFO  - Training [3][  380/  391]   Loss 0.163377   Top1 94.194079   Top5 99.962993   BatchTime 0.104144   LR 0.010000   
2022-11-03 20:41:19,698 - INFO  - ==> Top1: 94.190    Top5: 99.964    Loss: 0.163

2022-11-03 20:41:19,698 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:41:22,314 - INFO  - Validation [3][   20/   79]   Loss 0.399869   Top1 88.085938   Top5 99.453125   BatchTime 0.130683   
2022-11-03 20:41:22,994 - INFO  - Validation [3][   40/   79]   Loss 0.402916   Top1 88.320312   Top5 99.453125   BatchTime 0.082361   
2022-11-03 20:41:23,690 - INFO  - Validation [3][   60/   79]   Loss 0.394839   Top1 88.528646   Top5 99.518229   BatchTime 0.066493   
2022-11-03 20:41:24,501 - INFO  - ==> Top1: 88.520    Top5: 99.610    Loss: 0.390

2022-11-03 20:41:24,525 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 88.520   Top5: 99.610] Sparsity : 0.581
2022-11-03 20:41:24,526 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.930   Top5: 99.470] Sparsity : 0.573
2022-11-03 20:41:24,527 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.880   Top5: 99.480] Sparsity : 0.550
2022-11-03 20:41:24,796 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:41:24,796 - INFO  - >>>>>>>> Epoch   4
2022-11-03 20:41:24,798 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:41:28,807 - INFO  - Training [4][   20/  391]   Loss 0.137656   Top1 95.156250   Top5 100.000000   BatchTime 0.200479   LR 0.010000   
2022-11-03 20:41:30,802 - INFO  - Training [4][   40/  391]   Loss 0.140780   Top1 95.097656   Top5 99.960938   BatchTime 0.150102   LR 0.010000   
2022-11-03 20:41:32,823 - INFO  - Training [4][   60/  391]   Loss 0.136184   Top1 95.273438   Top5 99.973958   BatchTime 0.133757   LR 0.010000   
2022-11-03 20:41:34,815 - INFO  - Training [4][   80/  391]   Loss 0.134634   Top1 95.341797   Top5 99.970703   BatchTime 0.125218   LR 0.010000   
2022-11-03 20:41:36,803 - INFO  - Training [4][  100/  391]   Loss 0.137260   Top1 95.312500   Top5 99.968750   BatchTime 0.120052   LR 0.010000   
2022-11-03 20:41:38,789 - INFO  - Training [4][  120/  391]   Loss 0.135286   Top1 95.397135   Top5 99.973958   BatchTime 0.116592   LR 0.010000   
2022-11-03 20:41:40,783 - INFO  - Training [4][  140/  391]   Loss 0.136926   Top1 95.306920   Top5 99.977679   BatchTime 0.114178   LR 0.010000   
2022-11-03 20:41:42,764 - INFO  - Training [4][  160/  391]   Loss 0.136549   Top1 95.400391   Top5 99.980469   BatchTime 0.112289   LR 0.010000   
2022-11-03 20:41:44,757 - INFO  - Training [4][  180/  391]   Loss 0.137171   Top1 95.342882   Top5 99.982639   BatchTime 0.110883   LR 0.010000   
2022-11-03 20:41:46,741 - INFO  - Training [4][  200/  391]   Loss 0.138063   Top1 95.332031   Top5 99.984375   BatchTime 0.109715   LR 0.010000   
2022-11-03 20:41:48,709 - INFO  - Training [4][  220/  391]   Loss 0.137335   Top1 95.319602   Top5 99.978693   BatchTime 0.108683   LR 0.010000   
2022-11-03 20:41:50,687 - INFO  - Training [4][  240/  391]   Loss 0.136472   Top1 95.341797   Top5 99.977214   BatchTime 0.107869   LR 0.010000   
2022-11-03 20:41:52,669 - INFO  - Training [4][  260/  391]   Loss 0.136540   Top1 95.351562   Top5 99.978966   BatchTime 0.107196   LR 0.010000   
2022-11-03 20:41:54,635 - INFO  - Training [4][  280/  391]   Loss 0.137315   Top1 95.281808   Top5 99.977679   BatchTime 0.106561   LR 0.010000   
2022-11-03 20:41:56,612 - INFO  - Training [4][  300/  391]   Loss 0.136258   Top1 95.333333   Top5 99.976562   BatchTime 0.106047   LR 0.010000   
2022-11-03 20:41:58,608 - INFO  - Training [4][  320/  391]   Loss 0.135544   Top1 95.346680   Top5 99.975586   BatchTime 0.105656   LR 0.010000   
2022-11-03 20:42:00,546 - INFO  - Training [4][  340/  391]   Loss 0.135317   Top1 95.351562   Top5 99.977022   BatchTime 0.105140   LR 0.010000   
2022-11-03 20:42:02,474 - INFO  - Training [4][  360/  391]   Loss 0.135539   Top1 95.325521   Top5 99.976128   BatchTime 0.104653   LR 0.010000   
2022-11-03 20:42:04,400 - INFO  - Training [4][  380/  391]   Loss 0.135048   Top1 95.333059   Top5 99.975329   BatchTime 0.104214   LR 0.010000   
2022-11-03 20:42:05,611 - INFO  - ==> Top1: 95.320    Top5: 99.976    Loss: 0.135

2022-11-03 20:42:05,612 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:42:08,236 - INFO  - Validation [4][   20/   79]   Loss 0.404774   Top1 88.242188   Top5 99.453125   BatchTime 0.131135   
2022-11-03 20:42:08,927 - INFO  - Validation [4][   40/   79]   Loss 0.420828   Top1 88.457031   Top5 99.375000   BatchTime 0.082830   
2022-11-03 20:42:09,611 - INFO  - Validation [4][   60/   79]   Loss 0.402808   Top1 88.593750   Top5 99.492188   BatchTime 0.066619   
2022-11-03 20:42:10,372 - INFO  - ==> Top1: 88.610    Top5: 99.550    Loss: 0.398

2022-11-03 20:42:10,400 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.610   Top5: 99.550] Sparsity : 0.586
2022-11-03 20:42:10,401 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 88.520   Top5: 99.610] Sparsity : 0.581
2022-11-03 20:42:10,401 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.930   Top5: 99.470] Sparsity : 0.573
2022-11-03 20:42:10,583 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:42:10,584 - INFO  - >>>>>>>> Epoch   5
2022-11-03 20:42:10,585 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:42:14,634 - INFO  - Training [5][   20/  391]   Loss 0.139052   Top1 95.390625   Top5 99.921875   BatchTime 0.202432   LR 0.010000   
2022-11-03 20:42:16,619 - INFO  - Training [5][   40/  391]   Loss 0.125676   Top1 95.800781   Top5 99.960938   BatchTime 0.150860   LR 0.010000   
2022-11-03 20:42:18,603 - INFO  - Training [5][   60/  391]   Loss 0.124715   Top1 95.729167   Top5 99.973958   BatchTime 0.133639   LR 0.010000   
2022-11-03 20:42:20,573 - INFO  - Training [5][   80/  391]   Loss 0.122142   Top1 95.703125   Top5 99.970703   BatchTime 0.124851   LR 0.010000   
2022-11-03 20:42:22,556 - INFO  - Training [5][  100/  391]   Loss 0.121870   Top1 95.726562   Top5 99.968750   BatchTime 0.119709   LR 0.010000   
2022-11-03 20:42:24,524 - INFO  - Training [5][  120/  391]   Loss 0.120992   Top1 95.735677   Top5 99.973958   BatchTime 0.116162   LR 0.010000   
2022-11-03 20:42:26,501 - INFO  - Training [5][  140/  391]   Loss 0.119347   Top1 95.803571   Top5 99.977679   BatchTime 0.113685   LR 0.010000   
2022-11-03 20:42:28,492 - INFO  - Training [5][  160/  391]   Loss 0.119745   Top1 95.766602   Top5 99.980469   BatchTime 0.111918   LR 0.010000   
2022-11-03 20:42:30,494 - INFO  - Training [5][  180/  391]   Loss 0.119493   Top1 95.763889   Top5 99.982639   BatchTime 0.110607   LR 0.010000   
2022-11-03 20:42:32,478 - INFO  - Training [5][  200/  391]   Loss 0.118544   Top1 95.816406   Top5 99.972656   BatchTime 0.109466   LR 0.010000   
2022-11-03 20:42:34,465 - INFO  - Training [5][  220/  391]   Loss 0.119168   Top1 95.802557   Top5 99.971591   BatchTime 0.108546   LR 0.010000   
2022-11-03 20:42:36,439 - INFO  - Training [5][  240/  391]   Loss 0.117529   Top1 95.872396   Top5 99.973958   BatchTime 0.107724   LR 0.010000   
2022-11-03 20:42:38,433 - INFO  - Training [5][  260/  391]   Loss 0.115550   Top1 95.928486   Top5 99.975962   BatchTime 0.107105   LR 0.010000   
2022-11-03 20:42:40,409 - INFO  - Training [5][  280/  391]   Loss 0.115196   Top1 95.931920   Top5 99.977679   BatchTime 0.106513   LR 0.010000   
2022-11-03 20:42:42,416 - INFO  - Training [5][  300/  391]   Loss 0.114689   Top1 95.929688   Top5 99.979167   BatchTime 0.106103   LR 0.010000   
2022-11-03 20:42:44,392 - INFO  - Training [5][  320/  391]   Loss 0.114800   Top1 95.942383   Top5 99.978027   BatchTime 0.105644   LR 0.010000   
2022-11-03 20:42:46,340 - INFO  - Training [5][  340/  391]   Loss 0.115650   Top1 95.905331   Top5 99.977022   BatchTime 0.105159   LR 0.010000   
2022-11-03 20:42:48,275 - INFO  - Training [5][  360/  391]   Loss 0.114997   Top1 95.946181   Top5 99.978299   BatchTime 0.104694   LR 0.010000   
2022-11-03 20:42:50,292 - INFO  - Training [5][  380/  391]   Loss 0.115861   Top1 95.916941   Top5 99.979441   BatchTime 0.104491   LR 0.010000   
2022-11-03 20:42:51,365 - INFO  - ==> Top1: 95.920    Top5: 99.980    Loss: 0.116

2022-11-03 20:42:51,366 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:42:53,974 - INFO  - Validation [5][   20/   79]   Loss 0.384320   Top1 88.671875   Top5 99.531250   BatchTime 0.130284   
2022-11-03 20:42:54,665 - INFO  - Validation [5][   40/   79]   Loss 0.393364   Top1 88.574219   Top5 99.453125   BatchTime 0.082426   
2022-11-03 20:42:55,259 - INFO  - Validation [5][   60/   79]   Loss 0.379531   Top1 88.919271   Top5 99.492188   BatchTime 0.064847   
2022-11-03 20:42:56,023 - INFO  - ==> Top1: 88.940    Top5: 99.530    Loss: 0.376

2022-11-03 20:42:56,049 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 88.940   Top5: 99.530] Sparsity : 0.591
2022-11-03 20:42:56,050 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.610   Top5: 99.550] Sparsity : 0.586
2022-11-03 20:42:56,050 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 88.520   Top5: 99.610] Sparsity : 0.581
2022-11-03 20:42:56,241 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:42:56,241 - INFO  - >>>>>>>> Epoch   6
2022-11-03 20:42:56,243 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:43:00,220 - INFO  - Training [6][   20/  391]   Loss 0.110725   Top1 95.898438   Top5 100.000000   BatchTime 0.198847   LR 0.010000   
2022-11-03 20:43:02,210 - INFO  - Training [6][   40/  391]   Loss 0.105334   Top1 96.191406   Top5 99.980469   BatchTime 0.149186   LR 0.010000   
2022-11-03 20:43:04,212 - INFO  - Training [6][   60/  391]   Loss 0.103093   Top1 96.119792   Top5 99.973958   BatchTime 0.132827   LR 0.010000   
2022-11-03 20:43:06,179 - INFO  - Training [6][   80/  391]   Loss 0.102947   Top1 96.093750   Top5 99.980469   BatchTime 0.124205   LR 0.010000   
2022-11-03 20:43:08,167 - INFO  - Training [6][  100/  391]   Loss 0.102429   Top1 96.070312   Top5 99.984375   BatchTime 0.119243   LR 0.010000   
2022-11-03 20:43:10,166 - INFO  - Training [6][  120/  391]   Loss 0.102028   Top1 96.165365   Top5 99.986979   BatchTime 0.116022   LR 0.010000   
2022-11-03 20:43:12,156 - INFO  - Training [6][  140/  391]   Loss 0.102863   Top1 96.166295   Top5 99.988839   BatchTime 0.113664   LR 0.010000   
2022-11-03 20:43:14,166 - INFO  - Training [6][  160/  391]   Loss 0.101475   Top1 96.225586   Top5 99.990234   BatchTime 0.112021   LR 0.010000   
2022-11-03 20:43:16,140 - INFO  - Training [6][  180/  391]   Loss 0.101102   Top1 96.267361   Top5 99.986979   BatchTime 0.110538   LR 0.010000   
2022-11-03 20:43:18,144 - INFO  - Training [6][  200/  391]   Loss 0.101343   Top1 96.304688   Top5 99.988281   BatchTime 0.109505   LR 0.010000   
2022-11-03 20:43:20,125 - INFO  - Training [6][  220/  391]   Loss 0.099850   Top1 96.345881   Top5 99.989347   BatchTime 0.108552   LR 0.010000   
2022-11-03 20:43:22,117 - INFO  - Training [6][  240/  391]   Loss 0.098942   Top1 96.357422   Top5 99.990234   BatchTime 0.107809   LR 0.010000   
2022-11-03 20:43:24,107 - INFO  - Training [6][  260/  391]   Loss 0.098016   Top1 96.382212   Top5 99.990986   BatchTime 0.107167   LR 0.010000   
2022-11-03 20:43:26,111 - INFO  - Training [6][  280/  391]   Loss 0.097634   Top1 96.420201   Top5 99.991629   BatchTime 0.106669   LR 0.010000   
2022-11-03 20:43:28,090 - INFO  - Training [6][  300/  391]   Loss 0.097737   Top1 96.432292   Top5 99.992188   BatchTime 0.106154   LR 0.010000   
2022-11-03 20:43:30,060 - INFO  - Training [6][  320/  391]   Loss 0.097856   Top1 96.430664   Top5 99.990234   BatchTime 0.105677   LR 0.010000   
2022-11-03 20:43:31,995 - INFO  - Training [6][  340/  391]   Loss 0.098776   Top1 96.399357   Top5 99.990809   BatchTime 0.105152   LR 0.010000   
2022-11-03 20:43:33,929 - INFO  - Training [6][  360/  391]   Loss 0.098516   Top1 96.410590   Top5 99.991319   BatchTime 0.104682   LR 0.010000   
2022-11-03 20:43:35,869 - INFO  - Training [6][  380/  391]   Loss 0.098254   Top1 96.424753   Top5 99.991776   BatchTime 0.104277   LR 0.010000   
2022-11-03 20:43:36,893 - INFO  - ==> Top1: 96.444    Top5: 99.992    Loss: 0.098

2022-11-03 20:43:36,894 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:43:39,521 - INFO  - Validation [6][   20/   79]   Loss 0.391668   Top1 89.296875   Top5 99.570312   BatchTime 0.131260   
2022-11-03 20:43:40,230 - INFO  - Validation [6][   40/   79]   Loss 0.408603   Top1 89.140625   Top5 99.433594   BatchTime 0.083348   
2022-11-03 20:43:40,753 - INFO  - Validation [6][   60/   79]   Loss 0.395269   Top1 89.531250   Top5 99.505208   BatchTime 0.064292   
2022-11-03 20:43:41,505 - INFO  - ==> Top1: 89.530    Top5: 99.540    Loss: 0.391

2022-11-03 20:43:41,535 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.530   Top5: 99.540] Sparsity : 0.598
2022-11-03 20:43:41,536 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.940   Top5: 99.530] Sparsity : 0.591
2022-11-03 20:43:41,536 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.610   Top5: 99.550] Sparsity : 0.586
2022-11-03 20:43:41,719 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:43:41,720 - INFO  - >>>>>>>> Epoch   7
2022-11-03 20:43:41,721 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:43:45,733 - INFO  - Training [7][   20/  391]   Loss 0.081355   Top1 97.031250   Top5 100.000000   BatchTime 0.200608   LR 0.010000   
2022-11-03 20:43:47,863 - INFO  - Training [7][   40/  391]   Loss 0.083314   Top1 96.972656   Top5 100.000000   BatchTime 0.153551   LR 0.010000   
2022-11-03 20:43:49,883 - INFO  - Training [7][   60/  391]   Loss 0.088225   Top1 96.796875   Top5 99.986979   BatchTime 0.136022   LR 0.010000   
2022-11-03 20:43:51,895 - INFO  - Training [7][   80/  391]   Loss 0.086890   Top1 96.865234   Top5 99.990234   BatchTime 0.127173   LR 0.010000   
2022-11-03 20:43:53,906 - INFO  - Training [7][  100/  391]   Loss 0.087042   Top1 96.859375   Top5 99.992188   BatchTime 0.121850   LR 0.010000   
2022-11-03 20:43:55,894 - INFO  - Training [7][  120/  391]   Loss 0.086186   Top1 96.868490   Top5 99.986979   BatchTime 0.118104   LR 0.010000   
2022-11-03 20:43:57,874 - INFO  - Training [7][  140/  391]   Loss 0.086917   Top1 96.824777   Top5 99.988839   BatchTime 0.115376   LR 0.010000   
2022-11-03 20:43:59,876 - INFO  - Training [7][  160/  391]   Loss 0.085686   Top1 96.865234   Top5 99.990234   BatchTime 0.113467   LR 0.010000   
2022-11-03 20:44:01,846 - INFO  - Training [7][  180/  391]   Loss 0.085622   Top1 96.857639   Top5 99.991319   BatchTime 0.111803   LR 0.010000   
2022-11-03 20:44:03,810 - INFO  - Training [7][  200/  391]   Loss 0.086591   Top1 96.808594   Top5 99.988281   BatchTime 0.110442   LR 0.010000   
2022-11-03 20:44:05,799 - INFO  - Training [7][  220/  391]   Loss 0.086381   Top1 96.825284   Top5 99.989347   BatchTime 0.109442   LR 0.010000   
2022-11-03 20:44:07,783 - INFO  - Training [7][  240/  391]   Loss 0.086737   Top1 96.826172   Top5 99.990234   BatchTime 0.108590   LR 0.010000   
2022-11-03 20:44:09,764 - INFO  - Training [7][  260/  391]   Loss 0.087771   Top1 96.811899   Top5 99.987981   BatchTime 0.107855   LR 0.010000   
2022-11-03 20:44:11,777 - INFO  - Training [7][  280/  391]   Loss 0.088078   Top1 96.799665   Top5 99.988839   BatchTime 0.107339   LR 0.010000   
2022-11-03 20:44:13,744 - INFO  - Training [7][  300/  391]   Loss 0.088817   Top1 96.791667   Top5 99.989583   BatchTime 0.106741   LR 0.010000   
2022-11-03 20:44:15,693 - INFO  - Training [7][  320/  391]   Loss 0.089820   Top1 96.748047   Top5 99.990234   BatchTime 0.106160   LR 0.010000   
2022-11-03 20:44:17,635 - INFO  - Training [7][  340/  391]   Loss 0.090142   Top1 96.744026   Top5 99.990809   BatchTime 0.105628   LR 0.010000   
2022-11-03 20:44:19,569 - INFO  - Training [7][  360/  391]   Loss 0.089745   Top1 96.753472   Top5 99.991319   BatchTime 0.105131   LR 0.010000   
2022-11-03 20:44:21,404 - INFO  - Training [7][  380/  391]   Loss 0.089857   Top1 96.753701   Top5 99.991776   BatchTime 0.104425   LR 0.010000   
2022-11-03 20:44:22,432 - INFO  - ==> Top1: 96.752    Top5: 99.992    Loss: 0.090

2022-11-03 20:44:22,433 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:44:25,018 - INFO  - Validation [7][   20/   79]   Loss 0.411906   Top1 89.257812   Top5 99.648438   BatchTime 0.129184   
2022-11-03 20:44:25,632 - INFO  - Validation [7][   40/   79]   Loss 0.421921   Top1 89.257812   Top5 99.550781   BatchTime 0.079948   
2022-11-03 20:44:26,161 - INFO  - Validation [7][   60/   79]   Loss 0.405108   Top1 89.348958   Top5 99.596354   BatchTime 0.062102   
2022-11-03 20:44:26,915 - INFO  - ==> Top1: 89.270    Top5: 99.630    Loss: 0.397

2022-11-03 20:44:26,941 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.530   Top5: 99.540] Sparsity : 0.598
2022-11-03 20:44:26,942 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.270   Top5: 99.630] Sparsity : 0.616
2022-11-03 20:44:26,942 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.940   Top5: 99.530] Sparsity : 0.591
2022-11-03 20:44:27,039 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:44:27,039 - INFO  - >>>>>>>> Epoch   8
2022-11-03 20:44:27,041 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:44:31,000 - INFO  - Training [8][   20/  391]   Loss 0.075256   Top1 97.460938   Top5 100.000000   BatchTime 0.197958   LR 0.010000   
2022-11-03 20:44:32,991 - INFO  - Training [8][   40/  391]   Loss 0.081142   Top1 97.187500   Top5 99.980469   BatchTime 0.148748   LR 0.010000   
2022-11-03 20:44:34,977 - INFO  - Training [8][   60/  391]   Loss 0.085855   Top1 97.135417   Top5 99.986979   BatchTime 0.132266   LR 0.010000   
2022-11-03 20:44:36,972 - INFO  - Training [8][   80/  391]   Loss 0.085575   Top1 97.050781   Top5 99.990234   BatchTime 0.124143   LR 0.010000   
2022-11-03 20:44:38,971 - INFO  - Training [8][  100/  391]   Loss 0.084150   Top1 97.085938   Top5 99.992188   BatchTime 0.119301   LR 0.010000   
2022-11-03 20:44:40,985 - INFO  - Training [8][  120/  391]   Loss 0.084010   Top1 97.102865   Top5 99.993490   BatchTime 0.116198   LR 0.010000   
2022-11-03 20:44:42,979 - INFO  - Training [8][  140/  391]   Loss 0.083391   Top1 97.137277   Top5 99.994420   BatchTime 0.113841   LR 0.010000   
2022-11-03 20:44:44,979 - INFO  - Training [8][  160/  391]   Loss 0.083334   Top1 97.099609   Top5 99.995117   BatchTime 0.112113   LR 0.010000   
2022-11-03 20:44:46,981 - INFO  - Training [8][  180/  391]   Loss 0.083249   Top1 97.057292   Top5 99.995660   BatchTime 0.110776   LR 0.010000   
2022-11-03 20:44:48,992 - INFO  - Training [8][  200/  391]   Loss 0.082984   Top1 97.054688   Top5 99.996094   BatchTime 0.109757   LR 0.010000   
2022-11-03 20:44:50,980 - INFO  - Training [8][  220/  391]   Loss 0.083410   Top1 97.038352   Top5 99.996449   BatchTime 0.108815   LR 0.010000   
2022-11-03 20:44:52,981 - INFO  - Training [8][  240/  391]   Loss 0.083398   Top1 97.047526   Top5 99.996745   BatchTime 0.108084   LR 0.010000   
2022-11-03 20:44:54,967 - INFO  - Training [8][  260/  391]   Loss 0.083834   Top1 97.028245   Top5 99.996995   BatchTime 0.107408   LR 0.010000   
2022-11-03 20:44:56,956 - INFO  - Training [8][  280/  391]   Loss 0.084180   Top1 97.022879   Top5 99.997210   BatchTime 0.106840   LR 0.010000   
2022-11-03 20:44:58,937 - INFO  - Training [8][  300/  391]   Loss 0.084159   Top1 97.026042   Top5 99.994792   BatchTime 0.106321   LR 0.010000   
2022-11-03 20:45:00,917 - INFO  - Training [8][  320/  391]   Loss 0.084439   Top1 96.997070   Top5 99.995117   BatchTime 0.105862   LR 0.010000   
2022-11-03 20:45:02,865 - INFO  - Training [8][  340/  391]   Loss 0.084332   Top1 97.019761   Top5 99.995404   BatchTime 0.105365   LR 0.010000   
2022-11-03 20:45:04,796 - INFO  - Training [8][  360/  391]   Loss 0.085208   Top1 96.992188   Top5 99.995660   BatchTime 0.104873   LR 0.010000   
2022-11-03 20:45:06,670 - INFO  - Training [8][  380/  391]   Loss 0.085323   Top1 96.983964   Top5 99.995888   BatchTime 0.104285   LR 0.010000   
2022-11-03 20:45:07,705 - INFO  - ==> Top1: 96.976    Top5: 99.996    Loss: 0.085

2022-11-03 20:45:07,706 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:45:10,301 - INFO  - Validation [8][   20/   79]   Loss 0.388328   Top1 89.414062   Top5 99.492188   BatchTime 0.129709   
2022-11-03 20:45:11,006 - INFO  - Validation [8][   40/   79]   Loss 0.403386   Top1 89.296875   Top5 99.453125   BatchTime 0.082494   
2022-11-03 20:45:11,527 - INFO  - Validation [8][   60/   79]   Loss 0.386894   Top1 89.583333   Top5 99.505208   BatchTime 0.063667   
2022-11-03 20:45:12,288 - INFO  - ==> Top1: 89.560    Top5: 99.560    Loss: 0.385

2022-11-03 20:45:12,315 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.560   Top5: 99.560] Sparsity : 0.624
2022-11-03 20:45:12,316 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 89.530   Top5: 99.540] Sparsity : 0.598
2022-11-03 20:45:12,316 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.270   Top5: 99.630] Sparsity : 0.616
2022-11-03 20:45:12,509 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:45:12,509 - INFO  - >>>>>>>> Epoch   9
2022-11-03 20:45:12,510 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:45:16,482 - INFO  - Training [9][   20/  391]   Loss 0.077992   Top1 97.460938   Top5 100.000000   BatchTime 0.198567   LR 0.010000   
2022-11-03 20:45:18,474 - INFO  - Training [9][   40/  391]   Loss 0.076970   Top1 97.324219   Top5 100.000000   BatchTime 0.149081   LR 0.010000   
2022-11-03 20:45:20,474 - INFO  - Training [9][   60/  391]   Loss 0.074478   Top1 97.473958   Top5 100.000000   BatchTime 0.132722   LR 0.010000   
2022-11-03 20:45:22,457 - INFO  - Training [9][   80/  391]   Loss 0.076715   Top1 97.363281   Top5 100.000000   BatchTime 0.124332   LR 0.010000   
2022-11-03 20:45:24,464 - INFO  - Training [9][  100/  391]   Loss 0.076234   Top1 97.312500   Top5 99.992188   BatchTime 0.119531   LR 0.010000   
2022-11-03 20:45:26,542 - INFO  - Training [9][  120/  391]   Loss 0.076845   Top1 97.239583   Top5 99.993490   BatchTime 0.116926   LR 0.010000   
2022-11-03 20:45:28,544 - INFO  - Training [9][  140/  391]   Loss 0.076465   Top1 97.265625   Top5 99.988839   BatchTime 0.114524   LR 0.010000   
2022-11-03 20:45:30,543 - INFO  - Training [9][  160/  391]   Loss 0.075338   Top1 97.358398   Top5 99.990234   BatchTime 0.112702   LR 0.010000   
2022-11-03 20:45:32,516 - INFO  - Training [9][  180/  391]   Loss 0.076587   Top1 97.330729   Top5 99.991319   BatchTime 0.111142   LR 0.010000   
2022-11-03 20:45:34,521 - INFO  - Training [9][  200/  391]   Loss 0.075719   Top1 97.367188   Top5 99.992188   BatchTime 0.110051   LR 0.010000   
2022-11-03 20:45:36,526 - INFO  - Training [9][  220/  391]   Loss 0.074371   Top1 97.411222   Top5 99.992898   BatchTime 0.109161   LR 0.010000   
2022-11-03 20:45:38,517 - INFO  - Training [9][  240/  391]   Loss 0.074336   Top1 97.408854   Top5 99.993490   BatchTime 0.108357   LR 0.010000   
2022-11-03 20:45:40,509 - INFO  - Training [9][  260/  391]   Loss 0.074274   Top1 97.418870   Top5 99.993990   BatchTime 0.107684   LR 0.010000   
2022-11-03 20:45:42,512 - INFO  - Training [9][  280/  391]   Loss 0.074768   Top1 97.416295   Top5 99.994420   BatchTime 0.107146   LR 0.010000   
2022-11-03 20:45:44,513 - INFO  - Training [9][  300/  391]   Loss 0.074923   Top1 97.421875   Top5 99.994792   BatchTime 0.106674   LR 0.010000   
2022-11-03 20:45:46,500 - INFO  - Training [9][  320/  391]   Loss 0.075742   Top1 97.380371   Top5 99.995117   BatchTime 0.106216   LR 0.010000   
2022-11-03 20:45:48,442 - INFO  - Training [9][  340/  391]   Loss 0.076527   Top1 97.348346   Top5 99.995404   BatchTime 0.105679   LR 0.010000   
2022-11-03 20:45:50,389 - INFO  - Training [9][  360/  391]   Loss 0.076699   Top1 97.354601   Top5 99.995660   BatchTime 0.105215   LR 0.010000   
2022-11-03 20:45:52,277 - INFO  - Training [9][  380/  391]   Loss 0.076886   Top1 97.347862   Top5 99.995888   BatchTime 0.104647   LR 0.010000   
2022-11-03 20:45:53,351 - INFO  - ==> Top1: 97.336    Top5: 99.994    Loss: 0.077

2022-11-03 20:45:53,352 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:45:55,957 - INFO  - Validation [9][   20/   79]   Loss 0.407401   Top1 89.609375   Top5 99.492188   BatchTime 0.130138   
2022-11-03 20:45:56,545 - INFO  - Validation [9][   40/   79]   Loss 0.418494   Top1 89.589844   Top5 99.355469   BatchTime 0.079785   
2022-11-03 20:45:57,066 - INFO  - Validation [9][   60/   79]   Loss 0.404243   Top1 89.674479   Top5 99.492188   BatchTime 0.061860   
2022-11-03 20:45:57,818 - INFO  - ==> Top1: 89.680    Top5: 99.550    Loss: 0.401

2022-11-03 20:45:57,844 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:45:57,845 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.560   Top5: 99.560] Sparsity : 0.624
2022-11-03 20:45:57,845 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 89.530   Top5: 99.540] Sparsity : 0.598
2022-11-03 20:45:58,023 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:45:58,024 - INFO  - >>>>>>>> Epoch  10
2022-11-03 20:45:58,024 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:46:01,964 - INFO  - Training [10][   20/  391]   Loss 0.068231   Top1 97.421875   Top5 100.000000   BatchTime 0.196949   LR 0.010000   
2022-11-03 20:46:03,971 - INFO  - Training [10][   40/  391]   Loss 0.068279   Top1 97.421875   Top5 100.000000   BatchTime 0.148671   LR 0.010000   
2022-11-03 20:46:05,977 - INFO  - Training [10][   60/  391]   Loss 0.070662   Top1 97.486979   Top5 100.000000   BatchTime 0.132539   LR 0.010000   
2022-11-03 20:46:07,945 - INFO  - Training [10][   80/  391]   Loss 0.068718   Top1 97.539062   Top5 100.000000   BatchTime 0.124008   LR 0.010000   
2022-11-03 20:46:09,947 - INFO  - Training [10][  100/  391]   Loss 0.068733   Top1 97.562500   Top5 99.992188   BatchTime 0.119227   LR 0.010000   
2022-11-03 20:46:11,932 - INFO  - Training [10][  120/  391]   Loss 0.069367   Top1 97.591146   Top5 99.993490   BatchTime 0.115897   LR 0.010000   
2022-11-03 20:46:13,938 - INFO  - Training [10][  140/  391]   Loss 0.070591   Top1 97.511161   Top5 99.994420   BatchTime 0.113670   LR 0.010000   
2022-11-03 20:46:15,944 - INFO  - Training [10][  160/  391]   Loss 0.071870   Top1 97.426758   Top5 99.995117   BatchTime 0.111995   LR 0.010000   
2022-11-03 20:46:17,954 - INFO  - Training [10][  180/  391]   Loss 0.070849   Top1 97.508681   Top5 99.991319   BatchTime 0.110715   LR 0.010000   
2022-11-03 20:46:19,940 - INFO  - Training [10][  200/  391]   Loss 0.070923   Top1 97.503906   Top5 99.992188   BatchTime 0.109576   LR 0.010000   
2022-11-03 20:46:21,941 - INFO  - Training [10][  220/  391]   Loss 0.073352   Top1 97.425426   Top5 99.992898   BatchTime 0.108707   LR 0.010000   
2022-11-03 20:46:23,945 - INFO  - Training [10][  240/  391]   Loss 0.073502   Top1 97.434896   Top5 99.993490   BatchTime 0.107999   LR 0.010000   
2022-11-03 20:46:25,918 - INFO  - Training [10][  260/  391]   Loss 0.074708   Top1 97.388822   Top5 99.990986   BatchTime 0.107280   LR 0.010000   
2022-11-03 20:46:27,933 - INFO  - Training [10][  280/  391]   Loss 0.076345   Top1 97.321429   Top5 99.991629   BatchTime 0.106816   LR 0.010000   
2022-11-03 20:46:29,928 - INFO  - Training [10][  300/  391]   Loss 0.076970   Top1 97.302083   Top5 99.992188   BatchTime 0.106344   LR 0.010000   
2022-11-03 20:46:31,891 - INFO  - Training [10][  320/  391]   Loss 0.077681   Top1 97.260742   Top5 99.992676   BatchTime 0.105831   LR 0.010000   
2022-11-03 20:46:33,828 - INFO  - Training [10][  340/  391]   Loss 0.078336   Top1 97.247243   Top5 99.993107   BatchTime 0.105302   LR 0.010000   
2022-11-03 20:46:35,765 - INFO  - Training [10][  360/  391]   Loss 0.079280   Top1 97.211372   Top5 99.991319   BatchTime 0.104834   LR 0.010000   
2022-11-03 20:46:37,576 - INFO  - Training [10][  380/  391]   Loss 0.080426   Top1 97.175164   Top5 99.991776   BatchTime 0.104080   LR 0.010000   
2022-11-03 20:46:38,641 - INFO  - ==> Top1: 97.166    Top5: 99.990    Loss: 0.081

2022-11-03 20:46:38,642 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:46:41,225 - INFO  - Validation [10][   20/   79]   Loss 0.397392   Top1 89.570312   Top5 99.453125   BatchTime 0.129062   
2022-11-03 20:46:41,839 - INFO  - Validation [10][   40/   79]   Loss 0.411146   Top1 89.277344   Top5 99.355469   BatchTime 0.079874   
2022-11-03 20:46:42,364 - INFO  - Validation [10][   60/   79]   Loss 0.395390   Top1 89.739583   Top5 99.440104   BatchTime 0.062003   
2022-11-03 20:46:43,155 - INFO  - ==> Top1: 89.590    Top5: 99.460    Loss: 0.397

2022-11-03 20:46:43,182 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:46:43,183 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.590   Top5: 99.460] Sparsity : 0.687
2022-11-03 20:46:43,183 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.560   Top5: 99.560] Sparsity : 0.624
2022-11-03 20:46:43,283 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:46:43,284 - INFO  - >>>>>>>> Epoch  11
2022-11-03 20:46:43,285 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:46:47,223 - INFO  - Training [11][   20/  391]   Loss 0.078519   Top1 97.265625   Top5 100.000000   BatchTime 0.196867   LR 0.010000   
2022-11-03 20:46:49,228 - INFO  - Training [11][   40/  391]   Loss 0.079400   Top1 97.207031   Top5 100.000000   BatchTime 0.148553   LR 0.010000   
2022-11-03 20:46:51,223 - INFO  - Training [11][   60/  391]   Loss 0.078444   Top1 97.161458   Top5 100.000000   BatchTime 0.132294   LR 0.010000   
2022-11-03 20:46:53,205 - INFO  - Training [11][   80/  391]   Loss 0.080151   Top1 97.177734   Top5 100.000000   BatchTime 0.123999   LR 0.010000   
2022-11-03 20:46:55,206 - INFO  - Training [11][  100/  391]   Loss 0.081534   Top1 97.085938   Top5 99.992188   BatchTime 0.119202   LR 0.010000   
2022-11-03 20:46:57,207 - INFO  - Training [11][  120/  391]   Loss 0.081466   Top1 97.076823   Top5 99.993490   BatchTime 0.116014   LR 0.010000   
2022-11-03 20:46:59,205 - INFO  - Training [11][  140/  391]   Loss 0.080988   Top1 97.109375   Top5 99.994420   BatchTime 0.113710   LR 0.010000   
2022-11-03 20:47:01,193 - INFO  - Training [11][  160/  391]   Loss 0.083435   Top1 97.026367   Top5 99.995117   BatchTime 0.111918   LR 0.010000   
2022-11-03 20:47:03,265 - INFO  - Training [11][  180/  391]   Loss 0.084364   Top1 96.979167   Top5 99.986979   BatchTime 0.110998   LR 0.010000   
2022-11-03 20:47:05,243 - INFO  - Training [11][  200/  391]   Loss 0.084269   Top1 97.007812   Top5 99.988281   BatchTime 0.109785   LR 0.010000   
2022-11-03 20:47:07,233 - INFO  - Training [11][  220/  391]   Loss 0.084145   Top1 97.020597   Top5 99.989347   BatchTime 0.108849   LR 0.010000   
2022-11-03 20:47:09,230 - INFO  - Training [11][  240/  391]   Loss 0.084566   Top1 97.001953   Top5 99.990234   BatchTime 0.108102   LR 0.010000   
2022-11-03 20:47:11,234 - INFO  - Training [11][  260/  391]   Loss 0.085002   Top1 96.977163   Top5 99.990986   BatchTime 0.107493   LR 0.010000   
2022-11-03 20:47:13,240 - INFO  - Training [11][  280/  391]   Loss 0.084450   Top1 96.983817   Top5 99.991629   BatchTime 0.106979   LR 0.010000   
2022-11-03 20:47:15,231 - INFO  - Training [11][  300/  391]   Loss 0.084949   Top1 96.976562   Top5 99.992188   BatchTime 0.106483   LR 0.010000   
2022-11-03 20:47:17,204 - INFO  - Training [11][  320/  391]   Loss 0.084951   Top1 96.975098   Top5 99.990234   BatchTime 0.105994   LR 0.010000   
2022-11-03 20:47:19,160 - INFO  - Training [11][  340/  391]   Loss 0.085437   Top1 96.960018   Top5 99.990809   BatchTime 0.105511   LR 0.010000   
2022-11-03 20:47:21,108 - INFO  - Training [11][  360/  391]   Loss 0.085698   Top1 96.933594   Top5 99.991319   BatchTime 0.105061   LR 0.010000   
2022-11-03 20:47:22,883 - INFO  - Training [11][  380/  391]   Loss 0.086236   Top1 96.907895   Top5 99.991776   BatchTime 0.104201   LR 0.010000   
2022-11-03 20:47:23,916 - INFO  - ==> Top1: 96.934    Top5: 99.990    Loss: 0.086

2022-11-03 20:47:23,917 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:47:26,480 - INFO  - Validation [11][   20/   79]   Loss 0.365460   Top1 89.726562   Top5 99.492188   BatchTime 0.128102   
2022-11-03 20:47:27,116 - INFO  - Validation [11][   40/   79]   Loss 0.393364   Top1 89.335938   Top5 99.453125   BatchTime 0.079945   
2022-11-03 20:47:27,637 - INFO  - Validation [11][   60/   79]   Loss 0.390832   Top1 89.531250   Top5 99.518229   BatchTime 0.061984   
2022-11-03 20:47:28,390 - INFO  - ==> Top1: 89.440    Top5: 99.570    Loss: 0.393

2022-11-03 20:47:28,412 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:47:28,413 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.590   Top5: 99.460] Sparsity : 0.687
2022-11-03 20:47:28,413 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.560   Top5: 99.560] Sparsity : 0.624
2022-11-03 20:47:28,511 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:47:28,511 - INFO  - >>>>>>>> Epoch  12
2022-11-03 20:47:28,512 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:47:32,493 - INFO  - Training [12][   20/  391]   Loss 0.084611   Top1 96.914062   Top5 100.000000   BatchTime 0.199045   LR 0.010000   
2022-11-03 20:47:34,499 - INFO  - Training [12][   40/  391]   Loss 0.078573   Top1 97.304688   Top5 100.000000   BatchTime 0.149669   LR 0.010000   
2022-11-03 20:47:36,503 - INFO  - Training [12][   60/  391]   Loss 0.077359   Top1 97.291667   Top5 100.000000   BatchTime 0.133188   LR 0.010000   
2022-11-03 20:47:38,491 - INFO  - Training [12][   80/  391]   Loss 0.073995   Top1 97.421875   Top5 100.000000   BatchTime 0.124729   LR 0.010000   
2022-11-03 20:47:40,508 - INFO  - Training [12][  100/  391]   Loss 0.075072   Top1 97.414062   Top5 100.000000   BatchTime 0.119953   LR 0.010000   
2022-11-03 20:47:42,515 - INFO  - Training [12][  120/  391]   Loss 0.075368   Top1 97.395833   Top5 100.000000   BatchTime 0.116685   LR 0.010000   
2022-11-03 20:47:44,445 - INFO  - Training [12][  140/  391]   Loss 0.076603   Top1 97.276786   Top5 100.000000   BatchTime 0.113803   LR 0.010000   
2022-11-03 20:47:46,440 - INFO  - Training [12][  160/  391]   Loss 0.076349   Top1 97.314453   Top5 100.000000   BatchTime 0.112047   LR 0.010000   
2022-11-03 20:47:48,470 - INFO  - Training [12][  180/  391]   Loss 0.076523   Top1 97.304688   Top5 100.000000   BatchTime 0.110875   LR 0.010000   
2022-11-03 20:47:50,464 - INFO  - Training [12][  200/  391]   Loss 0.077737   Top1 97.257812   Top5 100.000000   BatchTime 0.109759   LR 0.010000   
2022-11-03 20:47:52,474 - INFO  - Training [12][  220/  391]   Loss 0.078417   Top1 97.237216   Top5 100.000000   BatchTime 0.108917   LR 0.010000   
2022-11-03 20:47:54,479 - INFO  - Training [12][  240/  391]   Loss 0.077803   Top1 97.246094   Top5 100.000000   BatchTime 0.108194   LR 0.010000   
2022-11-03 20:47:56,492 - INFO  - Training [12][  260/  391]   Loss 0.078281   Top1 97.184495   Top5 100.000000   BatchTime 0.107614   LR 0.010000   
2022-11-03 20:47:58,491 - INFO  - Training [12][  280/  391]   Loss 0.079590   Top1 97.123326   Top5 100.000000   BatchTime 0.107065   LR 0.010000   
2022-11-03 20:48:00,488 - INFO  - Training [12][  300/  391]   Loss 0.078868   Top1 97.158854   Top5 100.000000   BatchTime 0.106583   LR 0.010000   
2022-11-03 20:48:02,498 - INFO  - Training [12][  320/  391]   Loss 0.078153   Top1 97.175293   Top5 100.000000   BatchTime 0.106203   LR 0.010000   
2022-11-03 20:48:04,453 - INFO  - Training [12][  340/  391]   Loss 0.077665   Top1 97.185202   Top5 100.000000   BatchTime 0.105706   LR 0.010000   
2022-11-03 20:48:06,394 - INFO  - Training [12][  360/  391]   Loss 0.077452   Top1 97.191840   Top5 100.000000   BatchTime 0.105226   LR 0.010000   
2022-11-03 20:48:08,264 - INFO  - Training [12][  380/  391]   Loss 0.077959   Top1 97.189556   Top5 99.995888   BatchTime 0.104609   LR 0.010000   
2022-11-03 20:48:09,374 - INFO  - ==> Top1: 97.182    Top5: 99.996    Loss: 0.078

2022-11-03 20:48:09,375 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:48:11,989 - INFO  - Validation [12][   20/   79]   Loss 0.391800   Top1 89.765625   Top5 99.648438   BatchTime 0.130609   
2022-11-03 20:48:12,572 - INFO  - Validation [12][   40/   79]   Loss 0.401921   Top1 89.453125   Top5 99.570312   BatchTime 0.079868   
2022-11-03 20:48:13,093 - INFO  - Validation [12][   60/   79]   Loss 0.391652   Top1 89.895833   Top5 99.609375   BatchTime 0.061930   
2022-11-03 20:48:13,864 - INFO  - ==> Top1: 89.800    Top5: 99.640    Loss: 0.391

2022-11-03 20:48:13,891 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:48:13,891 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:48:13,892 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.590   Top5: 99.460] Sparsity : 0.687
2022-11-03 20:48:14,075 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:48:14,076 - INFO  - >>>>>>>> Epoch  13
2022-11-03 20:48:14,077 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:48:17,994 - INFO  - Training [13][   20/  391]   Loss 0.071947   Top1 97.382812   Top5 100.000000   BatchTime 0.195810   LR 0.010000   
2022-11-03 20:48:20,021 - INFO  - Training [13][   40/  391]   Loss 0.070696   Top1 97.363281   Top5 100.000000   BatchTime 0.148577   LR 0.010000   
2022-11-03 20:48:22,036 - INFO  - Training [13][   60/  391]   Loss 0.067211   Top1 97.565104   Top5 100.000000   BatchTime 0.132644   LR 0.010000   
2022-11-03 20:48:24,075 - INFO  - Training [13][   80/  391]   Loss 0.073061   Top1 97.451172   Top5 100.000000   BatchTime 0.124962   LR 0.010000   
2022-11-03 20:48:26,095 - INFO  - Training [13][  100/  391]   Loss 0.071419   Top1 97.546875   Top5 100.000000   BatchTime 0.120171   LR 0.010000   
2022-11-03 20:48:28,114 - INFO  - Training [13][  120/  391]   Loss 0.073590   Top1 97.473958   Top5 99.993490   BatchTime 0.116972   LR 0.010000   
2022-11-03 20:48:30,124 - INFO  - Training [13][  140/  391]   Loss 0.073187   Top1 97.483259   Top5 99.994420   BatchTime 0.114615   LR 0.010000   
2022-11-03 20:48:32,129 - INFO  - Training [13][  160/  391]   Loss 0.074024   Top1 97.465820   Top5 99.990234   BatchTime 0.112818   LR 0.010000   
2022-11-03 20:48:34,139 - INFO  - Training [13][  180/  391]   Loss 0.073916   Top1 97.460938   Top5 99.991319   BatchTime 0.111449   LR 0.010000   
2022-11-03 20:48:36,146 - INFO  - Training [13][  200/  391]   Loss 0.073997   Top1 97.460938   Top5 99.992188   BatchTime 0.110342   LR 0.010000   
2022-11-03 20:48:38,148 - INFO  - Training [13][  220/  391]   Loss 0.074663   Top1 97.418324   Top5 99.992898   BatchTime 0.109408   LR 0.010000   
2022-11-03 20:48:40,177 - INFO  - Training [13][  240/  391]   Loss 0.074841   Top1 97.441406   Top5 99.990234   BatchTime 0.108746   LR 0.010000   
2022-11-03 20:48:42,265 - INFO  - Training [13][  260/  391]   Loss 0.074643   Top1 97.445913   Top5 99.990986   BatchTime 0.108411   LR 0.010000   
2022-11-03 20:48:44,246 - INFO  - Training [13][  280/  391]   Loss 0.075403   Top1 97.421875   Top5 99.991629   BatchTime 0.107741   LR 0.010000   
2022-11-03 20:48:46,224 - INFO  - Training [13][  300/  391]   Loss 0.075809   Top1 97.403646   Top5 99.992188   BatchTime 0.107154   LR 0.010000   
2022-11-03 20:48:48,192 - INFO  - Training [13][  320/  391]   Loss 0.076526   Top1 97.368164   Top5 99.992676   BatchTime 0.106605   LR 0.010000   
2022-11-03 20:48:50,140 - INFO  - Training [13][  340/  391]   Loss 0.076713   Top1 97.366728   Top5 99.993107   BatchTime 0.106064   LR 0.010000   
2022-11-03 20:48:52,087 - INFO  - Training [13][  360/  391]   Loss 0.077080   Top1 97.363281   Top5 99.991319   BatchTime 0.105580   LR 0.010000   
2022-11-03 20:48:53,828 - INFO  - Training [13][  380/  391]   Loss 0.077033   Top1 97.358141   Top5 99.991776   BatchTime 0.104605   LR 0.010000   
2022-11-03 20:48:54,936 - INFO  - ==> Top1: 97.374    Top5: 99.992    Loss: 0.077

2022-11-03 20:48:54,937 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:48:57,507 - INFO  - Validation [13][   20/   79]   Loss 0.402819   Top1 89.101562   Top5 99.531250   BatchTime 0.128367   
2022-11-03 20:48:58,033 - INFO  - Validation [13][   40/   79]   Loss 0.426153   Top1 88.925781   Top5 99.394531   BatchTime 0.077350   
2022-11-03 20:48:58,547 - INFO  - Validation [13][   60/   79]   Loss 0.414251   Top1 89.361979   Top5 99.453125   BatchTime 0.060123   
2022-11-03 20:48:59,298 - INFO  - ==> Top1: 89.390    Top5: 99.520    Loss: 0.413

2022-11-03 20:48:59,325 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:48:59,326 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:48:59,326 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.590   Top5: 99.460] Sparsity : 0.687
2022-11-03 20:48:59,428 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:48:59,428 - INFO  - >>>>>>>> Epoch  14
2022-11-03 20:48:59,430 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:49:03,332 - INFO  - Training [14][   20/  391]   Loss 0.062849   Top1 97.695312   Top5 100.000000   BatchTime 0.195089   LR 0.010000   
2022-11-03 20:49:05,339 - INFO  - Training [14][   40/  391]   Loss 0.061147   Top1 97.890625   Top5 100.000000   BatchTime 0.147717   LR 0.010000   
2022-11-03 20:49:07,358 - INFO  - Training [14][   60/  391]   Loss 0.063986   Top1 97.747396   Top5 99.986979   BatchTime 0.132126   LR 0.010000   
2022-11-03 20:49:09,368 - INFO  - Training [14][   80/  391]   Loss 0.065122   Top1 97.724609   Top5 99.990234   BatchTime 0.124218   LR 0.010000   
2022-11-03 20:49:11,360 - INFO  - Training [14][  100/  391]   Loss 0.066084   Top1 97.804688   Top5 99.992188   BatchTime 0.119302   LR 0.010000   
2022-11-03 20:49:13,351 - INFO  - Training [14][  120/  391]   Loss 0.065748   Top1 97.740885   Top5 99.993490   BatchTime 0.116006   LR 0.010000   
2022-11-03 20:49:15,338 - INFO  - Training [14][  140/  391]   Loss 0.065696   Top1 97.723214   Top5 99.988839   BatchTime 0.113625   LR 0.010000   
2022-11-03 20:49:17,319 - INFO  - Training [14][  160/  391]   Loss 0.065457   Top1 97.749023   Top5 99.985352   BatchTime 0.111802   LR 0.010000   
2022-11-03 20:49:19,308 - INFO  - Training [14][  180/  391]   Loss 0.065405   Top1 97.708333   Top5 99.986979   BatchTime 0.110432   LR 0.010000   
2022-11-03 20:49:21,283 - INFO  - Training [14][  200/  391]   Loss 0.065780   Top1 97.695312   Top5 99.984375   BatchTime 0.109264   LR 0.010000   
2022-11-03 20:49:23,281 - INFO  - Training [14][  220/  391]   Loss 0.067246   Top1 97.649148   Top5 99.982244   BatchTime 0.108409   LR 0.010000   
2022-11-03 20:49:25,285 - INFO  - Training [14][  240/  391]   Loss 0.066836   Top1 97.685547   Top5 99.983724   BatchTime 0.107728   LR 0.010000   
2022-11-03 20:49:27,274 - INFO  - Training [14][  260/  391]   Loss 0.066933   Top1 97.710337   Top5 99.981971   BatchTime 0.107090   LR 0.010000   
2022-11-03 20:49:29,274 - INFO  - Training [14][  280/  391]   Loss 0.066410   Top1 97.731585   Top5 99.983259   BatchTime 0.106582   LR 0.010000   
2022-11-03 20:49:31,269 - INFO  - Training [14][  300/  391]   Loss 0.066413   Top1 97.721354   Top5 99.984375   BatchTime 0.106129   LR 0.010000   
2022-11-03 20:49:33,237 - INFO  - Training [14][  320/  391]   Loss 0.066443   Top1 97.707520   Top5 99.985352   BatchTime 0.105645   LR 0.010000   
2022-11-03 20:49:35,192 - INFO  - Training [14][  340/  391]   Loss 0.068171   Top1 97.672335   Top5 99.986213   BatchTime 0.105179   LR 0.010000   
2022-11-03 20:49:37,150 - INFO  - Training [14][  360/  391]   Loss 0.068511   Top1 97.647569   Top5 99.984809   BatchTime 0.104774   LR 0.010000   
2022-11-03 20:49:38,947 - INFO  - Training [14][  380/  391]   Loss 0.068482   Top1 97.645970   Top5 99.985609   BatchTime 0.103988   LR 0.010000   
2022-11-03 20:49:40,028 - INFO  - ==> Top1: 97.638    Top5: 99.986    Loss: 0.069

2022-11-03 20:49:40,030 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:49:42,705 - INFO  - Validation [14][   20/   79]   Loss 0.393532   Top1 90.078125   Top5 99.648438   BatchTime 0.133672   
2022-11-03 20:49:43,250 - INFO  - Validation [14][   40/   79]   Loss 0.419510   Top1 89.355469   Top5 99.550781   BatchTime 0.080456   
2022-11-03 20:49:43,766 - INFO  - Validation [14][   60/   79]   Loss 0.416249   Top1 89.427083   Top5 99.570312   BatchTime 0.062236   
2022-11-03 20:49:44,562 - INFO  - ==> Top1: 89.480    Top5: 99.570    Loss: 0.410

2022-11-03 20:49:44,602 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:49:44,608 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:49:44,608 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.590   Top5: 99.460] Sparsity : 0.687
2022-11-03 20:49:44,758 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:49:44,759 - INFO  - >>>>>>>> Epoch  15
2022-11-03 20:49:44,760 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:49:48,663 - INFO  - Training [15][   20/  391]   Loss 0.060648   Top1 97.929688   Top5 100.000000   BatchTime 0.195184   LR 0.010000   
2022-11-03 20:49:50,663 - INFO  - Training [15][   40/  391]   Loss 0.057316   Top1 97.988281   Top5 100.000000   BatchTime 0.147582   LR 0.010000   
2022-11-03 20:49:52,680 - INFO  - Training [15][   60/  391]   Loss 0.057610   Top1 98.020833   Top5 100.000000   BatchTime 0.132011   LR 0.010000   
2022-11-03 20:49:54,694 - INFO  - Training [15][   80/  391]   Loss 0.060027   Top1 97.900391   Top5 100.000000   BatchTime 0.124178   LR 0.010000   
2022-11-03 20:49:56,703 - INFO  - Training [15][  100/  391]   Loss 0.059345   Top1 97.929688   Top5 100.000000   BatchTime 0.119429   LR 0.010000   
2022-11-03 20:49:58,715 - INFO  - Training [15][  120/  391]   Loss 0.059900   Top1 97.942708   Top5 100.000000   BatchTime 0.116291   LR 0.010000   
2022-11-03 20:50:00,719 - INFO  - Training [15][  140/  391]   Loss 0.061697   Top1 97.840402   Top5 100.000000   BatchTime 0.113990   LR 0.010000   
2022-11-03 20:50:02,726 - INFO  - Training [15][  160/  391]   Loss 0.061954   Top1 97.802734   Top5 100.000000   BatchTime 0.112290   LR 0.010000   
2022-11-03 20:50:04,719 - INFO  - Training [15][  180/  391]   Loss 0.063513   Top1 97.730035   Top5 100.000000   BatchTime 0.110884   LR 0.010000   
2022-11-03 20:50:06,701 - INFO  - Training [15][  200/  391]   Loss 0.063311   Top1 97.742188   Top5 100.000000   BatchTime 0.109705   LR 0.010000   
2022-11-03 20:50:08,695 - INFO  - Training [15][  220/  391]   Loss 0.064361   Top1 97.716619   Top5 100.000000   BatchTime 0.108795   LR 0.010000   
2022-11-03 20:50:10,699 - INFO  - Training [15][  240/  391]   Loss 0.064565   Top1 97.727865   Top5 99.996745   BatchTime 0.108079   LR 0.010000   
2022-11-03 20:50:12,714 - INFO  - Training [15][  260/  391]   Loss 0.064049   Top1 97.752404   Top5 99.993990   BatchTime 0.107514   LR 0.010000   
2022-11-03 20:50:14,712 - INFO  - Training [15][  280/  391]   Loss 0.065358   Top1 97.712054   Top5 99.994420   BatchTime 0.106969   LR 0.010000   
2022-11-03 20:50:16,779 - INFO  - Training [15][  300/  391]   Loss 0.065246   Top1 97.729167   Top5 99.992188   BatchTime 0.106730   LR 0.010000   
2022-11-03 20:50:18,776 - INFO  - Training [15][  320/  391]   Loss 0.065227   Top1 97.729492   Top5 99.992676   BatchTime 0.106298   LR 0.010000   
2022-11-03 20:50:20,747 - INFO  - Training [15][  340/  391]   Loss 0.065015   Top1 97.715993   Top5 99.993107   BatchTime 0.105842   LR 0.010000   
2022-11-03 20:50:22,691 - INFO  - Training [15][  360/  391]   Loss 0.065160   Top1 97.714844   Top5 99.993490   BatchTime 0.105363   LR 0.010000   
2022-11-03 20:50:24,366 - INFO  - Training [15][  380/  391]   Loss 0.066136   Top1 97.693257   Top5 99.991776   BatchTime 0.104225   LR 0.010000   
2022-11-03 20:50:25,512 - INFO  - ==> Top1: 97.698    Top5: 99.992    Loss: 0.066

2022-11-03 20:50:25,513 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:50:28,015 - INFO  - Validation [15][   20/   79]   Loss 0.397485   Top1 90.195312   Top5 99.531250   BatchTime 0.125025   
2022-11-03 20:50:28,545 - INFO  - Validation [15][   40/   79]   Loss 0.415079   Top1 89.667969   Top5 99.511719   BatchTime 0.075746   
2022-11-03 20:50:29,067 - INFO  - Validation [15][   60/   79]   Loss 0.407975   Top1 89.856771   Top5 99.544271   BatchTime 0.059207   
2022-11-03 20:50:29,976 - INFO  - ==> Top1: 89.790    Top5: 99.570    Loss: 0.405

2022-11-03 20:50:30,009 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:50:30,010 - INFO  - Scoreboard best 2 ==> Epoch [15][Top1: 89.790   Top5: 99.570] Sparsity : 0.702
2022-11-03 20:50:30,010 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.680   Top5: 99.550] Sparsity : 0.651
2022-11-03 20:50:30,116 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:50:30,116 - INFO  - >>>>>>>> Epoch  16
2022-11-03 20:50:30,117 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:50:34,014 - INFO  - Training [16][   20/  391]   Loss 0.067243   Top1 97.500000   Top5 100.000000   BatchTime 0.194804   LR 0.010000   
2022-11-03 20:50:36,011 - INFO  - Training [16][   40/  391]   Loss 0.060092   Top1 97.753906   Top5 100.000000   BatchTime 0.147325   LR 0.010000   
2022-11-03 20:50:37,997 - INFO  - Training [16][   60/  391]   Loss 0.059683   Top1 97.851562   Top5 100.000000   BatchTime 0.131326   LR 0.010000   
2022-11-03 20:50:40,014 - INFO  - Training [16][   80/  391]   Loss 0.062013   Top1 97.832031   Top5 100.000000   BatchTime 0.123704   LR 0.010000   
2022-11-03 20:50:42,032 - INFO  - Training [16][  100/  391]   Loss 0.061678   Top1 97.859375   Top5 100.000000   BatchTime 0.119144   LR 0.010000   
2022-11-03 20:50:44,060 - INFO  - Training [16][  120/  391]   Loss 0.062010   Top1 97.877604   Top5 100.000000   BatchTime 0.116184   LR 0.010000   
2022-11-03 20:50:46,059 - INFO  - Training [16][  140/  391]   Loss 0.061306   Top1 97.857143   Top5 100.000000   BatchTime 0.113865   LR 0.010000   
2022-11-03 20:50:48,054 - INFO  - Training [16][  160/  391]   Loss 0.060343   Top1 97.905273   Top5 100.000000   BatchTime 0.112097   LR 0.010000   
2022-11-03 20:50:50,056 - INFO  - Training [16][  180/  391]   Loss 0.060063   Top1 97.916667   Top5 100.000000   BatchTime 0.110767   LR 0.010000   
2022-11-03 20:50:52,057 - INFO  - Training [16][  200/  391]   Loss 0.060587   Top1 97.906250   Top5 100.000000   BatchTime 0.109694   LR 0.010000   
2022-11-03 20:50:54,066 - INFO  - Training [16][  220/  391]   Loss 0.060574   Top1 97.890625   Top5 100.000000   BatchTime 0.108855   LR 0.010000   
2022-11-03 20:50:56,058 - INFO  - Training [16][  240/  391]   Loss 0.060131   Top1 97.887370   Top5 100.000000   BatchTime 0.108083   LR 0.010000   
2022-11-03 20:50:58,058 - INFO  - Training [16][  260/  391]   Loss 0.060987   Top1 97.827524   Top5 100.000000   BatchTime 0.107462   LR 0.010000   
2022-11-03 20:50:59,987 - INFO  - Training [16][  280/  391]   Loss 0.062007   Top1 97.759487   Top5 100.000000   BatchTime 0.106673   LR 0.010000   
2022-11-03 20:51:01,976 - INFO  - Training [16][  300/  391]   Loss 0.061662   Top1 97.778646   Top5 100.000000   BatchTime 0.106193   LR 0.010000   
2022-11-03 20:51:03,955 - INFO  - Training [16][  320/  391]   Loss 0.061511   Top1 97.775879   Top5 100.000000   BatchTime 0.105738   LR 0.010000   
2022-11-03 20:51:05,903 - INFO  - Training [16][  340/  391]   Loss 0.061985   Top1 97.761949   Top5 100.000000   BatchTime 0.105250   LR 0.010000   
2022-11-03 20:51:07,849 - INFO  - Training [16][  360/  391]   Loss 0.061771   Top1 97.773438   Top5 100.000000   BatchTime 0.104808   LR 0.010000   
2022-11-03 20:51:09,547 - INFO  - Training [16][  380/  391]   Loss 0.061218   Top1 97.791941   Top5 100.000000   BatchTime 0.103759   LR 0.010000   
2022-11-03 20:51:10,739 - INFO  - ==> Top1: 97.794    Top5: 100.000    Loss: 0.061

2022-11-03 20:51:10,740 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:51:13,234 - INFO  - Validation [16][   20/   79]   Loss 0.380760   Top1 90.390625   Top5 99.492188   BatchTime 0.124643   
2022-11-03 20:51:13,754 - INFO  - Validation [16][   40/   79]   Loss 0.410524   Top1 89.902344   Top5 99.511719   BatchTime 0.075323   
2022-11-03 20:51:14,270 - INFO  - Validation [16][   60/   79]   Loss 0.403471   Top1 90.104167   Top5 99.609375   BatchTime 0.058813   
2022-11-03 20:51:15,203 - INFO  - ==> Top1: 90.200    Top5: 99.640    Loss: 0.400

2022-11-03 20:51:15,244 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.200   Top5: 99.640] Sparsity : 0.706
2022-11-03 20:51:15,245 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:51:15,245 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 89.790   Top5: 99.570] Sparsity : 0.702
2022-11-03 20:51:15,440 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:51:15,441 - INFO  - >>>>>>>> Epoch  17
2022-11-03 20:51:15,441 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:51:19,339 - INFO  - Training [17][   20/  391]   Loss 0.045891   Top1 98.593750   Top5 100.000000   BatchTime 0.194850   LR 0.010000   
2022-11-03 20:51:21,344 - INFO  - Training [17][   40/  391]   Loss 0.051818   Top1 98.222656   Top5 100.000000   BatchTime 0.147548   LR 0.010000   
2022-11-03 20:51:23,345 - INFO  - Training [17][   60/  391]   Loss 0.050809   Top1 98.359375   Top5 100.000000   BatchTime 0.131726   LR 0.010000   
2022-11-03 20:51:25,353 - INFO  - Training [17][   80/  391]   Loss 0.053827   Top1 98.105469   Top5 99.990234   BatchTime 0.123894   LR 0.010000   
2022-11-03 20:51:27,355 - INFO  - Training [17][  100/  391]   Loss 0.054854   Top1 98.078125   Top5 99.992188   BatchTime 0.119134   LR 0.010000   
2022-11-03 20:51:29,355 - INFO  - Training [17][  120/  391]   Loss 0.057355   Top1 98.001302   Top5 99.993490   BatchTime 0.115946   LR 0.010000   
2022-11-03 20:51:31,347 - INFO  - Training [17][  140/  391]   Loss 0.057306   Top1 98.030134   Top5 99.994420   BatchTime 0.113611   LR 0.010000   
2022-11-03 20:51:33,355 - INFO  - Training [17][  160/  391]   Loss 0.057989   Top1 98.007812   Top5 99.995117   BatchTime 0.111958   LR 0.010000   
2022-11-03 20:51:35,351 - INFO  - Training [17][  180/  391]   Loss 0.057671   Top1 98.020833   Top5 99.995660   BatchTime 0.110605   LR 0.010000   
2022-11-03 20:51:37,361 - INFO  - Training [17][  200/  391]   Loss 0.058539   Top1 97.996094   Top5 99.996094   BatchTime 0.109596   LR 0.010000   
2022-11-03 20:51:39,349 - INFO  - Training [17][  220/  391]   Loss 0.058773   Top1 97.990057   Top5 99.996449   BatchTime 0.108669   LR 0.010000   
2022-11-03 20:51:41,336 - INFO  - Training [17][  240/  391]   Loss 0.059382   Top1 97.991536   Top5 99.996745   BatchTime 0.107891   LR 0.010000   
2022-11-03 20:51:43,328 - INFO  - Training [17][  260/  391]   Loss 0.060566   Top1 97.929688   Top5 99.993990   BatchTime 0.107253   LR 0.010000   
2022-11-03 20:51:45,340 - INFO  - Training [17][  280/  391]   Loss 0.060942   Top1 97.918527   Top5 99.994420   BatchTime 0.106778   LR 0.010000   
2022-11-03 20:51:47,337 - INFO  - Training [17][  300/  391]   Loss 0.061392   Top1 97.906250   Top5 99.994792   BatchTime 0.106317   LR 0.010000   
2022-11-03 20:51:49,313 - INFO  - Training [17][  320/  391]   Loss 0.061846   Top1 97.880859   Top5 99.995117   BatchTime 0.105847   LR 0.010000   
2022-11-03 20:51:51,388 - INFO  - Training [17][  340/  391]   Loss 0.061613   Top1 97.874540   Top5 99.995404   BatchTime 0.105721   LR 0.010000   
2022-11-03 20:51:53,393 - INFO  - Training [17][  360/  391]   Loss 0.061389   Top1 97.866753   Top5 99.995660   BatchTime 0.105418   LR 0.010000   
2022-11-03 20:51:54,844 - INFO  - Training [17][  380/  391]   Loss 0.061618   Top1 97.843339   Top5 99.995888   BatchTime 0.103688   LR 0.010000   
2022-11-03 20:51:56,017 - INFO  - ==> Top1: 97.816    Top5: 99.996    Loss: 0.062

2022-11-03 20:51:56,018 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:51:58,518 - INFO  - Validation [17][   20/   79]   Loss 0.385483   Top1 89.882812   Top5 99.648438   BatchTime 0.124937   
2022-11-03 20:51:59,041 - INFO  - Validation [17][   40/   79]   Loss 0.400359   Top1 89.785156   Top5 99.511719   BatchTime 0.075540   
2022-11-03 20:51:59,566 - INFO  - Validation [17][   60/   79]   Loss 0.397102   Top1 89.882812   Top5 99.570312   BatchTime 0.059113   
2022-11-03 20:52:00,736 - INFO  - ==> Top1: 89.950    Top5: 99.600    Loss: 0.395

2022-11-03 20:52:00,766 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.200   Top5: 99.640] Sparsity : 0.706
2022-11-03 20:52:00,766 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 89.950   Top5: 99.600] Sparsity : 0.724
2022-11-03 20:52:00,766 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:52:00,870 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:52:00,870 - INFO  - >>>>>>>> Epoch  18
2022-11-03 20:52:00,872 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:52:04,734 - INFO  - Training [18][   20/  391]   Loss 0.060093   Top1 97.578125   Top5 99.921875   BatchTime 0.193079   LR 0.010000   
2022-11-03 20:52:06,730 - INFO  - Training [18][   40/  391]   Loss 0.063658   Top1 97.675781   Top5 99.960938   BatchTime 0.146445   LR 0.010000   
2022-11-03 20:52:08,725 - INFO  - Training [18][   60/  391]   Loss 0.062703   Top1 97.760417   Top5 99.973958   BatchTime 0.130881   LR 0.010000   
2022-11-03 20:52:10,738 - INFO  - Training [18][   80/  391]   Loss 0.063037   Top1 97.714844   Top5 99.980469   BatchTime 0.123330   LR 0.010000   
2022-11-03 20:52:12,734 - INFO  - Training [18][  100/  391]   Loss 0.060857   Top1 97.851562   Top5 99.984375   BatchTime 0.118617   LR 0.010000   
2022-11-03 20:52:14,717 - INFO  - Training [18][  120/  391]   Loss 0.061387   Top1 97.832031   Top5 99.986979   BatchTime 0.115372   LR 0.010000   
2022-11-03 20:52:16,713 - INFO  - Training [18][  140/  391]   Loss 0.061214   Top1 97.818080   Top5 99.988839   BatchTime 0.113151   LR 0.010000   
2022-11-03 20:52:18,705 - INFO  - Training [18][  160/  391]   Loss 0.062640   Top1 97.739258   Top5 99.990234   BatchTime 0.111453   LR 0.010000   
2022-11-03 20:52:20,726 - INFO  - Training [18][  180/  391]   Loss 0.062635   Top1 97.734375   Top5 99.991319   BatchTime 0.110296   LR 0.010000   
2022-11-03 20:52:22,732 - INFO  - Training [18][  200/  391]   Loss 0.063030   Top1 97.707031   Top5 99.992188   BatchTime 0.109298   LR 0.010000   
2022-11-03 20:52:24,724 - INFO  - Training [18][  220/  391]   Loss 0.065413   Top1 97.620739   Top5 99.992898   BatchTime 0.108415   LR 0.010000   
2022-11-03 20:52:26,740 - INFO  - Training [18][  240/  391]   Loss 0.065371   Top1 97.584635   Top5 99.993490   BatchTime 0.107784   LR 0.010000   
2022-11-03 20:52:28,753 - INFO  - Training [18][  260/  391]   Loss 0.064987   Top1 97.626202   Top5 99.993990   BatchTime 0.107232   LR 0.010000   
2022-11-03 20:52:30,764 - INFO  - Training [18][  280/  391]   Loss 0.065450   Top1 97.611607   Top5 99.994420   BatchTime 0.106755   LR 0.010000   
2022-11-03 20:52:32,759 - INFO  - Training [18][  300/  391]   Loss 0.064738   Top1 97.640625   Top5 99.994792   BatchTime 0.106288   LR 0.010000   
2022-11-03 20:52:34,746 - INFO  - Training [18][  320/  391]   Loss 0.065104   Top1 97.641602   Top5 99.992676   BatchTime 0.105853   LR 0.010000   
2022-11-03 20:52:36,682 - INFO  - Training [18][  340/  391]   Loss 0.066185   Top1 97.605699   Top5 99.993107   BatchTime 0.105321   LR 0.010000   
2022-11-03 20:52:38,646 - INFO  - Training [18][  360/  391]   Loss 0.066571   Top1 97.575955   Top5 99.993490   BatchTime 0.104925   LR 0.010000   
2022-11-03 20:52:40,205 - INFO  - Training [18][  380/  391]   Loss 0.067068   Top1 97.553454   Top5 99.993832   BatchTime 0.103506   LR 0.010000   
2022-11-03 20:52:41,354 - INFO  - ==> Top1: 97.552    Top5: 99.994    Loss: 0.067

2022-11-03 20:52:41,355 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:52:43,853 - INFO  - Validation [18][   20/   79]   Loss 0.384011   Top1 89.960938   Top5 99.570312   BatchTime 0.124825   
2022-11-03 20:52:44,373 - INFO  - Validation [18][   40/   79]   Loss 0.409215   Top1 89.667969   Top5 99.531250   BatchTime 0.075423   
2022-11-03 20:52:45,036 - INFO  - Validation [18][   60/   79]   Loss 0.402560   Top1 89.739583   Top5 99.531250   BatchTime 0.061329   
2022-11-03 20:52:46,166 - INFO  - ==> Top1: 89.660    Top5: 99.600    Loss: 0.403

2022-11-03 20:52:46,197 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.200   Top5: 99.640] Sparsity : 0.706
2022-11-03 20:52:46,198 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 89.950   Top5: 99.600] Sparsity : 0.724
2022-11-03 20:52:46,198 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:52:46,268 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:52:46,268 - INFO  - >>>>>>>> Epoch  19
2022-11-03 20:52:46,269 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:52:50,163 - INFO  - Training [19][   20/  391]   Loss 0.062819   Top1 97.968750   Top5 100.000000   BatchTime 0.194665   LR 0.010000   
2022-11-03 20:52:52,168 - INFO  - Training [19][   40/  391]   Loss 0.063331   Top1 97.851562   Top5 100.000000   BatchTime 0.147457   LR 0.010000   
2022-11-03 20:52:54,159 - INFO  - Training [19][   60/  391]   Loss 0.061164   Top1 97.747396   Top5 100.000000   BatchTime 0.131498   LR 0.010000   
2022-11-03 20:52:56,169 - INFO  - Training [19][   80/  391]   Loss 0.060575   Top1 97.714844   Top5 100.000000   BatchTime 0.123746   LR 0.010000   
2022-11-03 20:52:58,169 - INFO  - Training [19][  100/  391]   Loss 0.062655   Top1 97.664062   Top5 100.000000   BatchTime 0.118989   LR 0.010000   
2022-11-03 20:53:00,150 - INFO  - Training [19][  120/  391]   Loss 0.063950   Top1 97.565104   Top5 100.000000   BatchTime 0.115670   LR 0.010000   
2022-11-03 20:53:02,156 - INFO  - Training [19][  140/  391]   Loss 0.064695   Top1 97.578125   Top5 100.000000   BatchTime 0.113474   LR 0.010000   
2022-11-03 20:53:04,156 - INFO  - Training [19][  160/  391]   Loss 0.063587   Top1 97.602539   Top5 100.000000   BatchTime 0.111792   LR 0.010000   
2022-11-03 20:53:06,161 - INFO  - Training [19][  180/  391]   Loss 0.062665   Top1 97.647569   Top5 100.000000   BatchTime 0.110508   LR 0.010000   
2022-11-03 20:53:08,149 - INFO  - Training [19][  200/  391]   Loss 0.063383   Top1 97.640625   Top5 100.000000   BatchTime 0.109395   LR 0.010000   
2022-11-03 20:53:10,133 - INFO  - Training [19][  220/  391]   Loss 0.063323   Top1 97.656250   Top5 99.996449   BatchTime 0.108468   LR 0.010000   
2022-11-03 20:53:12,123 - INFO  - Training [19][  240/  391]   Loss 0.063360   Top1 97.669271   Top5 99.996745   BatchTime 0.107721   LR 0.010000   
2022-11-03 20:53:14,116 - INFO  - Training [19][  260/  391]   Loss 0.064076   Top1 97.653245   Top5 99.996995   BatchTime 0.107099   LR 0.010000   
2022-11-03 20:53:16,105 - INFO  - Training [19][  280/  391]   Loss 0.064644   Top1 97.631138   Top5 99.994420   BatchTime 0.106552   LR 0.010000   
2022-11-03 20:53:18,068 - INFO  - Training [19][  300/  391]   Loss 0.064909   Top1 97.638021   Top5 99.994792   BatchTime 0.105992   LR 0.010000   
2022-11-03 20:53:20,036 - INFO  - Training [19][  320/  391]   Loss 0.065638   Top1 97.614746   Top5 99.995117   BatchTime 0.105519   LR 0.010000   
2022-11-03 20:53:22,006 - INFO  - Training [19][  340/  391]   Loss 0.065725   Top1 97.635570   Top5 99.995404   BatchTime 0.105107   LR 0.010000   
2022-11-03 20:53:23,804 - INFO  - Training [19][  360/  391]   Loss 0.066114   Top1 97.615017   Top5 99.995660   BatchTime 0.104262   LR 0.010000   
2022-11-03 20:53:25,346 - INFO  - Training [19][  380/  391]   Loss 0.065403   Top1 97.639803   Top5 99.995888   BatchTime 0.102831   LR 0.010000   
2022-11-03 20:53:26,641 - INFO  - ==> Top1: 97.636    Top5: 99.996    Loss: 0.066

2022-11-03 20:53:26,642 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:53:29,151 - INFO  - Validation [19][   20/   79]   Loss 0.399088   Top1 89.648438   Top5 99.648438   BatchTime 0.125365   
2022-11-03 20:53:29,716 - INFO  - Validation [19][   40/   79]   Loss 0.428623   Top1 89.414062   Top5 99.492188   BatchTime 0.076821   
2022-11-03 20:53:30,651 - INFO  - Validation [19][   60/   79]   Loss 0.418089   Top1 89.609375   Top5 99.557292   BatchTime 0.066792   
2022-11-03 20:53:31,825 - INFO  - ==> Top1: 89.630    Top5: 99.570    Loss: 0.411

2022-11-03 20:53:31,866 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.200   Top5: 99.640] Sparsity : 0.706
2022-11-03 20:53:31,866 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 89.950   Top5: 99.600] Sparsity : 0.724
2022-11-03 20:53:31,866 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.800   Top5: 99.640] Sparsity : 0.695
2022-11-03 20:53:31,975 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:53:31,975 - INFO  - >>>>>>>> Epoch  20
2022-11-03 20:53:31,976 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:53:35,867 - INFO  - Training [20][   20/  391]   Loss 0.063529   Top1 97.656250   Top5 100.000000   BatchTime 0.194561   LR 0.001000   
2022-11-03 20:53:37,862 - INFO  - Training [20][   40/  391]   Loss 0.066328   Top1 97.656250   Top5 100.000000   BatchTime 0.147154   LR 0.001000   
2022-11-03 20:53:39,857 - INFO  - Training [20][   60/  391]   Loss 0.059575   Top1 97.903646   Top5 100.000000   BatchTime 0.131344   LR 0.001000   
2022-11-03 20:53:41,887 - INFO  - Training [20][   80/  391]   Loss 0.058057   Top1 98.037109   Top5 100.000000   BatchTime 0.123891   LR 0.001000   
2022-11-03 20:53:43,897 - INFO  - Training [20][  100/  391]   Loss 0.059177   Top1 98.039062   Top5 100.000000   BatchTime 0.119212   LR 0.001000   
2022-11-03 20:53:45,892 - INFO  - Training [20][  120/  391]   Loss 0.059313   Top1 98.027344   Top5 100.000000   BatchTime 0.115962   LR 0.001000   
2022-11-03 20:53:47,882 - INFO  - Training [20][  140/  391]   Loss 0.059109   Top1 98.035714   Top5 100.000000   BatchTime 0.113612   LR 0.001000   
2022-11-03 20:53:49,883 - INFO  - Training [20][  160/  391]   Loss 0.058640   Top1 98.037109   Top5 100.000000   BatchTime 0.111914   LR 0.001000   
2022-11-03 20:53:51,884 - INFO  - Training [20][  180/  391]   Loss 0.057794   Top1 98.068576   Top5 100.000000   BatchTime 0.110595   LR 0.001000   
2022-11-03 20:53:53,871 - INFO  - Training [20][  200/  391]   Loss 0.057045   Top1 98.070312   Top5 100.000000   BatchTime 0.109475   LR 0.001000   
2022-11-03 20:53:55,873 - INFO  - Training [20][  220/  391]   Loss 0.056596   Top1 98.085938   Top5 100.000000   BatchTime 0.108620   LR 0.001000   
2022-11-03 20:53:57,883 - INFO  - Training [20][  240/  391]   Loss 0.055985   Top1 98.085938   Top5 100.000000   BatchTime 0.107942   LR 0.001000   
2022-11-03 20:53:59,868 - INFO  - Training [20][  260/  391]   Loss 0.055427   Top1 98.100962   Top5 100.000000   BatchTime 0.107274   LR 0.001000   
2022-11-03 20:54:01,862 - INFO  - Training [20][  280/  391]   Loss 0.054655   Top1 98.122210   Top5 100.000000   BatchTime 0.106734   LR 0.001000   
2022-11-03 20:54:03,819 - INFO  - Training [20][  300/  391]   Loss 0.053847   Top1 98.151042   Top5 100.000000   BatchTime 0.106141   LR 0.001000   
2022-11-03 20:54:05,782 - INFO  - Training [20][  320/  391]   Loss 0.053675   Top1 98.168945   Top5 100.000000   BatchTime 0.105642   LR 0.001000   
2022-11-03 20:54:07,724 - INFO  - Training [20][  340/  391]   Loss 0.053379   Top1 98.166360   Top5 100.000000   BatchTime 0.105140   LR 0.001000   
2022-11-03 20:54:09,267 - INFO  - Training [20][  360/  391]   Loss 0.053443   Top1 98.166233   Top5 100.000000   BatchTime 0.103583   LR 0.001000   
2022-11-03 20:54:10,885 - INFO  - Training [20][  380/  391]   Loss 0.053288   Top1 98.168174   Top5 100.000000   BatchTime 0.102390   LR 0.001000   
2022-11-03 20:54:11,998 - INFO  - ==> Top1: 98.176    Top5: 100.000    Loss: 0.053

2022-11-03 20:54:12,000 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:54:14,524 - INFO  - Validation [20][   20/   79]   Loss 0.374127   Top1 90.234375   Top5 99.570312   BatchTime 0.126167   
2022-11-03 20:54:15,292 - INFO  - Validation [20][   40/   79]   Loss 0.395263   Top1 90.253906   Top5 99.511719   BatchTime 0.082270   
2022-11-03 20:54:16,110 - INFO  - Validation [20][   60/   79]   Loss 0.385775   Top1 90.351562   Top5 99.570312   BatchTime 0.068488   
2022-11-03 20:54:17,235 - INFO  - ==> Top1: 90.420    Top5: 99.580    Loss: 0.381

2022-11-03 20:54:17,273 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 90.420   Top5: 99.580] Sparsity : 0.735
2022-11-03 20:54:17,273 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.200   Top5: 99.640] Sparsity : 0.706
2022-11-03 20:54:17,274 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 89.950   Top5: 99.600] Sparsity : 0.724
2022-11-03 20:54:17,454 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:54:17,454 - INFO  - >>>>>>>> Epoch  21
2022-11-03 20:54:17,455 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:54:21,394 - INFO  - Training [21][   20/  391]   Loss 0.045800   Top1 98.398438   Top5 100.000000   BatchTime 0.196930   LR 0.001000   
2022-11-03 20:54:23,399 - INFO  - Training [21][   40/  391]   Loss 0.044844   Top1 98.554688   Top5 100.000000   BatchTime 0.148574   LR 0.001000   
2022-11-03 20:54:25,417 - INFO  - Training [21][   60/  391]   Loss 0.046505   Top1 98.541667   Top5 100.000000   BatchTime 0.132682   LR 0.001000   
2022-11-03 20:54:27,418 - INFO  - Training [21][   80/  391]   Loss 0.046603   Top1 98.447266   Top5 100.000000   BatchTime 0.124529   LR 0.001000   
2022-11-03 20:54:29,417 - INFO  - Training [21][  100/  391]   Loss 0.046011   Top1 98.484375   Top5 100.000000   BatchTime 0.119617   LR 0.001000   
2022-11-03 20:54:31,414 - INFO  - Training [21][  120/  391]   Loss 0.047438   Top1 98.411458   Top5 100.000000   BatchTime 0.116323   LR 0.001000   
2022-11-03 20:54:33,408 - INFO  - Training [21][  140/  391]   Loss 0.045805   Top1 98.443080   Top5 100.000000   BatchTime 0.113943   LR 0.001000   
2022-11-03 20:54:35,416 - INFO  - Training [21][  160/  391]   Loss 0.045663   Top1 98.447266   Top5 100.000000   BatchTime 0.112251   LR 0.001000   
2022-11-03 20:54:37,423 - INFO  - Training [21][  180/  391]   Loss 0.045092   Top1 98.472222   Top5 100.000000   BatchTime 0.110927   LR 0.001000   
2022-11-03 20:54:39,407 - INFO  - Training [21][  200/  391]   Loss 0.044797   Top1 98.480469   Top5 100.000000   BatchTime 0.109755   LR 0.001000   
2022-11-03 20:54:41,408 - INFO  - Training [21][  220/  391]   Loss 0.046166   Top1 98.423295   Top5 100.000000   BatchTime 0.108873   LR 0.001000   
2022-11-03 20:54:43,410 - INFO  - Training [21][  240/  391]   Loss 0.045437   Top1 98.450521   Top5 100.000000   BatchTime 0.108143   LR 0.001000   
2022-11-03 20:54:45,406 - INFO  - Training [21][  260/  391]   Loss 0.044123   Top1 98.518630   Top5 100.000000   BatchTime 0.107498   LR 0.001000   
2022-11-03 20:54:47,389 - INFO  - Training [21][  280/  391]   Loss 0.043422   Top1 98.543527   Top5 100.000000   BatchTime 0.106904   LR 0.001000   
2022-11-03 20:54:49,366 - INFO  - Training [21][  300/  391]   Loss 0.043236   Top1 98.541667   Top5 99.997396   BatchTime 0.106367   LR 0.001000   
2022-11-03 20:54:51,337 - INFO  - Training [21][  320/  391]   Loss 0.043440   Top1 98.540039   Top5 99.997559   BatchTime 0.105878   LR 0.001000   
2022-11-03 20:54:53,282 - INFO  - Training [21][  340/  391]   Loss 0.043955   Top1 98.506434   Top5 99.997702   BatchTime 0.105371   LR 0.001000   
2022-11-03 20:54:54,808 - INFO  - Training [21][  360/  391]   Loss 0.044133   Top1 98.502604   Top5 99.997830   BatchTime 0.103754   LR 0.001000   
2022-11-03 20:54:56,435 - INFO  - Training [21][  380/  391]   Loss 0.044548   Top1 98.474507   Top5 99.997944   BatchTime 0.102575   LR 0.001000   
2022-11-03 20:54:57,585 - INFO  - ==> Top1: 98.456    Top5: 99.998    Loss: 0.045

2022-11-03 20:54:57,585 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:55:00,095 - INFO  - Validation [21][   20/   79]   Loss 0.382407   Top1 90.468750   Top5 99.609375   BatchTime 0.125411   
2022-11-03 20:55:00,905 - INFO  - Validation [21][   40/   79]   Loss 0.395730   Top1 90.273438   Top5 99.511719   BatchTime 0.082977   
2022-11-03 20:55:01,815 - INFO  - Validation [21][   60/   79]   Loss 0.386637   Top1 90.507812   Top5 99.583333   BatchTime 0.070475   
2022-11-03 20:55:02,923 - INFO  - ==> Top1: 90.470    Top5: 99.600    Loss: 0.384

2022-11-03 20:55:02,961 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 90.470   Top5: 99.600] Sparsity : 0.736
2022-11-03 20:55:02,962 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.420   Top5: 99.580] Sparsity : 0.735
2022-11-03 20:55:02,962 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 90.200   Top5: 99.640] Sparsity : 0.706
2022-11-03 20:55:03,172 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:55:03,172 - INFO  - >>>>>>>> Epoch  22
2022-11-03 20:55:03,173 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:55:07,168 - INFO  - Training [22][   20/  391]   Loss 0.038167   Top1 98.710938   Top5 100.000000   BatchTime 0.199714   LR 0.001000   
2022-11-03 20:55:09,166 - INFO  - Training [22][   40/  391]   Loss 0.043714   Top1 98.535156   Top5 100.000000   BatchTime 0.149813   LR 0.001000   
2022-11-03 20:55:11,159 - INFO  - Training [22][   60/  391]   Loss 0.041077   Top1 98.619792   Top5 100.000000   BatchTime 0.133095   LR 0.001000   
2022-11-03 20:55:13,146 - INFO  - Training [22][   80/  391]   Loss 0.041862   Top1 98.613281   Top5 99.990234   BatchTime 0.124657   LR 0.001000   
2022-11-03 20:55:15,168 - INFO  - Training [22][  100/  391]   Loss 0.042647   Top1 98.554688   Top5 99.992188   BatchTime 0.119939   LR 0.001000   
2022-11-03 20:55:17,155 - INFO  - Training [22][  120/  391]   Loss 0.043974   Top1 98.470052   Top5 99.993490   BatchTime 0.116511   LR 0.001000   
2022-11-03 20:55:19,186 - INFO  - Training [22][  140/  391]   Loss 0.044513   Top1 98.448661   Top5 99.994420   BatchTime 0.114371   LR 0.001000   
2022-11-03 20:55:21,218 - INFO  - Training [22][  160/  391]   Loss 0.044957   Top1 98.471680   Top5 99.995117   BatchTime 0.112777   LR 0.001000   
2022-11-03 20:55:23,214 - INFO  - Training [22][  180/  391]   Loss 0.045713   Top1 98.415799   Top5 99.995660   BatchTime 0.111334   LR 0.001000   
2022-11-03 20:55:25,219 - INFO  - Training [22][  200/  391]   Loss 0.046150   Top1 98.398438   Top5 99.996094   BatchTime 0.110227   LR 0.001000   
2022-11-03 20:55:27,230 - INFO  - Training [22][  220/  391]   Loss 0.045227   Top1 98.430398   Top5 99.996449   BatchTime 0.109347   LR 0.001000   
2022-11-03 20:55:29,225 - INFO  - Training [22][  240/  391]   Loss 0.044515   Top1 98.466797   Top5 99.996745   BatchTime 0.108545   LR 0.001000   
2022-11-03 20:55:31,226 - INFO  - Training [22][  260/  391]   Loss 0.044287   Top1 98.491587   Top5 99.996995   BatchTime 0.107894   LR 0.001000   
2022-11-03 20:55:33,218 - INFO  - Training [22][  280/  391]   Loss 0.044239   Top1 98.496094   Top5 99.997210   BatchTime 0.107301   LR 0.001000   
2022-11-03 20:55:35,192 - INFO  - Training [22][  300/  391]   Loss 0.044415   Top1 98.492188   Top5 99.992188   BatchTime 0.106726   LR 0.001000   
2022-11-03 20:55:37,166 - INFO  - Training [22][  320/  391]   Loss 0.043912   Top1 98.513184   Top5 99.992676   BatchTime 0.106225   LR 0.001000   
2022-11-03 20:55:39,112 - INFO  - Training [22][  340/  391]   Loss 0.043654   Top1 98.517923   Top5 99.993107   BatchTime 0.105700   LR 0.001000   
2022-11-03 20:55:40,547 - INFO  - Training [22][  360/  391]   Loss 0.043419   Top1 98.526476   Top5 99.993490   BatchTime 0.103814   LR 0.001000   
2022-11-03 20:55:42,257 - INFO  - Training [22][  380/  391]   Loss 0.043700   Top1 98.517681   Top5 99.993832   BatchTime 0.102850   LR 0.001000   
2022-11-03 20:55:43,405 - INFO  - ==> Top1: 98.512    Top5: 99.994    Loss: 0.044

2022-11-03 20:55:43,406 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:55:46,127 - INFO  - Validation [22][   20/   79]   Loss 0.380970   Top1 90.156250   Top5 99.609375   BatchTime 0.135972   
2022-11-03 20:55:46,996 - INFO  - Validation [22][   40/   79]   Loss 0.395273   Top1 90.292969   Top5 99.492188   BatchTime 0.089718   
2022-11-03 20:55:47,901 - INFO  - Validation [22][   60/   79]   Loss 0.387075   Top1 90.494792   Top5 99.557292   BatchTime 0.074888   
2022-11-03 20:55:49,018 - INFO  - ==> Top1: 90.550    Top5: 99.580    Loss: 0.381

2022-11-03 20:55:49,063 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.550   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:55:49,063 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 90.470   Top5: 99.600] Sparsity : 0.736
2022-11-03 20:55:49,064 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.420   Top5: 99.580] Sparsity : 0.735
2022-11-03 20:55:49,254 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:55:49,254 - INFO  - >>>>>>>> Epoch  23
2022-11-03 20:55:49,256 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:55:53,101 - INFO  - Training [23][   20/  391]   Loss 0.042565   Top1 98.359375   Top5 100.000000   BatchTime 0.192261   LR 0.001000   
2022-11-03 20:55:55,124 - INFO  - Training [23][   40/  391]   Loss 0.041825   Top1 98.476562   Top5 100.000000   BatchTime 0.146688   LR 0.001000   
2022-11-03 20:55:57,142 - INFO  - Training [23][   60/  391]   Loss 0.042371   Top1 98.450521   Top5 100.000000   BatchTime 0.131431   LR 0.001000   
2022-11-03 20:55:59,175 - INFO  - Training [23][   80/  391]   Loss 0.043831   Top1 98.339844   Top5 100.000000   BatchTime 0.123984   LR 0.001000   
2022-11-03 20:56:01,181 - INFO  - Training [23][  100/  391]   Loss 0.041967   Top1 98.476562   Top5 100.000000   BatchTime 0.119242   LR 0.001000   
2022-11-03 20:56:03,179 - INFO  - Training [23][  120/  391]   Loss 0.041247   Top1 98.496094   Top5 100.000000   BatchTime 0.116022   LR 0.001000   
2022-11-03 20:56:05,188 - INFO  - Training [23][  140/  391]   Loss 0.041869   Top1 98.510045   Top5 100.000000   BatchTime 0.113799   LR 0.001000   
2022-11-03 20:56:07,192 - INFO  - Training [23][  160/  391]   Loss 0.042019   Top1 98.520508   Top5 100.000000   BatchTime 0.112099   LR 0.001000   
2022-11-03 20:56:09,214 - INFO  - Training [23][  180/  391]   Loss 0.042140   Top1 98.519965   Top5 100.000000   BatchTime 0.110876   LR 0.001000   
2022-11-03 20:56:11,239 - INFO  - Training [23][  200/  391]   Loss 0.042882   Top1 98.511719   Top5 100.000000   BatchTime 0.109912   LR 0.001000   
2022-11-03 20:56:13,247 - INFO  - Training [23][  220/  391]   Loss 0.041974   Top1 98.554688   Top5 100.000000   BatchTime 0.109048   LR 0.001000   
2022-11-03 20:56:15,247 - INFO  - Training [23][  240/  391]   Loss 0.042160   Top1 98.544922   Top5 100.000000   BatchTime 0.108295   LR 0.001000   
2022-11-03 20:56:17,264 - INFO  - Training [23][  260/  391]   Loss 0.041872   Top1 98.572716   Top5 100.000000   BatchTime 0.107722   LR 0.001000   
2022-11-03 20:56:19,267 - INFO  - Training [23][  280/  391]   Loss 0.042121   Top1 98.551897   Top5 100.000000   BatchTime 0.107179   LR 0.001000   
2022-11-03 20:56:21,251 - INFO  - Training [23][  300/  391]   Loss 0.042097   Top1 98.557292   Top5 100.000000   BatchTime 0.106646   LR 0.001000   
2022-11-03 20:56:23,251 - INFO  - Training [23][  320/  391]   Loss 0.042679   Top1 98.530273   Top5 100.000000   BatchTime 0.106232   LR 0.001000   
2022-11-03 20:56:25,146 - INFO  - Training [23][  340/  391]   Loss 0.042470   Top1 98.540901   Top5 100.000000   BatchTime 0.105556   LR 0.001000   
2022-11-03 20:56:26,692 - INFO  - Training [23][  360/  391]   Loss 0.042330   Top1 98.543837   Top5 100.000000   BatchTime 0.103985   LR 0.001000   
2022-11-03 20:56:28,326 - INFO  - Training [23][  380/  391]   Loss 0.041896   Top1 98.564967   Top5 100.000000   BatchTime 0.102813   LR 0.001000   
2022-11-03 20:56:29,462 - INFO  - ==> Top1: 98.570    Top5: 100.000    Loss: 0.042

2022-11-03 20:56:29,462 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:56:32,316 - INFO  - Validation [23][   20/   79]   Loss 0.371429   Top1 90.468750   Top5 99.570312   BatchTime 0.142609   
2022-11-03 20:56:33,206 - INFO  - Validation [23][   40/   79]   Loss 0.392002   Top1 90.410156   Top5 99.531250   BatchTime 0.093556   
2022-11-03 20:56:34,105 - INFO  - Validation [23][   60/   79]   Loss 0.385353   Top1 90.533854   Top5 99.544271   BatchTime 0.077364   
2022-11-03 20:56:35,244 - INFO  - ==> Top1: 90.630    Top5: 99.580    Loss: 0.381

2022-11-03 20:56:35,274 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.630   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:56:35,275 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.550   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:56:35,275 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 90.470   Top5: 99.600] Sparsity : 0.736
2022-11-03 20:56:35,449 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:56:35,450 - INFO  - >>>>>>>> Epoch  24
2022-11-03 20:56:35,451 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:56:39,380 - INFO  - Training [24][   20/  391]   Loss 0.045454   Top1 98.515625   Top5 100.000000   BatchTime 0.196458   LR 0.001000   
2022-11-03 20:56:41,402 - INFO  - Training [24][   40/  391]   Loss 0.036651   Top1 98.828125   Top5 100.000000   BatchTime 0.148768   LR 0.001000   
2022-11-03 20:56:43,416 - INFO  - Training [24][   60/  391]   Loss 0.039058   Top1 98.736979   Top5 100.000000   BatchTime 0.132751   LR 0.001000   
2022-11-03 20:56:45,506 - INFO  - Training [24][   80/  391]   Loss 0.038159   Top1 98.730469   Top5 100.000000   BatchTime 0.125682   LR 0.001000   
2022-11-03 20:56:47,527 - INFO  - Training [24][  100/  391]   Loss 0.038760   Top1 98.734375   Top5 100.000000   BatchTime 0.120762   LR 0.001000   
2022-11-03 20:56:49,528 - INFO  - Training [24][  120/  391]   Loss 0.038638   Top1 98.736979   Top5 100.000000   BatchTime 0.117308   LR 0.001000   
2022-11-03 20:56:51,515 - INFO  - Training [24][  140/  391]   Loss 0.037946   Top1 98.750000   Top5 100.000000   BatchTime 0.114738   LR 0.001000   
2022-11-03 20:56:53,545 - INFO  - Training [24][  160/  391]   Loss 0.038295   Top1 98.740234   Top5 100.000000   BatchTime 0.113083   LR 0.001000   
2022-11-03 20:56:55,567 - INFO  - Training [24][  180/  391]   Loss 0.037899   Top1 98.732639   Top5 100.000000   BatchTime 0.111756   LR 0.001000   
2022-11-03 20:56:57,584 - INFO  - Training [24][  200/  391]   Loss 0.038627   Top1 98.710938   Top5 100.000000   BatchTime 0.110662   LR 0.001000   
2022-11-03 20:56:59,599 - INFO  - Training [24][  220/  391]   Loss 0.038637   Top1 98.728693   Top5 100.000000   BatchTime 0.109762   LR 0.001000   
2022-11-03 20:57:01,613 - INFO  - Training [24][  240/  391]   Loss 0.038124   Top1 98.746745   Top5 100.000000   BatchTime 0.109007   LR 0.001000   
2022-11-03 20:57:03,628 - INFO  - Training [24][  260/  391]   Loss 0.037720   Top1 98.762019   Top5 100.000000   BatchTime 0.108371   LR 0.001000   
2022-11-03 20:57:05,618 - INFO  - Training [24][  280/  391]   Loss 0.038039   Top1 98.736049   Top5 100.000000   BatchTime 0.107737   LR 0.001000   
2022-11-03 20:57:07,590 - INFO  - Training [24][  300/  391]   Loss 0.038722   Top1 98.690104   Top5 100.000000   BatchTime 0.107127   LR 0.001000   
2022-11-03 20:57:09,568 - INFO  - Training [24][  320/  391]   Loss 0.039484   Top1 98.676758   Top5 100.000000   BatchTime 0.106615   LR 0.001000   
2022-11-03 20:57:11,258 - INFO  - Training [24][  340/  391]   Loss 0.039244   Top1 98.671875   Top5 100.000000   BatchTime 0.105314   LR 0.001000   
2022-11-03 20:57:12,856 - INFO  - Training [24][  360/  391]   Loss 0.039310   Top1 98.676215   Top5 100.000000   BatchTime 0.103900   LR 0.001000   
2022-11-03 20:57:14,415 - INFO  - Training [24][  380/  391]   Loss 0.039126   Top1 98.682155   Top5 100.000000   BatchTime 0.102534   LR 0.001000   
2022-11-03 20:57:15,541 - INFO  - ==> Top1: 98.682    Top5: 100.000    Loss: 0.039

2022-11-03 20:57:15,542 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:57:18,442 - INFO  - Validation [24][   20/   79]   Loss 0.381637   Top1 90.546875   Top5 99.492188   BatchTime 0.144951   
2022-11-03 20:57:19,339 - INFO  - Validation [24][   40/   79]   Loss 0.393323   Top1 90.488281   Top5 99.433594   BatchTime 0.094912   
2022-11-03 20:57:20,216 - INFO  - Validation [24][   60/   79]   Loss 0.384404   Top1 90.716146   Top5 99.518229   BatchTime 0.077888   
2022-11-03 20:57:21,331 - INFO  - ==> Top1: 90.780    Top5: 99.570    Loss: 0.381

2022-11-03 20:57:21,361 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 20:57:21,362 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.630   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:57:21,362 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 90.550   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:57:21,538 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 20:57:21,538 - INFO  - >>>>>>>> Epoch  25
2022-11-03 20:57:21,539 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:57:25,489 - INFO  - Training [25][   20/  391]   Loss 0.040426   Top1 98.828125   Top5 100.000000   BatchTime 0.197461   LR 0.001000   
2022-11-03 20:57:27,494 - INFO  - Training [25][   40/  391]   Loss 0.035711   Top1 98.867188   Top5 100.000000   BatchTime 0.148871   LR 0.001000   
2022-11-03 20:57:29,513 - INFO  - Training [25][   60/  391]   Loss 0.035714   Top1 98.828125   Top5 100.000000   BatchTime 0.132886   LR 0.001000   
2022-11-03 20:57:31,441 - INFO  - Training [25][   80/  391]   Loss 0.036886   Top1 98.818359   Top5 100.000000   BatchTime 0.123765   LR 0.001000   
2022-11-03 20:57:33,447 - INFO  - Training [25][  100/  391]   Loss 0.039356   Top1 98.726562   Top5 100.000000   BatchTime 0.119074   LR 0.001000   
2022-11-03 20:57:35,457 - INFO  - Training [25][  120/  391]   Loss 0.038243   Top1 98.769531   Top5 100.000000   BatchTime 0.115973   LR 0.001000   
2022-11-03 20:57:37,477 - INFO  - Training [25][  140/  391]   Loss 0.038980   Top1 98.688616   Top5 100.000000   BatchTime 0.113836   LR 0.001000   
2022-11-03 20:57:39,478 - INFO  - Training [25][  160/  391]   Loss 0.039661   Top1 98.666992   Top5 100.000000   BatchTime 0.112110   LR 0.001000   
2022-11-03 20:57:41,480 - INFO  - Training [25][  180/  391]   Loss 0.039282   Top1 98.689236   Top5 100.000000   BatchTime 0.110778   LR 0.001000   
2022-11-03 20:57:43,488 - INFO  - Training [25][  200/  391]   Loss 0.039619   Top1 98.691406   Top5 100.000000   BatchTime 0.109740   LR 0.001000   
2022-11-03 20:57:45,477 - INFO  - Training [25][  220/  391]   Loss 0.039545   Top1 98.689631   Top5 100.000000   BatchTime 0.108805   LR 0.001000   
2022-11-03 20:57:47,485 - INFO  - Training [25][  240/  391]   Loss 0.039573   Top1 98.665365   Top5 100.000000   BatchTime 0.108104   LR 0.001000   
2022-11-03 20:57:49,519 - INFO  - Training [25][  260/  391]   Loss 0.039098   Top1 98.674880   Top5 100.000000   BatchTime 0.107611   LR 0.001000   
2022-11-03 20:57:51,510 - INFO  - Training [25][  280/  391]   Loss 0.039091   Top1 98.677455   Top5 100.000000   BatchTime 0.107035   LR 0.001000   
2022-11-03 20:57:53,478 - INFO  - Training [25][  300/  391]   Loss 0.038967   Top1 98.692708   Top5 100.000000   BatchTime 0.106458   LR 0.001000   
2022-11-03 20:57:55,455 - INFO  - Training [25][  320/  391]   Loss 0.039265   Top1 98.684082   Top5 100.000000   BatchTime 0.105983   LR 0.001000   
2022-11-03 20:57:57,173 - INFO  - Training [25][  340/  391]   Loss 0.039746   Top1 98.676471   Top5 100.000000   BatchTime 0.104802   LR 0.001000   
2022-11-03 20:57:58,808 - INFO  - Training [25][  360/  391]   Loss 0.039817   Top1 98.663194   Top5 100.000000   BatchTime 0.103522   LR 0.001000   
2022-11-03 20:58:00,433 - INFO  - Training [25][  380/  391]   Loss 0.039970   Top1 98.649260   Top5 100.000000   BatchTime 0.102349   LR 0.001000   
2022-11-03 20:58:01,704 - INFO  - ==> Top1: 98.646    Top5: 100.000    Loss: 0.040

2022-11-03 20:58:01,705 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:58:04,663 - INFO  - Validation [25][   20/   79]   Loss 0.376465   Top1 90.429688   Top5 99.648438   BatchTime 0.147710   
2022-11-03 20:58:05,553 - INFO  - Validation [25][   40/   79]   Loss 0.391892   Top1 90.371094   Top5 99.550781   BatchTime 0.096103   
2022-11-03 20:58:06,455 - INFO  - Validation [25][   60/   79]   Loss 0.385312   Top1 90.598958   Top5 99.609375   BatchTime 0.079108   
2022-11-03 20:58:07,580 - INFO  - ==> Top1: 90.610    Top5: 99.640    Loss: 0.384

2022-11-03 20:58:07,616 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 20:58:07,617 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.630   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:58:07,617 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.610   Top5: 99.640] Sparsity : 0.737
2022-11-03 20:58:07,723 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:58:07,724 - INFO  - >>>>>>>> Epoch  26
2022-11-03 20:58:07,725 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:58:11,644 - INFO  - Training [26][   20/  391]   Loss 0.037706   Top1 98.671875   Top5 100.000000   BatchTime 0.195962   LR 0.001000   
2022-11-03 20:58:13,646 - INFO  - Training [26][   40/  391]   Loss 0.036214   Top1 98.828125   Top5 100.000000   BatchTime 0.148024   LR 0.001000   
2022-11-03 20:58:15,651 - INFO  - Training [26][   60/  391]   Loss 0.036160   Top1 98.776042   Top5 100.000000   BatchTime 0.132096   LR 0.001000   
2022-11-03 20:58:17,666 - INFO  - Training [26][   80/  391]   Loss 0.037974   Top1 98.730469   Top5 100.000000   BatchTime 0.124271   LR 0.001000   
2022-11-03 20:58:19,685 - INFO  - Training [26][  100/  391]   Loss 0.038063   Top1 98.726562   Top5 100.000000   BatchTime 0.119598   LR 0.001000   
2022-11-03 20:58:21,685 - INFO  - Training [26][  120/  391]   Loss 0.037209   Top1 98.710938   Top5 100.000000   BatchTime 0.116330   LR 0.001000   
2022-11-03 20:58:23,826 - INFO  - Training [26][  140/  391]   Loss 0.036677   Top1 98.727679   Top5 100.000000   BatchTime 0.115011   LR 0.001000   
2022-11-03 20:58:25,844 - INFO  - Training [26][  160/  391]   Loss 0.037218   Top1 98.710938   Top5 100.000000   BatchTime 0.113246   LR 0.001000   
2022-11-03 20:58:27,858 - INFO  - Training [26][  180/  391]   Loss 0.037418   Top1 98.706597   Top5 100.000000   BatchTime 0.111849   LR 0.001000   
2022-11-03 20:58:29,865 - INFO  - Training [26][  200/  391]   Loss 0.036944   Top1 98.718750   Top5 100.000000   BatchTime 0.110699   LR 0.001000   
2022-11-03 20:58:31,874 - INFO  - Training [26][  220/  391]   Loss 0.037656   Top1 98.703835   Top5 100.000000   BatchTime 0.109766   LR 0.001000   
2022-11-03 20:58:33,883 - INFO  - Training [26][  240/  391]   Loss 0.037208   Top1 98.723958   Top5 100.000000   BatchTime 0.108989   LR 0.001000   
2022-11-03 20:58:35,879 - INFO  - Training [26][  260/  391]   Loss 0.036995   Top1 98.725962   Top5 100.000000   BatchTime 0.108283   LR 0.001000   
2022-11-03 20:58:37,844 - INFO  - Training [26][  280/  391]   Loss 0.036449   Top1 98.747210   Top5 100.000000   BatchTime 0.107568   LR 0.001000   
2022-11-03 20:58:39,811 - INFO  - Training [26][  300/  391]   Loss 0.036217   Top1 98.755208   Top5 100.000000   BatchTime 0.106954   LR 0.001000   
2022-11-03 20:58:41,879 - INFO  - Training [26][  320/  391]   Loss 0.036753   Top1 98.740234   Top5 100.000000   BatchTime 0.106730   LR 0.001000   
2022-11-03 20:58:43,363 - INFO  - Training [26][  340/  391]   Loss 0.036991   Top1 98.720129   Top5 99.997702   BatchTime 0.104817   LR 0.001000   
2022-11-03 20:58:45,055 - INFO  - Training [26][  360/  391]   Loss 0.037176   Top1 98.706597   Top5 99.997830   BatchTime 0.103693   LR 0.001000   
2022-11-03 20:58:46,662 - INFO  - Training [26][  380/  391]   Loss 0.037524   Top1 98.692434   Top5 99.997944   BatchTime 0.102465   LR 0.001000   
2022-11-03 20:58:47,876 - INFO  - ==> Top1: 98.698    Top5: 99.998    Loss: 0.037

2022-11-03 20:58:47,876 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:58:50,770 - INFO  - Validation [26][   20/   79]   Loss 0.385890   Top1 90.390625   Top5 99.609375   BatchTime 0.144644   
2022-11-03 20:58:51,684 - INFO  - Validation [26][   40/   79]   Loss 0.396848   Top1 90.507812   Top5 99.550781   BatchTime 0.095172   
2022-11-03 20:58:52,612 - INFO  - Validation [26][   60/   79]   Loss 0.388705   Top1 90.690104   Top5 99.596354   BatchTime 0.078910   
2022-11-03 20:58:53,780 - INFO  - ==> Top1: 90.750    Top5: 99.640    Loss: 0.383

2022-11-03 20:58:53,809 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 20:58:53,809 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 20:58:53,810 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.630   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:58:53,999 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:58:53,999 - INFO  - >>>>>>>> Epoch  27
2022-11-03 20:58:54,001 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:58:57,893 - INFO  - Training [27][   20/  391]   Loss 0.034027   Top1 98.984375   Top5 100.000000   BatchTime 0.194581   LR 0.001000   
2022-11-03 20:58:59,903 - INFO  - Training [27][   40/  391]   Loss 0.038485   Top1 98.769531   Top5 100.000000   BatchTime 0.147540   LR 0.001000   
2022-11-03 20:59:01,909 - INFO  - Training [27][   60/  391]   Loss 0.037924   Top1 98.854167   Top5 100.000000   BatchTime 0.131797   LR 0.001000   
2022-11-03 20:59:03,927 - INFO  - Training [27][   80/  391]   Loss 0.039032   Top1 98.789062   Top5 100.000000   BatchTime 0.124077   LR 0.001000   
2022-11-03 20:59:05,914 - INFO  - Training [27][  100/  391]   Loss 0.038331   Top1 98.796875   Top5 100.000000   BatchTime 0.119132   LR 0.001000   
2022-11-03 20:59:07,928 - INFO  - Training [27][  120/  391]   Loss 0.037749   Top1 98.808594   Top5 100.000000   BatchTime 0.116059   LR 0.001000   
2022-11-03 20:59:09,930 - INFO  - Training [27][  140/  391]   Loss 0.037154   Top1 98.833705   Top5 99.994420   BatchTime 0.113776   LR 0.001000   
2022-11-03 20:59:11,938 - INFO  - Training [27][  160/  391]   Loss 0.036266   Top1 98.862305   Top5 99.995117   BatchTime 0.112103   LR 0.001000   
2022-11-03 20:59:13,946 - INFO  - Training [27][  180/  391]   Loss 0.036236   Top1 98.867188   Top5 99.995660   BatchTime 0.110805   LR 0.001000   
2022-11-03 20:59:15,946 - INFO  - Training [27][  200/  391]   Loss 0.037516   Top1 98.785156   Top5 99.996094   BatchTime 0.109723   LR 0.001000   
2022-11-03 20:59:17,954 - INFO  - Training [27][  220/  391]   Loss 0.037692   Top1 98.767756   Top5 99.996449   BatchTime 0.108875   LR 0.001000   
2022-11-03 20:59:19,984 - INFO  - Training [27][  240/  391]   Loss 0.037701   Top1 98.769531   Top5 99.996745   BatchTime 0.108260   LR 0.001000   
2022-11-03 20:59:21,980 - INFO  - Training [27][  260/  391]   Loss 0.037267   Top1 98.771034   Top5 99.996995   BatchTime 0.107609   LR 0.001000   
2022-11-03 20:59:23,961 - INFO  - Training [27][  280/  391]   Loss 0.037121   Top1 98.766741   Top5 99.997210   BatchTime 0.106999   LR 0.001000   
2022-11-03 20:59:25,938 - INFO  - Training [27][  300/  391]   Loss 0.037032   Top1 98.773438   Top5 99.997396   BatchTime 0.106453   LR 0.001000   
2022-11-03 20:59:27,909 - INFO  - Training [27][  320/  391]   Loss 0.036636   Top1 98.784180   Top5 99.997559   BatchTime 0.105961   LR 0.001000   
2022-11-03 20:59:29,461 - INFO  - Training [27][  340/  391]   Loss 0.036406   Top1 98.793658   Top5 99.997702   BatchTime 0.104292   LR 0.001000   
2022-11-03 20:59:31,123 - INFO  - Training [27][  360/  391]   Loss 0.036708   Top1 98.786892   Top5 99.997830   BatchTime 0.103114   LR 0.001000   
2022-11-03 20:59:32,738 - INFO  - Training [27][  380/  391]   Loss 0.036881   Top1 98.778783   Top5 99.997944   BatchTime 0.101938   LR 0.001000   
2022-11-03 20:59:34,020 - INFO  - ==> Top1: 98.776    Top5: 99.998    Loss: 0.037

2022-11-03 20:59:34,021 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 20:59:36,877 - INFO  - Validation [27][   20/   79]   Loss 0.383793   Top1 90.312500   Top5 99.570312   BatchTime 0.142734   
2022-11-03 20:59:37,801 - INFO  - Validation [27][   40/   79]   Loss 0.399553   Top1 90.273438   Top5 99.472656   BatchTime 0.094466   
2022-11-03 20:59:38,714 - INFO  - Validation [27][   60/   79]   Loss 0.388814   Top1 90.598958   Top5 99.531250   BatchTime 0.078193   
2022-11-03 20:59:39,854 - INFO  - ==> Top1: 90.520    Top5: 99.570    Loss: 0.387

2022-11-03 20:59:39,898 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 20:59:39,899 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 20:59:39,899 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.630   Top5: 99.580] Sparsity : 0.736
2022-11-03 20:59:40,001 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 20:59:40,002 - INFO  - >>>>>>>> Epoch  28
2022-11-03 20:59:40,003 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 20:59:43,934 - INFO  - Training [28][   20/  391]   Loss 0.032260   Top1 98.984375   Top5 100.000000   BatchTime 0.196560   LR 0.001000   
2022-11-03 20:59:45,968 - INFO  - Training [28][   40/  391]   Loss 0.037906   Top1 98.710938   Top5 100.000000   BatchTime 0.149110   LR 0.001000   
2022-11-03 20:59:48,002 - INFO  - Training [28][   60/  391]   Loss 0.038764   Top1 98.736979   Top5 100.000000   BatchTime 0.133309   LR 0.001000   
2022-11-03 20:59:50,012 - INFO  - Training [28][   80/  391]   Loss 0.038129   Top1 98.759766   Top5 100.000000   BatchTime 0.125112   LR 0.001000   
2022-11-03 20:59:52,007 - INFO  - Training [28][  100/  391]   Loss 0.038390   Top1 98.734375   Top5 100.000000   BatchTime 0.120034   LR 0.001000   
2022-11-03 20:59:54,019 - INFO  - Training [28][  120/  391]   Loss 0.038091   Top1 98.730469   Top5 100.000000   BatchTime 0.116797   LR 0.001000   
2022-11-03 20:59:56,026 - INFO  - Training [28][  140/  391]   Loss 0.037356   Top1 98.750000   Top5 100.000000   BatchTime 0.114446   LR 0.001000   
2022-11-03 20:59:58,050 - INFO  - Training [28][  160/  391]   Loss 0.037496   Top1 98.730469   Top5 100.000000   BatchTime 0.112793   LR 0.001000   
2022-11-03 21:00:00,045 - INFO  - Training [28][  180/  391]   Loss 0.036913   Top1 98.754340   Top5 100.000000   BatchTime 0.111343   LR 0.001000   
2022-11-03 21:00:02,130 - INFO  - Training [28][  200/  391]   Loss 0.036812   Top1 98.753906   Top5 100.000000   BatchTime 0.110633   LR 0.001000   
2022-11-03 21:00:04,138 - INFO  - Training [28][  220/  391]   Loss 0.036196   Top1 98.767756   Top5 100.000000   BatchTime 0.109702   LR 0.001000   
2022-11-03 21:00:06,137 - INFO  - Training [28][  240/  391]   Loss 0.035801   Top1 98.782552   Top5 100.000000   BatchTime 0.108890   LR 0.001000   
2022-11-03 21:00:08,142 - INFO  - Training [28][  260/  391]   Loss 0.036164   Top1 98.777043   Top5 100.000000   BatchTime 0.108223   LR 0.001000   
2022-11-03 21:00:10,121 - INFO  - Training [28][  280/  391]   Loss 0.036940   Top1 98.761161   Top5 100.000000   BatchTime 0.107560   LR 0.001000   
2022-11-03 21:00:12,112 - INFO  - Training [28][  300/  391]   Loss 0.036659   Top1 98.747396   Top5 100.000000   BatchTime 0.107026   LR 0.001000   
2022-11-03 21:00:13,952 - INFO  - Training [28][  320/  391]   Loss 0.037265   Top1 98.710938   Top5 100.000000   BatchTime 0.106086   LR 0.001000   
2022-11-03 21:00:15,549 - INFO  - Training [28][  340/  391]   Loss 0.037501   Top1 98.699449   Top5 100.000000   BatchTime 0.104544   LR 0.001000   
2022-11-03 21:00:17,124 - INFO  - Training [28][  360/  391]   Loss 0.037792   Top1 98.682726   Top5 99.997830   BatchTime 0.103112   LR 0.001000   
2022-11-03 21:00:18,805 - INFO  - Training [28][  380/  391]   Loss 0.038226   Top1 98.673931   Top5 99.997944   BatchTime 0.102107   LR 0.001000   
2022-11-03 21:00:19,850 - INFO  - ==> Top1: 98.670    Top5: 99.998    Loss: 0.038

2022-11-03 21:00:19,851 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:00:22,744 - INFO  - Validation [28][   20/   79]   Loss 0.379617   Top1 90.390625   Top5 99.570312   BatchTime 0.144522   
2022-11-03 21:00:23,633 - INFO  - Validation [28][   40/   79]   Loss 0.399843   Top1 90.527344   Top5 99.492188   BatchTime 0.094494   
2022-11-03 21:00:24,526 - INFO  - Validation [28][   60/   79]   Loss 0.389656   Top1 90.820312   Top5 99.531250   BatchTime 0.077880   
2022-11-03 21:00:25,645 - INFO  - ==> Top1: 90.780    Top5: 99.570    Loss: 0.386

2022-11-03 21:00:25,696 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:00:25,697 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:00:25,697 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:00:25,872 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_best.pth.tar

2022-11-03 21:00:25,872 - INFO  - >>>>>>>> Epoch  29
2022-11-03 21:00:25,873 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:00:29,823 - INFO  - Training [29][   20/  391]   Loss 0.032033   Top1 98.828125   Top5 100.000000   BatchTime 0.197505   LR 0.001000   
2022-11-03 21:00:31,851 - INFO  - Training [29][   40/  391]   Loss 0.032505   Top1 98.828125   Top5 100.000000   BatchTime 0.149451   LR 0.001000   
2022-11-03 21:00:33,850 - INFO  - Training [29][   60/  391]   Loss 0.033419   Top1 98.710938   Top5 100.000000   BatchTime 0.132943   LR 0.001000   
2022-11-03 21:00:35,862 - INFO  - Training [29][   80/  391]   Loss 0.034821   Top1 98.662109   Top5 100.000000   BatchTime 0.124855   LR 0.001000   
2022-11-03 21:00:37,882 - INFO  - Training [29][  100/  391]   Loss 0.034754   Top1 98.703125   Top5 100.000000   BatchTime 0.120087   LR 0.001000   
2022-11-03 21:00:39,891 - INFO  - Training [29][  120/  391]   Loss 0.032939   Top1 98.802083   Top5 100.000000   BatchTime 0.116814   LR 0.001000   
2022-11-03 21:00:41,901 - INFO  - Training [29][  140/  391]   Loss 0.033494   Top1 98.805804   Top5 100.000000   BatchTime 0.114482   LR 0.001000   
2022-11-03 21:00:43,920 - INFO  - Training [29][  160/  391]   Loss 0.034510   Top1 98.779297   Top5 100.000000   BatchTime 0.112789   LR 0.001000   
2022-11-03 21:00:45,918 - INFO  - Training [29][  180/  391]   Loss 0.034723   Top1 98.780382   Top5 100.000000   BatchTime 0.111361   LR 0.001000   
2022-11-03 21:00:47,929 - INFO  - Training [29][  200/  391]   Loss 0.035739   Top1 98.757812   Top5 99.996094   BatchTime 0.110276   LR 0.001000   
2022-11-03 21:00:49,957 - INFO  - Training [29][  220/  391]   Loss 0.035438   Top1 98.781960   Top5 99.996449   BatchTime 0.109469   LR 0.001000   
2022-11-03 21:00:51,959 - INFO  - Training [29][  240/  391]   Loss 0.035127   Top1 98.802083   Top5 99.996745   BatchTime 0.108688   LR 0.001000   
2022-11-03 21:00:53,929 - INFO  - Training [29][  260/  391]   Loss 0.035057   Top1 98.822115   Top5 99.990986   BatchTime 0.107906   LR 0.001000   
2022-11-03 21:00:55,903 - INFO  - Training [29][  280/  391]   Loss 0.034897   Top1 98.828125   Top5 99.991629   BatchTime 0.107249   LR 0.001000   
2022-11-03 21:00:57,892 - INFO  - Training [29][  300/  391]   Loss 0.034299   Top1 98.854167   Top5 99.992188   BatchTime 0.106729   LR 0.001000   
2022-11-03 21:00:59,673 - INFO  - Training [29][  320/  391]   Loss 0.034605   Top1 98.835449   Top5 99.992676   BatchTime 0.105624   LR 0.001000   
2022-11-03 21:01:01,341 - INFO  - Training [29][  340/  391]   Loss 0.034450   Top1 98.839614   Top5 99.993107   BatchTime 0.104316   LR 0.001000   
2022-11-03 21:01:02,938 - INFO  - Training [29][  360/  391]   Loss 0.034761   Top1 98.825955   Top5 99.993490   BatchTime 0.102956   LR 0.001000   
2022-11-03 21:01:04,633 - INFO  - Training [29][  380/  391]   Loss 0.035366   Top1 98.801398   Top5 99.993832   BatchTime 0.101998   LR 0.001000   
2022-11-03 21:01:05,682 - INFO  - ==> Top1: 98.800    Top5: 99.994    Loss: 0.035

2022-11-03 21:01:05,683 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:01:08,499 - INFO  - Validation [29][   20/   79]   Loss 0.386714   Top1 90.390625   Top5 99.531250   BatchTime 0.140741   
2022-11-03 21:01:09,431 - INFO  - Validation [29][   40/   79]   Loss 0.399753   Top1 90.351562   Top5 99.511719   BatchTime 0.093687   
2022-11-03 21:01:10,330 - INFO  - Validation [29][   60/   79]   Loss 0.393321   Top1 90.481771   Top5 99.583333   BatchTime 0.077439   
2022-11-03 21:01:11,441 - INFO  - ==> Top1: 90.540    Top5: 99.590    Loss: 0.391

2022-11-03 21:01:11,480 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:01:11,481 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:01:11,481 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:01:11,588 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:01:11,588 - INFO  - >>>>>>>> Epoch  30
2022-11-03 21:01:11,590 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:01:15,465 - INFO  - Training [30][   20/  391]   Loss 0.038427   Top1 98.632812   Top5 100.000000   BatchTime 0.193760   LR 0.001000   
2022-11-03 21:01:17,472 - INFO  - Training [30][   40/  391]   Loss 0.035250   Top1 98.886719   Top5 100.000000   BatchTime 0.147044   LR 0.001000   
2022-11-03 21:01:19,485 - INFO  - Training [30][   60/  391]   Loss 0.036385   Top1 98.789062   Top5 100.000000   BatchTime 0.131585   LR 0.001000   
2022-11-03 21:01:21,500 - INFO  - Training [30][   80/  391]   Loss 0.036403   Top1 98.720703   Top5 100.000000   BatchTime 0.123882   LR 0.001000   
2022-11-03 21:01:23,506 - INFO  - Training [30][  100/  391]   Loss 0.036430   Top1 98.703125   Top5 100.000000   BatchTime 0.119161   LR 0.001000   
2022-11-03 21:01:25,517 - INFO  - Training [30][  120/  391]   Loss 0.036900   Top1 98.684896   Top5 100.000000   BatchTime 0.116057   LR 0.001000   
2022-11-03 21:01:27,525 - INFO  - Training [30][  140/  391]   Loss 0.035770   Top1 98.733259   Top5 100.000000   BatchTime 0.113822   LR 0.001000   
2022-11-03 21:01:29,508 - INFO  - Training [30][  160/  391]   Loss 0.034745   Top1 98.769531   Top5 100.000000   BatchTime 0.111984   LR 0.001000   
2022-11-03 21:01:31,506 - INFO  - Training [30][  180/  391]   Loss 0.033982   Top1 98.789062   Top5 100.000000   BatchTime 0.110643   LR 0.001000   
2022-11-03 21:01:33,496 - INFO  - Training [30][  200/  391]   Loss 0.034508   Top1 98.777344   Top5 100.000000   BatchTime 0.109528   LR 0.001000   
2022-11-03 21:01:35,496 - INFO  - Training [30][  220/  391]   Loss 0.034181   Top1 98.789062   Top5 100.000000   BatchTime 0.108662   LR 0.001000   
2022-11-03 21:01:37,590 - INFO  - Training [30][  240/  391]   Loss 0.034002   Top1 98.798828   Top5 100.000000   BatchTime 0.108332   LR 0.001000   
2022-11-03 21:01:39,563 - INFO  - Training [30][  260/  391]   Loss 0.034428   Top1 98.792067   Top5 100.000000   BatchTime 0.107589   LR 0.001000   
2022-11-03 21:01:41,539 - INFO  - Training [30][  280/  391]   Loss 0.034719   Top1 98.777902   Top5 100.000000   BatchTime 0.106959   LR 0.001000   
2022-11-03 21:01:43,529 - INFO  - Training [30][  300/  391]   Loss 0.034662   Top1 98.781250   Top5 100.000000   BatchTime 0.106463   LR 0.001000   
2022-11-03 21:01:45,285 - INFO  - Training [30][  320/  391]   Loss 0.035177   Top1 98.759766   Top5 100.000000   BatchTime 0.105295   LR 0.001000   
2022-11-03 21:01:46,953 - INFO  - Training [30][  340/  391]   Loss 0.035554   Top1 98.747702   Top5 100.000000   BatchTime 0.104008   LR 0.001000   
2022-11-03 21:01:48,590 - INFO  - Training [30][  360/  391]   Loss 0.035655   Top1 98.739149   Top5 100.000000   BatchTime 0.102777   LR 0.001000   
2022-11-03 21:01:50,272 - INFO  - Training [30][  380/  391]   Loss 0.035390   Top1 98.754112   Top5 100.000000   BatchTime 0.101794   LR 0.001000   
2022-11-03 21:01:51,330 - INFO  - ==> Top1: 98.752    Top5: 100.000    Loss: 0.035

2022-11-03 21:01:51,331 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:01:54,150 - INFO  - Validation [30][   20/   79]   Loss 0.391828   Top1 90.585938   Top5 99.531250   BatchTime 0.140869   
2022-11-03 21:01:55,047 - INFO  - Validation [30][   40/   79]   Loss 0.407528   Top1 90.429688   Top5 99.550781   BatchTime 0.092841   
2022-11-03 21:01:55,949 - INFO  - Validation [30][   60/   79]   Loss 0.398653   Top1 90.638021   Top5 99.609375   BatchTime 0.076928   
2022-11-03 21:01:57,060 - INFO  - ==> Top1: 90.620    Top5: 99.630    Loss: 0.393

2022-11-03 21:01:57,109 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:01:57,110 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:01:57,110 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:01:57,212 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:01:57,212 - INFO  - >>>>>>>> Epoch  31
2022-11-03 21:01:57,214 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:02:01,119 - INFO  - Training [31][   20/  391]   Loss 0.035206   Top1 98.828125   Top5 100.000000   BatchTime 0.195220   LR 0.001000   
2022-11-03 21:02:03,136 - INFO  - Training [31][   40/  391]   Loss 0.031414   Top1 99.062500   Top5 100.000000   BatchTime 0.148041   LR 0.001000   
2022-11-03 21:02:05,140 - INFO  - Training [31][   60/  391]   Loss 0.030863   Top1 99.036458   Top5 100.000000   BatchTime 0.132097   LR 0.001000   
2022-11-03 21:02:07,147 - INFO  - Training [31][   80/  391]   Loss 0.031569   Top1 99.003906   Top5 100.000000   BatchTime 0.124166   LR 0.001000   
2022-11-03 21:02:09,127 - INFO  - Training [31][  100/  391]   Loss 0.032447   Top1 98.929688   Top5 100.000000   BatchTime 0.119125   LR 0.001000   
2022-11-03 21:02:11,133 - INFO  - Training [31][  120/  391]   Loss 0.032790   Top1 98.925781   Top5 100.000000   BatchTime 0.115993   LR 0.001000   
2022-11-03 21:02:13,162 - INFO  - Training [31][  140/  391]   Loss 0.032642   Top1 98.934152   Top5 100.000000   BatchTime 0.113912   LR 0.001000   
2022-11-03 21:02:15,165 - INFO  - Training [31][  160/  391]   Loss 0.033090   Top1 98.920898   Top5 100.000000   BatchTime 0.112190   LR 0.001000   
2022-11-03 21:02:17,091 - INFO  - Training [31][  180/  391]   Loss 0.033242   Top1 98.914931   Top5 100.000000   BatchTime 0.110423   LR 0.001000   
2022-11-03 21:02:19,097 - INFO  - Training [31][  200/  391]   Loss 0.033654   Top1 98.886719   Top5 100.000000   BatchTime 0.109411   LR 0.001000   
2022-11-03 21:02:21,121 - INFO  - Training [31][  220/  391]   Loss 0.033864   Top1 98.874290   Top5 100.000000   BatchTime 0.108664   LR 0.001000   
2022-11-03 21:02:23,135 - INFO  - Training [31][  240/  391]   Loss 0.033984   Top1 98.870443   Top5 100.000000   BatchTime 0.108002   LR 0.001000   
2022-11-03 21:02:25,115 - INFO  - Training [31][  260/  391]   Loss 0.033943   Top1 98.888221   Top5 100.000000   BatchTime 0.107310   LR 0.001000   
2022-11-03 21:02:27,085 - INFO  - Training [31][  280/  391]   Loss 0.034370   Top1 98.861607   Top5 100.000000   BatchTime 0.106678   LR 0.001000   
2022-11-03 21:02:29,043 - INFO  - Training [31][  300/  391]   Loss 0.034135   Top1 98.869792   Top5 100.000000   BatchTime 0.106094   LR 0.001000   
2022-11-03 21:02:30,804 - INFO  - Training [31][  320/  391]   Loss 0.033930   Top1 98.864746   Top5 100.000000   BatchTime 0.104966   LR 0.001000   
2022-11-03 21:02:32,488 - INFO  - Training [31][  340/  391]   Loss 0.034101   Top1 98.844210   Top5 100.000000   BatchTime 0.103743   LR 0.001000   
2022-11-03 21:02:34,060 - INFO  - Training [31][  360/  391]   Loss 0.034172   Top1 98.845486   Top5 100.000000   BatchTime 0.102346   LR 0.001000   
2022-11-03 21:02:35,715 - INFO  - Training [31][  380/  391]   Loss 0.034440   Top1 98.836349   Top5 100.000000   BatchTime 0.101317   LR 0.001000   
2022-11-03 21:02:36,773 - INFO  - ==> Top1: 98.840    Top5: 100.000    Loss: 0.034

2022-11-03 21:02:36,774 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:02:39,617 - INFO  - Validation [31][   20/   79]   Loss 0.388808   Top1 90.585938   Top5 99.570312   BatchTime 0.142060   
2022-11-03 21:02:40,520 - INFO  - Validation [31][   40/   79]   Loss 0.404656   Top1 90.468750   Top5 99.472656   BatchTime 0.093603   
2022-11-03 21:02:41,417 - INFO  - Validation [31][   60/   79]   Loss 0.396383   Top1 90.677083   Top5 99.570312   BatchTime 0.077342   
2022-11-03 21:02:42,543 - INFO  - ==> Top1: 90.690    Top5: 99.590    Loss: 0.391

2022-11-03 21:02:42,583 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:02:42,583 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:02:42,583 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:02:42,679 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:02:42,679 - INFO  - >>>>>>>> Epoch  32
2022-11-03 21:02:42,681 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:02:46,566 - INFO  - Training [32][   20/  391]   Loss 0.039658   Top1 98.867188   Top5 100.000000   BatchTime 0.194255   LR 0.001000   
2022-11-03 21:02:48,568 - INFO  - Training [32][   40/  391]   Loss 0.036792   Top1 98.828125   Top5 100.000000   BatchTime 0.147169   LR 0.001000   
2022-11-03 21:02:50,559 - INFO  - Training [32][   60/  391]   Loss 0.034359   Top1 98.867188   Top5 100.000000   BatchTime 0.131301   LR 0.001000   
2022-11-03 21:02:52,567 - INFO  - Training [32][   80/  391]   Loss 0.034114   Top1 98.867188   Top5 100.000000   BatchTime 0.123576   LR 0.001000   
2022-11-03 21:02:54,579 - INFO  - Training [32][  100/  391]   Loss 0.037559   Top1 98.773438   Top5 100.000000   BatchTime 0.118982   LR 0.001000   
2022-11-03 21:02:56,591 - INFO  - Training [32][  120/  391]   Loss 0.036449   Top1 98.782552   Top5 100.000000   BatchTime 0.115919   LR 0.001000   
2022-11-03 21:02:58,602 - INFO  - Training [32][  140/  391]   Loss 0.036404   Top1 98.772321   Top5 100.000000   BatchTime 0.113717   LR 0.001000   
2022-11-03 21:03:00,593 - INFO  - Training [32][  160/  391]   Loss 0.036697   Top1 98.764648   Top5 100.000000   BatchTime 0.111949   LR 0.001000   
2022-11-03 21:03:02,592 - INFO  - Training [32][  180/  391]   Loss 0.036104   Top1 98.793403   Top5 100.000000   BatchTime 0.110614   LR 0.001000   
2022-11-03 21:03:04,592 - INFO  - Training [32][  200/  391]   Loss 0.035809   Top1 98.792969   Top5 100.000000   BatchTime 0.109554   LR 0.001000   
2022-11-03 21:03:06,610 - INFO  - Training [32][  220/  391]   Loss 0.035813   Top1 98.792614   Top5 100.000000   BatchTime 0.108765   LR 0.001000   
2022-11-03 21:03:08,627 - INFO  - Training [32][  240/  391]   Loss 0.035556   Top1 98.795573   Top5 100.000000   BatchTime 0.108108   LR 0.001000   
2022-11-03 21:03:10,614 - INFO  - Training [32][  260/  391]   Loss 0.035646   Top1 98.783053   Top5 100.000000   BatchTime 0.107433   LR 0.001000   
2022-11-03 21:03:12,594 - INFO  - Training [32][  280/  391]   Loss 0.035733   Top1 98.786272   Top5 100.000000   BatchTime 0.106831   LR 0.001000   
2022-11-03 21:03:14,712 - INFO  - Training [32][  300/  391]   Loss 0.035744   Top1 98.802083   Top5 100.000000   BatchTime 0.106768   LR 0.001000   
2022-11-03 21:03:16,336 - INFO  - Training [32][  320/  391]   Loss 0.035900   Top1 98.801270   Top5 100.000000   BatchTime 0.105169   LR 0.001000   
2022-11-03 21:03:18,041 - INFO  - Training [32][  340/  391]   Loss 0.036454   Top1 98.770680   Top5 99.997702   BatchTime 0.103998   LR 0.001000   
2022-11-03 21:03:19,638 - INFO  - Training [32][  360/  391]   Loss 0.036886   Top1 98.756510   Top5 99.997830   BatchTime 0.102656   LR 0.001000   
2022-11-03 21:03:21,306 - INFO  - Training [32][  380/  391]   Loss 0.037192   Top1 98.747944   Top5 99.997944   BatchTime 0.101641   LR 0.001000   
2022-11-03 21:03:22,418 - INFO  - ==> Top1: 98.746    Top5: 99.998    Loss: 0.037

2022-11-03 21:03:22,419 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:03:25,244 - INFO  - Validation [32][   20/   79]   Loss 0.388069   Top1 90.703125   Top5 99.531250   BatchTime 0.141025   
2022-11-03 21:03:26,159 - INFO  - Validation [32][   40/   79]   Loss 0.410451   Top1 90.566406   Top5 99.531250   BatchTime 0.093386   
2022-11-03 21:03:27,063 - INFO  - Validation [32][   60/   79]   Loss 0.400792   Top1 90.598958   Top5 99.609375   BatchTime 0.077325   
2022-11-03 21:03:28,191 - INFO  - ==> Top1: 90.590    Top5: 99.620    Loss: 0.397

2022-11-03 21:03:28,235 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:03:28,236 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:03:28,236 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:03:28,340 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:03:28,340 - INFO  - >>>>>>>> Epoch  33
2022-11-03 21:03:28,342 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:03:32,230 - INFO  - Training [33][   20/  391]   Loss 0.032377   Top1 98.867188   Top5 100.000000   BatchTime 0.194394   LR 0.001000   
2022-11-03 21:03:34,230 - INFO  - Training [33][   40/  391]   Loss 0.032158   Top1 98.808594   Top5 100.000000   BatchTime 0.147206   LR 0.001000   
2022-11-03 21:03:36,258 - INFO  - Training [33][   60/  391]   Loss 0.029521   Top1 98.971354   Top5 100.000000   BatchTime 0.131938   LR 0.001000   
2022-11-03 21:03:38,266 - INFO  - Training [33][   80/  391]   Loss 0.031483   Top1 98.867188   Top5 100.000000   BatchTime 0.124050   LR 0.001000   
2022-11-03 21:03:40,276 - INFO  - Training [33][  100/  391]   Loss 0.032047   Top1 98.828125   Top5 100.000000   BatchTime 0.119344   LR 0.001000   
2022-11-03 21:03:42,274 - INFO  - Training [33][  120/  391]   Loss 0.032350   Top1 98.782552   Top5 100.000000   BatchTime 0.116100   LR 0.001000   
2022-11-03 21:03:44,285 - INFO  - Training [33][  140/  391]   Loss 0.032605   Top1 98.794643   Top5 100.000000   BatchTime 0.113880   LR 0.001000   
2022-11-03 21:03:46,292 - INFO  - Training [33][  160/  391]   Loss 0.032640   Top1 98.803711   Top5 100.000000   BatchTime 0.112188   LR 0.001000   
2022-11-03 21:03:48,301 - INFO  - Training [33][  180/  391]   Loss 0.032744   Top1 98.823785   Top5 100.000000   BatchTime 0.110883   LR 0.001000   
2022-11-03 21:03:50,314 - INFO  - Training [33][  200/  391]   Loss 0.033171   Top1 98.808594   Top5 100.000000   BatchTime 0.109857   LR 0.001000   
2022-11-03 21:03:52,313 - INFO  - Training [33][  220/  391]   Loss 0.033318   Top1 98.817472   Top5 100.000000   BatchTime 0.108960   LR 0.001000   
2022-11-03 21:03:54,307 - INFO  - Training [33][  240/  391]   Loss 0.033270   Top1 98.815104   Top5 100.000000   BatchTime 0.108186   LR 0.001000   
2022-11-03 21:03:56,286 - INFO  - Training [33][  260/  391]   Loss 0.033057   Top1 98.834135   Top5 100.000000   BatchTime 0.107475   LR 0.001000   
2022-11-03 21:03:58,268 - INFO  - Training [33][  280/  391]   Loss 0.032824   Top1 98.869978   Top5 100.000000   BatchTime 0.106877   LR 0.001000   
2022-11-03 21:04:00,361 - INFO  - Training [33][  300/  391]   Loss 0.033291   Top1 98.856771   Top5 100.000000   BatchTime 0.106730   LR 0.001000   
2022-11-03 21:04:01,919 - INFO  - Training [33][  320/  391]   Loss 0.033410   Top1 98.854980   Top5 99.997559   BatchTime 0.104928   LR 0.001000   
2022-11-03 21:04:03,624 - INFO  - Training [33][  340/  391]   Loss 0.033772   Top1 98.835018   Top5 99.997702   BatchTime 0.103768   LR 0.001000   
2022-11-03 21:04:05,254 - INFO  - Training [33][  360/  391]   Loss 0.033386   Top1 98.845486   Top5 99.997830   BatchTime 0.102533   LR 0.001000   
2022-11-03 21:04:06,861 - INFO  - Training [33][  380/  391]   Loss 0.033573   Top1 98.846628   Top5 99.997944   BatchTime 0.101364   LR 0.001000   
2022-11-03 21:04:07,935 - INFO  - ==> Top1: 98.846    Top5: 99.998    Loss: 0.034

2022-11-03 21:04:07,937 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:04:10,748 - INFO  - Validation [33][   20/   79]   Loss 0.391723   Top1 90.976562   Top5 99.531250   BatchTime 0.140455   
2022-11-03 21:04:11,626 - INFO  - Validation [33][   40/   79]   Loss 0.405941   Top1 90.703125   Top5 99.570312   BatchTime 0.092189   
2022-11-03 21:04:12,525 - INFO  - Validation [33][   60/   79]   Loss 0.399896   Top1 90.638021   Top5 99.596354   BatchTime 0.076436   
2022-11-03 21:04:13,610 - INFO  - ==> Top1: 90.580    Top5: 99.590    Loss: 0.398

2022-11-03 21:04:13,656 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:04:13,657 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:04:13,657 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:04:13,763 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:04:13,763 - INFO  - >>>>>>>> Epoch  34
2022-11-03 21:04:13,765 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:04:17,667 - INFO  - Training [34][   20/  391]   Loss 0.025772   Top1 99.101562   Top5 100.000000   BatchTime 0.195094   LR 0.001000   
2022-11-03 21:04:19,701 - INFO  - Training [34][   40/  391]   Loss 0.029062   Top1 99.042969   Top5 100.000000   BatchTime 0.148394   LR 0.001000   
2022-11-03 21:04:21,705 - INFO  - Training [34][   60/  391]   Loss 0.030048   Top1 98.971354   Top5 100.000000   BatchTime 0.132339   LR 0.001000   
2022-11-03 21:04:23,719 - INFO  - Training [34][   80/  391]   Loss 0.030603   Top1 98.984375   Top5 100.000000   BatchTime 0.124428   LR 0.001000   
2022-11-03 21:04:25,728 - INFO  - Training [34][  100/  391]   Loss 0.030087   Top1 99.007812   Top5 100.000000   BatchTime 0.119627   LR 0.001000   
2022-11-03 21:04:27,733 - INFO  - Training [34][  120/  391]   Loss 0.030591   Top1 99.010417   Top5 100.000000   BatchTime 0.116398   LR 0.001000   
2022-11-03 21:04:29,740 - INFO  - Training [34][  140/  391]   Loss 0.029746   Top1 99.029018   Top5 100.000000   BatchTime 0.114103   LR 0.001000   
2022-11-03 21:04:31,745 - INFO  - Training [34][  160/  391]   Loss 0.030921   Top1 98.984375   Top5 100.000000   BatchTime 0.112373   LR 0.001000   
2022-11-03 21:04:33,761 - INFO  - Training [34][  180/  391]   Loss 0.031066   Top1 98.980035   Top5 99.995660   BatchTime 0.111086   LR 0.001000   
2022-11-03 21:04:35,785 - INFO  - Training [34][  200/  391]   Loss 0.031365   Top1 98.957031   Top5 99.996094   BatchTime 0.110099   LR 0.001000   
2022-11-03 21:04:37,806 - INFO  - Training [34][  220/  391]   Loss 0.031494   Top1 98.955966   Top5 99.996449   BatchTime 0.109274   LR 0.001000   
2022-11-03 21:04:39,796 - INFO  - Training [34][  240/  391]   Loss 0.031060   Top1 98.971354   Top5 99.996745   BatchTime 0.108461   LR 0.001000   
2022-11-03 21:04:41,783 - INFO  - Training [34][  260/  391]   Loss 0.031346   Top1 98.957332   Top5 99.996995   BatchTime 0.107761   LR 0.001000   
2022-11-03 21:04:43,750 - INFO  - Training [34][  280/  391]   Loss 0.031603   Top1 98.942522   Top5 99.997210   BatchTime 0.107087   LR 0.001000   
2022-11-03 21:04:45,777 - INFO  - Training [34][  300/  391]   Loss 0.031696   Top1 98.940104   Top5 99.997396   BatchTime 0.106703   LR 0.001000   
2022-11-03 21:04:47,341 - INFO  - Training [34][  320/  391]   Loss 0.032104   Top1 98.913574   Top5 99.997559   BatchTime 0.104924   LR 0.001000   
2022-11-03 21:04:49,017 - INFO  - Training [34][  340/  391]   Loss 0.032320   Top1 98.903952   Top5 99.997702   BatchTime 0.103680   LR 0.001000   
2022-11-03 21:04:50,721 - INFO  - Training [34][  360/  391]   Loss 0.032563   Top1 98.897569   Top5 99.997830   BatchTime 0.102653   LR 0.001000   
2022-11-03 21:04:52,335 - INFO  - Training [34][  380/  391]   Loss 0.032441   Top1 98.895970   Top5 99.997944   BatchTime 0.101499   LR 0.001000   
2022-11-03 21:04:53,572 - INFO  - ==> Top1: 98.890    Top5: 99.998    Loss: 0.033

2022-11-03 21:04:53,573 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:04:56,321 - INFO  - Validation [34][   20/   79]   Loss 0.396783   Top1 90.234375   Top5 99.570312   BatchTime 0.137339   
2022-11-03 21:04:57,214 - INFO  - Validation [34][   40/   79]   Loss 0.411371   Top1 90.332031   Top5 99.492188   BatchTime 0.090980   
2022-11-03 21:04:58,098 - INFO  - Validation [34][   60/   79]   Loss 0.398486   Top1 90.585938   Top5 99.583333   BatchTime 0.075382   
2022-11-03 21:04:59,214 - INFO  - ==> Top1: 90.620    Top5: 99.620    Loss: 0.394

2022-11-03 21:04:59,245 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:04:59,245 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:04:59,245 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:04:59,341 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:04:59,341 - INFO  - >>>>>>>> Epoch  35
2022-11-03 21:04:59,343 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:05:03,277 - INFO  - Training [35][   20/  391]   Loss 0.030283   Top1 98.906250   Top5 100.000000   BatchTime 0.196691   LR 0.001000   
2022-11-03 21:05:05,310 - INFO  - Training [35][   40/  391]   Loss 0.030730   Top1 98.906250   Top5 100.000000   BatchTime 0.149174   LR 0.001000   
2022-11-03 21:05:07,359 - INFO  - Training [35][   60/  391]   Loss 0.029723   Top1 99.010417   Top5 100.000000   BatchTime 0.133597   LR 0.001000   
2022-11-03 21:05:09,365 - INFO  - Training [35][   80/  391]   Loss 0.031079   Top1 98.974609   Top5 100.000000   BatchTime 0.125274   LR 0.001000   
2022-11-03 21:05:11,370 - INFO  - Training [35][  100/  391]   Loss 0.031371   Top1 98.945312   Top5 100.000000   BatchTime 0.120273   LR 0.001000   
2022-11-03 21:05:13,396 - INFO  - Training [35][  120/  391]   Loss 0.032398   Top1 98.860677   Top5 100.000000   BatchTime 0.117104   LR 0.001000   
2022-11-03 21:05:15,418 - INFO  - Training [35][  140/  391]   Loss 0.031524   Top1 98.878348   Top5 100.000000   BatchTime 0.114823   LR 0.001000   
2022-11-03 21:05:17,429 - INFO  - Training [35][  160/  391]   Loss 0.031866   Top1 98.862305   Top5 100.000000   BatchTime 0.113033   LR 0.001000   
2022-11-03 21:05:19,444 - INFO  - Training [35][  180/  391]   Loss 0.032868   Top1 98.832465   Top5 100.000000   BatchTime 0.111671   LR 0.001000   
2022-11-03 21:05:21,476 - INFO  - Training [35][  200/  391]   Loss 0.032121   Top1 98.855469   Top5 100.000000   BatchTime 0.110662   LR 0.001000   
2022-11-03 21:05:23,499 - INFO  - Training [35][  220/  391]   Loss 0.032990   Top1 98.845881   Top5 100.000000   BatchTime 0.109800   LR 0.001000   
2022-11-03 21:05:25,493 - INFO  - Training [35][  240/  391]   Loss 0.033270   Top1 98.834635   Top5 100.000000   BatchTime 0.108954   LR 0.001000   
2022-11-03 21:05:27,483 - INFO  - Training [35][  260/  391]   Loss 0.032978   Top1 98.849159   Top5 100.000000   BatchTime 0.108228   LR 0.001000   
2022-11-03 21:05:29,467 - INFO  - Training [35][  280/  391]   Loss 0.033159   Top1 98.850446   Top5 100.000000   BatchTime 0.107585   LR 0.001000   
2022-11-03 21:05:31,515 - INFO  - Training [35][  300/  391]   Loss 0.033209   Top1 98.835938   Top5 100.000000   BatchTime 0.107237   LR 0.001000   
2022-11-03 21:05:33,096 - INFO  - Training [35][  320/  391]   Loss 0.032844   Top1 98.854980   Top5 100.000000   BatchTime 0.105475   LR 0.001000   
2022-11-03 21:05:34,801 - INFO  - Training [35][  340/  391]   Loss 0.032730   Top1 98.844210   Top5 100.000000   BatchTime 0.104285   LR 0.001000   
2022-11-03 21:05:36,416 - INFO  - Training [35][  360/  391]   Loss 0.033050   Top1 98.830295   Top5 100.000000   BatchTime 0.102977   LR 0.001000   
2022-11-03 21:05:37,998 - INFO  - Training [35][  380/  391]   Loss 0.032973   Top1 98.842516   Top5 100.000000   BatchTime 0.101721   LR 0.001000   
2022-11-03 21:05:39,220 - INFO  - ==> Top1: 98.828    Top5: 100.000    Loss: 0.033

2022-11-03 21:05:39,220 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:05:42,180 - INFO  - Validation [35][   20/   79]   Loss 0.397426   Top1 90.546875   Top5 99.531250   BatchTime 0.141316   
2022-11-03 21:05:43,097 - INFO  - Validation [35][   40/   79]   Loss 0.413704   Top1 90.312500   Top5 99.492188   BatchTime 0.093609   
2022-11-03 21:05:44,051 - INFO  - Validation [35][   60/   79]   Loss 0.405502   Top1 90.559896   Top5 99.544271   BatchTime 0.078301   
2022-11-03 21:05:45,206 - INFO  - ==> Top1: 90.620    Top5: 99.590    Loss: 0.399

2022-11-03 21:05:45,249 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:05:45,250 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:05:45,250 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:05:45,356 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:05:45,356 - INFO  - >>>>>>>> Epoch  36
2022-11-03 21:05:45,357 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:05:49,242 - INFO  - Training [36][   20/  391]   Loss 0.034339   Top1 98.789062   Top5 100.000000   BatchTime 0.194226   LR 0.001000   
2022-11-03 21:05:51,248 - INFO  - Training [36][   40/  391]   Loss 0.034791   Top1 98.750000   Top5 100.000000   BatchTime 0.147273   LR 0.001000   
2022-11-03 21:05:53,275 - INFO  - Training [36][   60/  391]   Loss 0.031490   Top1 98.880208   Top5 100.000000   BatchTime 0.131956   LR 0.001000   
2022-11-03 21:05:55,289 - INFO  - Training [36][   80/  391]   Loss 0.032343   Top1 98.828125   Top5 100.000000   BatchTime 0.124152   LR 0.001000   
2022-11-03 21:05:57,297 - INFO  - Training [36][  100/  391]   Loss 0.031890   Top1 98.875000   Top5 100.000000   BatchTime 0.119393   LR 0.001000   
2022-11-03 21:05:59,315 - INFO  - Training [36][  120/  391]   Loss 0.032780   Top1 98.860677   Top5 100.000000   BatchTime 0.116317   LR 0.001000   
2022-11-03 21:06:01,331 - INFO  - Training [36][  140/  391]   Loss 0.033552   Top1 98.800223   Top5 100.000000   BatchTime 0.114096   LR 0.001000   
2022-11-03 21:06:03,325 - INFO  - Training [36][  160/  391]   Loss 0.033862   Top1 98.808594   Top5 100.000000   BatchTime 0.112298   LR 0.001000   
2022-11-03 21:06:05,329 - INFO  - Training [36][  180/  391]   Loss 0.033126   Top1 98.854167   Top5 100.000000   BatchTime 0.110952   LR 0.001000   
2022-11-03 21:06:07,340 - INFO  - Training [36][  200/  391]   Loss 0.032806   Top1 98.886719   Top5 100.000000   BatchTime 0.109911   LR 0.001000   
2022-11-03 21:06:09,349 - INFO  - Training [36][  220/  391]   Loss 0.032907   Top1 98.874290   Top5 100.000000   BatchTime 0.109053   LR 0.001000   
2022-11-03 21:06:11,332 - INFO  - Training [36][  240/  391]   Loss 0.032976   Top1 98.867188   Top5 100.000000   BatchTime 0.108226   LR 0.001000   
2022-11-03 21:06:13,324 - INFO  - Training [36][  260/  391]   Loss 0.032893   Top1 98.870192   Top5 100.000000   BatchTime 0.107561   LR 0.001000   
2022-11-03 21:06:15,304 - INFO  - Training [36][  280/  391]   Loss 0.032478   Top1 98.878348   Top5 100.000000   BatchTime 0.106952   LR 0.001000   
2022-11-03 21:06:17,223 - INFO  - Training [36][  300/  391]   Loss 0.032165   Top1 98.885417   Top5 100.000000   BatchTime 0.106217   LR 0.001000   
2022-11-03 21:06:18,901 - INFO  - Training [36][  320/  391]   Loss 0.032367   Top1 98.876953   Top5 100.000000   BatchTime 0.104824   LR 0.001000   
2022-11-03 21:06:20,552 - INFO  - Training [36][  340/  391]   Loss 0.032325   Top1 98.876379   Top5 100.000000   BatchTime 0.103511   LR 0.001000   
2022-11-03 21:06:22,254 - INFO  - Training [36][  360/  391]   Loss 0.032642   Top1 98.860677   Top5 100.000000   BatchTime 0.102488   LR 0.001000   
2022-11-03 21:06:23,675 - INFO  - Training [36][  380/  391]   Loss 0.032722   Top1 98.858964   Top5 100.000000   BatchTime 0.100835   LR 0.001000   
2022-11-03 21:06:25,001 - INFO  - ==> Top1: 98.856    Top5: 100.000    Loss: 0.033

2022-11-03 21:06:25,002 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:06:27,920 - INFO  - Validation [36][   20/   79]   Loss 0.394879   Top1 90.117188   Top5 99.492188   BatchTime 0.145855   
2022-11-03 21:06:28,805 - INFO  - Validation [36][   40/   79]   Loss 0.416797   Top1 90.273438   Top5 99.511719   BatchTime 0.095057   
2022-11-03 21:06:29,707 - INFO  - Validation [36][   60/   79]   Loss 0.406264   Top1 90.533854   Top5 99.557292   BatchTime 0.078398   
2022-11-03 21:06:30,865 - INFO  - ==> Top1: 90.580    Top5: 99.590    Loss: 0.402

2022-11-03 21:06:30,894 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:06:30,895 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:06:30,895 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:06:31,003 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:06:31,003 - INFO  - >>>>>>>> Epoch  37
2022-11-03 21:06:31,005 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:06:34,906 - INFO  - Training [37][   20/  391]   Loss 0.035495   Top1 98.828125   Top5 100.000000   BatchTime 0.195074   LR 0.001000   
2022-11-03 21:06:36,930 - INFO  - Training [37][   40/  391]   Loss 0.036561   Top1 98.710938   Top5 100.000000   BatchTime 0.148135   LR 0.001000   
2022-11-03 21:06:38,937 - INFO  - Training [37][   60/  391]   Loss 0.036798   Top1 98.750000   Top5 100.000000   BatchTime 0.132194   LR 0.001000   
2022-11-03 21:06:40,952 - INFO  - Training [37][   80/  391]   Loss 0.035519   Top1 98.808594   Top5 100.000000   BatchTime 0.124333   LR 0.001000   
2022-11-03 21:06:42,974 - INFO  - Training [37][  100/  391]   Loss 0.034073   Top1 98.820312   Top5 100.000000   BatchTime 0.119689   LR 0.001000   
2022-11-03 21:06:44,969 - INFO  - Training [37][  120/  391]   Loss 0.034229   Top1 98.782552   Top5 100.000000   BatchTime 0.116368   LR 0.001000   
2022-11-03 21:06:46,987 - INFO  - Training [37][  140/  391]   Loss 0.034853   Top1 98.783482   Top5 100.000000   BatchTime 0.114157   LR 0.001000   
2022-11-03 21:06:48,979 - INFO  - Training [37][  160/  391]   Loss 0.034461   Top1 98.808594   Top5 100.000000   BatchTime 0.112339   LR 0.001000   
2022-11-03 21:06:50,988 - INFO  - Training [37][  180/  391]   Loss 0.034041   Top1 98.845486   Top5 100.000000   BatchTime 0.111017   LR 0.001000   
2022-11-03 21:06:52,982 - INFO  - Training [37][  200/  391]   Loss 0.033401   Top1 98.863281   Top5 100.000000   BatchTime 0.109885   LR 0.001000   
2022-11-03 21:06:55,010 - INFO  - Training [37][  220/  391]   Loss 0.033659   Top1 98.856534   Top5 100.000000   BatchTime 0.109112   LR 0.001000   
2022-11-03 21:06:56,989 - INFO  - Training [37][  240/  391]   Loss 0.033303   Top1 98.867188   Top5 100.000000   BatchTime 0.108266   LR 0.001000   
2022-11-03 21:06:58,950 - INFO  - Training [37][  260/  391]   Loss 0.033283   Top1 98.873197   Top5 100.000000   BatchTime 0.107479   LR 0.001000   
2022-11-03 21:07:00,921 - INFO  - Training [37][  280/  391]   Loss 0.033407   Top1 98.881138   Top5 100.000000   BatchTime 0.106840   LR 0.001000   
2022-11-03 21:07:02,692 - INFO  - Training [37][  300/  391]   Loss 0.033312   Top1 98.872396   Top5 100.000000   BatchTime 0.105622   LR 0.001000   
2022-11-03 21:07:04,368 - INFO  - Training [37][  320/  391]   Loss 0.033147   Top1 98.874512   Top5 100.000000   BatchTime 0.104258   LR 0.001000   
2022-11-03 21:07:05,975 - INFO  - Training [37][  340/  391]   Loss 0.033131   Top1 98.871783   Top5 100.000000   BatchTime 0.102852   LR 0.001000   
2022-11-03 21:07:07,623 - INFO  - Training [37][  360/  391]   Loss 0.032960   Top1 98.880208   Top5 100.000000   BatchTime 0.101715   LR 0.001000   
2022-11-03 21:07:09,181 - INFO  - Training [37][  380/  391]   Loss 0.032899   Top1 98.889803   Top5 100.000000   BatchTime 0.100461   LR 0.001000   
2022-11-03 21:07:10,545 - INFO  - ==> Top1: 98.874    Top5: 100.000    Loss: 0.033

2022-11-03 21:07:10,545 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:07:13,289 - INFO  - Validation [37][   20/   79]   Loss 0.394357   Top1 90.390625   Top5 99.570312   BatchTime 0.137077   
2022-11-03 21:07:14,227 - INFO  - Validation [37][   40/   79]   Loss 0.415549   Top1 90.312500   Top5 99.550781   BatchTime 0.091992   
2022-11-03 21:07:15,146 - INFO  - Validation [37][   60/   79]   Loss 0.404212   Top1 90.559896   Top5 99.635417   BatchTime 0.076641   
2022-11-03 21:07:16,266 - INFO  - ==> Top1: 90.600    Top5: 99.630    Loss: 0.401

2022-11-03 21:07:16,298 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:07:16,299 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:07:16,299 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:07:16,403 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:07:16,404 - INFO  - >>>>>>>> Epoch  38
2022-11-03 21:07:16,405 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:07:20,319 - INFO  - Training [38][   20/  391]   Loss 0.028199   Top1 99.023438   Top5 100.000000   BatchTime 0.195712   LR 0.001000   
2022-11-03 21:07:22,321 - INFO  - Training [38][   40/  391]   Loss 0.025189   Top1 99.218750   Top5 99.980469   BatchTime 0.147893   LR 0.001000   
2022-11-03 21:07:24,314 - INFO  - Training [38][   60/  391]   Loss 0.025581   Top1 99.179688   Top5 99.986979   BatchTime 0.131818   LR 0.001000   
2022-11-03 21:07:26,324 - INFO  - Training [38][   80/  391]   Loss 0.028029   Top1 99.091797   Top5 99.980469   BatchTime 0.123984   LR 0.001000   
2022-11-03 21:07:28,334 - INFO  - Training [38][  100/  391]   Loss 0.027954   Top1 99.078125   Top5 99.984375   BatchTime 0.119292   LR 0.001000   
2022-11-03 21:07:30,352 - INFO  - Training [38][  120/  391]   Loss 0.029008   Top1 99.016927   Top5 99.986979   BatchTime 0.116224   LR 0.001000   
2022-11-03 21:07:32,375 - INFO  - Training [38][  140/  391]   Loss 0.029865   Top1 98.967634   Top5 99.988839   BatchTime 0.114067   LR 0.001000   
2022-11-03 21:07:34,380 - INFO  - Training [38][  160/  391]   Loss 0.029520   Top1 98.984375   Top5 99.990234   BatchTime 0.112344   LR 0.001000   
2022-11-03 21:07:36,381 - INFO  - Training [38][  180/  391]   Loss 0.029542   Top1 98.980035   Top5 99.991319   BatchTime 0.110978   LR 0.001000   
2022-11-03 21:07:38,377 - INFO  - Training [38][  200/  391]   Loss 0.030446   Top1 98.980469   Top5 99.988281   BatchTime 0.109859   LR 0.001000   
2022-11-03 21:07:40,382 - INFO  - Training [38][  220/  391]   Loss 0.030617   Top1 98.973722   Top5 99.989347   BatchTime 0.108986   LR 0.001000   
2022-11-03 21:07:42,374 - INFO  - Training [38][  240/  391]   Loss 0.030529   Top1 98.948568   Top5 99.990234   BatchTime 0.108203   LR 0.001000   
2022-11-03 21:07:44,352 - INFO  - Training [38][  260/  391]   Loss 0.030426   Top1 98.960337   Top5 99.990986   BatchTime 0.107488   LR 0.001000   
2022-11-03 21:07:46,342 - INFO  - Training [38][  280/  391]   Loss 0.030718   Top1 98.942522   Top5 99.991629   BatchTime 0.106914   LR 0.001000   
2022-11-03 21:07:48,032 - INFO  - Training [38][  300/  391]   Loss 0.030836   Top1 98.932292   Top5 99.992188   BatchTime 0.105421   LR 0.001000   
2022-11-03 21:07:49,675 - INFO  - Training [38][  320/  391]   Loss 0.030647   Top1 98.942871   Top5 99.992676   BatchTime 0.103968   LR 0.001000   
2022-11-03 21:07:51,287 - INFO  - Training [38][  340/  391]   Loss 0.030479   Top1 98.943015   Top5 99.993107   BatchTime 0.102593   LR 0.001000   
2022-11-03 21:07:52,969 - INFO  - Training [38][  360/  391]   Loss 0.030110   Top1 98.956163   Top5 99.993490   BatchTime 0.101565   LR 0.001000   
2022-11-03 21:07:54,561 - INFO  - Training [38][  380/  391]   Loss 0.030141   Top1 98.953536   Top5 99.993832   BatchTime 0.100408   LR 0.001000   
2022-11-03 21:07:55,896 - INFO  - ==> Top1: 98.960    Top5: 99.994    Loss: 0.030

2022-11-03 21:07:55,896 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:07:58,686 - INFO  - Validation [38][   20/   79]   Loss 0.389468   Top1 90.585938   Top5 99.531250   BatchTime 0.139405   
2022-11-03 21:07:59,609 - INFO  - Validation [38][   40/   79]   Loss 0.409496   Top1 90.449219   Top5 99.589844   BatchTime 0.092795   
2022-11-03 21:08:00,531 - INFO  - Validation [38][   60/   79]   Loss 0.401246   Top1 90.638021   Top5 99.635417   BatchTime 0.077222   
2022-11-03 21:08:01,634 - INFO  - ==> Top1: 90.670    Top5: 99.650    Loss: 0.398

2022-11-03 21:08:01,672 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:08:01,673 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:08:01,673 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:08:01,776 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:08:01,776 - INFO  - >>>>>>>> Epoch  39
2022-11-03 21:08:01,777 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:08:05,861 - INFO  - Training [39][   20/  391]   Loss 0.030784   Top1 98.945312   Top5 100.000000   BatchTime 0.204200   LR 0.001000   
2022-11-03 21:08:07,884 - INFO  - Training [39][   40/  391]   Loss 0.033732   Top1 98.847656   Top5 100.000000   BatchTime 0.152682   LR 0.001000   
2022-11-03 21:08:09,896 - INFO  - Training [39][   60/  391]   Loss 0.030750   Top1 98.971354   Top5 100.000000   BatchTime 0.135316   LR 0.001000   
2022-11-03 21:08:11,902 - INFO  - Training [39][   80/  391]   Loss 0.030493   Top1 98.945312   Top5 100.000000   BatchTime 0.126559   LR 0.001000   
2022-11-03 21:08:13,923 - INFO  - Training [39][  100/  391]   Loss 0.030784   Top1 98.929688   Top5 100.000000   BatchTime 0.121453   LR 0.001000   
2022-11-03 21:08:15,939 - INFO  - Training [39][  120/  391]   Loss 0.030700   Top1 98.912760   Top5 100.000000   BatchTime 0.118012   LR 0.001000   
2022-11-03 21:08:17,965 - INFO  - Training [39][  140/  391]   Loss 0.030323   Top1 98.962054   Top5 100.000000   BatchTime 0.115627   LR 0.001000   
2022-11-03 21:08:19,984 - INFO  - Training [39][  160/  391]   Loss 0.030182   Top1 98.950195   Top5 100.000000   BatchTime 0.113791   LR 0.001000   
2022-11-03 21:08:21,998 - INFO  - Training [39][  180/  391]   Loss 0.031874   Top1 98.867188   Top5 100.000000   BatchTime 0.112337   LR 0.001000   
2022-11-03 21:08:24,037 - INFO  - Training [39][  200/  391]   Loss 0.031905   Top1 98.882812   Top5 100.000000   BatchTime 0.111299   LR 0.001000   
2022-11-03 21:08:26,029 - INFO  - Training [39][  220/  391]   Loss 0.031973   Top1 98.899148   Top5 100.000000   BatchTime 0.110232   LR 0.001000   
2022-11-03 21:08:28,018 - INFO  - Training [39][  240/  391]   Loss 0.031240   Top1 98.922526   Top5 100.000000   BatchTime 0.109336   LR 0.001000   
2022-11-03 21:08:30,016 - INFO  - Training [39][  260/  391]   Loss 0.032192   Top1 98.903245   Top5 100.000000   BatchTime 0.108609   LR 0.001000   
2022-11-03 21:08:32,057 - INFO  - Training [39][  280/  391]   Loss 0.032573   Top1 98.889509   Top5 100.000000   BatchTime 0.108142   LR 0.001000   
2022-11-03 21:08:33,587 - INFO  - Training [39][  300/  391]   Loss 0.032562   Top1 98.888021   Top5 100.000000   BatchTime 0.106032   LR 0.001000   
2022-11-03 21:08:35,335 - INFO  - Training [39][  320/  391]   Loss 0.032284   Top1 98.894043   Top5 99.997559   BatchTime 0.104867   LR 0.001000   
2022-11-03 21:08:36,965 - INFO  - Training [39][  340/  391]   Loss 0.031992   Top1 98.899357   Top5 99.997702   BatchTime 0.103493   LR 0.001000   
2022-11-03 21:08:38,607 - INFO  - Training [39][  360/  391]   Loss 0.032082   Top1 98.891059   Top5 99.997830   BatchTime 0.102303   LR 0.001000   
2022-11-03 21:08:40,458 - INFO  - Training [39][  380/  391]   Loss 0.032034   Top1 98.889803   Top5 99.997944   BatchTime 0.101790   LR 0.001000   
2022-11-03 21:08:41,816 - INFO  - ==> Top1: 98.882    Top5: 99.998    Loss: 0.032

2022-11-03 21:08:41,817 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:08:44,564 - INFO  - Validation [39][   20/   79]   Loss 0.387984   Top1 90.156250   Top5 99.609375   BatchTime 0.137255   
2022-11-03 21:08:45,466 - INFO  - Validation [39][   40/   79]   Loss 0.407468   Top1 90.410156   Top5 99.550781   BatchTime 0.091176   
2022-11-03 21:08:46,367 - INFO  - Validation [39][   60/   79]   Loss 0.403643   Top1 90.546875   Top5 99.583333   BatchTime 0.075810   
2022-11-03 21:08:47,425 - INFO  - ==> Top1: 90.640    Top5: 99.610    Loss: 0.400

2022-11-03 21:08:47,458 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.780   Top5: 99.570] Sparsity : 0.738
2022-11-03 21:08:47,459 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.780   Top5: 99.570] Sparsity : 0.737
2022-11-03 21:08:47,459 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.750   Top5: 99.640] Sparsity : 0.737
2022-11-03 21:08:47,565 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_5_epoch60_20221103-203820/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:08:47,565 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 21:08:47,565 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:08:50,339 - INFO  - Validation [   20/   79]   Loss 0.387984   Top1 90.156250   Top5 99.609375   BatchTime 0.138634   
2022-11-03 21:08:51,246 - INFO  - Validation [   40/   79]   Loss 0.407468   Top1 90.410156   Top5 99.550781   BatchTime 0.091991   
2022-11-03 21:08:52,133 - INFO  - Validation [   60/   79]   Loss 0.403643   Top1 90.546875   Top5 99.583333   BatchTime 0.076112   
2022-11-03 21:08:53,261 - INFO  - ==> Top1: 90.640    Top5: 99.610    Loss: 0.400

2022-11-03 21:08:53,323 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar

2022-11-03 21:08:53,324 - INFO  - Program completed successfully ... exiting ...
2022-11-03 21:08:53,324 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
