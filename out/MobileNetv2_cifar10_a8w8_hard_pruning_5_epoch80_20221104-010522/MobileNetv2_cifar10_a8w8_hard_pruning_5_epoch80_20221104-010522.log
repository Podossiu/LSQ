2022-11-04 01:05:22,379 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522.log
2022-11-04 01:05:23,422 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/tb_runs
2022-11-04 01:05:24,539 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-04 01:05:24,590 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
2022-11-04 01:05:26,689 - INFO  - Inserted quantizers into the original model
2022-11-04 01:05:29,222 - INFO  - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_5_epoch80_checkpoint.pth.tar
2022-11-04 01:05:29,224 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-04 01:05:29,224 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-04 01:05:29,224 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-04 01:05:29,224 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:05:32,679 - INFO  - Validation [   20/   40]   Loss 0.412269   Top1 90.351562   Top5 99.511719   BatchTime 0.172718   
2022-11-04 01:05:33,815 - INFO  - Validation [   40/   40]   Loss 0.402214   Top1 90.500000   Top5 99.590000   BatchTime 0.114749   
2022-11-04 01:05:33,966 - INFO  - ==> Top1: 90.500    Top5: 99.590    Loss: 0.402

2022-11-04 01:05:34,004 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
2022-11-04 01:05:34,005 - INFO  - >>>>>>>> Epoch   0
2022-11-04 01:05:34,005 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:05:39,231 - INFO  - Training [0][   20/  196]   Loss 0.029285   Top1 98.945312   Top5 100.000000   BatchTime 0.261288   LR 0.010000   
2022-11-04 01:05:42,255 - INFO  - Training [0][   40/  196]   Loss 0.031289   Top1 98.857422   Top5 100.000000   BatchTime 0.206241   LR 0.010000   
2022-11-04 01:05:45,268 - INFO  - Training [0][   60/  196]   Loss 0.034107   Top1 98.769531   Top5 100.000000   BatchTime 0.187710   LR 0.010000   
2022-11-04 01:05:48,275 - INFO  - Training [0][   80/  196]   Loss 0.035260   Top1 98.740234   Top5 100.000000   BatchTime 0.178372   LR 0.010000   
2022-11-04 01:05:51,287 - INFO  - Training [0][  100/  196]   Loss 0.036265   Top1 98.722656   Top5 100.000000   BatchTime 0.172812   LR 0.010000   
2022-11-04 01:05:54,294 - INFO  - Training [0][  120/  196]   Loss 0.036477   Top1 98.694661   Top5 100.000000   BatchTime 0.169069   LR 0.010000   
2022-11-04 01:05:57,308 - INFO  - Training [0][  140/  196]   Loss 0.037272   Top1 98.663504   Top5 100.000000   BatchTime 0.166444   LR 0.010000   
2022-11-04 01:06:00,301 - INFO  - Training [0][  160/  196]   Loss 0.038279   Top1 98.623047   Top5 99.997559   BatchTime 0.164343   LR 0.010000   
2022-11-04 01:06:03,294 - INFO  - Training [0][  180/  196]   Loss 0.039104   Top1 98.582899   Top5 99.997830   BatchTime 0.162714   LR 0.010000   
2022-11-04 01:06:06,545 - INFO  - ==> Top1: 98.606    Top5: 99.998    Loss: 0.039

2022-11-04 01:06:06,546 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:06:09,335 - INFO  - Validation [0][   20/   40]   Loss 0.430218   Top1 90.019531   Top5 99.570312   BatchTime 0.139322   
2022-11-04 01:06:10,343 - INFO  - Validation [0][   40/   40]   Loss 0.415012   Top1 90.290000   Top5 99.630000   BatchTime 0.094873   
2022-11-04 01:06:10,673 - INFO  - ==> Top1: 90.290    Top5: 99.630    Loss: 0.415

2022-11-04 01:06:10,762 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
2022-11-04 01:06:10,762 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
2022-11-04 01:06:10,804 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:06:10,804 - INFO  - >>>>>>>> Epoch   1
2022-11-04 01:06:10,805 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:06:15,615 - INFO  - Training [1][   20/  196]   Loss 0.044071   Top1 98.574219   Top5 100.000000   BatchTime 0.240453   LR 0.010000   
2022-11-04 01:06:18,634 - INFO  - Training [1][   40/  196]   Loss 0.044024   Top1 98.583984   Top5 100.000000   BatchTime 0.195704   LR 0.010000   
2022-11-04 01:06:21,651 - INFO  - Training [1][   60/  196]   Loss 0.046415   Top1 98.509115   Top5 100.000000   BatchTime 0.180761   LR 0.010000   
2022-11-04 01:06:24,663 - INFO  - Training [1][   80/  196]   Loss 0.044021   Top1 98.549805   Top5 100.000000   BatchTime 0.173222   LR 0.010000   
2022-11-04 01:06:27,689 - INFO  - Training [1][  100/  196]   Loss 0.043364   Top1 98.558594   Top5 100.000000   BatchTime 0.168838   LR 0.010000   
2022-11-04 01:06:30,804 - INFO  - Training [1][  120/  196]   Loss 0.043097   Top1 98.531901   Top5 100.000000   BatchTime 0.166649   LR 0.010000   
2022-11-04 01:06:33,808 - INFO  - Training [1][  140/  196]   Loss 0.041560   Top1 98.568638   Top5 100.000000   BatchTime 0.164300   LR 0.010000   
2022-11-04 01:06:36,803 - INFO  - Training [1][  160/  196]   Loss 0.041151   Top1 98.596191   Top5 100.000000   BatchTime 0.162484   LR 0.010000   
2022-11-04 01:06:39,800 - INFO  - Training [1][  180/  196]   Loss 0.041284   Top1 98.598090   Top5 100.000000   BatchTime 0.161076   LR 0.010000   
2022-11-04 01:06:42,361 - INFO  - ==> Top1: 98.598    Top5: 100.000    Loss: 0.041

2022-11-04 01:06:42,361 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:06:45,016 - INFO  - Validation [1][   20/   40]   Loss 0.433011   Top1 90.000000   Top5 99.648438   BatchTime 0.132660   
2022-11-04 01:06:46,026 - INFO  - Validation [1][   40/   40]   Loss 0.420769   Top1 90.180000   Top5 99.650000   BatchTime 0.091583   
2022-11-04 01:06:46,261 - INFO  - ==> Top1: 90.180    Top5: 99.650    Loss: 0.421

2022-11-04 01:06:46,302 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
2022-11-04 01:06:46,303 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
2022-11-04 01:06:46,303 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 90.180   Top5: 99.650] Sparsity : 0.827
2022-11-04 01:06:46,399 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:06:46,400 - INFO  - >>>>>>>> Epoch   2
2022-11-04 01:06:46,401 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:06:51,226 - INFO  - Training [2][   20/  196]   Loss 0.031670   Top1 99.023438   Top5 100.000000   BatchTime 0.241216   LR 0.010000   
2022-11-04 01:06:54,260 - INFO  - Training [2][   40/  196]   Loss 0.032693   Top1 98.964844   Top5 100.000000   BatchTime 0.196473   LR 0.010000   
2022-11-04 01:06:57,295 - INFO  - Training [2][   60/  196]   Loss 0.034533   Top1 98.841146   Top5 100.000000   BatchTime 0.181559   LR 0.010000   
2022-11-04 01:07:00,330 - INFO  - Training [2][   80/  196]   Loss 0.034845   Top1 98.793945   Top5 100.000000   BatchTime 0.174104   LR 0.010000   
2022-11-04 01:07:03,364 - INFO  - Training [2][  100/  196]   Loss 0.034493   Top1 98.804688   Top5 100.000000   BatchTime 0.169625   LR 0.010000   
2022-11-04 01:07:06,396 - INFO  - Training [2][  120/  196]   Loss 0.035439   Top1 98.723958   Top5 100.000000   BatchTime 0.166617   LR 0.010000   
2022-11-04 01:07:09,423 - INFO  - Training [2][  140/  196]   Loss 0.036971   Top1 98.669085   Top5 100.000000   BatchTime 0.164436   LR 0.010000   
2022-11-04 01:07:12,424 - INFO  - Training [2][  160/  196]   Loss 0.037564   Top1 98.657227   Top5 100.000000   BatchTime 0.162636   LR 0.010000   
2022-11-04 01:07:15,429 - INFO  - Training [2][  180/  196]   Loss 0.038951   Top1 98.608941   Top5 99.997830   BatchTime 0.161260   LR 0.010000   
2022-11-04 01:07:18,008 - INFO  - ==> Top1: 98.612    Top5: 99.998    Loss: 0.039

2022-11-04 01:07:18,009 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:07:20,613 - INFO  - Validation [2][   20/   40]   Loss 0.435636   Top1 90.234375   Top5 99.511719   BatchTime 0.130153   
2022-11-04 01:07:21,656 - INFO  - Validation [2][   40/   40]   Loss 0.423086   Top1 90.550000   Top5 99.560000   BatchTime 0.091139   
2022-11-04 01:07:21,884 - INFO  - ==> Top1: 90.550    Top5: 99.560    Loss: 0.423

2022-11-04 01:07:21,921 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:07:21,922 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
2022-11-04 01:07:21,922 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
2022-11-04 01:07:22,069 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:07:22,134 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:07:22,135 - INFO  - >>>>>>>> Epoch   3
2022-11-04 01:07:22,135 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:07:26,491 - INFO  - Training [3][   20/  196]   Loss 0.036699   Top1 98.691406   Top5 100.000000   BatchTime 0.217774   LR 0.010000   
2022-11-04 01:07:29,521 - INFO  - Training [3][   40/  196]   Loss 0.039743   Top1 98.593750   Top5 100.000000   BatchTime 0.184635   LR 0.010000   
2022-11-04 01:07:32,541 - INFO  - Training [3][   60/  196]   Loss 0.039968   Top1 98.574219   Top5 100.000000   BatchTime 0.173430   LR 0.010000   
2022-11-04 01:07:35,573 - INFO  - Training [3][   80/  196]   Loss 0.038580   Top1 98.642578   Top5 100.000000   BatchTime 0.167966   LR 0.010000   
2022-11-04 01:07:38,590 - INFO  - Training [3][  100/  196]   Loss 0.037863   Top1 98.679688   Top5 100.000000   BatchTime 0.164543   LR 0.010000   
2022-11-04 01:07:41,635 - INFO  - Training [3][  120/  196]   Loss 0.038440   Top1 98.652344   Top5 100.000000   BatchTime 0.162490   LR 0.010000   
2022-11-04 01:07:44,656 - INFO  - Training [3][  140/  196]   Loss 0.039490   Top1 98.627232   Top5 100.000000   BatchTime 0.160859   LR 0.010000   
2022-11-04 01:07:47,648 - INFO  - Training [3][  160/  196]   Loss 0.038956   Top1 98.666992   Top5 100.000000   BatchTime 0.159451   LR 0.010000   
2022-11-04 01:07:50,648 - INFO  - Training [3][  180/  196]   Loss 0.039735   Top1 98.628472   Top5 100.000000   BatchTime 0.158403   LR 0.010000   
2022-11-04 01:07:53,220 - INFO  - ==> Top1: 98.636    Top5: 100.000    Loss: 0.040

2022-11-04 01:07:53,221 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:07:55,718 - INFO  - Validation [3][   20/   40]   Loss 0.441783   Top1 90.097656   Top5 99.453125   BatchTime 0.124763   
2022-11-04 01:07:56,587 - INFO  - Validation [3][   40/   40]   Loss 0.429969   Top1 90.280000   Top5 99.560000   BatchTime 0.084106   
2022-11-04 01:07:56,835 - INFO  - ==> Top1: 90.280    Top5: 99.560    Loss: 0.430

2022-11-04 01:07:56,876 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:07:56,877 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
2022-11-04 01:07:56,877 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 90.290   Top5: 99.630] Sparsity : 0.827
2022-11-04 01:07:56,976 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:07:56,977 - INFO  - >>>>>>>> Epoch   4
2022-11-04 01:07:56,978 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:08:01,005 - INFO  - Training [4][   20/  196]   Loss 0.036828   Top1 98.730469   Top5 100.000000   BatchTime 0.201353   LR 0.010000   
2022-11-04 01:08:03,995 - INFO  - Training [4][   40/  196]   Loss 0.032848   Top1 98.867188   Top5 100.000000   BatchTime 0.175420   LR 0.010000   
2022-11-04 01:08:07,019 - INFO  - Training [4][   60/  196]   Loss 0.034444   Top1 98.841146   Top5 100.000000   BatchTime 0.167343   LR 0.010000   
2022-11-04 01:08:10,050 - INFO  - Training [4][   80/  196]   Loss 0.035752   Top1 98.740234   Top5 100.000000   BatchTime 0.163395   LR 0.010000   
2022-11-04 01:08:13,075 - INFO  - Training [4][  100/  196]   Loss 0.036376   Top1 98.703125   Top5 100.000000   BatchTime 0.160967   LR 0.010000   
2022-11-04 01:08:16,101 - INFO  - Training [4][  120/  196]   Loss 0.037333   Top1 98.655599   Top5 100.000000   BatchTime 0.159355   LR 0.010000   
2022-11-04 01:08:19,110 - INFO  - Training [4][  140/  196]   Loss 0.038002   Top1 98.607701   Top5 100.000000   BatchTime 0.158084   LR 0.010000   
2022-11-04 01:08:22,108 - INFO  - Training [4][  160/  196]   Loss 0.038385   Top1 98.598633   Top5 100.000000   BatchTime 0.157059   LR 0.010000   
2022-11-04 01:08:25,101 - INFO  - Training [4][  180/  196]   Loss 0.038903   Top1 98.602431   Top5 100.000000   BatchTime 0.156234   LR 0.010000   
2022-11-04 01:08:27,684 - INFO  - ==> Top1: 98.580    Top5: 100.000    Loss: 0.039

2022-11-04 01:08:27,685 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:08:30,212 - INFO  - Validation [4][   20/   40]   Loss 0.429817   Top1 90.527344   Top5 99.531250   BatchTime 0.126299   
2022-11-04 01:08:30,898 - INFO  - Validation [4][   40/   40]   Loss 0.425634   Top1 90.600000   Top5 99.590000   BatchTime 0.080295   
2022-11-04 01:08:31,151 - INFO  - ==> Top1: 90.600    Top5: 99.590    Loss: 0.426

2022-11-04 01:08:31,211 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:08:31,212 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:08:31,212 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.500   Top5: 99.590] Sparsity : 0.826
2022-11-04 01:08:31,430 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:08:31,612 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:08:31,612 - INFO  - >>>>>>>> Epoch   5
2022-11-04 01:08:31,614 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:08:35,488 - INFO  - Training [5][   20/  196]   Loss 0.037389   Top1 98.671875   Top5 100.000000   BatchTime 0.193726   LR 0.010000   
2022-11-04 01:08:38,550 - INFO  - Training [5][   40/  196]   Loss 0.037689   Top1 98.642578   Top5 100.000000   BatchTime 0.173409   LR 0.010000   
2022-11-04 01:08:41,573 - INFO  - Training [5][   60/  196]   Loss 0.036665   Top1 98.678385   Top5 100.000000   BatchTime 0.165991   LR 0.010000   
2022-11-04 01:08:44,598 - INFO  - Training [5][   80/  196]   Loss 0.035769   Top1 98.701172   Top5 99.995117   BatchTime 0.162305   LR 0.010000   
2022-11-04 01:08:47,620 - INFO  - Training [5][  100/  196]   Loss 0.035578   Top1 98.726562   Top5 99.996094   BatchTime 0.160059   LR 0.010000   
2022-11-04 01:08:50,717 - INFO  - Training [5][  120/  196]   Loss 0.036666   Top1 98.704427   Top5 99.996745   BatchTime 0.159194   LR 0.010000   
2022-11-04 01:08:53,736 - INFO  - Training [5][  140/  196]   Loss 0.037059   Top1 98.705357   Top5 99.997210   BatchTime 0.158013   LR 0.010000   
2022-11-04 01:08:56,733 - INFO  - Training [5][  160/  196]   Loss 0.037045   Top1 98.696289   Top5 99.997559   BatchTime 0.156993   LR 0.010000   
2022-11-04 01:08:59,727 - INFO  - Training [5][  180/  196]   Loss 0.037289   Top1 98.656684   Top5 99.997830   BatchTime 0.156185   LR 0.010000   
2022-11-04 01:09:02,297 - INFO  - ==> Top1: 98.646    Top5: 99.998    Loss: 0.038

2022-11-04 01:09:02,298 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:09:04,826 - INFO  - Validation [5][   20/   40]   Loss 0.441704   Top1 90.566406   Top5 99.511719   BatchTime 0.126328   
2022-11-04 01:09:05,515 - INFO  - Validation [5][   40/   40]   Loss 0.428170   Top1 90.520000   Top5 99.590000   BatchTime 0.080379   
2022-11-04 01:09:05,754 - INFO  - ==> Top1: 90.520    Top5: 99.590    Loss: 0.428

2022-11-04 01:09:05,778 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:09:05,779 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:09:05,779 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:09:05,893 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:09:05,894 - INFO  - >>>>>>>> Epoch   6
2022-11-04 01:09:05,896 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:09:09,729 - INFO  - Training [6][   20/  196]   Loss 0.033900   Top1 98.808594   Top5 100.000000   BatchTime 0.191655   LR 0.010000   
2022-11-04 01:09:12,750 - INFO  - Training [6][   40/  196]   Loss 0.036099   Top1 98.671875   Top5 100.000000   BatchTime 0.171352   LR 0.010000   
2022-11-04 01:09:15,782 - INFO  - Training [6][   60/  196]   Loss 0.037066   Top1 98.691406   Top5 100.000000   BatchTime 0.164761   LR 0.010000   
2022-11-04 01:09:18,815 - INFO  - Training [6][   80/  196]   Loss 0.034513   Top1 98.813477   Top5 100.000000   BatchTime 0.161479   LR 0.010000   
2022-11-04 01:09:21,840 - INFO  - Training [6][  100/  196]   Loss 0.035028   Top1 98.789062   Top5 100.000000   BatchTime 0.159431   LR 0.010000   
2022-11-04 01:09:24,875 - INFO  - Training [6][  120/  196]   Loss 0.035112   Top1 98.795573   Top5 100.000000   BatchTime 0.158151   LR 0.010000   
2022-11-04 01:09:27,914 - INFO  - Training [6][  140/  196]   Loss 0.035079   Top1 98.789062   Top5 100.000000   BatchTime 0.157266   LR 0.010000   
2022-11-04 01:09:30,919 - INFO  - Training [6][  160/  196]   Loss 0.035336   Top1 98.776855   Top5 100.000000   BatchTime 0.156387   LR 0.010000   
2022-11-04 01:09:33,912 - INFO  - Training [6][  180/  196]   Loss 0.035394   Top1 98.771701   Top5 100.000000   BatchTime 0.155639   LR 0.010000   
2022-11-04 01:09:36,460 - INFO  - ==> Top1: 98.770    Top5: 100.000    Loss: 0.035

2022-11-04 01:09:36,461 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:09:39,079 - INFO  - Validation [6][   20/   40]   Loss 0.448127   Top1 90.214844   Top5 99.550781   BatchTime 0.130854   
2022-11-04 01:09:39,766 - INFO  - Validation [6][   40/   40]   Loss 0.430425   Top1 90.410000   Top5 99.590000   BatchTime 0.082618   
2022-11-04 01:09:39,998 - INFO  - ==> Top1: 90.410    Top5: 99.590    Loss: 0.430

2022-11-04 01:09:40,022 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:09:40,023 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:09:40,023 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:09:40,139 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:09:40,139 - INFO  - >>>>>>>> Epoch   7
2022-11-04 01:09:40,140 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:09:43,948 - INFO  - Training [7][   20/  196]   Loss 0.027297   Top1 99.082031   Top5 100.000000   BatchTime 0.190377   LR 0.010000   
2022-11-04 01:09:46,445 - INFO  - Training [7][   40/  196]   Loss 0.029878   Top1 99.013672   Top5 100.000000   BatchTime 0.157610   LR 0.010000   
2022-11-04 01:09:49,465 - INFO  - Training [7][   60/  196]   Loss 0.030339   Top1 99.016927   Top5 100.000000   BatchTime 0.155401   LR 0.010000   
2022-11-04 01:09:52,482 - INFO  - Training [7][   80/  196]   Loss 0.031888   Top1 98.955078   Top5 100.000000   BatchTime 0.154272   LR 0.010000   
2022-11-04 01:09:55,510 - INFO  - Training [7][  100/  196]   Loss 0.031826   Top1 98.929688   Top5 100.000000   BatchTime 0.153698   LR 0.010000   
2022-11-04 01:09:58,527 - INFO  - Training [7][  120/  196]   Loss 0.032100   Top1 98.909505   Top5 100.000000   BatchTime 0.153222   LR 0.010000   
2022-11-04 01:10:01,547 - INFO  - Training [7][  140/  196]   Loss 0.033251   Top1 98.856027   Top5 100.000000   BatchTime 0.152904   LR 0.010000   
2022-11-04 01:10:04,558 - INFO  - Training [7][  160/  196]   Loss 0.034229   Top1 98.825684   Top5 100.000000   BatchTime 0.152605   LR 0.010000   
2022-11-04 01:10:07,556 - INFO  - Training [7][  180/  196]   Loss 0.034142   Top1 98.836806   Top5 100.000000   BatchTime 0.152308   LR 0.010000   
2022-11-04 01:10:10,112 - INFO  - ==> Top1: 98.830    Top5: 100.000    Loss: 0.034

2022-11-04 01:10:10,113 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:10:13,139 - INFO  - Validation [7][   20/   40]   Loss 0.439483   Top1 90.039062   Top5 99.667969   BatchTime 0.151241   
2022-11-04 01:10:13,861 - INFO  - Validation [7][   40/   40]   Loss 0.427296   Top1 90.420000   Top5 99.710000   BatchTime 0.093681   
2022-11-04 01:10:14,112 - INFO  - ==> Top1: 90.420    Top5: 99.710    Loss: 0.427

2022-11-04 01:10:14,138 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:10:14,139 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:10:14,139 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:10:14,244 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:10:14,244 - INFO  - >>>>>>>> Epoch   8
2022-11-04 01:10:14,246 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:10:18,270 - INFO  - Training [8][   20/  196]   Loss 0.031072   Top1 98.964844   Top5 100.000000   BatchTime 0.201209   LR 0.010000   
2022-11-04 01:10:20,349 - INFO  - Training [8][   40/  196]   Loss 0.029871   Top1 99.033203   Top5 100.000000   BatchTime 0.152566   LR 0.010000   
2022-11-04 01:10:23,369 - INFO  - Training [8][   60/  196]   Loss 0.028948   Top1 99.042969   Top5 100.000000   BatchTime 0.152046   LR 0.010000   
2022-11-04 01:10:26,412 - INFO  - Training [8][   80/  196]   Loss 0.030877   Top1 98.994141   Top5 100.000000   BatchTime 0.152078   LR 0.010000   
2022-11-04 01:10:29,418 - INFO  - Training [8][  100/  196]   Loss 0.030424   Top1 98.980469   Top5 100.000000   BatchTime 0.151719   LR 0.010000   
2022-11-04 01:10:32,459 - INFO  - Training [8][  120/  196]   Loss 0.030521   Top1 99.003906   Top5 100.000000   BatchTime 0.151768   LR 0.010000   
2022-11-04 01:10:35,471 - INFO  - Training [8][  140/  196]   Loss 0.030413   Top1 98.995536   Top5 100.000000   BatchTime 0.151604   LR 0.010000   
2022-11-04 01:10:38,490 - INFO  - Training [8][  160/  196]   Loss 0.031868   Top1 98.942871   Top5 100.000000   BatchTime 0.151523   LR 0.010000   
2022-11-04 01:10:41,487 - INFO  - Training [8][  180/  196]   Loss 0.031853   Top1 98.934462   Top5 100.000000   BatchTime 0.151338   LR 0.010000   
2022-11-04 01:10:44,063 - INFO  - ==> Top1: 98.938    Top5: 100.000    Loss: 0.032

2022-11-04 01:10:44,063 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:10:47,227 - INFO  - Validation [8][   20/   40]   Loss 0.446328   Top1 90.429688   Top5 99.433594   BatchTime 0.158140   
2022-11-04 01:10:48,148 - INFO  - Validation [8][   40/   40]   Loss 0.435362   Top1 90.450000   Top5 99.550000   BatchTime 0.102085   
2022-11-04 01:10:48,388 - INFO  - ==> Top1: 90.450    Top5: 99.550    Loss: 0.435

2022-11-04 01:10:48,414 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:10:48,414 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:10:48,414 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 90.520   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:10:48,513 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:10:48,513 - INFO  - >>>>>>>> Epoch   9
2022-11-04 01:10:48,514 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:10:52,683 - INFO  - Training [9][   20/  196]   Loss 0.026089   Top1 99.121094   Top5 99.980469   BatchTime 0.208390   LR 0.010000   
2022-11-04 01:10:54,421 - INFO  - Training [9][   40/  196]   Loss 0.029548   Top1 98.935547   Top5 99.990234   BatchTime 0.147655   LR 0.010000   
2022-11-04 01:10:57,232 - INFO  - Training [9][   60/  196]   Loss 0.029710   Top1 98.886719   Top5 99.993490   BatchTime 0.145294   LR 0.010000   
2022-11-04 01:11:00,267 - INFO  - Training [9][   80/  196]   Loss 0.030891   Top1 98.847656   Top5 99.995117   BatchTime 0.146905   LR 0.010000   
2022-11-04 01:11:03,286 - INFO  - Training [9][  100/  196]   Loss 0.030760   Top1 98.855469   Top5 99.996094   BatchTime 0.147710   LR 0.010000   
2022-11-04 01:11:06,314 - INFO  - Training [9][  120/  196]   Loss 0.029913   Top1 98.886719   Top5 99.996745   BatchTime 0.148327   LR 0.010000   
2022-11-04 01:11:09,321 - INFO  - Training [9][  140/  196]   Loss 0.030519   Top1 98.869978   Top5 99.997210   BatchTime 0.148614   LR 0.010000   
2022-11-04 01:11:12,320 - INFO  - Training [9][  160/  196]   Loss 0.030706   Top1 98.852539   Top5 99.997559   BatchTime 0.148780   LR 0.010000   
2022-11-04 01:11:15,424 - INFO  - Training [9][  180/  196]   Loss 0.030511   Top1 98.858507   Top5 99.997830   BatchTime 0.149495   LR 0.010000   
2022-11-04 01:11:18,002 - INFO  - ==> Top1: 98.850    Top5: 99.998    Loss: 0.031

2022-11-04 01:11:18,002 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:11:21,174 - INFO  - Validation [9][   20/   40]   Loss 0.456671   Top1 90.214844   Top5 99.628906   BatchTime 0.158478   
2022-11-04 01:11:22,549 - INFO  - Validation [9][   40/   40]   Loss 0.436166   Top1 90.580000   Top5 99.670000   BatchTime 0.113634   
2022-11-04 01:11:22,798 - INFO  - ==> Top1: 90.580    Top5: 99.670    Loss: 0.436

2022-11-04 01:11:22,824 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:11:22,825 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:11:22,825 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:11:22,914 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:11:22,914 - INFO  - >>>>>>>> Epoch  10
2022-11-04 01:11:22,915 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:11:27,258 - INFO  - Training [10][   20/  196]   Loss 0.029550   Top1 99.042969   Top5 100.000000   BatchTime 0.217122   LR 0.010000   
2022-11-04 01:11:29,229 - INFO  - Training [10][   40/  196]   Loss 0.030677   Top1 98.925781   Top5 100.000000   BatchTime 0.157855   LR 0.010000   
2022-11-04 01:11:31,763 - INFO  - Training [10][   60/  196]   Loss 0.032102   Top1 98.834635   Top5 100.000000   BatchTime 0.147459   LR 0.010000   
2022-11-04 01:11:34,791 - INFO  - Training [10][   80/  196]   Loss 0.032421   Top1 98.862305   Top5 100.000000   BatchTime 0.148441   LR 0.010000   
2022-11-04 01:11:37,820 - INFO  - Training [10][  100/  196]   Loss 0.032942   Top1 98.839844   Top5 100.000000   BatchTime 0.149048   LR 0.010000   
2022-11-04 01:11:40,842 - INFO  - Training [10][  120/  196]   Loss 0.033058   Top1 98.824870   Top5 100.000000   BatchTime 0.149385   LR 0.010000   
2022-11-04 01:11:43,871 - INFO  - Training [10][  140/  196]   Loss 0.032185   Top1 98.839286   Top5 100.000000   BatchTime 0.149681   LR 0.010000   
2022-11-04 01:11:46,874 - INFO  - Training [10][  160/  196]   Loss 0.031758   Top1 98.859863   Top5 100.000000   BatchTime 0.149741   LR 0.010000   
2022-11-04 01:11:49,896 - INFO  - Training [10][  180/  196]   Loss 0.031385   Top1 98.865017   Top5 100.000000   BatchTime 0.149889   LR 0.010000   
2022-11-04 01:11:52,468 - INFO  - ==> Top1: 98.864    Top5: 100.000    Loss: 0.031

2022-11-04 01:11:52,469 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:11:55,654 - INFO  - Validation [10][   20/   40]   Loss 0.443440   Top1 90.332031   Top5 99.589844   BatchTime 0.159167   
2022-11-04 01:11:57,136 - INFO  - Validation [10][   40/   40]   Loss 0.429766   Top1 90.480000   Top5 99.630000   BatchTime 0.116634   
2022-11-04 01:11:57,370 - INFO  - ==> Top1: 90.480    Top5: 99.630    Loss: 0.430

2022-11-04 01:11:57,406 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:11:57,407 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:11:57,407 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:11:57,520 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:11:57,521 - INFO  - >>>>>>>> Epoch  11
2022-11-04 01:11:57,521 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:12:01,783 - INFO  - Training [11][   20/  196]   Loss 0.030170   Top1 98.945312   Top5 100.000000   BatchTime 0.213057   LR 0.010000   
2022-11-04 01:12:03,811 - INFO  - Training [11][   40/  196]   Loss 0.031098   Top1 98.916016   Top5 100.000000   BatchTime 0.157241   LR 0.010000   
2022-11-04 01:12:05,933 - INFO  - Training [11][   60/  196]   Loss 0.032182   Top1 98.847656   Top5 100.000000   BatchTime 0.140182   LR 0.010000   
2022-11-04 01:12:08,940 - INFO  - Training [11][   80/  196]   Loss 0.033318   Top1 98.808594   Top5 100.000000   BatchTime 0.142726   LR 0.010000   
2022-11-04 01:12:11,973 - INFO  - Training [11][  100/  196]   Loss 0.034545   Top1 98.785156   Top5 100.000000   BatchTime 0.144509   LR 0.010000   
2022-11-04 01:12:15,005 - INFO  - Training [11][  120/  196]   Loss 0.034155   Top1 98.792318   Top5 100.000000   BatchTime 0.145691   LR 0.010000   
2022-11-04 01:12:18,023 - INFO  - Training [11][  140/  196]   Loss 0.033752   Top1 98.830915   Top5 100.000000   BatchTime 0.146436   LR 0.010000   
2022-11-04 01:12:21,036 - INFO  - Training [11][  160/  196]   Loss 0.032886   Top1 98.864746   Top5 100.000000   BatchTime 0.146960   LR 0.010000   
2022-11-04 01:12:24,043 - INFO  - Training [11][  180/  196]   Loss 0.033084   Top1 98.862847   Top5 100.000000   BatchTime 0.147341   LR 0.010000   
2022-11-04 01:12:26,619 - INFO  - ==> Top1: 98.842    Top5: 100.000    Loss: 0.033

2022-11-04 01:12:26,620 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:12:29,786 - INFO  - Validation [11][   20/   40]   Loss 0.458660   Top1 90.429688   Top5 99.414062   BatchTime 0.158205   
2022-11-04 01:12:31,302 - INFO  - Validation [11][   40/   40]   Loss 0.443853   Top1 90.500000   Top5 99.510000   BatchTime 0.117008   
2022-11-04 01:12:31,541 - INFO  - ==> Top1: 90.500    Top5: 99.510    Loss: 0.444

2022-11-04 01:12:31,602 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:12:31,603 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:12:31,603 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.550   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:12:31,692 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:12:31,693 - INFO  - >>>>>>>> Epoch  12
2022-11-04 01:12:31,694 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:12:35,763 - INFO  - Training [12][   20/  196]   Loss 0.034780   Top1 98.691406   Top5 100.000000   BatchTime 0.203418   LR 0.010000   
2022-11-04 01:12:38,024 - INFO  - Training [12][   40/  196]   Loss 0.029905   Top1 98.847656   Top5 100.000000   BatchTime 0.158239   LR 0.010000   
2022-11-04 01:12:39,931 - INFO  - Training [12][   60/  196]   Loss 0.031059   Top1 98.802083   Top5 100.000000   BatchTime 0.137277   LR 0.010000   
2022-11-04 01:12:42,976 - INFO  - Training [12][   80/  196]   Loss 0.031909   Top1 98.818359   Top5 100.000000   BatchTime 0.141017   LR 0.010000   
2022-11-04 01:12:45,992 - INFO  - Training [12][  100/  196]   Loss 0.030992   Top1 98.847656   Top5 100.000000   BatchTime 0.142973   LR 0.010000   
2022-11-04 01:12:49,011 - INFO  - Training [12][  120/  196]   Loss 0.031315   Top1 98.860677   Top5 100.000000   BatchTime 0.144301   LR 0.010000   
2022-11-04 01:12:52,040 - INFO  - Training [12][  140/  196]   Loss 0.032427   Top1 98.842076   Top5 100.000000   BatchTime 0.145322   LR 0.010000   
2022-11-04 01:12:55,040 - INFO  - Training [12][  160/  196]   Loss 0.032002   Top1 98.845215   Top5 100.000000   BatchTime 0.145910   LR 0.010000   
2022-11-04 01:12:58,047 - INFO  - Training [12][  180/  196]   Loss 0.031556   Top1 98.884549   Top5 100.000000   BatchTime 0.146402   LR 0.010000   
2022-11-04 01:13:00,626 - INFO  - ==> Top1: 98.886    Top5: 100.000    Loss: 0.032

2022-11-04 01:13:00,627 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:13:03,806 - INFO  - Validation [12][   20/   40]   Loss 0.458137   Top1 90.527344   Top5 99.570312   BatchTime 0.158872   
2022-11-04 01:13:05,273 - INFO  - Validation [12][   40/   40]   Loss 0.440626   Top1 90.570000   Top5 99.580000   BatchTime 0.116128   
2022-11-04 01:13:05,511 - INFO  - ==> Top1: 90.570    Top5: 99.580    Loss: 0.441

2022-11-04 01:13:05,552 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:13:05,553 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:13:05,553 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:13:05,663 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:13:05,663 - INFO  - >>>>>>>> Epoch  13
2022-11-04 01:13:05,664 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:13:09,633 - INFO  - Training [13][   20/  196]   Loss 0.026587   Top1 98.925781   Top5 100.000000   BatchTime 0.198420   LR 0.010000   
2022-11-04 01:13:11,933 - INFO  - Training [13][   40/  196]   Loss 0.028188   Top1 98.955078   Top5 100.000000   BatchTime 0.156712   LR 0.010000   
2022-11-04 01:13:13,651 - INFO  - Training [13][   60/  196]   Loss 0.027774   Top1 98.990885   Top5 100.000000   BatchTime 0.133110   LR 0.010000   
2022-11-04 01:13:16,670 - INFO  - Training [13][   80/  196]   Loss 0.028434   Top1 98.950195   Top5 100.000000   BatchTime 0.137563   LR 0.010000   
2022-11-04 01:13:19,700 - INFO  - Training [13][  100/  196]   Loss 0.029311   Top1 98.949219   Top5 100.000000   BatchTime 0.140353   LR 0.010000   
2022-11-04 01:13:22,718 - INFO  - Training [13][  120/  196]   Loss 0.029030   Top1 98.974609   Top5 100.000000   BatchTime 0.142107   LR 0.010000   
2022-11-04 01:13:25,741 - INFO  - Training [13][  140/  196]   Loss 0.029165   Top1 98.962054   Top5 100.000000   BatchTime 0.143402   LR 0.010000   
2022-11-04 01:13:28,752 - INFO  - Training [13][  160/  196]   Loss 0.029758   Top1 98.935547   Top5 100.000000   BatchTime 0.144297   LR 0.010000   
2022-11-04 01:13:31,759 - INFO  - Training [13][  180/  196]   Loss 0.030281   Top1 98.910590   Top5 100.000000   BatchTime 0.144966   LR 0.010000   
2022-11-04 01:13:34,334 - INFO  - ==> Top1: 98.900    Top5: 100.000    Loss: 0.030

2022-11-04 01:13:34,335 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:13:37,505 - INFO  - Validation [13][   20/   40]   Loss 0.459975   Top1 90.390625   Top5 99.687500   BatchTime 0.158447   
2022-11-04 01:13:38,981 - INFO  - Validation [13][   40/   40]   Loss 0.436822   Top1 90.490000   Top5 99.680000   BatchTime 0.116103   
2022-11-04 01:13:39,219 - INFO  - ==> Top1: 90.490    Top5: 99.680    Loss: 0.437

2022-11-04 01:13:39,296 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:13:39,296 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:13:39,296 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:13:39,400 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:13:39,400 - INFO  - >>>>>>>> Epoch  14
2022-11-04 01:13:39,401 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:13:43,563 - INFO  - Training [14][   20/  196]   Loss 0.025494   Top1 99.082031   Top5 100.000000   BatchTime 0.208090   LR 0.010000   
2022-11-04 01:13:45,870 - INFO  - Training [14][   40/  196]   Loss 0.028973   Top1 98.857422   Top5 100.000000   BatchTime 0.161714   LR 0.010000   
2022-11-04 01:13:47,604 - INFO  - Training [14][   60/  196]   Loss 0.030741   Top1 98.847656   Top5 100.000000   BatchTime 0.136708   LR 0.010000   
2022-11-04 01:13:50,609 - INFO  - Training [14][   80/  196]   Loss 0.030260   Top1 98.886719   Top5 100.000000   BatchTime 0.140096   LR 0.010000   
2022-11-04 01:13:53,634 - INFO  - Training [14][  100/  196]   Loss 0.029074   Top1 98.960938   Top5 100.000000   BatchTime 0.142329   LR 0.010000   
2022-11-04 01:13:56,572 - INFO  - Training [14][  120/  196]   Loss 0.028791   Top1 98.971354   Top5 100.000000   BatchTime 0.143093   LR 0.010000   
2022-11-04 01:13:59,603 - INFO  - Training [14][  140/  196]   Loss 0.028749   Top1 98.962054   Top5 100.000000   BatchTime 0.144299   LR 0.010000   
2022-11-04 01:14:02,602 - INFO  - Training [14][  160/  196]   Loss 0.029128   Top1 98.959961   Top5 100.000000   BatchTime 0.145007   LR 0.010000   
2022-11-04 01:14:05,595 - INFO  - Training [14][  180/  196]   Loss 0.029933   Top1 98.943142   Top5 100.000000   BatchTime 0.145522   LR 0.010000   
2022-11-04 01:14:08,179 - INFO  - ==> Top1: 98.940    Top5: 100.000    Loss: 0.030

2022-11-04 01:14:08,180 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:14:11,335 - INFO  - Validation [14][   20/   40]   Loss 0.453526   Top1 90.292969   Top5 99.492188   BatchTime 0.157691   
2022-11-04 01:14:12,840 - INFO  - Validation [14][   40/   40]   Loss 0.438445   Top1 90.480000   Top5 99.570000   BatchTime 0.116453   
2022-11-04 01:14:13,082 - INFO  - ==> Top1: 90.480    Top5: 99.570    Loss: 0.438

2022-11-04 01:14:13,130 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:14:13,131 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:14:13,131 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:14:13,236 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:14:13,236 - INFO  - >>>>>>>> Epoch  15
2022-11-04 01:14:13,237 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:14:17,154 - INFO  - Training [15][   20/  196]   Loss 0.026282   Top1 99.062500   Top5 100.000000   BatchTime 0.195801   LR 0.010000   
2022-11-04 01:14:19,435 - INFO  - Training [15][   40/  196]   Loss 0.026688   Top1 99.111328   Top5 100.000000   BatchTime 0.154930   LR 0.010000   
2022-11-04 01:14:21,309 - INFO  - Training [15][   60/  196]   Loss 0.027384   Top1 99.075521   Top5 100.000000   BatchTime 0.134514   LR 0.010000   
2022-11-04 01:14:24,080 - INFO  - Training [15][   80/  196]   Loss 0.027687   Top1 99.067383   Top5 100.000000   BatchTime 0.135524   LR 0.010000   
2022-11-04 01:14:27,105 - INFO  - Training [15][  100/  196]   Loss 0.027618   Top1 99.046875   Top5 100.000000   BatchTime 0.138670   LR 0.010000   
2022-11-04 01:14:30,129 - INFO  - Training [15][  120/  196]   Loss 0.028269   Top1 99.023438   Top5 100.000000   BatchTime 0.140761   LR 0.010000   
2022-11-04 01:14:33,133 - INFO  - Training [15][  140/  196]   Loss 0.028472   Top1 99.015067   Top5 100.000000   BatchTime 0.142105   LR 0.010000   
2022-11-04 01:14:36,148 - INFO  - Training [15][  160/  196]   Loss 0.028892   Top1 99.003906   Top5 100.000000   BatchTime 0.143188   LR 0.010000   
2022-11-04 01:14:39,160 - INFO  - Training [15][  180/  196]   Loss 0.029495   Top1 98.990885   Top5 100.000000   BatchTime 0.144009   LR 0.010000   
2022-11-04 01:14:41,775 - INFO  - ==> Top1: 98.994    Top5: 100.000    Loss: 0.030

2022-11-04 01:14:41,775 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:14:44,955 - INFO  - Validation [15][   20/   40]   Loss 0.453889   Top1 90.312500   Top5 99.628906   BatchTime 0.158902   
2022-11-04 01:14:46,459 - INFO  - Validation [15][   40/   40]   Loss 0.441252   Top1 90.420000   Top5 99.680000   BatchTime 0.117056   
2022-11-04 01:14:46,691 - INFO  - ==> Top1: 90.420    Top5: 99.680    Loss: 0.441

2022-11-04 01:14:46,744 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:14:46,745 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:14:46,745 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.570   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:14:46,876 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:14:46,876 - INFO  - >>>>>>>> Epoch  16
2022-11-04 01:14:46,877 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:14:50,722 - INFO  - Training [16][   20/  196]   Loss 0.026293   Top1 98.964844   Top5 100.000000   BatchTime 0.192214   LR 0.010000   
2022-11-04 01:14:52,989 - INFO  - Training [16][   40/  196]   Loss 0.027217   Top1 98.964844   Top5 100.000000   BatchTime 0.152775   LR 0.010000   
2022-11-04 01:14:54,949 - INFO  - Training [16][   60/  196]   Loss 0.028179   Top1 98.932292   Top5 100.000000   BatchTime 0.134520   LR 0.010000   
2022-11-04 01:14:57,678 - INFO  - Training [16][   80/  196]   Loss 0.027769   Top1 98.955078   Top5 100.000000   BatchTime 0.135002   LR 0.010000   
2022-11-04 01:15:00,709 - INFO  - Training [16][  100/  196]   Loss 0.027964   Top1 98.949219   Top5 100.000000   BatchTime 0.138314   LR 0.010000   
2022-11-04 01:15:03,722 - INFO  - Training [16][  120/  196]   Loss 0.027353   Top1 98.997396   Top5 100.000000   BatchTime 0.140366   LR 0.010000   
2022-11-04 01:15:06,712 - INFO  - Training [16][  140/  196]   Loss 0.027626   Top1 99.003906   Top5 100.000000   BatchTime 0.141673   LR 0.010000   
2022-11-04 01:15:09,722 - INFO  - Training [16][  160/  196]   Loss 0.028390   Top1 98.974609   Top5 100.000000   BatchTime 0.142777   LR 0.010000   
2022-11-04 01:15:12,733 - INFO  - Training [16][  180/  196]   Loss 0.028488   Top1 98.973524   Top5 100.000000   BatchTime 0.143639   LR 0.010000   
2022-11-04 01:15:15,314 - INFO  - ==> Top1: 98.980    Top5: 100.000    Loss: 0.028

2022-11-04 01:15:15,315 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:15:18,477 - INFO  - Validation [16][   20/   40]   Loss 0.464504   Top1 90.625000   Top5 99.511719   BatchTime 0.158003   
2022-11-04 01:15:19,967 - INFO  - Validation [16][   40/   40]   Loss 0.449164   Top1 90.670000   Top5 99.640000   BatchTime 0.116249   
2022-11-04 01:15:20,201 - INFO  - ==> Top1: 90.670    Top5: 99.640    Loss: 0.449

2022-11-04 01:15:20,240 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:15:20,240 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:15:20,241 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:15:20,465 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:15:20,642 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:15:20,642 - INFO  - >>>>>>>> Epoch  17
2022-11-04 01:15:20,643 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:15:24,462 - INFO  - Training [17][   20/  196]   Loss 0.029159   Top1 99.082031   Top5 100.000000   BatchTime 0.190941   LR 0.010000   
2022-11-04 01:15:26,731 - INFO  - Training [17][   40/  196]   Loss 0.026081   Top1 99.169922   Top5 100.000000   BatchTime 0.152199   LR 0.010000   
2022-11-04 01:15:28,596 - INFO  - Training [17][   60/  196]   Loss 0.025835   Top1 99.166667   Top5 100.000000   BatchTime 0.132553   LR 0.010000   
2022-11-04 01:15:31,229 - INFO  - Training [17][   80/  196]   Loss 0.027195   Top1 99.082031   Top5 100.000000   BatchTime 0.132326   LR 0.010000   
2022-11-04 01:15:34,255 - INFO  - Training [17][  100/  196]   Loss 0.026392   Top1 99.132812   Top5 100.000000   BatchTime 0.136114   LR 0.010000   
2022-11-04 01:15:37,274 - INFO  - Training [17][  120/  196]   Loss 0.026575   Top1 99.134115   Top5 100.000000   BatchTime 0.138589   LR 0.010000   
2022-11-04 01:15:40,283 - INFO  - Training [17][  140/  196]   Loss 0.026584   Top1 99.118304   Top5 100.000000   BatchTime 0.140281   LR 0.010000   
2022-11-04 01:15:43,278 - INFO  - Training [17][  160/  196]   Loss 0.026665   Top1 99.108887   Top5 100.000000   BatchTime 0.141466   LR 0.010000   
2022-11-04 01:15:46,292 - INFO  - Training [17][  180/  196]   Loss 0.026871   Top1 99.097222   Top5 100.000000   BatchTime 0.142493   LR 0.010000   
2022-11-04 01:15:48,869 - INFO  - ==> Top1: 99.106    Top5: 100.000    Loss: 0.027

2022-11-04 01:15:48,870 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:15:52,068 - INFO  - Validation [17][   20/   40]   Loss 0.453575   Top1 90.468750   Top5 99.335938   BatchTime 0.159823   
2022-11-04 01:15:53,555 - INFO  - Validation [17][   40/   40]   Loss 0.441660   Top1 90.560000   Top5 99.540000   BatchTime 0.117102   
2022-11-04 01:15:53,789 - INFO  - ==> Top1: 90.560    Top5: 99.540    Loss: 0.442

2022-11-04 01:15:53,820 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:15:53,821 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:15:53,821 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.580   Top5: 99.670] Sparsity : 0.827
2022-11-04 01:15:53,906 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:15:53,906 - INFO  - >>>>>>>> Epoch  18
2022-11-04 01:15:53,907 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:15:57,703 - INFO  - Training [18][   20/  196]   Loss 0.027062   Top1 99.121094   Top5 100.000000   BatchTime 0.189818   LR 0.010000   
2022-11-04 01:15:59,962 - INFO  - Training [18][   40/  196]   Loss 0.024962   Top1 99.169922   Top5 100.000000   BatchTime 0.151371   LR 0.010000   
2022-11-04 01:16:02,033 - INFO  - Training [18][   60/  196]   Loss 0.025863   Top1 99.121094   Top5 100.000000   BatchTime 0.135426   LR 0.010000   
2022-11-04 01:16:04,477 - INFO  - Training [18][   80/  196]   Loss 0.025546   Top1 99.140625   Top5 100.000000   BatchTime 0.132119   LR 0.010000   
2022-11-04 01:16:07,505 - INFO  - Training [18][  100/  196]   Loss 0.026277   Top1 99.093750   Top5 99.996094   BatchTime 0.135975   LR 0.010000   
2022-11-04 01:16:10,512 - INFO  - Training [18][  120/  196]   Loss 0.027577   Top1 99.055990   Top5 99.996745   BatchTime 0.138370   LR 0.010000   
2022-11-04 01:16:13,533 - INFO  - Training [18][  140/  196]   Loss 0.027836   Top1 99.059710   Top5 99.997210   BatchTime 0.140185   LR 0.010000   
2022-11-04 01:16:16,531 - INFO  - Training [18][  160/  196]   Loss 0.027533   Top1 99.067383   Top5 99.995117   BatchTime 0.141401   LR 0.010000   
2022-11-04 01:16:19,472 - INFO  - Training [18][  180/  196]   Loss 0.028192   Top1 99.060330   Top5 99.995660   BatchTime 0.142024   LR 0.010000   
2022-11-04 01:16:22,040 - INFO  - ==> Top1: 99.068    Top5: 99.996    Loss: 0.028

2022-11-04 01:16:22,040 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:16:25,234 - INFO  - Validation [18][   20/   40]   Loss 0.459623   Top1 90.664062   Top5 99.375000   BatchTime 0.159648   
2022-11-04 01:16:26,713 - INFO  - Validation [18][   40/   40]   Loss 0.448657   Top1 90.630000   Top5 99.540000   BatchTime 0.116793   
2022-11-04 01:16:26,943 - INFO  - ==> Top1: 90.630    Top5: 99.540    Loss: 0.449

2022-11-04 01:16:27,016 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:16:27,017 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:16:27,017 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:16:27,126 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:16:27,126 - INFO  - >>>>>>>> Epoch  19
2022-11-04 01:16:27,128 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:16:30,827 - INFO  - Training [19][   20/  196]   Loss 0.021685   Top1 99.355469   Top5 100.000000   BatchTime 0.184967   LR 0.010000   
2022-11-04 01:16:33,050 - INFO  - Training [19][   40/  196]   Loss 0.022089   Top1 99.267578   Top5 100.000000   BatchTime 0.148048   LR 0.010000   
2022-11-04 01:16:35,093 - INFO  - Training [19][   60/  196]   Loss 0.023411   Top1 99.205729   Top5 100.000000   BatchTime 0.132756   LR 0.010000   
2022-11-04 01:16:37,268 - INFO  - Training [19][   80/  196]   Loss 0.023164   Top1 99.204102   Top5 100.000000   BatchTime 0.126747   LR 0.010000   
2022-11-04 01:16:40,341 - INFO  - Training [19][  100/  196]   Loss 0.023543   Top1 99.171875   Top5 100.000000   BatchTime 0.132130   LR 0.010000   
2022-11-04 01:16:43,364 - INFO  - Training [19][  120/  196]   Loss 0.024153   Top1 99.153646   Top5 100.000000   BatchTime 0.135302   LR 0.010000   
2022-11-04 01:16:46,371 - INFO  - Training [19][  140/  196]   Loss 0.024553   Top1 99.154576   Top5 100.000000   BatchTime 0.137451   LR 0.010000   
2022-11-04 01:16:49,392 - INFO  - Training [19][  160/  196]   Loss 0.024875   Top1 99.150391   Top5 100.000000   BatchTime 0.139146   LR 0.010000   
2022-11-04 01:16:52,394 - INFO  - Training [19][  180/  196]   Loss 0.025442   Top1 99.118924   Top5 100.000000   BatchTime 0.140368   LR 0.010000   
2022-11-04 01:16:54,978 - INFO  - ==> Top1: 99.124    Top5: 100.000    Loss: 0.025

2022-11-04 01:16:54,979 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:16:58,201 - INFO  - Validation [19][   20/   40]   Loss 0.466178   Top1 90.429688   Top5 99.414062   BatchTime 0.161039   
2022-11-04 01:16:59,680 - INFO  - Validation [19][   40/   40]   Loss 0.445522   Top1 90.570000   Top5 99.530000   BatchTime 0.117493   
2022-11-04 01:16:59,916 - INFO  - ==> Top1: 90.570    Top5: 99.530    Loss: 0.446

2022-11-04 01:16:59,989 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:16:59,990 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:16:59,990 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 90.600   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:17:00,063 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:17:00,063 - INFO  - >>>>>>>> Epoch  20
2022-11-04 01:17:00,064 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:17:03,980 - INFO  - Training [20][   20/  196]   Loss 0.024721   Top1 99.121094   Top5 100.000000   BatchTime 0.195816   LR 0.010000   
2022-11-04 01:17:06,092 - INFO  - Training [20][   40/  196]   Loss 0.026047   Top1 99.042969   Top5 100.000000   BatchTime 0.150702   LR 0.010000   
2022-11-04 01:17:08,252 - INFO  - Training [20][   60/  196]   Loss 0.028737   Top1 98.990885   Top5 100.000000   BatchTime 0.136461   LR 0.010000   
2022-11-04 01:17:10,136 - INFO  - Training [20][   80/  196]   Loss 0.028376   Top1 99.023438   Top5 100.000000   BatchTime 0.125893   LR 0.010000   
2022-11-04 01:17:13,162 - INFO  - Training [20][  100/  196]   Loss 0.027918   Top1 99.023438   Top5 100.000000   BatchTime 0.130979   LR 0.010000   
2022-11-04 01:17:16,195 - INFO  - Training [20][  120/  196]   Loss 0.027641   Top1 99.049479   Top5 100.000000   BatchTime 0.134420   LR 0.010000   
2022-11-04 01:17:19,211 - INFO  - Training [20][  140/  196]   Loss 0.027383   Top1 99.059710   Top5 100.000000   BatchTime 0.136760   LR 0.010000   
2022-11-04 01:17:22,203 - INFO  - Training [20][  160/  196]   Loss 0.027788   Top1 99.057617   Top5 100.000000   BatchTime 0.138368   LR 0.010000   
2022-11-04 01:17:25,196 - INFO  - Training [20][  180/  196]   Loss 0.028319   Top1 99.058160   Top5 100.000000   BatchTime 0.139620   LR 0.010000   
2022-11-04 01:17:27,786 - INFO  - ==> Top1: 99.050    Top5: 100.000    Loss: 0.029

2022-11-04 01:17:27,787 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:17:31,000 - INFO  - Validation [20][   20/   40]   Loss 0.462125   Top1 90.585938   Top5 99.394531   BatchTime 0.160539   
2022-11-04 01:17:32,477 - INFO  - Validation [20][   40/   40]   Loss 0.448622   Top1 90.650000   Top5 99.530000   BatchTime 0.117197   
2022-11-04 01:17:32,698 - INFO  - ==> Top1: 90.650    Top5: 99.530    Loss: 0.449

2022-11-04 01:17:32,768 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:17:32,769 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
2022-11-04 01:17:32,769 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:17:32,876 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:17:32,876 - INFO  - >>>>>>>> Epoch  21
2022-11-04 01:17:32,878 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:17:37,083 - INFO  - Training [21][   20/  196]   Loss 0.019054   Top1 99.257812   Top5 100.000000   BatchTime 0.210234   LR 0.010000   
2022-11-04 01:17:39,094 - INFO  - Training [21][   40/  196]   Loss 0.022475   Top1 99.150391   Top5 100.000000   BatchTime 0.155396   LR 0.010000   
2022-11-04 01:17:41,446 - INFO  - Training [21][   60/  196]   Loss 0.024051   Top1 99.114583   Top5 100.000000   BatchTime 0.142805   LR 0.010000   
2022-11-04 01:17:43,157 - INFO  - Training [21][   80/  196]   Loss 0.025666   Top1 99.091797   Top5 100.000000   BatchTime 0.128488   LR 0.010000   
2022-11-04 01:17:46,151 - INFO  - Training [21][  100/  196]   Loss 0.025807   Top1 99.082031   Top5 100.000000   BatchTime 0.132731   LR 0.010000   
2022-11-04 01:17:49,168 - INFO  - Training [21][  120/  196]   Loss 0.025527   Top1 99.091797   Top5 100.000000   BatchTime 0.135751   LR 0.010000   
2022-11-04 01:17:52,186 - INFO  - Training [21][  140/  196]   Loss 0.025405   Top1 99.095982   Top5 100.000000   BatchTime 0.137909   LR 0.010000   
2022-11-04 01:17:55,188 - INFO  - Training [21][  160/  196]   Loss 0.025655   Top1 99.094238   Top5 100.000000   BatchTime 0.139436   LR 0.010000   
2022-11-04 01:17:58,184 - INFO  - Training [21][  180/  196]   Loss 0.025905   Top1 99.092882   Top5 100.000000   BatchTime 0.140587   LR 0.010000   
2022-11-04 01:18:00,772 - INFO  - ==> Top1: 99.094    Top5: 100.000    Loss: 0.026

2022-11-04 01:18:00,773 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:18:03,948 - INFO  - Validation [21][   20/   40]   Loss 0.470151   Top1 90.175781   Top5 99.531250   BatchTime 0.158635   
2022-11-04 01:18:05,419 - INFO  - Validation [21][   40/   40]   Loss 0.461824   Top1 90.320000   Top5 99.620000   BatchTime 0.116092   
2022-11-04 01:18:05,654 - INFO  - ==> Top1: 90.320    Top5: 99.620    Loss: 0.462

2022-11-04 01:18:05,727 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:18:05,728 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
2022-11-04 01:18:05,728 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 90.630   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:18:05,832 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:18:05,832 - INFO  - >>>>>>>> Epoch  22
2022-11-04 01:18:05,833 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:18:10,260 - INFO  - Training [22][   20/  196]   Loss 0.031012   Top1 98.984375   Top5 100.000000   BatchTime 0.221345   LR 0.010000   
2022-11-04 01:18:12,184 - INFO  - Training [22][   40/  196]   Loss 0.027211   Top1 99.072266   Top5 100.000000   BatchTime 0.158771   LR 0.010000   
2022-11-04 01:18:14,459 - INFO  - Training [22][   60/  196]   Loss 0.026342   Top1 99.108073   Top5 100.000000   BatchTime 0.143760   LR 0.010000   
2022-11-04 01:18:16,449 - INFO  - Training [22][   80/  196]   Loss 0.025922   Top1 99.130859   Top5 100.000000   BatchTime 0.132687   LR 0.010000   
2022-11-04 01:18:19,431 - INFO  - Training [22][  100/  196]   Loss 0.025907   Top1 99.109375   Top5 100.000000   BatchTime 0.135974   LR 0.010000   
2022-11-04 01:18:22,463 - INFO  - Training [22][  120/  196]   Loss 0.025793   Top1 99.114583   Top5 100.000000   BatchTime 0.138577   LR 0.010000   
2022-11-04 01:18:25,479 - INFO  - Training [22][  140/  196]   Loss 0.026109   Top1 99.109933   Top5 100.000000   BatchTime 0.140326   LR 0.010000   
2022-11-04 01:18:28,473 - INFO  - Training [22][  160/  196]   Loss 0.025917   Top1 99.118652   Top5 100.000000   BatchTime 0.141492   LR 0.010000   
2022-11-04 01:18:31,477 - INFO  - Training [22][  180/  196]   Loss 0.026007   Top1 99.092882   Top5 100.000000   BatchTime 0.142462   LR 0.010000   
2022-11-04 01:18:34,061 - INFO  - ==> Top1: 99.084    Top5: 100.000    Loss: 0.026

2022-11-04 01:18:34,061 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:18:37,107 - INFO  - Validation [22][   20/   40]   Loss 0.446938   Top1 90.703125   Top5 99.550781   BatchTime 0.152260   
2022-11-04 01:18:38,589 - INFO  - Validation [22][   40/   40]   Loss 0.442373   Top1 90.730000   Top5 99.620000   BatchTime 0.113169   
2022-11-04 01:18:38,833 - INFO  - ==> Top1: 90.730    Top5: 99.620    Loss: 0.442

2022-11-04 01:18:38,896 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:18:38,897 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:18:38,897 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
2022-11-04 01:18:39,085 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:18:39,298 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:18:39,299 - INFO  - >>>>>>>> Epoch  23
2022-11-04 01:18:39,300 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:18:43,681 - INFO  - Training [23][   20/  196]   Loss 0.021535   Top1 99.140625   Top5 100.000000   BatchTime 0.219033   LR 0.010000   
2022-11-04 01:18:45,622 - INFO  - Training [23][   40/  196]   Loss 0.022148   Top1 99.169922   Top5 100.000000   BatchTime 0.158032   LR 0.010000   
2022-11-04 01:18:47,885 - INFO  - Training [23][   60/  196]   Loss 0.022438   Top1 99.166667   Top5 100.000000   BatchTime 0.143078   LR 0.010000   
2022-11-04 01:18:49,711 - INFO  - Training [23][   80/  196]   Loss 0.023715   Top1 99.179688   Top5 100.000000   BatchTime 0.130137   LR 0.010000   
2022-11-04 01:18:52,372 - INFO  - Training [23][  100/  196]   Loss 0.023731   Top1 99.171875   Top5 100.000000   BatchTime 0.130712   LR 0.010000   
2022-11-04 01:18:55,401 - INFO  - Training [23][  120/  196]   Loss 0.023910   Top1 99.169922   Top5 100.000000   BatchTime 0.134167   LR 0.010000   
2022-11-04 01:18:58,422 - INFO  - Training [23][  140/  196]   Loss 0.023722   Top1 99.182478   Top5 100.000000   BatchTime 0.136581   LR 0.010000   
2022-11-04 01:19:01,439 - INFO  - Training [23][  160/  196]   Loss 0.024197   Top1 99.174805   Top5 100.000000   BatchTime 0.138363   LR 0.010000   
2022-11-04 01:19:04,438 - INFO  - Training [23][  180/  196]   Loss 0.024297   Top1 99.175347   Top5 100.000000   BatchTime 0.139652   LR 0.010000   
2022-11-04 01:19:07,011 - INFO  - ==> Top1: 99.168    Top5: 100.000    Loss: 0.025

2022-11-04 01:19:07,012 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:19:10,204 - INFO  - Validation [23][   20/   40]   Loss 0.475016   Top1 90.156250   Top5 99.414062   BatchTime 0.159565   
2022-11-04 01:19:11,676 - INFO  - Validation [23][   40/   40]   Loss 0.461854   Top1 90.430000   Top5 99.530000   BatchTime 0.116576   
2022-11-04 01:19:11,920 - INFO  - ==> Top1: 90.430    Top5: 99.530    Loss: 0.462

2022-11-04 01:19:11,987 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:19:11,988 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:19:11,988 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.650   Top5: 99.530] Sparsity : 0.827
2022-11-04 01:19:12,086 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:19:12,086 - INFO  - >>>>>>>> Epoch  24
2022-11-04 01:19:12,087 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:19:16,798 - INFO  - Training [24][   20/  196]   Loss 0.021320   Top1 99.238281   Top5 100.000000   BatchTime 0.235508   LR 0.010000   
2022-11-04 01:19:18,615 - INFO  - Training [24][   40/  196]   Loss 0.021694   Top1 99.218750   Top5 100.000000   BatchTime 0.163196   LR 0.010000   
2022-11-04 01:19:20,897 - INFO  - Training [24][   60/  196]   Loss 0.022401   Top1 99.205729   Top5 100.000000   BatchTime 0.146828   LR 0.010000   
2022-11-04 01:19:22,877 - INFO  - Training [24][   80/  196]   Loss 0.023406   Top1 99.174805   Top5 100.000000   BatchTime 0.134872   LR 0.010000   
2022-11-04 01:19:25,420 - INFO  - Training [24][  100/  196]   Loss 0.024022   Top1 99.171875   Top5 100.000000   BatchTime 0.133328   LR 0.010000   
2022-11-04 01:19:28,441 - INFO  - Training [24][  120/  196]   Loss 0.023774   Top1 99.189453   Top5 100.000000   BatchTime 0.136278   LR 0.010000   
2022-11-04 01:19:31,449 - INFO  - Training [24][  140/  196]   Loss 0.023617   Top1 99.204799   Top5 100.000000   BatchTime 0.138292   LR 0.010000   
2022-11-04 01:19:34,465 - INFO  - Training [24][  160/  196]   Loss 0.023606   Top1 99.201660   Top5 100.000000   BatchTime 0.139856   LR 0.010000   
2022-11-04 01:19:37,456 - INFO  - Training [24][  180/  196]   Loss 0.024906   Top1 99.160156   Top5 100.000000   BatchTime 0.140934   LR 0.010000   
2022-11-04 01:19:40,051 - INFO  - ==> Top1: 99.156    Top5: 100.000    Loss: 0.025

2022-11-04 01:19:40,052 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:19:43,249 - INFO  - Validation [24][   20/   40]   Loss 0.478948   Top1 90.742188   Top5 99.375000   BatchTime 0.159820   
2022-11-04 01:19:44,765 - INFO  - Validation [24][   40/   40]   Loss 0.464886   Top1 90.770000   Top5 99.550000   BatchTime 0.117816   
2022-11-04 01:19:45,006 - INFO  - ==> Top1: 90.770    Top5: 99.550    Loss: 0.465

2022-11-04 01:19:45,044 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:19:45,045 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:19:45,045 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:19:45,263 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:19:45,457 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:19:45,457 - INFO  - >>>>>>>> Epoch  25
2022-11-04 01:19:45,459 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:19:50,015 - INFO  - Training [25][   20/  196]   Loss 0.023247   Top1 99.335938   Top5 100.000000   BatchTime 0.227800   LR 0.010000   
2022-11-04 01:19:51,874 - INFO  - Training [25][   40/  196]   Loss 0.021155   Top1 99.384766   Top5 100.000000   BatchTime 0.160387   LR 0.010000   
2022-11-04 01:19:54,154 - INFO  - Training [25][   60/  196]   Loss 0.022309   Top1 99.309896   Top5 100.000000   BatchTime 0.144920   LR 0.010000   
2022-11-04 01:19:56,067 - INFO  - Training [25][   80/  196]   Loss 0.024198   Top1 99.213867   Top5 100.000000   BatchTime 0.132594   LR 0.010000   
2022-11-04 01:19:58,679 - INFO  - Training [25][  100/  196]   Loss 0.025176   Top1 99.175781   Top5 100.000000   BatchTime 0.132196   LR 0.010000   
2022-11-04 01:20:01,699 - INFO  - Training [25][  120/  196]   Loss 0.024908   Top1 99.166667   Top5 100.000000   BatchTime 0.135333   LR 0.010000   
2022-11-04 01:20:04,719 - INFO  - Training [25][  140/  196]   Loss 0.024575   Top1 99.174107   Top5 100.000000   BatchTime 0.137569   LR 0.010000   
2022-11-04 01:20:07,713 - INFO  - Training [25][  160/  196]   Loss 0.024800   Top1 99.162598   Top5 100.000000   BatchTime 0.139086   LR 0.010000   
2022-11-04 01:20:10,727 - INFO  - Training [25][  180/  196]   Loss 0.024424   Top1 99.175347   Top5 100.000000   BatchTime 0.140378   LR 0.010000   
2022-11-04 01:20:13,314 - INFO  - ==> Top1: 99.158    Top5: 100.000    Loss: 0.025

2022-11-04 01:20:13,314 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:20:16,522 - INFO  - Validation [25][   20/   40]   Loss 0.480095   Top1 90.292969   Top5 99.394531   BatchTime 0.160291   
2022-11-04 01:20:18,002 - INFO  - Validation [25][   40/   40]   Loss 0.458020   Top1 90.580000   Top5 99.510000   BatchTime 0.117152   
2022-11-04 01:20:18,243 - INFO  - ==> Top1: 90.580    Top5: 99.510    Loss: 0.458

2022-11-04 01:20:18,281 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:20:18,282 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:20:18,282 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:20:18,386 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:20:18,386 - INFO  - >>>>>>>> Epoch  26
2022-11-04 01:20:18,387 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:20:23,215 - INFO  - Training [26][   20/  196]   Loss 0.015810   Top1 99.492188   Top5 100.000000   BatchTime 0.241413   LR 0.010000   
2022-11-04 01:20:24,941 - INFO  - Training [26][   40/  196]   Loss 0.018963   Top1 99.375000   Top5 100.000000   BatchTime 0.163840   LR 0.010000   
2022-11-04 01:20:27,347 - INFO  - Training [26][   60/  196]   Loss 0.020569   Top1 99.316406   Top5 100.000000   BatchTime 0.149336   LR 0.010000   
2022-11-04 01:20:29,313 - INFO  - Training [26][   80/  196]   Loss 0.021436   Top1 99.287109   Top5 99.995117   BatchTime 0.136573   LR 0.010000   
2022-11-04 01:20:31,754 - INFO  - Training [26][  100/  196]   Loss 0.021943   Top1 99.257812   Top5 99.996094   BatchTime 0.133663   LR 0.010000   
2022-11-04 01:20:34,786 - INFO  - Training [26][  120/  196]   Loss 0.022908   Top1 99.225260   Top5 99.996745   BatchTime 0.136655   LR 0.010000   
2022-11-04 01:20:37,795 - INFO  - Training [26][  140/  196]   Loss 0.022554   Top1 99.241071   Top5 99.994420   BatchTime 0.138624   LR 0.010000   
2022-11-04 01:20:40,797 - INFO  - Training [26][  160/  196]   Loss 0.023021   Top1 99.238281   Top5 99.995117   BatchTime 0.140061   LR 0.010000   
2022-11-04 01:20:43,811 - INFO  - Training [26][  180/  196]   Loss 0.023479   Top1 99.227431   Top5 99.995660   BatchTime 0.141245   LR 0.010000   
2022-11-04 01:20:46,395 - INFO  - ==> Top1: 99.226    Top5: 99.996    Loss: 0.023

2022-11-04 01:20:46,396 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:20:49,611 - INFO  - Validation [26][   20/   40]   Loss 0.484872   Top1 90.156250   Top5 99.550781   BatchTime 0.160661   
2022-11-04 01:20:51,088 - INFO  - Validation [26][   40/   40]   Loss 0.466915   Top1 90.540000   Top5 99.610000   BatchTime 0.117260   
2022-11-04 01:20:51,318 - INFO  - ==> Top1: 90.540    Top5: 99.610    Loss: 0.467

2022-11-04 01:20:51,373 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:20:51,374 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:20:51,374 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:20:51,485 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:20:51,485 - INFO  - >>>>>>>> Epoch  27
2022-11-04 01:20:51,487 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:20:56,202 - INFO  - Training [27][   20/  196]   Loss 0.024780   Top1 99.238281   Top5 100.000000   BatchTime 0.235765   LR 0.010000   
2022-11-04 01:20:58,162 - INFO  - Training [27][   40/  196]   Loss 0.023580   Top1 99.189453   Top5 100.000000   BatchTime 0.166870   LR 0.010000   
2022-11-04 01:21:00,354 - INFO  - Training [27][   60/  196]   Loss 0.024683   Top1 99.147135   Top5 100.000000   BatchTime 0.147781   LR 0.010000   
2022-11-04 01:21:02,441 - INFO  - Training [27][   80/  196]   Loss 0.024910   Top1 99.101562   Top5 100.000000   BatchTime 0.136932   LR 0.010000   
2022-11-04 01:21:04,536 - INFO  - Training [27][  100/  196]   Loss 0.025063   Top1 99.101562   Top5 100.000000   BatchTime 0.130489   LR 0.010000   
2022-11-04 01:21:07,536 - INFO  - Training [27][  120/  196]   Loss 0.024079   Top1 99.127604   Top5 100.000000   BatchTime 0.133742   LR 0.010000   
2022-11-04 01:21:10,548 - INFO  - Training [27][  140/  196]   Loss 0.023486   Top1 99.143415   Top5 100.000000   BatchTime 0.136146   LR 0.010000   
2022-11-04 01:21:13,569 - INFO  - Training [27][  160/  196]   Loss 0.023529   Top1 99.145508   Top5 100.000000   BatchTime 0.138011   LR 0.010000   
2022-11-04 01:21:16,580 - INFO  - Training [27][  180/  196]   Loss 0.023436   Top1 99.149306   Top5 100.000000   BatchTime 0.139403   LR 0.010000   
2022-11-04 01:21:19,161 - INFO  - ==> Top1: 99.148    Top5: 100.000    Loss: 0.024

2022-11-04 01:21:19,162 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:21:22,393 - INFO  - Validation [27][   20/   40]   Loss 0.483721   Top1 90.292969   Top5 99.335938   BatchTime 0.161473   
2022-11-04 01:21:23,887 - INFO  - Validation [27][   40/   40]   Loss 0.459833   Top1 90.520000   Top5 99.500000   BatchTime 0.118105   
2022-11-04 01:21:24,125 - INFO  - ==> Top1: 90.520    Top5: 99.500    Loss: 0.460

2022-11-04 01:21:24,195 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:21:24,196 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:21:24,196 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 90.670   Top5: 99.640] Sparsity : 0.827
2022-11-04 01:21:24,281 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:21:24,282 - INFO  - >>>>>>>> Epoch  28
2022-11-04 01:21:24,283 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:21:29,068 - INFO  - Training [28][   20/  196]   Loss 0.020933   Top1 99.199219   Top5 100.000000   BatchTime 0.239280   LR 0.010000   
2022-11-04 01:21:31,300 - INFO  - Training [28][   40/  196]   Loss 0.022064   Top1 99.238281   Top5 100.000000   BatchTime 0.175422   LR 0.010000   
2022-11-04 01:21:33,417 - INFO  - Training [28][   60/  196]   Loss 0.020483   Top1 99.290365   Top5 100.000000   BatchTime 0.152227   LR 0.010000   
2022-11-04 01:21:35,588 - INFO  - Training [28][   80/  196]   Loss 0.020979   Top1 99.257812   Top5 100.000000   BatchTime 0.141315   LR 0.010000   
2022-11-04 01:21:37,479 - INFO  - Training [28][  100/  196]   Loss 0.020492   Top1 99.269531   Top5 100.000000   BatchTime 0.131959   LR 0.010000   
2022-11-04 01:21:40,454 - INFO  - Training [28][  120/  196]   Loss 0.021051   Top1 99.225260   Top5 100.000000   BatchTime 0.134754   LR 0.010000   
2022-11-04 01:21:43,468 - INFO  - Training [28][  140/  196]   Loss 0.021196   Top1 99.221540   Top5 100.000000   BatchTime 0.137033   LR 0.010000   
2022-11-04 01:21:46,491 - INFO  - Training [28][  160/  196]   Loss 0.020845   Top1 99.250488   Top5 100.000000   BatchTime 0.138799   LR 0.010000   
2022-11-04 01:21:49,487 - INFO  - Training [28][  180/  196]   Loss 0.021303   Top1 99.238281   Top5 100.000000   BatchTime 0.140023   LR 0.010000   
2022-11-04 01:21:52,075 - INFO  - ==> Top1: 99.216    Top5: 100.000    Loss: 0.022

2022-11-04 01:21:52,076 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:21:55,283 - INFO  - Validation [28][   20/   40]   Loss 0.478783   Top1 90.664062   Top5 99.414062   BatchTime 0.160268   
2022-11-04 01:21:56,797 - INFO  - Validation [28][   40/   40]   Loss 0.461122   Top1 90.830000   Top5 99.560000   BatchTime 0.117982   
2022-11-04 01:21:57,029 - INFO  - ==> Top1: 90.830    Top5: 99.560    Loss: 0.461

2022-11-04 01:21:57,061 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:21:57,062 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:21:57,062 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:21:57,227 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:21:57,391 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:21:57,391 - INFO  - >>>>>>>> Epoch  29
2022-11-04 01:21:57,392 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:22:02,221 - INFO  - Training [29][   20/  196]   Loss 0.015748   Top1 99.414062   Top5 100.000000   BatchTime 0.241432   LR 0.010000   
2022-11-04 01:22:04,529 - INFO  - Training [29][   40/  196]   Loss 0.016529   Top1 99.443359   Top5 100.000000   BatchTime 0.178411   LR 0.010000   
2022-11-04 01:22:06,585 - INFO  - Training [29][   60/  196]   Loss 0.017521   Top1 99.420573   Top5 100.000000   BatchTime 0.153213   LR 0.010000   
2022-11-04 01:22:08,903 - INFO  - Training [29][   80/  196]   Loss 0.018740   Top1 99.316406   Top5 100.000000   BatchTime 0.143887   LR 0.010000   
2022-11-04 01:22:10,636 - INFO  - Training [29][  100/  196]   Loss 0.019234   Top1 99.316406   Top5 100.000000   BatchTime 0.132438   LR 0.010000   
2022-11-04 01:22:13,765 - INFO  - Training [29][  120/  196]   Loss 0.020057   Top1 99.303385   Top5 100.000000   BatchTime 0.136436   LR 0.010000   
2022-11-04 01:22:16,769 - INFO  - Training [29][  140/  196]   Loss 0.020898   Top1 99.291295   Top5 100.000000   BatchTime 0.138403   LR 0.010000   
2022-11-04 01:22:19,772 - INFO  - Training [29][  160/  196]   Loss 0.021241   Top1 99.287109   Top5 100.000000   BatchTime 0.139873   LR 0.010000   
2022-11-04 01:22:22,759 - INFO  - Training [29][  180/  196]   Loss 0.021520   Top1 99.279514   Top5 100.000000   BatchTime 0.140925   LR 0.010000   
2022-11-04 01:22:25,348 - INFO  - ==> Top1: 99.274    Top5: 100.000    Loss: 0.022

2022-11-04 01:22:25,349 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:22:28,546 - INFO  - Validation [29][   20/   40]   Loss 0.483510   Top1 90.058594   Top5 99.375000   BatchTime 0.159791   
2022-11-04 01:22:30,064 - INFO  - Validation [29][   40/   40]   Loss 0.467497   Top1 90.250000   Top5 99.510000   BatchTime 0.117851   
2022-11-04 01:22:30,315 - INFO  - ==> Top1: 90.250    Top5: 99.510    Loss: 0.467

2022-11-04 01:22:30,362 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:22:30,363 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:22:30,363 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 90.730   Top5: 99.620] Sparsity : 0.827
2022-11-04 01:22:30,467 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:22:30,467 - INFO  - >>>>>>>> Epoch  30
2022-11-04 01:22:30,468 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:22:35,330 - INFO  - Training [30][   20/  196]   Loss 0.022003   Top1 99.238281   Top5 100.000000   BatchTime 0.243083   LR 0.001000   
2022-11-04 01:22:37,796 - INFO  - Training [30][   40/  196]   Loss 0.021288   Top1 99.218750   Top5 100.000000   BatchTime 0.183186   LR 0.001000   
2022-11-04 01:22:39,796 - INFO  - Training [30][   60/  196]   Loss 0.021903   Top1 99.218750   Top5 100.000000   BatchTime 0.155450   LR 0.001000   
2022-11-04 01:22:42,095 - INFO  - Training [30][   80/  196]   Loss 0.021262   Top1 99.218750   Top5 100.000000   BatchTime 0.145327   LR 0.001000   
2022-11-04 01:22:43,965 - INFO  - Training [30][  100/  196]   Loss 0.022189   Top1 99.238281   Top5 100.000000   BatchTime 0.134965   LR 0.001000   
2022-11-04 01:22:46,895 - INFO  - Training [30][  120/  196]   Loss 0.022057   Top1 99.241536   Top5 100.000000   BatchTime 0.136886   LR 0.001000   
2022-11-04 01:22:49,895 - INFO  - Training [30][  140/  196]   Loss 0.021572   Top1 99.260603   Top5 100.000000   BatchTime 0.138755   LR 0.001000   
2022-11-04 01:22:52,914 - INFO  - Training [30][  160/  196]   Loss 0.021168   Top1 99.274902   Top5 100.000000   BatchTime 0.140278   LR 0.001000   
2022-11-04 01:22:55,918 - INFO  - Training [30][  180/  196]   Loss 0.021314   Top1 99.281684   Top5 100.000000   BatchTime 0.141380   LR 0.001000   
2022-11-04 01:22:58,519 - INFO  - ==> Top1: 99.288    Top5: 100.000    Loss: 0.021

2022-11-04 01:22:58,520 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:23:01,721 - INFO  - Validation [30][   20/   40]   Loss 0.454868   Top1 91.210938   Top5 99.433594   BatchTime 0.159978   
2022-11-04 01:23:03,195 - INFO  - Validation [30][   40/   40]   Loss 0.442234   Top1 91.150000   Top5 99.570000   BatchTime 0.116847   
2022-11-04 01:23:03,434 - INFO  - ==> Top1: 91.150    Top5: 99.570    Loss: 0.442

2022-11-04 01:23:03,510 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:23:03,511 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:23:03,511 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:23:03,694 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:23:03,875 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:23:03,875 - INFO  - >>>>>>>> Epoch  31
2022-11-04 01:23:03,877 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:23:08,720 - INFO  - Training [31][   20/  196]   Loss 0.018348   Top1 99.472656   Top5 100.000000   BatchTime 0.242171   LR 0.001000   
2022-11-04 01:23:11,069 - INFO  - Training [31][   40/  196]   Loss 0.018527   Top1 99.472656   Top5 100.000000   BatchTime 0.179799   LR 0.001000   
2022-11-04 01:23:13,148 - INFO  - Training [31][   60/  196]   Loss 0.017263   Top1 99.505208   Top5 100.000000   BatchTime 0.154519   LR 0.001000   
2022-11-04 01:23:15,383 - INFO  - Training [31][   80/  196]   Loss 0.017390   Top1 99.443359   Top5 100.000000   BatchTime 0.143829   LR 0.001000   
2022-11-04 01:23:17,122 - INFO  - Training [31][  100/  196]   Loss 0.017678   Top1 99.429688   Top5 100.000000   BatchTime 0.132449   LR 0.001000   
2022-11-04 01:23:20,237 - INFO  - Training [31][  120/  196]   Loss 0.017474   Top1 99.430339   Top5 100.000000   BatchTime 0.136334   LR 0.001000   
2022-11-04 01:23:23,273 - INFO  - Training [31][  140/  196]   Loss 0.018070   Top1 99.400112   Top5 100.000000   BatchTime 0.138542   LR 0.001000   
2022-11-04 01:23:26,215 - INFO  - Training [31][  160/  196]   Loss 0.017894   Top1 99.416504   Top5 100.000000   BatchTime 0.139611   LR 0.001000   
2022-11-04 01:23:29,227 - INFO  - Training [31][  180/  196]   Loss 0.018213   Top1 99.398872   Top5 100.000000   BatchTime 0.140831   LR 0.001000   
2022-11-04 01:23:31,829 - INFO  - ==> Top1: 99.384    Top5: 100.000    Loss: 0.018

2022-11-04 01:23:31,830 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:23:35,045 - INFO  - Validation [31][   20/   40]   Loss 0.457074   Top1 90.546875   Top5 99.375000   BatchTime 0.160645   
2022-11-04 01:23:36,523 - INFO  - Validation [31][   40/   40]   Loss 0.444738   Top1 90.680000   Top5 99.510000   BatchTime 0.117283   
2022-11-04 01:23:36,764 - INFO  - ==> Top1: 90.680    Top5: 99.510    Loss: 0.445

2022-11-04 01:23:36,815 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:23:36,816 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:23:36,816 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.770   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:23:36,914 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:23:36,915 - INFO  - >>>>>>>> Epoch  32
2022-11-04 01:23:36,916 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:23:41,768 - INFO  - Training [32][   20/  196]   Loss 0.018004   Top1 99.316406   Top5 100.000000   BatchTime 0.242569   LR 0.001000   
2022-11-04 01:23:44,285 - INFO  - Training [32][   40/  196]   Loss 0.017755   Top1 99.423828   Top5 100.000000   BatchTime 0.184224   LR 0.001000   
2022-11-04 01:23:46,246 - INFO  - Training [32][   60/  196]   Loss 0.018482   Top1 99.414062   Top5 100.000000   BatchTime 0.155490   LR 0.001000   
2022-11-04 01:23:48,521 - INFO  - Training [32][   80/  196]   Loss 0.018443   Top1 99.394531   Top5 100.000000   BatchTime 0.145052   LR 0.001000   
2022-11-04 01:23:50,300 - INFO  - Training [32][  100/  196]   Loss 0.018416   Top1 99.386719   Top5 100.000000   BatchTime 0.133838   LR 0.001000   
2022-11-04 01:23:53,174 - INFO  - Training [32][  120/  196]   Loss 0.018754   Top1 99.394531   Top5 100.000000   BatchTime 0.135476   LR 0.001000   
2022-11-04 01:23:56,186 - INFO  - Training [32][  140/  196]   Loss 0.018894   Top1 99.391741   Top5 100.000000   BatchTime 0.137639   LR 0.001000   
2022-11-04 01:23:59,184 - INFO  - Training [32][  160/  196]   Loss 0.018914   Top1 99.387207   Top5 100.000000   BatchTime 0.139172   LR 0.001000   
2022-11-04 01:24:02,182 - INFO  - Training [32][  180/  196]   Loss 0.018415   Top1 99.418403   Top5 100.000000   BatchTime 0.140362   LR 0.001000   
2022-11-04 01:24:04,759 - INFO  - ==> Top1: 99.430    Top5: 100.000    Loss: 0.018

2022-11-04 01:24:04,759 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:24:07,961 - INFO  - Validation [32][   20/   40]   Loss 0.454368   Top1 90.585938   Top5 99.453125   BatchTime 0.160040   
2022-11-04 01:24:09,441 - INFO  - Validation [32][   40/   40]   Loss 0.444571   Top1 90.790000   Top5 99.560000   BatchTime 0.117022   
2022-11-04 01:24:09,679 - INFO  - ==> Top1: 90.790    Top5: 99.560    Loss: 0.445

2022-11-04 01:24:09,733 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:24:09,734 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:24:09,734 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.790   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:24:09,860 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:24:09,860 - INFO  - >>>>>>>> Epoch  33
2022-11-04 01:24:09,862 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:24:14,659 - INFO  - Training [33][   20/  196]   Loss 0.017976   Top1 99.453125   Top5 99.980469   BatchTime 0.239858   LR 0.001000   
2022-11-04 01:24:17,447 - INFO  - Training [33][   40/  196]   Loss 0.017599   Top1 99.453125   Top5 99.990234   BatchTime 0.189634   LR 0.001000   
2022-11-04 01:24:19,332 - INFO  - Training [33][   60/  196]   Loss 0.018022   Top1 99.414062   Top5 99.993490   BatchTime 0.157842   LR 0.001000   
2022-11-04 01:24:21,607 - INFO  - Training [33][   80/  196]   Loss 0.017950   Top1 99.409180   Top5 99.995117   BatchTime 0.146818   LR 0.001000   
2022-11-04 01:24:23,576 - INFO  - Training [33][  100/  196]   Loss 0.017312   Top1 99.437500   Top5 99.996094   BatchTime 0.137136   LR 0.001000   
2022-11-04 01:24:26,240 - INFO  - Training [33][  120/  196]   Loss 0.017450   Top1 99.430339   Top5 99.996745   BatchTime 0.136482   LR 0.001000   
2022-11-04 01:24:29,262 - INFO  - Training [33][  140/  196]   Loss 0.017946   Top1 99.411272   Top5 99.997210   BatchTime 0.138567   LR 0.001000   
2022-11-04 01:24:32,264 - INFO  - Training [33][  160/  196]   Loss 0.018039   Top1 99.396973   Top5 99.997559   BatchTime 0.140011   LR 0.001000   
2022-11-04 01:24:35,270 - INFO  - Training [33][  180/  196]   Loss 0.018150   Top1 99.405382   Top5 99.997830   BatchTime 0.141154   LR 0.001000   
2022-11-04 01:24:37,834 - INFO  - ==> Top1: 99.400    Top5: 99.998    Loss: 0.018

2022-11-04 01:24:37,835 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:24:41,040 - INFO  - Validation [33][   20/   40]   Loss 0.460219   Top1 90.820312   Top5 99.375000   BatchTime 0.160181   
2022-11-04 01:24:42,531 - INFO  - Validation [33][   40/   40]   Loss 0.445093   Top1 90.800000   Top5 99.550000   BatchTime 0.117378   
2022-11-04 01:24:42,772 - INFO  - ==> Top1: 90.800    Top5: 99.550    Loss: 0.445

2022-11-04 01:24:42,833 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:24:42,834 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:24:42,834 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.800   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:24:42,950 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:24:42,950 - INFO  - >>>>>>>> Epoch  34
2022-11-04 01:24:42,951 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:24:47,753 - INFO  - Training [34][   20/  196]   Loss 0.017246   Top1 99.433594   Top5 100.000000   BatchTime 0.240067   LR 0.001000   
2022-11-04 01:24:50,713 - INFO  - Training [34][   40/  196]   Loss 0.016494   Top1 99.404297   Top5 100.000000   BatchTime 0.194033   LR 0.001000   
2022-11-04 01:24:52,410 - INFO  - Training [34][   60/  196]   Loss 0.016340   Top1 99.440104   Top5 100.000000   BatchTime 0.157643   LR 0.001000   
2022-11-04 01:24:54,709 - INFO  - Training [34][   80/  196]   Loss 0.016506   Top1 99.428711   Top5 100.000000   BatchTime 0.146972   LR 0.001000   
2022-11-04 01:24:56,753 - INFO  - Training [34][  100/  196]   Loss 0.016593   Top1 99.433594   Top5 100.000000   BatchTime 0.138014   LR 0.001000   
2022-11-04 01:24:59,294 - INFO  - Training [34][  120/  196]   Loss 0.016479   Top1 99.420573   Top5 100.000000   BatchTime 0.136183   LR 0.001000   
2022-11-04 01:25:02,318 - INFO  - Training [34][  140/  196]   Loss 0.016525   Top1 99.439174   Top5 100.000000   BatchTime 0.138333   LR 0.001000   
2022-11-04 01:25:05,334 - INFO  - Training [34][  160/  196]   Loss 0.016640   Top1 99.436035   Top5 100.000000   BatchTime 0.139886   LR 0.001000   
2022-11-04 01:25:08,346 - INFO  - Training [34][  180/  196]   Loss 0.017009   Top1 99.422743   Top5 100.000000   BatchTime 0.141079   LR 0.001000   
2022-11-04 01:25:10,919 - INFO  - ==> Top1: 99.416    Top5: 100.000    Loss: 0.017

2022-11-04 01:25:10,920 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:25:14,118 - INFO  - Validation [34][   20/   40]   Loss 0.459479   Top1 90.800781   Top5 99.414062   BatchTime 0.159835   
2022-11-04 01:25:15,599 - INFO  - Validation [34][   40/   40]   Loss 0.446821   Top1 90.850000   Top5 99.520000   BatchTime 0.116950   
2022-11-04 01:25:15,855 - INFO  - ==> Top1: 90.850    Top5: 99.520    Loss: 0.447

2022-11-04 01:25:15,893 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:25:15,894 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:25:15,894 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.830   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:25:16,024 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:25:16,024 - INFO  - >>>>>>>> Epoch  35
2022-11-04 01:25:16,026 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:25:20,885 - INFO  - Training [35][   20/  196]   Loss 0.020794   Top1 99.296875   Top5 100.000000   BatchTime 0.242936   LR 0.001000   
2022-11-04 01:25:23,890 - INFO  - Training [35][   40/  196]   Loss 0.019741   Top1 99.355469   Top5 100.000000   BatchTime 0.196603   LR 0.001000   
2022-11-04 01:25:25,788 - INFO  - Training [35][   60/  196]   Loss 0.018824   Top1 99.394531   Top5 100.000000   BatchTime 0.162697   LR 0.001000   
2022-11-04 01:25:27,983 - INFO  - Training [35][   80/  196]   Loss 0.018290   Top1 99.404297   Top5 100.000000   BatchTime 0.149459   LR 0.001000   
2022-11-04 01:25:30,162 - INFO  - Training [35][  100/  196]   Loss 0.017892   Top1 99.417969   Top5 100.000000   BatchTime 0.141358   LR 0.001000   
2022-11-04 01:25:32,296 - INFO  - Training [35][  120/  196]   Loss 0.017921   Top1 99.414062   Top5 100.000000   BatchTime 0.135585   LR 0.001000   
2022-11-04 01:25:35,302 - INFO  - Training [35][  140/  196]   Loss 0.017587   Top1 99.428013   Top5 100.000000   BatchTime 0.137682   LR 0.001000   
2022-11-04 01:25:38,311 - INFO  - Training [35][  160/  196]   Loss 0.017403   Top1 99.421387   Top5 100.000000   BatchTime 0.139280   LR 0.001000   
2022-11-04 01:25:41,326 - INFO  - Training [35][  180/  196]   Loss 0.017143   Top1 99.435764   Top5 100.000000   BatchTime 0.140553   LR 0.001000   
2022-11-04 01:25:43,900 - INFO  - ==> Top1: 99.438    Top5: 100.000    Loss: 0.017

2022-11-04 01:25:43,901 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:25:47,095 - INFO  - Validation [35][   20/   40]   Loss 0.463526   Top1 90.605469   Top5 99.394531   BatchTime 0.159630   
2022-11-04 01:25:48,592 - INFO  - Validation [35][   40/   40]   Loss 0.446073   Top1 90.860000   Top5 99.570000   BatchTime 0.117241   
2022-11-04 01:25:48,848 - INFO  - ==> Top1: 90.860    Top5: 99.570    Loss: 0.446

2022-11-04 01:25:48,917 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:25:48,918 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:25:48,918 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:25:49,041 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:25:49,041 - INFO  - >>>>>>>> Epoch  36
2022-11-04 01:25:49,043 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:25:53,807 - INFO  - Training [36][   20/  196]   Loss 0.019334   Top1 99.316406   Top5 100.000000   BatchTime 0.238182   LR 0.001000   
2022-11-04 01:25:56,799 - INFO  - Training [36][   40/  196]   Loss 0.017901   Top1 99.375000   Top5 100.000000   BatchTime 0.193902   LR 0.001000   
2022-11-04 01:25:58,968 - INFO  - Training [36][   60/  196]   Loss 0.017613   Top1 99.401042   Top5 100.000000   BatchTime 0.165411   LR 0.001000   
2022-11-04 01:26:01,099 - INFO  - Training [36][   80/  196]   Loss 0.016996   Top1 99.418945   Top5 100.000000   BatchTime 0.150694   LR 0.001000   
2022-11-04 01:26:03,305 - INFO  - Training [36][  100/  196]   Loss 0.016726   Top1 99.453125   Top5 100.000000   BatchTime 0.142616   LR 0.001000   
2022-11-04 01:26:05,036 - INFO  - Training [36][  120/  196]   Loss 0.016582   Top1 99.462891   Top5 100.000000   BatchTime 0.133272   LR 0.001000   
2022-11-04 01:26:08,179 - INFO  - Training [36][  140/  196]   Loss 0.016818   Top1 99.455915   Top5 100.000000   BatchTime 0.136681   LR 0.001000   
2022-11-04 01:26:11,190 - INFO  - Training [36][  160/  196]   Loss 0.016870   Top1 99.458008   Top5 100.000000   BatchTime 0.138417   LR 0.001000   
2022-11-04 01:26:14,196 - INFO  - Training [36][  180/  196]   Loss 0.017055   Top1 99.457465   Top5 100.000000   BatchTime 0.139735   LR 0.001000   
2022-11-04 01:26:16,768 - INFO  - ==> Top1: 99.444    Top5: 100.000    Loss: 0.017

2022-11-04 01:26:16,769 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:26:20,001 - INFO  - Validation [36][   20/   40]   Loss 0.469121   Top1 90.566406   Top5 99.394531   BatchTime 0.161553   
2022-11-04 01:26:21,439 - INFO  - Validation [36][   40/   40]   Loss 0.453467   Top1 90.810000   Top5 99.550000   BatchTime 0.116739   
2022-11-04 01:26:21,686 - INFO  - ==> Top1: 90.810    Top5: 99.550    Loss: 0.453

2022-11-04 01:26:21,734 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:26:21,735 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:26:21,735 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:26:21,826 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:26:21,826 - INFO  - >>>>>>>> Epoch  37
2022-11-04 01:26:21,828 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:26:26,645 - INFO  - Training [37][   20/  196]   Loss 0.016945   Top1 99.316406   Top5 100.000000   BatchTime 0.240843   LR 0.001000   
2022-11-04 01:26:29,658 - INFO  - Training [37][   40/  196]   Loss 0.017321   Top1 99.404297   Top5 99.990234   BatchTime 0.195758   LR 0.001000   
2022-11-04 01:26:32,130 - INFO  - Training [37][   60/  196]   Loss 0.017538   Top1 99.420573   Top5 99.993490   BatchTime 0.171703   LR 0.001000   
2022-11-04 01:26:34,102 - INFO  - Training [37][   80/  196]   Loss 0.017361   Top1 99.404297   Top5 99.995117   BatchTime 0.153417   LR 0.001000   
2022-11-04 01:26:36,350 - INFO  - Training [37][  100/  196]   Loss 0.016861   Top1 99.402344   Top5 99.996094   BatchTime 0.145212   LR 0.001000   
2022-11-04 01:26:38,223 - INFO  - Training [37][  120/  196]   Loss 0.017655   Top1 99.361979   Top5 99.996745   BatchTime 0.136620   LR 0.001000   
2022-11-04 01:26:41,099 - INFO  - Training [37][  140/  196]   Loss 0.017605   Top1 99.358259   Top5 99.997210   BatchTime 0.137646   LR 0.001000   
2022-11-04 01:26:44,114 - INFO  - Training [37][  160/  196]   Loss 0.016971   Top1 99.384766   Top5 99.997559   BatchTime 0.139282   LR 0.001000   
2022-11-04 01:26:47,122 - INFO  - Training [37][  180/  196]   Loss 0.016554   Top1 99.401042   Top5 99.997830   BatchTime 0.140517   LR 0.001000   
2022-11-04 01:26:49,700 - INFO  - ==> Top1: 99.402    Top5: 99.998    Loss: 0.017

2022-11-04 01:26:49,700 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:26:52,927 - INFO  - Validation [37][   20/   40]   Loss 0.463041   Top1 90.605469   Top5 99.433594   BatchTime 0.161254   
2022-11-04 01:26:54,433 - INFO  - Validation [37][   40/   40]   Loss 0.455363   Top1 90.750000   Top5 99.590000   BatchTime 0.118271   
2022-11-04 01:26:54,685 - INFO  - ==> Top1: 90.750    Top5: 99.590    Loss: 0.455

2022-11-04 01:26:54,747 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:26:54,747 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:26:54,748 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.850   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:26:54,858 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:26:54,858 - INFO  - >>>>>>>> Epoch  38
2022-11-04 01:26:54,859 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:26:59,664 - INFO  - Training [38][   20/  196]   Loss 0.013153   Top1 99.472656   Top5 100.000000   BatchTime 0.240247   LR 0.001000   
2022-11-04 01:27:02,672 - INFO  - Training [38][   40/  196]   Loss 0.014253   Top1 99.462891   Top5 100.000000   BatchTime 0.195315   LR 0.001000   
2022-11-04 01:27:05,492 - INFO  - Training [38][   60/  196]   Loss 0.014417   Top1 99.531250   Top5 100.000000   BatchTime 0.177209   LR 0.001000   
2022-11-04 01:27:07,314 - INFO  - Training [38][   80/  196]   Loss 0.014727   Top1 99.487305   Top5 100.000000   BatchTime 0.155690   LR 0.001000   
2022-11-04 01:27:09,710 - INFO  - Training [38][  100/  196]   Loss 0.015306   Top1 99.500000   Top5 100.000000   BatchTime 0.148510   LR 0.001000   
2022-11-04 01:27:11,605 - INFO  - Training [38][  120/  196]   Loss 0.015049   Top1 99.514974   Top5 100.000000   BatchTime 0.139546   LR 0.001000   
2022-11-04 01:27:14,250 - INFO  - Training [38][  140/  196]   Loss 0.015130   Top1 99.517299   Top5 100.000000   BatchTime 0.138505   LR 0.001000   
2022-11-04 01:27:17,261 - INFO  - Training [38][  160/  196]   Loss 0.014891   Top1 99.521484   Top5 100.000000   BatchTime 0.140010   LR 0.001000   
2022-11-04 01:27:20,269 - INFO  - Training [38][  180/  196]   Loss 0.014929   Top1 99.520399   Top5 100.000000   BatchTime 0.141163   LR 0.001000   
2022-11-04 01:27:22,844 - INFO  - ==> Top1: 99.506    Top5: 100.000    Loss: 0.015

2022-11-04 01:27:22,845 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:27:26,047 - INFO  - Validation [38][   20/   40]   Loss 0.466985   Top1 90.781250   Top5 99.453125   BatchTime 0.160031   
2022-11-04 01:27:27,519 - INFO  - Validation [38][   40/   40]   Loss 0.449936   Top1 91.000000   Top5 99.590000   BatchTime 0.116819   
2022-11-04 01:27:27,759 - INFO  - ==> Top1: 91.000    Top5: 99.590    Loss: 0.450

2022-11-04 01:27:27,808 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:27:27,809 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:27:27,810 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:27:27,908 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:27:27,908 - INFO  - >>>>>>>> Epoch  39
2022-11-04 01:27:27,909 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:27:32,711 - INFO  - Training [39][   20/  196]   Loss 0.016221   Top1 99.414062   Top5 100.000000   BatchTime 0.240103   LR 0.001000   
2022-11-04 01:27:35,717 - INFO  - Training [39][   40/  196]   Loss 0.017495   Top1 99.414062   Top5 100.000000   BatchTime 0.195201   LR 0.001000   
2022-11-04 01:27:38,761 - INFO  - Training [39][   60/  196]   Loss 0.016531   Top1 99.414062   Top5 100.000000   BatchTime 0.180870   LR 0.001000   
2022-11-04 01:27:40,543 - INFO  - Training [39][   80/  196]   Loss 0.016156   Top1 99.423828   Top5 100.000000   BatchTime 0.157927   LR 0.001000   
2022-11-04 01:27:42,813 - INFO  - Training [39][  100/  196]   Loss 0.016348   Top1 99.414062   Top5 100.000000   BatchTime 0.149038   LR 0.001000   
2022-11-04 01:27:44,823 - INFO  - Training [39][  120/  196]   Loss 0.016390   Top1 99.401042   Top5 100.000000   BatchTime 0.140949   LR 0.001000   
2022-11-04 01:27:47,239 - INFO  - Training [39][  140/  196]   Loss 0.016309   Top1 99.425223   Top5 100.000000   BatchTime 0.138066   LR 0.001000   
2022-11-04 01:27:50,240 - INFO  - Training [39][  160/  196]   Loss 0.016069   Top1 99.426270   Top5 100.000000   BatchTime 0.139565   LR 0.001000   
2022-11-04 01:27:53,240 - INFO  - Training [39][  180/  196]   Loss 0.016159   Top1 99.422743   Top5 100.000000   BatchTime 0.140725   LR 0.001000   
2022-11-04 01:27:55,821 - INFO  - ==> Top1: 99.424    Top5: 100.000    Loss: 0.016

2022-11-04 01:27:55,822 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:27:58,997 - INFO  - Validation [39][   20/   40]   Loss 0.464393   Top1 90.683594   Top5 99.375000   BatchTime 0.158699   
2022-11-04 01:28:00,524 - INFO  - Validation [39][   40/   40]   Loss 0.452542   Top1 90.820000   Top5 99.530000   BatchTime 0.117521   
2022-11-04 01:28:00,768 - INFO  - ==> Top1: 90.820    Top5: 99.530    Loss: 0.453

2022-11-04 01:28:00,834 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:28:00,835 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:28:00,835 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.860   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:28:00,936 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:28:00,936 - INFO  - >>>>>>>> Epoch  40
2022-11-04 01:28:00,937 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:28:05,766 - INFO  - Training [40][   20/  196]   Loss 0.013843   Top1 99.550781   Top5 100.000000   BatchTime 0.241433   LR 0.001000   
2022-11-04 01:28:08,781 - INFO  - Training [40][   40/  196]   Loss 0.016022   Top1 99.531250   Top5 100.000000   BatchTime 0.196084   LR 0.001000   
2022-11-04 01:28:11,721 - INFO  - Training [40][   60/  196]   Loss 0.016445   Top1 99.518229   Top5 100.000000   BatchTime 0.179733   LR 0.001000   
2022-11-04 01:28:13,716 - INFO  - Training [40][   80/  196]   Loss 0.016109   Top1 99.511719   Top5 100.000000   BatchTime 0.159731   LR 0.001000   
2022-11-04 01:28:15,916 - INFO  - Training [40][  100/  196]   Loss 0.016580   Top1 99.519531   Top5 100.000000   BatchTime 0.149786   LR 0.001000   
2022-11-04 01:28:18,088 - INFO  - Training [40][  120/  196]   Loss 0.016678   Top1 99.505208   Top5 100.000000   BatchTime 0.142924   LR 0.001000   
2022-11-04 01:28:19,998 - INFO  - Training [40][  140/  196]   Loss 0.016938   Top1 99.481027   Top5 100.000000   BatchTime 0.136149   LR 0.001000   
2022-11-04 01:28:22,254 - INFO  - Training [40][  160/  196]   Loss 0.016547   Top1 99.484863   Top5 100.000000   BatchTime 0.133228   LR 0.001000   
2022-11-04 01:28:24,063 - INFO  - Training [40][  180/  196]   Loss 0.016154   Top1 99.496528   Top5 100.000000   BatchTime 0.128475   LR 0.001000   
2022-11-04 01:28:25,634 - INFO  - ==> Top1: 99.506    Top5: 100.000    Loss: 0.016

2022-11-04 01:28:25,635 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:28:28,007 - INFO  - Validation [40][   20/   40]   Loss 0.456160   Top1 90.996094   Top5 99.433594   BatchTime 0.118546   
2022-11-04 01:28:28,697 - INFO  - Validation [40][   40/   40]   Loss 0.444209   Top1 91.090000   Top5 99.550000   BatchTime 0.076508   
2022-11-04 01:28:28,942 - INFO  - ==> Top1: 91.090    Top5: 99.550    Loss: 0.444

2022-11-04 01:28:28,967 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:28:28,968 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:28:28,968 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:28:29,068 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:28:29,068 - INFO  - >>>>>>>> Epoch  41
2022-11-04 01:28:29,069 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:28:32,652 - INFO  - Training [41][   20/  196]   Loss 0.015437   Top1 99.453125   Top5 100.000000   BatchTime 0.179093   LR 0.001000   
2022-11-04 01:28:34,350 - INFO  - Training [41][   40/  196]   Loss 0.015045   Top1 99.453125   Top5 100.000000   BatchTime 0.132002   LR 0.001000   
2022-11-04 01:28:36,094 - INFO  - Training [41][   60/  196]   Loss 0.014992   Top1 99.440104   Top5 100.000000   BatchTime 0.117077   LR 0.001000   
2022-11-04 01:28:37,822 - INFO  - Training [41][   80/  196]   Loss 0.014637   Top1 99.453125   Top5 100.000000   BatchTime 0.109397   LR 0.001000   
2022-11-04 01:28:39,525 - INFO  - Training [41][  100/  196]   Loss 0.015170   Top1 99.449219   Top5 100.000000   BatchTime 0.104551   LR 0.001000   
2022-11-04 01:28:41,233 - INFO  - Training [41][  120/  196]   Loss 0.014871   Top1 99.462891   Top5 100.000000   BatchTime 0.101358   LR 0.001000   
2022-11-04 01:28:42,903 - INFO  - Training [41][  140/  196]   Loss 0.014522   Top1 99.478237   Top5 100.000000   BatchTime 0.098807   LR 0.001000   
2022-11-04 01:28:44,549 - INFO  - Training [41][  160/  196]   Loss 0.014752   Top1 99.467773   Top5 100.000000   BatchTime 0.096743   LR 0.001000   
2022-11-04 01:28:46,205 - INFO  - Training [41][  180/  196]   Loss 0.015212   Top1 99.466146   Top5 100.000000   BatchTime 0.095191   LR 0.001000   
2022-11-04 01:28:47,737 - INFO  - ==> Top1: 99.482    Top5: 100.000    Loss: 0.015

2022-11-04 01:28:47,738 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:28:50,121 - INFO  - Validation [41][   20/   40]   Loss 0.468601   Top1 90.742188   Top5 99.414062   BatchTime 0.119067   
2022-11-04 01:28:50,807 - INFO  - Validation [41][   40/   40]   Loss 0.452327   Top1 90.910000   Top5 99.560000   BatchTime 0.076668   
2022-11-04 01:28:51,033 - INFO  - ==> Top1: 90.910    Top5: 99.560    Loss: 0.452

2022-11-04 01:28:51,059 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:28:51,060 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:28:51,060 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:28:51,160 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:28:51,160 - INFO  - >>>>>>>> Epoch  42
2022-11-04 01:28:51,161 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:28:54,711 - INFO  - Training [42][   20/  196]   Loss 0.012867   Top1 99.511719   Top5 100.000000   BatchTime 0.177480   LR 0.001000   
2022-11-04 01:28:56,409 - INFO  - Training [42][   40/  196]   Loss 0.014564   Top1 99.501953   Top5 100.000000   BatchTime 0.131174   LR 0.001000   
2022-11-04 01:28:58,107 - INFO  - Training [42][   60/  196]   Loss 0.014028   Top1 99.557292   Top5 100.000000   BatchTime 0.115750   LR 0.001000   
2022-11-04 01:28:59,792 - INFO  - Training [42][   80/  196]   Loss 0.014234   Top1 99.550781   Top5 100.000000   BatchTime 0.107879   LR 0.001000   
2022-11-04 01:29:01,467 - INFO  - Training [42][  100/  196]   Loss 0.014253   Top1 99.562500   Top5 100.000000   BatchTime 0.103056   LR 0.001000   
2022-11-04 01:29:03,167 - INFO  - Training [42][  120/  196]   Loss 0.014354   Top1 99.544271   Top5 100.000000   BatchTime 0.100039   LR 0.001000   
2022-11-04 01:29:04,952 - INFO  - Training [42][  140/  196]   Loss 0.014466   Top1 99.525670   Top5 100.000000   BatchTime 0.098498   LR 0.001000   
2022-11-04 01:29:06,595 - INFO  - Training [42][  160/  196]   Loss 0.014457   Top1 99.531250   Top5 100.000000   BatchTime 0.096454   LR 0.001000   
2022-11-04 01:29:08,243 - INFO  - Training [42][  180/  196]   Loss 0.014039   Top1 99.548611   Top5 100.000000   BatchTime 0.094892   LR 0.001000   
2022-11-04 01:29:09,778 - INFO  - ==> Top1: 99.540    Top5: 100.000    Loss: 0.014

2022-11-04 01:29:09,778 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:29:12,153 - INFO  - Validation [42][   20/   40]   Loss 0.462023   Top1 90.957031   Top5 99.453125   BatchTime 0.118644   
2022-11-04 01:29:12,839 - INFO  - Validation [42][   40/   40]   Loss 0.449277   Top1 90.860000   Top5 99.580000   BatchTime 0.076468   
2022-11-04 01:29:13,063 - INFO  - ==> Top1: 90.860    Top5: 99.580    Loss: 0.449

2022-11-04 01:29:13,088 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:29:13,089 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:29:13,089 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:29:13,181 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:29:13,182 - INFO  - >>>>>>>> Epoch  43
2022-11-04 01:29:13,183 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:29:16,730 - INFO  - Training [43][   20/  196]   Loss 0.018755   Top1 99.335938   Top5 100.000000   BatchTime 0.177327   LR 0.001000   
2022-11-04 01:29:18,415 - INFO  - Training [43][   40/  196]   Loss 0.015992   Top1 99.414062   Top5 100.000000   BatchTime 0.130785   LR 0.001000   
2022-11-04 01:29:20,113 - INFO  - Training [43][   60/  196]   Loss 0.015837   Top1 99.427083   Top5 100.000000   BatchTime 0.115500   LR 0.001000   
2022-11-04 01:29:21,804 - INFO  - Training [43][   80/  196]   Loss 0.014897   Top1 99.477539   Top5 100.000000   BatchTime 0.107754   LR 0.001000   
2022-11-04 01:29:23,491 - INFO  - Training [43][  100/  196]   Loss 0.015182   Top1 99.476562   Top5 100.000000   BatchTime 0.103072   LR 0.001000   
2022-11-04 01:29:25,163 - INFO  - Training [43][  120/  196]   Loss 0.014669   Top1 99.495443   Top5 100.000000   BatchTime 0.099827   LR 0.001000   
2022-11-04 01:29:26,848 - INFO  - Training [43][  140/  196]   Loss 0.014809   Top1 99.492188   Top5 100.000000   BatchTime 0.097605   LR 0.001000   
2022-11-04 01:29:28,544 - INFO  - Training [43][  160/  196]   Loss 0.014855   Top1 99.497070   Top5 100.000000   BatchTime 0.096004   LR 0.001000   
2022-11-04 01:29:30,215 - INFO  - Training [43][  180/  196]   Loss 0.015020   Top1 99.494358   Top5 100.000000   BatchTime 0.094620   LR 0.001000   
2022-11-04 01:29:31,752 - INFO  - ==> Top1: 99.500    Top5: 100.000    Loss: 0.015

2022-11-04 01:29:31,753 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:29:34,138 - INFO  - Validation [43][   20/   40]   Loss 0.462392   Top1 90.937500   Top5 99.472656   BatchTime 0.119162   
2022-11-04 01:29:34,824 - INFO  - Validation [43][   40/   40]   Loss 0.449188   Top1 90.970000   Top5 99.580000   BatchTime 0.076731   
2022-11-04 01:29:35,061 - INFO  - ==> Top1: 90.970    Top5: 99.580    Loss: 0.449

2022-11-04 01:29:35,086 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:29:35,087 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:29:35,087 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.000   Top5: 99.590] Sparsity : 0.827
2022-11-04 01:29:35,185 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:29:35,186 - INFO  - >>>>>>>> Epoch  44
2022-11-04 01:29:35,187 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:29:38,732 - INFO  - Training [44][   20/  196]   Loss 0.014705   Top1 99.414062   Top5 100.000000   BatchTime 0.177200   LR 0.001000   
2022-11-04 01:29:40,408 - INFO  - Training [44][   40/  196]   Loss 0.013397   Top1 99.501953   Top5 100.000000   BatchTime 0.130523   LR 0.001000   
2022-11-04 01:29:42,112 - INFO  - Training [44][   60/  196]   Loss 0.013751   Top1 99.479167   Top5 100.000000   BatchTime 0.115413   LR 0.001000   
2022-11-04 01:29:43,802 - INFO  - Training [44][   80/  196]   Loss 0.014020   Top1 99.492188   Top5 100.000000   BatchTime 0.107681   LR 0.001000   
2022-11-04 01:29:45,488 - INFO  - Training [44][  100/  196]   Loss 0.014386   Top1 99.476562   Top5 100.000000   BatchTime 0.103005   LR 0.001000   
2022-11-04 01:29:47,153 - INFO  - Training [44][  120/  196]   Loss 0.014144   Top1 99.488932   Top5 100.000000   BatchTime 0.099714   LR 0.001000   
2022-11-04 01:29:48,827 - INFO  - Training [44][  140/  196]   Loss 0.014124   Top1 99.497768   Top5 100.000000   BatchTime 0.097422   LR 0.001000   
2022-11-04 01:29:50,483 - INFO  - Training [44][  160/  196]   Loss 0.013998   Top1 99.511719   Top5 100.000000   BatchTime 0.095596   LR 0.001000   
2022-11-04 01:29:52,140 - INFO  - Training [44][  180/  196]   Loss 0.013964   Top1 99.505208   Top5 100.000000   BatchTime 0.094180   LR 0.001000   
2022-11-04 01:29:53,695 - INFO  - ==> Top1: 99.492    Top5: 100.000    Loss: 0.014

2022-11-04 01:29:53,696 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:29:56,071 - INFO  - Validation [44][   20/   40]   Loss 0.461794   Top1 90.820312   Top5 99.394531   BatchTime 0.118680   
2022-11-04 01:29:56,754 - INFO  - Validation [44][   40/   40]   Loss 0.447922   Top1 91.020000   Top5 99.580000   BatchTime 0.076422   
2022-11-04 01:29:56,976 - INFO  - ==> Top1: 91.020    Top5: 99.580    Loss: 0.448

2022-11-04 01:29:57,001 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:29:57,002 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:29:57,002 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:29:57,109 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:29:57,110 - INFO  - >>>>>>>> Epoch  45
2022-11-04 01:29:57,111 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:30:00,653 - INFO  - Training [45][   20/  196]   Loss 0.013351   Top1 99.570312   Top5 100.000000   BatchTime 0.177093   LR 0.001000   
2022-11-04 01:30:02,336 - INFO  - Training [45][   40/  196]   Loss 0.014152   Top1 99.443359   Top5 100.000000   BatchTime 0.130615   LR 0.001000   
2022-11-04 01:30:04,020 - INFO  - Training [45][   60/  196]   Loss 0.013362   Top1 99.531250   Top5 100.000000   BatchTime 0.115145   LR 0.001000   
2022-11-04 01:30:05,722 - INFO  - Training [45][   80/  196]   Loss 0.012784   Top1 99.580078   Top5 100.000000   BatchTime 0.107626   LR 0.001000   
2022-11-04 01:30:07,394 - INFO  - Training [45][  100/  196]   Loss 0.012867   Top1 99.574219   Top5 100.000000   BatchTime 0.102820   LR 0.001000   
2022-11-04 01:30:09,101 - INFO  - Training [45][  120/  196]   Loss 0.012773   Top1 99.570312   Top5 100.000000   BatchTime 0.099916   LR 0.001000   
2022-11-04 01:30:10,762 - INFO  - Training [45][  140/  196]   Loss 0.013105   Top1 99.564732   Top5 100.000000   BatchTime 0.097501   LR 0.001000   
2022-11-04 01:30:12,411 - INFO  - Training [45][  160/  196]   Loss 0.013331   Top1 99.567871   Top5 100.000000   BatchTime 0.095621   LR 0.001000   
2022-11-04 01:30:14,064 - INFO  - Training [45][  180/  196]   Loss 0.013395   Top1 99.574653   Top5 100.000000   BatchTime 0.094180   LR 0.001000   
2022-11-04 01:30:15,596 - INFO  - ==> Top1: 99.574    Top5: 100.000    Loss: 0.014

2022-11-04 01:30:15,597 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:30:17,969 - INFO  - Validation [45][   20/   40]   Loss 0.459615   Top1 90.800781   Top5 99.394531   BatchTime 0.118560   
2022-11-04 01:30:18,653 - INFO  - Validation [45][   40/   40]   Loss 0.446250   Top1 91.000000   Top5 99.530000   BatchTime 0.076395   
2022-11-04 01:30:18,888 - INFO  - ==> Top1: 91.000    Top5: 99.530    Loss: 0.446

2022-11-04 01:30:18,913 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:30:18,913 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:30:18,914 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:30:19,035 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:30:19,035 - INFO  - >>>>>>>> Epoch  46
2022-11-04 01:30:19,036 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:30:22,571 - INFO  - Training [46][   20/  196]   Loss 0.013866   Top1 99.472656   Top5 100.000000   BatchTime 0.176724   LR 0.001000   
2022-11-04 01:30:24,279 - INFO  - Training [46][   40/  196]   Loss 0.014250   Top1 99.443359   Top5 100.000000   BatchTime 0.131075   LR 0.001000   
2022-11-04 01:30:25,945 - INFO  - Training [46][   60/  196]   Loss 0.014464   Top1 99.479167   Top5 100.000000   BatchTime 0.115145   LR 0.001000   
2022-11-04 01:30:27,628 - INFO  - Training [46][   80/  196]   Loss 0.013338   Top1 99.541016   Top5 100.000000   BatchTime 0.107396   LR 0.001000   
2022-11-04 01:30:29,291 - INFO  - Training [46][  100/  196]   Loss 0.013303   Top1 99.531250   Top5 100.000000   BatchTime 0.102542   LR 0.001000   
2022-11-04 01:30:30,967 - INFO  - Training [46][  120/  196]   Loss 0.013368   Top1 99.527995   Top5 100.000000   BatchTime 0.099419   LR 0.001000   
2022-11-04 01:30:32,634 - INFO  - Training [46][  140/  196]   Loss 0.013546   Top1 99.525670   Top5 100.000000   BatchTime 0.097121   LR 0.001000   
2022-11-04 01:30:34,408 - INFO  - Training [46][  160/  196]   Loss 0.013935   Top1 99.514160   Top5 100.000000   BatchTime 0.096068   LR 0.001000   
2022-11-04 01:30:36,052 - INFO  - Training [46][  180/  196]   Loss 0.014022   Top1 99.520399   Top5 100.000000   BatchTime 0.094529   LR 0.001000   
2022-11-04 01:30:37,576 - INFO  - ==> Top1: 99.520    Top5: 100.000    Loss: 0.014

2022-11-04 01:30:37,576 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:30:39,952 - INFO  - Validation [46][   20/   40]   Loss 0.462690   Top1 91.054688   Top5 99.433594   BatchTime 0.118694   
2022-11-04 01:30:40,635 - INFO  - Validation [46][   40/   40]   Loss 0.448832   Top1 91.020000   Top5 99.550000   BatchTime 0.076430   
2022-11-04 01:30:40,872 - INFO  - ==> Top1: 91.020    Top5: 99.550    Loss: 0.449

2022-11-04 01:30:40,896 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:30:40,897 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:30:40,897 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:30:41,008 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:30:41,008 - INFO  - >>>>>>>> Epoch  47
2022-11-04 01:30:41,009 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:30:44,497 - INFO  - Training [47][   20/  196]   Loss 0.011959   Top1 99.570312   Top5 100.000000   BatchTime 0.174419   LR 0.001000   
2022-11-04 01:30:46,184 - INFO  - Training [47][   40/  196]   Loss 0.012558   Top1 99.589844   Top5 100.000000   BatchTime 0.129388   LR 0.001000   
2022-11-04 01:30:47,841 - INFO  - Training [47][   60/  196]   Loss 0.013014   Top1 99.583333   Top5 100.000000   BatchTime 0.113863   LR 0.001000   
2022-11-04 01:30:49,538 - INFO  - Training [47][   80/  196]   Loss 0.012695   Top1 99.604492   Top5 100.000000   BatchTime 0.106618   LR 0.001000   
2022-11-04 01:30:51,243 - INFO  - Training [47][  100/  196]   Loss 0.013367   Top1 99.570312   Top5 100.000000   BatchTime 0.102335   LR 0.001000   
2022-11-04 01:30:52,915 - INFO  - Training [47][  120/  196]   Loss 0.012949   Top1 99.583333   Top5 100.000000   BatchTime 0.099213   LR 0.001000   
2022-11-04 01:30:54,605 - INFO  - Training [47][  140/  196]   Loss 0.013324   Top1 99.570312   Top5 100.000000   BatchTime 0.097113   LR 0.001000   
2022-11-04 01:30:56,266 - INFO  - Training [47][  160/  196]   Loss 0.013493   Top1 99.548340   Top5 100.000000   BatchTime 0.095355   LR 0.001000   
2022-11-04 01:30:57,921 - INFO  - Training [47][  180/  196]   Loss 0.013859   Top1 99.531250   Top5 100.000000   BatchTime 0.093956   LR 0.001000   
2022-11-04 01:30:59,460 - INFO  - ==> Top1: 99.526    Top5: 100.000    Loss: 0.014

2022-11-04 01:30:59,461 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:31:01,822 - INFO  - Validation [47][   20/   40]   Loss 0.464906   Top1 90.976562   Top5 99.472656   BatchTime 0.117998   
2022-11-04 01:31:02,502 - INFO  - Validation [47][   40/   40]   Loss 0.451248   Top1 90.970000   Top5 99.560000   BatchTime 0.076000   
2022-11-04 01:31:02,734 - INFO  - ==> Top1: 90.970    Top5: 99.560    Loss: 0.451

2022-11-04 01:31:02,760 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:31:02,760 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:31:02,760 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:31:02,849 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:31:02,849 - INFO  - >>>>>>>> Epoch  48
2022-11-04 01:31:02,851 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:31:06,380 - INFO  - Training [48][   20/  196]   Loss 0.014115   Top1 99.511719   Top5 100.000000   BatchTime 0.176445   LR 0.001000   
2022-11-04 01:31:08,053 - INFO  - Training [48][   40/  196]   Loss 0.014753   Top1 99.482422   Top5 100.000000   BatchTime 0.130033   LR 0.001000   
2022-11-04 01:31:09,722 - INFO  - Training [48][   60/  196]   Loss 0.014316   Top1 99.518229   Top5 100.000000   BatchTime 0.114508   LR 0.001000   
2022-11-04 01:31:11,392 - INFO  - Training [48][   80/  196]   Loss 0.014647   Top1 99.492188   Top5 100.000000   BatchTime 0.106754   LR 0.001000   
2022-11-04 01:31:13,062 - INFO  - Training [48][  100/  196]   Loss 0.014667   Top1 99.503906   Top5 100.000000   BatchTime 0.102109   LR 0.001000   
2022-11-04 01:31:14,729 - INFO  - Training [48][  120/  196]   Loss 0.014101   Top1 99.531250   Top5 100.000000   BatchTime 0.098981   LR 0.001000   
2022-11-04 01:31:16,394 - INFO  - Training [48][  140/  196]   Loss 0.014622   Top1 99.503348   Top5 100.000000   BatchTime 0.096732   LR 0.001000   
2022-11-04 01:31:18,035 - INFO  - Training [48][  160/  196]   Loss 0.014297   Top1 99.519043   Top5 100.000000   BatchTime 0.094896   LR 0.001000   
2022-11-04 01:31:19,684 - INFO  - Training [48][  180/  196]   Loss 0.013979   Top1 99.535590   Top5 100.000000   BatchTime 0.093512   LR 0.001000   
2022-11-04 01:31:21,209 - INFO  - ==> Top1: 99.544    Top5: 100.000    Loss: 0.014

2022-11-04 01:31:21,210 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:31:23,582 - INFO  - Validation [48][   20/   40]   Loss 0.471396   Top1 90.937500   Top5 99.394531   BatchTime 0.118485   
2022-11-04 01:31:24,260 - INFO  - Validation [48][   40/   40]   Loss 0.452010   Top1 91.010000   Top5 99.560000   BatchTime 0.076207   
2022-11-04 01:31:24,494 - INFO  - ==> Top1: 91.010    Top5: 99.560    Loss: 0.452

2022-11-04 01:31:24,517 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:31:24,518 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:31:24,518 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 91.020   Top5: 99.580] Sparsity : 0.827
2022-11-04 01:31:24,628 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:31:24,629 - INFO  - >>>>>>>> Epoch  49
2022-11-04 01:31:24,629 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:31:28,118 - INFO  - Training [49][   20/  196]   Loss 0.013178   Top1 99.570312   Top5 100.000000   BatchTime 0.174413   LR 0.001000   
2022-11-04 01:31:29,788 - INFO  - Training [49][   40/  196]   Loss 0.013957   Top1 99.482422   Top5 100.000000   BatchTime 0.128956   LR 0.001000   
2022-11-04 01:31:31,438 - INFO  - Training [49][   60/  196]   Loss 0.013736   Top1 99.518229   Top5 100.000000   BatchTime 0.113481   LR 0.001000   
2022-11-04 01:31:33,101 - INFO  - Training [49][   80/  196]   Loss 0.013411   Top1 99.536133   Top5 100.000000   BatchTime 0.105891   LR 0.001000   
2022-11-04 01:31:34,760 - INFO  - Training [49][  100/  196]   Loss 0.012971   Top1 99.554688   Top5 100.000000   BatchTime 0.101302   LR 0.001000   
2022-11-04 01:31:36,430 - INFO  - Training [49][  120/  196]   Loss 0.013493   Top1 99.527995   Top5 100.000000   BatchTime 0.098334   LR 0.001000   
2022-11-04 01:31:38,116 - INFO  - Training [49][  140/  196]   Loss 0.013976   Top1 99.517299   Top5 100.000000   BatchTime 0.096327   LR 0.001000   
2022-11-04 01:31:39,799 - INFO  - Training [49][  160/  196]   Loss 0.014032   Top1 99.536133   Top5 100.000000   BatchTime 0.094809   LR 0.001000   
2022-11-04 01:31:41,470 - INFO  - Training [49][  180/  196]   Loss 0.014265   Top1 99.520399   Top5 100.000000   BatchTime 0.093553   LR 0.001000   
2022-11-04 01:31:42,996 - INFO  - ==> Top1: 99.526    Top5: 100.000    Loss: 0.014

2022-11-04 01:31:42,996 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:31:45,372 - INFO  - Validation [49][   20/   40]   Loss 0.471677   Top1 90.898438   Top5 99.355469   BatchTime 0.118752   
2022-11-04 01:31:46,051 - INFO  - Validation [49][   40/   40]   Loss 0.451127   Top1 91.180000   Top5 99.520000   BatchTime 0.076353   
2022-11-04 01:31:46,285 - INFO  - ==> Top1: 91.180    Top5: 99.520    Loss: 0.451

2022-11-04 01:31:46,309 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:31:46,310 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:31:46,310 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 91.090   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:31:46,501 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:31:46,670 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_best.pth.tar

2022-11-04 01:31:46,670 - INFO  - >>>>>>>> Epoch  50
2022-11-04 01:31:46,671 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:31:50,214 - INFO  - Training [50][   20/  196]   Loss 0.013394   Top1 99.550781   Top5 100.000000   BatchTime 0.177143   LR 0.001000   
2022-11-04 01:31:51,883 - INFO  - Training [50][   40/  196]   Loss 0.014186   Top1 99.433594   Top5 100.000000   BatchTime 0.130297   LR 0.001000   
2022-11-04 01:31:53,555 - INFO  - Training [50][   60/  196]   Loss 0.014539   Top1 99.466146   Top5 100.000000   BatchTime 0.114738   LR 0.001000   
2022-11-04 01:31:55,214 - INFO  - Training [50][   80/  196]   Loss 0.014799   Top1 99.472656   Top5 100.000000   BatchTime 0.106783   LR 0.001000   
2022-11-04 01:31:56,874 - INFO  - Training [50][  100/  196]   Loss 0.014962   Top1 99.468750   Top5 100.000000   BatchTime 0.102031   LR 0.001000   
2022-11-04 01:31:58,578 - INFO  - Training [50][  120/  196]   Loss 0.014636   Top1 99.488932   Top5 100.000000   BatchTime 0.099221   LR 0.001000   
2022-11-04 01:32:00,253 - INFO  - Training [50][  140/  196]   Loss 0.014387   Top1 99.486607   Top5 100.000000   BatchTime 0.097014   LR 0.001000   
2022-11-04 01:32:02,022 - INFO  - Training [50][  160/  196]   Loss 0.014387   Top1 99.487305   Top5 100.000000   BatchTime 0.095939   LR 0.001000   
2022-11-04 01:32:03,676 - INFO  - Training [50][  180/  196]   Loss 0.014510   Top1 99.472656   Top5 100.000000   BatchTime 0.094472   LR 0.001000   
2022-11-04 01:32:05,210 - INFO  - ==> Top1: 99.476    Top5: 100.000    Loss: 0.014

2022-11-04 01:32:05,211 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:32:07,590 - INFO  - Validation [50][   20/   40]   Loss 0.464092   Top1 90.976562   Top5 99.375000   BatchTime 0.118858   
2022-11-04 01:32:08,270 - INFO  - Validation [50][   40/   40]   Loss 0.451559   Top1 91.120000   Top5 99.540000   BatchTime 0.076435   
2022-11-04 01:32:08,495 - INFO  - ==> Top1: 91.120    Top5: 99.540    Loss: 0.452

2022-11-04 01:32:08,520 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:32:08,521 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:32:08,521 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:32:08,600 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:32:08,600 - INFO  - >>>>>>>> Epoch  51
2022-11-04 01:32:08,601 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:32:12,155 - INFO  - Training [51][   20/  196]   Loss 0.015710   Top1 99.511719   Top5 100.000000   BatchTime 0.177656   LR 0.001000   
2022-11-04 01:32:13,845 - INFO  - Training [51][   40/  196]   Loss 0.013766   Top1 99.589844   Top5 100.000000   BatchTime 0.131089   LR 0.001000   
2022-11-04 01:32:15,553 - INFO  - Training [51][   60/  196]   Loss 0.013989   Top1 99.537760   Top5 100.000000   BatchTime 0.115862   LR 0.001000   
2022-11-04 01:32:17,256 - INFO  - Training [51][   80/  196]   Loss 0.013584   Top1 99.575195   Top5 100.000000   BatchTime 0.108175   LR 0.001000   
2022-11-04 01:32:18,946 - INFO  - Training [51][  100/  196]   Loss 0.013397   Top1 99.570312   Top5 100.000000   BatchTime 0.103441   LR 0.001000   
2022-11-04 01:32:20,642 - INFO  - Training [51][  120/  196]   Loss 0.013960   Top1 99.547526   Top5 100.000000   BatchTime 0.100335   LR 0.001000   
2022-11-04 01:32:22,305 - INFO  - Training [51][  140/  196]   Loss 0.014075   Top1 99.553571   Top5 100.000000   BatchTime 0.097880   LR 0.001000   
2022-11-04 01:32:23,949 - INFO  - Training [51][  160/  196]   Loss 0.013932   Top1 99.555664   Top5 100.000000   BatchTime 0.095920   LR 0.001000   
2022-11-04 01:32:25,611 - INFO  - Training [51][  180/  196]   Loss 0.013896   Top1 99.563802   Top5 100.000000   BatchTime 0.094497   LR 0.001000   
2022-11-04 01:32:27,131 - INFO  - ==> Top1: 99.552    Top5: 100.000    Loss: 0.014

2022-11-04 01:32:27,132 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:32:29,505 - INFO  - Validation [51][   20/   40]   Loss 0.470930   Top1 90.703125   Top5 99.414062   BatchTime 0.118586   
2022-11-04 01:32:30,191 - INFO  - Validation [51][   40/   40]   Loss 0.455807   Top1 90.930000   Top5 99.550000   BatchTime 0.076425   
2022-11-04 01:32:30,408 - INFO  - ==> Top1: 90.930    Top5: 99.550    Loss: 0.456

2022-11-04 01:32:30,431 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:32:30,431 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:32:30,432 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:32:30,537 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:32:30,537 - INFO  - >>>>>>>> Epoch  52
2022-11-04 01:32:30,539 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:32:34,054 - INFO  - Training [52][   20/  196]   Loss 0.012543   Top1 99.531250   Top5 100.000000   BatchTime 0.175746   LR 0.001000   
2022-11-04 01:32:35,768 - INFO  - Training [52][   40/  196]   Loss 0.013032   Top1 99.531250   Top5 100.000000   BatchTime 0.130723   LR 0.001000   
2022-11-04 01:32:37,466 - INFO  - Training [52][   60/  196]   Loss 0.013422   Top1 99.550781   Top5 100.000000   BatchTime 0.115455   LR 0.001000   
2022-11-04 01:32:39,153 - INFO  - Training [52][   80/  196]   Loss 0.012981   Top1 99.565430   Top5 100.000000   BatchTime 0.107668   LR 0.001000   
2022-11-04 01:32:40,827 - INFO  - Training [52][  100/  196]   Loss 0.013946   Top1 99.539062   Top5 100.000000   BatchTime 0.102880   LR 0.001000   
2022-11-04 01:32:42,522 - INFO  - Training [52][  120/  196]   Loss 0.013691   Top1 99.554036   Top5 100.000000   BatchTime 0.099858   LR 0.001000   
2022-11-04 01:32:44,185 - INFO  - Training [52][  140/  196]   Loss 0.013111   Top1 99.587054   Top5 100.000000   BatchTime 0.097470   LR 0.001000   
2022-11-04 01:32:45,838 - INFO  - Training [52][  160/  196]   Loss 0.013681   Top1 99.560547   Top5 100.000000   BatchTime 0.095615   LR 0.001000   
2022-11-04 01:32:47,484 - INFO  - Training [52][  180/  196]   Loss 0.014187   Top1 99.533420   Top5 100.000000   BatchTime 0.094135   LR 0.001000   
2022-11-04 01:32:49,015 - INFO  - ==> Top1: 99.538    Top5: 100.000    Loss: 0.014

2022-11-04 01:32:49,015 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:32:51,392 - INFO  - Validation [52][   20/   40]   Loss 0.466332   Top1 90.820312   Top5 99.492188   BatchTime 0.118727   
2022-11-04 01:32:52,069 - INFO  - Validation [52][   40/   40]   Loss 0.448765   Top1 90.930000   Top5 99.620000   BatchTime 0.076310   
2022-11-04 01:32:52,293 - INFO  - ==> Top1: 90.930    Top5: 99.620    Loss: 0.449

2022-11-04 01:32:52,314 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:32:52,315 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:32:52,315 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:32:52,424 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:32:52,425 - INFO  - >>>>>>>> Epoch  53
2022-11-04 01:32:52,425 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:32:55,975 - INFO  - Training [53][   20/  196]   Loss 0.015889   Top1 99.394531   Top5 100.000000   BatchTime 0.177477   LR 0.001000   
2022-11-04 01:32:57,653 - INFO  - Training [53][   40/  196]   Loss 0.013203   Top1 99.560547   Top5 100.000000   BatchTime 0.130675   LR 0.001000   
2022-11-04 01:32:59,316 - INFO  - Training [53][   60/  196]   Loss 0.012840   Top1 99.576823   Top5 100.000000   BatchTime 0.114842   LR 0.001000   
2022-11-04 01:33:00,992 - INFO  - Training [53][   80/  196]   Loss 0.012867   Top1 99.570312   Top5 100.000000   BatchTime 0.107077   LR 0.001000   
2022-11-04 01:33:02,684 - INFO  - Training [53][  100/  196]   Loss 0.013127   Top1 99.566406   Top5 100.000000   BatchTime 0.102577   LR 0.001000   
2022-11-04 01:33:04,373 - INFO  - Training [53][  120/  196]   Loss 0.013439   Top1 99.544271   Top5 100.000000   BatchTime 0.099556   LR 0.001000   
2022-11-04 01:33:06,086 - INFO  - Training [53][  140/  196]   Loss 0.013159   Top1 99.559152   Top5 100.000000   BatchTime 0.097575   LR 0.001000   
2022-11-04 01:33:07,754 - INFO  - Training [53][  160/  196]   Loss 0.013034   Top1 99.575195   Top5 100.000000   BatchTime 0.095799   LR 0.001000   
2022-11-04 01:33:09,415 - INFO  - Training [53][  180/  196]   Loss 0.012926   Top1 99.578993   Top5 100.000000   BatchTime 0.094382   LR 0.001000   
2022-11-04 01:33:10,945 - INFO  - ==> Top1: 99.570    Top5: 100.000    Loss: 0.013

2022-11-04 01:33:10,945 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:33:13,310 - INFO  - Validation [53][   20/   40]   Loss 0.470453   Top1 90.878906   Top5 99.394531   BatchTime 0.118166   
2022-11-04 01:33:13,993 - INFO  - Validation [53][   40/   40]   Loss 0.454776   Top1 90.890000   Top5 99.560000   BatchTime 0.076150   
2022-11-04 01:33:14,221 - INFO  - ==> Top1: 90.890    Top5: 99.560    Loss: 0.455

2022-11-04 01:33:14,243 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:33:14,244 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:33:14,244 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:33:14,353 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:33:14,354 - INFO  - >>>>>>>> Epoch  54
2022-11-04 01:33:14,355 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:33:17,866 - INFO  - Training [54][   20/  196]   Loss 0.014506   Top1 99.531250   Top5 100.000000   BatchTime 0.175561   LR 0.001000   
2022-11-04 01:33:19,528 - INFO  - Training [54][   40/  196]   Loss 0.015927   Top1 99.501953   Top5 100.000000   BatchTime 0.129315   LR 0.001000   
2022-11-04 01:33:21,237 - INFO  - Training [54][   60/  196]   Loss 0.014103   Top1 99.557292   Top5 100.000000   BatchTime 0.114702   LR 0.001000   
2022-11-04 01:33:22,910 - INFO  - Training [54][   80/  196]   Loss 0.014086   Top1 99.555664   Top5 100.000000   BatchTime 0.106933   LR 0.001000   
2022-11-04 01:33:24,574 - INFO  - Training [54][  100/  196]   Loss 0.014351   Top1 99.531250   Top5 100.000000   BatchTime 0.102188   LR 0.001000   
2022-11-04 01:33:26,272 - INFO  - Training [54][  120/  196]   Loss 0.014036   Top1 99.567057   Top5 100.000000   BatchTime 0.099306   LR 0.001000   
2022-11-04 01:33:27,934 - INFO  - Training [54][  140/  196]   Loss 0.013660   Top1 99.575893   Top5 100.000000   BatchTime 0.096989   LR 0.001000   
2022-11-04 01:33:29,698 - INFO  - Training [54][  160/  196]   Loss 0.013075   Top1 99.594727   Top5 100.000000   BatchTime 0.095891   LR 0.001000   
2022-11-04 01:33:31,361 - INFO  - Training [54][  180/  196]   Loss 0.013027   Top1 99.585503   Top5 100.000000   BatchTime 0.094473   LR 0.001000   
2022-11-04 01:33:32,898 - INFO  - ==> Top1: 99.584    Top5: 100.000    Loss: 0.013

2022-11-04 01:33:32,898 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:33:35,336 - INFO  - Validation [54][   20/   40]   Loss 0.468519   Top1 90.898438   Top5 99.472656   BatchTime 0.121843   
2022-11-04 01:33:36,031 - INFO  - Validation [54][   40/   40]   Loss 0.454295   Top1 90.950000   Top5 99.570000   BatchTime 0.078290   
2022-11-04 01:33:36,270 - INFO  - ==> Top1: 90.950    Top5: 99.570    Loss: 0.454

2022-11-04 01:33:36,294 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:33:36,295 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:33:36,295 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:33:36,401 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:33:36,401 - INFO  - >>>>>>>> Epoch  55
2022-11-04 01:33:36,402 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:33:40,025 - INFO  - Training [55][   20/  196]   Loss 0.011485   Top1 99.648438   Top5 100.000000   BatchTime 0.181133   LR 0.001000   
2022-11-04 01:33:41,786 - INFO  - Training [55][   40/  196]   Loss 0.011612   Top1 99.609375   Top5 100.000000   BatchTime 0.134572   LR 0.001000   
2022-11-04 01:33:43,534 - INFO  - Training [55][   60/  196]   Loss 0.011565   Top1 99.609375   Top5 100.000000   BatchTime 0.118851   LR 0.001000   
2022-11-04 01:33:45,231 - INFO  - Training [55][   80/  196]   Loss 0.011807   Top1 99.594727   Top5 100.000000   BatchTime 0.110355   LR 0.001000   
2022-11-04 01:33:46,932 - INFO  - Training [55][  100/  196]   Loss 0.012232   Top1 99.582031   Top5 100.000000   BatchTime 0.105294   LR 0.001000   
2022-11-04 01:33:48,619 - INFO  - Training [55][  120/  196]   Loss 0.012252   Top1 99.589844   Top5 100.000000   BatchTime 0.101798   LR 0.001000   
2022-11-04 01:33:50,359 - INFO  - Training [55][  140/  196]   Loss 0.013109   Top1 99.547991   Top5 100.000000   BatchTime 0.099684   LR 0.001000   
2022-11-04 01:33:52,048 - INFO  - Training [55][  160/  196]   Loss 0.013018   Top1 99.570312   Top5 100.000000   BatchTime 0.097783   LR 0.001000   
2022-11-04 01:33:53,718 - INFO  - Training [55][  180/  196]   Loss 0.012954   Top1 99.583333   Top5 100.000000   BatchTime 0.096192   LR 0.001000   
2022-11-04 01:33:55,296 - INFO  - ==> Top1: 99.590    Top5: 100.000    Loss: 0.013

2022-11-04 01:33:55,296 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:33:57,748 - INFO  - Validation [55][   20/   40]   Loss 0.468102   Top1 90.781250   Top5 99.433594   BatchTime 0.122494   
2022-11-04 01:33:58,470 - INFO  - Validation [55][   40/   40]   Loss 0.450338   Top1 91.040000   Top5 99.570000   BatchTime 0.079309   
2022-11-04 01:33:58,726 - INFO  - ==> Top1: 91.040    Top5: 99.570    Loss: 0.450

2022-11-04 01:33:58,751 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:33:58,752 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:33:58,752 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 91.120   Top5: 99.540] Sparsity : 0.827
2022-11-04 01:33:58,863 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:33:58,863 - INFO  - >>>>>>>> Epoch  56
2022-11-04 01:33:58,865 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:34:02,441 - INFO  - Training [56][   20/  196]   Loss 0.012289   Top1 99.667969   Top5 100.000000   BatchTime 0.178773   LR 0.001000   
2022-11-04 01:34:04,105 - INFO  - Training [56][   40/  196]   Loss 0.012641   Top1 99.667969   Top5 100.000000   BatchTime 0.130995   LR 0.001000   
2022-11-04 01:34:05,792 - INFO  - Training [56][   60/  196]   Loss 0.012305   Top1 99.667969   Top5 100.000000   BatchTime 0.115456   LR 0.001000   
2022-11-04 01:34:07,523 - INFO  - Training [56][   80/  196]   Loss 0.012349   Top1 99.643555   Top5 100.000000   BatchTime 0.108229   LR 0.001000   
2022-11-04 01:34:09,231 - INFO  - Training [56][  100/  196]   Loss 0.013067   Top1 99.625000   Top5 100.000000   BatchTime 0.103656   LR 0.001000   
2022-11-04 01:34:10,901 - INFO  - Training [56][  120/  196]   Loss 0.013126   Top1 99.632161   Top5 100.000000   BatchTime 0.100300   LR 0.001000   
2022-11-04 01:34:12,573 - INFO  - Training [56][  140/  196]   Loss 0.012835   Top1 99.623326   Top5 100.000000   BatchTime 0.097908   LR 0.001000   
2022-11-04 01:34:14,228 - INFO  - Training [56][  160/  196]   Loss 0.013365   Top1 99.599609   Top5 100.000000   BatchTime 0.096014   LR 0.001000   
2022-11-04 01:34:15,880 - INFO  - Training [56][  180/  196]   Loss 0.013299   Top1 99.600694   Top5 100.000000   BatchTime 0.094526   LR 0.001000   
2022-11-04 01:34:17,397 - INFO  - ==> Top1: 99.606    Top5: 100.000    Loss: 0.013

2022-11-04 01:34:17,398 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:34:19,784 - INFO  - Validation [56][   20/   40]   Loss 0.475249   Top1 90.976562   Top5 99.414062   BatchTime 0.119244   
2022-11-04 01:34:20,474 - INFO  - Validation [56][   40/   40]   Loss 0.456045   Top1 91.130000   Top5 99.560000   BatchTime 0.076851   
2022-11-04 01:34:20,708 - INFO  - ==> Top1: 91.130    Top5: 99.560    Loss: 0.456

2022-11-04 01:34:20,730 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:34:20,730 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:34:20,731 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.130   Top5: 99.560] Sparsity : 0.827
2022-11-04 01:34:20,836 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:34:20,836 - INFO  - >>>>>>>> Epoch  57
2022-11-04 01:34:20,837 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:34:24,363 - INFO  - Training [57][   20/  196]   Loss 0.012318   Top1 99.609375   Top5 100.000000   BatchTime 0.176276   LR 0.001000   
2022-11-04 01:34:26,055 - INFO  - Training [57][   40/  196]   Loss 0.012280   Top1 99.609375   Top5 100.000000   BatchTime 0.130445   LR 0.001000   
2022-11-04 01:34:27,752 - INFO  - Training [57][   60/  196]   Loss 0.012022   Top1 99.615885   Top5 100.000000   BatchTime 0.115232   LR 0.001000   
2022-11-04 01:34:29,468 - INFO  - Training [57][   80/  196]   Loss 0.012501   Top1 99.614258   Top5 100.000000   BatchTime 0.107876   LR 0.001000   
2022-11-04 01:34:31,152 - INFO  - Training [57][  100/  196]   Loss 0.012792   Top1 99.609375   Top5 100.000000   BatchTime 0.103145   LR 0.001000   
2022-11-04 01:34:32,820 - INFO  - Training [57][  120/  196]   Loss 0.012750   Top1 99.606120   Top5 100.000000   BatchTime 0.099854   LR 0.001000   
2022-11-04 01:34:34,484 - INFO  - Training [57][  140/  196]   Loss 0.012627   Top1 99.601004   Top5 100.000000   BatchTime 0.097474   LR 0.001000   
2022-11-04 01:34:36,132 - INFO  - Training [57][  160/  196]   Loss 0.012507   Top1 99.602051   Top5 100.000000   BatchTime 0.095585   LR 0.001000   
2022-11-04 01:34:37,779 - INFO  - Training [57][  180/  196]   Loss 0.012457   Top1 99.602865   Top5 100.000000   BatchTime 0.094117   LR 0.001000   
2022-11-04 01:34:39,315 - INFO  - ==> Top1: 99.596    Top5: 100.000    Loss: 0.013

2022-11-04 01:34:39,316 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:34:41,677 - INFO  - Validation [57][   20/   40]   Loss 0.469736   Top1 91.093750   Top5 99.433594   BatchTime 0.117954   
2022-11-04 01:34:42,362 - INFO  - Validation [57][   40/   40]   Loss 0.454394   Top1 91.160000   Top5 99.550000   BatchTime 0.076096   
2022-11-04 01:34:42,591 - INFO  - ==> Top1: 91.160    Top5: 99.550    Loss: 0.454

2022-11-04 01:34:42,614 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:34:42,615 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:34:42,615 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:34:42,727 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:34:42,728 - INFO  - >>>>>>>> Epoch  58
2022-11-04 01:34:42,729 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:34:46,290 - INFO  - Training [58][   20/  196]   Loss 0.012857   Top1 99.609375   Top5 100.000000   BatchTime 0.178040   LR 0.001000   
2022-11-04 01:34:47,958 - INFO  - Training [58][   40/  196]   Loss 0.013789   Top1 99.580078   Top5 100.000000   BatchTime 0.130709   LR 0.001000   
2022-11-04 01:34:49,641 - INFO  - Training [58][   60/  196]   Loss 0.013936   Top1 99.563802   Top5 100.000000   BatchTime 0.115191   LR 0.001000   
2022-11-04 01:34:51,369 - INFO  - Training [58][   80/  196]   Loss 0.013075   Top1 99.599609   Top5 100.000000   BatchTime 0.107996   LR 0.001000   
2022-11-04 01:34:53,084 - INFO  - Training [58][  100/  196]   Loss 0.012832   Top1 99.609375   Top5 100.000000   BatchTime 0.103544   LR 0.001000   
2022-11-04 01:34:54,829 - INFO  - Training [58][  120/  196]   Loss 0.012446   Top1 99.609375   Top5 100.000000   BatchTime 0.100826   LR 0.001000   
2022-11-04 01:34:56,559 - INFO  - Training [58][  140/  196]   Loss 0.012988   Top1 99.561942   Top5 100.000000   BatchTime 0.098783   LR 0.001000   
2022-11-04 01:34:58,286 - INFO  - Training [58][  160/  196]   Loss 0.013562   Top1 99.541016   Top5 100.000000   BatchTime 0.097226   LR 0.001000   
2022-11-04 01:35:00,042 - INFO  - Training [58][  180/  196]   Loss 0.013651   Top1 99.537760   Top5 100.000000   BatchTime 0.096180   LR 0.001000   
2022-11-04 01:35:01,592 - INFO  - ==> Top1: 99.544    Top5: 100.000    Loss: 0.014

2022-11-04 01:35:01,593 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:35:04,130 - INFO  - Validation [58][   20/   40]   Loss 0.479641   Top1 90.761719   Top5 99.453125   BatchTime 0.126767   
2022-11-04 01:35:04,931 - INFO  - Validation [58][   40/   40]   Loss 0.460857   Top1 90.850000   Top5 99.580000   BatchTime 0.083399   
2022-11-04 01:35:05,173 - INFO  - ==> Top1: 90.850    Top5: 99.580    Loss: 0.461

2022-11-04 01:35:05,204 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:35:05,205 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:35:05,205 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:35:05,276 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:35:05,276 - INFO  - >>>>>>>> Epoch  59
2022-11-04 01:35:05,277 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:35:09,161 - INFO  - Training [59][   20/  196]   Loss 0.010925   Top1 99.667969   Top5 100.000000   BatchTime 0.194155   LR 0.001000   
2022-11-04 01:35:11,563 - INFO  - Training [59][   40/  196]   Loss 0.012298   Top1 99.638672   Top5 100.000000   BatchTime 0.157128   LR 0.001000   
2022-11-04 01:35:14,041 - INFO  - Training [59][   60/  196]   Loss 0.012701   Top1 99.570312   Top5 100.000000   BatchTime 0.146055   LR 0.001000   
2022-11-04 01:35:16,512 - INFO  - Training [59][   80/  196]   Loss 0.012550   Top1 99.570312   Top5 100.000000   BatchTime 0.140425   LR 0.001000   
2022-11-04 01:35:19,011 - INFO  - Training [59][  100/  196]   Loss 0.013122   Top1 99.558594   Top5 100.000000   BatchTime 0.137329   LR 0.001000   
2022-11-04 01:35:21,497 - INFO  - Training [59][  120/  196]   Loss 0.013060   Top1 99.567057   Top5 100.000000   BatchTime 0.135157   LR 0.001000   
2022-11-04 01:35:24,004 - INFO  - Training [59][  140/  196]   Loss 0.013008   Top1 99.567522   Top5 100.000000   BatchTime 0.133759   LR 0.001000   
2022-11-04 01:35:26,472 - INFO  - Training [59][  160/  196]   Loss 0.013688   Top1 99.553223   Top5 100.000000   BatchTime 0.132462   LR 0.001000   
2022-11-04 01:35:28,938 - INFO  - Training [59][  180/  196]   Loss 0.013456   Top1 99.557292   Top5 100.000000   BatchTime 0.131441   LR 0.001000   
2022-11-04 01:35:31,110 - INFO  - ==> Top1: 99.560    Top5: 100.000    Loss: 0.013

2022-11-04 01:35:31,111 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:35:33,973 - INFO  - Validation [59][   20/   40]   Loss 0.479521   Top1 90.566406   Top5 99.433594   BatchTime 0.143033   
2022-11-04 01:35:35,085 - INFO  - Validation [59][   40/   40]   Loss 0.460271   Top1 90.860000   Top5 99.610000   BatchTime 0.099298   
2022-11-04 01:35:35,328 - INFO  - ==> Top1: 90.860    Top5: 99.610    Loss: 0.460

2022-11-04 01:35:35,361 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:35:35,362 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:35:35,362 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:35:35,470 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:35:35,470 - INFO  - >>>>>>>> Epoch  60
2022-11-04 01:35:35,471 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:35:39,825 - INFO  - Training [60][   20/  196]   Loss 0.011517   Top1 99.628906   Top5 100.000000   BatchTime 0.217670   LR 0.000100   
2022-11-04 01:35:42,313 - INFO  - Training [60][   40/  196]   Loss 0.011288   Top1 99.667969   Top5 100.000000   BatchTime 0.171044   LR 0.000100   
2022-11-04 01:35:44,791 - INFO  - Training [60][   60/  196]   Loss 0.011946   Top1 99.654948   Top5 100.000000   BatchTime 0.155312   LR 0.000100   
2022-11-04 01:35:47,277 - INFO  - Training [60][   80/  196]   Loss 0.012874   Top1 99.628906   Top5 100.000000   BatchTime 0.147569   LR 0.000100   
2022-11-04 01:35:49,742 - INFO  - Training [60][  100/  196]   Loss 0.012323   Top1 99.656250   Top5 100.000000   BatchTime 0.142706   LR 0.000100   
2022-11-04 01:35:52,219 - INFO  - Training [60][  120/  196]   Loss 0.012091   Top1 99.645182   Top5 100.000000   BatchTime 0.139555   LR 0.000100   
2022-11-04 01:35:54,654 - INFO  - Training [60][  140/  196]   Loss 0.012071   Top1 99.640067   Top5 100.000000   BatchTime 0.137016   LR 0.000100   
2022-11-04 01:35:56,753 - INFO  - Training [60][  160/  196]   Loss 0.012142   Top1 99.641113   Top5 100.000000   BatchTime 0.133007   LR 0.000100   
2022-11-04 01:35:58,629 - INFO  - Training [60][  180/  196]   Loss 0.012409   Top1 99.626736   Top5 100.000000   BatchTime 0.128650   LR 0.000100   
2022-11-04 01:36:00,459 - INFO  - ==> Top1: 99.622    Top5: 100.000    Loss: 0.012

2022-11-04 01:36:00,460 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:36:02,977 - INFO  - Validation [60][   20/   40]   Loss 0.472325   Top1 90.664062   Top5 99.375000   BatchTime 0.125779   
2022-11-04 01:36:03,794 - INFO  - Validation [60][   40/   40]   Loss 0.459797   Top1 90.930000   Top5 99.530000   BatchTime 0.083315   
2022-11-04 01:36:04,028 - INFO  - ==> Top1: 90.930    Top5: 99.530    Loss: 0.460

2022-11-04 01:36:04,055 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:36:04,056 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:36:04,056 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:36:04,160 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:36:04,160 - INFO  - >>>>>>>> Epoch  61
2022-11-04 01:36:04,161 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:36:08,516 - INFO  - Training [61][   20/  196]   Loss 0.013573   Top1 99.550781   Top5 100.000000   BatchTime 0.217732   LR 0.000100   
2022-11-04 01:36:10,991 - INFO  - Training [61][   40/  196]   Loss 0.012485   Top1 99.599609   Top5 100.000000   BatchTime 0.170736   LR 0.000100   
2022-11-04 01:36:13,476 - INFO  - Training [61][   60/  196]   Loss 0.012203   Top1 99.576823   Top5 100.000000   BatchTime 0.155248   LR 0.000100   
2022-11-04 01:36:15,963 - INFO  - Training [61][   80/  196]   Loss 0.011575   Top1 99.599609   Top5 100.000000   BatchTime 0.147516   LR 0.000100   
2022-11-04 01:36:18,442 - INFO  - Training [61][  100/  196]   Loss 0.012017   Top1 99.601562   Top5 100.000000   BatchTime 0.142808   LR 0.000100   
2022-11-04 01:36:20,941 - INFO  - Training [61][  120/  196]   Loss 0.012333   Top1 99.606120   Top5 100.000000   BatchTime 0.139831   LR 0.000100   
2022-11-04 01:36:23,411 - INFO  - Training [61][  140/  196]   Loss 0.012592   Top1 99.606585   Top5 100.000000   BatchTime 0.137495   LR 0.000100   
2022-11-04 01:36:25,878 - INFO  - Training [61][  160/  196]   Loss 0.012984   Top1 99.594727   Top5 100.000000   BatchTime 0.135728   LR 0.000100   
2022-11-04 01:36:28,339 - INFO  - Training [61][  180/  196]   Loss 0.012958   Top1 99.600694   Top5 100.000000   BatchTime 0.134320   LR 0.000100   
2022-11-04 01:36:30,504 - INFO  - ==> Top1: 99.598    Top5: 100.000    Loss: 0.013

2022-11-04 01:36:30,505 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:36:33,354 - INFO  - Validation [61][   20/   40]   Loss 0.473589   Top1 90.957031   Top5 99.453125   BatchTime 0.142358   
2022-11-04 01:36:34,465 - INFO  - Validation [61][   40/   40]   Loss 0.457938   Top1 91.040000   Top5 99.570000   BatchTime 0.098942   
2022-11-04 01:36:34,701 - INFO  - ==> Top1: 91.040    Top5: 99.570    Loss: 0.458

2022-11-04 01:36:34,742 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:36:34,743 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:36:34,743 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:36:34,851 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:36:34,851 - INFO  - >>>>>>>> Epoch  62
2022-11-04 01:36:34,853 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:36:39,193 - INFO  - Training [62][   20/  196]   Loss 0.014780   Top1 99.531250   Top5 100.000000   BatchTime 0.217003   LR 0.000100   
2022-11-04 01:36:41,675 - INFO  - Training [62][   40/  196]   Loss 0.013556   Top1 99.560547   Top5 100.000000   BatchTime 0.170542   LR 0.000100   
2022-11-04 01:36:44,151 - INFO  - Training [62][   60/  196]   Loss 0.013363   Top1 99.557292   Top5 100.000000   BatchTime 0.154956   LR 0.000100   
2022-11-04 01:36:46,618 - INFO  - Training [62][   80/  196]   Loss 0.013205   Top1 99.575195   Top5 100.000000   BatchTime 0.147054   LR 0.000100   
2022-11-04 01:36:49,021 - INFO  - Training [62][  100/  196]   Loss 0.014054   Top1 99.542969   Top5 100.000000   BatchTime 0.141679   LR 0.000100   
2022-11-04 01:36:50,827 - INFO  - Training [62][  120/  196]   Loss 0.014218   Top1 99.531250   Top5 100.000000   BatchTime 0.133110   LR 0.000100   
2022-11-04 01:36:52,867 - INFO  - Training [62][  140/  196]   Loss 0.013929   Top1 99.550781   Top5 100.000000   BatchTime 0.128670   LR 0.000100   
2022-11-04 01:36:54,870 - INFO  - Training [62][  160/  196]   Loss 0.014030   Top1 99.536133   Top5 100.000000   BatchTime 0.125103   LR 0.000100   
2022-11-04 01:36:56,736 - INFO  - Training [62][  180/  196]   Loss 0.013527   Top1 99.552951   Top5 100.000000   BatchTime 0.121567   LR 0.000100   
2022-11-04 01:36:58,422 - INFO  - ==> Top1: 99.564    Top5: 100.000    Loss: 0.013

2022-11-04 01:36:58,423 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:37:01,257 - INFO  - Validation [62][   20/   40]   Loss 0.477251   Top1 90.820312   Top5 99.394531   BatchTime 0.141602   
2022-11-04 01:37:02,380 - INFO  - Validation [62][   40/   40]   Loss 0.457427   Top1 91.030000   Top5 99.540000   BatchTime 0.098882   
2022-11-04 01:37:02,625 - INFO  - ==> Top1: 91.030    Top5: 99.540    Loss: 0.457

2022-11-04 01:37:02,665 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:37:02,666 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:37:02,666 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:37:02,789 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:37:02,790 - INFO  - >>>>>>>> Epoch  63
2022-11-04 01:37:02,790 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:37:07,121 - INFO  - Training [63][   20/  196]   Loss 0.011248   Top1 99.667969   Top5 100.000000   BatchTime 0.216541   LR 0.000100   
2022-11-04 01:37:09,687 - INFO  - Training [63][   40/  196]   Loss 0.011811   Top1 99.638672   Top5 100.000000   BatchTime 0.172414   LR 0.000100   
2022-11-04 01:37:12,162 - INFO  - Training [63][   60/  196]   Loss 0.012578   Top1 99.622396   Top5 100.000000   BatchTime 0.156182   LR 0.000100   
2022-11-04 01:37:14,645 - INFO  - Training [63][   80/  196]   Loss 0.012203   Top1 99.638672   Top5 100.000000   BatchTime 0.148178   LR 0.000100   
2022-11-04 01:37:17,114 - INFO  - Training [63][  100/  196]   Loss 0.012502   Top1 99.609375   Top5 100.000000   BatchTime 0.143235   LR 0.000100   
2022-11-04 01:37:19,585 - INFO  - Training [63][  120/  196]   Loss 0.012606   Top1 99.599609   Top5 100.000000   BatchTime 0.139954   LR 0.000100   
2022-11-04 01:37:22,054 - INFO  - Training [63][  140/  196]   Loss 0.012803   Top1 99.595424   Top5 100.000000   BatchTime 0.137591   LR 0.000100   
2022-11-04 01:37:24,518 - INFO  - Training [63][  160/  196]   Loss 0.012965   Top1 99.584961   Top5 100.000000   BatchTime 0.135796   LR 0.000100   
2022-11-04 01:37:26,996 - INFO  - Training [63][  180/  196]   Loss 0.013048   Top1 99.578993   Top5 100.000000   BatchTime 0.134471   LR 0.000100   
2022-11-04 01:37:29,174 - INFO  - ==> Top1: 99.592    Top5: 100.000    Loss: 0.013

2022-11-04 01:37:29,175 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:37:31,989 - INFO  - Validation [63][   20/   40]   Loss 0.476097   Top1 90.859375   Top5 99.375000   BatchTime 0.140617   
2022-11-04 01:37:33,108 - INFO  - Validation [63][   40/   40]   Loss 0.455674   Top1 91.090000   Top5 99.570000   BatchTime 0.098289   
2022-11-04 01:37:33,348 - INFO  - ==> Top1: 91.090    Top5: 99.570    Loss: 0.456

2022-11-04 01:37:33,376 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:37:33,377 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:37:33,377 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:37:33,480 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:37:33,480 - INFO  - >>>>>>>> Epoch  64
2022-11-04 01:37:33,482 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:37:37,763 - INFO  - Training [64][   20/  196]   Loss 0.011097   Top1 99.628906   Top5 100.000000   BatchTime 0.214036   LR 0.000100   
2022-11-04 01:37:40,237 - INFO  - Training [64][   40/  196]   Loss 0.012189   Top1 99.580078   Top5 100.000000   BatchTime 0.168886   LR 0.000100   
2022-11-04 01:37:42,251 - INFO  - Training [64][   60/  196]   Loss 0.012193   Top1 99.589844   Top5 100.000000   BatchTime 0.146149   LR 0.000100   
2022-11-04 01:37:44,219 - INFO  - Training [64][   80/  196]   Loss 0.011950   Top1 99.594727   Top5 100.000000   BatchTime 0.134205   LR 0.000100   
2022-11-04 01:37:46,253 - INFO  - Training [64][  100/  196]   Loss 0.011424   Top1 99.628906   Top5 100.000000   BatchTime 0.127707   LR 0.000100   
2022-11-04 01:37:48,384 - INFO  - Training [64][  120/  196]   Loss 0.011817   Top1 99.596354   Top5 100.000000   BatchTime 0.124179   LR 0.000100   
2022-11-04 01:37:50,108 - INFO  - Training [64][  140/  196]   Loss 0.012098   Top1 99.589844   Top5 100.000000   BatchTime 0.118757   LR 0.000100   
2022-11-04 01:37:52,749 - INFO  - Training [64][  160/  196]   Loss 0.012039   Top1 99.597168   Top5 100.000000   BatchTime 0.120415   LR 0.000100   
2022-11-04 01:37:55,219 - INFO  - Training [64][  180/  196]   Loss 0.012686   Top1 99.581163   Top5 100.000000   BatchTime 0.120760   LR 0.000100   
2022-11-04 01:37:57,382 - INFO  - ==> Top1: 99.580    Top5: 100.000    Loss: 0.013

2022-11-04 01:37:57,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:38:00,215 - INFO  - Validation [64][   20/   40]   Loss 0.480072   Top1 90.683594   Top5 99.472656   BatchTime 0.141545   
2022-11-04 01:38:01,346 - INFO  - Validation [64][   40/   40]   Loss 0.461412   Top1 90.930000   Top5 99.610000   BatchTime 0.099040   
2022-11-04 01:38:01,591 - INFO  - ==> Top1: 90.930    Top5: 99.610    Loss: 0.461

2022-11-04 01:38:01,621 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:38:01,622 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:38:01,623 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:38:01,733 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:38:01,733 - INFO  - >>>>>>>> Epoch  65
2022-11-04 01:38:01,735 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:38:06,090 - INFO  - Training [65][   20/  196]   Loss 0.011061   Top1 99.687500   Top5 100.000000   BatchTime 0.217773   LR 0.000100   
2022-11-04 01:38:08,576 - INFO  - Training [65][   40/  196]   Loss 0.012394   Top1 99.619141   Top5 100.000000   BatchTime 0.171031   LR 0.000100   
2022-11-04 01:38:11,052 - INFO  - Training [65][   60/  196]   Loss 0.012890   Top1 99.583333   Top5 100.000000   BatchTime 0.155288   LR 0.000100   
2022-11-04 01:38:13,528 - INFO  - Training [65][   80/  196]   Loss 0.012546   Top1 99.614258   Top5 100.000000   BatchTime 0.147412   LR 0.000100   
2022-11-04 01:38:16,027 - INFO  - Training [65][  100/  196]   Loss 0.013300   Top1 99.558594   Top5 100.000000   BatchTime 0.142915   LR 0.000100   
2022-11-04 01:38:18,524 - INFO  - Training [65][  120/  196]   Loss 0.013651   Top1 99.541016   Top5 100.000000   BatchTime 0.139907   LR 0.000100   
2022-11-04 01:38:20,996 - INFO  - Training [65][  140/  196]   Loss 0.013624   Top1 99.547991   Top5 100.000000   BatchTime 0.137579   LR 0.000100   
2022-11-04 01:38:23,451 - INFO  - Training [65][  160/  196]   Loss 0.013547   Top1 99.560547   Top5 100.000000   BatchTime 0.135722   LR 0.000100   
2022-11-04 01:38:25,922 - INFO  - Training [65][  180/  196]   Loss 0.013463   Top1 99.568142   Top5 100.000000   BatchTime 0.134372   LR 0.000100   
2022-11-04 01:38:28,080 - INFO  - ==> Top1: 99.566    Top5: 100.000    Loss: 0.013

2022-11-04 01:38:28,081 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:38:30,913 - INFO  - Validation [65][   20/   40]   Loss 0.476754   Top1 90.976562   Top5 99.453125   BatchTime 0.141576   
2022-11-04 01:38:32,042 - INFO  - Validation [65][   40/   40]   Loss 0.460958   Top1 91.050000   Top5 99.590000   BatchTime 0.098994   
2022-11-04 01:38:32,283 - INFO  - ==> Top1: 91.050    Top5: 99.590    Loss: 0.461

2022-11-04 01:38:32,325 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:38:32,326 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:38:32,326 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:38:32,432 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:38:32,432 - INFO  - >>>>>>>> Epoch  66
2022-11-04 01:38:32,433 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:38:36,349 - INFO  - Training [66][   20/  196]   Loss 0.013305   Top1 99.628906   Top5 100.000000   BatchTime 0.195785   LR 0.000100   
2022-11-04 01:38:38,379 - INFO  - Training [66][   40/  196]   Loss 0.015619   Top1 99.570312   Top5 100.000000   BatchTime 0.148632   LR 0.000100   
2022-11-04 01:38:40,411 - INFO  - Training [66][   60/  196]   Loss 0.014310   Top1 99.583333   Top5 100.000000   BatchTime 0.132962   LR 0.000100   
2022-11-04 01:38:42,341 - INFO  - Training [66][   80/  196]   Loss 0.015071   Top1 99.536133   Top5 100.000000   BatchTime 0.123846   LR 0.000100   
2022-11-04 01:38:44,468 - INFO  - Training [66][  100/  196]   Loss 0.014162   Top1 99.558594   Top5 100.000000   BatchTime 0.120343   LR 0.000100   
2022-11-04 01:38:46,950 - INFO  - Training [66][  120/  196]   Loss 0.014151   Top1 99.541016   Top5 100.000000   BatchTime 0.120968   LR 0.000100   
2022-11-04 01:38:49,425 - INFO  - Training [66][  140/  196]   Loss 0.013847   Top1 99.547991   Top5 100.000000   BatchTime 0.121364   LR 0.000100   
2022-11-04 01:38:51,890 - INFO  - Training [66][  160/  196]   Loss 0.013560   Top1 99.560547   Top5 100.000000   BatchTime 0.121601   LR 0.000100   
2022-11-04 01:38:54,351 - INFO  - Training [66][  180/  196]   Loss 0.013735   Top1 99.548611   Top5 100.000000   BatchTime 0.121761   LR 0.000100   
2022-11-04 01:38:56,522 - INFO  - ==> Top1: 99.558    Top5: 100.000    Loss: 0.014

2022-11-04 01:38:56,523 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:38:59,347 - INFO  - Validation [66][   20/   40]   Loss 0.469738   Top1 90.664062   Top5 99.375000   BatchTime 0.141130   
2022-11-04 01:39:00,429 - INFO  - Validation [66][   40/   40]   Loss 0.454138   Top1 90.790000   Top5 99.550000   BatchTime 0.097624   
2022-11-04 01:39:00,671 - INFO  - ==> Top1: 90.790    Top5: 99.550    Loss: 0.454

2022-11-04 01:39:00,698 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:39:00,699 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:39:00,699 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:39:00,808 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:39:00,808 - INFO  - >>>>>>>> Epoch  67
2022-11-04 01:39:00,810 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:39:05,160 - INFO  - Training [67][   20/  196]   Loss 0.010840   Top1 99.648438   Top5 100.000000   BatchTime 0.217514   LR 0.000100   
2022-11-04 01:39:07,774 - INFO  - Training [67][   40/  196]   Loss 0.010050   Top1 99.697266   Top5 100.000000   BatchTime 0.174090   LR 0.000100   
2022-11-04 01:39:10,249 - INFO  - Training [67][   60/  196]   Loss 0.011567   Top1 99.648438   Top5 100.000000   BatchTime 0.157315   LR 0.000100   
2022-11-04 01:39:12,721 - INFO  - Training [67][   80/  196]   Loss 0.012427   Top1 99.594727   Top5 100.000000   BatchTime 0.148886   LR 0.000100   
2022-11-04 01:39:15,185 - INFO  - Training [67][  100/  196]   Loss 0.012536   Top1 99.589844   Top5 100.000000   BatchTime 0.143744   LR 0.000100   
2022-11-04 01:39:17,665 - INFO  - Training [67][  120/  196]   Loss 0.013285   Top1 99.560547   Top5 100.000000   BatchTime 0.140453   LR 0.000100   
2022-11-04 01:39:20,152 - INFO  - Training [67][  140/  196]   Loss 0.013370   Top1 99.573103   Top5 100.000000   BatchTime 0.138155   LR 0.000100   
2022-11-04 01:39:22,603 - INFO  - Training [67][  160/  196]   Loss 0.013421   Top1 99.572754   Top5 100.000000   BatchTime 0.136206   LR 0.000100   
2022-11-04 01:39:25,057 - INFO  - Training [67][  180/  196]   Loss 0.013263   Top1 99.572483   Top5 100.000000   BatchTime 0.134704   LR 0.000100   
2022-11-04 01:39:27,216 - INFO  - ==> Top1: 99.574    Top5: 100.000    Loss: 0.013

2022-11-04 01:39:27,216 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:39:29,754 - INFO  - Validation [67][   20/   40]   Loss 0.474352   Top1 91.015625   Top5 99.375000   BatchTime 0.126782   
2022-11-04 01:39:30,534 - INFO  - Validation [67][   40/   40]   Loss 0.461017   Top1 90.990000   Top5 99.550000   BatchTime 0.082896   
2022-11-04 01:39:30,773 - INFO  - ==> Top1: 90.990    Top5: 99.550    Loss: 0.461

2022-11-04 01:39:30,806 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:39:30,807 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:39:30,807 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:39:30,904 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:39:30,904 - INFO  - >>>>>>>> Epoch  68
2022-11-04 01:39:30,906 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:39:34,563 - INFO  - Training [68][   20/  196]   Loss 0.010739   Top1 99.707031   Top5 100.000000   BatchTime 0.182866   LR 0.000100   
2022-11-04 01:39:36,856 - INFO  - Training [68][   40/  196]   Loss 0.012480   Top1 99.677734   Top5 100.000000   BatchTime 0.148749   LR 0.000100   
2022-11-04 01:39:39,292 - INFO  - Training [68][   60/  196]   Loss 0.012863   Top1 99.641927   Top5 100.000000   BatchTime 0.139766   LR 0.000100   
2022-11-04 01:39:41,762 - INFO  - Training [68][   80/  196]   Loss 0.012686   Top1 99.628906   Top5 100.000000   BatchTime 0.135699   LR 0.000100   
2022-11-04 01:39:44,238 - INFO  - Training [68][  100/  196]   Loss 0.012939   Top1 99.613281   Top5 100.000000   BatchTime 0.133317   LR 0.000100   
2022-11-04 01:39:46,731 - INFO  - Training [68][  120/  196]   Loss 0.013342   Top1 99.580078   Top5 100.000000   BatchTime 0.131871   LR 0.000100   
2022-11-04 01:39:49,214 - INFO  - Training [68][  140/  196]   Loss 0.013635   Top1 99.564732   Top5 100.000000   BatchTime 0.130767   LR 0.000100   
2022-11-04 01:39:51,674 - INFO  - Training [68][  160/  196]   Loss 0.013806   Top1 99.558105   Top5 100.000000   BatchTime 0.129795   LR 0.000100   
2022-11-04 01:39:54,141 - INFO  - Training [68][  180/  196]   Loss 0.013986   Top1 99.548611   Top5 100.000000   BatchTime 0.129081   LR 0.000100   
2022-11-04 01:39:56,303 - INFO  - ==> Top1: 99.556    Top5: 100.000    Loss: 0.014

2022-11-04 01:39:56,304 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:39:59,147 - INFO  - Validation [68][   20/   40]   Loss 0.470692   Top1 91.074219   Top5 99.550781   BatchTime 0.142056   
2022-11-04 01:40:00,272 - INFO  - Validation [68][   40/   40]   Loss 0.453757   Top1 91.140000   Top5 99.670000   BatchTime 0.099165   
2022-11-04 01:40:00,518 - INFO  - ==> Top1: 91.140    Top5: 99.670    Loss: 0.454

2022-11-04 01:40:00,563 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:40:00,564 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:40:00,564 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:40:00,695 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:40:00,695 - INFO  - >>>>>>>> Epoch  69
2022-11-04 01:40:00,696 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:40:05,094 - INFO  - Training [69][   20/  196]   Loss 0.015797   Top1 99.414062   Top5 100.000000   BatchTime 0.219869   LR 0.000100   
2022-11-04 01:40:07,580 - INFO  - Training [69][   40/  196]   Loss 0.015028   Top1 99.501953   Top5 100.000000   BatchTime 0.172086   LR 0.000100   
2022-11-04 01:40:10,055 - INFO  - Training [69][   60/  196]   Loss 0.014352   Top1 99.524740   Top5 100.000000   BatchTime 0.155980   LR 0.000100   
2022-11-04 01:40:12,535 - INFO  - Training [69][   80/  196]   Loss 0.012824   Top1 99.580078   Top5 100.000000   BatchTime 0.147980   LR 0.000100   
2022-11-04 01:40:15,004 - INFO  - Training [69][  100/  196]   Loss 0.012330   Top1 99.597656   Top5 100.000000   BatchTime 0.143075   LR 0.000100   
2022-11-04 01:40:17,475 - INFO  - Training [69][  120/  196]   Loss 0.012891   Top1 99.570312   Top5 100.000000   BatchTime 0.139819   LR 0.000100   
2022-11-04 01:40:19,944 - INFO  - Training [69][  140/  196]   Loss 0.013027   Top1 99.570312   Top5 100.000000   BatchTime 0.137482   LR 0.000100   
2022-11-04 01:40:21,996 - INFO  - Training [69][  160/  196]   Loss 0.012977   Top1 99.570312   Top5 100.000000   BatchTime 0.133123   LR 0.000100   
2022-11-04 01:40:23,884 - INFO  - Training [69][  180/  196]   Loss 0.012960   Top1 99.572483   Top5 100.000000   BatchTime 0.128817   LR 0.000100   
2022-11-04 01:40:25,713 - INFO  - ==> Top1: 99.570    Top5: 100.000    Loss: 0.013

2022-11-04 01:40:25,714 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:40:28,237 - INFO  - Validation [69][   20/   40]   Loss 0.472391   Top1 90.722656   Top5 99.375000   BatchTime 0.126107   
2022-11-04 01:40:28,962 - INFO  - Validation [69][   40/   40]   Loss 0.456229   Top1 90.990000   Top5 99.510000   BatchTime 0.081180   
2022-11-04 01:40:29,272 - INFO  - ==> Top1: 90.990    Top5: 99.510    Loss: 0.456

2022-11-04 01:40:29,300 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:40:29,301 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:40:29,301 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:40:29,444 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:40:29,444 - INFO  - >>>>>>>> Epoch  70
2022-11-04 01:40:29,446 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:40:33,763 - INFO  - Training [70][   20/  196]   Loss 0.012627   Top1 99.531250   Top5 100.000000   BatchTime 0.215862   LR 0.000010   
2022-11-04 01:40:36,247 - INFO  - Training [70][   40/  196]   Loss 0.012420   Top1 99.599609   Top5 100.000000   BatchTime 0.170030   LR 0.000010   
2022-11-04 01:40:38,745 - INFO  - Training [70][   60/  196]   Loss 0.011858   Top1 99.615885   Top5 100.000000   BatchTime 0.154979   LR 0.000010   
2022-11-04 01:40:41,235 - INFO  - Training [70][   80/  196]   Loss 0.012496   Top1 99.580078   Top5 100.000000   BatchTime 0.147361   LR 0.000010   
2022-11-04 01:40:43,723 - INFO  - Training [70][  100/  196]   Loss 0.013099   Top1 99.558594   Top5 100.000000   BatchTime 0.142765   LR 0.000010   
2022-11-04 01:40:46,214 - INFO  - Training [70][  120/  196]   Loss 0.012755   Top1 99.573568   Top5 100.000000   BatchTime 0.139734   LR 0.000010   
2022-11-04 01:40:48,687 - INFO  - Training [70][  140/  196]   Loss 0.012384   Top1 99.595424   Top5 100.000000   BatchTime 0.137432   LR 0.000010   
2022-11-04 01:40:51,163 - INFO  - Training [70][  160/  196]   Loss 0.012270   Top1 99.592285   Top5 100.000000   BatchTime 0.135728   LR 0.000010   
2022-11-04 01:40:53,626 - INFO  - Training [70][  180/  196]   Loss 0.012215   Top1 99.594184   Top5 100.000000   BatchTime 0.134330   LR 0.000010   
2022-11-04 01:40:55,789 - INFO  - ==> Top1: 99.586    Top5: 100.000    Loss: 0.012

2022-11-04 01:40:55,790 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:40:58,623 - INFO  - Validation [70][   20/   40]   Loss 0.470100   Top1 90.839844   Top5 99.394531   BatchTime 0.141608   
2022-11-04 01:40:59,744 - INFO  - Validation [70][   40/   40]   Loss 0.453894   Top1 91.110000   Top5 99.560000   BatchTime 0.098833   
2022-11-04 01:40:59,992 - INFO  - ==> Top1: 91.110    Top5: 99.560    Loss: 0.454

2022-11-04 01:41:00,024 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:41:00,024 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:41:00,025 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:41:00,132 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:41:00,132 - INFO  - >>>>>>>> Epoch  71
2022-11-04 01:41:00,134 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:41:04,484 - INFO  - Training [71][   20/  196]   Loss 0.015272   Top1 99.531250   Top5 100.000000   BatchTime 0.217519   LR 0.000010   
2022-11-04 01:41:06,962 - INFO  - Training [71][   40/  196]   Loss 0.013452   Top1 99.599609   Top5 100.000000   BatchTime 0.170715   LR 0.000010   
2022-11-04 01:41:09,448 - INFO  - Training [71][   60/  196]   Loss 0.012212   Top1 99.635417   Top5 100.000000   BatchTime 0.155241   LR 0.000010   
2022-11-04 01:41:11,915 - INFO  - Training [71][   80/  196]   Loss 0.012044   Top1 99.633789   Top5 100.000000   BatchTime 0.147259   LR 0.000010   
2022-11-04 01:41:14,522 - INFO  - Training [71][  100/  196]   Loss 0.011719   Top1 99.632812   Top5 100.000000   BatchTime 0.143879   LR 0.000010   
2022-11-04 01:41:16,324 - INFO  - Training [71][  120/  196]   Loss 0.012667   Top1 99.609375   Top5 100.000000   BatchTime 0.134920   LR 0.000010   
2022-11-04 01:41:18,377 - INFO  - Training [71][  140/  196]   Loss 0.012702   Top1 99.598214   Top5 100.000000   BatchTime 0.130305   LR 0.000010   
2022-11-04 01:41:20,392 - INFO  - Training [71][  160/  196]   Loss 0.012437   Top1 99.611816   Top5 100.000000   BatchTime 0.126610   LR 0.000010   
2022-11-04 01:41:22,268 - INFO  - Training [71][  180/  196]   Loss 0.012492   Top1 99.607205   Top5 100.000000   BatchTime 0.122966   LR 0.000010   
2022-11-04 01:41:24,100 - INFO  - ==> Top1: 99.590    Top5: 100.000    Loss: 0.013

2022-11-04 01:41:24,101 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:41:26,928 - INFO  - Validation [71][   20/   40]   Loss 0.475168   Top1 90.722656   Top5 99.433594   BatchTime 0.141265   
2022-11-04 01:41:28,030 - INFO  - Validation [71][   40/   40]   Loss 0.459020   Top1 90.890000   Top5 99.570000   BatchTime 0.098176   
2022-11-04 01:41:28,267 - INFO  - ==> Top1: 90.890    Top5: 99.570    Loss: 0.459

2022-11-04 01:41:28,296 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:41:28,297 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:41:28,297 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:41:28,407 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:41:28,408 - INFO  - >>>>>>>> Epoch  72
2022-11-04 01:41:28,409 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:41:32,703 - INFO  - Training [72][   20/  196]   Loss 0.012625   Top1 99.628906   Top5 100.000000   BatchTime 0.214654   LR 0.000010   
2022-11-04 01:41:35,193 - INFO  - Training [72][   40/  196]   Loss 0.012352   Top1 99.580078   Top5 100.000000   BatchTime 0.169580   LR 0.000010   
2022-11-04 01:41:37,670 - INFO  - Training [72][   60/  196]   Loss 0.014047   Top1 99.537760   Top5 100.000000   BatchTime 0.154342   LR 0.000010   
2022-11-04 01:41:40,141 - INFO  - Training [72][   80/  196]   Loss 0.014282   Top1 99.536133   Top5 100.000000   BatchTime 0.146645   LR 0.000010   
2022-11-04 01:41:42,617 - INFO  - Training [72][  100/  196]   Loss 0.014726   Top1 99.511719   Top5 100.000000   BatchTime 0.142074   LR 0.000010   
2022-11-04 01:41:45,102 - INFO  - Training [72][  120/  196]   Loss 0.014168   Top1 99.524740   Top5 100.000000   BatchTime 0.139098   LR 0.000010   
2022-11-04 01:41:47,585 - INFO  - Training [72][  140/  196]   Loss 0.014001   Top1 99.536830   Top5 100.000000   BatchTime 0.136964   LR 0.000010   
2022-11-04 01:41:50,047 - INFO  - Training [72][  160/  196]   Loss 0.014178   Top1 99.531250   Top5 100.000000   BatchTime 0.135233   LR 0.000010   
2022-11-04 01:41:52,508 - INFO  - Training [72][  180/  196]   Loss 0.013981   Top1 99.535590   Top5 100.000000   BatchTime 0.133877   LR 0.000010   
2022-11-04 01:41:54,670 - INFO  - ==> Top1: 99.540    Top5: 100.000    Loss: 0.014

2022-11-04 01:41:54,671 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:41:57,577 - INFO  - Validation [72][   20/   40]   Loss 0.472666   Top1 90.917969   Top5 99.453125   BatchTime 0.145263   
2022-11-04 01:41:58,705 - INFO  - Validation [72][   40/   40]   Loss 0.453520   Top1 90.910000   Top5 99.590000   BatchTime 0.100832   
2022-11-04 01:41:58,957 - INFO  - ==> Top1: 90.910    Top5: 99.590    Loss: 0.454

2022-11-04 01:41:58,993 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:41:58,994 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:41:58,994 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:41:59,108 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:41:59,108 - INFO  - >>>>>>>> Epoch  73
2022-11-04 01:41:59,109 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:42:03,417 - INFO  - Training [73][   20/  196]   Loss 0.011612   Top1 99.570312   Top5 100.000000   BatchTime 0.215363   LR 0.000010   
2022-11-04 01:42:05,880 - INFO  - Training [73][   40/  196]   Loss 0.013433   Top1 99.580078   Top5 100.000000   BatchTime 0.169271   LR 0.000010   
2022-11-04 01:42:07,828 - INFO  - Training [73][   60/  196]   Loss 0.013351   Top1 99.570312   Top5 100.000000   BatchTime 0.145307   LR 0.000010   
2022-11-04 01:42:09,868 - INFO  - Training [73][   80/  196]   Loss 0.014464   Top1 99.521484   Top5 100.000000   BatchTime 0.134478   LR 0.000010   
2022-11-04 01:42:11,926 - INFO  - Training [73][  100/  196]   Loss 0.014879   Top1 99.507812   Top5 100.000000   BatchTime 0.128169   LR 0.000010   
2022-11-04 01:42:13,919 - INFO  - Training [73][  120/  196]   Loss 0.015034   Top1 99.518229   Top5 100.000000   BatchTime 0.123411   LR 0.000010   
2022-11-04 01:42:15,779 - INFO  - Training [73][  140/  196]   Loss 0.014664   Top1 99.534040   Top5 100.000000   BatchTime 0.119064   LR 0.000010   
2022-11-04 01:42:18,251 - INFO  - Training [73][  160/  196]   Loss 0.014102   Top1 99.560547   Top5 100.000000   BatchTime 0.119633   LR 0.000010   
2022-11-04 01:42:20,723 - INFO  - Training [73][  180/  196]   Loss 0.013444   Top1 99.585503   Top5 100.000000   BatchTime 0.120076   LR 0.000010   
2022-11-04 01:42:22,870 - INFO  - ==> Top1: 99.566    Top5: 100.000    Loss: 0.014

2022-11-04 01:42:22,870 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:42:25,698 - INFO  - Validation [73][   20/   40]   Loss 0.477458   Top1 90.664062   Top5 99.375000   BatchTime 0.141309   
2022-11-04 01:42:26,828 - INFO  - Validation [73][   40/   40]   Loss 0.461009   Top1 90.930000   Top5 99.540000   BatchTime 0.098913   
2022-11-04 01:42:27,066 - INFO  - ==> Top1: 90.930    Top5: 99.540    Loss: 0.461

2022-11-04 01:42:27,105 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:42:27,105 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:42:27,105 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:42:27,212 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:42:27,213 - INFO  - >>>>>>>> Epoch  74
2022-11-04 01:42:27,214 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:42:31,541 - INFO  - Training [74][   20/  196]   Loss 0.013757   Top1 99.648438   Top5 100.000000   BatchTime 0.216338   LR 0.000010   
2022-11-04 01:42:34,018 - INFO  - Training [74][   40/  196]   Loss 0.012842   Top1 99.687500   Top5 100.000000   BatchTime 0.170093   LR 0.000010   
2022-11-04 01:42:36,503 - INFO  - Training [74][   60/  196]   Loss 0.012229   Top1 99.674479   Top5 100.000000   BatchTime 0.154812   LR 0.000010   
2022-11-04 01:42:38,983 - INFO  - Training [74][   80/  196]   Loss 0.011184   Top1 99.707031   Top5 100.000000   BatchTime 0.147103   LR 0.000010   
2022-11-04 01:42:41,456 - INFO  - Training [74][  100/  196]   Loss 0.012069   Top1 99.683594   Top5 100.000000   BatchTime 0.142421   LR 0.000010   
2022-11-04 01:42:43,937 - INFO  - Training [74][  120/  196]   Loss 0.011996   Top1 99.677734   Top5 100.000000   BatchTime 0.139354   LR 0.000010   
2022-11-04 01:42:46,412 - INFO  - Training [74][  140/  196]   Loss 0.012156   Top1 99.659598   Top5 100.000000   BatchTime 0.137124   LR 0.000010   
2022-11-04 01:42:48,874 - INFO  - Training [74][  160/  196]   Loss 0.012310   Top1 99.628906   Top5 100.000000   BatchTime 0.135371   LR 0.000010   
2022-11-04 01:42:51,337 - INFO  - Training [74][  180/  196]   Loss 0.012360   Top1 99.626736   Top5 100.000000   BatchTime 0.134015   LR 0.000010   
2022-11-04 01:42:53,499 - INFO  - ==> Top1: 99.618    Top5: 100.000    Loss: 0.013

2022-11-04 01:42:53,499 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:42:56,342 - INFO  - Validation [74][   20/   40]   Loss 0.467562   Top1 90.996094   Top5 99.414062   BatchTime 0.142028   
2022-11-04 01:42:57,462 - INFO  - Validation [74][   40/   40]   Loss 0.453970   Top1 91.030000   Top5 99.570000   BatchTime 0.099017   
2022-11-04 01:42:57,716 - INFO  - ==> Top1: 91.030    Top5: 99.570    Loss: 0.454

2022-11-04 01:42:57,759 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:42:57,759 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:42:57,759 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:42:57,857 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:42:57,857 - INFO  - >>>>>>>> Epoch  75
2022-11-04 01:42:57,858 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:43:01,850 - INFO  - Training [75][   20/  196]   Loss 0.014632   Top1 99.531250   Top5 100.000000   BatchTime 0.199556   LR 0.000010   
2022-11-04 01:43:03,905 - INFO  - Training [75][   40/  196]   Loss 0.014150   Top1 99.511719   Top5 100.000000   BatchTime 0.151146   LR 0.000010   
2022-11-04 01:43:05,976 - INFO  - Training [75][   60/  196]   Loss 0.014277   Top1 99.492188   Top5 100.000000   BatchTime 0.135286   LR 0.000010   
2022-11-04 01:43:07,726 - INFO  - Training [75][   80/  196]   Loss 0.013391   Top1 99.536133   Top5 100.000000   BatchTime 0.123333   LR 0.000010   
2022-11-04 01:43:10,112 - INFO  - Training [75][  100/  196]   Loss 0.013124   Top1 99.535156   Top5 100.000000   BatchTime 0.122530   LR 0.000010   
2022-11-04 01:43:12,597 - INFO  - Training [75][  120/  196]   Loss 0.012675   Top1 99.560547   Top5 100.000000   BatchTime 0.122814   LR 0.000010   
2022-11-04 01:43:15,168 - INFO  - Training [75][  140/  196]   Loss 0.012842   Top1 99.556362   Top5 100.000000   BatchTime 0.123633   LR 0.000010   
2022-11-04 01:43:17,639 - INFO  - Training [75][  160/  196]   Loss 0.012744   Top1 99.572754   Top5 100.000000   BatchTime 0.123626   LR 0.000010   
2022-11-04 01:43:20,114 - INFO  - Training [75][  180/  196]   Loss 0.012664   Top1 99.565972   Top5 100.000000   BatchTime 0.123635   LR 0.000010   
2022-11-04 01:43:22,286 - INFO  - ==> Top1: 99.566    Top5: 100.000    Loss: 0.013

2022-11-04 01:43:22,287 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:43:25,143 - INFO  - Validation [75][   20/   40]   Loss 0.471413   Top1 90.859375   Top5 99.492188   BatchTime 0.142763   
2022-11-04 01:43:26,253 - INFO  - Validation [75][   40/   40]   Loss 0.457189   Top1 90.990000   Top5 99.600000   BatchTime 0.099138   
2022-11-04 01:43:26,488 - INFO  - ==> Top1: 90.990    Top5: 99.600    Loss: 0.457

2022-11-04 01:43:26,532 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:43:26,533 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:43:26,533 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:43:26,638 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:43:26,638 - INFO  - >>>>>>>> Epoch  76
2022-11-04 01:43:26,640 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:43:30,938 - INFO  - Training [76][   20/  196]   Loss 0.014349   Top1 99.550781   Top5 100.000000   BatchTime 0.214907   LR 0.000010   
2022-11-04 01:43:33,420 - INFO  - Training [76][   40/  196]   Loss 0.013025   Top1 99.589844   Top5 100.000000   BatchTime 0.169490   LR 0.000010   
2022-11-04 01:43:35,916 - INFO  - Training [76][   60/  196]   Loss 0.011894   Top1 99.628906   Top5 100.000000   BatchTime 0.154604   LR 0.000010   
2022-11-04 01:43:38,394 - INFO  - Training [76][   80/  196]   Loss 0.012073   Top1 99.624023   Top5 100.000000   BatchTime 0.146926   LR 0.000010   
2022-11-04 01:43:40,878 - INFO  - Training [76][  100/  196]   Loss 0.011983   Top1 99.625000   Top5 100.000000   BatchTime 0.142374   LR 0.000010   
2022-11-04 01:43:43,372 - INFO  - Training [76][  120/  196]   Loss 0.012477   Top1 99.586589   Top5 100.000000   BatchTime 0.139433   LR 0.000010   
2022-11-04 01:43:45,844 - INFO  - Training [76][  140/  196]   Loss 0.012089   Top1 99.620536   Top5 100.000000   BatchTime 0.137167   LR 0.000010   
2022-11-04 01:43:48,303 - INFO  - Training [76][  160/  196]   Loss 0.012689   Top1 99.609375   Top5 100.000000   BatchTime 0.135393   LR 0.000010   
2022-11-04 01:43:50,755 - INFO  - Training [76][  180/  196]   Loss 0.012619   Top1 99.615885   Top5 100.000000   BatchTime 0.133971   LR 0.000010   
2022-11-04 01:43:52,911 - INFO  - ==> Top1: 99.608    Top5: 100.000    Loss: 0.013

2022-11-04 01:43:52,912 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:43:55,471 - INFO  - Validation [76][   20/   40]   Loss 0.471384   Top1 90.878906   Top5 99.375000   BatchTime 0.127876   
2022-11-04 01:43:56,333 - INFO  - Validation [76][   40/   40]   Loss 0.456607   Top1 90.960000   Top5 99.540000   BatchTime 0.085493   
2022-11-04 01:43:56,576 - INFO  - ==> Top1: 90.960    Top5: 99.540    Loss: 0.457

2022-11-04 01:43:56,606 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:43:56,607 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:43:56,607 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:43:56,699 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:43:56,699 - INFO  - >>>>>>>> Epoch  77
2022-11-04 01:43:56,701 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:44:00,609 - INFO  - Training [77][   20/  196]   Loss 0.011230   Top1 99.550781   Top5 100.000000   BatchTime 0.195420   LR 0.000010   
2022-11-04 01:44:03,102 - INFO  - Training [77][   40/  196]   Loss 0.012052   Top1 99.580078   Top5 100.000000   BatchTime 0.160027   LR 0.000010   
2022-11-04 01:44:05,594 - INFO  - Training [77][   60/  196]   Loss 0.011790   Top1 99.596354   Top5 100.000000   BatchTime 0.148217   LR 0.000010   
2022-11-04 01:44:08,067 - INFO  - Training [77][   80/  196]   Loss 0.011745   Top1 99.614258   Top5 100.000000   BatchTime 0.142079   LR 0.000010   
2022-11-04 01:44:10,539 - INFO  - Training [77][  100/  196]   Loss 0.012199   Top1 99.601562   Top5 100.000000   BatchTime 0.138375   LR 0.000010   
2022-11-04 01:44:13,022 - INFO  - Training [77][  120/  196]   Loss 0.012424   Top1 99.593099   Top5 100.000000   BatchTime 0.136010   LR 0.000010   
2022-11-04 01:44:15,501 - INFO  - Training [77][  140/  196]   Loss 0.012672   Top1 99.584263   Top5 100.000000   BatchTime 0.134287   LR 0.000010   
2022-11-04 01:44:17,964 - INFO  - Training [77][  160/  196]   Loss 0.013022   Top1 99.572754   Top5 100.000000   BatchTime 0.132891   LR 0.000010   
2022-11-04 01:44:20,428 - INFO  - Training [77][  180/  196]   Loss 0.013023   Top1 99.585503   Top5 100.000000   BatchTime 0.131817   LR 0.000010   
2022-11-04 01:44:22,584 - INFO  - ==> Top1: 99.598    Top5: 100.000    Loss: 0.013

2022-11-04 01:44:22,584 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:44:25,398 - INFO  - Validation [77][   20/   40]   Loss 0.472604   Top1 90.683594   Top5 99.414062   BatchTime 0.140629   
2022-11-04 01:44:26,549 - INFO  - Validation [77][   40/   40]   Loss 0.459682   Top1 90.980000   Top5 99.580000   BatchTime 0.099093   
2022-11-04 01:44:26,799 - INFO  - ==> Top1: 90.980    Top5: 99.580    Loss: 0.460

2022-11-04 01:44:26,833 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:44:26,833 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:44:26,834 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:44:26,937 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:44:26,938 - INFO  - >>>>>>>> Epoch  78
2022-11-04 01:44:26,939 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:44:31,292 - INFO  - Training [78][   20/  196]   Loss 0.013107   Top1 99.628906   Top5 100.000000   BatchTime 0.217596   LR 0.000010   
2022-11-04 01:44:33,759 - INFO  - Training [78][   40/  196]   Loss 0.012786   Top1 99.619141   Top5 100.000000   BatchTime 0.170488   LR 0.000010   
2022-11-04 01:44:36,235 - INFO  - Training [78][   60/  196]   Loss 0.012456   Top1 99.622396   Top5 100.000000   BatchTime 0.154930   LR 0.000010   
2022-11-04 01:44:38,704 - INFO  - Training [78][   80/  196]   Loss 0.012979   Top1 99.599609   Top5 100.000000   BatchTime 0.147057   LR 0.000010   
2022-11-04 01:44:41,165 - INFO  - Training [78][  100/  196]   Loss 0.012626   Top1 99.625000   Top5 100.000000   BatchTime 0.142248   LR 0.000010   
2022-11-04 01:44:43,640 - INFO  - Training [78][  120/  196]   Loss 0.012052   Top1 99.648438   Top5 100.000000   BatchTime 0.139170   LR 0.000010   
2022-11-04 01:44:46,091 - INFO  - Training [78][  140/  196]   Loss 0.012318   Top1 99.626116   Top5 100.000000   BatchTime 0.136795   LR 0.000010   
2022-11-04 01:44:47,879 - INFO  - Training [78][  160/  196]   Loss 0.012356   Top1 99.616699   Top5 100.000000   BatchTime 0.130870   LR 0.000010   
2022-11-04 01:44:49,963 - INFO  - Training [78][  180/  196]   Loss 0.013260   Top1 99.587674   Top5 99.997830   BatchTime 0.127907   LR 0.000010   
2022-11-04 01:44:51,797 - INFO  - ==> Top1: 99.598    Top5: 99.998    Loss: 0.013

2022-11-04 01:44:51,798 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:44:54,360 - INFO  - Validation [78][   20/   40]   Loss 0.466565   Top1 90.761719   Top5 99.433594   BatchTime 0.127992   
2022-11-04 01:44:55,380 - INFO  - Validation [78][   40/   40]   Loss 0.453328   Top1 90.900000   Top5 99.590000   BatchTime 0.089513   
2022-11-04 01:44:55,625 - INFO  - ==> Top1: 90.900    Top5: 99.590    Loss: 0.453

2022-11-04 01:44:55,654 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:44:55,654 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:44:55,654 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:44:55,763 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:44:55,764 - INFO  - >>>>>>>> Epoch  79
2022-11-04 01:44:55,765 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 01:45:00,120 - INFO  - Training [79][   20/  196]   Loss 0.013295   Top1 99.570312   Top5 100.000000   BatchTime 0.217724   LR 0.000010   
2022-11-04 01:45:02,606 - INFO  - Training [79][   40/  196]   Loss 0.012862   Top1 99.599609   Top5 100.000000   BatchTime 0.171012   LR 0.000010   
2022-11-04 01:45:05,104 - INFO  - Training [79][   60/  196]   Loss 0.013640   Top1 99.609375   Top5 100.000000   BatchTime 0.155633   LR 0.000010   
2022-11-04 01:45:07,574 - INFO  - Training [79][   80/  196]   Loss 0.013540   Top1 99.609375   Top5 100.000000   BatchTime 0.147605   LR 0.000010   
2022-11-04 01:45:10,065 - INFO  - Training [79][  100/  196]   Loss 0.013073   Top1 99.621094   Top5 100.000000   BatchTime 0.142989   LR 0.000010   
2022-11-04 01:45:12,546 - INFO  - Training [79][  120/  196]   Loss 0.013069   Top1 99.615885   Top5 100.000000   BatchTime 0.139833   LR 0.000010   
2022-11-04 01:45:15,112 - INFO  - Training [79][  140/  196]   Loss 0.013416   Top1 99.601004   Top5 99.997210   BatchTime 0.138188   LR 0.000010   
2022-11-04 01:45:17,606 - INFO  - Training [79][  160/  196]   Loss 0.013033   Top1 99.621582   Top5 99.997559   BatchTime 0.136502   LR 0.000010   
2022-11-04 01:45:20,028 - INFO  - Training [79][  180/  196]   Loss 0.013113   Top1 99.607205   Top5 99.997830   BatchTime 0.134789   LR 0.000010   
2022-11-04 01:45:22,189 - INFO  - ==> Top1: 99.614    Top5: 99.998    Loss: 0.013

2022-11-04 01:45:22,190 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:45:25,043 - INFO  - Validation [79][   20/   40]   Loss 0.468417   Top1 91.015625   Top5 99.394531   BatchTime 0.142558   
2022-11-04 01:45:26,158 - INFO  - Validation [79][   40/   40]   Loss 0.457222   Top1 90.920000   Top5 99.560000   BatchTime 0.099165   
2022-11-04 01:45:26,397 - INFO  - ==> Top1: 90.920    Top5: 99.560    Loss: 0.457

2022-11-04 01:45:26,437 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 91.180   Top5: 99.520] Sparsity : 0.827
2022-11-04 01:45:26,438 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.160   Top5: 99.550] Sparsity : 0.827
2022-11-04 01:45:26,438 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 91.150   Top5: 99.570] Sparsity : 0.827
2022-11-04 01:45:26,547 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_20221104-010522/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch80_checkpoint.pth.tar

2022-11-04 01:45:26,547 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-04 01:45:26,547 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 01:45:29,353 - INFO  - Validation [   20/   40]   Loss 0.468417   Top1 91.015625   Top5 99.394531   BatchTime 0.140246   
2022-11-04 01:45:30,455 - INFO  - Validation [   40/   40]   Loss 0.457222   Top1 90.920000   Top5 99.560000   BatchTime 0.097678   
2022-11-04 01:45:30,687 - INFO  - ==> Top1: 90.920    Top5: 99.560    Loss: 0.457

2022-11-04 01:45:30,728 - INFO  - Program completed successfully ... exiting ...
2022-11-04 01:45:30,729 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
