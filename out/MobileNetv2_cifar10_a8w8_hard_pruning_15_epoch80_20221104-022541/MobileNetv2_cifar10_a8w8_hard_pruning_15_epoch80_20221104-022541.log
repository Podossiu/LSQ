2022-11-04 02:25:41,538 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541.log
2022-11-04 02:25:42,573 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/tb_runs
2022-11-04 02:25:43,687 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-04 02:25:43,730 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
2022-11-04 02:25:45,978 - INFO  - Inserted quantizers into the original model
2022-11-04 02:25:47,879 - INFO  - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
2022-11-04 02:25:47,880 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-04 02:25:47,880 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-04 02:25:47,881 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-04 02:25:47,881 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:25:51,818 - INFO  - Validation [   20/   40]   Loss 0.403770   Top1 89.003906   Top5 99.453125   BatchTime 0.196851   
2022-11-04 02:25:53,057 - INFO  - Validation [   40/   40]   Loss 0.389260   Top1 89.200000   Top5 99.600000   BatchTime 0.129403   
2022-11-04 02:25:53,226 - INFO  - ==> Top1: 89.200    Top5: 99.600    Loss: 0.389

2022-11-04 02:25:53,263 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:25:53,264 - INFO  - >>>>>>>> Epoch   0
2022-11-04 02:25:53,264 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:25:58,145 - INFO  - Training [0][   20/  196]   Loss 0.086413   Top1 97.031250   Top5 100.000000   BatchTime 0.244044   LR 0.010000   
2022-11-04 02:26:00,601 - INFO  - Training [0][   40/  196]   Loss 0.088526   Top1 96.835938   Top5 99.990234   BatchTime 0.183417   LR 0.010000   
2022-11-04 02:26:02,780 - INFO  - Training [0][   60/  196]   Loss 0.085977   Top1 96.940104   Top5 99.993490   BatchTime 0.158596   LR 0.010000   
2022-11-04 02:26:04,684 - INFO  - Training [0][   80/  196]   Loss 0.084929   Top1 96.997070   Top5 99.995117   BatchTime 0.142743   LR 0.010000   
2022-11-04 02:26:06,716 - INFO  - Training [0][  100/  196]   Loss 0.085184   Top1 96.968750   Top5 99.996094   BatchTime 0.134512   LR 0.010000   
2022-11-04 02:26:08,762 - INFO  - Training [0][  120/  196]   Loss 0.084374   Top1 97.037760   Top5 99.993490   BatchTime 0.129144   LR 0.010000   
2022-11-04 02:26:10,597 - INFO  - Training [0][  140/  196]   Loss 0.085021   Top1 97.011719   Top5 99.991629   BatchTime 0.123804   LR 0.010000   
2022-11-04 02:26:12,903 - INFO  - Training [0][  160/  196]   Loss 0.087064   Top1 96.921387   Top5 99.990234   BatchTime 0.122739   LR 0.010000   
2022-11-04 02:26:15,366 - INFO  - Training [0][  180/  196]   Loss 0.088273   Top1 96.864149   Top5 99.991319   BatchTime 0.122784   LR 0.010000   
2022-11-04 02:26:17,903 - INFO  - ==> Top1: 96.846    Top5: 99.992    Loss: 0.089

2022-11-04 02:26:17,904 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:26:20,821 - INFO  - Validation [0][   20/   40]   Loss 0.418054   Top1 88.945312   Top5 99.570312   BatchTime 0.145781   
2022-11-04 02:26:21,952 - INFO  - Validation [0][   40/   40]   Loss 0.411619   Top1 89.100000   Top5 99.580000   BatchTime 0.101159   
2022-11-04 02:26:22,202 - INFO  - ==> Top1: 89.100    Top5: 99.580    Loss: 0.412

2022-11-04 02:26:22,243 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:26:22,243 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 89.100   Top5: 99.580] Sparsity : 0.888
2022-11-04 02:26:22,275 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:26:22,275 - INFO  - >>>>>>>> Epoch   1
2022-11-04 02:26:22,276 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:26:26,650 - INFO  - Training [1][   20/  196]   Loss 0.080844   Top1 96.992188   Top5 99.980469   BatchTime 0.218674   LR 0.010000   
2022-11-04 02:26:29,127 - INFO  - Training [1][   40/  196]   Loss 0.082513   Top1 97.041016   Top5 99.990234   BatchTime 0.171256   LR 0.010000   
2022-11-04 02:26:31,596 - INFO  - Training [1][   60/  196]   Loss 0.085548   Top1 97.011719   Top5 99.993490   BatchTime 0.155324   LR 0.010000   
2022-11-04 02:26:34,069 - INFO  - Training [1][   80/  196]   Loss 0.085441   Top1 97.041016   Top5 99.980469   BatchTime 0.147407   LR 0.010000   
2022-11-04 02:26:36,539 - INFO  - Training [1][  100/  196]   Loss 0.084878   Top1 97.054688   Top5 99.980469   BatchTime 0.142627   LR 0.010000   
2022-11-04 02:26:39,140 - INFO  - Training [1][  120/  196]   Loss 0.085358   Top1 96.995443   Top5 99.983724   BatchTime 0.140529   LR 0.010000   
2022-11-04 02:26:41,623 - INFO  - Training [1][  140/  196]   Loss 0.086360   Top1 96.955915   Top5 99.983259   BatchTime 0.138185   LR 0.010000   
2022-11-04 02:26:44,018 - INFO  - Training [1][  160/  196]   Loss 0.085622   Top1 96.982422   Top5 99.985352   BatchTime 0.135883   LR 0.010000   
2022-11-04 02:26:46,506 - INFO  - Training [1][  180/  196]   Loss 0.086073   Top1 96.959635   Top5 99.986979   BatchTime 0.134607   LR 0.010000   
2022-11-04 02:26:48,679 - INFO  - ==> Top1: 96.944    Top5: 99.988    Loss: 0.086

2022-11-04 02:26:48,680 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:26:51,542 - INFO  - Validation [1][   20/   40]   Loss 0.421002   Top1 88.808594   Top5 99.589844   BatchTime 0.143011   
2022-11-04 02:26:52,684 - INFO  - Validation [1][   40/   40]   Loss 0.406165   Top1 89.170000   Top5 99.620000   BatchTime 0.100063   
2022-11-04 02:26:52,937 - INFO  - ==> Top1: 89.170    Top5: 99.620    Loss: 0.406

2022-11-04 02:26:52,987 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:26:52,987 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 89.170   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:26:52,988 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 89.100   Top5: 99.580] Sparsity : 0.888
2022-11-04 02:26:53,226 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:26:53,227 - INFO  - >>>>>>>> Epoch   2
2022-11-04 02:26:53,228 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:26:57,205 - INFO  - Training [2][   20/  196]   Loss 0.075325   Top1 97.480469   Top5 100.000000   BatchTime 0.198840   LR 0.010000   
2022-11-04 02:26:59,245 - INFO  - Training [2][   40/  196]   Loss 0.078276   Top1 97.099609   Top5 100.000000   BatchTime 0.150425   LR 0.010000   
2022-11-04 02:27:01,280 - INFO  - Training [2][   60/  196]   Loss 0.076813   Top1 97.187500   Top5 100.000000   BatchTime 0.134188   LR 0.010000   
2022-11-04 02:27:03,091 - INFO  - Training [2][   80/  196]   Loss 0.080436   Top1 97.089844   Top5 99.995117   BatchTime 0.123276   LR 0.010000   
2022-11-04 02:27:05,460 - INFO  - Training [2][  100/  196]   Loss 0.079418   Top1 97.164062   Top5 99.996094   BatchTime 0.122312   LR 0.010000   
2022-11-04 02:27:07,955 - INFO  - Training [2][  120/  196]   Loss 0.079732   Top1 97.180990   Top5 99.993490   BatchTime 0.122721   LR 0.010000   
2022-11-04 02:27:10,424 - INFO  - Training [2][  140/  196]   Loss 0.082306   Top1 97.059152   Top5 99.994420   BatchTime 0.122821   LR 0.010000   
2022-11-04 02:27:12,889 - INFO  - Training [2][  160/  196]   Loss 0.084289   Top1 96.958008   Top5 99.995117   BatchTime 0.122876   LR 0.010000   
2022-11-04 02:27:15,351 - INFO  - Training [2][  180/  196]   Loss 0.084388   Top1 96.970486   Top5 99.993490   BatchTime 0.122901   LR 0.010000   
2022-11-04 02:27:17,519 - INFO  - ==> Top1: 96.966    Top5: 99.994    Loss: 0.085

2022-11-04 02:27:17,520 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:27:20,407 - INFO  - Validation [2][   20/   40]   Loss 0.410674   Top1 89.589844   Top5 99.511719   BatchTime 0.144239   
2022-11-04 02:27:21,523 - INFO  - Validation [2][   40/   40]   Loss 0.404980   Top1 89.600000   Top5 99.580000   BatchTime 0.100035   
2022-11-04 02:27:21,772 - INFO  - ==> Top1: 89.600    Top5: 99.580    Loss: 0.405

2022-11-04 02:27:21,805 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 89.600   Top5: 99.580] Sparsity : 0.888
2022-11-04 02:27:21,806 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:27:21,806 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 89.170   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:27:21,942 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:27:22,004 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:27:22,004 - INFO  - >>>>>>>> Epoch   3
2022-11-04 02:27:22,005 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:27:26,414 - INFO  - Training [3][   20/  196]   Loss 0.072102   Top1 97.382812   Top5 99.980469   BatchTime 0.220445   LR 0.010000   
2022-11-04 02:27:28,905 - INFO  - Training [3][   40/  196]   Loss 0.075279   Top1 97.392578   Top5 99.980469   BatchTime 0.172501   LR 0.010000   
2022-11-04 02:27:31,374 - INFO  - Training [3][   60/  196]   Loss 0.078542   Top1 97.317708   Top5 99.986979   BatchTime 0.156142   LR 0.010000   
2022-11-04 02:27:33,853 - INFO  - Training [3][   80/  196]   Loss 0.079897   Top1 97.231445   Top5 99.980469   BatchTime 0.148090   LR 0.010000   
2022-11-04 02:27:36,321 - INFO  - Training [3][  100/  196]   Loss 0.080749   Top1 97.210938   Top5 99.972656   BatchTime 0.143157   LR 0.010000   
2022-11-04 02:27:38,788 - INFO  - Training [3][  120/  196]   Loss 0.082807   Top1 97.109375   Top5 99.977214   BatchTime 0.139854   LR 0.010000   
2022-11-04 02:27:41,248 - INFO  - Training [3][  140/  196]   Loss 0.082424   Top1 97.109375   Top5 99.974888   BatchTime 0.137445   LR 0.010000   
2022-11-04 02:27:43,696 - INFO  - Training [3][  160/  196]   Loss 0.083002   Top1 97.089844   Top5 99.975586   BatchTime 0.135563   LR 0.010000   
2022-11-04 02:27:46,141 - INFO  - Training [3][  180/  196]   Loss 0.083327   Top1 97.050781   Top5 99.976128   BatchTime 0.134083   LR 0.010000   
2022-11-04 02:27:48,289 - INFO  - ==> Top1: 97.038    Top5: 99.976    Loss: 0.083

2022-11-04 02:27:48,290 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:27:50,944 - INFO  - Validation [3][   20/   40]   Loss 0.414420   Top1 89.570312   Top5 99.433594   BatchTime 0.132667   
2022-11-04 02:27:51,867 - INFO  - Validation [3][   40/   40]   Loss 0.409284   Top1 89.620000   Top5 99.480000   BatchTime 0.089413   
2022-11-04 02:27:52,133 - INFO  - ==> Top1: 89.620    Top5: 99.480    Loss: 0.409

2022-11-04 02:27:52,167 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 89.620   Top5: 99.480] Sparsity : 0.888
2022-11-04 02:27:52,168 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 89.600   Top5: 99.580] Sparsity : 0.888
2022-11-04 02:27:52,168 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 89.200   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:27:52,365 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:27:52,549 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:27:52,550 - INFO  - >>>>>>>> Epoch   4
2022-11-04 02:27:52,551 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:27:56,522 - INFO  - Training [4][   20/  196]   Loss 0.085244   Top1 96.796875   Top5 100.000000   BatchTime 0.198519   LR 0.010000   
2022-11-04 02:27:58,580 - INFO  - Training [4][   40/  196]   Loss 0.077827   Top1 97.099609   Top5 100.000000   BatchTime 0.150710   LR 0.010000   
2022-11-04 02:28:00,637 - INFO  - Training [4][   60/  196]   Loss 0.078619   Top1 97.089844   Top5 99.993490   BatchTime 0.134753   LR 0.010000   
2022-11-04 02:28:02,442 - INFO  - Training [4][   80/  196]   Loss 0.079419   Top1 97.089844   Top5 99.995117   BatchTime 0.123634   LR 0.010000   
2022-11-04 02:28:04,139 - INFO  - Training [4][  100/  196]   Loss 0.080401   Top1 97.085938   Top5 99.992188   BatchTime 0.115870   LR 0.010000   
2022-11-04 02:28:05,798 - INFO  - Training [4][  120/  196]   Loss 0.080793   Top1 97.073568   Top5 99.993490   BatchTime 0.110382   LR 0.010000   
2022-11-04 02:28:07,466 - INFO  - Training [4][  140/  196]   Loss 0.080733   Top1 97.114955   Top5 99.994420   BatchTime 0.106532   LR 0.010000   
2022-11-04 02:28:09,166 - INFO  - Training [4][  160/  196]   Loss 0.080939   Top1 97.106934   Top5 99.995117   BatchTime 0.103841   LR 0.010000   
2022-11-04 02:28:10,874 - INFO  - Training [4][  180/  196]   Loss 0.081536   Top1 97.042101   Top5 99.995660   BatchTime 0.101791   LR 0.010000   
2022-11-04 02:28:12,485 - INFO  - ==> Top1: 97.058    Top5: 99.996    Loss: 0.081

2022-11-04 02:28:12,485 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:28:15,028 - INFO  - Validation [4][   20/   40]   Loss 0.405439   Top1 89.726562   Top5 99.570312   BatchTime 0.127019   
2022-11-04 02:28:15,750 - INFO  - Validation [4][   40/   40]   Loss 0.397967   Top1 89.720000   Top5 99.620000   BatchTime 0.081568   
2022-11-04 02:28:16,013 - INFO  - ==> Top1: 89.720    Top5: 99.620    Loss: 0.398

2022-11-04 02:28:16,040 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:28:16,040 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 89.620   Top5: 99.480] Sparsity : 0.888
2022-11-04 02:28:16,040 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 89.600   Top5: 99.580] Sparsity : 0.888
2022-11-04 02:28:16,236 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:28:16,421 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:28:16,421 - INFO  - >>>>>>>> Epoch   5
2022-11-04 02:28:16,423 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:28:20,329 - INFO  - Training [5][   20/  196]   Loss 0.070819   Top1 97.460938   Top5 99.980469   BatchTime 0.195312   LR 0.010000   
2022-11-04 02:28:22,287 - INFO  - Training [5][   40/  196]   Loss 0.072699   Top1 97.402344   Top5 99.990234   BatchTime 0.146607   LR 0.010000   
2022-11-04 02:28:24,333 - INFO  - Training [5][   60/  196]   Loss 0.072001   Top1 97.415365   Top5 99.993490   BatchTime 0.131829   LR 0.010000   
2022-11-04 02:28:26,370 - INFO  - Training [5][   80/  196]   Loss 0.071551   Top1 97.465820   Top5 99.995117   BatchTime 0.124340   LR 0.010000   
2022-11-04 02:28:28,300 - INFO  - Training [5][  100/  196]   Loss 0.073336   Top1 97.414062   Top5 99.996094   BatchTime 0.118769   LR 0.010000   
2022-11-04 02:28:30,679 - INFO  - Training [5][  120/  196]   Loss 0.073957   Top1 97.340495   Top5 99.996745   BatchTime 0.118795   LR 0.010000   
2022-11-04 02:28:33,149 - INFO  - Training [5][  140/  196]   Loss 0.075230   Top1 97.307478   Top5 99.994420   BatchTime 0.119467   LR 0.010000   
2022-11-04 02:28:35,624 - INFO  - Training [5][  160/  196]   Loss 0.074325   Top1 97.324219   Top5 99.992676   BatchTime 0.120005   LR 0.010000   
2022-11-04 02:28:38,083 - INFO  - Training [5][  180/  196]   Loss 0.075088   Top1 97.289497   Top5 99.993490   BatchTime 0.120333   LR 0.010000   
2022-11-04 02:28:40,257 - INFO  - ==> Top1: 97.270    Top5: 99.992    Loss: 0.076

2022-11-04 02:28:40,258 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:28:43,171 - INFO  - Validation [5][   20/   40]   Loss 0.399813   Top1 89.785156   Top5 99.492188   BatchTime 0.145575   
2022-11-04 02:28:44,297 - INFO  - Validation [5][   40/   40]   Loss 0.391039   Top1 89.750000   Top5 99.590000   BatchTime 0.100957   
2022-11-04 02:28:44,555 - INFO  - ==> Top1: 89.750    Top5: 99.590    Loss: 0.391

2022-11-04 02:28:44,591 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:28:44,592 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:28:44,592 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 89.620   Top5: 99.480] Sparsity : 0.888
2022-11-04 02:28:44,773 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:28:44,940 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:28:44,940 - INFO  - >>>>>>>> Epoch   6
2022-11-04 02:28:44,941 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:28:49,347 - INFO  - Training [6][   20/  196]   Loss 0.074017   Top1 97.324219   Top5 100.000000   BatchTime 0.220281   LR 0.010000   
2022-11-04 02:28:51,822 - INFO  - Training [6][   40/  196]   Loss 0.073041   Top1 97.431641   Top5 99.990234   BatchTime 0.172007   LR 0.010000   
2022-11-04 02:28:54,302 - INFO  - Training [6][   60/  196]   Loss 0.073628   Top1 97.421875   Top5 99.993490   BatchTime 0.156003   LR 0.010000   
2022-11-04 02:28:56,779 - INFO  - Training [6][   80/  196]   Loss 0.071406   Top1 97.475586   Top5 99.995117   BatchTime 0.147966   LR 0.010000   
2022-11-04 02:28:59,253 - INFO  - Training [6][  100/  196]   Loss 0.072223   Top1 97.453125   Top5 99.992188   BatchTime 0.143116   LR 0.010000   
2022-11-04 02:29:01,725 - INFO  - Training [6][  120/  196]   Loss 0.071906   Top1 97.480469   Top5 99.993490   BatchTime 0.139860   LR 0.010000   
2022-11-04 02:29:04,198 - INFO  - Training [6][  140/  196]   Loss 0.072647   Top1 97.435826   Top5 99.991629   BatchTime 0.137549   LR 0.010000   
2022-11-04 02:29:06,657 - INFO  - Training [6][  160/  196]   Loss 0.072366   Top1 97.438965   Top5 99.992676   BatchTime 0.135723   LR 0.010000   
2022-11-04 02:29:09,105 - INFO  - Training [6][  180/  196]   Loss 0.072981   Top1 97.421875   Top5 99.993490   BatchTime 0.134239   LR 0.010000   
2022-11-04 02:29:11,269 - INFO  - ==> Top1: 97.424    Top5: 99.994    Loss: 0.073

2022-11-04 02:29:11,270 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:29:14,028 - INFO  - Validation [6][   20/   40]   Loss 0.408951   Top1 90.039062   Top5 99.570312   BatchTime 0.137866   
2022-11-04 02:29:14,744 - INFO  - Validation [6][   40/   40]   Loss 0.403155   Top1 89.820000   Top5 99.570000   BatchTime 0.086832   
2022-11-04 02:29:14,995 - INFO  - ==> Top1: 89.820    Top5: 99.570    Loss: 0.403

2022-11-04 02:29:15,020 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:29:15,021 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:29:15,021 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:29:15,188 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:29:15,366 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:29:15,366 - INFO  - >>>>>>>> Epoch   7
2022-11-04 02:29:15,367 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:29:19,432 - INFO  - Training [7][   20/  196]   Loss 0.063842   Top1 97.578125   Top5 100.000000   BatchTime 0.203230   LR 0.010000   
2022-11-04 02:29:21,341 - INFO  - Training [7][   40/  196]   Loss 0.065586   Top1 97.626953   Top5 99.990234   BatchTime 0.149349   LR 0.010000   
2022-11-04 02:29:23,734 - INFO  - Training [7][   60/  196]   Loss 0.067372   Top1 97.604167   Top5 99.993490   BatchTime 0.139442   LR 0.010000   
2022-11-04 02:29:26,225 - INFO  - Training [7][   80/  196]   Loss 0.068610   Top1 97.524414   Top5 99.995117   BatchTime 0.135719   LR 0.010000   
2022-11-04 02:29:28,706 - INFO  - Training [7][  100/  196]   Loss 0.069709   Top1 97.460938   Top5 99.996094   BatchTime 0.133384   LR 0.010000   
2022-11-04 02:29:31,191 - INFO  - Training [7][  120/  196]   Loss 0.069879   Top1 97.447917   Top5 99.996745   BatchTime 0.131862   LR 0.010000   
2022-11-04 02:29:33,683 - INFO  - Training [7][  140/  196]   Loss 0.070847   Top1 97.427455   Top5 99.997210   BatchTime 0.130820   LR 0.010000   
2022-11-04 02:29:36,147 - INFO  - Training [7][  160/  196]   Loss 0.071603   Top1 97.387695   Top5 99.995117   BatchTime 0.129870   LR 0.010000   
2022-11-04 02:29:38,609 - INFO  - Training [7][  180/  196]   Loss 0.071493   Top1 97.395833   Top5 99.995660   BatchTime 0.129118   LR 0.010000   
2022-11-04 02:29:40,773 - INFO  - ==> Top1: 97.390    Top5: 99.996    Loss: 0.072

2022-11-04 02:29:40,773 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:29:43,671 - INFO  - Validation [7][   20/   40]   Loss 0.412415   Top1 89.394531   Top5 99.492188   BatchTime 0.144771   
2022-11-04 02:29:44,781 - INFO  - Validation [7][   40/   40]   Loss 0.406938   Top1 89.610000   Top5 99.580000   BatchTime 0.100150   
2022-11-04 02:29:45,040 - INFO  - ==> Top1: 89.610    Top5: 99.580    Loss: 0.407

2022-11-04 02:29:45,079 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:29:45,080 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:29:45,080 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 89.720   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:29:45,289 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:29:45,289 - INFO  - >>>>>>>> Epoch   8
2022-11-04 02:29:45,290 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:29:49,665 - INFO  - Training [8][   20/  196]   Loss 0.068212   Top1 97.812500   Top5 99.980469   BatchTime 0.218723   LR 0.010000   
2022-11-04 02:29:52,130 - INFO  - Training [8][   40/  196]   Loss 0.066342   Top1 97.744141   Top5 99.990234   BatchTime 0.170979   LR 0.010000   
2022-11-04 02:29:54,602 - INFO  - Training [8][   60/  196]   Loss 0.068634   Top1 97.623698   Top5 99.993490   BatchTime 0.155182   LR 0.010000   
2022-11-04 02:29:57,066 - INFO  - Training [8][   80/  196]   Loss 0.068033   Top1 97.636719   Top5 99.995117   BatchTime 0.147196   LR 0.010000   
2022-11-04 02:29:59,542 - INFO  - Training [8][  100/  196]   Loss 0.068802   Top1 97.597656   Top5 99.992188   BatchTime 0.142512   LR 0.010000   
2022-11-04 02:30:02,003 - INFO  - Training [8][  120/  196]   Loss 0.067822   Top1 97.649740   Top5 99.993490   BatchTime 0.139265   LR 0.010000   
2022-11-04 02:30:04,470 - INFO  - Training [8][  140/  196]   Loss 0.067167   Top1 97.670201   Top5 99.994420   BatchTime 0.136991   LR 0.010000   
2022-11-04 02:30:06,914 - INFO  - Training [8][  160/  196]   Loss 0.068521   Top1 97.626953   Top5 99.995117   BatchTime 0.135145   LR 0.010000   
2022-11-04 02:30:08,826 - INFO  - Training [8][  180/  196]   Loss 0.068394   Top1 97.604167   Top5 99.995660   BatchTime 0.130749   LR 0.010000   
2022-11-04 02:30:10,609 - INFO  - ==> Top1: 97.562    Top5: 99.996    Loss: 0.070

2022-11-04 02:30:10,610 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:30:13,220 - INFO  - Validation [8][   20/   40]   Loss 0.414967   Top1 89.707031   Top5 99.511719   BatchTime 0.130448   
2022-11-04 02:30:13,910 - INFO  - Validation [8][   40/   40]   Loss 0.402811   Top1 89.790000   Top5 99.600000   BatchTime 0.082476   
2022-11-04 02:30:14,169 - INFO  - ==> Top1: 89.790    Top5: 99.600    Loss: 0.403

2022-11-04 02:30:14,196 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:30:14,197 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.790   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:30:14,197 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.750   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:30:14,296 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:30:14,297 - INFO  - >>>>>>>> Epoch   9
2022-11-04 02:30:14,298 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:30:18,765 - INFO  - Training [9][   20/  196]   Loss 0.064796   Top1 97.578125   Top5 99.960938   BatchTime 0.223332   LR 0.010000   
2022-11-04 02:30:21,242 - INFO  - Training [9][   40/  196]   Loss 0.065401   Top1 97.705078   Top5 99.970703   BatchTime 0.173606   LR 0.010000   
2022-11-04 02:30:23,709 - INFO  - Training [9][   60/  196]   Loss 0.065565   Top1 97.734375   Top5 99.980469   BatchTime 0.156842   LR 0.010000   
2022-11-04 02:30:26,189 - INFO  - Training [9][   80/  196]   Loss 0.065690   Top1 97.739258   Top5 99.985352   BatchTime 0.148640   LR 0.010000   
2022-11-04 02:30:28,653 - INFO  - Training [9][  100/  196]   Loss 0.066222   Top1 97.687500   Top5 99.984375   BatchTime 0.143549   LR 0.010000   
2022-11-04 02:30:31,214 - INFO  - Training [9][  120/  196]   Loss 0.065452   Top1 97.705078   Top5 99.986979   BatchTime 0.140967   LR 0.010000   
2022-11-04 02:30:33,702 - INFO  - Training [9][  140/  196]   Loss 0.066374   Top1 97.670201   Top5 99.986049   BatchTime 0.138596   LR 0.010000   
2022-11-04 02:30:36,159 - INFO  - Training [9][  160/  196]   Loss 0.066959   Top1 97.685547   Top5 99.987793   BatchTime 0.136630   LR 0.010000   
2022-11-04 02:30:38,615 - INFO  - Training [9][  180/  196]   Loss 0.067281   Top1 97.667101   Top5 99.989149   BatchTime 0.135091   LR 0.010000   
2022-11-04 02:30:40,775 - INFO  - ==> Top1: 97.612    Top5: 99.988    Loss: 0.069

2022-11-04 02:30:40,775 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:30:43,666 - INFO  - Validation [9][   20/   40]   Loss 0.405753   Top1 89.707031   Top5 99.550781   BatchTime 0.144449   
2022-11-04 02:30:44,751 - INFO  - Validation [9][   40/   40]   Loss 0.404721   Top1 89.830000   Top5 99.590000   BatchTime 0.099357   
2022-11-04 02:30:45,016 - INFO  - ==> Top1: 89.830    Top5: 99.590    Loss: 0.405

2022-11-04 02:30:45,055 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:30:45,056 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:30:45,056 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.790   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:30:45,244 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:30:45,399 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:30:45,399 - INFO  - >>>>>>>> Epoch  10
2022-11-04 02:30:45,401 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:30:49,776 - INFO  - Training [10][   20/  196]   Loss 0.057342   Top1 98.066406   Top5 100.000000   BatchTime 0.218732   LR 0.010000   
2022-11-04 02:30:52,245 - INFO  - Training [10][   40/  196]   Loss 0.058293   Top1 97.929688   Top5 99.990234   BatchTime 0.171108   LR 0.010000   
2022-11-04 02:30:54,699 - INFO  - Training [10][   60/  196]   Loss 0.063175   Top1 97.812500   Top5 99.980469   BatchTime 0.154973   LR 0.010000   
2022-11-04 02:30:57,159 - INFO  - Training [10][   80/  196]   Loss 0.064864   Top1 97.700195   Top5 99.985352   BatchTime 0.146978   LR 0.010000   
2022-11-04 02:30:59,606 - INFO  - Training [10][  100/  196]   Loss 0.065408   Top1 97.675781   Top5 99.988281   BatchTime 0.142044   LR 0.010000   
2022-11-04 02:31:01,422 - INFO  - Training [10][  120/  196]   Loss 0.065915   Top1 97.656250   Top5 99.986979   BatchTime 0.133510   LR 0.010000   
2022-11-04 02:31:03,495 - INFO  - Training [10][  140/  196]   Loss 0.066676   Top1 97.603237   Top5 99.988839   BatchTime 0.129243   LR 0.010000   
2022-11-04 02:31:05,497 - INFO  - Training [10][  160/  196]   Loss 0.066018   Top1 97.614746   Top5 99.990234   BatchTime 0.125600   LR 0.010000   
2022-11-04 02:31:07,452 - INFO  - Training [10][  180/  196]   Loss 0.066324   Top1 97.591146   Top5 99.991319   BatchTime 0.122505   LR 0.010000   
2022-11-04 02:31:09,012 - INFO  - ==> Top1: 97.584    Top5: 99.992    Loss: 0.067

2022-11-04 02:31:09,013 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:31:11,982 - INFO  - Validation [10][   20/   40]   Loss 0.411230   Top1 89.824219   Top5 99.511719   BatchTime 0.148412   
2022-11-04 02:31:13,098 - INFO  - Validation [10][   40/   40]   Loss 0.405139   Top1 89.830000   Top5 99.540000   BatchTime 0.102103   
2022-11-04 02:31:13,351 - INFO  - ==> Top1: 89.830    Top5: 99.540    Loss: 0.405

2022-11-04 02:31:13,396 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:31:13,397 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.830   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:31:13,397 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 89.820   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:31:13,506 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:31:13,506 - INFO  - >>>>>>>> Epoch  11
2022-11-04 02:31:13,507 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:31:17,906 - INFO  - Training [11][   20/  196]   Loss 0.063195   Top1 97.675781   Top5 100.000000   BatchTime 0.219969   LR 0.010000   
2022-11-04 02:31:20,385 - INFO  - Training [11][   40/  196]   Loss 0.062096   Top1 97.773438   Top5 100.000000   BatchTime 0.171940   LR 0.010000   
2022-11-04 02:31:22,850 - INFO  - Training [11][   60/  196]   Loss 0.061782   Top1 97.714844   Top5 100.000000   BatchTime 0.155709   LR 0.010000   
2022-11-04 02:31:25,327 - INFO  - Training [11][   80/  196]   Loss 0.064814   Top1 97.592773   Top5 100.000000   BatchTime 0.147745   LR 0.010000   
2022-11-04 02:31:27,811 - INFO  - Training [11][  100/  196]   Loss 0.066201   Top1 97.542969   Top5 99.996094   BatchTime 0.143036   LR 0.010000   
2022-11-04 02:31:30,285 - INFO  - Training [11][  120/  196]   Loss 0.066100   Top1 97.532552   Top5 99.996745   BatchTime 0.139811   LR 0.010000   
2022-11-04 02:31:32,747 - INFO  - Training [11][  140/  196]   Loss 0.066311   Top1 97.533482   Top5 99.997210   BatchTime 0.137424   LR 0.010000   
2022-11-04 02:31:35,203 - INFO  - Training [11][  160/  196]   Loss 0.066194   Top1 97.573242   Top5 99.997559   BatchTime 0.135600   LR 0.010000   
2022-11-04 02:31:37,658 - INFO  - Training [11][  180/  196]   Loss 0.066510   Top1 97.562934   Top5 99.995660   BatchTime 0.134170   LR 0.010000   
2022-11-04 02:31:39,833 - INFO  - ==> Top1: 97.568    Top5: 99.996    Loss: 0.067

2022-11-04 02:31:39,834 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:31:42,734 - INFO  - Validation [11][   20/   40]   Loss 0.413018   Top1 90.058594   Top5 99.511719   BatchTime 0.144961   
2022-11-04 02:31:43,841 - INFO  - Validation [11][   40/   40]   Loss 0.404523   Top1 89.950000   Top5 99.560000   BatchTime 0.100148   
2022-11-04 02:31:44,095 - INFO  - ==> Top1: 89.950    Top5: 99.560    Loss: 0.405

2022-11-04 02:31:44,127 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.950   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:31:44,127 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:31:44,127 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.830   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:31:44,316 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:31:44,491 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:31:44,491 - INFO  - >>>>>>>> Epoch  12
2022-11-04 02:31:44,492 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:31:48,895 - INFO  - Training [12][   20/  196]   Loss 0.064474   Top1 97.714844   Top5 99.980469   BatchTime 0.220142   LR 0.010000   
2022-11-04 02:31:51,344 - INFO  - Training [12][   40/  196]   Loss 0.062174   Top1 97.890625   Top5 99.990234   BatchTime 0.171304   LR 0.010000   
2022-11-04 02:31:53,451 - INFO  - Training [12][   60/  196]   Loss 0.063158   Top1 97.779948   Top5 99.993490   BatchTime 0.149319   LR 0.010000   
2022-11-04 02:31:55,427 - INFO  - Training [12][   80/  196]   Loss 0.063281   Top1 97.783203   Top5 99.995117   BatchTime 0.136691   LR 0.010000   
2022-11-04 02:31:57,467 - INFO  - Training [12][  100/  196]   Loss 0.063744   Top1 97.750000   Top5 99.996094   BatchTime 0.129753   LR 0.010000   
2022-11-04 02:31:59,565 - INFO  - Training [12][  120/  196]   Loss 0.065187   Top1 97.688802   Top5 99.996745   BatchTime 0.125611   LR 0.010000   
2022-11-04 02:32:01,272 - INFO  - Training [12][  140/  196]   Loss 0.065595   Top1 97.714844   Top5 99.994420   BatchTime 0.119859   LR 0.010000   
2022-11-04 02:32:03,656 - INFO  - Training [12][  160/  196]   Loss 0.065569   Top1 97.707520   Top5 99.995117   BatchTime 0.119771   LR 0.010000   
2022-11-04 02:32:06,118 - INFO  - Training [12][  180/  196]   Loss 0.065283   Top1 97.719184   Top5 99.995660   BatchTime 0.120145   LR 0.010000   
2022-11-04 02:32:08,303 - INFO  - ==> Top1: 97.710    Top5: 99.996    Loss: 0.065

2022-11-04 02:32:08,304 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:32:11,170 - INFO  - Validation [12][   20/   40]   Loss 0.401190   Top1 90.000000   Top5 99.492188   BatchTime 0.143185   
2022-11-04 02:32:12,265 - INFO  - Validation [12][   40/   40]   Loss 0.394713   Top1 90.110000   Top5 99.560000   BatchTime 0.098976   
2022-11-04 02:32:12,532 - INFO  - ==> Top1: 90.110    Top5: 99.560    Loss: 0.395

2022-11-04 02:32:12,565 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:32:12,565 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 89.950   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:32:12,565 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.830   Top5: 99.590] Sparsity : 0.888
2022-11-04 02:32:12,763 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:32:12,940 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:32:12,941 - INFO  - >>>>>>>> Epoch  13
2022-11-04 02:32:12,943 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:32:17,342 - INFO  - Training [13][   20/  196]   Loss 0.058482   Top1 97.714844   Top5 100.000000   BatchTime 0.219916   LR 0.010000   
2022-11-04 02:32:19,816 - INFO  - Training [13][   40/  196]   Loss 0.059051   Top1 97.714844   Top5 100.000000   BatchTime 0.171826   LR 0.010000   
2022-11-04 02:32:22,389 - INFO  - Training [13][   60/  196]   Loss 0.062891   Top1 97.669271   Top5 100.000000   BatchTime 0.157427   LR 0.010000   
2022-11-04 02:32:24,878 - INFO  - Training [13][   80/  196]   Loss 0.061907   Top1 97.729492   Top5 100.000000   BatchTime 0.149181   LR 0.010000   
2022-11-04 02:32:27,370 - INFO  - Training [13][  100/  196]   Loss 0.061536   Top1 97.757812   Top5 100.000000   BatchTime 0.144263   LR 0.010000   
2022-11-04 02:32:29,839 - INFO  - Training [13][  120/  196]   Loss 0.062474   Top1 97.721354   Top5 100.000000   BatchTime 0.140795   LR 0.010000   
2022-11-04 02:32:32,313 - INFO  - Training [13][  140/  196]   Loss 0.062500   Top1 97.734375   Top5 100.000000   BatchTime 0.138354   LR 0.010000   
2022-11-04 02:32:34,773 - INFO  - Training [13][  160/  196]   Loss 0.062676   Top1 97.744141   Top5 99.997559   BatchTime 0.136433   LR 0.010000   
2022-11-04 02:32:37,236 - INFO  - Training [13][  180/  196]   Loss 0.062954   Top1 97.727865   Top5 99.995660   BatchTime 0.134958   LR 0.010000   
2022-11-04 02:32:39,397 - INFO  - ==> Top1: 97.724    Top5: 99.996    Loss: 0.063

2022-11-04 02:32:39,398 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:32:42,277 - INFO  - Validation [13][   20/   40]   Loss 0.423223   Top1 89.921875   Top5 99.531250   BatchTime 0.143859   
2022-11-04 02:32:43,388 - INFO  - Validation [13][   40/   40]   Loss 0.412509   Top1 90.060000   Top5 99.520000   BatchTime 0.099709   
2022-11-04 02:32:43,640 - INFO  - ==> Top1: 90.060    Top5: 99.520    Loss: 0.413

2022-11-04 02:32:43,678 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:32:43,679 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
2022-11-04 02:32:43,679 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.950   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:32:43,783 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:32:43,783 - INFO  - >>>>>>>> Epoch  14
2022-11-04 02:32:43,785 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:32:47,853 - INFO  - Training [14][   20/  196]   Loss 0.055952   Top1 97.949219   Top5 100.000000   BatchTime 0.203406   LR 0.010000   
2022-11-04 02:32:49,881 - INFO  - Training [14][   40/  196]   Loss 0.056878   Top1 97.919922   Top5 100.000000   BatchTime 0.152416   LR 0.010000   
2022-11-04 02:32:51,990 - INFO  - Training [14][   60/  196]   Loss 0.062543   Top1 97.760417   Top5 100.000000   BatchTime 0.136747   LR 0.010000   
2022-11-04 02:32:53,734 - INFO  - Training [14][   80/  196]   Loss 0.063020   Top1 97.744141   Top5 100.000000   BatchTime 0.124357   LR 0.010000   
2022-11-04 02:32:56,147 - INFO  - Training [14][  100/  196]   Loss 0.062805   Top1 97.761719   Top5 99.996094   BatchTime 0.123615   LR 0.010000   
2022-11-04 02:32:58,663 - INFO  - Training [14][  120/  196]   Loss 0.062275   Top1 97.773438   Top5 99.996745   BatchTime 0.123983   LR 0.010000   
2022-11-04 02:33:01,142 - INFO  - Training [14][  140/  196]   Loss 0.063326   Top1 97.734375   Top5 99.997210   BatchTime 0.123974   LR 0.010000   
2022-11-04 02:33:03,611 - INFO  - Training [14][  160/  196]   Loss 0.064008   Top1 97.717285   Top5 99.997559   BatchTime 0.123913   LR 0.010000   
2022-11-04 02:33:06,076 - INFO  - Training [14][  180/  196]   Loss 0.065001   Top1 97.701823   Top5 99.995660   BatchTime 0.123840   LR 0.010000   
2022-11-04 02:33:08,254 - INFO  - ==> Top1: 97.710    Top5: 99.994    Loss: 0.065

2022-11-04 02:33:08,254 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:33:11,153 - INFO  - Validation [14][   20/   40]   Loss 0.416732   Top1 89.902344   Top5 99.570312   BatchTime 0.144837   
2022-11-04 02:33:12,296 - INFO  - Validation [14][   40/   40]   Loss 0.407526   Top1 89.990000   Top5 99.610000   BatchTime 0.101010   
2022-11-04 02:33:12,560 - INFO  - ==> Top1: 89.990    Top5: 99.610    Loss: 0.408

2022-11-04 02:33:12,604 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:33:12,605 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
2022-11-04 02:33:12,605 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 89.990   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:33:12,712 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:33:12,712 - INFO  - >>>>>>>> Epoch  15
2022-11-04 02:33:12,713 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:33:17,125 - INFO  - Training [15][   20/  196]   Loss 0.061283   Top1 97.832031   Top5 100.000000   BatchTime 0.220579   LR 0.010000   
2022-11-04 02:33:19,602 - INFO  - Training [15][   40/  196]   Loss 0.059819   Top1 97.929688   Top5 100.000000   BatchTime 0.172202   LR 0.010000   
2022-11-04 02:33:22,082 - INFO  - Training [15][   60/  196]   Loss 0.061506   Top1 97.884115   Top5 100.000000   BatchTime 0.156132   LR 0.010000   
2022-11-04 02:33:24,548 - INFO  - Training [15][   80/  196]   Loss 0.061572   Top1 97.856445   Top5 100.000000   BatchTime 0.147924   LR 0.010000   
2022-11-04 02:33:27,015 - INFO  - Training [15][  100/  196]   Loss 0.062292   Top1 97.777344   Top5 100.000000   BatchTime 0.143007   LR 0.010000   
2022-11-04 02:33:29,489 - INFO  - Training [15][  120/  196]   Loss 0.061973   Top1 97.783203   Top5 99.996745   BatchTime 0.139789   LR 0.010000   
2022-11-04 02:33:31,954 - INFO  - Training [15][  140/  196]   Loss 0.061924   Top1 97.776228   Top5 99.997210   BatchTime 0.137427   LR 0.010000   
2022-11-04 02:33:34,411 - INFO  - Training [15][  160/  196]   Loss 0.062601   Top1 97.739258   Top5 99.997559   BatchTime 0.135607   LR 0.010000   
2022-11-04 02:33:36,861 - INFO  - Training [15][  180/  196]   Loss 0.062316   Top1 97.745226   Top5 99.997830   BatchTime 0.134151   LR 0.010000   
2022-11-04 02:33:39,034 - INFO  - ==> Top1: 97.710    Top5: 99.998    Loss: 0.063

2022-11-04 02:33:39,034 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:33:41,716 - INFO  - Validation [15][   20/   40]   Loss 0.429839   Top1 89.765625   Top5 99.550781   BatchTime 0.134023   
2022-11-04 02:33:42,609 - INFO  - Validation [15][   40/   40]   Loss 0.415216   Top1 89.840000   Top5 99.610000   BatchTime 0.089357   
2022-11-04 02:33:42,864 - INFO  - ==> Top1: 89.840    Top5: 99.610    Loss: 0.415

2022-11-04 02:33:42,897 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:33:42,897 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
2022-11-04 02:33:42,898 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 89.990   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:33:43,004 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:33:43,004 - INFO  - >>>>>>>> Epoch  16
2022-11-04 02:33:43,005 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:33:47,006 - INFO  - Training [16][   20/  196]   Loss 0.055780   Top1 98.007812   Top5 99.980469   BatchTime 0.200022   LR 0.010000   
2022-11-04 02:33:49,487 - INFO  - Training [16][   40/  196]   Loss 0.056345   Top1 98.017578   Top5 99.990234   BatchTime 0.162028   LR 0.010000   
2022-11-04 02:33:51,956 - INFO  - Training [16][   60/  196]   Loss 0.055961   Top1 98.040365   Top5 99.993490   BatchTime 0.149179   LR 0.010000   
2022-11-04 02:33:54,431 - INFO  - Training [16][   80/  196]   Loss 0.056409   Top1 98.046875   Top5 99.995117   BatchTime 0.142813   LR 0.010000   
2022-11-04 02:33:56,923 - INFO  - Training [16][  100/  196]   Loss 0.057423   Top1 97.941406   Top5 99.996094   BatchTime 0.139170   LR 0.010000   
2022-11-04 02:33:59,403 - INFO  - Training [16][  120/  196]   Loss 0.058075   Top1 97.916667   Top5 99.996745   BatchTime 0.136644   LR 0.010000   
2022-11-04 02:34:01,865 - INFO  - Training [16][  140/  196]   Loss 0.060110   Top1 97.845982   Top5 99.997210   BatchTime 0.134706   LR 0.010000   
2022-11-04 02:34:04,325 - INFO  - Training [16][  160/  196]   Loss 0.060608   Top1 97.770996   Top5 99.995117   BatchTime 0.133242   LR 0.010000   
2022-11-04 02:34:06,785 - INFO  - Training [16][  180/  196]   Loss 0.060860   Top1 97.764757   Top5 99.995660   BatchTime 0.132108   LR 0.010000   
2022-11-04 02:34:08,955 - INFO  - ==> Top1: 97.758    Top5: 99.996    Loss: 0.061

2022-11-04 02:34:08,956 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:34:11,859 - INFO  - Validation [16][   20/   40]   Loss 0.435992   Top1 89.726562   Top5 99.570312   BatchTime 0.145105   
2022-11-04 02:34:12,963 - INFO  - Validation [16][   40/   40]   Loss 0.433133   Top1 89.570000   Top5 99.590000   BatchTime 0.100147   
2022-11-04 02:34:13,209 - INFO  - ==> Top1: 89.570    Top5: 99.590    Loss: 0.433

2022-11-04 02:34:13,252 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:34:13,253 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
2022-11-04 02:34:13,253 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 89.990   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:34:13,357 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:34:13,357 - INFO  - >>>>>>>> Epoch  17
2022-11-04 02:34:13,359 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:34:17,785 - INFO  - Training [17][   20/  196]   Loss 0.060041   Top1 97.890625   Top5 100.000000   BatchTime 0.221293   LR 0.010000   
2022-11-04 02:34:20,265 - INFO  - Training [17][   40/  196]   Loss 0.055898   Top1 97.919922   Top5 100.000000   BatchTime 0.172656   LR 0.010000   
2022-11-04 02:34:22,832 - INFO  - Training [17][   60/  196]   Loss 0.058147   Top1 97.897135   Top5 100.000000   BatchTime 0.157887   LR 0.010000   
2022-11-04 02:34:25,308 - INFO  - Training [17][   80/  196]   Loss 0.061136   Top1 97.807617   Top5 100.000000   BatchTime 0.149366   LR 0.010000   
2022-11-04 02:34:27,780 - INFO  - Training [17][  100/  196]   Loss 0.060870   Top1 97.765625   Top5 100.000000   BatchTime 0.144210   LR 0.010000   
2022-11-04 02:34:30,239 - INFO  - Training [17][  120/  196]   Loss 0.060418   Top1 97.832031   Top5 100.000000   BatchTime 0.140664   LR 0.010000   
2022-11-04 02:34:32,673 - INFO  - Training [17][  140/  196]   Loss 0.060176   Top1 97.851562   Top5 100.000000   BatchTime 0.137960   LR 0.010000   
2022-11-04 02:34:34,479 - INFO  - Training [17][  160/  196]   Loss 0.060010   Top1 97.863770   Top5 99.997559   BatchTime 0.131997   LR 0.010000   
2022-11-04 02:34:36,489 - INFO  - Training [17][  180/  196]   Loss 0.060838   Top1 97.847222   Top5 99.995660   BatchTime 0.128502   LR 0.010000   
2022-11-04 02:34:38,327 - INFO  - ==> Top1: 97.884    Top5: 99.996    Loss: 0.060

2022-11-04 02:34:38,328 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:34:41,151 - INFO  - Validation [17][   20/   40]   Loss 0.427046   Top1 89.863281   Top5 99.433594   BatchTime 0.141064   
2022-11-04 02:34:42,235 - INFO  - Validation [17][   40/   40]   Loss 0.414662   Top1 90.090000   Top5 99.540000   BatchTime 0.097647   
2022-11-04 02:34:42,505 - INFO  - ==> Top1: 90.090    Top5: 99.540    Loss: 0.415

2022-11-04 02:34:42,553 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:34:42,553 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:34:42,553 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 90.060   Top5: 99.520] Sparsity : 0.888
2022-11-04 02:34:42,647 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:34:42,648 - INFO  - >>>>>>>> Epoch  18
2022-11-04 02:34:42,648 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:34:47,023 - INFO  - Training [18][   20/  196]   Loss 0.057421   Top1 97.929688   Top5 100.000000   BatchTime 0.218723   LR 0.010000   
2022-11-04 02:34:49,473 - INFO  - Training [18][   40/  196]   Loss 0.055076   Top1 98.066406   Top5 100.000000   BatchTime 0.170608   LR 0.010000   
2022-11-04 02:34:51,956 - INFO  - Training [18][   60/  196]   Loss 0.056111   Top1 97.981771   Top5 100.000000   BatchTime 0.155122   LR 0.010000   
2022-11-04 02:34:54,427 - INFO  - Training [18][   80/  196]   Loss 0.057551   Top1 97.944336   Top5 100.000000   BatchTime 0.147224   LR 0.010000   
2022-11-04 02:34:56,911 - INFO  - Training [18][  100/  196]   Loss 0.057568   Top1 97.925781   Top5 99.996094   BatchTime 0.142623   LR 0.010000   
2022-11-04 02:34:59,395 - INFO  - Training [18][  120/  196]   Loss 0.059291   Top1 97.841797   Top5 99.996745   BatchTime 0.139554   LR 0.010000   
2022-11-04 02:35:01,864 - INFO  - Training [18][  140/  196]   Loss 0.059435   Top1 97.834821   Top5 99.997210   BatchTime 0.137250   LR 0.010000   
2022-11-04 02:35:04,315 - INFO  - Training [18][  160/  196]   Loss 0.058989   Top1 97.868652   Top5 99.995117   BatchTime 0.135411   LR 0.010000   
2022-11-04 02:35:06,780 - INFO  - Training [18][  180/  196]   Loss 0.058452   Top1 97.884115   Top5 99.995660   BatchTime 0.134060   LR 0.010000   
2022-11-04 02:35:08,963 - INFO  - ==> Top1: 97.900    Top5: 99.996    Loss: 0.059

2022-11-04 02:35:08,964 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:35:11,879 - INFO  - Validation [18][   20/   40]   Loss 0.421294   Top1 90.019531   Top5 99.550781   BatchTime 0.145678   
2022-11-04 02:35:12,997 - INFO  - Validation [18][   40/   40]   Loss 0.410693   Top1 90.140000   Top5 99.630000   BatchTime 0.100808   
2022-11-04 02:35:13,255 - INFO  - ==> Top1: 90.140    Top5: 99.630    Loss: 0.411

2022-11-04 02:35:13,297 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:35:13,298 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:35:13,298 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:35:13,474 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:35:13,638 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:35:13,639 - INFO  - >>>>>>>> Epoch  19
2022-11-04 02:35:13,640 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:35:18,028 - INFO  - Training [19][   20/  196]   Loss 0.053053   Top1 98.125000   Top5 100.000000   BatchTime 0.219412   LR 0.010000   
2022-11-04 02:35:20,492 - INFO  - Training [19][   40/  196]   Loss 0.051668   Top1 98.154297   Top5 100.000000   BatchTime 0.171307   LR 0.010000   
2022-11-04 02:35:22,952 - INFO  - Training [19][   60/  196]   Loss 0.055746   Top1 98.014323   Top5 100.000000   BatchTime 0.155197   LR 0.010000   
2022-11-04 02:35:25,384 - INFO  - Training [19][   80/  196]   Loss 0.057906   Top1 97.905273   Top5 99.995117   BatchTime 0.146799   LR 0.010000   
2022-11-04 02:35:27,150 - INFO  - Training [19][  100/  196]   Loss 0.057501   Top1 97.929688   Top5 99.996094   BatchTime 0.135102   LR 0.010000   
2022-11-04 02:35:29,212 - INFO  - Training [19][  120/  196]   Loss 0.058309   Top1 97.845052   Top5 99.996745   BatchTime 0.129762   LR 0.010000   
2022-11-04 02:35:31,243 - INFO  - Training [19][  140/  196]   Loss 0.057742   Top1 97.882254   Top5 99.997210   BatchTime 0.125731   LR 0.010000   
2022-11-04 02:35:33,189 - INFO  - Training [19][  160/  196]   Loss 0.058648   Top1 97.841797   Top5 99.997559   BatchTime 0.122178   LR 0.010000   
2022-11-04 02:35:35,275 - INFO  - Training [19][  180/  196]   Loss 0.058967   Top1 97.862413   Top5 99.995660   BatchTime 0.120191   LR 0.010000   
2022-11-04 02:35:37,469 - INFO  - ==> Top1: 97.864    Top5: 99.996    Loss: 0.059

2022-11-04 02:35:37,470 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:35:40,399 - INFO  - Validation [19][   20/   40]   Loss 0.436813   Top1 89.765625   Top5 99.433594   BatchTime 0.146330   
2022-11-04 02:35:41,500 - INFO  - Validation [19][   40/   40]   Loss 0.422059   Top1 89.860000   Top5 99.530000   BatchTime 0.100697   
2022-11-04 02:35:41,769 - INFO  - ==> Top1: 89.860    Top5: 99.530    Loss: 0.422

2022-11-04 02:35:41,800 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:35:41,800 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:35:41,800 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:35:41,904 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:35:41,904 - INFO  - >>>>>>>> Epoch  20
2022-11-04 02:35:41,906 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:35:46,352 - INFO  - Training [20][   20/  196]   Loss 0.058625   Top1 97.832031   Top5 100.000000   BatchTime 0.222308   LR 0.010000   
2022-11-04 02:35:48,829 - INFO  - Training [20][   40/  196]   Loss 0.059137   Top1 97.812500   Top5 99.990234   BatchTime 0.173083   LR 0.010000   
2022-11-04 02:35:51,304 - INFO  - Training [20][   60/  196]   Loss 0.059610   Top1 97.845052   Top5 99.993490   BatchTime 0.156629   LR 0.010000   
2022-11-04 02:35:53,776 - INFO  - Training [20][   80/  196]   Loss 0.058692   Top1 97.885742   Top5 99.990234   BatchTime 0.148374   LR 0.010000   
2022-11-04 02:35:56,255 - INFO  - Training [20][  100/  196]   Loss 0.059296   Top1 97.886719   Top5 99.992188   BatchTime 0.143492   LR 0.010000   
2022-11-04 02:35:58,728 - INFO  - Training [20][  120/  196]   Loss 0.058920   Top1 97.936198   Top5 99.990234   BatchTime 0.140184   LR 0.010000   
2022-11-04 02:36:01,213 - INFO  - Training [20][  140/  196]   Loss 0.059579   Top1 97.901786   Top5 99.991629   BatchTime 0.137909   LR 0.010000   
2022-11-04 02:36:03,668 - INFO  - Training [20][  160/  196]   Loss 0.059562   Top1 97.917480   Top5 99.992676   BatchTime 0.136013   LR 0.010000   
2022-11-04 02:36:06,127 - INFO  - Training [20][  180/  196]   Loss 0.060345   Top1 97.894965   Top5 99.991319   BatchTime 0.134562   LR 0.010000   
2022-11-04 02:36:08,305 - INFO  - ==> Top1: 97.868    Top5: 99.992    Loss: 0.061

2022-11-04 02:36:08,306 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:36:11,200 - INFO  - Validation [20][   20/   40]   Loss 0.425188   Top1 89.980469   Top5 99.472656   BatchTime 0.144638   
2022-11-04 02:36:12,318 - INFO  - Validation [20][   40/   40]   Loss 0.415178   Top1 89.950000   Top5 99.580000   BatchTime 0.100280   
2022-11-04 02:36:12,564 - INFO  - ==> Top1: 89.950    Top5: 99.580    Loss: 0.415

2022-11-04 02:36:12,594 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:36:12,595 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:36:12,595 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:36:12,698 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:36:12,698 - INFO  - >>>>>>>> Epoch  21
2022-11-04 02:36:12,700 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:36:17,136 - INFO  - Training [21][   20/  196]   Loss 0.050600   Top1 98.066406   Top5 100.000000   BatchTime 0.221794   LR 0.010000   
2022-11-04 02:36:18,919 - INFO  - Training [21][   40/  196]   Loss 0.053567   Top1 97.919922   Top5 100.000000   BatchTime 0.155480   LR 0.010000   
2022-11-04 02:36:20,975 - INFO  - Training [21][   60/  196]   Loss 0.055867   Top1 97.858073   Top5 100.000000   BatchTime 0.137921   LR 0.010000   
2022-11-04 02:36:23,015 - INFO  - Training [21][   80/  196]   Loss 0.056064   Top1 97.875977   Top5 99.995117   BatchTime 0.128940   LR 0.010000   
2022-11-04 02:36:25,079 - INFO  - Training [21][  100/  196]   Loss 0.055256   Top1 97.929688   Top5 99.996094   BatchTime 0.123784   LR 0.010000   
2022-11-04 02:36:27,290 - INFO  - Training [21][  120/  196]   Loss 0.054563   Top1 97.994792   Top5 99.996745   BatchTime 0.121578   LR 0.010000   
2022-11-04 02:36:29,758 - INFO  - Training [21][  140/  196]   Loss 0.055797   Top1 97.985491   Top5 99.991629   BatchTime 0.121843   LR 0.010000   
2022-11-04 02:36:32,215 - INFO  - Training [21][  160/  196]   Loss 0.056337   Top1 97.978516   Top5 99.992676   BatchTime 0.121970   LR 0.010000   
2022-11-04 02:36:34,676 - INFO  - Training [21][  180/  196]   Loss 0.056819   Top1 97.962240   Top5 99.993490   BatchTime 0.122089   LR 0.010000   
2022-11-04 02:36:36,843 - INFO  - ==> Top1: 97.932    Top5: 99.994    Loss: 0.058

2022-11-04 02:36:36,844 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:36:39,753 - INFO  - Validation [21][   20/   40]   Loss 0.436165   Top1 89.726562   Top5 99.492188   BatchTime 0.145370   
2022-11-04 02:36:40,788 - INFO  - Validation [21][   40/   40]   Loss 0.420442   Top1 89.880000   Top5 99.560000   BatchTime 0.098574   
2022-11-04 02:36:41,035 - INFO  - ==> Top1: 89.880    Top5: 99.560    Loss: 0.420

2022-11-04 02:36:41,076 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:36:41,077 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:36:41,077 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:36:41,153 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:36:41,153 - INFO  - >>>>>>>> Epoch  22
2022-11-04 02:36:41,154 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:36:45,571 - INFO  - Training [22][   20/  196]   Loss 0.051299   Top1 98.300781   Top5 100.000000   BatchTime 0.220831   LR 0.010000   
2022-11-04 02:36:48,051 - INFO  - Training [22][   40/  196]   Loss 0.052534   Top1 98.203125   Top5 100.000000   BatchTime 0.172433   LR 0.010000   
2022-11-04 02:36:50,526 - INFO  - Training [22][   60/  196]   Loss 0.053519   Top1 98.157552   Top5 100.000000   BatchTime 0.156197   LR 0.010000   
2022-11-04 02:36:53,003 - INFO  - Training [22][   80/  196]   Loss 0.055371   Top1 98.110352   Top5 99.995117   BatchTime 0.148105   LR 0.010000   
2022-11-04 02:36:55,469 - INFO  - Training [22][  100/  196]   Loss 0.056307   Top1 98.035156   Top5 99.996094   BatchTime 0.143150   LR 0.010000   
2022-11-04 02:36:57,943 - INFO  - Training [22][  120/  196]   Loss 0.055924   Top1 98.030599   Top5 99.996745   BatchTime 0.139909   LR 0.010000   
2022-11-04 02:37:00,414 - INFO  - Training [22][  140/  196]   Loss 0.056219   Top1 98.018973   Top5 99.994420   BatchTime 0.137569   LR 0.010000   
2022-11-04 02:37:02,871 - INFO  - Training [22][  160/  196]   Loss 0.056270   Top1 98.034668   Top5 99.995117   BatchTime 0.135728   LR 0.010000   
2022-11-04 02:37:05,321 - INFO  - Training [22][  180/  196]   Loss 0.056630   Top1 97.990451   Top5 99.995660   BatchTime 0.134258   LR 0.010000   
2022-11-04 02:37:07,469 - INFO  - ==> Top1: 97.942    Top5: 99.996    Loss: 0.057

2022-11-04 02:37:07,470 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:37:10,332 - INFO  - Validation [22][   20/   40]   Loss 0.435211   Top1 89.687500   Top5 99.589844   BatchTime 0.143037   
2022-11-04 02:37:11,106 - INFO  - Validation [22][   40/   40]   Loss 0.416820   Top1 89.950000   Top5 99.630000   BatchTime 0.090865   
2022-11-04 02:37:11,356 - INFO  - ==> Top1: 89.950    Top5: 99.630    Loss: 0.417

2022-11-04 02:37:11,377 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:37:11,378 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:37:11,378 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:37:11,485 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:37:11,486 - INFO  - >>>>>>>> Epoch  23
2022-11-04 02:37:11,487 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:37:15,544 - INFO  - Training [23][   20/  196]   Loss 0.055179   Top1 97.949219   Top5 100.000000   BatchTime 0.202833   LR 0.010000   
2022-11-04 02:37:17,565 - INFO  - Training [23][   40/  196]   Loss 0.053416   Top1 98.037109   Top5 100.000000   BatchTime 0.151948   LR 0.010000   
2022-11-04 02:37:19,627 - INFO  - Training [23][   60/  196]   Loss 0.052692   Top1 98.066406   Top5 99.993490   BatchTime 0.135650   LR 0.010000   
2022-11-04 02:37:22,094 - INFO  - Training [23][   80/  196]   Loss 0.052749   Top1 98.105469   Top5 99.995117   BatchTime 0.132586   LR 0.010000   
2022-11-04 02:37:24,584 - INFO  - Training [23][  100/  196]   Loss 0.055577   Top1 98.015625   Top5 99.996094   BatchTime 0.130968   LR 0.010000   
2022-11-04 02:37:27,052 - INFO  - Training [23][  120/  196]   Loss 0.055576   Top1 98.020833   Top5 99.996745   BatchTime 0.129703   LR 0.010000   
2022-11-04 02:37:29,523 - INFO  - Training [23][  140/  196]   Loss 0.057393   Top1 97.968750   Top5 99.997210   BatchTime 0.128822   LR 0.010000   
2022-11-04 02:37:31,985 - INFO  - Training [23][  160/  196]   Loss 0.057698   Top1 97.939453   Top5 99.997559   BatchTime 0.128104   LR 0.010000   
2022-11-04 02:37:34,444 - INFO  - Training [23][  180/  196]   Loss 0.057819   Top1 97.964410   Top5 99.997830   BatchTime 0.127537   LR 0.010000   
2022-11-04 02:37:36,616 - INFO  - ==> Top1: 97.978    Top5: 99.998    Loss: 0.057

2022-11-04 02:37:36,617 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:37:39,541 - INFO  - Validation [23][   20/   40]   Loss 0.433529   Top1 89.843750   Top5 99.687500   BatchTime 0.146116   
2022-11-04 02:37:40,668 - INFO  - Validation [23][   40/   40]   Loss 0.426339   Top1 90.040000   Top5 99.640000   BatchTime 0.101235   
2022-11-04 02:37:40,925 - INFO  - ==> Top1: 90.040    Top5: 99.640    Loss: 0.426

2022-11-04 02:37:40,974 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:37:40,975 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:37:40,975 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:37:41,079 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:37:41,080 - INFO  - >>>>>>>> Epoch  24
2022-11-04 02:37:41,081 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:37:45,515 - INFO  - Training [24][   20/  196]   Loss 0.054225   Top1 98.105469   Top5 100.000000   BatchTime 0.221675   LR 0.010000   
2022-11-04 02:37:47,988 - INFO  - Training [24][   40/  196]   Loss 0.051040   Top1 98.173828   Top5 100.000000   BatchTime 0.172663   LR 0.010000   
2022-11-04 02:37:50,472 - INFO  - Training [24][   60/  196]   Loss 0.051025   Top1 98.170573   Top5 100.000000   BatchTime 0.156506   LR 0.010000   
2022-11-04 02:37:52,955 - INFO  - Training [24][   80/  196]   Loss 0.051308   Top1 98.173828   Top5 100.000000   BatchTime 0.148421   LR 0.010000   
2022-11-04 02:37:55,422 - INFO  - Training [24][  100/  196]   Loss 0.051838   Top1 98.148438   Top5 100.000000   BatchTime 0.143406   LR 0.010000   
2022-11-04 02:37:57,893 - INFO  - Training [24][  120/  196]   Loss 0.051979   Top1 98.170573   Top5 99.993490   BatchTime 0.140099   LR 0.010000   
2022-11-04 02:38:00,356 - INFO  - Training [24][  140/  196]   Loss 0.051042   Top1 98.189174   Top5 99.994420   BatchTime 0.137675   LR 0.010000   
2022-11-04 02:38:02,803 - INFO  - Training [24][  160/  196]   Loss 0.052289   Top1 98.139648   Top5 99.995117   BatchTime 0.135760   LR 0.010000   
2022-11-04 02:38:05,126 - INFO  - Training [24][  180/  196]   Loss 0.052698   Top1 98.120660   Top5 99.995660   BatchTime 0.133578   LR 0.010000   
2022-11-04 02:38:06,760 - INFO  - ==> Top1: 98.116    Top5: 99.996    Loss: 0.053

2022-11-04 02:38:06,760 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:38:09,394 - INFO  - Validation [24][   20/   40]   Loss 0.439511   Top1 89.765625   Top5 99.550781   BatchTime 0.131617   
2022-11-04 02:38:10,092 - INFO  - Validation [24][   40/   40]   Loss 0.433519   Top1 89.840000   Top5 99.590000   BatchTime 0.083241   
2022-11-04 02:38:10,346 - INFO  - ==> Top1: 89.840    Top5: 99.590    Loss: 0.434

2022-11-04 02:38:10,373 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:38:10,374 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:38:10,374 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:38:10,463 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:38:10,463 - INFO  - >>>>>>>> Epoch  25
2022-11-04 02:38:10,464 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:38:14,938 - INFO  - Training [25][   20/  196]   Loss 0.050679   Top1 98.378906   Top5 100.000000   BatchTime 0.223683   LR 0.010000   
2022-11-04 02:38:17,410 - INFO  - Training [25][   40/  196]   Loss 0.051550   Top1 98.144531   Top5 100.000000   BatchTime 0.173640   LR 0.010000   
2022-11-04 02:38:19,891 - INFO  - Training [25][   60/  196]   Loss 0.052205   Top1 98.105469   Top5 100.000000   BatchTime 0.157107   LR 0.010000   
2022-11-04 02:38:22,365 - INFO  - Training [25][   80/  196]   Loss 0.052025   Top1 98.129883   Top5 100.000000   BatchTime 0.148756   LR 0.010000   
2022-11-04 02:38:24,832 - INFO  - Training [25][  100/  196]   Loss 0.052111   Top1 98.148438   Top5 100.000000   BatchTime 0.143675   LR 0.010000   
2022-11-04 02:38:27,314 - INFO  - Training [25][  120/  196]   Loss 0.052065   Top1 98.173828   Top5 100.000000   BatchTime 0.140410   LR 0.010000   
2022-11-04 02:38:29,779 - INFO  - Training [25][  140/  196]   Loss 0.051444   Top1 98.197545   Top5 100.000000   BatchTime 0.137958   LR 0.010000   
2022-11-04 02:38:32,192 - INFO  - Training [25][  160/  196]   Loss 0.052874   Top1 98.139648   Top5 100.000000   BatchTime 0.135792   LR 0.010000   
2022-11-04 02:38:34,736 - INFO  - Training [25][  180/  196]   Loss 0.053109   Top1 98.148872   Top5 100.000000   BatchTime 0.134841   LR 0.010000   
2022-11-04 02:38:36,910 - INFO  - ==> Top1: 98.144    Top5: 99.998    Loss: 0.053

2022-11-04 02:38:36,911 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:38:39,797 - INFO  - Validation [25][   20/   40]   Loss 0.436772   Top1 89.609375   Top5 99.453125   BatchTime 0.144142   
2022-11-04 02:38:40,899 - INFO  - Validation [25][   40/   40]   Loss 0.423505   Top1 89.980000   Top5 99.550000   BatchTime 0.099636   
2022-11-04 02:38:41,152 - INFO  - ==> Top1: 89.980    Top5: 99.550    Loss: 0.424

2022-11-04 02:38:41,179 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:38:41,180 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:38:41,180 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.090   Top5: 99.540] Sparsity : 0.888
2022-11-04 02:38:41,277 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:38:41,277 - INFO  - >>>>>>>> Epoch  26
2022-11-04 02:38:41,279 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:38:45,690 - INFO  - Training [26][   20/  196]   Loss 0.050997   Top1 98.300781   Top5 100.000000   BatchTime 0.220545   LR 0.010000   
2022-11-04 02:38:48,154 - INFO  - Training [26][   40/  196]   Loss 0.050574   Top1 98.310547   Top5 100.000000   BatchTime 0.171884   LR 0.010000   
2022-11-04 02:38:50,618 - INFO  - Training [26][   60/  196]   Loss 0.052554   Top1 98.274740   Top5 99.993490   BatchTime 0.155660   LR 0.010000   
2022-11-04 02:38:53,068 - INFO  - Training [26][   80/  196]   Loss 0.054130   Top1 98.193359   Top5 99.995117   BatchTime 0.147362   LR 0.010000   
2022-11-04 02:38:55,513 - INFO  - Training [26][  100/  196]   Loss 0.054525   Top1 98.132812   Top5 99.996094   BatchTime 0.142343   LR 0.010000   
2022-11-04 02:38:57,544 - INFO  - Training [26][  120/  196]   Loss 0.054674   Top1 98.102214   Top5 99.996745   BatchTime 0.135542   LR 0.010000   
2022-11-04 02:38:59,499 - INFO  - Training [26][  140/  196]   Loss 0.054186   Top1 98.122210   Top5 99.997210   BatchTime 0.130141   LR 0.010000   
2022-11-04 02:39:01,498 - INFO  - Training [26][  160/  196]   Loss 0.054059   Top1 98.125000   Top5 99.997559   BatchTime 0.126367   LR 0.010000   
2022-11-04 02:39:03,500 - INFO  - Training [26][  180/  196]   Loss 0.054810   Top1 98.098958   Top5 99.997830   BatchTime 0.123447   LR 0.010000   
2022-11-04 02:39:05,120 - INFO  - ==> Top1: 98.076    Top5: 99.998    Loss: 0.055

2022-11-04 02:39:05,121 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:39:08,117 - INFO  - Validation [26][   20/   40]   Loss 0.438121   Top1 89.941406   Top5 99.453125   BatchTime 0.149732   
2022-11-04 02:39:09,255 - INFO  - Validation [26][   40/   40]   Loss 0.424594   Top1 90.090000   Top5 99.570000   BatchTime 0.103309   
2022-11-04 02:39:09,510 - INFO  - ==> Top1: 90.090    Top5: 99.570    Loss: 0.425

2022-11-04 02:39:09,554 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:39:09,554 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:39:09,554 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.090   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:39:09,671 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:39:09,671 - INFO  - >>>>>>>> Epoch  27
2022-11-04 02:39:09,673 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:39:14,067 - INFO  - Training [27][   20/  196]   Loss 0.051838   Top1 98.222656   Top5 100.000000   BatchTime 0.219726   LR 0.010000   
2022-11-04 02:39:16,534 - INFO  - Training [27][   40/  196]   Loss 0.049860   Top1 98.242188   Top5 100.000000   BatchTime 0.171540   LR 0.010000   
2022-11-04 02:39:19,000 - INFO  - Training [27][   60/  196]   Loss 0.050971   Top1 98.183594   Top5 100.000000   BatchTime 0.155445   LR 0.010000   
2022-11-04 02:39:21,470 - INFO  - Training [27][   80/  196]   Loss 0.052272   Top1 98.164062   Top5 100.000000   BatchTime 0.147465   LR 0.010000   
2022-11-04 02:39:23,933 - INFO  - Training [27][  100/  196]   Loss 0.054337   Top1 98.062500   Top5 100.000000   BatchTime 0.142604   LR 0.010000   
2022-11-04 02:39:26,404 - INFO  - Training [27][  120/  196]   Loss 0.053161   Top1 98.105469   Top5 100.000000   BatchTime 0.139427   LR 0.010000   
2022-11-04 02:39:28,865 - INFO  - Training [27][  140/  196]   Loss 0.053247   Top1 98.088728   Top5 100.000000   BatchTime 0.137087   LR 0.010000   
2022-11-04 02:39:31,318 - INFO  - Training [27][  160/  196]   Loss 0.053640   Top1 98.081055   Top5 100.000000   BatchTime 0.135284   LR 0.010000   
2022-11-04 02:39:33,782 - INFO  - Training [27][  180/  196]   Loss 0.053402   Top1 98.094618   Top5 100.000000   BatchTime 0.133937   LR 0.010000   
2022-11-04 02:39:35,952 - INFO  - ==> Top1: 98.084    Top5: 100.000    Loss: 0.054

2022-11-04 02:39:35,952 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:39:38,851 - INFO  - Validation [27][   20/   40]   Loss 0.436028   Top1 90.117188   Top5 99.492188   BatchTime 0.144860   
2022-11-04 02:39:39,970 - INFO  - Validation [27][   40/   40]   Loss 0.425793   Top1 90.100000   Top5 99.570000   BatchTime 0.100406   
2022-11-04 02:39:40,220 - INFO  - ==> Top1: 90.100    Top5: 99.570    Loss: 0.426

2022-11-04 02:39:40,263 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:39:40,264 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:39:40,264 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.100   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:39:40,341 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:39:40,342 - INFO  - >>>>>>>> Epoch  28
2022-11-04 02:39:40,342 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:39:44,709 - INFO  - Training [28][   20/  196]   Loss 0.052638   Top1 98.203125   Top5 100.000000   BatchTime 0.218340   LR 0.010000   
2022-11-04 02:39:47,164 - INFO  - Training [28][   40/  196]   Loss 0.050131   Top1 98.242188   Top5 100.000000   BatchTime 0.170535   LR 0.010000   
2022-11-04 02:39:49,469 - INFO  - Training [28][   60/  196]   Loss 0.048808   Top1 98.242188   Top5 100.000000   BatchTime 0.152098   LR 0.010000   
2022-11-04 02:39:51,341 - INFO  - Training [28][   80/  196]   Loss 0.048825   Top1 98.276367   Top5 100.000000   BatchTime 0.137480   LR 0.010000   
2022-11-04 02:39:53,393 - INFO  - Training [28][  100/  196]   Loss 0.050011   Top1 98.222656   Top5 100.000000   BatchTime 0.130507   LR 0.010000   
2022-11-04 02:39:55,441 - INFO  - Training [28][  120/  196]   Loss 0.051042   Top1 98.167318   Top5 99.996745   BatchTime 0.125816   LR 0.010000   
2022-11-04 02:39:57,365 - INFO  - Training [28][  140/  196]   Loss 0.050529   Top1 98.164062   Top5 99.997210   BatchTime 0.121587   LR 0.010000   
2022-11-04 02:39:59,565 - INFO  - Training [28][  160/  196]   Loss 0.050771   Top1 98.166504   Top5 99.997559   BatchTime 0.120135   LR 0.010000   
2022-11-04 02:40:02,019 - INFO  - Training [28][  180/  196]   Loss 0.051354   Top1 98.157552   Top5 99.997830   BatchTime 0.120423   LR 0.010000   
2022-11-04 02:40:04,186 - INFO  - ==> Top1: 98.160    Top5: 99.996    Loss: 0.052

2022-11-04 02:40:04,187 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:40:07,063 - INFO  - Validation [28][   20/   40]   Loss 0.442969   Top1 89.667969   Top5 99.550781   BatchTime 0.143727   
2022-11-04 02:40:08,164 - INFO  - Validation [28][   40/   40]   Loss 0.429040   Top1 89.950000   Top5 99.600000   BatchTime 0.099386   
2022-11-04 02:40:08,423 - INFO  - ==> Top1: 89.950    Top5: 99.600    Loss: 0.429

2022-11-04 02:40:08,470 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:40:08,471 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:40:08,471 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.100   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:40:08,580 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:40:08,581 - INFO  - >>>>>>>> Epoch  29
2022-11-04 02:40:08,582 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:40:12,951 - INFO  - Training [29][   20/  196]   Loss 0.049481   Top1 98.125000   Top5 100.000000   BatchTime 0.218430   LR 0.010000   
2022-11-04 02:40:15,433 - INFO  - Training [29][   40/  196]   Loss 0.049114   Top1 98.115234   Top5 100.000000   BatchTime 0.171269   LR 0.010000   
2022-11-04 02:40:17,903 - INFO  - Training [29][   60/  196]   Loss 0.047823   Top1 98.209635   Top5 100.000000   BatchTime 0.155347   LR 0.010000   
2022-11-04 02:40:20,375 - INFO  - Training [29][   80/  196]   Loss 0.046617   Top1 98.281250   Top5 100.000000   BatchTime 0.147413   LR 0.010000   
2022-11-04 02:40:22,851 - INFO  - Training [29][  100/  196]   Loss 0.046717   Top1 98.296875   Top5 100.000000   BatchTime 0.142690   LR 0.010000   
2022-11-04 02:40:25,332 - INFO  - Training [29][  120/  196]   Loss 0.046620   Top1 98.320312   Top5 100.000000   BatchTime 0.139575   LR 0.010000   
2022-11-04 02:40:27,755 - INFO  - Training [29][  140/  196]   Loss 0.047517   Top1 98.286830   Top5 99.997210   BatchTime 0.136946   LR 0.010000   
2022-11-04 02:40:30,209 - INFO  - Training [29][  160/  196]   Loss 0.048031   Top1 98.266602   Top5 99.997559   BatchTime 0.135164   LR 0.010000   
2022-11-04 02:40:32,671 - INFO  - Training [29][  180/  196]   Loss 0.048702   Top1 98.246528   Top5 99.997830   BatchTime 0.133822   LR 0.010000   
2022-11-04 02:40:34,819 - INFO  - ==> Top1: 98.224    Top5: 99.998    Loss: 0.049

2022-11-04 02:40:34,819 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:40:37,700 - INFO  - Validation [29][   20/   40]   Loss 0.447336   Top1 89.687500   Top5 99.531250   BatchTime 0.143984   
2022-11-04 02:40:38,812 - INFO  - Validation [29][   40/   40]   Loss 0.438053   Top1 89.980000   Top5 99.560000   BatchTime 0.099787   
2022-11-04 02:40:39,060 - INFO  - ==> Top1: 89.980    Top5: 99.560    Loss: 0.438

2022-11-04 02:40:39,106 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:40:39,107 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:40:39,107 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.100   Top5: 99.570] Sparsity : 0.888
2022-11-04 02:40:39,216 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:40:39,217 - INFO  - >>>>>>>> Epoch  30
2022-11-04 02:40:39,218 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:40:43,233 - INFO  - Training [30][   20/  196]   Loss 0.056209   Top1 97.871094   Top5 100.000000   BatchTime 0.200735   LR 0.001000   
2022-11-04 02:40:45,279 - INFO  - Training [30][   40/  196]   Loss 0.050928   Top1 98.154297   Top5 99.990234   BatchTime 0.151526   LR 0.001000   
2022-11-04 02:40:47,336 - INFO  - Training [30][   60/  196]   Loss 0.048787   Top1 98.196615   Top5 99.993490   BatchTime 0.135299   LR 0.001000   
2022-11-04 02:40:49,293 - INFO  - Training [30][   80/  196]   Loss 0.047706   Top1 98.281250   Top5 99.995117   BatchTime 0.125931   LR 0.001000   
2022-11-04 02:40:51,385 - INFO  - Training [30][  100/  196]   Loss 0.048323   Top1 98.257812   Top5 99.992188   BatchTime 0.121663   LR 0.001000   
2022-11-04 02:40:53,853 - INFO  - Training [30][  120/  196]   Loss 0.047591   Top1 98.258464   Top5 99.993490   BatchTime 0.121952   LR 0.001000   
2022-11-04 02:40:56,321 - INFO  - Training [30][  140/  196]   Loss 0.048663   Top1 98.228237   Top5 99.994420   BatchTime 0.122157   LR 0.001000   
2022-11-04 02:40:58,780 - INFO  - Training [30][  160/  196]   Loss 0.047255   Top1 98.281250   Top5 99.995117   BatchTime 0.122260   LR 0.001000   
2022-11-04 02:41:01,236 - INFO  - Training [30][  180/  196]   Loss 0.047146   Top1 98.309462   Top5 99.995660   BatchTime 0.122316   LR 0.001000   
2022-11-04 02:41:03,407 - INFO  - ==> Top1: 98.336    Top5: 99.996    Loss: 0.046

2022-11-04 02:41:03,408 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:41:06,274 - INFO  - Validation [30][   20/   40]   Loss 0.434981   Top1 90.175781   Top5 99.570312   BatchTime 0.143221   
2022-11-04 02:41:07,384 - INFO  - Validation [30][   40/   40]   Loss 0.421283   Top1 90.320000   Top5 99.640000   BatchTime 0.099358   
2022-11-04 02:41:07,637 - INFO  - ==> Top1: 90.320    Top5: 99.640    Loss: 0.421

2022-11-04 02:41:07,678 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:41:07,679 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:41:07,679 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 90.110   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:41:07,884 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:41:08,049 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:41:08,050 - INFO  - >>>>>>>> Epoch  31
2022-11-04 02:41:08,051 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:41:12,462 - INFO  - Training [31][   20/  196]   Loss 0.049121   Top1 98.222656   Top5 100.000000   BatchTime 0.220564   LR 0.001000   
2022-11-04 02:41:14,939 - INFO  - Training [31][   40/  196]   Loss 0.043598   Top1 98.535156   Top5 100.000000   BatchTime 0.172195   LR 0.001000   
2022-11-04 02:41:17,419 - INFO  - Training [31][   60/  196]   Loss 0.043517   Top1 98.535156   Top5 100.000000   BatchTime 0.156136   LR 0.001000   
2022-11-04 02:41:19,907 - INFO  - Training [31][   80/  196]   Loss 0.043842   Top1 98.515625   Top5 100.000000   BatchTime 0.148202   LR 0.001000   
2022-11-04 02:41:22,379 - INFO  - Training [31][  100/  196]   Loss 0.043911   Top1 98.542969   Top5 99.996094   BatchTime 0.143283   LR 0.001000   
2022-11-04 02:41:24,850 - INFO  - Training [31][  120/  196]   Loss 0.042865   Top1 98.567708   Top5 99.996745   BatchTime 0.139994   LR 0.001000   
2022-11-04 02:41:27,324 - INFO  - Training [31][  140/  196]   Loss 0.042291   Top1 98.577009   Top5 99.997210   BatchTime 0.137662   LR 0.001000   
2022-11-04 02:41:29,779 - INFO  - Training [31][  160/  196]   Loss 0.041819   Top1 98.581543   Top5 99.995117   BatchTime 0.135801   LR 0.001000   
2022-11-04 02:41:32,229 - INFO  - Training [31][  180/  196]   Loss 0.042166   Top1 98.559028   Top5 99.995660   BatchTime 0.134323   LR 0.001000   
2022-11-04 02:41:34,388 - INFO  - ==> Top1: 98.534    Top5: 99.996    Loss: 0.043

2022-11-04 02:41:34,389 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:41:36,968 - INFO  - Validation [31][   20/   40]   Loss 0.428077   Top1 90.039062   Top5 99.609375   BatchTime 0.128883   
2022-11-04 02:41:37,808 - INFO  - Validation [31][   40/   40]   Loss 0.415420   Top1 90.330000   Top5 99.660000   BatchTime 0.085430   
2022-11-04 02:41:38,055 - INFO  - ==> Top1: 90.330    Top5: 99.660    Loss: 0.415

2022-11-04 02:41:38,085 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:41:38,086 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:41:38,086 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:41:38,281 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:41:38,443 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:41:38,444 - INFO  - >>>>>>>> Epoch  32
2022-11-04 02:41:38,444 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:41:42,381 - INFO  - Training [32][   20/  196]   Loss 0.038475   Top1 98.691406   Top5 100.000000   BatchTime 0.196820   LR 0.001000   
2022-11-04 02:41:44,846 - INFO  - Training [32][   40/  196]   Loss 0.038400   Top1 98.681641   Top5 100.000000   BatchTime 0.160033   LR 0.001000   
2022-11-04 02:41:47,315 - INFO  - Training [32][   60/  196]   Loss 0.039097   Top1 98.639323   Top5 100.000000   BatchTime 0.147837   LR 0.001000   
2022-11-04 02:41:49,787 - INFO  - Training [32][   80/  196]   Loss 0.038557   Top1 98.706055   Top5 100.000000   BatchTime 0.141782   LR 0.001000   
2022-11-04 02:41:52,266 - INFO  - Training [32][  100/  196]   Loss 0.040593   Top1 98.621094   Top5 100.000000   BatchTime 0.138215   LR 0.001000   
2022-11-04 02:41:54,736 - INFO  - Training [32][  120/  196]   Loss 0.040699   Top1 98.610026   Top5 99.996745   BatchTime 0.135762   LR 0.001000   
2022-11-04 02:41:57,205 - INFO  - Training [32][  140/  196]   Loss 0.040628   Top1 98.613281   Top5 99.997210   BatchTime 0.134002   LR 0.001000   
2022-11-04 02:41:59,666 - INFO  - Training [32][  160/  196]   Loss 0.040736   Top1 98.608398   Top5 99.997559   BatchTime 0.132631   LR 0.001000   
2022-11-04 02:42:02,129 - INFO  - Training [32][  180/  196]   Loss 0.041515   Top1 98.585069   Top5 99.995660   BatchTime 0.131577   LR 0.001000   
2022-11-04 02:42:04,309 - INFO  - ==> Top1: 98.576    Top5: 99.996    Loss: 0.041

2022-11-04 02:42:04,310 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:42:07,215 - INFO  - Validation [32][   20/   40]   Loss 0.430293   Top1 89.785156   Top5 99.609375   BatchTime 0.145185   
2022-11-04 02:42:08,322 - INFO  - Validation [32][   40/   40]   Loss 0.420866   Top1 90.130000   Top5 99.670000   BatchTime 0.100260   
2022-11-04 02:42:08,571 - INFO  - ==> Top1: 90.130    Top5: 99.670    Loss: 0.421

2022-11-04 02:42:08,605 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:42:08,606 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:42:08,606 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 90.140   Top5: 99.630] Sparsity : 0.888
2022-11-04 02:42:08,698 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:42:08,698 - INFO  - >>>>>>>> Epoch  33
2022-11-04 02:42:08,699 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:42:13,122 - INFO  - Training [33][   20/  196]   Loss 0.038982   Top1 98.710938   Top5 100.000000   BatchTime 0.221139   LR 0.001000   
2022-11-04 02:42:15,600 - INFO  - Training [33][   40/  196]   Loss 0.038553   Top1 98.710938   Top5 100.000000   BatchTime 0.172512   LR 0.001000   
2022-11-04 02:42:18,078 - INFO  - Training [33][   60/  196]   Loss 0.038875   Top1 98.691406   Top5 100.000000   BatchTime 0.156308   LR 0.001000   
2022-11-04 02:42:20,513 - INFO  - Training [33][   80/  196]   Loss 0.039019   Top1 98.657227   Top5 100.000000   BatchTime 0.147666   LR 0.001000   
2022-11-04 02:42:22,979 - INFO  - Training [33][  100/  196]   Loss 0.038702   Top1 98.675781   Top5 99.996094   BatchTime 0.142793   LR 0.001000   
2022-11-04 02:42:25,439 - INFO  - Training [33][  120/  196]   Loss 0.038081   Top1 98.694661   Top5 99.996745   BatchTime 0.139496   LR 0.001000   
2022-11-04 02:42:27,943 - INFO  - Training [33][  140/  196]   Loss 0.038422   Top1 98.663504   Top5 99.997210   BatchTime 0.137451   LR 0.001000   
2022-11-04 02:42:29,671 - INFO  - Training [33][  160/  196]   Loss 0.038655   Top1 98.654785   Top5 99.997559   BatchTime 0.131071   LR 0.001000   
2022-11-04 02:42:31,711 - INFO  - Training [33][  180/  196]   Loss 0.039035   Top1 98.654514   Top5 99.997830   BatchTime 0.127843   LR 0.001000   
2022-11-04 02:42:33,535 - INFO  - ==> Top1: 98.638    Top5: 99.996    Loss: 0.039

2022-11-04 02:42:33,536 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:42:36,172 - INFO  - Validation [33][   20/   40]   Loss 0.432688   Top1 90.175781   Top5 99.628906   BatchTime 0.131740   
2022-11-04 02:42:37,299 - INFO  - Validation [33][   40/   40]   Loss 0.417816   Top1 90.370000   Top5 99.670000   BatchTime 0.094035   
2022-11-04 02:42:37,554 - INFO  - ==> Top1: 90.370    Top5: 99.670    Loss: 0.418

2022-11-04 02:42:37,592 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
2022-11-04 02:42:37,593 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:42:37,593 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.320   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:42:37,781 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:42:37,934 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:42:37,934 - INFO  - >>>>>>>> Epoch  34
2022-11-04 02:42:37,935 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:42:42,642 - INFO  - Training [34][   20/  196]   Loss 0.036086   Top1 98.789062   Top5 100.000000   BatchTime 0.235313   LR 0.001000   
2022-11-04 02:42:45,118 - INFO  - Training [34][   40/  196]   Loss 0.038398   Top1 98.632812   Top5 100.000000   BatchTime 0.179550   LR 0.001000   
2022-11-04 02:42:47,601 - INFO  - Training [34][   60/  196]   Loss 0.038804   Top1 98.658854   Top5 100.000000   BatchTime 0.161089   LR 0.001000   
2022-11-04 02:42:50,075 - INFO  - Training [34][   80/  196]   Loss 0.038656   Top1 98.647461   Top5 100.000000   BatchTime 0.151745   LR 0.001000   
2022-11-04 02:42:52,554 - INFO  - Training [34][  100/  196]   Loss 0.039215   Top1 98.644531   Top5 100.000000   BatchTime 0.146184   LR 0.001000   
2022-11-04 02:42:55,021 - INFO  - Training [34][  120/  196]   Loss 0.038845   Top1 98.671875   Top5 100.000000   BatchTime 0.142377   LR 0.001000   
2022-11-04 02:42:57,492 - INFO  - Training [34][  140/  196]   Loss 0.038956   Top1 98.674665   Top5 100.000000   BatchTime 0.139690   LR 0.001000   
2022-11-04 02:42:59,954 - INFO  - Training [34][  160/  196]   Loss 0.038851   Top1 98.654785   Top5 100.000000   BatchTime 0.137616   LR 0.001000   
2022-11-04 02:43:02,408 - INFO  - Training [34][  180/  196]   Loss 0.038767   Top1 98.661024   Top5 99.997830   BatchTime 0.135957   LR 0.001000   
2022-11-04 02:43:04,583 - INFO  - ==> Top1: 98.662    Top5: 99.998    Loss: 0.039

2022-11-04 02:43:04,584 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:43:07,485 - INFO  - Validation [34][   20/   40]   Loss 0.432835   Top1 90.097656   Top5 99.609375   BatchTime 0.144983   
2022-11-04 02:43:08,577 - INFO  - Validation [34][   40/   40]   Loss 0.423339   Top1 90.330000   Top5 99.640000   BatchTime 0.099794   
2022-11-04 02:43:08,823 - INFO  - ==> Top1: 90.330    Top5: 99.640    Loss: 0.423

2022-11-04 02:43:08,862 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
2022-11-04 02:43:08,863 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:43:08,863 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.330   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:43:08,964 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:43:08,964 - INFO  - >>>>>>>> Epoch  35
2022-11-04 02:43:08,965 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:43:13,399 - INFO  - Training [35][   20/  196]   Loss 0.036716   Top1 98.886719   Top5 100.000000   BatchTime 0.221694   LR 0.001000   
2022-11-04 02:43:15,860 - INFO  - Training [35][   40/  196]   Loss 0.037070   Top1 98.808594   Top5 100.000000   BatchTime 0.172381   LR 0.001000   
2022-11-04 02:43:18,316 - INFO  - Training [35][   60/  196]   Loss 0.038436   Top1 98.678385   Top5 100.000000   BatchTime 0.155845   LR 0.001000   
2022-11-04 02:43:20,776 - INFO  - Training [35][   80/  196]   Loss 0.037323   Top1 98.701172   Top5 100.000000   BatchTime 0.147638   LR 0.001000   
2022-11-04 02:43:22,528 - INFO  - Training [35][  100/  196]   Loss 0.037231   Top1 98.691406   Top5 100.000000   BatchTime 0.135630   LR 0.001000   
2022-11-04 02:43:24,568 - INFO  - Training [35][  120/  196]   Loss 0.037737   Top1 98.678385   Top5 100.000000   BatchTime 0.130018   LR 0.001000   
2022-11-04 02:43:26,590 - INFO  - Training [35][  140/  196]   Loss 0.037926   Top1 98.663504   Top5 100.000000   BatchTime 0.125891   LR 0.001000   
2022-11-04 02:43:28,555 - INFO  - Training [35][  160/  196]   Loss 0.037245   Top1 98.713379   Top5 100.000000   BatchTime 0.122435   LR 0.001000   
2022-11-04 02:43:30,533 - INFO  - Training [35][  180/  196]   Loss 0.037169   Top1 98.723958   Top5 100.000000   BatchTime 0.119817   LR 0.001000   
2022-11-04 02:43:32,700 - INFO  - ==> Top1: 98.716    Top5: 100.000    Loss: 0.037

2022-11-04 02:43:32,701 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:43:35,593 - INFO  - Validation [35][   20/   40]   Loss 0.417452   Top1 90.332031   Top5 99.687500   BatchTime 0.144543   
2022-11-04 02:43:36,695 - INFO  - Validation [35][   40/   40]   Loss 0.411926   Top1 90.490000   Top5 99.660000   BatchTime 0.099802   
2022-11-04 02:43:36,950 - INFO  - ==> Top1: 90.490    Top5: 99.660    Loss: 0.412

2022-11-04 02:43:36,980 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:43:36,981 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
2022-11-04 02:43:36,981 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.330   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:43:37,167 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:43:37,330 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:43:37,330 - INFO  - >>>>>>>> Epoch  36
2022-11-04 02:43:37,331 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:43:41,712 - INFO  - Training [36][   20/  196]   Loss 0.033571   Top1 98.945312   Top5 100.000000   BatchTime 0.219061   LR 0.001000   
2022-11-04 02:43:44,187 - INFO  - Training [36][   40/  196]   Loss 0.034023   Top1 98.906250   Top5 100.000000   BatchTime 0.171408   LR 0.001000   
2022-11-04 02:43:46,667 - INFO  - Training [36][   60/  196]   Loss 0.034011   Top1 98.847656   Top5 100.000000   BatchTime 0.155601   LR 0.001000   
2022-11-04 02:43:49,137 - INFO  - Training [36][   80/  196]   Loss 0.034655   Top1 98.808594   Top5 100.000000   BatchTime 0.147577   LR 0.001000   
2022-11-04 02:43:51,605 - INFO  - Training [36][  100/  196]   Loss 0.034418   Top1 98.832031   Top5 100.000000   BatchTime 0.142740   LR 0.001000   
2022-11-04 02:43:54,068 - INFO  - Training [36][  120/  196]   Loss 0.034378   Top1 98.818359   Top5 100.000000   BatchTime 0.139475   LR 0.001000   
2022-11-04 02:43:56,534 - INFO  - Training [36][  140/  196]   Loss 0.035143   Top1 98.783482   Top5 100.000000   BatchTime 0.137161   LR 0.001000   
2022-11-04 02:43:58,999 - INFO  - Training [36][  160/  196]   Loss 0.035675   Top1 98.767090   Top5 100.000000   BatchTime 0.135423   LR 0.001000   
2022-11-04 02:44:01,463 - INFO  - Training [36][  180/  196]   Loss 0.035850   Top1 98.745660   Top5 100.000000   BatchTime 0.134064   LR 0.001000   
2022-11-04 02:44:03,630 - INFO  - ==> Top1: 98.726    Top5: 100.000    Loss: 0.036

2022-11-04 02:44:03,631 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:44:06,553 - INFO  - Validation [36][   20/   40]   Loss 0.428114   Top1 89.941406   Top5 99.648438   BatchTime 0.146030   
2022-11-04 02:44:07,671 - INFO  - Validation [36][   40/   40]   Loss 0.417463   Top1 90.350000   Top5 99.640000   BatchTime 0.100954   
2022-11-04 02:44:07,934 - INFO  - ==> Top1: 90.350    Top5: 99.640    Loss: 0.417

2022-11-04 02:44:07,967 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:44:07,968 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
2022-11-04 02:44:07,968 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 90.350   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:44:08,075 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:44:08,075 - INFO  - >>>>>>>> Epoch  37
2022-11-04 02:44:08,076 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:44:12,411 - INFO  - Training [37][   20/  196]   Loss 0.039313   Top1 98.750000   Top5 100.000000   BatchTime 0.216739   LR 0.001000   
2022-11-04 02:44:14,183 - INFO  - Training [37][   40/  196]   Loss 0.036524   Top1 98.828125   Top5 100.000000   BatchTime 0.152666   LR 0.001000   
2022-11-04 02:44:16,239 - INFO  - Training [37][   60/  196]   Loss 0.037846   Top1 98.736979   Top5 100.000000   BatchTime 0.136058   LR 0.001000   
2022-11-04 02:44:18,285 - INFO  - Training [37][   80/  196]   Loss 0.037809   Top1 98.750000   Top5 100.000000   BatchTime 0.127618   LR 0.001000   
2022-11-04 02:44:20,255 - INFO  - Training [37][  100/  196]   Loss 0.037266   Top1 98.761719   Top5 99.996094   BatchTime 0.121785   LR 0.001000   
2022-11-04 02:44:22,366 - INFO  - Training [37][  120/  196]   Loss 0.037068   Top1 98.746745   Top5 99.996745   BatchTime 0.119082   LR 0.001000   
2022-11-04 02:44:24,835 - INFO  - Training [37][  140/  196]   Loss 0.036937   Top1 98.755580   Top5 99.997210   BatchTime 0.119706   LR 0.001000   
2022-11-04 02:44:27,309 - INFO  - Training [37][  160/  196]   Loss 0.036593   Top1 98.754883   Top5 99.997559   BatchTime 0.120202   LR 0.001000   
2022-11-04 02:44:29,785 - INFO  - Training [37][  180/  196]   Loss 0.036935   Top1 98.728299   Top5 99.997830   BatchTime 0.120605   LR 0.001000   
2022-11-04 02:44:31,980 - INFO  - ==> Top1: 98.718    Top5: 99.998    Loss: 0.037

2022-11-04 02:44:31,981 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:44:34,902 - INFO  - Validation [37][   20/   40]   Loss 0.432591   Top1 89.980469   Top5 99.628906   BatchTime 0.146041   
2022-11-04 02:44:36,025 - INFO  - Validation [37][   40/   40]   Loss 0.419551   Top1 90.310000   Top5 99.630000   BatchTime 0.101076   
2022-11-04 02:44:36,280 - INFO  - ==> Top1: 90.310    Top5: 99.630    Loss: 0.420

2022-11-04 02:44:36,331 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:44:36,332 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
2022-11-04 02:44:36,332 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 90.350   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:44:36,432 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:44:36,433 - INFO  - >>>>>>>> Epoch  38
2022-11-04 02:44:36,434 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:44:40,899 - INFO  - Training [38][   20/  196]   Loss 0.035312   Top1 98.750000   Top5 100.000000   BatchTime 0.223257   LR 0.001000   
2022-11-04 02:44:43,368 - INFO  - Training [38][   40/  196]   Loss 0.035407   Top1 98.779297   Top5 100.000000   BatchTime 0.173348   LR 0.001000   
2022-11-04 02:44:45,844 - INFO  - Training [38][   60/  196]   Loss 0.035275   Top1 98.710938   Top5 100.000000   BatchTime 0.156846   LR 0.001000   
2022-11-04 02:44:48,317 - INFO  - Training [38][   80/  196]   Loss 0.035468   Top1 98.696289   Top5 99.995117   BatchTime 0.148535   LR 0.001000   
2022-11-04 02:44:50,782 - INFO  - Training [38][  100/  196]   Loss 0.034811   Top1 98.734375   Top5 99.996094   BatchTime 0.143480   LR 0.001000   
2022-11-04 02:44:53,258 - INFO  - Training [38][  120/  196]   Loss 0.035535   Top1 98.714193   Top5 99.996745   BatchTime 0.140198   LR 0.001000   
2022-11-04 02:44:55,730 - INFO  - Training [38][  140/  196]   Loss 0.035680   Top1 98.719308   Top5 99.997210   BatchTime 0.137830   LR 0.001000   
2022-11-04 02:44:58,185 - INFO  - Training [38][  160/  196]   Loss 0.035518   Top1 98.742676   Top5 99.997559   BatchTime 0.135942   LR 0.001000   
2022-11-04 02:45:00,643 - INFO  - Training [38][  180/  196]   Loss 0.035206   Top1 98.752170   Top5 99.997830   BatchTime 0.134496   LR 0.001000   
2022-11-04 02:45:02,797 - INFO  - ==> Top1: 98.736    Top5: 99.998    Loss: 0.036

2022-11-04 02:45:02,797 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:45:05,598 - INFO  - Validation [38][   20/   40]   Loss 0.429448   Top1 90.332031   Top5 99.570312   BatchTime 0.139939   
2022-11-04 02:45:06,290 - INFO  - Validation [38][   40/   40]   Loss 0.416152   Top1 90.510000   Top5 99.610000   BatchTime 0.087277   
2022-11-04 02:45:06,542 - INFO  - ==> Top1: 90.510    Top5: 99.610    Loss: 0.416

2022-11-04 02:45:06,568 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:45:06,569 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:45:06,569 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.370   Top5: 99.670] Sparsity : 0.888
2022-11-04 02:45:06,753 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:45:06,970 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:45:06,970 - INFO  - >>>>>>>> Epoch  39
2022-11-04 02:45:06,971 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:45:11,065 - INFO  - Training [39][   20/  196]   Loss 0.039126   Top1 98.769531   Top5 99.980469   BatchTime 0.204646   LR 0.001000   
2022-11-04 02:45:12,827 - INFO  - Training [39][   40/  196]   Loss 0.036586   Top1 98.779297   Top5 99.990234   BatchTime 0.146387   LR 0.001000   
2022-11-04 02:45:15,229 - INFO  - Training [39][   60/  196]   Loss 0.037295   Top1 98.763021   Top5 99.993490   BatchTime 0.137623   LR 0.001000   
2022-11-04 02:45:17,714 - INFO  - Training [39][   80/  196]   Loss 0.036591   Top1 98.754883   Top5 99.995117   BatchTime 0.134283   LR 0.001000   
2022-11-04 02:45:20,205 - INFO  - Training [39][  100/  196]   Loss 0.036946   Top1 98.742188   Top5 99.996094   BatchTime 0.132337   LR 0.001000   
2022-11-04 02:45:22,685 - INFO  - Training [39][  120/  196]   Loss 0.036074   Top1 98.753255   Top5 99.996745   BatchTime 0.130944   LR 0.001000   
2022-11-04 02:45:25,156 - INFO  - Training [39][  140/  196]   Loss 0.037614   Top1 98.680246   Top5 99.997210   BatchTime 0.129884   LR 0.001000   
2022-11-04 02:45:27,611 - INFO  - Training [39][  160/  196]   Loss 0.037399   Top1 98.696289   Top5 99.997559   BatchTime 0.128995   LR 0.001000   
2022-11-04 02:45:30,080 - INFO  - Training [39][  180/  196]   Loss 0.037615   Top1 98.697917   Top5 99.997830   BatchTime 0.128377   LR 0.001000   
2022-11-04 02:45:32,251 - INFO  - ==> Top1: 98.692    Top5: 99.998    Loss: 0.038

2022-11-04 02:45:32,252 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:45:35,172 - INFO  - Validation [39][   20/   40]   Loss 0.427051   Top1 90.312500   Top5 99.628906   BatchTime 0.145924   
2022-11-04 02:45:36,293 - INFO  - Validation [39][   40/   40]   Loss 0.414187   Top1 90.430000   Top5 99.650000   BatchTime 0.100999   
2022-11-04 02:45:36,553 - INFO  - ==> Top1: 90.430    Top5: 99.650    Loss: 0.414

2022-11-04 02:45:36,590 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:45:36,591 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:45:36,591 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.430   Top5: 99.650] Sparsity : 0.888
2022-11-04 02:45:36,699 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:45:36,699 - INFO  - >>>>>>>> Epoch  40
2022-11-04 02:45:36,700 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:45:41,070 - INFO  - Training [40][   20/  196]   Loss 0.035625   Top1 98.808594   Top5 100.000000   BatchTime 0.218486   LR 0.001000   
2022-11-04 02:45:43,563 - INFO  - Training [40][   40/  196]   Loss 0.037321   Top1 98.720703   Top5 100.000000   BatchTime 0.171557   LR 0.001000   
2022-11-04 02:45:46,044 - INFO  - Training [40][   60/  196]   Loss 0.036226   Top1 98.756510   Top5 100.000000   BatchTime 0.155712   LR 0.001000   
2022-11-04 02:45:48,520 - INFO  - Training [40][   80/  196]   Loss 0.036052   Top1 98.818359   Top5 100.000000   BatchTime 0.147735   LR 0.001000   
2022-11-04 02:45:50,989 - INFO  - Training [40][  100/  196]   Loss 0.036451   Top1 98.796875   Top5 100.000000   BatchTime 0.142885   LR 0.001000   
2022-11-04 02:45:53,463 - INFO  - Training [40][  120/  196]   Loss 0.036586   Top1 98.785807   Top5 100.000000   BatchTime 0.139681   LR 0.001000   
2022-11-04 02:45:55,916 - INFO  - Training [40][  140/  196]   Loss 0.036280   Top1 98.814174   Top5 100.000000   BatchTime 0.137252   LR 0.001000   
2022-11-04 02:45:58,358 - INFO  - Training [40][  160/  196]   Loss 0.035979   Top1 98.847656   Top5 99.997559   BatchTime 0.135356   LR 0.001000   
2022-11-04 02:46:00,312 - INFO  - Training [40][  180/  196]   Loss 0.035763   Top1 98.856337   Top5 99.997830   BatchTime 0.131171   LR 0.001000   
2022-11-04 02:46:02,109 - INFO  - ==> Top1: 98.860    Top5: 99.998    Loss: 0.036

2022-11-04 02:46:02,109 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:46:04,702 - INFO  - Validation [40][   20/   40]   Loss 0.427918   Top1 90.234375   Top5 99.609375   BatchTime 0.129558   
2022-11-04 02:46:05,384 - INFO  - Validation [40][   40/   40]   Loss 0.419334   Top1 90.470000   Top5 99.650000   BatchTime 0.081835   
2022-11-04 02:46:05,639 - INFO  - ==> Top1: 90.470    Top5: 99.650    Loss: 0.419

2022-11-04 02:46:05,664 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:46:05,665 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:46:05,665 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 90.470   Top5: 99.650] Sparsity : 0.888
2022-11-04 02:46:05,757 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:46:05,757 - INFO  - >>>>>>>> Epoch  41
2022-11-04 02:46:05,759 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:46:10,256 - INFO  - Training [41][   20/  196]   Loss 0.034707   Top1 98.808594   Top5 100.000000   BatchTime 0.224879   LR 0.001000   
2022-11-04 02:46:12,720 - INFO  - Training [41][   40/  196]   Loss 0.033618   Top1 98.828125   Top5 100.000000   BatchTime 0.174042   LR 0.001000   
2022-11-04 02:46:15,183 - INFO  - Training [41][   60/  196]   Loss 0.037113   Top1 98.606771   Top5 100.000000   BatchTime 0.157072   LR 0.001000   
2022-11-04 02:46:17,667 - INFO  - Training [41][   80/  196]   Loss 0.036441   Top1 98.686523   Top5 100.000000   BatchTime 0.148857   LR 0.001000   
2022-11-04 02:46:20,142 - INFO  - Training [41][  100/  196]   Loss 0.035503   Top1 98.761719   Top5 100.000000   BatchTime 0.143830   LR 0.001000   
2022-11-04 02:46:22,622 - INFO  - Training [41][  120/  196]   Loss 0.035816   Top1 98.756510   Top5 100.000000   BatchTime 0.140526   LR 0.001000   
2022-11-04 02:46:25,088 - INFO  - Training [41][  140/  196]   Loss 0.036097   Top1 98.755580   Top5 100.000000   BatchTime 0.138061   LR 0.001000   
2022-11-04 02:46:27,538 - INFO  - Training [41][  160/  196]   Loss 0.036674   Top1 98.740234   Top5 100.000000   BatchTime 0.136118   LR 0.001000   
2022-11-04 02:46:30,000 - INFO  - Training [41][  180/  196]   Loss 0.036959   Top1 98.756510   Top5 100.000000   BatchTime 0.134674   LR 0.001000   
2022-11-04 02:46:32,164 - INFO  - ==> Top1: 98.748    Top5: 100.000    Loss: 0.037

2022-11-04 02:46:32,164 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:46:35,068 - INFO  - Validation [41][   20/   40]   Loss 0.426380   Top1 90.156250   Top5 99.589844   BatchTime 0.145088   
2022-11-04 02:46:36,175 - INFO  - Validation [41][   40/   40]   Loss 0.414595   Top1 90.390000   Top5 99.610000   BatchTime 0.100216   
2022-11-04 02:46:36,434 - INFO  - ==> Top1: 90.390    Top5: 99.610    Loss: 0.415

2022-11-04 02:46:36,475 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:46:36,476 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:46:36,476 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 90.470   Top5: 99.650] Sparsity : 0.888
2022-11-04 02:46:36,581 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:46:36,582 - INFO  - >>>>>>>> Epoch  42
2022-11-04 02:46:36,583 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:46:40,975 - INFO  - Training [42][   20/  196]   Loss 0.029607   Top1 99.042969   Top5 100.000000   BatchTime 0.219568   LR 0.001000   
2022-11-04 02:46:43,462 - INFO  - Training [42][   40/  196]   Loss 0.031938   Top1 98.994141   Top5 100.000000   BatchTime 0.171973   LR 0.001000   
2022-11-04 02:46:45,919 - INFO  - Training [42][   60/  196]   Loss 0.032988   Top1 98.925781   Top5 100.000000   BatchTime 0.155602   LR 0.001000   
2022-11-04 02:46:48,472 - INFO  - Training [42][   80/  196]   Loss 0.033090   Top1 98.930664   Top5 100.000000   BatchTime 0.148613   LR 0.001000   
2022-11-04 02:46:50,966 - INFO  - Training [42][  100/  196]   Loss 0.033095   Top1 98.925781   Top5 100.000000   BatchTime 0.143829   LR 0.001000   
2022-11-04 02:46:52,746 - INFO  - Training [42][  120/  196]   Loss 0.033700   Top1 98.899740   Top5 100.000000   BatchTime 0.134684   LR 0.001000   
2022-11-04 02:46:54,782 - INFO  - Training [42][  140/  196]   Loss 0.033498   Top1 98.903460   Top5 100.000000   BatchTime 0.129989   LR 0.001000   
2022-11-04 02:46:56,783 - INFO  - Training [42][  160/  196]   Loss 0.033724   Top1 98.869629   Top5 100.000000   BatchTime 0.126250   LR 0.001000   
2022-11-04 02:46:58,771 - INFO  - Training [42][  180/  196]   Loss 0.033700   Top1 98.865017   Top5 100.000000   BatchTime 0.123264   LR 0.001000   
2022-11-04 02:47:00,465 - INFO  - ==> Top1: 98.844    Top5: 100.000    Loss: 0.034

2022-11-04 02:47:00,466 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:47:03,344 - INFO  - Validation [42][   20/   40]   Loss 0.423782   Top1 90.117188   Top5 99.570312   BatchTime 0.143830   
2022-11-04 02:47:04,435 - INFO  - Validation [42][   40/   40]   Loss 0.415140   Top1 90.530000   Top5 99.620000   BatchTime 0.099176   
2022-11-04 02:47:04,698 - INFO  - ==> Top1: 90.530    Top5: 99.620    Loss: 0.415

2022-11-04 02:47:04,741 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:47:04,742 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:47:04,742 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:47:04,929 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:47:05,082 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:47:05,083 - INFO  - >>>>>>>> Epoch  43
2022-11-04 02:47:05,084 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:47:09,463 - INFO  - Training [43][   20/  196]   Loss 0.038046   Top1 98.730469   Top5 100.000000   BatchTime 0.218926   LR 0.001000   
2022-11-04 02:47:11,940 - INFO  - Training [43][   40/  196]   Loss 0.036873   Top1 98.710938   Top5 100.000000   BatchTime 0.171399   LR 0.001000   
2022-11-04 02:47:14,411 - INFO  - Training [43][   60/  196]   Loss 0.037501   Top1 98.763021   Top5 100.000000   BatchTime 0.155448   LR 0.001000   
2022-11-04 02:47:16,881 - INFO  - Training [43][   80/  196]   Loss 0.036929   Top1 98.750000   Top5 100.000000   BatchTime 0.147459   LR 0.001000   
2022-11-04 02:47:19,360 - INFO  - Training [43][  100/  196]   Loss 0.036020   Top1 98.777344   Top5 100.000000   BatchTime 0.142754   LR 0.001000   
2022-11-04 02:47:21,834 - INFO  - Training [43][  120/  196]   Loss 0.035513   Top1 98.811849   Top5 100.000000   BatchTime 0.139580   LR 0.001000   
2022-11-04 02:47:24,301 - INFO  - Training [43][  140/  196]   Loss 0.035230   Top1 98.828125   Top5 100.000000   BatchTime 0.137258   LR 0.001000   
2022-11-04 02:47:26,764 - INFO  - Training [43][  160/  196]   Loss 0.034985   Top1 98.847656   Top5 100.000000   BatchTime 0.135494   LR 0.001000   
2022-11-04 02:47:29,216 - INFO  - Training [43][  180/  196]   Loss 0.035296   Top1 98.832465   Top5 99.997830   BatchTime 0.134060   LR 0.001000   
2022-11-04 02:47:31,399 - INFO  - ==> Top1: 98.832    Top5: 99.998    Loss: 0.036

2022-11-04 02:47:31,400 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:47:34,265 - INFO  - Validation [43][   20/   40]   Loss 0.429719   Top1 90.097656   Top5 99.570312   BatchTime 0.143208   
2022-11-04 02:47:35,389 - INFO  - Validation [43][   40/   40]   Loss 0.417351   Top1 90.430000   Top5 99.600000   BatchTime 0.099695   
2022-11-04 02:47:35,642 - INFO  - ==> Top1: 90.430    Top5: 99.600    Loss: 0.417

2022-11-04 02:47:35,680 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:47:35,681 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:47:35,681 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:47:35,791 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:47:35,791 - INFO  - >>>>>>>> Epoch  44
2022-11-04 02:47:35,792 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:47:40,153 - INFO  - Training [44][   20/  196]   Loss 0.038610   Top1 98.710938   Top5 100.000000   BatchTime 0.218011   LR 0.001000   
2022-11-04 02:47:42,631 - INFO  - Training [44][   40/  196]   Loss 0.036103   Top1 98.837891   Top5 100.000000   BatchTime 0.170953   LR 0.001000   
2022-11-04 02:47:44,535 - INFO  - Training [44][   60/  196]   Loss 0.036288   Top1 98.769531   Top5 100.000000   BatchTime 0.145716   LR 0.001000   
2022-11-04 02:47:46,595 - INFO  - Training [44][   80/  196]   Loss 0.034953   Top1 98.842773   Top5 100.000000   BatchTime 0.135036   LR 0.001000   
2022-11-04 02:47:48,666 - INFO  - Training [44][  100/  196]   Loss 0.035522   Top1 98.843750   Top5 100.000000   BatchTime 0.128735   LR 0.001000   
2022-11-04 02:47:50,709 - INFO  - Training [44][  120/  196]   Loss 0.034328   Top1 98.876953   Top5 100.000000   BatchTime 0.124300   LR 0.001000   
2022-11-04 02:47:52,674 - INFO  - Training [44][  140/  196]   Loss 0.034351   Top1 98.864397   Top5 100.000000   BatchTime 0.120578   LR 0.001000   
2022-11-04 02:47:55,138 - INFO  - Training [44][  160/  196]   Loss 0.034051   Top1 98.869629   Top5 100.000000   BatchTime 0.120907   LR 0.001000   
2022-11-04 02:47:57,605 - INFO  - Training [44][  180/  196]   Loss 0.034436   Top1 98.869358   Top5 100.000000   BatchTime 0.121182   LR 0.001000   
2022-11-04 02:47:59,773 - INFO  - ==> Top1: 98.886    Top5: 100.000    Loss: 0.034

2022-11-04 02:47:59,774 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:48:02,575 - INFO  - Validation [44][   20/   40]   Loss 0.433240   Top1 89.941406   Top5 99.570312   BatchTime 0.140021   
2022-11-04 02:48:03,695 - INFO  - Validation [44][   40/   40]   Loss 0.418161   Top1 90.290000   Top5 99.620000   BatchTime 0.098016   
2022-11-04 02:48:03,950 - INFO  - ==> Top1: 90.290    Top5: 99.620    Loss: 0.418

2022-11-04 02:48:03,983 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:48:03,984 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:48:03,984 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:48:04,097 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:48:04,098 - INFO  - >>>>>>>> Epoch  45
2022-11-04 02:48:04,099 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:48:08,490 - INFO  - Training [45][   20/  196]   Loss 0.034178   Top1 98.964844   Top5 100.000000   BatchTime 0.219573   LR 0.001000   
2022-11-04 02:48:10,956 - INFO  - Training [45][   40/  196]   Loss 0.033718   Top1 98.867188   Top5 100.000000   BatchTime 0.171439   LR 0.001000   
2022-11-04 02:48:13,421 - INFO  - Training [45][   60/  196]   Loss 0.034892   Top1 98.808594   Top5 100.000000   BatchTime 0.155369   LR 0.001000   
2022-11-04 02:48:15,890 - INFO  - Training [45][   80/  196]   Loss 0.034586   Top1 98.842773   Top5 100.000000   BatchTime 0.147382   LR 0.001000   
2022-11-04 02:48:18,387 - INFO  - Training [45][  100/  196]   Loss 0.034015   Top1 98.878906   Top5 100.000000   BatchTime 0.142884   LR 0.001000   
2022-11-04 02:48:20,888 - INFO  - Training [45][  120/  196]   Loss 0.033448   Top1 98.886719   Top5 100.000000   BatchTime 0.139912   LR 0.001000   
2022-11-04 02:48:23,353 - INFO  - Training [45][  140/  196]   Loss 0.033707   Top1 98.867188   Top5 100.000000   BatchTime 0.137530   LR 0.001000   
2022-11-04 02:48:25,816 - INFO  - Training [45][  160/  196]   Loss 0.034127   Top1 98.857422   Top5 100.000000   BatchTime 0.135733   LR 0.001000   
2022-11-04 02:48:28,276 - INFO  - Training [45][  180/  196]   Loss 0.033998   Top1 98.871528   Top5 100.000000   BatchTime 0.134313   LR 0.001000   
2022-11-04 02:48:30,439 - INFO  - ==> Top1: 98.852    Top5: 100.000    Loss: 0.034

2022-11-04 02:48:30,440 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:48:33,336 - INFO  - Validation [45][   20/   40]   Loss 0.427845   Top1 90.136719   Top5 99.570312   BatchTime 0.144700   
2022-11-04 02:48:34,459 - INFO  - Validation [45][   40/   40]   Loss 0.416760   Top1 90.360000   Top5 99.610000   BatchTime 0.100427   
2022-11-04 02:48:34,718 - INFO  - ==> Top1: 90.360    Top5: 99.610    Loss: 0.417

2022-11-04 02:48:34,747 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:48:34,747 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:48:34,747 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.490   Top5: 99.660] Sparsity : 0.888
2022-11-04 02:48:34,852 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:48:34,852 - INFO  - >>>>>>>> Epoch  46
2022-11-04 02:48:34,853 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:48:38,912 - INFO  - Training [46][   20/  196]   Loss 0.032894   Top1 98.867188   Top5 100.000000   BatchTime 0.202936   LR 0.001000   
2022-11-04 02:48:40,968 - INFO  - Training [46][   40/  196]   Loss 0.034938   Top1 98.779297   Top5 100.000000   BatchTime 0.152864   LR 0.001000   
2022-11-04 02:48:43,101 - INFO  - Training [46][   60/  196]   Loss 0.035603   Top1 98.769531   Top5 100.000000   BatchTime 0.137468   LR 0.001000   
2022-11-04 02:48:44,800 - INFO  - Training [46][   80/  196]   Loss 0.033995   Top1 98.867188   Top5 100.000000   BatchTime 0.124330   LR 0.001000   
2022-11-04 02:48:47,298 - INFO  - Training [46][  100/  196]   Loss 0.033286   Top1 98.894531   Top5 100.000000   BatchTime 0.124450   LR 0.001000   
2022-11-04 02:48:49,867 - INFO  - Training [46][  120/  196]   Loss 0.034111   Top1 98.847656   Top5 100.000000   BatchTime 0.125113   LR 0.001000   
2022-11-04 02:48:52,329 - INFO  - Training [46][  140/  196]   Loss 0.033801   Top1 98.875558   Top5 100.000000   BatchTime 0.124823   LR 0.001000   
2022-11-04 02:48:54,787 - INFO  - Training [46][  160/  196]   Loss 0.034395   Top1 98.862305   Top5 100.000000   BatchTime 0.124586   LR 0.001000   
2022-11-04 02:48:57,243 - INFO  - Training [46][  180/  196]   Loss 0.033824   Top1 98.897569   Top5 100.000000   BatchTime 0.124388   LR 0.001000   
2022-11-04 02:48:59,402 - INFO  - ==> Top1: 98.890    Top5: 100.000    Loss: 0.034

2022-11-04 02:48:59,403 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:49:02,287 - INFO  - Validation [46][   20/   40]   Loss 0.428832   Top1 90.195312   Top5 99.453125   BatchTime 0.144190   
2022-11-04 02:49:03,407 - INFO  - Validation [46][   40/   40]   Loss 0.418967   Top1 90.500000   Top5 99.550000   BatchTime 0.100080   
2022-11-04 02:49:03,655 - INFO  - ==> Top1: 90.500    Top5: 99.550    Loss: 0.419

2022-11-04 02:49:03,693 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:49:03,694 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:49:03,694 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
2022-11-04 02:49:03,805 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:49:03,805 - INFO  - >>>>>>>> Epoch  47
2022-11-04 02:49:03,807 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:49:08,215 - INFO  - Training [47][   20/  196]   Loss 0.034038   Top1 98.925781   Top5 100.000000   BatchTime 0.220422   LR 0.001000   
2022-11-04 02:49:10,703 - INFO  - Training [47][   40/  196]   Loss 0.032181   Top1 98.994141   Top5 100.000000   BatchTime 0.172401   LR 0.001000   
2022-11-04 02:49:13,171 - INFO  - Training [47][   60/  196]   Loss 0.034337   Top1 98.906250   Top5 100.000000   BatchTime 0.156069   LR 0.001000   
2022-11-04 02:49:15,650 - INFO  - Training [47][   80/  196]   Loss 0.035614   Top1 98.847656   Top5 100.000000   BatchTime 0.148035   LR 0.001000   
2022-11-04 02:49:18,132 - INFO  - Training [47][  100/  196]   Loss 0.036313   Top1 98.828125   Top5 99.996094   BatchTime 0.143246   LR 0.001000   
2022-11-04 02:49:20,627 - INFO  - Training [47][  120/  196]   Loss 0.035427   Top1 98.854167   Top5 99.996745   BatchTime 0.140167   LR 0.001000   
2022-11-04 02:49:23,090 - INFO  - Training [47][  140/  196]   Loss 0.035042   Top1 98.847656   Top5 99.997210   BatchTime 0.137735   LR 0.001000   
2022-11-04 02:49:25,541 - INFO  - Training [47][  160/  196]   Loss 0.035223   Top1 98.833008   Top5 99.997559   BatchTime 0.135833   LR 0.001000   
2022-11-04 02:49:27,990 - INFO  - Training [47][  180/  196]   Loss 0.035374   Top1 98.810764   Top5 99.997830   BatchTime 0.134347   LR 0.001000   
2022-11-04 02:49:30,151 - INFO  - ==> Top1: 98.808    Top5: 99.998    Loss: 0.035

2022-11-04 02:49:30,152 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:49:32,931 - INFO  - Validation [47][   20/   40]   Loss 0.441276   Top1 89.882812   Top5 99.511719   BatchTime 0.138929   
2022-11-04 02:49:33,784 - INFO  - Validation [47][   40/   40]   Loss 0.422306   Top1 90.340000   Top5 99.560000   BatchTime 0.090778   
2022-11-04 02:49:34,031 - INFO  - ==> Top1: 90.340    Top5: 99.560    Loss: 0.422

2022-11-04 02:49:34,059 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:49:34,060 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:49:34,060 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
2022-11-04 02:49:34,169 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:49:34,169 - INFO  - >>>>>>>> Epoch  48
2022-11-04 02:49:34,171 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:49:38,297 - INFO  - Training [48][   20/  196]   Loss 0.036459   Top1 98.710938   Top5 100.000000   BatchTime 0.206307   LR 0.001000   
2022-11-04 02:49:40,777 - INFO  - Training [48][   40/  196]   Loss 0.034487   Top1 98.789062   Top5 99.990234   BatchTime 0.165146   LR 0.001000   
2022-11-04 02:49:43,248 - INFO  - Training [48][   60/  196]   Loss 0.033861   Top1 98.802083   Top5 99.993490   BatchTime 0.151285   LR 0.001000   
2022-11-04 02:49:45,718 - INFO  - Training [48][   80/  196]   Loss 0.033111   Top1 98.837891   Top5 99.995117   BatchTime 0.144330   LR 0.001000   
2022-11-04 02:49:48,192 - INFO  - Training [48][  100/  196]   Loss 0.033956   Top1 98.828125   Top5 99.996094   BatchTime 0.140208   LR 0.001000   
2022-11-04 02:49:50,673 - INFO  - Training [48][  120/  196]   Loss 0.033603   Top1 98.860677   Top5 99.996745   BatchTime 0.137513   LR 0.001000   
2022-11-04 02:49:53,097 - INFO  - Training [48][  140/  196]   Loss 0.034178   Top1 98.839286   Top5 99.997210   BatchTime 0.135181   LR 0.001000   
2022-11-04 02:49:55,555 - INFO  - Training [48][  160/  196]   Loss 0.034086   Top1 98.833008   Top5 99.997559   BatchTime 0.133648   LR 0.001000   
2022-11-04 02:49:58,012 - INFO  - Training [48][  180/  196]   Loss 0.033982   Top1 98.823785   Top5 99.997830   BatchTime 0.132448   LR 0.001000   
2022-11-04 02:50:00,187 - INFO  - ==> Top1: 98.818    Top5: 99.998    Loss: 0.034

2022-11-04 02:50:00,188 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:50:03,054 - INFO  - Validation [48][   20/   40]   Loss 0.433363   Top1 89.960938   Top5 99.609375   BatchTime 0.143200   
2022-11-04 02:50:04,159 - INFO  - Validation [48][   40/   40]   Loss 0.417968   Top1 90.450000   Top5 99.630000   BatchTime 0.099225   
2022-11-04 02:50:04,417 - INFO  - ==> Top1: 90.450    Top5: 99.630    Loss: 0.418

2022-11-04 02:50:04,445 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:50:04,446 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:50:04,446 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
2022-11-04 02:50:04,566 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:50:04,567 - INFO  - >>>>>>>> Epoch  49
2022-11-04 02:50:04,568 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:50:08,933 - INFO  - Training [49][   20/  196]   Loss 0.029920   Top1 99.121094   Top5 100.000000   BatchTime 0.218240   LR 0.001000   
2022-11-04 02:50:11,407 - INFO  - Training [49][   40/  196]   Loss 0.033410   Top1 98.886719   Top5 100.000000   BatchTime 0.170955   LR 0.001000   
2022-11-04 02:50:13,871 - INFO  - Training [49][   60/  196]   Loss 0.032545   Top1 98.860677   Top5 100.000000   BatchTime 0.155036   LR 0.001000   
2022-11-04 02:50:16,364 - INFO  - Training [49][   80/  196]   Loss 0.032542   Top1 98.896484   Top5 100.000000   BatchTime 0.147438   LR 0.001000   
2022-11-04 02:50:18,831 - INFO  - Training [49][  100/  196]   Loss 0.032515   Top1 98.914062   Top5 100.000000   BatchTime 0.142629   LR 0.001000   
2022-11-04 02:50:21,295 - INFO  - Training [49][  120/  196]   Loss 0.033092   Top1 98.896484   Top5 100.000000   BatchTime 0.139389   LR 0.001000   
2022-11-04 02:50:23,710 - INFO  - Training [49][  140/  196]   Loss 0.033083   Top1 98.900670   Top5 100.000000   BatchTime 0.136725   LR 0.001000   
2022-11-04 02:50:25,482 - INFO  - Training [49][  160/  196]   Loss 0.032951   Top1 98.918457   Top5 100.000000   BatchTime 0.130707   LR 0.001000   
2022-11-04 02:50:27,501 - INFO  - Training [49][  180/  196]   Loss 0.033473   Top1 98.901910   Top5 100.000000   BatchTime 0.127399   LR 0.001000   
2022-11-04 02:50:29,342 - INFO  - ==> Top1: 98.872    Top5: 100.000    Loss: 0.034

2022-11-04 02:50:29,343 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:50:32,051 - INFO  - Validation [49][   20/   40]   Loss 0.435246   Top1 89.960938   Top5 99.609375   BatchTime 0.135337   
2022-11-04 02:50:33,129 - INFO  - Validation [49][   40/   40]   Loss 0.420567   Top1 90.300000   Top5 99.650000   BatchTime 0.094630   
2022-11-04 02:50:33,382 - INFO  - ==> Top1: 90.300    Top5: 99.650    Loss: 0.421

2022-11-04 02:50:33,428 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:50:33,429 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:50:33,429 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 90.500   Top5: 99.550] Sparsity : 0.888
2022-11-04 02:50:33,532 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:50:33,532 - INFO  - >>>>>>>> Epoch  50
2022-11-04 02:50:33,534 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:50:37,946 - INFO  - Training [50][   20/  196]   Loss 0.029610   Top1 98.964844   Top5 100.000000   BatchTime 0.220593   LR 0.001000   
2022-11-04 02:50:40,416 - INFO  - Training [50][   40/  196]   Loss 0.032696   Top1 98.876953   Top5 100.000000   BatchTime 0.172046   LR 0.001000   
2022-11-04 02:50:42,909 - INFO  - Training [50][   60/  196]   Loss 0.031654   Top1 98.964844   Top5 100.000000   BatchTime 0.156259   LR 0.001000   
2022-11-04 02:50:45,378 - INFO  - Training [50][   80/  196]   Loss 0.032392   Top1 98.945312   Top5 100.000000   BatchTime 0.148052   LR 0.001000   
2022-11-04 02:50:47,846 - INFO  - Training [50][  100/  196]   Loss 0.032925   Top1 98.925781   Top5 100.000000   BatchTime 0.143123   LR 0.001000   
2022-11-04 02:50:50,322 - INFO  - Training [50][  120/  196]   Loss 0.032685   Top1 98.929036   Top5 100.000000   BatchTime 0.139902   LR 0.001000   
2022-11-04 02:50:52,794 - INFO  - Training [50][  140/  196]   Loss 0.032340   Top1 98.925781   Top5 100.000000   BatchTime 0.137574   LR 0.001000   
2022-11-04 02:50:55,260 - INFO  - Training [50][  160/  196]   Loss 0.032880   Top1 98.881836   Top5 100.000000   BatchTime 0.135788   LR 0.001000   
2022-11-04 02:50:57,795 - INFO  - Training [50][  180/  196]   Loss 0.033073   Top1 98.867188   Top5 100.000000   BatchTime 0.134780   LR 0.001000   
2022-11-04 02:50:59,972 - INFO  - ==> Top1: 98.858    Top5: 99.998    Loss: 0.033

2022-11-04 02:50:59,972 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:51:02,838 - INFO  - Validation [50][   20/   40]   Loss 0.423570   Top1 90.253906   Top5 99.492188   BatchTime 0.143182   
2022-11-04 02:51:03,934 - INFO  - Validation [50][   40/   40]   Loss 0.413712   Top1 90.630000   Top5 99.560000   BatchTime 0.099001   
2022-11-04 02:51:04,186 - INFO  - ==> Top1: 90.630    Top5: 99.560    Loss: 0.414

2022-11-04 02:51:04,232 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:51:04,233 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:51:04,233 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:51:04,402 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:51:04,554 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:51:04,554 - INFO  - >>>>>>>> Epoch  51
2022-11-04 02:51:04,556 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:51:08,953 - INFO  - Training [51][   20/  196]   Loss 0.027245   Top1 99.062500   Top5 100.000000   BatchTime 0.219847   LR 0.001000   
2022-11-04 02:51:11,421 - INFO  - Training [51][   40/  196]   Loss 0.028934   Top1 99.023438   Top5 100.000000   BatchTime 0.171612   LR 0.001000   
2022-11-04 02:51:13,880 - INFO  - Training [51][   60/  196]   Loss 0.030242   Top1 98.958333   Top5 100.000000   BatchTime 0.155396   LR 0.001000   
2022-11-04 02:51:16,365 - INFO  - Training [51][   80/  196]   Loss 0.029842   Top1 98.964844   Top5 100.000000   BatchTime 0.147610   LR 0.001000   
2022-11-04 02:51:18,115 - INFO  - Training [51][  100/  196]   Loss 0.030265   Top1 98.949219   Top5 100.000000   BatchTime 0.135587   LR 0.001000   
2022-11-04 02:51:20,178 - INFO  - Training [51][  120/  196]   Loss 0.030963   Top1 98.922526   Top5 100.000000   BatchTime 0.130182   LR 0.001000   
2022-11-04 02:51:22,199 - INFO  - Training [51][  140/  196]   Loss 0.030824   Top1 98.936942   Top5 100.000000   BatchTime 0.126022   LR 0.001000   
2022-11-04 02:51:24,135 - INFO  - Training [51][  160/  196]   Loss 0.031076   Top1 98.920898   Top5 100.000000   BatchTime 0.122364   LR 0.001000   
2022-11-04 02:51:26,114 - INFO  - Training [51][  180/  196]   Loss 0.031273   Top1 98.921441   Top5 100.000000   BatchTime 0.119764   LR 0.001000   
2022-11-04 02:51:28,299 - INFO  - ==> Top1: 98.900    Top5: 100.000    Loss: 0.032

2022-11-04 02:51:28,300 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:51:31,186 - INFO  - Validation [51][   20/   40]   Loss 0.431651   Top1 90.058594   Top5 99.609375   BatchTime 0.144213   
2022-11-04 02:51:32,286 - INFO  - Validation [51][   40/   40]   Loss 0.420282   Top1 90.480000   Top5 99.610000   BatchTime 0.099593   
2022-11-04 02:51:32,538 - INFO  - ==> Top1: 90.480    Top5: 99.610    Loss: 0.420

2022-11-04 02:51:32,583 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:51:32,584 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:51:32,584 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:51:32,688 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:51:32,688 - INFO  - >>>>>>>> Epoch  52
2022-11-04 02:51:32,690 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:51:37,112 - INFO  - Training [52][   20/  196]   Loss 0.035323   Top1 98.769531   Top5 99.980469   BatchTime 0.221087   LR 0.001000   
2022-11-04 02:51:39,585 - INFO  - Training [52][   40/  196]   Loss 0.033970   Top1 98.876953   Top5 99.990234   BatchTime 0.172386   LR 0.001000   
2022-11-04 02:51:42,052 - INFO  - Training [52][   60/  196]   Loss 0.034453   Top1 98.860677   Top5 99.993490   BatchTime 0.156036   LR 0.001000   
2022-11-04 02:51:44,532 - INFO  - Training [52][   80/  196]   Loss 0.033549   Top1 98.901367   Top5 99.995117   BatchTime 0.148027   LR 0.001000   
2022-11-04 02:51:46,971 - INFO  - Training [52][  100/  196]   Loss 0.033653   Top1 98.871094   Top5 99.996094   BatchTime 0.142809   LR 0.001000   
2022-11-04 02:51:49,443 - INFO  - Training [52][  120/  196]   Loss 0.033687   Top1 98.850911   Top5 99.996745   BatchTime 0.139609   LR 0.001000   
2022-11-04 02:51:51,906 - INFO  - Training [52][  140/  196]   Loss 0.033573   Top1 98.858817   Top5 99.997210   BatchTime 0.137255   LR 0.001000   
2022-11-04 02:51:54,354 - INFO  - Training [52][  160/  196]   Loss 0.033659   Top1 98.854980   Top5 99.997559   BatchTime 0.135398   LR 0.001000   
2022-11-04 02:51:56,812 - INFO  - Training [52][  180/  196]   Loss 0.034008   Top1 98.819444   Top5 99.997830   BatchTime 0.134010   LR 0.001000   
2022-11-04 02:51:58,982 - INFO  - ==> Top1: 98.818    Top5: 99.998    Loss: 0.034

2022-11-04 02:51:58,983 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:52:01,855 - INFO  - Validation [52][   20/   40]   Loss 0.428578   Top1 89.902344   Top5 99.570312   BatchTime 0.143486   
2022-11-04 02:52:02,984 - INFO  - Validation [52][   40/   40]   Loss 0.419319   Top1 90.320000   Top5 99.620000   BatchTime 0.099973   
2022-11-04 02:52:03,229 - INFO  - ==> Top1: 90.320    Top5: 99.620    Loss: 0.419

2022-11-04 02:52:03,257 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:52:03,258 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:52:03,258 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:52:03,364 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:52:03,364 - INFO  - >>>>>>>> Epoch  53
2022-11-04 02:52:03,365 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:52:07,707 - INFO  - Training [53][   20/  196]   Loss 0.030026   Top1 98.945312   Top5 100.000000   BatchTime 0.217097   LR 0.001000   
2022-11-04 02:52:09,664 - INFO  - Training [53][   40/  196]   Loss 0.029122   Top1 99.062500   Top5 100.000000   BatchTime 0.157484   LR 0.001000   
2022-11-04 02:52:11,668 - INFO  - Training [53][   60/  196]   Loss 0.031542   Top1 98.951823   Top5 100.000000   BatchTime 0.138391   LR 0.001000   
2022-11-04 02:52:13,705 - INFO  - Training [53][   80/  196]   Loss 0.032859   Top1 98.867188   Top5 100.000000   BatchTime 0.129246   LR 0.001000   
2022-11-04 02:52:15,764 - INFO  - Training [53][  100/  196]   Loss 0.032767   Top1 98.863281   Top5 100.000000   BatchTime 0.123990   LR 0.001000   
2022-11-04 02:52:17,470 - INFO  - Training [53][  120/  196]   Loss 0.031802   Top1 98.889974   Top5 100.000000   BatchTime 0.117542   LR 0.001000   
2022-11-04 02:52:20,014 - INFO  - Training [53][  140/  196]   Loss 0.031609   Top1 98.869978   Top5 100.000000   BatchTime 0.118923   LR 0.001000   
2022-11-04 02:52:22,472 - INFO  - Training [53][  160/  196]   Loss 0.032095   Top1 98.852539   Top5 99.997559   BatchTime 0.119419   LR 0.001000   
2022-11-04 02:52:24,929 - INFO  - Training [53][  180/  196]   Loss 0.032287   Top1 98.847656   Top5 99.997830   BatchTime 0.119797   LR 0.001000   
2022-11-04 02:52:27,100 - INFO  - ==> Top1: 98.830    Top5: 99.998    Loss: 0.033

2022-11-04 02:52:27,101 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:52:29,979 - INFO  - Validation [53][   20/   40]   Loss 0.428238   Top1 90.136719   Top5 99.550781   BatchTime 0.143858   
2022-11-04 02:52:31,078 - INFO  - Validation [53][   40/   40]   Loss 0.422203   Top1 90.500000   Top5 99.610000   BatchTime 0.099400   
2022-11-04 02:52:31,320 - INFO  - ==> Top1: 90.500    Top5: 99.610    Loss: 0.422

2022-11-04 02:52:31,362 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:52:31,363 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:52:31,363 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:52:31,470 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:52:31,470 - INFO  - >>>>>>>> Epoch  54
2022-11-04 02:52:31,471 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:52:35,808 - INFO  - Training [54][   20/  196]   Loss 0.034896   Top1 98.710938   Top5 100.000000   BatchTime 0.216822   LR 0.001000   
2022-11-04 02:52:38,277 - INFO  - Training [54][   40/  196]   Loss 0.032974   Top1 98.847656   Top5 100.000000   BatchTime 0.170130   LR 0.001000   
2022-11-04 02:52:40,748 - INFO  - Training [54][   60/  196]   Loss 0.032466   Top1 98.873698   Top5 100.000000   BatchTime 0.154605   LR 0.001000   
2022-11-04 02:52:43,244 - INFO  - Training [54][   80/  196]   Loss 0.031730   Top1 98.916016   Top5 100.000000   BatchTime 0.147157   LR 0.001000   
2022-11-04 02:52:45,710 - INFO  - Training [54][  100/  196]   Loss 0.032582   Top1 98.882812   Top5 100.000000   BatchTime 0.142378   LR 0.001000   
2022-11-04 02:52:48,178 - INFO  - Training [54][  120/  196]   Loss 0.032141   Top1 98.893229   Top5 99.996745   BatchTime 0.139218   LR 0.001000   
2022-11-04 02:52:50,636 - INFO  - Training [54][  140/  196]   Loss 0.032123   Top1 98.917411   Top5 99.997210   BatchTime 0.136886   LR 0.001000   
2022-11-04 02:52:53,098 - INFO  - Training [54][  160/  196]   Loss 0.031987   Top1 98.906250   Top5 99.997559   BatchTime 0.135161   LR 0.001000   
2022-11-04 02:52:55,654 - INFO  - Training [54][  180/  196]   Loss 0.032225   Top1 98.886719   Top5 99.997830   BatchTime 0.134343   LR 0.001000   
2022-11-04 02:52:57,812 - INFO  - ==> Top1: 98.836    Top5: 99.998    Loss: 0.033

2022-11-04 02:52:57,813 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:53:00,694 - INFO  - Validation [54][   20/   40]   Loss 0.436469   Top1 89.765625   Top5 99.589844   BatchTime 0.143959   
2022-11-04 02:53:01,723 - INFO  - Validation [54][   40/   40]   Loss 0.422775   Top1 90.260000   Top5 99.610000   BatchTime 0.097710   
2022-11-04 02:53:01,969 - INFO  - ==> Top1: 90.260    Top5: 99.610    Loss: 0.423

2022-11-04 02:53:01,995 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:53:01,996 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:53:01,996 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.510   Top5: 99.610] Sparsity : 0.888
2022-11-04 02:53:02,105 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:53:02,106 - INFO  - >>>>>>>> Epoch  55
2022-11-04 02:53:02,107 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:53:06,206 - INFO  - Training [55][   20/  196]   Loss 0.031007   Top1 99.023438   Top5 100.000000   BatchTime 0.204931   LR 0.001000   
2022-11-04 02:53:08,245 - INFO  - Training [55][   40/  196]   Loss 0.030509   Top1 99.033203   Top5 100.000000   BatchTime 0.153444   LR 0.001000   
2022-11-04 02:53:10,095 - INFO  - Training [55][   60/  196]   Loss 0.030114   Top1 99.055990   Top5 100.000000   BatchTime 0.133123   LR 0.001000   
2022-11-04 02:53:12,356 - INFO  - Training [55][   80/  196]   Loss 0.030380   Top1 99.038086   Top5 100.000000   BatchTime 0.128109   LR 0.001000   
2022-11-04 02:53:14,833 - INFO  - Training [55][  100/  196]   Loss 0.030484   Top1 99.015625   Top5 100.000000   BatchTime 0.127253   LR 0.001000   
2022-11-04 02:53:17,304 - INFO  - Training [55][  120/  196]   Loss 0.030926   Top1 98.994141   Top5 100.000000   BatchTime 0.126641   LR 0.001000   
2022-11-04 02:53:19,781 - INFO  - Training [55][  140/  196]   Loss 0.031351   Top1 98.967634   Top5 100.000000   BatchTime 0.126240   LR 0.001000   
2022-11-04 02:53:22,246 - INFO  - Training [55][  160/  196]   Loss 0.031638   Top1 98.950195   Top5 100.000000   BatchTime 0.125865   LR 0.001000   
2022-11-04 02:53:24,710 - INFO  - Training [55][  180/  196]   Loss 0.031607   Top1 98.962674   Top5 100.000000   BatchTime 0.125568   LR 0.001000   
2022-11-04 02:53:26,881 - INFO  - ==> Top1: 98.984    Top5: 100.000    Loss: 0.031

2022-11-04 02:53:26,882 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:53:29,780 - INFO  - Validation [55][   20/   40]   Loss 0.428939   Top1 90.449219   Top5 99.609375   BatchTime 0.144810   
2022-11-04 02:53:30,878 - INFO  - Validation [55][   40/   40]   Loss 0.421316   Top1 90.640000   Top5 99.600000   BatchTime 0.099864   
2022-11-04 02:53:31,147 - INFO  - ==> Top1: 90.640    Top5: 99.600    Loss: 0.421

2022-11-04 02:53:31,180 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:53:31,181 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:53:31,181 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:53:31,377 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:53:31,562 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_best.pth.tar

2022-11-04 02:53:31,562 - INFO  - >>>>>>>> Epoch  56
2022-11-04 02:53:31,563 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:53:35,942 - INFO  - Training [56][   20/  196]   Loss 0.030930   Top1 98.906250   Top5 100.000000   BatchTime 0.218960   LR 0.001000   
2022-11-04 02:53:38,370 - INFO  - Training [56][   40/  196]   Loss 0.030483   Top1 98.925781   Top5 100.000000   BatchTime 0.170176   LR 0.001000   
2022-11-04 02:53:40,861 - INFO  - Training [56][   60/  196]   Loss 0.030491   Top1 98.906250   Top5 100.000000   BatchTime 0.154962   LR 0.001000   
2022-11-04 02:53:43,352 - INFO  - Training [56][   80/  196]   Loss 0.030376   Top1 98.940430   Top5 100.000000   BatchTime 0.147356   LR 0.001000   
2022-11-04 02:53:45,827 - INFO  - Training [56][  100/  196]   Loss 0.031376   Top1 98.894531   Top5 100.000000   BatchTime 0.142637   LR 0.001000   
2022-11-04 02:53:48,295 - INFO  - Training [56][  120/  196]   Loss 0.031529   Top1 98.893229   Top5 100.000000   BatchTime 0.139433   LR 0.001000   
2022-11-04 02:53:50,781 - INFO  - Training [56][  140/  196]   Loss 0.031932   Top1 98.892299   Top5 100.000000   BatchTime 0.137266   LR 0.001000   
2022-11-04 02:53:53,226 - INFO  - Training [56][  160/  196]   Loss 0.031838   Top1 98.891602   Top5 100.000000   BatchTime 0.135391   LR 0.001000   
2022-11-04 02:53:55,677 - INFO  - Training [56][  180/  196]   Loss 0.032057   Top1 98.895399   Top5 100.000000   BatchTime 0.133966   LR 0.001000   
2022-11-04 02:53:57,617 - INFO  - ==> Top1: 98.896    Top5: 100.000    Loss: 0.032

2022-11-04 02:53:57,618 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:54:00,335 - INFO  - Validation [56][   20/   40]   Loss 0.431372   Top1 90.214844   Top5 99.628906   BatchTime 0.135797   
2022-11-04 02:54:01,189 - INFO  - Validation [56][   40/   40]   Loss 0.425167   Top1 90.480000   Top5 99.650000   BatchTime 0.089232   
2022-11-04 02:54:01,455 - INFO  - ==> Top1: 90.480    Top5: 99.650    Loss: 0.425

2022-11-04 02:54:01,487 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:54:01,487 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:54:01,487 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:54:01,580 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:54:01,580 - INFO  - >>>>>>>> Epoch  57
2022-11-04 02:54:01,581 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:54:06,152 - INFO  - Training [57][   20/  196]   Loss 0.029247   Top1 98.984375   Top5 100.000000   BatchTime 0.228530   LR 0.001000   
2022-11-04 02:54:08,645 - INFO  - Training [57][   40/  196]   Loss 0.028923   Top1 99.042969   Top5 100.000000   BatchTime 0.176586   LR 0.001000   
2022-11-04 02:54:11,121 - INFO  - Training [57][   60/  196]   Loss 0.029179   Top1 99.003906   Top5 100.000000   BatchTime 0.159003   LR 0.001000   
2022-11-04 02:54:13,602 - INFO  - Training [57][   80/  196]   Loss 0.029507   Top1 98.984375   Top5 100.000000   BatchTime 0.150258   LR 0.001000   
2022-11-04 02:54:16,083 - INFO  - Training [57][  100/  196]   Loss 0.031064   Top1 98.906250   Top5 100.000000   BatchTime 0.145013   LR 0.001000   
2022-11-04 02:54:18,568 - INFO  - Training [57][  120/  196]   Loss 0.030438   Top1 98.929036   Top5 100.000000   BatchTime 0.141554   LR 0.001000   
2022-11-04 02:54:21,041 - INFO  - Training [57][  140/  196]   Loss 0.031329   Top1 98.909040   Top5 100.000000   BatchTime 0.138994   LR 0.001000   
2022-11-04 02:54:23,499 - INFO  - Training [57][  160/  196]   Loss 0.031661   Top1 98.916016   Top5 100.000000   BatchTime 0.136982   LR 0.001000   
2022-11-04 02:54:25,965 - INFO  - Training [57][  180/  196]   Loss 0.031442   Top1 98.921441   Top5 100.000000   BatchTime 0.135461   LR 0.001000   
2022-11-04 02:54:28,159 - INFO  - ==> Top1: 98.914    Top5: 100.000    Loss: 0.032

2022-11-04 02:54:28,159 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:54:31,083 - INFO  - Validation [57][   20/   40]   Loss 0.436991   Top1 90.156250   Top5 99.589844   BatchTime 0.146091   
2022-11-04 02:54:32,223 - INFO  - Validation [57][   40/   40]   Loss 0.426409   Top1 90.330000   Top5 99.630000   BatchTime 0.101550   
2022-11-04 02:54:32,484 - INFO  - ==> Top1: 90.330    Top5: 99.630    Loss: 0.426

2022-11-04 02:54:32,524 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:54:32,525 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:54:32,525 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:54:32,617 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:54:32,617 - INFO  - >>>>>>>> Epoch  58
2022-11-04 02:54:32,619 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:54:37,029 - INFO  - Training [58][   20/  196]   Loss 0.032753   Top1 98.828125   Top5 100.000000   BatchTime 0.220497   LR 0.001000   
2022-11-04 02:54:39,494 - INFO  - Training [58][   40/  196]   Loss 0.032968   Top1 98.857422   Top5 100.000000   BatchTime 0.171865   LR 0.001000   
2022-11-04 02:54:41,970 - INFO  - Training [58][   60/  196]   Loss 0.033038   Top1 98.906250   Top5 100.000000   BatchTime 0.155846   LR 0.001000   
2022-11-04 02:54:44,419 - INFO  - Training [58][   80/  196]   Loss 0.033303   Top1 98.945312   Top5 100.000000   BatchTime 0.147498   LR 0.001000   
2022-11-04 02:54:46,880 - INFO  - Training [58][  100/  196]   Loss 0.032532   Top1 98.953125   Top5 100.000000   BatchTime 0.142606   LR 0.001000   
2022-11-04 02:54:49,341 - INFO  - Training [58][  120/  196]   Loss 0.032047   Top1 98.948568   Top5 100.000000   BatchTime 0.139347   LR 0.001000   
2022-11-04 02:54:51,164 - INFO  - Training [58][  140/  196]   Loss 0.032241   Top1 98.934152   Top5 100.000000   BatchTime 0.132463   LR 0.001000   
2022-11-04 02:54:53,170 - INFO  - Training [58][  160/  196]   Loss 0.032773   Top1 98.908691   Top5 100.000000   BatchTime 0.128445   LR 0.001000   
2022-11-04 02:54:55,190 - INFO  - Training [58][  180/  196]   Loss 0.032184   Top1 98.943142   Top5 100.000000   BatchTime 0.125393   LR 0.001000   
2022-11-04 02:54:57,219 - INFO  - ==> Top1: 98.936    Top5: 100.000    Loss: 0.033

2022-11-04 02:54:57,219 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:55:00,237 - INFO  - Validation [58][   20/   40]   Loss 0.430917   Top1 90.097656   Top5 99.570312   BatchTime 0.150819   
2022-11-04 02:55:01,317 - INFO  - Validation [58][   40/   40]   Loss 0.422603   Top1 90.490000   Top5 99.640000   BatchTime 0.102406   
2022-11-04 02:55:01,562 - INFO  - ==> Top1: 90.490    Top5: 99.640    Loss: 0.423

2022-11-04 02:55:01,607 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:55:01,608 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:55:01,608 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:55:01,712 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:55:01,712 - INFO  - >>>>>>>> Epoch  59
2022-11-04 02:55:01,713 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:55:06,109 - INFO  - Training [59][   20/  196]   Loss 0.028424   Top1 99.218750   Top5 100.000000   BatchTime 0.219773   LR 0.001000   
2022-11-04 02:55:08,576 - INFO  - Training [59][   40/  196]   Loss 0.030924   Top1 99.052734   Top5 99.990234   BatchTime 0.171580   LR 0.001000   
2022-11-04 02:55:11,043 - INFO  - Training [59][   60/  196]   Loss 0.030734   Top1 98.977865   Top5 99.993490   BatchTime 0.155496   LR 0.001000   
2022-11-04 02:55:13,517 - INFO  - Training [59][   80/  196]   Loss 0.031103   Top1 98.945312   Top5 99.995117   BatchTime 0.147546   LR 0.001000   
2022-11-04 02:55:15,986 - INFO  - Training [59][  100/  196]   Loss 0.030793   Top1 98.933594   Top5 99.996094   BatchTime 0.142726   LR 0.001000   
2022-11-04 02:55:18,453 - INFO  - Training [59][  120/  196]   Loss 0.031225   Top1 98.932292   Top5 99.996745   BatchTime 0.139496   LR 0.001000   
2022-11-04 02:55:20,928 - INFO  - Training [59][  140/  196]   Loss 0.031359   Top1 98.920201   Top5 99.997210   BatchTime 0.137243   LR 0.001000   
2022-11-04 02:55:23,383 - INFO  - Training [59][  160/  196]   Loss 0.031633   Top1 98.916016   Top5 99.995117   BatchTime 0.135431   LR 0.001000   
2022-11-04 02:55:25,837 - INFO  - Training [59][  180/  196]   Loss 0.031559   Top1 98.921441   Top5 99.995660   BatchTime 0.134019   LR 0.001000   
2022-11-04 02:55:27,996 - INFO  - ==> Top1: 98.928    Top5: 99.996    Loss: 0.031

2022-11-04 02:55:27,997 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:55:30,897 - INFO  - Validation [59][   20/   40]   Loss 0.428809   Top1 90.253906   Top5 99.570312   BatchTime 0.144938   
2022-11-04 02:55:31,988 - INFO  - Validation [59][   40/   40]   Loss 0.427629   Top1 90.440000   Top5 99.610000   BatchTime 0.099747   
2022-11-04 02:55:32,245 - INFO  - ==> Top1: 90.440    Top5: 99.610    Loss: 0.428

2022-11-04 02:55:32,275 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:55:32,276 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:55:32,276 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:55:32,360 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:55:32,360 - INFO  - >>>>>>>> Epoch  60
2022-11-04 02:55:32,361 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:55:36,737 - INFO  - Training [60][   20/  196]   Loss 0.030585   Top1 98.925781   Top5 100.000000   BatchTime 0.218775   LR 0.000100   
2022-11-04 02:55:39,205 - INFO  - Training [60][   40/  196]   Loss 0.028510   Top1 98.994141   Top5 100.000000   BatchTime 0.171106   LR 0.000100   
2022-11-04 02:55:41,672 - INFO  - Training [60][   60/  196]   Loss 0.029165   Top1 98.971354   Top5 100.000000   BatchTime 0.155183   LR 0.000100   
2022-11-04 02:55:43,894 - INFO  - Training [60][   80/  196]   Loss 0.029855   Top1 98.955078   Top5 100.000000   BatchTime 0.144164   LR 0.000100   
2022-11-04 02:55:45,807 - INFO  - Training [60][  100/  196]   Loss 0.030047   Top1 98.968750   Top5 100.000000   BatchTime 0.134459   LR 0.000100   
2022-11-04 02:55:47,841 - INFO  - Training [60][  120/  196]   Loss 0.029469   Top1 98.968099   Top5 100.000000   BatchTime 0.128999   LR 0.000100   
2022-11-04 02:55:49,864 - INFO  - Training [60][  140/  196]   Loss 0.029578   Top1 98.976004   Top5 99.997210   BatchTime 0.125017   LR 0.000100   
2022-11-04 02:55:51,697 - INFO  - Training [60][  160/  196]   Loss 0.029973   Top1 98.977051   Top5 99.997559   BatchTime 0.120845   LR 0.000100   
2022-11-04 02:55:53,884 - INFO  - Training [60][  180/  196]   Loss 0.030066   Top1 98.962674   Top5 99.997830   BatchTime 0.119569   LR 0.000100   
2022-11-04 02:55:56,061 - INFO  - ==> Top1: 98.968    Top5: 99.998    Loss: 0.030

2022-11-04 02:55:56,061 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:55:58,957 - INFO  - Validation [60][   20/   40]   Loss 0.439641   Top1 89.941406   Top5 99.609375   BatchTime 0.144726   
2022-11-04 02:56:00,053 - INFO  - Validation [60][   40/   40]   Loss 0.429081   Top1 90.340000   Top5 99.630000   BatchTime 0.099763   
2022-11-04 02:56:00,316 - INFO  - ==> Top1: 90.340    Top5: 99.630    Loss: 0.429

2022-11-04 02:56:00,356 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:56:00,357 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:56:00,357 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.530   Top5: 99.620] Sparsity : 0.888
2022-11-04 02:56:00,447 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:56:00,448 - INFO  - >>>>>>>> Epoch  61
2022-11-04 02:56:00,449 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:56:04,855 - INFO  - Training [61][   20/  196]   Loss 0.031869   Top1 98.945312   Top5 100.000000   BatchTime 0.220291   LR 0.000100   
2022-11-04 02:56:07,324 - INFO  - Training [61][   40/  196]   Loss 0.031777   Top1 98.886719   Top5 100.000000   BatchTime 0.171869   LR 0.000100   
2022-11-04 02:56:09,800 - INFO  - Training [61][   60/  196]   Loss 0.029896   Top1 99.016927   Top5 100.000000   BatchTime 0.155856   LR 0.000100   
2022-11-04 02:56:12,276 - INFO  - Training [61][   80/  196]   Loss 0.029600   Top1 98.989258   Top5 100.000000   BatchTime 0.147837   LR 0.000100   
2022-11-04 02:56:14,753 - INFO  - Training [61][  100/  196]   Loss 0.030873   Top1 98.945312   Top5 99.996094   BatchTime 0.143041   LR 0.000100   
2022-11-04 02:56:17,232 - INFO  - Training [61][  120/  196]   Loss 0.031571   Top1 98.925781   Top5 99.996745   BatchTime 0.139854   LR 0.000100   
2022-11-04 02:56:19,715 - INFO  - Training [61][  140/  196]   Loss 0.031397   Top1 98.931362   Top5 99.997210   BatchTime 0.137612   LR 0.000100   
2022-11-04 02:56:22,176 - INFO  - Training [61][  160/  196]   Loss 0.031904   Top1 98.920898   Top5 99.997559   BatchTime 0.135791   LR 0.000100   
2022-11-04 02:56:24,637 - INFO  - Training [61][  180/  196]   Loss 0.031892   Top1 98.947483   Top5 99.997830   BatchTime 0.134373   LR 0.000100   
2022-11-04 02:56:26,803 - INFO  - ==> Top1: 98.958    Top5: 99.998    Loss: 0.032

2022-11-04 02:56:26,803 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:56:29,733 - INFO  - Validation [61][   20/   40]   Loss 0.431096   Top1 90.175781   Top5 99.687500   BatchTime 0.146381   
2022-11-04 02:56:30,842 - INFO  - Validation [61][   40/   40]   Loss 0.422660   Top1 90.530000   Top5 99.640000   BatchTime 0.100932   
2022-11-04 02:56:31,096 - INFO  - ==> Top1: 90.530    Top5: 99.640    Loss: 0.423

2022-11-04 02:56:31,140 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:56:31,140 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:56:31,140 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:56:31,220 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:56:31,220 - INFO  - >>>>>>>> Epoch  62
2022-11-04 02:56:31,221 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:56:35,599 - INFO  - Training [62][   20/  196]   Loss 0.032757   Top1 98.847656   Top5 100.000000   BatchTime 0.218883   LR 0.000100   
2022-11-04 02:56:37,360 - INFO  - Training [62][   40/  196]   Loss 0.030242   Top1 98.994141   Top5 100.000000   BatchTime 0.153447   LR 0.000100   
2022-11-04 02:56:39,428 - INFO  - Training [62][   60/  196]   Loss 0.030451   Top1 98.990885   Top5 100.000000   BatchTime 0.136776   LR 0.000100   
2022-11-04 02:56:41,453 - INFO  - Training [62][   80/  196]   Loss 0.029696   Top1 99.047852   Top5 100.000000   BatchTime 0.127886   LR 0.000100   
2022-11-04 02:56:43,495 - INFO  - Training [62][  100/  196]   Loss 0.030883   Top1 98.980469   Top5 100.000000   BatchTime 0.122729   LR 0.000100   
2022-11-04 02:56:45,551 - INFO  - Training [62][  120/  196]   Loss 0.031259   Top1 98.964844   Top5 100.000000   BatchTime 0.119405   LR 0.000100   
2022-11-04 02:56:48,011 - INFO  - Training [62][  140/  196]   Loss 0.031315   Top1 98.936942   Top5 99.997210   BatchTime 0.119922   LR 0.000100   
2022-11-04 02:56:50,489 - INFO  - Training [62][  160/  196]   Loss 0.031384   Top1 98.930664   Top5 99.997559   BatchTime 0.120417   LR 0.000100   
2022-11-04 02:56:52,947 - INFO  - Training [62][  180/  196]   Loss 0.030894   Top1 98.956163   Top5 99.995660   BatchTime 0.120691   LR 0.000100   
2022-11-04 02:56:55,126 - INFO  - ==> Top1: 98.948    Top5: 99.996    Loss: 0.031

2022-11-04 02:56:55,127 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:56:58,055 - INFO  - Validation [62][   20/   40]   Loss 0.439130   Top1 89.960938   Top5 99.648438   BatchTime 0.146310   
2022-11-04 02:56:59,160 - INFO  - Validation [62][   40/   40]   Loss 0.426707   Top1 90.350000   Top5 99.640000   BatchTime 0.100794   
2022-11-04 02:56:59,412 - INFO  - ==> Top1: 90.350    Top5: 99.640    Loss: 0.427

2022-11-04 02:56:59,457 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:56:59,458 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:56:59,458 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:56:59,673 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:56:59,674 - INFO  - >>>>>>>> Epoch  63
2022-11-04 02:56:59,674 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:57:04,055 - INFO  - Training [63][   20/  196]   Loss 0.027876   Top1 99.042969   Top5 100.000000   BatchTime 0.219027   LR 0.000100   
2022-11-04 02:57:06,528 - INFO  - Training [63][   40/  196]   Loss 0.028845   Top1 99.003906   Top5 100.000000   BatchTime 0.171345   LR 0.000100   
2022-11-04 02:57:09,001 - INFO  - Training [63][   60/  196]   Loss 0.027777   Top1 99.075521   Top5 100.000000   BatchTime 0.155442   LR 0.000100   
2022-11-04 02:57:11,470 - INFO  - Training [63][   80/  196]   Loss 0.028123   Top1 99.057617   Top5 100.000000   BatchTime 0.147444   LR 0.000100   
2022-11-04 02:57:13,951 - INFO  - Training [63][  100/  196]   Loss 0.029718   Top1 98.984375   Top5 100.000000   BatchTime 0.142766   LR 0.000100   
2022-11-04 02:57:16,424 - INFO  - Training [63][  120/  196]   Loss 0.030591   Top1 98.945312   Top5 100.000000   BatchTime 0.139576   LR 0.000100   
2022-11-04 02:57:18,893 - INFO  - Training [63][  140/  196]   Loss 0.030295   Top1 98.978795   Top5 100.000000   BatchTime 0.137274   LR 0.000100   
2022-11-04 02:57:21,356 - INFO  - Training [63][  160/  196]   Loss 0.031172   Top1 98.940430   Top5 100.000000   BatchTime 0.135505   LR 0.000100   
2022-11-04 02:57:23,813 - INFO  - Training [63][  180/  196]   Loss 0.031142   Top1 98.949653   Top5 100.000000   BatchTime 0.134099   LR 0.000100   
2022-11-04 02:57:25,938 - INFO  - ==> Top1: 98.946    Top5: 100.000    Loss: 0.031

2022-11-04 02:57:25,939 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:57:28,821 - INFO  - Validation [63][   20/   40]   Loss 0.440136   Top1 90.195312   Top5 99.628906   BatchTime 0.144045   
2022-11-04 02:57:29,680 - INFO  - Validation [63][   40/   40]   Loss 0.427744   Top1 90.480000   Top5 99.650000   BatchTime 0.093490   
2022-11-04 02:57:29,942 - INFO  - ==> Top1: 90.480    Top5: 99.650    Loss: 0.428

2022-11-04 02:57:29,967 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:57:29,968 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:57:29,968 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:57:30,072 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:57:30,072 - INFO  - >>>>>>>> Epoch  64
2022-11-04 02:57:30,074 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:57:34,128 - INFO  - Training [64][   20/  196]   Loss 0.022329   Top1 99.238281   Top5 100.000000   BatchTime 0.202710   LR 0.000100   
2022-11-04 02:57:36,240 - INFO  - Training [64][   40/  196]   Loss 0.027591   Top1 99.013672   Top5 100.000000   BatchTime 0.154144   LR 0.000100   
2022-11-04 02:57:38,215 - INFO  - Training [64][   60/  196]   Loss 0.027083   Top1 99.069010   Top5 100.000000   BatchTime 0.135679   LR 0.000100   
2022-11-04 02:57:40,696 - INFO  - Training [64][   80/  196]   Loss 0.027785   Top1 99.038086   Top5 100.000000   BatchTime 0.132779   LR 0.000100   
2022-11-04 02:57:43,177 - INFO  - Training [64][  100/  196]   Loss 0.028171   Top1 99.031250   Top5 100.000000   BatchTime 0.131031   LR 0.000100   
2022-11-04 02:57:45,646 - INFO  - Training [64][  120/  196]   Loss 0.028537   Top1 99.003906   Top5 100.000000   BatchTime 0.129764   LR 0.000100   
2022-11-04 02:57:48,132 - INFO  - Training [64][  140/  196]   Loss 0.028976   Top1 98.987165   Top5 100.000000   BatchTime 0.128985   LR 0.000100   
2022-11-04 02:57:50,587 - INFO  - Training [64][  160/  196]   Loss 0.029256   Top1 98.984375   Top5 100.000000   BatchTime 0.128204   LR 0.000100   
2022-11-04 02:57:53,063 - INFO  - Training [64][  180/  196]   Loss 0.029792   Top1 98.967014   Top5 100.000000   BatchTime 0.127713   LR 0.000100   
2022-11-04 02:57:55,248 - INFO  - ==> Top1: 98.942    Top5: 100.000    Loss: 0.030

2022-11-04 02:57:55,249 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:57:58,155 - INFO  - Validation [64][   20/   40]   Loss 0.434906   Top1 89.804688   Top5 99.550781   BatchTime 0.145271   
2022-11-04 02:57:59,235 - INFO  - Validation [64][   40/   40]   Loss 0.427729   Top1 90.330000   Top5 99.590000   BatchTime 0.099634   
2022-11-04 02:57:59,478 - INFO  - ==> Top1: 90.330    Top5: 99.590    Loss: 0.428

2022-11-04 02:57:59,511 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:57:59,512 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:57:59,512 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.530   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:57:59,606 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:57:59,607 - INFO  - >>>>>>>> Epoch  65
2022-11-04 02:57:59,608 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:58:04,008 - INFO  - Training [65][   20/  196]   Loss 0.031106   Top1 99.160156   Top5 100.000000   BatchTime 0.220012   LR 0.000100   
2022-11-04 02:58:06,487 - INFO  - Training [65][   40/  196]   Loss 0.029619   Top1 99.140625   Top5 100.000000   BatchTime 0.171968   LR 0.000100   
2022-11-04 02:58:08,961 - INFO  - Training [65][   60/  196]   Loss 0.030339   Top1 99.016927   Top5 100.000000   BatchTime 0.155880   LR 0.000100   
2022-11-04 02:58:11,439 - INFO  - Training [65][   80/  196]   Loss 0.029893   Top1 99.013672   Top5 100.000000   BatchTime 0.147886   LR 0.000100   
2022-11-04 02:58:13,913 - INFO  - Training [65][  100/  196]   Loss 0.031713   Top1 98.925781   Top5 100.000000   BatchTime 0.143052   LR 0.000100   
2022-11-04 02:58:16,398 - INFO  - Training [65][  120/  196]   Loss 0.031330   Top1 98.942057   Top5 100.000000   BatchTime 0.139920   LR 0.000100   
2022-11-04 02:58:18,865 - INFO  - Training [65][  140/  196]   Loss 0.031593   Top1 98.953683   Top5 100.000000   BatchTime 0.137549   LR 0.000100   
2022-11-04 02:58:21,318 - INFO  - Training [65][  160/  196]   Loss 0.031566   Top1 98.952637   Top5 100.000000   BatchTime 0.135689   LR 0.000100   
2022-11-04 02:58:23,774 - INFO  - Training [65][  180/  196]   Loss 0.031156   Top1 98.971354   Top5 100.000000   BatchTime 0.134257   LR 0.000100   
2022-11-04 02:58:25,382 - INFO  - ==> Top1: 98.966    Top5: 100.000    Loss: 0.031

2022-11-04 02:58:25,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:58:28,073 - INFO  - Validation [65][   20/   40]   Loss 0.433163   Top1 90.312500   Top5 99.648438   BatchTime 0.134413   
2022-11-04 02:58:28,885 - INFO  - Validation [65][   40/   40]   Loss 0.424717   Top1 90.570000   Top5 99.640000   BatchTime 0.087496   
2022-11-04 02:58:29,140 - INFO  - ==> Top1: 90.570    Top5: 99.640    Loss: 0.425

2022-11-04 02:58:29,163 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:58:29,163 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:58:29,164 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:58:29,266 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:58:29,267 - INFO  - >>>>>>>> Epoch  66
2022-11-04 02:58:29,268 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:58:33,753 - INFO  - Training [66][   20/  196]   Loss 0.028237   Top1 99.160156   Top5 100.000000   BatchTime 0.224248   LR 0.000100   
2022-11-04 02:58:36,228 - INFO  - Training [66][   40/  196]   Loss 0.030862   Top1 98.945312   Top5 99.990234   BatchTime 0.173996   LR 0.000100   
2022-11-04 02:58:38,694 - INFO  - Training [66][   60/  196]   Loss 0.031173   Top1 98.919271   Top5 99.993490   BatchTime 0.157103   LR 0.000100   
2022-11-04 02:58:41,164 - INFO  - Training [66][   80/  196]   Loss 0.030498   Top1 98.920898   Top5 99.995117   BatchTime 0.148697   LR 0.000100   
2022-11-04 02:58:43,636 - INFO  - Training [66][  100/  196]   Loss 0.030774   Top1 98.929688   Top5 99.996094   BatchTime 0.143674   LR 0.000100   
2022-11-04 02:58:46,112 - INFO  - Training [66][  120/  196]   Loss 0.030878   Top1 98.925781   Top5 99.996745   BatchTime 0.140359   LR 0.000100   
2022-11-04 02:58:48,588 - INFO  - Training [66][  140/  196]   Loss 0.030442   Top1 98.934152   Top5 99.997210   BatchTime 0.137999   LR 0.000100   
2022-11-04 02:58:51,054 - INFO  - Training [66][  160/  196]   Loss 0.030757   Top1 98.930664   Top5 99.997559   BatchTime 0.136158   LR 0.000100   
2022-11-04 02:58:53,514 - INFO  - Training [66][  180/  196]   Loss 0.030908   Top1 98.936632   Top5 99.997830   BatchTime 0.134695   LR 0.000100   
2022-11-04 02:58:55,700 - INFO  - ==> Top1: 98.936    Top5: 99.998    Loss: 0.031

2022-11-04 02:58:55,700 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:58:58,585 - INFO  - Validation [66][   20/   40]   Loss 0.432095   Top1 90.175781   Top5 99.648438   BatchTime 0.144166   
2022-11-04 02:58:59,714 - INFO  - Validation [66][   40/   40]   Loss 0.425051   Top1 90.550000   Top5 99.660000   BatchTime 0.100291   
2022-11-04 02:58:59,977 - INFO  - ==> Top1: 90.550    Top5: 99.660    Loss: 0.425

2022-11-04 02:59:00,007 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:59:00,007 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:59:00,008 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:59:00,094 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:59:00,095 - INFO  - >>>>>>>> Epoch  67
2022-11-04 02:59:00,096 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:59:04,837 - INFO  - Training [67][   20/  196]   Loss 0.030025   Top1 99.003906   Top5 100.000000   BatchTime 0.237012   LR 0.000100   
2022-11-04 02:59:07,316 - INFO  - Training [67][   40/  196]   Loss 0.030353   Top1 98.964844   Top5 100.000000   BatchTime 0.180494   LR 0.000100   
2022-11-04 02:59:09,796 - INFO  - Training [67][   60/  196]   Loss 0.030419   Top1 98.958333   Top5 100.000000   BatchTime 0.161665   LR 0.000100   
2022-11-04 02:59:12,271 - INFO  - Training [67][   80/  196]   Loss 0.030511   Top1 98.945312   Top5 100.000000   BatchTime 0.152183   LR 0.000100   
2022-11-04 02:59:14,731 - INFO  - Training [67][  100/  196]   Loss 0.031132   Top1 98.949219   Top5 100.000000   BatchTime 0.146348   LR 0.000100   
2022-11-04 02:59:16,889 - INFO  - Training [67][  120/  196]   Loss 0.030544   Top1 98.958333   Top5 99.996745   BatchTime 0.139940   LR 0.000100   
2022-11-04 02:59:18,837 - INFO  - Training [67][  140/  196]   Loss 0.030603   Top1 98.945312   Top5 99.997210   BatchTime 0.133856   LR 0.000100   
2022-11-04 02:59:20,850 - INFO  - Training [67][  160/  196]   Loss 0.030764   Top1 98.913574   Top5 99.997559   BatchTime 0.129711   LR 0.000100   
2022-11-04 02:59:22,862 - INFO  - Training [67][  180/  196]   Loss 0.030552   Top1 98.930122   Top5 99.997830   BatchTime 0.126475   LR 0.000100   
2022-11-04 02:59:24,608 - INFO  - ==> Top1: 98.920    Top5: 99.998    Loss: 0.031

2022-11-04 02:59:24,609 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:59:27,636 - INFO  - Validation [67][   20/   40]   Loss 0.436161   Top1 89.863281   Top5 99.628906   BatchTime 0.151262   
2022-11-04 02:59:28,766 - INFO  - Validation [67][   40/   40]   Loss 0.424610   Top1 90.300000   Top5 99.640000   BatchTime 0.103903   
2022-11-04 02:59:29,028 - INFO  - ==> Top1: 90.300    Top5: 99.640    Loss: 0.425

2022-11-04 02:59:29,065 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:59:29,066 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:59:29,066 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:59:29,153 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:59:29,153 - INFO  - >>>>>>>> Epoch  68
2022-11-04 02:59:29,154 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 02:59:33,543 - INFO  - Training [68][   20/  196]   Loss 0.028108   Top1 98.945312   Top5 100.000000   BatchTime 0.219429   LR 0.000100   
2022-11-04 02:59:36,023 - INFO  - Training [68][   40/  196]   Loss 0.029170   Top1 98.984375   Top5 100.000000   BatchTime 0.171725   LR 0.000100   
2022-11-04 02:59:38,508 - INFO  - Training [68][   60/  196]   Loss 0.029030   Top1 98.997396   Top5 100.000000   BatchTime 0.155901   LR 0.000100   
2022-11-04 02:59:40,999 - INFO  - Training [68][   80/  196]   Loss 0.027639   Top1 99.067383   Top5 100.000000   BatchTime 0.148056   LR 0.000100   
2022-11-04 02:59:43,472 - INFO  - Training [68][  100/  196]   Loss 0.028256   Top1 99.046875   Top5 100.000000   BatchTime 0.143175   LR 0.000100   
2022-11-04 02:59:45,952 - INFO  - Training [68][  120/  196]   Loss 0.028980   Top1 99.016927   Top5 100.000000   BatchTime 0.139980   LR 0.000100   
2022-11-04 02:59:48,428 - INFO  - Training [68][  140/  196]   Loss 0.029085   Top1 98.989955   Top5 100.000000   BatchTime 0.137666   LR 0.000100   
2022-11-04 02:59:50,884 - INFO  - Training [68][  160/  196]   Loss 0.029239   Top1 99.006348   Top5 100.000000   BatchTime 0.135808   LR 0.000100   
2022-11-04 02:59:53,346 - INFO  - Training [68][  180/  196]   Loss 0.029792   Top1 99.001736   Top5 100.000000   BatchTime 0.134397   LR 0.000100   
2022-11-04 02:59:55,518 - INFO  - ==> Top1: 98.984    Top5: 100.000    Loss: 0.030

2022-11-04 02:59:55,519 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 02:59:58,397 - INFO  - Validation [68][   20/   40]   Loss 0.428882   Top1 90.156250   Top5 99.609375   BatchTime 0.143825   
2022-11-04 02:59:59,493 - INFO  - Validation [68][   40/   40]   Loss 0.422347   Top1 90.460000   Top5 99.620000   BatchTime 0.099323   
2022-11-04 02:59:59,769 - INFO  - ==> Top1: 90.460    Top5: 99.620    Loss: 0.422

2022-11-04 02:59:59,798 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 02:59:59,798 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 02:59:59,798 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 02:59:59,911 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 02:59:59,912 - INFO  - >>>>>>>> Epoch  69
2022-11-04 02:59:59,913 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:00:04,383 - INFO  - Training [69][   20/  196]   Loss 0.026419   Top1 99.121094   Top5 100.000000   BatchTime 0.223490   LR 0.000100   
2022-11-04 03:00:06,850 - INFO  - Training [69][   40/  196]   Loss 0.028125   Top1 98.984375   Top5 100.000000   BatchTime 0.173414   LR 0.000100   
2022-11-04 03:00:09,309 - INFO  - Training [69][   60/  196]   Loss 0.029088   Top1 98.925781   Top5 100.000000   BatchTime 0.156587   LR 0.000100   
2022-11-04 03:00:11,243 - INFO  - Training [69][   80/  196]   Loss 0.027878   Top1 99.013672   Top5 100.000000   BatchTime 0.141619   LR 0.000100   
2022-11-04 03:00:13,331 - INFO  - Training [69][  100/  196]   Loss 0.027868   Top1 99.039062   Top5 100.000000   BatchTime 0.134171   LR 0.000100   
2022-11-04 03:00:15,368 - INFO  - Training [69][  120/  196]   Loss 0.028122   Top1 99.023438   Top5 100.000000   BatchTime 0.128790   LR 0.000100   
2022-11-04 03:00:17,336 - INFO  - Training [69][  140/  196]   Loss 0.028338   Top1 99.031808   Top5 100.000000   BatchTime 0.124444   LR 0.000100   
2022-11-04 03:00:19,192 - INFO  - Training [69][  160/  196]   Loss 0.028718   Top1 99.023438   Top5 100.000000   BatchTime 0.120488   LR 0.000100   
2022-11-04 03:00:21,664 - INFO  - Training [69][  180/  196]   Loss 0.028635   Top1 99.027778   Top5 100.000000   BatchTime 0.120834   LR 0.000100   
2022-11-04 03:00:23,842 - INFO  - ==> Top1: 99.012    Top5: 100.000    Loss: 0.029

2022-11-04 03:00:23,843 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:00:26,717 - INFO  - Validation [69][   20/   40]   Loss 0.434272   Top1 90.078125   Top5 99.589844   BatchTime 0.143646   
2022-11-04 03:00:27,837 - INFO  - Validation [69][   40/   40]   Loss 0.424550   Top1 90.460000   Top5 99.610000   BatchTime 0.099828   
2022-11-04 03:00:28,099 - INFO  - ==> Top1: 90.460    Top5: 99.610    Loss: 0.425

2022-11-04 03:00:28,142 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:00:28,143 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:00:28,143 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:00:28,247 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:00:28,247 - INFO  - >>>>>>>> Epoch  70
2022-11-04 03:00:28,249 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:00:32,655 - INFO  - Training [70][   20/  196]   Loss 0.030880   Top1 99.003906   Top5 100.000000   BatchTime 0.220286   LR 0.000010   
2022-11-04 03:00:35,122 - INFO  - Training [70][   40/  196]   Loss 0.030631   Top1 99.003906   Top5 100.000000   BatchTime 0.171832   LR 0.000010   
2022-11-04 03:00:37,589 - INFO  - Training [70][   60/  196]   Loss 0.030020   Top1 99.069010   Top5 100.000000   BatchTime 0.155671   LR 0.000010   
2022-11-04 03:00:40,060 - INFO  - Training [70][   80/  196]   Loss 0.031369   Top1 98.979492   Top5 100.000000   BatchTime 0.147643   LR 0.000010   
2022-11-04 03:00:42,534 - INFO  - Training [70][  100/  196]   Loss 0.030920   Top1 99.007812   Top5 100.000000   BatchTime 0.142849   LR 0.000010   
2022-11-04 03:00:45,000 - INFO  - Training [70][  120/  196]   Loss 0.030412   Top1 99.000651   Top5 100.000000   BatchTime 0.139595   LR 0.000010   
2022-11-04 03:00:47,464 - INFO  - Training [70][  140/  196]   Loss 0.030254   Top1 98.998326   Top5 100.000000   BatchTime 0.137251   LR 0.000010   
2022-11-04 03:00:49,921 - INFO  - Training [70][  160/  196]   Loss 0.031028   Top1 98.955078   Top5 99.997559   BatchTime 0.135446   LR 0.000010   
2022-11-04 03:00:52,376 - INFO  - Training [70][  180/  196]   Loss 0.030647   Top1 98.962674   Top5 99.997830   BatchTime 0.134038   LR 0.000010   
2022-11-04 03:00:54,555 - INFO  - ==> Top1: 98.956    Top5: 99.998    Loss: 0.031

2022-11-04 03:00:54,556 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:00:57,461 - INFO  - Validation [70][   20/   40]   Loss 0.436523   Top1 89.960938   Top5 99.570312   BatchTime 0.145162   
2022-11-04 03:00:58,592 - INFO  - Validation [70][   40/   40]   Loss 0.424295   Top1 90.440000   Top5 99.600000   BatchTime 0.100854   
2022-11-04 03:00:58,848 - INFO  - ==> Top1: 90.440    Top5: 99.600    Loss: 0.424

2022-11-04 03:00:58,888 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:00:58,889 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:00:58,889 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:00:58,992 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:00:58,992 - INFO  - >>>>>>>> Epoch  71
2022-11-04 03:00:58,994 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:01:02,948 - INFO  - Training [71][   20/  196]   Loss 0.031285   Top1 98.789062   Top5 100.000000   BatchTime 0.197700   LR 0.000010   
2022-11-04 03:01:04,924 - INFO  - Training [71][   40/  196]   Loss 0.030347   Top1 98.935547   Top5 100.000000   BatchTime 0.148246   LR 0.000010   
2022-11-04 03:01:06,965 - INFO  - Training [71][   60/  196]   Loss 0.030702   Top1 98.984375   Top5 100.000000   BatchTime 0.132849   LR 0.000010   
2022-11-04 03:01:09,053 - INFO  - Training [71][   80/  196]   Loss 0.031327   Top1 98.959961   Top5 100.000000   BatchTime 0.125743   LR 0.000010   
2022-11-04 03:01:10,789 - INFO  - Training [71][  100/  196]   Loss 0.030894   Top1 98.984375   Top5 100.000000   BatchTime 0.117952   LR 0.000010   
2022-11-04 03:01:13,311 - INFO  - Training [71][  120/  196]   Loss 0.031134   Top1 98.955078   Top5 100.000000   BatchTime 0.119308   LR 0.000010   
2022-11-04 03:01:15,778 - INFO  - Training [71][  140/  196]   Loss 0.030870   Top1 98.970424   Top5 100.000000   BatchTime 0.119884   LR 0.000010   
2022-11-04 03:01:18,207 - INFO  - Training [71][  160/  196]   Loss 0.030767   Top1 98.959961   Top5 100.000000   BatchTime 0.120079   LR 0.000010   
2022-11-04 03:01:20,671 - INFO  - Training [71][  180/  196]   Loss 0.030284   Top1 98.988715   Top5 100.000000   BatchTime 0.120426   LR 0.000010   
2022-11-04 03:01:22,839 - INFO  - ==> Top1: 98.986    Top5: 100.000    Loss: 0.030

2022-11-04 03:01:22,839 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:01:25,728 - INFO  - Validation [71][   20/   40]   Loss 0.441990   Top1 90.175781   Top5 99.628906   BatchTime 0.144392   
2022-11-04 03:01:26,858 - INFO  - Validation [71][   40/   40]   Loss 0.432338   Top1 90.470000   Top5 99.640000   BatchTime 0.100432   
2022-11-04 03:01:27,118 - INFO  - ==> Top1: 90.470    Top5: 99.640    Loss: 0.432

2022-11-04 03:01:27,152 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:01:27,153 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:01:27,153 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:01:27,254 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:01:27,254 - INFO  - >>>>>>>> Epoch  72
2022-11-04 03:01:27,256 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:01:31,671 - INFO  - Training [72][   20/  196]   Loss 0.030580   Top1 98.867188   Top5 100.000000   BatchTime 0.220736   LR 0.000010   
2022-11-04 03:01:34,151 - INFO  - Training [72][   40/  196]   Loss 0.031588   Top1 98.886719   Top5 100.000000   BatchTime 0.172366   LR 0.000010   
2022-11-04 03:01:36,617 - INFO  - Training [72][   60/  196]   Loss 0.030567   Top1 98.860677   Top5 100.000000   BatchTime 0.156020   LR 0.000010   
2022-11-04 03:01:39,099 - INFO  - Training [72][   80/  196]   Loss 0.030397   Top1 98.916016   Top5 100.000000   BatchTime 0.148036   LR 0.000010   
2022-11-04 03:01:41,575 - INFO  - Training [72][  100/  196]   Loss 0.031330   Top1 98.882812   Top5 100.000000   BatchTime 0.143188   LR 0.000010   
2022-11-04 03:01:44,054 - INFO  - Training [72][  120/  196]   Loss 0.030924   Top1 98.886719   Top5 100.000000   BatchTime 0.139982   LR 0.000010   
2022-11-04 03:01:46,522 - INFO  - Training [72][  140/  196]   Loss 0.031259   Top1 98.869978   Top5 100.000000   BatchTime 0.137615   LR 0.000010   
2022-11-04 03:01:48,981 - INFO  - Training [72][  160/  196]   Loss 0.031607   Top1 98.874512   Top5 100.000000   BatchTime 0.135778   LR 0.000010   
2022-11-04 03:01:51,427 - INFO  - Training [72][  180/  196]   Loss 0.031761   Top1 98.880208   Top5 100.000000   BatchTime 0.134281   LR 0.000010   
2022-11-04 03:01:53,586 - INFO  - ==> Top1: 98.874    Top5: 100.000    Loss: 0.032

2022-11-04 03:01:53,587 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:01:56,146 - INFO  - Validation [72][   20/   40]   Loss 0.430282   Top1 90.156250   Top5 99.609375   BatchTime 0.127852   
2022-11-04 03:01:56,830 - INFO  - Validation [72][   40/   40]   Loss 0.422216   Top1 90.550000   Top5 99.620000   BatchTime 0.081022   
2022-11-04 03:01:57,092 - INFO  - ==> Top1: 90.550    Top5: 99.620    Loss: 0.422

2022-11-04 03:01:57,118 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:01:57,118 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:01:57,118 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:01:57,237 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:01:57,238 - INFO  - >>>>>>>> Epoch  73
2022-11-04 03:01:57,239 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:02:01,268 - INFO  - Training [73][   20/  196]   Loss 0.026625   Top1 99.277344   Top5 100.000000   BatchTime 0.201451   LR 0.000010   
2022-11-04 03:02:03,033 - INFO  - Training [73][   40/  196]   Loss 0.030010   Top1 99.003906   Top5 100.000000   BatchTime 0.144833   LR 0.000010   
2022-11-04 03:02:05,601 - INFO  - Training [73][   60/  196]   Loss 0.029819   Top1 98.984375   Top5 100.000000   BatchTime 0.139354   LR 0.000010   
2022-11-04 03:02:08,076 - INFO  - Training [73][   80/  196]   Loss 0.030989   Top1 98.906250   Top5 100.000000   BatchTime 0.135464   LR 0.000010   
2022-11-04 03:02:10,550 - INFO  - Training [73][  100/  196]   Loss 0.031512   Top1 98.921875   Top5 100.000000   BatchTime 0.133102   LR 0.000010   
2022-11-04 03:02:13,022 - INFO  - Training [73][  120/  196]   Loss 0.031497   Top1 98.932292   Top5 100.000000   BatchTime 0.131517   LR 0.000010   
2022-11-04 03:02:15,489 - INFO  - Training [73][  140/  196]   Loss 0.031120   Top1 98.942522   Top5 100.000000   BatchTime 0.130353   LR 0.000010   
2022-11-04 03:02:17,948 - INFO  - Training [73][  160/  196]   Loss 0.030950   Top1 98.955078   Top5 100.000000   BatchTime 0.129428   LR 0.000010   
2022-11-04 03:02:20,408 - INFO  - Training [73][  180/  196]   Loss 0.030371   Top1 98.980035   Top5 100.000000   BatchTime 0.128714   LR 0.000010   
2022-11-04 03:02:22,595 - INFO  - ==> Top1: 98.984    Top5: 99.998    Loss: 0.030

2022-11-04 03:02:22,596 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:02:25,519 - INFO  - Validation [73][   20/   40]   Loss 0.432856   Top1 89.902344   Top5 99.609375   BatchTime 0.146077   
2022-11-04 03:02:26,609 - INFO  - Validation [73][   40/   40]   Loss 0.425027   Top1 90.350000   Top5 99.630000   BatchTime 0.100297   
2022-11-04 03:02:26,867 - INFO  - ==> Top1: 90.350    Top5: 99.630    Loss: 0.425

2022-11-04 03:02:26,914 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:02:26,915 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:02:26,915 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:02:27,020 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:02:27,021 - INFO  - >>>>>>>> Epoch  74
2022-11-04 03:02:27,022 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:02:31,401 - INFO  - Training [74][   20/  196]   Loss 0.025598   Top1 99.121094   Top5 100.000000   BatchTime 0.218953   LR 0.000010   
2022-11-04 03:02:33,871 - INFO  - Training [74][   40/  196]   Loss 0.025960   Top1 99.169922   Top5 99.990234   BatchTime 0.171226   LR 0.000010   
2022-11-04 03:02:36,340 - INFO  - Training [74][   60/  196]   Loss 0.027893   Top1 99.062500   Top5 99.993490   BatchTime 0.155294   LR 0.000010   
2022-11-04 03:02:38,805 - INFO  - Training [74][   80/  196]   Loss 0.027129   Top1 99.077148   Top5 99.995117   BatchTime 0.147277   LR 0.000010   
2022-11-04 03:02:41,276 - INFO  - Training [74][  100/  196]   Loss 0.026864   Top1 99.097656   Top5 99.996094   BatchTime 0.142537   LR 0.000010   
2022-11-04 03:02:43,749 - INFO  - Training [74][  120/  196]   Loss 0.028753   Top1 99.039714   Top5 99.996745   BatchTime 0.139386   LR 0.000010   
2022-11-04 03:02:46,203 - INFO  - Training [74][  140/  196]   Loss 0.029340   Top1 99.006696   Top5 99.997210   BatchTime 0.137005   LR 0.000010   
2022-11-04 03:02:48,637 - INFO  - Training [74][  160/  196]   Loss 0.030398   Top1 98.977051   Top5 99.997559   BatchTime 0.135090   LR 0.000010   
2022-11-04 03:02:50,381 - INFO  - Training [74][  180/  196]   Loss 0.030247   Top1 98.975694   Top5 99.997830   BatchTime 0.129767   LR 0.000010   
2022-11-04 03:02:52,237 - INFO  - ==> Top1: 98.952    Top5: 99.998    Loss: 0.031

2022-11-04 03:02:52,237 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:02:54,790 - INFO  - Validation [74][   20/   40]   Loss 0.431682   Top1 90.175781   Top5 99.609375   BatchTime 0.127592   
2022-11-04 03:02:55,491 - INFO  - Validation [74][   40/   40]   Loss 0.422402   Top1 90.520000   Top5 99.610000   BatchTime 0.081332   
2022-11-04 03:02:55,734 - INFO  - ==> Top1: 90.520    Top5: 99.610    Loss: 0.422

2022-11-04 03:02:55,756 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:02:55,756 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:02:55,756 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:02:55,857 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:02:55,857 - INFO  - >>>>>>>> Epoch  75
2022-11-04 03:02:55,859 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:03:00,355 - INFO  - Training [75][   20/  196]   Loss 0.029846   Top1 99.101562   Top5 100.000000   BatchTime 0.224782   LR 0.000010   
2022-11-04 03:03:02,926 - INFO  - Training [75][   40/  196]   Loss 0.030076   Top1 99.111328   Top5 99.990234   BatchTime 0.176669   LR 0.000010   
2022-11-04 03:03:05,411 - INFO  - Training [75][   60/  196]   Loss 0.029837   Top1 99.082031   Top5 99.986979   BatchTime 0.159197   LR 0.000010   
2022-11-04 03:03:07,883 - INFO  - Training [75][   80/  196]   Loss 0.030369   Top1 99.023438   Top5 99.990234   BatchTime 0.150300   LR 0.000010   
2022-11-04 03:03:10,325 - INFO  - Training [75][  100/  196]   Loss 0.030798   Top1 98.996094   Top5 99.992188   BatchTime 0.144658   LR 0.000010   
2022-11-04 03:03:12,814 - INFO  - Training [75][  120/  196]   Loss 0.030448   Top1 98.987630   Top5 99.993490   BatchTime 0.141287   LR 0.000010   
2022-11-04 03:03:15,279 - INFO  - Training [75][  140/  196]   Loss 0.030625   Top1 98.976004   Top5 99.994420   BatchTime 0.138714   LR 0.000010   
2022-11-04 03:03:17,750 - INFO  - Training [75][  160/  196]   Loss 0.030725   Top1 98.979492   Top5 99.995117   BatchTime 0.136816   LR 0.000010   
2022-11-04 03:03:20,216 - INFO  - Training [75][  180/  196]   Loss 0.030716   Top1 98.977865   Top5 99.995660   BatchTime 0.135316   LR 0.000010   
2022-11-04 03:03:22,406 - INFO  - ==> Top1: 98.962    Top5: 99.996    Loss: 0.031

2022-11-04 03:03:22,407 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:03:25,328 - INFO  - Validation [75][   20/   40]   Loss 0.433682   Top1 90.000000   Top5 99.628906   BatchTime 0.146004   
2022-11-04 03:03:26,448 - INFO  - Validation [75][   40/   40]   Loss 0.424304   Top1 90.390000   Top5 99.620000   BatchTime 0.100978   
2022-11-04 03:03:26,708 - INFO  - ==> Top1: 90.390    Top5: 99.620    Loss: 0.424

2022-11-04 03:03:26,741 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:03:26,741 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:03:26,741 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:03:26,841 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:03:26,841 - INFO  - >>>>>>>> Epoch  76
2022-11-04 03:03:26,842 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:03:31,285 - INFO  - Training [76][   20/  196]   Loss 0.024526   Top1 99.199219   Top5 100.000000   BatchTime 0.222127   LR 0.000010   
2022-11-04 03:03:33,758 - INFO  - Training [76][   40/  196]   Loss 0.026263   Top1 99.189453   Top5 100.000000   BatchTime 0.172886   LR 0.000010   
2022-11-04 03:03:36,226 - INFO  - Training [76][   60/  196]   Loss 0.025968   Top1 99.205729   Top5 100.000000   BatchTime 0.156391   LR 0.000010   
2022-11-04 03:03:38,691 - INFO  - Training [76][   80/  196]   Loss 0.027171   Top1 99.125977   Top5 100.000000   BatchTime 0.148099   LR 0.000010   
2022-11-04 03:03:41,170 - INFO  - Training [76][  100/  196]   Loss 0.028573   Top1 99.074219   Top5 100.000000   BatchTime 0.143275   LR 0.000010   
2022-11-04 03:03:42,927 - INFO  - Training [76][  120/  196]   Loss 0.029268   Top1 99.039714   Top5 100.000000   BatchTime 0.134031   LR 0.000010   
2022-11-04 03:03:44,970 - INFO  - Training [76][  140/  196]   Loss 0.029822   Top1 99.023438   Top5 100.000000   BatchTime 0.129476   LR 0.000010   
2022-11-04 03:03:46,982 - INFO  - Training [76][  160/  196]   Loss 0.030316   Top1 98.999023   Top5 100.000000   BatchTime 0.125871   LR 0.000010   
2022-11-04 03:03:48,902 - INFO  - Training [76][  180/  196]   Loss 0.029698   Top1 99.027778   Top5 100.000000   BatchTime 0.122548   LR 0.000010   
2022-11-04 03:03:50,567 - INFO  - ==> Top1: 99.006    Top5: 100.000    Loss: 0.030

2022-11-04 03:03:50,568 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:03:53,434 - INFO  - Validation [76][   20/   40]   Loss 0.432005   Top1 90.117188   Top5 99.628906   BatchTime 0.143276   
2022-11-04 03:03:54,547 - INFO  - Validation [76][   40/   40]   Loss 0.425760   Top1 90.550000   Top5 99.630000   BatchTime 0.099468   
2022-11-04 03:03:54,799 - INFO  - ==> Top1: 90.550    Top5: 99.630    Loss: 0.426

2022-11-04 03:03:54,831 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:03:54,832 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:03:54,832 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:03:54,938 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:03:54,939 - INFO  - >>>>>>>> Epoch  77
2022-11-04 03:03:54,940 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:03:59,344 - INFO  - Training [77][   20/  196]   Loss 0.032933   Top1 98.789062   Top5 100.000000   BatchTime 0.220207   LR 0.000010   
2022-11-04 03:04:01,808 - INFO  - Training [77][   40/  196]   Loss 0.031290   Top1 98.886719   Top5 100.000000   BatchTime 0.171684   LR 0.000010   
2022-11-04 03:04:04,279 - INFO  - Training [77][   60/  196]   Loss 0.031794   Top1 98.899740   Top5 100.000000   BatchTime 0.155643   LR 0.000010   
2022-11-04 03:04:06,768 - INFO  - Training [77][   80/  196]   Loss 0.031288   Top1 98.920898   Top5 100.000000   BatchTime 0.147843   LR 0.000010   
2022-11-04 03:04:09,238 - INFO  - Training [77][  100/  196]   Loss 0.031082   Top1 98.917969   Top5 100.000000   BatchTime 0.142972   LR 0.000010   
2022-11-04 03:04:11,720 - INFO  - Training [77][  120/  196]   Loss 0.031338   Top1 98.883464   Top5 100.000000   BatchTime 0.139830   LR 0.000010   
2022-11-04 03:04:14,194 - INFO  - Training [77][  140/  196]   Loss 0.030900   Top1 98.909040   Top5 100.000000   BatchTime 0.137528   LR 0.000010   
2022-11-04 03:04:16,654 - INFO  - Training [77][  160/  196]   Loss 0.030684   Top1 98.935547   Top5 100.000000   BatchTime 0.135710   LR 0.000010   
2022-11-04 03:04:19,112 - INFO  - Training [77][  180/  196]   Loss 0.030711   Top1 98.940972   Top5 100.000000   BatchTime 0.134283   LR 0.000010   
2022-11-04 03:04:21,301 - INFO  - ==> Top1: 98.934    Top5: 100.000    Loss: 0.031

2022-11-04 03:04:21,302 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:04:24,205 - INFO  - Validation [77][   20/   40]   Loss 0.436687   Top1 89.707031   Top5 99.492188   BatchTime 0.145082   
2022-11-04 03:04:25,307 - INFO  - Validation [77][   40/   40]   Loss 0.426865   Top1 90.280000   Top5 99.550000   BatchTime 0.100102   
2022-11-04 03:04:25,567 - INFO  - ==> Top1: 90.280    Top5: 99.550    Loss: 0.427

2022-11-04 03:04:25,604 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:04:25,605 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:04:25,605 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:04:25,703 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:04:25,703 - INFO  - >>>>>>>> Epoch  78
2022-11-04 03:04:25,705 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:04:30,097 - INFO  - Training [78][   20/  196]   Loss 0.028347   Top1 99.101562   Top5 100.000000   BatchTime 0.219608   LR 0.000010   
2022-11-04 03:04:32,564 - INFO  - Training [78][   40/  196]   Loss 0.029542   Top1 99.101562   Top5 100.000000   BatchTime 0.171479   LR 0.000010   
2022-11-04 03:04:34,596 - INFO  - Training [78][   60/  196]   Loss 0.030074   Top1 99.075521   Top5 100.000000   BatchTime 0.148183   LR 0.000010   
2022-11-04 03:04:36,561 - INFO  - Training [78][   80/  196]   Loss 0.031110   Top1 98.979492   Top5 100.000000   BatchTime 0.135705   LR 0.000010   
2022-11-04 03:04:38,620 - INFO  - Training [78][  100/  196]   Loss 0.029789   Top1 99.007812   Top5 100.000000   BatchTime 0.129149   LR 0.000010   
2022-11-04 03:04:40,713 - INFO  - Training [78][  120/  196]   Loss 0.029634   Top1 99.013672   Top5 100.000000   BatchTime 0.125068   LR 0.000010   
2022-11-04 03:04:42,424 - INFO  - Training [78][  140/  196]   Loss 0.029789   Top1 99.006696   Top5 99.997210   BatchTime 0.119418   LR 0.000010   
2022-11-04 03:04:44,893 - INFO  - Training [78][  160/  196]   Loss 0.030176   Top1 98.994141   Top5 99.997559   BatchTime 0.119926   LR 0.000010   
2022-11-04 03:04:47,354 - INFO  - Training [78][  180/  196]   Loss 0.030344   Top1 98.993056   Top5 99.997830   BatchTime 0.120272   LR 0.000010   
2022-11-04 03:04:49,520 - INFO  - ==> Top1: 98.994    Top5: 99.998    Loss: 0.030

2022-11-04 03:04:49,521 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:04:52,418 - INFO  - Validation [78][   20/   40]   Loss 0.424612   Top1 90.078125   Top5 99.667969   BatchTime 0.144787   
2022-11-04 03:04:53,526 - INFO  - Validation [78][   40/   40]   Loss 0.418604   Top1 90.370000   Top5 99.640000   BatchTime 0.100088   
2022-11-04 03:04:53,805 - INFO  - ==> Top1: 90.370    Top5: 99.640    Loss: 0.419

2022-11-04 03:04:53,832 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:04:53,833 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:04:53,833 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:04:53,939 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:04:53,940 - INFO  - >>>>>>>> Epoch  79
2022-11-04 03:04:53,941 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 03:04:58,340 - INFO  - Training [79][   20/  196]   Loss 0.031341   Top1 99.023438   Top5 100.000000   BatchTime 0.219941   LR 0.000010   
2022-11-04 03:05:00,777 - INFO  - Training [79][   40/  196]   Loss 0.029996   Top1 99.042969   Top5 100.000000   BatchTime 0.170899   LR 0.000010   
2022-11-04 03:05:03,350 - INFO  - Training [79][   60/  196]   Loss 0.030463   Top1 98.990885   Top5 100.000000   BatchTime 0.156806   LR 0.000010   
2022-11-04 03:05:05,829 - INFO  - Training [79][   80/  196]   Loss 0.029264   Top1 99.047852   Top5 100.000000   BatchTime 0.148594   LR 0.000010   
2022-11-04 03:05:08,298 - INFO  - Training [79][  100/  196]   Loss 0.029250   Top1 99.027344   Top5 100.000000   BatchTime 0.143563   LR 0.000010   
2022-11-04 03:05:10,766 - INFO  - Training [79][  120/  196]   Loss 0.029556   Top1 98.987630   Top5 100.000000   BatchTime 0.140200   LR 0.000010   
2022-11-04 03:05:13,234 - INFO  - Training [79][  140/  196]   Loss 0.029991   Top1 98.950893   Top5 100.000000   BatchTime 0.137802   LR 0.000010   
2022-11-04 03:05:15,678 - INFO  - Training [79][  160/  196]   Loss 0.030358   Top1 98.925781   Top5 100.000000   BatchTime 0.135851   LR 0.000010   
2022-11-04 03:05:18,133 - INFO  - Training [79][  180/  196]   Loss 0.030531   Top1 98.947483   Top5 100.000000   BatchTime 0.134395   LR 0.000010   
2022-11-04 03:05:20,284 - INFO  - ==> Top1: 98.948    Top5: 100.000    Loss: 0.030

2022-11-04 03:05:20,284 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:05:23,167 - INFO  - Validation [79][   20/   40]   Loss 0.437743   Top1 90.097656   Top5 99.628906   BatchTime 0.144077   
2022-11-04 03:05:24,293 - INFO  - Validation [79][   40/   40]   Loss 0.424009   Top1 90.500000   Top5 99.610000   BatchTime 0.100181   
2022-11-04 03:05:24,544 - INFO  - ==> Top1: 90.500    Top5: 99.610    Loss: 0.424

2022-11-04 03:05:24,581 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.640   Top5: 99.600] Sparsity : 0.888
2022-11-04 03:05:24,582 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.630   Top5: 99.560] Sparsity : 0.888
2022-11-04 03:05:24,582 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.570   Top5: 99.640] Sparsity : 0.888
2022-11-04 03:05:24,686 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_20221104-022541/MobileNetv2_cifar10_a8w8_hard_pruning_15_epoch80_checkpoint.pth.tar

2022-11-04 03:05:24,686 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-04 03:05:24,686 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 03:05:27,297 - INFO  - Validation [   20/   40]   Loss 0.437743   Top1 90.097656   Top5 99.628906   BatchTime 0.130480   
2022-11-04 03:05:28,128 - INFO  - Validation [   40/   40]   Loss 0.424009   Top1 90.500000   Top5 99.610000   BatchTime 0.086014   
2022-11-04 03:05:28,387 - INFO  - ==> Top1: 90.500    Top5: 99.610    Loss: 0.424

2022-11-04 03:05:28,418 - INFO  - Program completed successfully ... exiting ...
2022-11-04 03:05:28,419 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
