2022-11-03 23:27:58,255 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758.log
2022-11-03 23:27:59,258 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/tb_runs
2022-11-03 23:28:00,436 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-03 23:28:00,488 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
2022-11-03 23:28:02,750 - INFO  - Inserted quantizers into the original model
2022-11-03 23:28:04,653 - INFO  - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_5_epoch60_checkpoint.pth.tar
2022-11-03 23:28:04,654 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 23:28:04,654 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 23:28:04,654 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 23:28:04,655 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:28:08,529 - INFO  - Validation [   20/   40]   Loss 0.404983   Top1 90.195312   Top5 99.511719   BatchTime 0.193672   
2022-11-03 23:28:09,717 - INFO  - Validation [   40/   40]   Loss 0.395401   Top1 90.590000   Top5 99.570000   BatchTime 0.126549   
2022-11-03 23:28:09,893 - INFO  - ==> Top1: 90.590    Top5: 99.570    Loss: 0.395

2022-11-03 23:28:09,923 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:28:09,923 - INFO  - >>>>>>>> Epoch   0
2022-11-03 23:28:09,924 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:28:14,783 - INFO  - Training [0][   20/  196]   Loss 0.026072   Top1 99.179688   Top5 100.000000   BatchTime 0.242918   LR 0.010000   
2022-11-03 23:28:17,264 - INFO  - Training [0][   40/  196]   Loss 0.026566   Top1 99.150391   Top5 100.000000   BatchTime 0.183487   LR 0.010000   
2022-11-03 23:28:19,759 - INFO  - Training [0][   60/  196]   Loss 0.027222   Top1 99.082031   Top5 100.000000   BatchTime 0.163906   LR 0.010000   
2022-11-03 23:28:22,253 - INFO  - Training [0][   80/  196]   Loss 0.028006   Top1 99.028320   Top5 100.000000   BatchTime 0.154112   LR 0.010000   
2022-11-03 23:28:24,736 - INFO  - Training [0][  100/  196]   Loss 0.028875   Top1 98.988281   Top5 100.000000   BatchTime 0.148112   LR 0.010000   
2022-11-03 23:28:27,223 - INFO  - Training [0][  120/  196]   Loss 0.028980   Top1 99.016927   Top5 100.000000   BatchTime 0.144156   LR 0.010000   
2022-11-03 23:28:29,696 - INFO  - Training [0][  140/  196]   Loss 0.029900   Top1 99.006696   Top5 100.000000   BatchTime 0.141225   LR 0.010000   
2022-11-03 23:28:32,172 - INFO  - Training [0][  160/  196]   Loss 0.031447   Top1 98.928223   Top5 100.000000   BatchTime 0.139049   LR 0.010000   
2022-11-03 23:28:34,646 - INFO  - Training [0][  180/  196]   Loss 0.032103   Top1 98.899740   Top5 100.000000   BatchTime 0.137339   LR 0.010000   
2022-11-03 23:28:37,231 - INFO  - ==> Top1: 98.894    Top5: 100.000    Loss: 0.032

2022-11-03 23:28:37,232 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:28:40,103 - INFO  - Validation [0][   20/   40]   Loss 0.422709   Top1 90.156250   Top5 99.550781   BatchTime 0.143459   
2022-11-03 23:28:41,235 - INFO  - Validation [0][   40/   40]   Loss 0.402163   Top1 90.640000   Top5 99.570000   BatchTime 0.100028   
2022-11-03 23:28:41,488 - INFO  - ==> Top1: 90.640    Top5: 99.570    Loss: 0.402

2022-11-03 23:28:41,536 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:28:41,536 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:28:41,606 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:28:41,668 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:28:41,669 - INFO  - >>>>>>>> Epoch   1
2022-11-03 23:28:41,669 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:28:45,713 - INFO  - Training [1][   20/  196]   Loss 0.032587   Top1 98.984375   Top5 100.000000   BatchTime 0.202183   LR 0.010000   
2022-11-03 23:28:47,738 - INFO  - Training [1][   40/  196]   Loss 0.033495   Top1 98.916016   Top5 100.000000   BatchTime 0.151704   LR 0.010000   
2022-11-03 23:28:49,784 - INFO  - Training [1][   60/  196]   Loss 0.033844   Top1 98.906250   Top5 100.000000   BatchTime 0.135233   LR 0.010000   
2022-11-03 23:28:51,693 - INFO  - Training [1][   80/  196]   Loss 0.032505   Top1 98.959961   Top5 100.000000   BatchTime 0.125292   LR 0.010000   
2022-11-03 23:28:54,155 - INFO  - Training [1][  100/  196]   Loss 0.033482   Top1 98.937500   Top5 100.000000   BatchTime 0.124849   LR 0.010000   
2022-11-03 23:28:56,644 - INFO  - Training [1][  120/  196]   Loss 0.032548   Top1 98.955078   Top5 100.000000   BatchTime 0.124784   LR 0.010000   
2022-11-03 23:28:59,128 - INFO  - Training [1][  140/  196]   Loss 0.032716   Top1 98.948103   Top5 100.000000   BatchTime 0.124697   LR 0.010000   
2022-11-03 23:29:01,596 - INFO  - Training [1][  160/  196]   Loss 0.032614   Top1 98.945312   Top5 100.000000   BatchTime 0.124536   LR 0.010000   
2022-11-03 23:29:04,071 - INFO  - Training [1][  180/  196]   Loss 0.033606   Top1 98.914931   Top5 99.997830   BatchTime 0.124450   LR 0.010000   
2022-11-03 23:29:06,258 - INFO  - ==> Top1: 98.882    Top5: 99.998    Loss: 0.034

2022-11-03 23:29:06,259 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:29:09,147 - INFO  - Validation [1][   20/   40]   Loss 0.434121   Top1 89.980469   Top5 99.335938   BatchTime 0.144321   
2022-11-03 23:29:10,278 - INFO  - Validation [1][   40/   40]   Loss 0.421849   Top1 90.190000   Top5 99.500000   BatchTime 0.100430   
2022-11-03 23:29:10,543 - INFO  - ==> Top1: 90.190    Top5: 99.500    Loss: 0.422

2022-11-03 23:29:10,574 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:29:10,575 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:29:10,575 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 90.190   Top5: 99.500] Sparsity : 0.774
2022-11-03 23:29:10,679 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:29:10,680 - INFO  - >>>>>>>> Epoch   2
2022-11-03 23:29:10,681 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:29:15,092 - INFO  - Training [2][   20/  196]   Loss 0.027154   Top1 98.925781   Top5 100.000000   BatchTime 0.220541   LR 0.010000   
2022-11-03 23:29:17,554 - INFO  - Training [2][   40/  196]   Loss 0.028418   Top1 98.916016   Top5 100.000000   BatchTime 0.171814   LR 0.010000   
2022-11-03 23:29:20,064 - INFO  - Training [2][   60/  196]   Loss 0.028723   Top1 98.893229   Top5 100.000000   BatchTime 0.156380   LR 0.010000   
2022-11-03 23:29:22,548 - INFO  - Training [2][   80/  196]   Loss 0.029911   Top1 98.896484   Top5 100.000000   BatchTime 0.148328   LR 0.010000   
2022-11-03 23:29:25,045 - INFO  - Training [2][  100/  196]   Loss 0.029867   Top1 98.910156   Top5 100.000000   BatchTime 0.143631   LR 0.010000   
2022-11-03 23:29:27,526 - INFO  - Training [2][  120/  196]   Loss 0.030313   Top1 98.893229   Top5 100.000000   BatchTime 0.140370   LR 0.010000   
2022-11-03 23:29:30,016 - INFO  - Training [2][  140/  196]   Loss 0.030753   Top1 98.878348   Top5 100.000000   BatchTime 0.138098   LR 0.010000   
2022-11-03 23:29:32,478 - INFO  - Training [2][  160/  196]   Loss 0.031949   Top1 98.857422   Top5 100.000000   BatchTime 0.136228   LR 0.010000   
2022-11-03 23:29:34,940 - INFO  - Training [2][  180/  196]   Loss 0.032561   Top1 98.836806   Top5 100.000000   BatchTime 0.134765   LR 0.010000   
2022-11-03 23:29:37,107 - INFO  - ==> Top1: 98.830    Top5: 100.000    Loss: 0.033

2022-11-03 23:29:37,107 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:29:39,678 - INFO  - Validation [2][   20/   40]   Loss 0.442107   Top1 90.195312   Top5 99.453125   BatchTime 0.128461   
2022-11-03 23:29:40,582 - INFO  - Validation [2][   40/   40]   Loss 0.425591   Top1 90.600000   Top5 99.550000   BatchTime 0.086814   
2022-11-03 23:29:40,832 - INFO  - ==> Top1: 90.600    Top5: 99.550    Loss: 0.426

2022-11-03 23:29:40,868 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:29:40,869 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:29:40,869 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:29:40,967 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:29:40,968 - INFO  - >>>>>>>> Epoch   3
2022-11-03 23:29:40,969 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:29:44,814 - INFO  - Training [3][   20/  196]   Loss 0.024891   Top1 99.199219   Top5 100.000000   BatchTime 0.192214   LR 0.010000   
2022-11-03 23:29:47,288 - INFO  - Training [3][   40/  196]   Loss 0.025113   Top1 99.169922   Top5 100.000000   BatchTime 0.157981   LR 0.010000   
2022-11-03 23:29:49,764 - INFO  - Training [3][   60/  196]   Loss 0.028087   Top1 99.062500   Top5 99.993490   BatchTime 0.146574   LR 0.010000   
2022-11-03 23:29:52,251 - INFO  - Training [3][   80/  196]   Loss 0.029606   Top1 98.994141   Top5 99.995117   BatchTime 0.141017   LR 0.010000   
2022-11-03 23:29:54,735 - INFO  - Training [3][  100/  196]   Loss 0.030006   Top1 98.992188   Top5 99.996094   BatchTime 0.137657   LR 0.010000   
2022-11-03 23:29:57,214 - INFO  - Training [3][  120/  196]   Loss 0.030175   Top1 98.974609   Top5 99.996745   BatchTime 0.135375   LR 0.010000   
2022-11-03 23:29:59,695 - INFO  - Training [3][  140/  196]   Loss 0.030872   Top1 98.953683   Top5 99.997210   BatchTime 0.133751   LR 0.010000   
2022-11-03 23:30:02,165 - INFO  - Training [3][  160/  196]   Loss 0.030976   Top1 98.945312   Top5 99.997559   BatchTime 0.132470   LR 0.010000   
2022-11-03 23:30:04,635 - INFO  - Training [3][  180/  196]   Loss 0.030841   Top1 98.953993   Top5 99.997830   BatchTime 0.131475   LR 0.010000   
2022-11-03 23:30:06,843 - INFO  - ==> Top1: 98.926    Top5: 99.998    Loss: 0.032

2022-11-03 23:30:06,844 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:30:09,710 - INFO  - Validation [3][   20/   40]   Loss 0.440977   Top1 89.941406   Top5 99.570312   BatchTime 0.143256   
2022-11-03 23:30:10,825 - INFO  - Validation [3][   40/   40]   Loss 0.427584   Top1 90.310000   Top5 99.620000   BatchTime 0.099507   
2022-11-03 23:30:11,103 - INFO  - ==> Top1: 90.310    Top5: 99.620    Loss: 0.428

2022-11-03 23:30:11,145 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:30:11,146 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:30:11,146 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:30:11,254 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:30:11,255 - INFO  - >>>>>>>> Epoch   4
2022-11-03 23:30:11,256 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:30:15,673 - INFO  - Training [4][   20/  196]   Loss 0.032738   Top1 98.906250   Top5 100.000000   BatchTime 0.220842   LR 0.010000   
2022-11-03 23:30:18,170 - INFO  - Training [4][   40/  196]   Loss 0.028842   Top1 99.062500   Top5 100.000000   BatchTime 0.172852   LR 0.010000   
2022-11-03 23:30:20,668 - INFO  - Training [4][   60/  196]   Loss 0.030080   Top1 98.997396   Top5 99.993490   BatchTime 0.156859   LR 0.010000   
2022-11-03 23:30:23,152 - INFO  - Training [4][   80/  196]   Loss 0.030201   Top1 98.969727   Top5 99.995117   BatchTime 0.148692   LR 0.010000   
2022-11-03 23:30:25,631 - INFO  - Training [4][  100/  196]   Loss 0.031380   Top1 98.929688   Top5 99.996094   BatchTime 0.143748   LR 0.010000   
2022-11-03 23:30:28,119 - INFO  - Training [4][  120/  196]   Loss 0.031555   Top1 98.922526   Top5 99.996745   BatchTime 0.140521   LR 0.010000   
2022-11-03 23:30:30,594 - INFO  - Training [4][  140/  196]   Loss 0.031702   Top1 98.922991   Top5 99.997210   BatchTime 0.138126   LR 0.010000   
2022-11-03 23:30:32,396 - INFO  - Training [4][  160/  196]   Loss 0.032045   Top1 98.916016   Top5 99.997559   BatchTime 0.132123   LR 0.010000   
2022-11-03 23:30:34,457 - INFO  - Training [4][  180/  196]   Loss 0.032055   Top1 98.908420   Top5 99.997830   BatchTime 0.128894   LR 0.010000   
2022-11-03 23:30:36,300 - INFO  - ==> Top1: 98.890    Top5: 99.998    Loss: 0.032

2022-11-03 23:30:36,301 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:30:38,896 - INFO  - Validation [4][   20/   40]   Loss 0.455635   Top1 90.234375   Top5 99.472656   BatchTime 0.129706   
2022-11-03 23:30:40,013 - INFO  - Validation [4][   40/   40]   Loss 0.435932   Top1 90.420000   Top5 99.560000   BatchTime 0.092776   
2022-11-03 23:30:40,264 - INFO  - ==> Top1: 90.420    Top5: 99.560    Loss: 0.436

2022-11-03 23:30:40,293 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:30:40,294 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:30:40,294 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:30:40,396 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:30:40,396 - INFO  - >>>>>>>> Epoch   5
2022-11-03 23:30:40,397 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:30:44,777 - INFO  - Training [5][   20/  196]   Loss 0.027176   Top1 99.179688   Top5 100.000000   BatchTime 0.218969   LR 0.010000   
2022-11-03 23:30:47,267 - INFO  - Training [5][   40/  196]   Loss 0.031313   Top1 98.964844   Top5 100.000000   BatchTime 0.171748   LR 0.010000   
2022-11-03 23:30:49,750 - INFO  - Training [5][   60/  196]   Loss 0.032570   Top1 98.873698   Top5 100.000000   BatchTime 0.155883   LR 0.010000   
2022-11-03 23:30:52,323 - INFO  - Training [5][   80/  196]   Loss 0.031542   Top1 98.906250   Top5 100.000000   BatchTime 0.149066   LR 0.010000   
2022-11-03 23:30:54,811 - INFO  - Training [5][  100/  196]   Loss 0.031000   Top1 98.917969   Top5 100.000000   BatchTime 0.144133   LR 0.010000   
2022-11-03 23:30:57,292 - INFO  - Training [5][  120/  196]   Loss 0.031918   Top1 98.876953   Top5 100.000000   BatchTime 0.140790   LR 0.010000   
2022-11-03 23:30:59,770 - INFO  - Training [5][  140/  196]   Loss 0.032221   Top1 98.878348   Top5 100.000000   BatchTime 0.138374   LR 0.010000   
2022-11-03 23:31:02,243 - INFO  - Training [5][  160/  196]   Loss 0.031659   Top1 98.906250   Top5 100.000000   BatchTime 0.136533   LR 0.010000   
2022-11-03 23:31:04,711 - INFO  - Training [5][  180/  196]   Loss 0.032388   Top1 98.886719   Top5 100.000000   BatchTime 0.135072   LR 0.010000   
2022-11-03 23:31:06,892 - INFO  - ==> Top1: 98.884    Top5: 100.000    Loss: 0.033

2022-11-03 23:31:06,893 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:31:09,751 - INFO  - Validation [5][   20/   40]   Loss 0.447515   Top1 90.273438   Top5 99.511719   BatchTime 0.142867   
2022-11-03 23:31:10,844 - INFO  - Validation [5][   40/   40]   Loss 0.430193   Top1 90.490000   Top5 99.610000   BatchTime 0.098759   
2022-11-03 23:31:11,099 - INFO  - ==> Top1: 90.490    Top5: 99.610    Loss: 0.430

2022-11-03 23:31:11,133 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:31:11,134 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:31:11,134 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.590   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:31:11,270 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:31:11,270 - INFO  - >>>>>>>> Epoch   6
2022-11-03 23:31:11,271 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:31:15,651 - INFO  - Training [6][   20/  196]   Loss 0.029733   Top1 99.062500   Top5 100.000000   BatchTime 0.218962   LR 0.010000   
2022-11-03 23:31:18,131 - INFO  - Training [6][   40/  196]   Loss 0.028205   Top1 99.091797   Top5 100.000000   BatchTime 0.171489   LR 0.010000   
2022-11-03 23:31:20,609 - INFO  - Training [6][   60/  196]   Loss 0.027562   Top1 99.088542   Top5 100.000000   BatchTime 0.155627   LR 0.010000   
2022-11-03 23:31:23,084 - INFO  - Training [6][   80/  196]   Loss 0.025620   Top1 99.174805   Top5 100.000000   BatchTime 0.147661   LR 0.010000   
2022-11-03 23:31:25,156 - INFO  - Training [6][  100/  196]   Loss 0.027187   Top1 99.113281   Top5 99.996094   BatchTime 0.138847   LR 0.010000   
2022-11-03 23:31:27,118 - INFO  - Training [6][  120/  196]   Loss 0.027338   Top1 99.082031   Top5 99.996745   BatchTime 0.132054   LR 0.010000   
2022-11-03 23:31:29,168 - INFO  - Training [6][  140/  196]   Loss 0.027331   Top1 99.082031   Top5 99.997210   BatchTime 0.127834   LR 0.010000   
2022-11-03 23:31:31,174 - INFO  - Training [6][  160/  196]   Loss 0.027305   Top1 99.067383   Top5 99.997559   BatchTime 0.124390   LR 0.010000   
2022-11-03 23:31:33,006 - INFO  - Training [6][  180/  196]   Loss 0.027796   Top1 99.029948   Top5 99.997830   BatchTime 0.120748   LR 0.010000   
2022-11-03 23:31:35,052 - INFO  - ==> Top1: 99.022    Top5: 99.998    Loss: 0.028

2022-11-03 23:31:35,053 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:31:37,974 - INFO  - Validation [6][   20/   40]   Loss 0.450137   Top1 90.273438   Top5 99.550781   BatchTime 0.145993   
2022-11-03 23:31:39,103 - INFO  - Validation [6][   40/   40]   Loss 0.426382   Top1 90.600000   Top5 99.570000   BatchTime 0.101224   
2022-11-03 23:31:39,360 - INFO  - ==> Top1: 90.600    Top5: 99.570    Loss: 0.426

2022-11-03 23:31:39,402 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:31:39,403 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.600   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:31:39,403 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:31:39,508 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:31:39,508 - INFO  - >>>>>>>> Epoch   7
2022-11-03 23:31:39,510 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:31:43,913 - INFO  - Training [7][   20/  196]   Loss 0.026759   Top1 99.160156   Top5 100.000000   BatchTime 0.220178   LR 0.010000   
2022-11-03 23:31:46,398 - INFO  - Training [7][   40/  196]   Loss 0.028133   Top1 99.072266   Top5 100.000000   BatchTime 0.172196   LR 0.010000   
2022-11-03 23:31:48,877 - INFO  - Training [7][   60/  196]   Loss 0.027300   Top1 99.114583   Top5 100.000000   BatchTime 0.156121   LR 0.010000   
2022-11-03 23:31:51,357 - INFO  - Training [7][   80/  196]   Loss 0.027896   Top1 99.082031   Top5 100.000000   BatchTime 0.148091   LR 0.010000   
2022-11-03 23:31:53,839 - INFO  - Training [7][  100/  196]   Loss 0.028740   Top1 99.023438   Top5 100.000000   BatchTime 0.143285   LR 0.010000   
2022-11-03 23:31:56,329 - INFO  - Training [7][  120/  196]   Loss 0.028986   Top1 98.997396   Top5 100.000000   BatchTime 0.140153   LR 0.010000   
2022-11-03 23:31:58,807 - INFO  - Training [7][  140/  196]   Loss 0.029093   Top1 98.981585   Top5 100.000000   BatchTime 0.137831   LR 0.010000   
2022-11-03 23:32:01,282 - INFO  - Training [7][  160/  196]   Loss 0.029265   Top1 98.977051   Top5 100.000000   BatchTime 0.136073   LR 0.010000   
2022-11-03 23:32:03,753 - INFO  - Training [7][  180/  196]   Loss 0.029439   Top1 98.971354   Top5 100.000000   BatchTime 0.134684   LR 0.010000   
2022-11-03 23:32:05,932 - INFO  - ==> Top1: 98.974    Top5: 100.000    Loss: 0.029

2022-11-03 23:32:05,932 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:32:08,812 - INFO  - Validation [7][   20/   40]   Loss 0.454944   Top1 90.312500   Top5 99.511719   BatchTime 0.143906   
2022-11-03 23:32:09,922 - INFO  - Validation [7][   40/   40]   Loss 0.435083   Top1 90.420000   Top5 99.570000   BatchTime 0.099707   
2022-11-03 23:32:10,178 - INFO  - ==> Top1: 90.420    Top5: 99.570    Loss: 0.435

2022-11-03 23:32:10,216 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:32:10,216 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.600   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:32:10,216 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:32:10,339 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:32:10,340 - INFO  - >>>>>>>> Epoch   8
2022-11-03 23:32:10,341 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:32:14,714 - INFO  - Training [8][   20/  196]   Loss 0.023527   Top1 99.296875   Top5 100.000000   BatchTime 0.218600   LR 0.010000   
2022-11-03 23:32:17,013 - INFO  - Training [8][   40/  196]   Loss 0.024897   Top1 99.169922   Top5 100.000000   BatchTime 0.166779   LR 0.010000   
2022-11-03 23:32:18,873 - INFO  - Training [8][   60/  196]   Loss 0.025355   Top1 99.166667   Top5 100.000000   BatchTime 0.142182   LR 0.010000   
2022-11-03 23:32:20,936 - INFO  - Training [8][   80/  196]   Loss 0.026235   Top1 99.135742   Top5 100.000000   BatchTime 0.132425   LR 0.010000   
2022-11-03 23:32:22,984 - INFO  - Training [8][  100/  196]   Loss 0.026415   Top1 99.113281   Top5 100.000000   BatchTime 0.126420   LR 0.010000   
2022-11-03 23:32:24,887 - INFO  - Training [8][  120/  196]   Loss 0.026594   Top1 99.111328   Top5 100.000000   BatchTime 0.121209   LR 0.010000   
2022-11-03 23:32:27,166 - INFO  - Training [8][  140/  196]   Loss 0.026329   Top1 99.129464   Top5 100.000000   BatchTime 0.120172   LR 0.010000   
2022-11-03 23:32:29,641 - INFO  - Training [8][  160/  196]   Loss 0.027575   Top1 99.079590   Top5 100.000000   BatchTime 0.120621   LR 0.010000   
2022-11-03 23:32:32,111 - INFO  - Training [8][  180/  196]   Loss 0.027021   Top1 99.075521   Top5 100.000000   BatchTime 0.120941   LR 0.010000   
2022-11-03 23:32:34,288 - INFO  - ==> Top1: 99.068    Top5: 100.000    Loss: 0.028

2022-11-03 23:32:34,288 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:32:37,210 - INFO  - Validation [8][   20/   40]   Loss 0.460408   Top1 89.960938   Top5 99.550781   BatchTime 0.146015   
2022-11-03 23:32:38,371 - INFO  - Validation [8][   40/   40]   Loss 0.442979   Top1 89.980000   Top5 99.630000   BatchTime 0.102028   
2022-11-03 23:32:38,632 - INFO  - ==> Top1: 89.980    Top5: 99.630    Loss: 0.443

2022-11-03 23:32:38,660 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:32:38,661 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.600   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:32:38,661 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 90.600   Top5: 99.550] Sparsity : 0.774
2022-11-03 23:32:38,755 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:32:38,755 - INFO  - >>>>>>>> Epoch   9
2022-11-03 23:32:38,757 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:32:43,117 - INFO  - Training [9][   20/  196]   Loss 0.023327   Top1 99.121094   Top5 100.000000   BatchTime 0.217976   LR 0.010000   
2022-11-03 23:32:45,609 - INFO  - Training [9][   40/  196]   Loss 0.025733   Top1 99.121094   Top5 99.990234   BatchTime 0.171297   LR 0.010000   
2022-11-03 23:32:48,095 - INFO  - Training [9][   60/  196]   Loss 0.024537   Top1 99.173177   Top5 99.993490   BatchTime 0.155639   LR 0.010000   
2022-11-03 23:32:50,563 - INFO  - Training [9][   80/  196]   Loss 0.023883   Top1 99.194336   Top5 99.995117   BatchTime 0.147575   LR 0.010000   
2022-11-03 23:32:53,171 - INFO  - Training [9][  100/  196]   Loss 0.025483   Top1 99.132812   Top5 99.996094   BatchTime 0.144142   LR 0.010000   
2022-11-03 23:32:55,647 - INFO  - Training [9][  120/  196]   Loss 0.024716   Top1 99.169922   Top5 99.996745   BatchTime 0.140750   LR 0.010000   
2022-11-03 23:32:58,124 - INFO  - Training [9][  140/  196]   Loss 0.024837   Top1 99.162946   Top5 99.997210   BatchTime 0.138331   LR 0.010000   
2022-11-03 23:33:00,588 - INFO  - Training [9][  160/  196]   Loss 0.024864   Top1 99.157715   Top5 99.997559   BatchTime 0.136444   LR 0.010000   
2022-11-03 23:33:03,057 - INFO  - Training [9][  180/  196]   Loss 0.024963   Top1 99.153646   Top5 99.995660   BatchTime 0.134995   LR 0.010000   
2022-11-03 23:33:05,196 - INFO  - ==> Top1: 99.160    Top5: 99.996    Loss: 0.025

2022-11-03 23:33:05,197 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:33:08,084 - INFO  - Validation [9][   20/   40]   Loss 0.461379   Top1 90.488281   Top5 99.550781   BatchTime 0.144293   
2022-11-03 23:33:09,185 - INFO  - Validation [9][   40/   40]   Loss 0.439396   Top1 90.670000   Top5 99.650000   BatchTime 0.099675   
2022-11-03 23:33:09,518 - INFO  - ==> Top1: 90.670    Top5: 99.650    Loss: 0.439

2022-11-03 23:33:09,542 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:33:09,543 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:33:09,543 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.600   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:33:09,731 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:33:09,902 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:33:09,902 - INFO  - >>>>>>>> Epoch  10
2022-11-03 23:33:09,903 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:33:13,990 - INFO  - Training [10][   20/  196]   Loss 0.023761   Top1 99.160156   Top5 100.000000   BatchTime 0.204330   LR 0.010000   
2022-11-03 23:33:16,114 - INFO  - Training [10][   40/  196]   Loss 0.024730   Top1 99.062500   Top5 100.000000   BatchTime 0.155253   LR 0.010000   
2022-11-03 23:33:17,868 - INFO  - Training [10][   60/  196]   Loss 0.024923   Top1 99.101562   Top5 100.000000   BatchTime 0.132738   LR 0.010000   
2022-11-03 23:33:20,313 - INFO  - Training [10][   80/  196]   Loss 0.025553   Top1 99.067383   Top5 100.000000   BatchTime 0.130114   LR 0.010000   
2022-11-03 23:33:22,801 - INFO  - Training [10][  100/  196]   Loss 0.025185   Top1 99.101562   Top5 100.000000   BatchTime 0.128969   LR 0.010000   
2022-11-03 23:33:25,301 - INFO  - Training [10][  120/  196]   Loss 0.025018   Top1 99.098307   Top5 100.000000   BatchTime 0.128314   LR 0.010000   
2022-11-03 23:33:27,793 - INFO  - Training [10][  140/  196]   Loss 0.025149   Top1 99.095982   Top5 100.000000   BatchTime 0.127780   LR 0.010000   
2022-11-03 23:33:30,260 - INFO  - Training [10][  160/  196]   Loss 0.024900   Top1 99.125977   Top5 100.000000   BatchTime 0.127228   LR 0.010000   
2022-11-03 23:33:32,740 - INFO  - Training [10][  180/  196]   Loss 0.024748   Top1 99.127604   Top5 100.000000   BatchTime 0.126865   LR 0.010000   
2022-11-03 23:33:34,932 - INFO  - ==> Top1: 99.138    Top5: 100.000    Loss: 0.025

2022-11-03 23:33:34,933 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:33:37,837 - INFO  - Validation [10][   20/   40]   Loss 0.469323   Top1 90.312500   Top5 99.433594   BatchTime 0.145145   
2022-11-03 23:33:38,973 - INFO  - Validation [10][   40/   40]   Loss 0.449628   Top1 90.490000   Top5 99.530000   BatchTime 0.100974   
2022-11-03 23:33:39,233 - INFO  - ==> Top1: 90.490    Top5: 99.530    Loss: 0.450

2022-11-03 23:33:39,267 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:33:39,267 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:33:39,267 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.600   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:33:39,361 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:33:39,361 - INFO  - >>>>>>>> Epoch  11
2022-11-03 23:33:39,363 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:33:43,778 - INFO  - Training [11][   20/  196]   Loss 0.021992   Top1 99.277344   Top5 100.000000   BatchTime 0.220768   LR 0.010000   
2022-11-03 23:33:46,266 - INFO  - Training [11][   40/  196]   Loss 0.024922   Top1 99.218750   Top5 100.000000   BatchTime 0.172574   LR 0.010000   
2022-11-03 23:33:48,745 - INFO  - Training [11][   60/  196]   Loss 0.026365   Top1 99.173177   Top5 100.000000   BatchTime 0.156373   LR 0.010000   
2022-11-03 23:33:51,231 - INFO  - Training [11][   80/  196]   Loss 0.026621   Top1 99.169922   Top5 100.000000   BatchTime 0.148348   LR 0.010000   
2022-11-03 23:33:53,716 - INFO  - Training [11][  100/  196]   Loss 0.027632   Top1 99.128906   Top5 100.000000   BatchTime 0.143524   LR 0.010000   
2022-11-03 23:33:56,191 - INFO  - Training [11][  120/  196]   Loss 0.027552   Top1 99.127604   Top5 100.000000   BatchTime 0.140228   LR 0.010000   
2022-11-03 23:33:58,665 - INFO  - Training [11][  140/  196]   Loss 0.027741   Top1 99.095982   Top5 100.000000   BatchTime 0.137867   LR 0.010000   
2022-11-03 23:34:01,129 - INFO  - Training [11][  160/  196]   Loss 0.027255   Top1 99.106445   Top5 100.000000   BatchTime 0.136037   LR 0.010000   
2022-11-03 23:34:03,594 - INFO  - Training [11][  180/  196]   Loss 0.026970   Top1 99.112413   Top5 100.000000   BatchTime 0.134616   LR 0.010000   
2022-11-03 23:34:05,366 - INFO  - ==> Top1: 99.102    Top5: 100.000    Loss: 0.027

2022-11-03 23:34:05,367 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:34:08,036 - INFO  - Validation [11][   20/   40]   Loss 0.462496   Top1 90.253906   Top5 99.453125   BatchTime 0.133362   
2022-11-03 23:34:08,881 - INFO  - Validation [11][   40/   40]   Loss 0.439356   Top1 90.630000   Top5 99.580000   BatchTime 0.087808   
2022-11-03 23:34:09,289 - INFO  - ==> Top1: 90.630    Top5: 99.580    Loss: 0.439

2022-11-03 23:34:09,328 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:34:09,336 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:34:09,336 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:34:09,421 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:34:09,421 - INFO  - >>>>>>>> Epoch  12
2022-11-03 23:34:09,423 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:34:13,929 - INFO  - Training [12][   20/  196]   Loss 0.030777   Top1 98.945312   Top5 100.000000   BatchTime 0.225306   LR 0.010000   
2022-11-03 23:34:16,437 - INFO  - Training [12][   40/  196]   Loss 0.026854   Top1 99.062500   Top5 100.000000   BatchTime 0.175360   LR 0.010000   
2022-11-03 23:34:18,941 - INFO  - Training [12][   60/  196]   Loss 0.027429   Top1 99.036458   Top5 100.000000   BatchTime 0.158636   LR 0.010000   
2022-11-03 23:34:21,424 - INFO  - Training [12][   80/  196]   Loss 0.027155   Top1 99.033203   Top5 100.000000   BatchTime 0.150014   LR 0.010000   
2022-11-03 23:34:23,914 - INFO  - Training [12][  100/  196]   Loss 0.025487   Top1 99.109375   Top5 100.000000   BatchTime 0.144913   LR 0.010000   
2022-11-03 23:34:26,398 - INFO  - Training [12][  120/  196]   Loss 0.025192   Top1 99.121094   Top5 100.000000   BatchTime 0.141455   LR 0.010000   
2022-11-03 23:34:28,876 - INFO  - Training [12][  140/  196]   Loss 0.025371   Top1 99.101562   Top5 100.000000   BatchTime 0.138950   LR 0.010000   
2022-11-03 23:34:31,344 - INFO  - Training [12][  160/  196]   Loss 0.024661   Top1 99.155273   Top5 100.000000   BatchTime 0.137004   LR 0.010000   
2022-11-03 23:34:33,813 - INFO  - Training [12][  180/  196]   Loss 0.024152   Top1 99.168837   Top5 100.000000   BatchTime 0.135498   LR 0.010000   
2022-11-03 23:34:36,009 - INFO  - ==> Top1: 99.164    Top5: 100.000    Loss: 0.024

2022-11-03 23:34:36,009 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:34:38,910 - INFO  - Validation [12][   20/   40]   Loss 0.468665   Top1 90.234375   Top5 99.472656   BatchTime 0.144995   
2022-11-03 23:34:40,031 - INFO  - Validation [12][   40/   40]   Loss 0.444911   Top1 90.420000   Top5 99.590000   BatchTime 0.100500   
2022-11-03 23:34:40,293 - INFO  - ==> Top1: 90.420    Top5: 99.590    Loss: 0.445

2022-11-03 23:34:40,331 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:34:40,332 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:34:40,332 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:34:40,446 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:34:40,446 - INFO  - >>>>>>>> Epoch  13
2022-11-03 23:34:40,447 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:34:44,872 - INFO  - Training [13][   20/  196]   Loss 0.021642   Top1 99.257812   Top5 100.000000   BatchTime 0.221197   LR 0.010000   
2022-11-03 23:34:47,367 - INFO  - Training [13][   40/  196]   Loss 0.022545   Top1 99.248047   Top5 100.000000   BatchTime 0.172993   LR 0.010000   
2022-11-03 23:34:49,869 - INFO  - Training [13][   60/  196]   Loss 0.024461   Top1 99.166667   Top5 100.000000   BatchTime 0.157016   LR 0.010000   
2022-11-03 23:34:52,436 - INFO  - Training [13][   80/  196]   Loss 0.025096   Top1 99.135742   Top5 100.000000   BatchTime 0.149857   LR 0.010000   
2022-11-03 23:34:54,933 - INFO  - Training [13][  100/  196]   Loss 0.025572   Top1 99.125000   Top5 100.000000   BatchTime 0.144854   LR 0.010000   
2022-11-03 23:34:57,437 - INFO  - Training [13][  120/  196]   Loss 0.024398   Top1 99.169922   Top5 100.000000   BatchTime 0.141576   LR 0.010000   
2022-11-03 23:34:59,229 - INFO  - Training [13][  140/  196]   Loss 0.023716   Top1 99.193638   Top5 100.000000   BatchTime 0.134146   LR 0.010000   
2022-11-03 23:35:01,277 - INFO  - Training [13][  160/  196]   Loss 0.024023   Top1 99.187012   Top5 100.000000   BatchTime 0.130178   LR 0.010000   
2022-11-03 23:35:03,302 - INFO  - Training [13][  180/  196]   Loss 0.024514   Top1 99.164497   Top5 100.000000   BatchTime 0.126963   LR 0.010000   
2022-11-03 23:35:05,155 - INFO  - ==> Top1: 99.174    Top5: 100.000    Loss: 0.024

2022-11-03 23:35:05,156 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:35:08,110 - INFO  - Validation [13][   20/   40]   Loss 0.474657   Top1 90.175781   Top5 99.453125   BatchTime 0.147624   
2022-11-03 23:35:09,238 - INFO  - Validation [13][   40/   40]   Loss 0.456133   Top1 90.380000   Top5 99.580000   BatchTime 0.102011   
2022-11-03 23:35:09,497 - INFO  - ==> Top1: 90.380    Top5: 99.580    Loss: 0.456

2022-11-03 23:35:09,538 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:35:09,539 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:35:09,539 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:35:09,619 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:35:09,619 - INFO  - >>>>>>>> Epoch  14
2022-11-03 23:35:09,620 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:35:14,004 - INFO  - Training [14][   20/  196]   Loss 0.019791   Top1 99.335938   Top5 100.000000   BatchTime 0.219174   LR 0.010000   
2022-11-03 23:35:16,491 - INFO  - Training [14][   40/  196]   Loss 0.021142   Top1 99.277344   Top5 100.000000   BatchTime 0.171757   LR 0.010000   
2022-11-03 23:35:18,975 - INFO  - Training [14][   60/  196]   Loss 0.021291   Top1 99.270833   Top5 100.000000   BatchTime 0.155907   LR 0.010000   
2022-11-03 23:35:21,466 - INFO  - Training [14][   80/  196]   Loss 0.022234   Top1 99.238281   Top5 100.000000   BatchTime 0.148064   LR 0.010000   
2022-11-03 23:35:23,972 - INFO  - Training [14][  100/  196]   Loss 0.021421   Top1 99.296875   Top5 100.000000   BatchTime 0.143511   LR 0.010000   
2022-11-03 23:35:26,464 - INFO  - Training [14][  120/  196]   Loss 0.021261   Top1 99.283854   Top5 100.000000   BatchTime 0.140359   LR 0.010000   
2022-11-03 23:35:28,935 - INFO  - Training [14][  140/  196]   Loss 0.021257   Top1 99.282924   Top5 100.000000   BatchTime 0.137958   LR 0.010000   
2022-11-03 23:35:31,408 - INFO  - Training [14][  160/  196]   Loss 0.021749   Top1 99.267578   Top5 100.000000   BatchTime 0.136167   LR 0.010000   
2022-11-03 23:35:33,891 - INFO  - Training [14][  180/  196]   Loss 0.022123   Top1 99.257812   Top5 100.000000   BatchTime 0.134835   LR 0.010000   
2022-11-03 23:35:36,096 - INFO  - ==> Top1: 99.230    Top5: 100.000    Loss: 0.022

2022-11-03 23:35:36,097 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:35:39,039 - INFO  - Validation [14][   20/   40]   Loss 0.468162   Top1 90.195312   Top5 99.628906   BatchTime 0.146984   
2022-11-03 23:35:40,175 - INFO  - Validation [14][   40/   40]   Loss 0.450584   Top1 90.520000   Top5 99.640000   BatchTime 0.101896   
2022-11-03 23:35:40,425 - INFO  - ==> Top1: 90.520    Top5: 99.640    Loss: 0.451

2022-11-03 23:35:40,468 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:35:40,468 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:35:40,469 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:35:40,576 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:35:40,576 - INFO  - >>>>>>>> Epoch  15
2022-11-03 23:35:40,578 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:35:45,006 - INFO  - Training [15][   20/  196]   Loss 0.020090   Top1 99.414062   Top5 100.000000   BatchTime 0.221407   LR 0.010000   
2022-11-03 23:35:47,496 - INFO  - Training [15][   40/  196]   Loss 0.020165   Top1 99.287109   Top5 100.000000   BatchTime 0.172955   LR 0.010000   
2022-11-03 23:35:49,967 - INFO  - Training [15][   60/  196]   Loss 0.019658   Top1 99.303385   Top5 100.000000   BatchTime 0.156484   LR 0.010000   
2022-11-03 23:35:52,145 - INFO  - Training [15][   80/  196]   Loss 0.020479   Top1 99.277344   Top5 100.000000   BatchTime 0.144590   LR 0.010000   
2022-11-03 23:35:54,119 - INFO  - Training [15][  100/  196]   Loss 0.020051   Top1 99.285156   Top5 100.000000   BatchTime 0.135406   LR 0.010000   
2022-11-03 23:35:56,198 - INFO  - Training [15][  120/  196]   Loss 0.020650   Top1 99.248047   Top5 100.000000   BatchTime 0.130162   LR 0.010000   
2022-11-03 23:35:58,289 - INFO  - Training [15][  140/  196]   Loss 0.021412   Top1 99.246652   Top5 100.000000   BatchTime 0.126507   LR 0.010000   
2022-11-03 23:36:00,014 - INFO  - Training [15][  160/  196]   Loss 0.021415   Top1 99.250488   Top5 100.000000   BatchTime 0.121476   LR 0.010000   
2022-11-03 23:36:02,409 - INFO  - Training [15][  180/  196]   Loss 0.021478   Top1 99.255642   Top5 100.000000   BatchTime 0.121280   LR 0.010000   
2022-11-03 23:36:04,583 - INFO  - ==> Top1: 99.256    Top5: 100.000    Loss: 0.022

2022-11-03 23:36:04,583 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:36:07,492 - INFO  - Validation [15][   20/   40]   Loss 0.478869   Top1 89.746094   Top5 99.531250   BatchTime 0.145397   
2022-11-03 23:36:08,606 - INFO  - Validation [15][   40/   40]   Loss 0.457846   Top1 90.120000   Top5 99.610000   BatchTime 0.100545   
2022-11-03 23:36:08,858 - INFO  - ==> Top1: 90.120    Top5: 99.610    Loss: 0.458

2022-11-03 23:36:08,900 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:36:08,901 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:36:08,901 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:36:08,999 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:36:08,999 - INFO  - >>>>>>>> Epoch  16
2022-11-03 23:36:09,000 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:36:13,404 - INFO  - Training [16][   20/  196]   Loss 0.020029   Top1 99.296875   Top5 100.000000   BatchTime 0.220187   LR 0.010000   
2022-11-03 23:36:15,892 - INFO  - Training [16][   40/  196]   Loss 0.020920   Top1 99.287109   Top5 100.000000   BatchTime 0.172286   LR 0.010000   
2022-11-03 23:36:18,375 - INFO  - Training [16][   60/  196]   Loss 0.021355   Top1 99.251302   Top5 100.000000   BatchTime 0.156233   LR 0.010000   
2022-11-03 23:36:20,868 - INFO  - Training [16][   80/  196]   Loss 0.020209   Top1 99.287109   Top5 100.000000   BatchTime 0.148342   LR 0.010000   
2022-11-03 23:36:23,355 - INFO  - Training [16][  100/  196]   Loss 0.020526   Top1 99.277344   Top5 100.000000   BatchTime 0.143548   LR 0.010000   
2022-11-03 23:36:25,843 - INFO  - Training [16][  120/  196]   Loss 0.021104   Top1 99.274089   Top5 100.000000   BatchTime 0.140352   LR 0.010000   
2022-11-03 23:36:28,329 - INFO  - Training [16][  140/  196]   Loss 0.021557   Top1 99.241071   Top5 100.000000   BatchTime 0.138060   LR 0.010000   
2022-11-03 23:36:30,802 - INFO  - Training [16][  160/  196]   Loss 0.021685   Top1 99.228516   Top5 100.000000   BatchTime 0.136254   LR 0.010000   
2022-11-03 23:36:33,273 - INFO  - Training [16][  180/  196]   Loss 0.021397   Top1 99.242622   Top5 100.000000   BatchTime 0.134842   LR 0.010000   
2022-11-03 23:36:35,467 - INFO  - ==> Top1: 99.256    Top5: 100.000    Loss: 0.021

2022-11-03 23:36:35,468 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:36:38,333 - INFO  - Validation [16][   20/   40]   Loss 0.479265   Top1 90.195312   Top5 99.589844   BatchTime 0.143159   
2022-11-03 23:36:39,468 - INFO  - Validation [16][   40/   40]   Loss 0.463039   Top1 90.500000   Top5 99.630000   BatchTime 0.099973   
2022-11-03 23:36:39,735 - INFO  - ==> Top1: 90.500    Top5: 99.630    Loss: 0.463

2022-11-03 23:36:39,765 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:36:39,766 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:36:39,766 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:36:39,875 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:36:39,875 - INFO  - >>>>>>>> Epoch  17
2022-11-03 23:36:39,877 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:36:44,111 - INFO  - Training [17][   20/  196]   Loss 0.024795   Top1 99.199219   Top5 100.000000   BatchTime 0.211665   LR 0.010000   
2022-11-03 23:36:45,969 - INFO  - Training [17][   40/  196]   Loss 0.023392   Top1 99.228516   Top5 100.000000   BatchTime 0.152293   LR 0.010000   
2022-11-03 23:36:48,022 - INFO  - Training [17][   60/  196]   Loss 0.022788   Top1 99.225260   Top5 100.000000   BatchTime 0.135743   LR 0.010000   
2022-11-03 23:36:50,093 - INFO  - Training [17][   80/  196]   Loss 0.023773   Top1 99.204102   Top5 100.000000   BatchTime 0.127690   LR 0.010000   
2022-11-03 23:36:51,990 - INFO  - Training [17][  100/  196]   Loss 0.023034   Top1 99.230469   Top5 100.000000   BatchTime 0.121117   LR 0.010000   
2022-11-03 23:36:54,374 - INFO  - Training [17][  120/  196]   Loss 0.022929   Top1 99.244792   Top5 100.000000   BatchTime 0.120801   LR 0.010000   
2022-11-03 23:36:56,863 - INFO  - Training [17][  140/  196]   Loss 0.022751   Top1 99.260603   Top5 100.000000   BatchTime 0.121322   LR 0.010000   
2022-11-03 23:36:59,349 - INFO  - Training [17][  160/  196]   Loss 0.022348   Top1 99.265137   Top5 100.000000   BatchTime 0.121691   LR 0.010000   
2022-11-03 23:37:01,819 - INFO  - Training [17][  180/  196]   Loss 0.021903   Top1 99.279514   Top5 100.000000   BatchTime 0.121892   LR 0.010000   
2022-11-03 23:37:04,000 - INFO  - ==> Top1: 99.278    Top5: 100.000    Loss: 0.022

2022-11-03 23:37:04,001 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:37:06,925 - INFO  - Validation [17][   20/   40]   Loss 0.457542   Top1 90.527344   Top5 99.609375   BatchTime 0.146123   
2022-11-03 23:37:08,062 - INFO  - Validation [17][   40/   40]   Loss 0.446764   Top1 90.580000   Top5 99.620000   BatchTime 0.101496   
2022-11-03 23:37:08,320 - INFO  - ==> Top1: 90.580    Top5: 99.620    Loss: 0.447

2022-11-03 23:37:08,360 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:37:08,360 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:37:08,360 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:37:08,465 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:37:08,465 - INFO  - >>>>>>>> Epoch  18
2022-11-03 23:37:08,466 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:37:12,865 - INFO  - Training [18][   20/  196]   Loss 0.025004   Top1 99.179688   Top5 100.000000   BatchTime 0.219931   LR 0.010000   
2022-11-03 23:37:15,351 - INFO  - Training [18][   40/  196]   Loss 0.021919   Top1 99.296875   Top5 100.000000   BatchTime 0.172109   LR 0.010000   
2022-11-03 23:37:17,839 - INFO  - Training [18][   60/  196]   Loss 0.020206   Top1 99.368490   Top5 100.000000   BatchTime 0.156201   LR 0.010000   
2022-11-03 23:37:20,337 - INFO  - Training [18][   80/  196]   Loss 0.020181   Top1 99.365234   Top5 100.000000   BatchTime 0.148383   LR 0.010000   
2022-11-03 23:37:22,843 - INFO  - Training [18][  100/  196]   Loss 0.020079   Top1 99.347656   Top5 100.000000   BatchTime 0.143759   LR 0.010000   
2022-11-03 23:37:25,324 - INFO  - Training [18][  120/  196]   Loss 0.020426   Top1 99.326172   Top5 100.000000   BatchTime 0.140474   LR 0.010000   
2022-11-03 23:37:27,799 - INFO  - Training [18][  140/  196]   Loss 0.020811   Top1 99.321987   Top5 100.000000   BatchTime 0.138089   LR 0.010000   
2022-11-03 23:37:30,272 - INFO  - Training [18][  160/  196]   Loss 0.020327   Top1 99.318848   Top5 100.000000   BatchTime 0.136280   LR 0.010000   
2022-11-03 23:37:32,738 - INFO  - Training [18][  180/  196]   Loss 0.020737   Top1 99.309896   Top5 100.000000   BatchTime 0.134842   LR 0.010000   
2022-11-03 23:37:34,935 - INFO  - ==> Top1: 99.322    Top5: 100.000    Loss: 0.021

2022-11-03 23:37:34,936 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:37:37,680 - INFO  - Validation [18][   20/   40]   Loss 0.478443   Top1 90.097656   Top5 99.589844   BatchTime 0.137138   
2022-11-03 23:37:38,387 - INFO  - Validation [18][   40/   40]   Loss 0.461129   Top1 90.310000   Top5 99.630000   BatchTime 0.086255   
2022-11-03 23:37:38,633 - INFO  - ==> Top1: 90.310    Top5: 99.630    Loss: 0.461

2022-11-03 23:37:38,658 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:37:38,659 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:37:38,659 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:37:38,760 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:37:38,760 - INFO  - >>>>>>>> Epoch  19
2022-11-03 23:37:38,762 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:37:42,803 - INFO  - Training [19][   20/  196]   Loss 0.020314   Top1 99.257812   Top5 100.000000   BatchTime 0.202058   LR 0.010000   
2022-11-03 23:37:44,699 - INFO  - Training [19][   40/  196]   Loss 0.020236   Top1 99.287109   Top5 100.000000   BatchTime 0.148430   LR 0.010000   
2022-11-03 23:37:47,032 - INFO  - Training [19][   60/  196]   Loss 0.020162   Top1 99.277344   Top5 100.000000   BatchTime 0.137842   LR 0.010000   
2022-11-03 23:37:49,528 - INFO  - Training [19][   80/  196]   Loss 0.020857   Top1 99.262695   Top5 100.000000   BatchTime 0.134575   LR 0.010000   
2022-11-03 23:37:52,017 - INFO  - Training [19][  100/  196]   Loss 0.020755   Top1 99.285156   Top5 100.000000   BatchTime 0.132545   LR 0.010000   
2022-11-03 23:37:54,518 - INFO  - Training [19][  120/  196]   Loss 0.020735   Top1 99.270833   Top5 100.000000   BatchTime 0.131300   LR 0.010000   
2022-11-03 23:37:57,019 - INFO  - Training [19][  140/  196]   Loss 0.020491   Top1 99.288504   Top5 100.000000   BatchTime 0.130405   LR 0.010000   
2022-11-03 23:37:59,511 - INFO  - Training [19][  160/  196]   Loss 0.020628   Top1 99.284668   Top5 100.000000   BatchTime 0.129683   LR 0.010000   
2022-11-03 23:38:01,993 - INFO  - Training [19][  180/  196]   Loss 0.020864   Top1 99.281684   Top5 100.000000   BatchTime 0.129062   LR 0.010000   
2022-11-03 23:38:04,174 - INFO  - ==> Top1: 99.268    Top5: 99.998    Loss: 0.021

2022-11-03 23:38:04,174 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:38:07,071 - INFO  - Validation [19][   20/   40]   Loss 0.490359   Top1 89.843750   Top5 99.511719   BatchTime 0.144799   
2022-11-03 23:38:08,193 - INFO  - Validation [19][   40/   40]   Loss 0.465111   Top1 90.340000   Top5 99.590000   BatchTime 0.100452   
2022-11-03 23:38:08,458 - INFO  - ==> Top1: 90.340    Top5: 99.590    Loss: 0.465

2022-11-03 23:38:08,486 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:38:08,487 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:38:08,487 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.630   Top5: 99.580] Sparsity : 0.774
2022-11-03 23:38:08,595 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:38:08,595 - INFO  - >>>>>>>> Epoch  20
2022-11-03 23:38:08,597 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:38:12,990 - INFO  - Training [20][   20/  196]   Loss 0.019035   Top1 99.433594   Top5 100.000000   BatchTime 0.219634   LR 0.001000   
2022-11-03 23:38:15,482 - INFO  - Training [20][   40/  196]   Loss 0.019750   Top1 99.345703   Top5 100.000000   BatchTime 0.172127   LR 0.001000   
2022-11-03 23:38:17,969 - INFO  - Training [20][   60/  196]   Loss 0.021411   Top1 99.277344   Top5 100.000000   BatchTime 0.156204   LR 0.001000   
2022-11-03 23:38:20,451 - INFO  - Training [20][   80/  196]   Loss 0.022126   Top1 99.262695   Top5 100.000000   BatchTime 0.148166   LR 0.001000   
2022-11-03 23:38:22,933 - INFO  - Training [20][  100/  196]   Loss 0.021731   Top1 99.277344   Top5 100.000000   BatchTime 0.143354   LR 0.001000   
2022-11-03 23:38:25,420 - INFO  - Training [20][  120/  196]   Loss 0.022237   Top1 99.280599   Top5 100.000000   BatchTime 0.140192   LR 0.001000   
2022-11-03 23:38:27,893 - INFO  - Training [20][  140/  196]   Loss 0.021900   Top1 99.285714   Top5 100.000000   BatchTime 0.137824   LR 0.001000   
2022-11-03 23:38:30,351 - INFO  - Training [20][  160/  196]   Loss 0.021451   Top1 99.291992   Top5 100.000000   BatchTime 0.135957   LR 0.001000   
2022-11-03 23:38:32,356 - INFO  - Training [20][  180/  196]   Loss 0.021441   Top1 99.292535   Top5 100.000000   BatchTime 0.131990   LR 0.001000   
2022-11-03 23:38:34,135 - INFO  - ==> Top1: 99.294    Top5: 100.000    Loss: 0.021

2022-11-03 23:38:34,136 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:38:36,767 - INFO  - Validation [20][   20/   40]   Loss 0.472823   Top1 90.312500   Top5 99.589844   BatchTime 0.131450   
2022-11-03 23:38:37,455 - INFO  - Validation [20][   40/   40]   Loss 0.451008   Top1 90.670000   Top5 99.640000   BatchTime 0.082946   
2022-11-03 23:38:37,718 - INFO  - ==> Top1: 90.670    Top5: 99.640    Loss: 0.451

2022-11-03 23:38:37,743 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:38:37,744 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.670   Top5: 99.640] Sparsity : 0.775
2022-11-03 23:38:37,744 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 90.640   Top5: 99.570] Sparsity : 0.774
2022-11-03 23:38:37,840 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:38:37,841 - INFO  - >>>>>>>> Epoch  21
2022-11-03 23:38:37,842 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:38:42,311 - INFO  - Training [21][   20/  196]   Loss 0.015299   Top1 99.433594   Top5 100.000000   BatchTime 0.223424   LR 0.001000   
2022-11-03 23:38:44,789 - INFO  - Training [21][   40/  196]   Loss 0.015918   Top1 99.482422   Top5 100.000000   BatchTime 0.173669   LR 0.001000   
2022-11-03 23:38:47,276 - INFO  - Training [21][   60/  196]   Loss 0.017621   Top1 99.368490   Top5 100.000000   BatchTime 0.157230   LR 0.001000   
2022-11-03 23:38:49,716 - INFO  - Training [21][   80/  196]   Loss 0.017782   Top1 99.350586   Top5 100.000000   BatchTime 0.148419   LR 0.001000   
2022-11-03 23:38:52,198 - INFO  - Training [21][  100/  196]   Loss 0.017625   Top1 99.386719   Top5 100.000000   BatchTime 0.143556   LR 0.001000   
2022-11-03 23:38:54,681 - INFO  - Training [21][  120/  196]   Loss 0.018117   Top1 99.368490   Top5 100.000000   BatchTime 0.140324   LR 0.001000   
2022-11-03 23:38:57,250 - INFO  - Training [21][  140/  196]   Loss 0.018137   Top1 99.380580   Top5 100.000000   BatchTime 0.138624   LR 0.001000   
2022-11-03 23:38:59,712 - INFO  - Training [21][  160/  196]   Loss 0.018133   Top1 99.367676   Top5 100.000000   BatchTime 0.136685   LR 0.001000   
2022-11-03 23:39:02,179 - INFO  - Training [21][  180/  196]   Loss 0.018183   Top1 99.372830   Top5 100.000000   BatchTime 0.135201   LR 0.001000   
2022-11-03 23:39:04,372 - INFO  - ==> Top1: 99.372    Top5: 100.000    Loss: 0.018

2022-11-03 23:39:04,373 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:39:07,244 - INFO  - Validation [21][   20/   40]   Loss 0.465315   Top1 90.429688   Top5 99.628906   BatchTime 0.143433   
2022-11-03 23:39:08,354 - INFO  - Validation [21][   40/   40]   Loss 0.447034   Top1 90.660000   Top5 99.670000   BatchTime 0.099475   
2022-11-03 23:39:08,612 - INFO  - ==> Top1: 90.660    Top5: 99.670    Loss: 0.447

2022-11-03 23:39:08,657 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:39:08,658 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.670   Top5: 99.640] Sparsity : 0.775
2022-11-03 23:39:08,658 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 90.660   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:39:08,755 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:39:08,755 - INFO  - >>>>>>>> Epoch  22
2022-11-03 23:39:08,756 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:39:13,152 - INFO  - Training [22][   20/  196]   Loss 0.017343   Top1 99.375000   Top5 100.000000   BatchTime 0.219793   LR 0.001000   
2022-11-03 23:39:15,637 - INFO  - Training [22][   40/  196]   Loss 0.018225   Top1 99.355469   Top5 100.000000   BatchTime 0.172005   LR 0.001000   
2022-11-03 23:39:18,102 - INFO  - Training [22][   60/  196]   Loss 0.016958   Top1 99.420573   Top5 100.000000   BatchTime 0.155753   LR 0.001000   
2022-11-03 23:39:20,578 - INFO  - Training [22][   80/  196]   Loss 0.017197   Top1 99.409180   Top5 100.000000   BatchTime 0.147761   LR 0.001000   
2022-11-03 23:39:23,060 - INFO  - Training [22][  100/  196]   Loss 0.018105   Top1 99.378906   Top5 100.000000   BatchTime 0.143031   LR 0.001000   
2022-11-03 23:39:24,887 - INFO  - Training [22][  120/  196]   Loss 0.017730   Top1 99.397786   Top5 100.000000   BatchTime 0.134418   LR 0.001000   
2022-11-03 23:39:26,974 - INFO  - Training [22][  140/  196]   Loss 0.017901   Top1 99.402902   Top5 100.000000   BatchTime 0.130121   LR 0.001000   
2022-11-03 23:39:28,976 - INFO  - Training [22][  160/  196]   Loss 0.018085   Top1 99.372559   Top5 100.000000   BatchTime 0.126367   LR 0.001000   
2022-11-03 23:39:30,906 - INFO  - Training [22][  180/  196]   Loss 0.018111   Top1 99.361979   Top5 100.000000   BatchTime 0.123052   LR 0.001000   
2022-11-03 23:39:32,519 - INFO  - ==> Top1: 99.360    Top5: 100.000    Loss: 0.018

2022-11-03 23:39:32,520 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:39:35,482 - INFO  - Validation [22][   20/   40]   Loss 0.468168   Top1 90.566406   Top5 99.589844   BatchTime 0.147994   
2022-11-03 23:39:36,609 - INFO  - Validation [22][   40/   40]   Loss 0.448912   Top1 90.770000   Top5 99.630000   BatchTime 0.102174   
2022-11-03 23:39:36,862 - INFO  - ==> Top1: 90.770    Top5: 99.630    Loss: 0.449

2022-11-03 23:39:36,894 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:39:36,895 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:39:36,895 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.670   Top5: 99.640] Sparsity : 0.775
2022-11-03 23:39:37,092 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:39:37,282 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:39:37,283 - INFO  - >>>>>>>> Epoch  23
2022-11-03 23:39:37,284 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:39:41,674 - INFO  - Training [23][   20/  196]   Loss 0.014594   Top1 99.550781   Top5 100.000000   BatchTime 0.219506   LR 0.001000   
2022-11-03 23:39:44,156 - INFO  - Training [23][   40/  196]   Loss 0.015490   Top1 99.521484   Top5 100.000000   BatchTime 0.171786   LR 0.001000   
2022-11-03 23:39:46,637 - INFO  - Training [23][   60/  196]   Loss 0.015674   Top1 99.485677   Top5 100.000000   BatchTime 0.155883   LR 0.001000   
2022-11-03 23:39:49,120 - INFO  - Training [23][   80/  196]   Loss 0.015048   Top1 99.511719   Top5 100.000000   BatchTime 0.147946   LR 0.001000   
2022-11-03 23:39:51,605 - INFO  - Training [23][  100/  196]   Loss 0.016034   Top1 99.472656   Top5 100.000000   BatchTime 0.143211   LR 0.001000   
2022-11-03 23:39:54,092 - INFO  - Training [23][  120/  196]   Loss 0.016111   Top1 99.466146   Top5 99.996745   BatchTime 0.140062   LR 0.001000   
2022-11-03 23:39:56,570 - INFO  - Training [23][  140/  196]   Loss 0.016078   Top1 99.478237   Top5 99.997210   BatchTime 0.137752   LR 0.001000   
2022-11-03 23:39:59,034 - INFO  - Training [23][  160/  196]   Loss 0.016161   Top1 99.467773   Top5 99.997559   BatchTime 0.135937   LR 0.001000   
2022-11-03 23:40:01,496 - INFO  - Training [23][  180/  196]   Loss 0.016478   Top1 99.459635   Top5 99.997830   BatchTime 0.134510   LR 0.001000   
2022-11-03 23:40:03,668 - INFO  - ==> Top1: 99.454    Top5: 99.998    Loss: 0.017

2022-11-03 23:40:03,669 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:40:06,529 - INFO  - Validation [23][   20/   40]   Loss 0.469250   Top1 90.644531   Top5 99.628906   BatchTime 0.142956   
2022-11-03 23:40:07,631 - INFO  - Validation [23][   40/   40]   Loss 0.448769   Top1 90.760000   Top5 99.680000   BatchTime 0.099016   
2022-11-03 23:40:07,897 - INFO  - ==> Top1: 90.760    Top5: 99.680    Loss: 0.449

2022-11-03 23:40:07,940 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:40:07,941 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.760   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:40:07,941 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.670   Top5: 99.650] Sparsity : 0.774
2022-11-03 23:40:08,050 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:40:08,051 - INFO  - >>>>>>>> Epoch  24
2022-11-03 23:40:08,052 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:40:12,435 - INFO  - Training [24][   20/  196]   Loss 0.013214   Top1 99.609375   Top5 100.000000   BatchTime 0.219156   LR 0.001000   
2022-11-03 23:40:14,905 - INFO  - Training [24][   40/  196]   Loss 0.014413   Top1 99.550781   Top5 100.000000   BatchTime 0.171331   LR 0.001000   
2022-11-03 23:40:16,882 - INFO  - Training [24][   60/  196]   Loss 0.016335   Top1 99.446615   Top5 100.000000   BatchTime 0.147164   LR 0.001000   
2022-11-03 23:40:18,896 - INFO  - Training [24][   80/  196]   Loss 0.016099   Top1 99.453125   Top5 100.000000   BatchTime 0.135554   LR 0.001000   
2022-11-03 23:40:20,945 - INFO  - Training [24][  100/  196]   Loss 0.015818   Top1 99.445312   Top5 100.000000   BatchTime 0.128931   LR 0.001000   
2022-11-03 23:40:23,021 - INFO  - Training [24][  120/  196]   Loss 0.015809   Top1 99.449870   Top5 100.000000   BatchTime 0.124744   LR 0.001000   
2022-11-03 23:40:24,787 - INFO  - Training [24][  140/  196]   Loss 0.016043   Top1 99.461496   Top5 100.000000   BatchTime 0.119531   LR 0.001000   
2022-11-03 23:40:27,330 - INFO  - Training [24][  160/  196]   Loss 0.016372   Top1 99.436035   Top5 100.000000   BatchTime 0.120488   LR 0.001000   
2022-11-03 23:40:29,800 - INFO  - Training [24][  180/  196]   Loss 0.016745   Top1 99.429253   Top5 100.000000   BatchTime 0.120820   LR 0.001000   
2022-11-03 23:40:31,970 - INFO  - ==> Top1: 99.434    Top5: 100.000    Loss: 0.017

2022-11-03 23:40:31,971 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:40:34,848 - INFO  - Validation [24][   20/   40]   Loss 0.462552   Top1 90.546875   Top5 99.531250   BatchTime 0.143731   
2022-11-03 23:40:35,962 - INFO  - Validation [24][   40/   40]   Loss 0.446522   Top1 90.700000   Top5 99.600000   BatchTime 0.099728   
2022-11-03 23:40:36,211 - INFO  - ==> Top1: 90.700    Top5: 99.600    Loss: 0.447

2022-11-03 23:40:36,240 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:40:36,241 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.760   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:40:36,241 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.700   Top5: 99.600] Sparsity : 0.775
2022-11-03 23:40:36,338 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:40:36,339 - INFO  - >>>>>>>> Epoch  25
2022-11-03 23:40:36,340 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:40:40,724 - INFO  - Training [25][   20/  196]   Loss 0.013855   Top1 99.550781   Top5 100.000000   BatchTime 0.219191   LR 0.001000   
2022-11-03 23:40:43,189 - INFO  - Training [25][   40/  196]   Loss 0.014383   Top1 99.570312   Top5 100.000000   BatchTime 0.171222   LR 0.001000   
2022-11-03 23:40:45,670 - INFO  - Training [25][   60/  196]   Loss 0.015398   Top1 99.531250   Top5 100.000000   BatchTime 0.155493   LR 0.001000   
2022-11-03 23:40:48,143 - INFO  - Training [25][   80/  196]   Loss 0.016145   Top1 99.487305   Top5 100.000000   BatchTime 0.147533   LR 0.001000   
2022-11-03 23:40:50,620 - INFO  - Training [25][  100/  196]   Loss 0.016239   Top1 99.460938   Top5 100.000000   BatchTime 0.142797   LR 0.001000   
2022-11-03 23:40:53,097 - INFO  - Training [25][  120/  196]   Loss 0.016162   Top1 99.485677   Top5 100.000000   BatchTime 0.139637   LR 0.001000   
2022-11-03 23:40:55,583 - INFO  - Training [25][  140/  196]   Loss 0.016114   Top1 99.469866   Top5 100.000000   BatchTime 0.137448   LR 0.001000   
2022-11-03 23:40:58,183 - INFO  - Training [25][  160/  196]   Loss 0.016539   Top1 99.467773   Top5 100.000000   BatchTime 0.136517   LR 0.001000   
2022-11-03 23:41:00,648 - INFO  - Training [25][  180/  196]   Loss 0.016961   Top1 99.448785   Top5 100.000000   BatchTime 0.135044   LR 0.001000   
2022-11-03 23:41:02,832 - INFO  - ==> Top1: 99.452    Top5: 100.000    Loss: 0.017

2022-11-03 23:41:02,833 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:41:05,685 - INFO  - Validation [25][   20/   40]   Loss 0.467365   Top1 90.605469   Top5 99.589844   BatchTime 0.142544   
2022-11-03 23:41:06,793 - INFO  - Validation [25][   40/   40]   Loss 0.446095   Top1 90.720000   Top5 99.640000   BatchTime 0.098970   
2022-11-03 23:41:07,035 - INFO  - ==> Top1: 90.720    Top5: 99.640    Loss: 0.446

2022-11-03 23:41:07,070 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:41:07,071 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.760   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:41:07,071 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.720   Top5: 99.640] Sparsity : 0.775
2022-11-03 23:41:07,176 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:41:07,176 - INFO  - >>>>>>>> Epoch  26
2022-11-03 23:41:07,178 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:41:11,204 - INFO  - Training [26][   20/  196]   Loss 0.011799   Top1 99.687500   Top5 100.000000   BatchTime 0.201320   LR 0.001000   
2022-11-03 23:41:13,231 - INFO  - Training [26][   40/  196]   Loss 0.014606   Top1 99.560547   Top5 100.000000   BatchTime 0.151340   LR 0.001000   
2022-11-03 23:41:15,255 - INFO  - Training [26][   60/  196]   Loss 0.015316   Top1 99.531250   Top5 100.000000   BatchTime 0.134628   LR 0.001000   
2022-11-03 23:41:17,029 - INFO  - Training [26][   80/  196]   Loss 0.015978   Top1 99.472656   Top5 100.000000   BatchTime 0.123138   LR 0.001000   
2022-11-03 23:41:19,381 - INFO  - Training [26][  100/  196]   Loss 0.015896   Top1 99.472656   Top5 100.000000   BatchTime 0.122029   LR 0.001000   
2022-11-03 23:41:21,867 - INFO  - Training [26][  120/  196]   Loss 0.016091   Top1 99.459635   Top5 100.000000   BatchTime 0.122411   LR 0.001000   
2022-11-03 23:41:24,342 - INFO  - Training [26][  140/  196]   Loss 0.015776   Top1 99.464286   Top5 100.000000   BatchTime 0.122597   LR 0.001000   
2022-11-03 23:41:26,805 - INFO  - Training [26][  160/  196]   Loss 0.016041   Top1 99.460449   Top5 100.000000   BatchTime 0.122668   LR 0.001000   
2022-11-03 23:41:29,269 - INFO  - Training [26][  180/  196]   Loss 0.016029   Top1 99.448785   Top5 100.000000   BatchTime 0.122729   LR 0.001000   
2022-11-03 23:41:31,464 - INFO  - ==> Top1: 99.446    Top5: 100.000    Loss: 0.016

2022-11-03 23:41:31,465 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:41:34,375 - INFO  - Validation [26][   20/   40]   Loss 0.465042   Top1 90.683594   Top5 99.609375   BatchTime 0.145466   
2022-11-03 23:41:35,504 - INFO  - Validation [26][   40/   40]   Loss 0.443632   Top1 90.970000   Top5 99.660000   BatchTime 0.100950   
2022-11-03 23:41:35,755 - INFO  - ==> Top1: 90.970    Top5: 99.660    Loss: 0.444

2022-11-03 23:41:35,797 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:41:35,798 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:41:35,798 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.760   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:41:35,993 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:41:36,164 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:41:36,165 - INFO  - >>>>>>>> Epoch  27
2022-11-03 23:41:36,165 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:41:40,559 - INFO  - Training [27][   20/  196]   Loss 0.015324   Top1 99.492188   Top5 100.000000   BatchTime 0.219667   LR 0.001000   
2022-11-03 23:41:43,054 - INFO  - Training [27][   40/  196]   Loss 0.014562   Top1 99.521484   Top5 100.000000   BatchTime 0.172203   LR 0.001000   
2022-11-03 23:41:45,532 - INFO  - Training [27][   60/  196]   Loss 0.015731   Top1 99.459635   Top5 100.000000   BatchTime 0.156110   LR 0.001000   
2022-11-03 23:41:48,024 - INFO  - Training [27][   80/  196]   Loss 0.015517   Top1 99.462891   Top5 100.000000   BatchTime 0.148233   LR 0.001000   
2022-11-03 23:41:50,513 - INFO  - Training [27][  100/  196]   Loss 0.015875   Top1 99.449219   Top5 100.000000   BatchTime 0.143475   LR 0.001000   
2022-11-03 23:41:52,988 - INFO  - Training [27][  120/  196]   Loss 0.015987   Top1 99.446615   Top5 100.000000   BatchTime 0.140182   LR 0.001000   
2022-11-03 23:41:55,460 - INFO  - Training [27][  140/  196]   Loss 0.016295   Top1 99.441964   Top5 100.000000   BatchTime 0.137818   LR 0.001000   
2022-11-03 23:41:57,914 - INFO  - Training [27][  160/  196]   Loss 0.016374   Top1 99.448242   Top5 100.000000   BatchTime 0.135923   LR 0.001000   
2022-11-03 23:42:00,374 - INFO  - Training [27][  180/  196]   Loss 0.016045   Top1 99.470486   Top5 100.000000   BatchTime 0.134491   LR 0.001000   
2022-11-03 23:42:02,522 - INFO  - ==> Top1: 99.454    Top5: 99.998    Loss: 0.016

2022-11-03 23:42:02,522 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:42:05,257 - INFO  - Validation [27][   20/   40]   Loss 0.463848   Top1 90.761719   Top5 99.628906   BatchTime 0.136682   
2022-11-03 23:42:06,133 - INFO  - Validation [27][   40/   40]   Loss 0.447711   Top1 90.730000   Top5 99.690000   BatchTime 0.090227   
2022-11-03 23:42:06,376 - INFO  - ==> Top1: 90.730    Top5: 99.690    Loss: 0.448

2022-11-03 23:42:06,409 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:42:06,410 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:42:06,410 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.760   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:42:06,516 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:42:06,517 - INFO  - >>>>>>>> Epoch  28
2022-11-03 23:42:06,518 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:42:10,524 - INFO  - Training [28][   20/  196]   Loss 0.015166   Top1 99.511719   Top5 100.000000   BatchTime 0.200298   LR 0.001000   
2022-11-03 23:42:13,009 - INFO  - Training [28][   40/  196]   Loss 0.015472   Top1 99.492188   Top5 100.000000   BatchTime 0.162278   LR 0.001000   
2022-11-03 23:42:15,494 - INFO  - Training [28][   60/  196]   Loss 0.015500   Top1 99.531250   Top5 100.000000   BatchTime 0.149588   LR 0.001000   
2022-11-03 23:42:17,977 - INFO  - Training [28][   80/  196]   Loss 0.014941   Top1 99.541016   Top5 100.000000   BatchTime 0.143234   LR 0.001000   
2022-11-03 23:42:20,451 - INFO  - Training [28][  100/  196]   Loss 0.014391   Top1 99.535156   Top5 100.000000   BatchTime 0.139328   LR 0.001000   
2022-11-03 23:42:22,920 - INFO  - Training [28][  120/  196]   Loss 0.014729   Top1 99.524740   Top5 99.996745   BatchTime 0.136678   LR 0.001000   
2022-11-03 23:42:25,401 - INFO  - Training [28][  140/  196]   Loss 0.015246   Top1 99.514509   Top5 99.997210   BatchTime 0.134876   LR 0.001000   
2022-11-03 23:42:27,869 - INFO  - Training [28][  160/  196]   Loss 0.015393   Top1 99.501953   Top5 99.997559   BatchTime 0.133440   LR 0.001000   
2022-11-03 23:42:30,335 - INFO  - Training [28][  180/  196]   Loss 0.015568   Top1 99.490017   Top5 99.997830   BatchTime 0.132310   LR 0.001000   
2022-11-03 23:42:32,506 - INFO  - ==> Top1: 99.476    Top5: 99.998    Loss: 0.016

2022-11-03 23:42:32,506 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:42:35,391 - INFO  - Validation [28][   20/   40]   Loss 0.465954   Top1 90.761719   Top5 99.648438   BatchTime 0.144186   
2022-11-03 23:42:36,431 - INFO  - Validation [28][   40/   40]   Loss 0.447421   Top1 90.940000   Top5 99.660000   BatchTime 0.098082   
2022-11-03 23:42:36,685 - INFO  - ==> Top1: 90.940    Top5: 99.660    Loss: 0.447

2022-11-03 23:42:36,715 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:42:36,716 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:42:36,716 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 90.770   Top5: 99.630] Sparsity : 0.775
2022-11-03 23:42:36,824 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:42:36,824 - INFO  - >>>>>>>> Epoch  29
2022-11-03 23:42:36,826 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:42:41,246 - INFO  - Training [29][   20/  196]   Loss 0.016081   Top1 99.433594   Top5 100.000000   BatchTime 0.221021   LR 0.001000   
2022-11-03 23:42:43,733 - INFO  - Training [29][   40/  196]   Loss 0.015239   Top1 99.462891   Top5 100.000000   BatchTime 0.172686   LR 0.001000   
2022-11-03 23:42:46,214 - INFO  - Training [29][   60/  196]   Loss 0.014779   Top1 99.492188   Top5 100.000000   BatchTime 0.156462   LR 0.001000   
2022-11-03 23:42:48,689 - INFO  - Training [29][   80/  196]   Loss 0.014351   Top1 99.526367   Top5 100.000000   BatchTime 0.148288   LR 0.001000   
2022-11-03 23:42:51,161 - INFO  - Training [29][  100/  196]   Loss 0.014490   Top1 99.511719   Top5 100.000000   BatchTime 0.143345   LR 0.001000   
2022-11-03 23:42:53,634 - INFO  - Training [29][  120/  196]   Loss 0.014252   Top1 99.537760   Top5 100.000000   BatchTime 0.140062   LR 0.001000   
2022-11-03 23:42:56,155 - INFO  - Training [29][  140/  196]   Loss 0.014146   Top1 99.539621   Top5 100.000000   BatchTime 0.138063   LR 0.001000   
2022-11-03 23:42:57,908 - INFO  - Training [29][  160/  196]   Loss 0.014308   Top1 99.528809   Top5 100.000000   BatchTime 0.131761   LR 0.001000   
2022-11-03 23:43:00,044 - INFO  - Training [29][  180/  196]   Loss 0.014357   Top1 99.533420   Top5 100.000000   BatchTime 0.128986   LR 0.001000   
2022-11-03 23:43:01,860 - INFO  - ==> Top1: 99.540    Top5: 100.000    Loss: 0.014

2022-11-03 23:43:01,861 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:43:04,655 - INFO  - Validation [29][   20/   40]   Loss 0.470920   Top1 90.644531   Top5 99.589844   BatchTime 0.139666   
2022-11-03 23:43:05,755 - INFO  - Validation [29][   40/   40]   Loss 0.450280   Top1 90.870000   Top5 99.650000   BatchTime 0.097313   
2022-11-03 23:43:06,005 - INFO  - ==> Top1: 90.870    Top5: 99.650    Loss: 0.450

2022-11-03 23:43:06,040 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:43:06,041 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:43:06,041 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:43:06,152 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:43:06,152 - INFO  - >>>>>>>> Epoch  30
2022-11-03 23:43:06,153 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:43:10,550 - INFO  - Training [30][   20/  196]   Loss 0.014991   Top1 99.492188   Top5 100.000000   BatchTime 0.219806   LR 0.001000   
2022-11-03 23:43:13,036 - INFO  - Training [30][   40/  196]   Loss 0.014103   Top1 99.531250   Top5 100.000000   BatchTime 0.172055   LR 0.001000   
2022-11-03 23:43:15,520 - INFO  - Training [30][   60/  196]   Loss 0.014774   Top1 99.524740   Top5 100.000000   BatchTime 0.156108   LR 0.001000   
2022-11-03 23:43:17,991 - INFO  - Training [30][   80/  196]   Loss 0.014091   Top1 99.541016   Top5 100.000000   BatchTime 0.147972   LR 0.001000   
2022-11-03 23:43:20,481 - INFO  - Training [30][  100/  196]   Loss 0.014633   Top1 99.515625   Top5 100.000000   BatchTime 0.143278   LR 0.001000   
2022-11-03 23:43:22,964 - INFO  - Training [30][  120/  196]   Loss 0.014497   Top1 99.524740   Top5 100.000000   BatchTime 0.140084   LR 0.001000   
2022-11-03 23:43:25,444 - INFO  - Training [30][  140/  196]   Loss 0.014615   Top1 99.525670   Top5 100.000000   BatchTime 0.137789   LR 0.001000   
2022-11-03 23:43:27,912 - INFO  - Training [30][  160/  196]   Loss 0.014840   Top1 99.523926   Top5 100.000000   BatchTime 0.135986   LR 0.001000   
2022-11-03 23:43:30,380 - INFO  - Training [30][  180/  196]   Loss 0.014944   Top1 99.537760   Top5 100.000000   BatchTime 0.134590   LR 0.001000   
2022-11-03 23:43:32,579 - INFO  - ==> Top1: 99.536    Top5: 100.000    Loss: 0.015

2022-11-03 23:43:32,580 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:43:35,461 - INFO  - Validation [30][   20/   40]   Loss 0.465318   Top1 90.664062   Top5 99.531250   BatchTime 0.143974   
2022-11-03 23:43:36,576 - INFO  - Validation [30][   40/   40]   Loss 0.448785   Top1 90.810000   Top5 99.630000   BatchTime 0.099865   
2022-11-03 23:43:36,829 - INFO  - ==> Top1: 90.810    Top5: 99.630    Loss: 0.449

2022-11-03 23:43:36,858 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:43:36,859 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:43:36,859 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:43:36,966 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:43:36,967 - INFO  - >>>>>>>> Epoch  31
2022-11-03 23:43:36,968 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:43:41,339 - INFO  - Training [31][   20/  196]   Loss 0.017006   Top1 99.433594   Top5 100.000000   BatchTime 0.218535   LR 0.001000   
2022-11-03 23:43:43,815 - INFO  - Training [31][   40/  196]   Loss 0.017647   Top1 99.472656   Top5 100.000000   BatchTime 0.171161   LR 0.001000   
2022-11-03 23:43:46,285 - INFO  - Training [31][   60/  196]   Loss 0.016068   Top1 99.498698   Top5 100.000000   BatchTime 0.155284   LR 0.001000   
2022-11-03 23:43:48,762 - INFO  - Training [31][   80/  196]   Loss 0.015571   Top1 99.506836   Top5 100.000000   BatchTime 0.147419   LR 0.001000   
2022-11-03 23:43:50,625 - INFO  - Training [31][  100/  196]   Loss 0.015588   Top1 99.480469   Top5 100.000000   BatchTime 0.136567   LR 0.001000   
2022-11-03 23:43:52,710 - INFO  - Training [31][  120/  196]   Loss 0.015706   Top1 99.488932   Top5 100.000000   BatchTime 0.131175   LR 0.001000   
2022-11-03 23:43:54,743 - INFO  - Training [31][  140/  196]   Loss 0.015700   Top1 99.497768   Top5 100.000000   BatchTime 0.126956   LR 0.001000   
2022-11-03 23:43:56,719 - INFO  - Training [31][  160/  196]   Loss 0.015696   Top1 99.497070   Top5 100.000000   BatchTime 0.123438   LR 0.001000   
2022-11-03 23:43:58,553 - INFO  - Training [31][  180/  196]   Loss 0.015592   Top1 99.496528   Top5 100.000000   BatchTime 0.119910   LR 0.001000   
2022-11-03 23:44:00,729 - INFO  - ==> Top1: 99.500    Top5: 100.000    Loss: 0.016

2022-11-03 23:44:00,730 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:44:03,631 - INFO  - Validation [31][   20/   40]   Loss 0.470886   Top1 90.546875   Top5 99.628906   BatchTime 0.144986   
2022-11-03 23:44:04,765 - INFO  - Validation [31][   40/   40]   Loss 0.452231   Top1 90.740000   Top5 99.660000   BatchTime 0.100842   
2022-11-03 23:44:05,035 - INFO  - ==> Top1: 90.740    Top5: 99.660    Loss: 0.452

2022-11-03 23:44:05,078 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:44:05,079 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:44:05,079 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:44:05,193 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:44:05,193 - INFO  - >>>>>>>> Epoch  32
2022-11-03 23:44:05,195 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:44:09,574 - INFO  - Training [32][   20/  196]   Loss 0.015140   Top1 99.492188   Top5 100.000000   BatchTime 0.218943   LR 0.001000   
2022-11-03 23:44:12,068 - INFO  - Training [32][   40/  196]   Loss 0.013786   Top1 99.541016   Top5 100.000000   BatchTime 0.171832   LR 0.001000   
2022-11-03 23:44:14,558 - INFO  - Training [32][   60/  196]   Loss 0.013821   Top1 99.550781   Top5 100.000000   BatchTime 0.156044   LR 0.001000   
2022-11-03 23:44:17,035 - INFO  - Training [32][   80/  196]   Loss 0.013491   Top1 99.580078   Top5 100.000000   BatchTime 0.147997   LR 0.001000   
2022-11-03 23:44:19,504 - INFO  - Training [32][  100/  196]   Loss 0.013697   Top1 99.570312   Top5 100.000000   BatchTime 0.143087   LR 0.001000   
2022-11-03 23:44:22,014 - INFO  - Training [32][  120/  196]   Loss 0.014044   Top1 99.550781   Top5 100.000000   BatchTime 0.140161   LR 0.001000   
2022-11-03 23:44:24,489 - INFO  - Training [32][  140/  196]   Loss 0.014251   Top1 99.547991   Top5 100.000000   BatchTime 0.137813   LR 0.001000   
2022-11-03 23:44:26,960 - INFO  - Training [32][  160/  196]   Loss 0.014588   Top1 99.531250   Top5 100.000000   BatchTime 0.136033   LR 0.001000   
2022-11-03 23:44:29,426 - INFO  - Training [32][  180/  196]   Loss 0.014782   Top1 99.509549   Top5 100.000000   BatchTime 0.134614   LR 0.001000   
2022-11-03 23:44:31,555 - INFO  - ==> Top1: 99.514    Top5: 100.000    Loss: 0.015

2022-11-03 23:44:31,556 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:44:34,475 - INFO  - Validation [32][   20/   40]   Loss 0.469309   Top1 90.410156   Top5 99.628906   BatchTime 0.145863   
2022-11-03 23:44:35,607 - INFO  - Validation [32][   40/   40]   Loss 0.450317   Top1 90.620000   Top5 99.660000   BatchTime 0.101235   
2022-11-03 23:44:35,849 - INFO  - ==> Top1: 90.620    Top5: 99.660    Loss: 0.450

2022-11-03 23:44:35,888 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:44:35,888 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:44:35,889 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:44:35,992 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:44:35,992 - INFO  - >>>>>>>> Epoch  33
2022-11-03 23:44:35,993 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:44:40,340 - INFO  - Training [33][   20/  196]   Loss 0.010334   Top1 99.687500   Top5 100.000000   BatchTime 0.217336   LR 0.001000   
2022-11-03 23:44:42,322 - INFO  - Training [33][   40/  196]   Loss 0.011177   Top1 99.619141   Top5 100.000000   BatchTime 0.158212   LR 0.001000   
2022-11-03 23:44:44,356 - INFO  - Training [33][   60/  196]   Loss 0.012324   Top1 99.570312   Top5 100.000000   BatchTime 0.139381   LR 0.001000   
2022-11-03 23:44:46,404 - INFO  - Training [33][   80/  196]   Loss 0.012810   Top1 99.555664   Top5 100.000000   BatchTime 0.130135   LR 0.001000   
2022-11-03 23:44:48,472 - INFO  - Training [33][  100/  196]   Loss 0.013385   Top1 99.531250   Top5 100.000000   BatchTime 0.124789   LR 0.001000   
2022-11-03 23:44:50,214 - INFO  - Training [33][  120/  196]   Loss 0.013615   Top1 99.521484   Top5 100.000000   BatchTime 0.118502   LR 0.001000   
2022-11-03 23:44:52,316 - INFO  - Training [33][  140/  196]   Loss 0.013687   Top1 99.522879   Top5 100.000000   BatchTime 0.116586   LR 0.001000   
2022-11-03 23:44:54,318 - INFO  - Training [33][  160/  196]   Loss 0.013833   Top1 99.521484   Top5 100.000000   BatchTime 0.114529   LR 0.001000   
2022-11-03 23:44:56,251 - INFO  - Training [33][  180/  196]   Loss 0.013887   Top1 99.524740   Top5 100.000000   BatchTime 0.112541   LR 0.001000   
2022-11-03 23:44:57,817 - INFO  - ==> Top1: 99.528    Top5: 100.000    Loss: 0.014

2022-11-03 23:44:57,817 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:45:00,250 - INFO  - Validation [33][   20/   40]   Loss 0.467059   Top1 90.566406   Top5 99.570312   BatchTime 0.121525   
2022-11-03 23:45:00,929 - INFO  - Validation [33][   40/   40]   Loss 0.449250   Top1 90.780000   Top5 99.640000   BatchTime 0.077747   
2022-11-03 23:45:01,168 - INFO  - ==> Top1: 90.780    Top5: 99.640    Loss: 0.449

2022-11-03 23:45:01,190 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:45:01,191 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:45:01,191 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:45:01,301 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:45:01,301 - INFO  - >>>>>>>> Epoch  34
2022-11-03 23:45:01,302 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:45:05,127 - INFO  - Training [34][   20/  196]   Loss 0.013669   Top1 99.589844   Top5 100.000000   BatchTime 0.191261   LR 0.001000   
2022-11-03 23:45:06,870 - INFO  - Training [34][   40/  196]   Loss 0.012832   Top1 99.628906   Top5 100.000000   BatchTime 0.139209   LR 0.001000   
2022-11-03 23:45:08,609 - INFO  - Training [34][   60/  196]   Loss 0.013429   Top1 99.563802   Top5 100.000000   BatchTime 0.121776   LR 0.001000   
2022-11-03 23:45:10,432 - INFO  - Training [34][   80/  196]   Loss 0.013882   Top1 99.565430   Top5 100.000000   BatchTime 0.114126   LR 0.001000   
2022-11-03 23:45:12,198 - INFO  - Training [34][  100/  196]   Loss 0.014349   Top1 99.542969   Top5 100.000000   BatchTime 0.108952   LR 0.001000   
2022-11-03 23:45:13,952 - INFO  - Training [34][  120/  196]   Loss 0.013956   Top1 99.550781   Top5 100.000000   BatchTime 0.105412   LR 0.001000   
2022-11-03 23:45:15,775 - INFO  - Training [34][  140/  196]   Loss 0.014260   Top1 99.539621   Top5 100.000000   BatchTime 0.103378   LR 0.001000   
2022-11-03 23:45:17,740 - INFO  - Training [34][  160/  196]   Loss 0.014830   Top1 99.538574   Top5 100.000000   BatchTime 0.102736   LR 0.001000   
2022-11-03 23:45:19,762 - INFO  - Training [34][  180/  196]   Loss 0.015385   Top1 99.522569   Top5 100.000000   BatchTime 0.102551   LR 0.001000   
2022-11-03 23:45:21,721 - INFO  - ==> Top1: 99.510    Top5: 100.000    Loss: 0.016

2022-11-03 23:45:21,722 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:45:24,661 - INFO  - Validation [34][   20/   40]   Loss 0.464651   Top1 90.664062   Top5 99.609375   BatchTime 0.146913   
2022-11-03 23:45:25,795 - INFO  - Validation [34][   40/   40]   Loss 0.447657   Top1 90.810000   Top5 99.660000   BatchTime 0.101794   
2022-11-03 23:45:26,049 - INFO  - ==> Top1: 90.810    Top5: 99.660    Loss: 0.448

2022-11-03 23:45:26,084 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:45:26,084 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:45:26,085 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:45:26,201 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:45:26,201 - INFO  - >>>>>>>> Epoch  35
2022-11-03 23:45:26,203 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:45:30,608 - INFO  - Training [35][   20/  196]   Loss 0.016058   Top1 99.511719   Top5 100.000000   BatchTime 0.220258   LR 0.001000   
2022-11-03 23:45:33,077 - INFO  - Training [35][   40/  196]   Loss 0.015390   Top1 99.511719   Top5 100.000000   BatchTime 0.171856   LR 0.001000   
2022-11-03 23:45:35,546 - INFO  - Training [35][   60/  196]   Loss 0.014926   Top1 99.570312   Top5 100.000000   BatchTime 0.155716   LR 0.001000   
2022-11-03 23:45:38,018 - INFO  - Training [35][   80/  196]   Loss 0.014292   Top1 99.584961   Top5 100.000000   BatchTime 0.147680   LR 0.001000   
2022-11-03 23:45:40,487 - INFO  - Training [35][  100/  196]   Loss 0.014190   Top1 99.566406   Top5 100.000000   BatchTime 0.142833   LR 0.001000   
2022-11-03 23:45:42,968 - INFO  - Training [35][  120/  196]   Loss 0.014770   Top1 99.547526   Top5 100.000000   BatchTime 0.139708   LR 0.001000   
2022-11-03 23:45:45,440 - INFO  - Training [35][  140/  196]   Loss 0.014378   Top1 99.561942   Top5 100.000000   BatchTime 0.137406   LR 0.001000   
2022-11-03 23:45:47,899 - INFO  - Training [35][  160/  196]   Loss 0.014344   Top1 99.562988   Top5 100.000000   BatchTime 0.135600   LR 0.001000   
2022-11-03 23:45:50,360 - INFO  - Training [35][  180/  196]   Loss 0.014317   Top1 99.557292   Top5 100.000000   BatchTime 0.134205   LR 0.001000   
2022-11-03 23:45:52,542 - INFO  - ==> Top1: 99.544    Top5: 100.000    Loss: 0.014

2022-11-03 23:45:52,543 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:45:55,441 - INFO  - Validation [35][   20/   40]   Loss 0.465878   Top1 90.566406   Top5 99.609375   BatchTime 0.144813   
2022-11-03 23:45:56,595 - INFO  - Validation [35][   40/   40]   Loss 0.448227   Top1 90.780000   Top5 99.660000   BatchTime 0.101272   
2022-11-03 23:45:56,852 - INFO  - ==> Top1: 90.780    Top5: 99.660    Loss: 0.448

2022-11-03 23:45:56,892 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:45:56,893 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:45:56,893 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:45:56,993 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:45:56,993 - INFO  - >>>>>>>> Epoch  36
2022-11-03 23:45:56,994 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:46:01,408 - INFO  - Training [36][   20/  196]   Loss 0.012765   Top1 99.648438   Top5 100.000000   BatchTime 0.220659   LR 0.001000   
2022-11-03 23:46:03,869 - INFO  - Training [36][   40/  196]   Loss 0.013818   Top1 99.609375   Top5 100.000000   BatchTime 0.171858   LR 0.001000   
2022-11-03 23:46:06,322 - INFO  - Training [36][   60/  196]   Loss 0.014436   Top1 99.576823   Top5 100.000000   BatchTime 0.155461   LR 0.001000   
2022-11-03 23:46:08,686 - INFO  - Training [36][   80/  196]   Loss 0.014223   Top1 99.555664   Top5 100.000000   BatchTime 0.146146   LR 0.001000   
2022-11-03 23:46:10,452 - INFO  - Training [36][  100/  196]   Loss 0.014642   Top1 99.566406   Top5 100.000000   BatchTime 0.134572   LR 0.001000   
2022-11-03 23:46:12,512 - INFO  - Training [36][  120/  196]   Loss 0.014626   Top1 99.570312   Top5 100.000000   BatchTime 0.129311   LR 0.001000   
2022-11-03 23:46:14,535 - INFO  - Training [36][  140/  196]   Loss 0.014868   Top1 99.542411   Top5 100.000000   BatchTime 0.125289   LR 0.001000   
2022-11-03 23:46:16,499 - INFO  - Training [36][  160/  196]   Loss 0.014791   Top1 99.541016   Top5 100.000000   BatchTime 0.121899   LR 0.001000   
2022-11-03 23:46:18,401 - INFO  - Training [36][  180/  196]   Loss 0.014346   Top1 99.544271   Top5 100.000000   BatchTime 0.118925   LR 0.001000   
2022-11-03 23:46:20,579 - INFO  - ==> Top1: 99.548    Top5: 100.000    Loss: 0.014

2022-11-03 23:46:20,580 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:46:23,450 - INFO  - Validation [36][   20/   40]   Loss 0.469256   Top1 90.761719   Top5 99.570312   BatchTime 0.143442   
2022-11-03 23:46:24,586 - INFO  - Validation [36][   40/   40]   Loss 0.452628   Top1 90.820000   Top5 99.660000   BatchTime 0.100106   
2022-11-03 23:46:24,839 - INFO  - ==> Top1: 90.820    Top5: 99.660    Loss: 0.453

2022-11-03 23:46:24,872 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:46:24,873 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:46:24,873 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:46:24,980 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:46:24,980 - INFO  - >>>>>>>> Epoch  37
2022-11-03 23:46:24,982 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:46:29,345 - INFO  - Training [37][   20/  196]   Loss 0.014832   Top1 99.472656   Top5 100.000000   BatchTime 0.218178   LR 0.001000   
2022-11-03 23:46:31,823 - INFO  - Training [37][   40/  196]   Loss 0.015158   Top1 99.472656   Top5 100.000000   BatchTime 0.171030   LR 0.001000   
2022-11-03 23:46:34,303 - INFO  - Training [37][   60/  196]   Loss 0.014206   Top1 99.524740   Top5 100.000000   BatchTime 0.155353   LR 0.001000   
2022-11-03 23:46:36,776 - INFO  - Training [37][   80/  196]   Loss 0.014084   Top1 99.531250   Top5 100.000000   BatchTime 0.147430   LR 0.001000   
2022-11-03 23:46:39,246 - INFO  - Training [37][  100/  196]   Loss 0.014724   Top1 99.492188   Top5 100.000000   BatchTime 0.142638   LR 0.001000   
2022-11-03 23:46:41,740 - INFO  - Training [37][  120/  196]   Loss 0.015146   Top1 99.485677   Top5 100.000000   BatchTime 0.139646   LR 0.001000   
2022-11-03 23:46:44,209 - INFO  - Training [37][  140/  196]   Loss 0.015144   Top1 99.475446   Top5 100.000000   BatchTime 0.137333   LR 0.001000   
2022-11-03 23:46:46,663 - INFO  - Training [37][  160/  196]   Loss 0.014863   Top1 99.477539   Top5 100.000000   BatchTime 0.135504   LR 0.001000   
2022-11-03 23:46:49,119 - INFO  - Training [37][  180/  196]   Loss 0.014759   Top1 99.492188   Top5 100.000000   BatchTime 0.134094   LR 0.001000   
2022-11-03 23:46:51,291 - INFO  - ==> Top1: 99.478    Top5: 100.000    Loss: 0.015

2022-11-03 23:46:51,292 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:46:54,169 - INFO  - Validation [37][   20/   40]   Loss 0.468954   Top1 90.585938   Top5 99.570312   BatchTime 0.143801   
2022-11-03 23:46:55,300 - INFO  - Validation [37][   40/   40]   Loss 0.450584   Top1 90.750000   Top5 99.640000   BatchTime 0.100195   
2022-11-03 23:46:55,553 - INFO  - ==> Top1: 90.750    Top5: 99.640    Loss: 0.451

2022-11-03 23:46:55,589 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:46:55,589 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:46:55,589 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.870   Top5: 99.650] Sparsity : 0.775
2022-11-03 23:46:55,698 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:46:55,698 - INFO  - >>>>>>>> Epoch  38
2022-11-03 23:46:55,699 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:47:00,018 - INFO  - Training [38][   20/  196]   Loss 0.012563   Top1 99.570312   Top5 100.000000   BatchTime 0.215953   LR 0.001000   
2022-11-03 23:47:01,985 - INFO  - Training [38][   40/  196]   Loss 0.015550   Top1 99.501953   Top5 100.000000   BatchTime 0.157151   LR 0.001000   
2022-11-03 23:47:04,135 - INFO  - Training [38][   60/  196]   Loss 0.014554   Top1 99.511719   Top5 100.000000   BatchTime 0.140599   LR 0.001000   
2022-11-03 23:47:06,188 - INFO  - Training [38][   80/  196]   Loss 0.014850   Top1 99.511719   Top5 100.000000   BatchTime 0.131104   LR 0.001000   
2022-11-03 23:47:08,267 - INFO  - Training [38][  100/  196]   Loss 0.014542   Top1 99.531250   Top5 100.000000   BatchTime 0.125679   LR 0.001000   
2022-11-03 23:47:10,351 - INFO  - Training [38][  120/  196]   Loss 0.013979   Top1 99.554036   Top5 100.000000   BatchTime 0.122092   LR 0.001000   
2022-11-03 23:47:12,822 - INFO  - Training [38][  140/  196]   Loss 0.014009   Top1 99.550781   Top5 100.000000   BatchTime 0.122301   LR 0.001000   
2022-11-03 23:47:15,278 - INFO  - Training [38][  160/  196]   Loss 0.013732   Top1 99.553223   Top5 100.000000   BatchTime 0.122365   LR 0.001000   
2022-11-03 23:47:17,746 - INFO  - Training [38][  180/  196]   Loss 0.013941   Top1 99.539931   Top5 100.000000   BatchTime 0.122479   LR 0.001000   
2022-11-03 23:47:19,919 - INFO  - ==> Top1: 99.538    Top5: 100.000    Loss: 0.014

2022-11-03 23:47:19,920 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:47:22,857 - INFO  - Validation [38][   20/   40]   Loss 0.470591   Top1 90.839844   Top5 99.628906   BatchTime 0.146783   
2022-11-03 23:47:23,985 - INFO  - Validation [38][   40/   40]   Loss 0.454468   Top1 90.920000   Top5 99.660000   BatchTime 0.101592   
2022-11-03 23:47:24,238 - INFO  - ==> Top1: 90.920    Top5: 99.660    Loss: 0.454

2022-11-03 23:47:24,275 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:47:24,276 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:47:24,276 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.920   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:47:24,384 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:47:24,385 - INFO  - >>>>>>>> Epoch  39
2022-11-03 23:47:24,386 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:47:28,769 - INFO  - Training [39][   20/  196]   Loss 0.013144   Top1 99.550781   Top5 100.000000   BatchTime 0.219122   LR 0.001000   
2022-11-03 23:47:31,236 - INFO  - Training [39][   40/  196]   Loss 0.013639   Top1 99.550781   Top5 100.000000   BatchTime 0.171227   LR 0.001000   
2022-11-03 23:47:33,704 - INFO  - Training [39][   60/  196]   Loss 0.013570   Top1 99.570312   Top5 100.000000   BatchTime 0.155289   LR 0.001000   
2022-11-03 23:47:36,173 - INFO  - Training [39][   80/  196]   Loss 0.013091   Top1 99.584961   Top5 100.000000   BatchTime 0.147329   LR 0.001000   
2022-11-03 23:47:38,647 - INFO  - Training [39][  100/  196]   Loss 0.013819   Top1 99.542969   Top5 100.000000   BatchTime 0.142599   LR 0.001000   
2022-11-03 23:47:41,106 - INFO  - Training [39][  120/  196]   Loss 0.013609   Top1 99.560547   Top5 100.000000   BatchTime 0.139328   LR 0.001000   
2022-11-03 23:47:43,569 - INFO  - Training [39][  140/  196]   Loss 0.014635   Top1 99.525670   Top5 100.000000   BatchTime 0.137016   LR 0.001000   
2022-11-03 23:47:46,031 - INFO  - Training [39][  160/  196]   Loss 0.014196   Top1 99.541016   Top5 100.000000   BatchTime 0.135274   LR 0.001000   
2022-11-03 23:47:48,491 - INFO  - Training [39][  180/  196]   Loss 0.014511   Top1 99.526910   Top5 100.000000   BatchTime 0.133911   LR 0.001000   
2022-11-03 23:47:50,665 - INFO  - ==> Top1: 99.528    Top5: 100.000    Loss: 0.015

2022-11-03 23:47:50,666 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:47:53,526 - INFO  - Validation [39][   20/   40]   Loss 0.467070   Top1 90.664062   Top5 99.648438   BatchTime 0.142913   
2022-11-03 23:47:54,320 - INFO  - Validation [39][   40/   40]   Loss 0.449426   Top1 90.890000   Top5 99.650000   BatchTime 0.091307   
2022-11-03 23:47:54,564 - INFO  - ==> Top1: 90.890    Top5: 99.650    Loss: 0.449

2022-11-03 23:47:54,591 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:47:54,592 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:47:54,592 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.920   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:47:54,696 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:47:54,696 - INFO  - >>>>>>>> Epoch  40
2022-11-03 23:47:54,697 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:47:58,735 - INFO  - Training [40][   20/  196]   Loss 0.014692   Top1 99.570312   Top5 100.000000   BatchTime 0.201855   LR 0.000100   
2022-11-03 23:48:00,736 - INFO  - Training [40][   40/  196]   Loss 0.015420   Top1 99.560547   Top5 100.000000   BatchTime 0.150965   LR 0.000100   
2022-11-03 23:48:02,617 - INFO  - Training [40][   60/  196]   Loss 0.016106   Top1 99.550781   Top5 100.000000   BatchTime 0.131998   LR 0.000100   
2022-11-03 23:48:05,089 - INFO  - Training [40][   80/  196]   Loss 0.015527   Top1 99.550781   Top5 100.000000   BatchTime 0.129895   LR 0.000100   
2022-11-03 23:48:07,556 - INFO  - Training [40][  100/  196]   Loss 0.016719   Top1 99.472656   Top5 100.000000   BatchTime 0.128587   LR 0.000100   
2022-11-03 23:48:10,019 - INFO  - Training [40][  120/  196]   Loss 0.016231   Top1 99.485677   Top5 100.000000   BatchTime 0.127679   LR 0.000100   
2022-11-03 23:48:12,491 - INFO  - Training [40][  140/  196]   Loss 0.016067   Top1 99.483817   Top5 100.000000   BatchTime 0.127092   LR 0.000100   
2022-11-03 23:48:14,936 - INFO  - Training [40][  160/  196]   Loss 0.015335   Top1 99.514160   Top5 100.000000   BatchTime 0.126486   LR 0.000100   
2022-11-03 23:48:17,385 - INFO  - Training [40][  180/  196]   Loss 0.015253   Top1 99.522569   Top5 100.000000   BatchTime 0.126041   LR 0.000100   
2022-11-03 23:48:19,554 - INFO  - ==> Top1: 99.526    Top5: 100.000    Loss: 0.015

2022-11-03 23:48:19,555 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:48:22,453 - INFO  - Validation [40][   20/   40]   Loss 0.465657   Top1 90.644531   Top5 99.589844   BatchTime 0.144816   
2022-11-03 23:48:23,618 - INFO  - Validation [40][   40/   40]   Loss 0.447591   Top1 90.810000   Top5 99.650000   BatchTime 0.101520   
2022-11-03 23:48:23,862 - INFO  - ==> Top1: 90.810    Top5: 99.650    Loss: 0.448

2022-11-03 23:48:23,891 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:48:23,892 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:48:23,892 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.920   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:48:24,000 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:48:24,001 - INFO  - >>>>>>>> Epoch  41
2022-11-03 23:48:24,002 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:48:28,414 - INFO  - Training [41][   20/  196]   Loss 0.013142   Top1 99.570312   Top5 100.000000   BatchTime 0.220581   LR 0.000100   
2022-11-03 23:48:30,875 - INFO  - Training [41][   40/  196]   Loss 0.014748   Top1 99.541016   Top5 100.000000   BatchTime 0.171811   LR 0.000100   
2022-11-03 23:48:33,338 - INFO  - Training [41][   60/  196]   Loss 0.015198   Top1 99.518229   Top5 100.000000   BatchTime 0.155585   LR 0.000100   
2022-11-03 23:48:35,809 - INFO  - Training [41][   80/  196]   Loss 0.014838   Top1 99.477539   Top5 100.000000   BatchTime 0.147582   LR 0.000100   
2022-11-03 23:48:38,276 - INFO  - Training [41][  100/  196]   Loss 0.014460   Top1 99.503906   Top5 100.000000   BatchTime 0.142733   LR 0.000100   
2022-11-03 23:48:40,737 - INFO  - Training [41][  120/  196]   Loss 0.014426   Top1 99.514974   Top5 100.000000   BatchTime 0.139455   LR 0.000100   
2022-11-03 23:48:43,191 - INFO  - Training [41][  140/  196]   Loss 0.014067   Top1 99.531250   Top5 100.000000   BatchTime 0.137058   LR 0.000100   
2022-11-03 23:48:45,637 - INFO  - Training [41][  160/  196]   Loss 0.014153   Top1 99.523926   Top5 100.000000   BatchTime 0.135212   LR 0.000100   
2022-11-03 23:48:48,064 - INFO  - Training [41][  180/  196]   Loss 0.014422   Top1 99.511719   Top5 100.000000   BatchTime 0.133670   LR 0.000100   
2022-11-03 23:48:49,662 - INFO  - ==> Top1: 99.526    Top5: 100.000    Loss: 0.014

2022-11-03 23:48:49,664 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:48:52,335 - INFO  - Validation [41][   20/   40]   Loss 0.472375   Top1 90.781250   Top5 99.589844   BatchTime 0.133465   
2022-11-03 23:48:53,102 - INFO  - Validation [41][   40/   40]   Loss 0.451948   Top1 91.040000   Top5 99.670000   BatchTime 0.085923   
2022-11-03 23:48:53,359 - INFO  - ==> Top1: 91.040    Top5: 99.670    Loss: 0.452

2022-11-03 23:48:53,385 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:48:53,386 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:48:53,386 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:48:53,572 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:48:53,730 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_best.pth.tar

2022-11-03 23:48:53,731 - INFO  - >>>>>>>> Epoch  42
2022-11-03 23:48:53,731 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:48:58,203 - INFO  - Training [42][   20/  196]   Loss 0.010568   Top1 99.687500   Top5 100.000000   BatchTime 0.223547   LR 0.000100   
2022-11-03 23:49:00,668 - INFO  - Training [42][   40/  196]   Loss 0.013611   Top1 99.472656   Top5 100.000000   BatchTime 0.173413   LR 0.000100   
2022-11-03 23:49:03,268 - INFO  - Training [42][   60/  196]   Loss 0.013965   Top1 99.505208   Top5 100.000000   BatchTime 0.158940   LR 0.000100   
2022-11-03 23:49:05,749 - INFO  - Training [42][   80/  196]   Loss 0.014639   Top1 99.492188   Top5 100.000000   BatchTime 0.150218   LR 0.000100   
2022-11-03 23:49:08,214 - INFO  - Training [42][  100/  196]   Loss 0.014154   Top1 99.507812   Top5 100.000000   BatchTime 0.144827   LR 0.000100   
2022-11-03 23:49:10,686 - INFO  - Training [42][  120/  196]   Loss 0.014657   Top1 99.492188   Top5 100.000000   BatchTime 0.141285   LR 0.000100   
2022-11-03 23:49:13,154 - INFO  - Training [42][  140/  196]   Loss 0.014403   Top1 99.508929   Top5 100.000000   BatchTime 0.138727   LR 0.000100   
2022-11-03 23:49:15,613 - INFO  - Training [42][  160/  196]   Loss 0.014287   Top1 99.523926   Top5 100.000000   BatchTime 0.136755   LR 0.000100   
2022-11-03 23:49:18,080 - INFO  - Training [42][  180/  196]   Loss 0.014222   Top1 99.529080   Top5 100.000000   BatchTime 0.135267   LR 0.000100   
2022-11-03 23:49:20,272 - INFO  - ==> Top1: 99.538    Top5: 100.000    Loss: 0.014

2022-11-03 23:49:20,273 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:49:23,157 - INFO  - Validation [42][   20/   40]   Loss 0.466851   Top1 90.800781   Top5 99.609375   BatchTime 0.144139   
2022-11-03 23:49:24,266 - INFO  - Validation [42][   40/   40]   Loss 0.445110   Top1 90.920000   Top5 99.650000   BatchTime 0.099779   
2022-11-03 23:49:24,520 - INFO  - ==> Top1: 90.920    Top5: 99.650    Loss: 0.445

2022-11-03 23:49:24,549 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:49:24,550 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:49:24,550 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:49:24,656 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:49:24,656 - INFO  - >>>>>>>> Epoch  43
2022-11-03 23:49:24,658 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:49:29,010 - INFO  - Training [43][   20/  196]   Loss 0.013382   Top1 99.589844   Top5 100.000000   BatchTime 0.217620   LR 0.000100   
2022-11-03 23:49:31,495 - INFO  - Training [43][   40/  196]   Loss 0.012958   Top1 99.589844   Top5 100.000000   BatchTime 0.170925   LR 0.000100   
2022-11-03 23:49:33,952 - INFO  - Training [43][   60/  196]   Loss 0.014327   Top1 99.518229   Top5 100.000000   BatchTime 0.154907   LR 0.000100   
2022-11-03 23:49:36,410 - INFO  - Training [43][   80/  196]   Loss 0.013607   Top1 99.531250   Top5 100.000000   BatchTime 0.146903   LR 0.000100   
2022-11-03 23:49:38,869 - INFO  - Training [43][  100/  196]   Loss 0.013951   Top1 99.550781   Top5 100.000000   BatchTime 0.142113   LR 0.000100   
2022-11-03 23:49:40,932 - INFO  - Training [43][  120/  196]   Loss 0.014252   Top1 99.541016   Top5 100.000000   BatchTime 0.135615   LR 0.000100   
2022-11-03 23:49:42,901 - INFO  - Training [43][  140/  196]   Loss 0.014429   Top1 99.534040   Top5 100.000000   BatchTime 0.130306   LR 0.000100   
2022-11-03 23:49:44,914 - INFO  - Training [43][  160/  196]   Loss 0.014395   Top1 99.538574   Top5 100.000000   BatchTime 0.126595   LR 0.000100   
2022-11-03 23:49:47,000 - INFO  - Training [43][  180/  196]   Loss 0.014470   Top1 99.544271   Top5 100.000000   BatchTime 0.124123   LR 0.000100   
2022-11-03 23:49:48,589 - INFO  - ==> Top1: 99.534    Top5: 100.000    Loss: 0.015

2022-11-03 23:49:48,590 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:49:51,553 - INFO  - Validation [43][   20/   40]   Loss 0.469271   Top1 90.781250   Top5 99.609375   BatchTime 0.148141   
2022-11-03 23:49:52,679 - INFO  - Validation [43][   40/   40]   Loss 0.449511   Top1 90.870000   Top5 99.680000   BatchTime 0.102212   
2022-11-03 23:49:52,955 - INFO  - ==> Top1: 90.870    Top5: 99.680    Loss: 0.450

2022-11-03 23:49:53,003 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:49:53,003 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:49:53,003 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.940   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:49:53,101 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:49:53,101 - INFO  - >>>>>>>> Epoch  44
2022-11-03 23:49:53,102 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:49:57,464 - INFO  - Training [44][   20/  196]   Loss 0.015302   Top1 99.355469   Top5 100.000000   BatchTime 0.218123   LR 0.000100   
2022-11-03 23:49:59,939 - INFO  - Training [44][   40/  196]   Loss 0.015376   Top1 99.414062   Top5 100.000000   BatchTime 0.170928   LR 0.000100   
2022-11-03 23:50:02,403 - INFO  - Training [44][   60/  196]   Loss 0.015102   Top1 99.459635   Top5 100.000000   BatchTime 0.155020   LR 0.000100   
2022-11-03 23:50:04,870 - INFO  - Training [44][   80/  196]   Loss 0.014493   Top1 99.492188   Top5 100.000000   BatchTime 0.147103   LR 0.000100   
2022-11-03 23:50:07,341 - INFO  - Training [44][  100/  196]   Loss 0.015008   Top1 99.488281   Top5 100.000000   BatchTime 0.142389   LR 0.000100   
2022-11-03 23:50:09,803 - INFO  - Training [44][  120/  196]   Loss 0.014640   Top1 99.505208   Top5 100.000000   BatchTime 0.139177   LR 0.000100   
2022-11-03 23:50:12,275 - INFO  - Training [44][  140/  196]   Loss 0.014740   Top1 99.514509   Top5 100.000000   BatchTime 0.136949   LR 0.000100   
2022-11-03 23:50:14,735 - INFO  - Training [44][  160/  196]   Loss 0.014903   Top1 99.511719   Top5 100.000000   BatchTime 0.135202   LR 0.000100   
2022-11-03 23:50:17,200 - INFO  - Training [44][  180/  196]   Loss 0.014391   Top1 99.535590   Top5 100.000000   BatchTime 0.133878   LR 0.000100   
2022-11-03 23:50:19,373 - INFO  - ==> Top1: 99.552    Top5: 100.000    Loss: 0.014

2022-11-03 23:50:19,374 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:50:22,266 - INFO  - Validation [44][   20/   40]   Loss 0.467407   Top1 90.625000   Top5 99.648438   BatchTime 0.144515   
2022-11-03 23:50:23,389 - INFO  - Validation [44][   40/   40]   Loss 0.448954   Top1 90.940000   Top5 99.680000   BatchTime 0.100334   
2022-11-03 23:50:23,650 - INFO  - ==> Top1: 90.940    Top5: 99.680    Loss: 0.449

2022-11-03 23:50:23,689 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:50:23,690 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:50:23,690 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.940   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:50:23,795 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:50:23,795 - INFO  - >>>>>>>> Epoch  45
2022-11-03 23:50:23,796 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:50:28,177 - INFO  - Training [45][   20/  196]   Loss 0.014046   Top1 99.531250   Top5 100.000000   BatchTime 0.219029   LR 0.000100   
2022-11-03 23:50:30,642 - INFO  - Training [45][   40/  196]   Loss 0.014764   Top1 99.541016   Top5 100.000000   BatchTime 0.171131   LR 0.000100   
2022-11-03 23:50:32,881 - INFO  - Training [45][   60/  196]   Loss 0.015496   Top1 99.518229   Top5 100.000000   BatchTime 0.151406   LR 0.000100   
2022-11-03 23:50:34,791 - INFO  - Training [45][   80/  196]   Loss 0.015584   Top1 99.511719   Top5 100.000000   BatchTime 0.137424   LR 0.000100   
2022-11-03 23:50:36,848 - INFO  - Training [45][  100/  196]   Loss 0.015556   Top1 99.492188   Top5 100.000000   BatchTime 0.130513   LR 0.000100   
2022-11-03 23:50:38,925 - INFO  - Training [45][  120/  196]   Loss 0.014887   Top1 99.521484   Top5 100.000000   BatchTime 0.126069   LR 0.000100   
2022-11-03 23:50:40,768 - INFO  - Training [45][  140/  196]   Loss 0.015252   Top1 99.506138   Top5 100.000000   BatchTime 0.121223   LR 0.000100   
2022-11-03 23:50:43,086 - INFO  - Training [45][  160/  196]   Loss 0.015488   Top1 99.509277   Top5 100.000000   BatchTime 0.120558   LR 0.000100   
2022-11-03 23:50:45,553 - INFO  - Training [45][  180/  196]   Loss 0.015311   Top1 99.522569   Top5 100.000000   BatchTime 0.120868   LR 0.000100   
2022-11-03 23:50:47,743 - INFO  - ==> Top1: 99.532    Top5: 100.000    Loss: 0.015

2022-11-03 23:50:47,744 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:50:50,607 - INFO  - Validation [45][   20/   40]   Loss 0.474318   Top1 90.605469   Top5 99.609375   BatchTime 0.143067   
2022-11-03 23:50:51,734 - INFO  - Validation [45][   40/   40]   Loss 0.453528   Top1 90.850000   Top5 99.650000   BatchTime 0.099698   
2022-11-03 23:50:51,990 - INFO  - ==> Top1: 90.850    Top5: 99.650    Loss: 0.454

2022-11-03 23:50:52,030 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:50:52,031 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:50:52,031 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.940   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:50:52,137 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:50:52,137 - INFO  - >>>>>>>> Epoch  46
2022-11-03 23:50:52,139 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:50:56,537 - INFO  - Training [46][   20/  196]   Loss 0.013830   Top1 99.628906   Top5 100.000000   BatchTime 0.219922   LR 0.000100   
2022-11-03 23:50:59,017 - INFO  - Training [46][   40/  196]   Loss 0.014121   Top1 99.580078   Top5 100.000000   BatchTime 0.171948   LR 0.000100   
2022-11-03 23:51:01,629 - INFO  - Training [46][   60/  196]   Loss 0.013959   Top1 99.570312   Top5 100.000000   BatchTime 0.158177   LR 0.000100   
2022-11-03 23:51:04,119 - INFO  - Training [46][   80/  196]   Loss 0.013874   Top1 99.594727   Top5 100.000000   BatchTime 0.149747   LR 0.000100   
2022-11-03 23:51:06,619 - INFO  - Training [46][  100/  196]   Loss 0.013496   Top1 99.593750   Top5 100.000000   BatchTime 0.144804   LR 0.000100   
2022-11-03 23:51:09,089 - INFO  - Training [46][  120/  196]   Loss 0.013540   Top1 99.606120   Top5 100.000000   BatchTime 0.141249   LR 0.000100   
2022-11-03 23:51:11,582 - INFO  - Training [46][  140/  196]   Loss 0.013353   Top1 99.603795   Top5 100.000000   BatchTime 0.138881   LR 0.000100   
2022-11-03 23:51:14,048 - INFO  - Training [46][  160/  196]   Loss 0.013671   Top1 99.587402   Top5 100.000000   BatchTime 0.136932   LR 0.000100   
2022-11-03 23:51:16,507 - INFO  - Training [46][  180/  196]   Loss 0.013543   Top1 99.583333   Top5 100.000000   BatchTime 0.135377   LR 0.000100   
2022-11-03 23:51:18,719 - INFO  - ==> Top1: 99.576    Top5: 100.000    Loss: 0.014

2022-11-03 23:51:18,720 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:51:21,593 - INFO  - Validation [46][   20/   40]   Loss 0.472170   Top1 90.644531   Top5 99.531250   BatchTime 0.143591   
2022-11-03 23:51:22,730 - INFO  - Validation [46][   40/   40]   Loss 0.451494   Top1 90.820000   Top5 99.590000   BatchTime 0.100229   
2022-11-03 23:51:22,982 - INFO  - ==> Top1: 90.820    Top5: 99.590    Loss: 0.451

2022-11-03 23:51:23,025 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:51:23,026 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:51:23,026 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.940   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:51:23,132 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:51:23,132 - INFO  - >>>>>>>> Epoch  47
2022-11-03 23:51:23,134 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:51:27,122 - INFO  - Training [47][   20/  196]   Loss 0.010418   Top1 99.667969   Top5 100.000000   BatchTime 0.199417   LR 0.000100   
2022-11-03 23:51:29,178 - INFO  - Training [47][   40/  196]   Loss 0.013062   Top1 99.589844   Top5 100.000000   BatchTime 0.151109   LR 0.000100   
2022-11-03 23:51:31,234 - INFO  - Training [47][   60/  196]   Loss 0.015329   Top1 99.498698   Top5 100.000000   BatchTime 0.134994   LR 0.000100   
2022-11-03 23:51:33,046 - INFO  - Training [47][   80/  196]   Loss 0.015947   Top1 99.477539   Top5 100.000000   BatchTime 0.123895   LR 0.000100   
2022-11-03 23:51:35,488 - INFO  - Training [47][  100/  196]   Loss 0.015186   Top1 99.503906   Top5 100.000000   BatchTime 0.123536   LR 0.000100   
2022-11-03 23:51:37,962 - INFO  - Training [47][  120/  196]   Loss 0.014486   Top1 99.524740   Top5 100.000000   BatchTime 0.123565   LR 0.000100   
2022-11-03 23:51:40,438 - INFO  - Training [47][  140/  196]   Loss 0.014220   Top1 99.550781   Top5 100.000000   BatchTime 0.123598   LR 0.000100   
2022-11-03 23:51:42,864 - INFO  - Training [47][  160/  196]   Loss 0.013934   Top1 99.553223   Top5 100.000000   BatchTime 0.123310   LR 0.000100   
2022-11-03 23:51:45,329 - INFO  - Training [47][  180/  196]   Loss 0.014627   Top1 99.535590   Top5 100.000000   BatchTime 0.123301   LR 0.000100   
2022-11-03 23:51:47,504 - INFO  - ==> Top1: 99.524    Top5: 100.000    Loss: 0.015

2022-11-03 23:51:47,505 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:51:50,413 - INFO  - Validation [47][   20/   40]   Loss 0.472134   Top1 90.664062   Top5 99.687500   BatchTime 0.145328   
2022-11-03 23:51:51,519 - INFO  - Validation [47][   40/   40]   Loss 0.447425   Top1 90.850000   Top5 99.690000   BatchTime 0.100298   
2022-11-03 23:51:51,785 - INFO  - ==> Top1: 90.850    Top5: 99.690    Loss: 0.447

2022-11-03 23:51:51,821 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:51:51,822 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:51:51,822 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.940   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:51:51,923 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:51:51,923 - INFO  - >>>>>>>> Epoch  48
2022-11-03 23:51:51,925 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:51:56,386 - INFO  - Training [48][   20/  196]   Loss 0.014553   Top1 99.550781   Top5 100.000000   BatchTime 0.223025   LR 0.000100   
2022-11-03 23:51:58,862 - INFO  - Training [48][   40/  196]   Loss 0.014271   Top1 99.550781   Top5 100.000000   BatchTime 0.173437   LR 0.000100   
2022-11-03 23:52:01,350 - INFO  - Training [48][   60/  196]   Loss 0.013920   Top1 99.563802   Top5 100.000000   BatchTime 0.157086   LR 0.000100   
2022-11-03 23:52:03,847 - INFO  - Training [48][   80/  196]   Loss 0.013761   Top1 99.545898   Top5 100.000000   BatchTime 0.149019   LR 0.000100   
2022-11-03 23:52:06,333 - INFO  - Training [48][  100/  196]   Loss 0.014298   Top1 99.523438   Top5 100.000000   BatchTime 0.144075   LR 0.000100   
2022-11-03 23:52:08,819 - INFO  - Training [48][  120/  196]   Loss 0.014422   Top1 99.508464   Top5 100.000000   BatchTime 0.140779   LR 0.000100   
2022-11-03 23:52:11,285 - INFO  - Training [48][  140/  196]   Loss 0.014427   Top1 99.503348   Top5 100.000000   BatchTime 0.138280   LR 0.000100   
2022-11-03 23:52:13,743 - INFO  - Training [48][  160/  196]   Loss 0.013893   Top1 99.531250   Top5 100.000000   BatchTime 0.136358   LR 0.000100   
2022-11-03 23:52:16,195 - INFO  - Training [48][  180/  196]   Loss 0.013958   Top1 99.531250   Top5 100.000000   BatchTime 0.134829   LR 0.000100   
2022-11-03 23:52:18,378 - INFO  - ==> Top1: 99.534    Top5: 100.000    Loss: 0.014

2022-11-03 23:52:18,379 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:52:21,068 - INFO  - Validation [48][   20/   40]   Loss 0.468166   Top1 90.449219   Top5 99.609375   BatchTime 0.134388   
2022-11-03 23:52:21,932 - INFO  - Validation [48][   40/   40]   Loss 0.447868   Top1 90.760000   Top5 99.650000   BatchTime 0.088806   
2022-11-03 23:52:22,184 - INFO  - ==> Top1: 90.760    Top5: 99.650    Loss: 0.448

2022-11-03 23:52:22,215 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:52:22,215 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:52:22,215 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.940   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:52:22,314 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:52:22,314 - INFO  - >>>>>>>> Epoch  49
2022-11-03 23:52:22,316 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:52:26,300 - INFO  - Training [49][   20/  196]   Loss 0.014339   Top1 99.511719   Top5 100.000000   BatchTime 0.199209   LR 0.000100   
2022-11-03 23:52:28,782 - INFO  - Training [49][   40/  196]   Loss 0.014533   Top1 99.521484   Top5 100.000000   BatchTime 0.161656   LR 0.000100   
2022-11-03 23:52:31,259 - INFO  - Training [49][   60/  196]   Loss 0.013722   Top1 99.511719   Top5 100.000000   BatchTime 0.149047   LR 0.000100   
2022-11-03 23:52:33,732 - INFO  - Training [49][   80/  196]   Loss 0.013970   Top1 99.511719   Top5 100.000000   BatchTime 0.142696   LR 0.000100   
2022-11-03 23:52:36,208 - INFO  - Training [49][  100/  196]   Loss 0.013628   Top1 99.523438   Top5 100.000000   BatchTime 0.138919   LR 0.000100   
2022-11-03 23:52:38,680 - INFO  - Training [49][  120/  196]   Loss 0.014011   Top1 99.511719   Top5 100.000000   BatchTime 0.136361   LR 0.000100   
2022-11-03 23:52:41,158 - INFO  - Training [49][  140/  196]   Loss 0.014177   Top1 99.506138   Top5 100.000000   BatchTime 0.134586   LR 0.000100   
2022-11-03 23:52:43,628 - INFO  - Training [49][  160/  196]   Loss 0.014097   Top1 99.511719   Top5 100.000000   BatchTime 0.133196   LR 0.000100   
2022-11-03 23:52:46,093 - INFO  - Training [49][  180/  196]   Loss 0.014085   Top1 99.516059   Top5 100.000000   BatchTime 0.132090   LR 0.000100   
2022-11-03 23:52:48,266 - INFO  - ==> Top1: 99.518    Top5: 100.000    Loss: 0.014

2022-11-03 23:52:48,267 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:52:51,151 - INFO  - Validation [49][   20/   40]   Loss 0.474405   Top1 90.371094   Top5 99.609375   BatchTime 0.144160   
2022-11-03 23:52:52,271 - INFO  - Validation [49][   40/   40]   Loss 0.450248   Top1 90.810000   Top5 99.660000   BatchTime 0.100080   
2022-11-03 23:52:52,529 - INFO  - ==> Top1: 90.810    Top5: 99.660    Loss: 0.450

2022-11-03 23:52:52,561 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:52:52,562 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:52:52,562 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.940   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:52:52,668 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:52:52,668 - INFO  - >>>>>>>> Epoch  50
2022-11-03 23:52:52,670 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:52:57,084 - INFO  - Training [50][   20/  196]   Loss 0.013632   Top1 99.531250   Top5 100.000000   BatchTime 0.220726   LR 0.000010   
2022-11-03 23:52:59,560 - INFO  - Training [50][   40/  196]   Loss 0.015512   Top1 99.414062   Top5 100.000000   BatchTime 0.172259   LR 0.000010   
2022-11-03 23:53:02,033 - INFO  - Training [50][   60/  196]   Loss 0.015045   Top1 99.440104   Top5 100.000000   BatchTime 0.156044   LR 0.000010   
2022-11-03 23:53:04,643 - INFO  - Training [50][   80/  196]   Loss 0.014738   Top1 99.467773   Top5 100.000000   BatchTime 0.149667   LR 0.000010   
2022-11-03 23:53:07,128 - INFO  - Training [50][  100/  196]   Loss 0.014849   Top1 99.472656   Top5 100.000000   BatchTime 0.144580   LR 0.000010   
2022-11-03 23:53:09,608 - INFO  - Training [50][  120/  196]   Loss 0.014314   Top1 99.492188   Top5 100.000000   BatchTime 0.141146   LR 0.000010   
2022-11-03 23:53:11,867 - INFO  - Training [50][  140/  196]   Loss 0.014463   Top1 99.489397   Top5 100.000000   BatchTime 0.137118   LR 0.000010   
2022-11-03 23:53:13,701 - INFO  - Training [50][  160/  196]   Loss 0.014388   Top1 99.489746   Top5 100.000000   BatchTime 0.131442   LR 0.000010   
2022-11-03 23:53:15,706 - INFO  - Training [50][  180/  196]   Loss 0.014825   Top1 99.474826   Top5 100.000000   BatchTime 0.127975   LR 0.000010   
2022-11-03 23:53:17,520 - INFO  - ==> Top1: 99.468    Top5: 100.000    Loss: 0.015

2022-11-03 23:53:17,521 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:53:20,269 - INFO  - Validation [50][   20/   40]   Loss 0.468174   Top1 90.820312   Top5 99.628906   BatchTime 0.137352   
2022-11-03 23:53:21,375 - INFO  - Validation [50][   40/   40]   Loss 0.449652   Top1 91.010000   Top5 99.680000   BatchTime 0.096319   
2022-11-03 23:53:21,627 - INFO  - ==> Top1: 91.010    Top5: 99.680    Loss: 0.450

2022-11-03 23:53:21,655 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:53:21,655 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:53:21,656 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.970   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:53:21,772 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:53:21,772 - INFO  - >>>>>>>> Epoch  51
2022-11-03 23:53:21,774 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:53:26,198 - INFO  - Training [51][   20/  196]   Loss 0.012263   Top1 99.550781   Top5 100.000000   BatchTime 0.221199   LR 0.000010   
2022-11-03 23:53:28,674 - INFO  - Training [51][   40/  196]   Loss 0.013775   Top1 99.501953   Top5 100.000000   BatchTime 0.172506   LR 0.000010   
2022-11-03 23:53:31,134 - INFO  - Training [51][   60/  196]   Loss 0.013253   Top1 99.583333   Top5 100.000000   BatchTime 0.156012   LR 0.000010   
2022-11-03 23:53:33,609 - INFO  - Training [51][   80/  196]   Loss 0.013329   Top1 99.584961   Top5 100.000000   BatchTime 0.147942   LR 0.000010   
2022-11-03 23:53:36,044 - INFO  - Training [51][  100/  196]   Loss 0.013523   Top1 99.570312   Top5 100.000000   BatchTime 0.142700   LR 0.000010   
2022-11-03 23:53:38,503 - INFO  - Training [51][  120/  196]   Loss 0.013540   Top1 99.557292   Top5 100.000000   BatchTime 0.139408   LR 0.000010   
2022-11-03 23:53:40,957 - INFO  - Training [51][  140/  196]   Loss 0.014201   Top1 99.531250   Top5 100.000000   BatchTime 0.137020   LR 0.000010   
2022-11-03 23:53:43,406 - INFO  - Training [51][  160/  196]   Loss 0.014238   Top1 99.523926   Top5 100.000000   BatchTime 0.135202   LR 0.000010   
2022-11-03 23:53:45,867 - INFO  - Training [51][  180/  196]   Loss 0.014409   Top1 99.529080   Top5 100.000000   BatchTime 0.133848   LR 0.000010   
2022-11-03 23:53:48,040 - INFO  - ==> Top1: 99.530    Top5: 100.000    Loss: 0.014

2022-11-03 23:53:48,041 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:53:50,919 - INFO  - Validation [51][   20/   40]   Loss 0.463256   Top1 90.722656   Top5 99.648438   BatchTime 0.143852   
2022-11-03 23:53:52,016 - INFO  - Validation [51][   40/   40]   Loss 0.447745   Top1 91.010000   Top5 99.660000   BatchTime 0.099335   
2022-11-03 23:53:52,286 - INFO  - ==> Top1: 91.010    Top5: 99.660    Loss: 0.448

2022-11-03 23:53:52,329 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:53:52,330 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:53:52,331 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:53:52,435 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:53:52,436 - INFO  - >>>>>>>> Epoch  52
2022-11-03 23:53:52,437 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:53:56,828 - INFO  - Training [52][   20/  196]   Loss 0.014987   Top1 99.511719   Top5 100.000000   BatchTime 0.219563   LR 0.000010   
2022-11-03 23:53:59,292 - INFO  - Training [52][   40/  196]   Loss 0.014645   Top1 99.541016   Top5 100.000000   BatchTime 0.171373   LR 0.000010   
2022-11-03 23:54:01,746 - INFO  - Training [52][   60/  196]   Loss 0.015893   Top1 99.485677   Top5 100.000000   BatchTime 0.155147   LR 0.000010   
2022-11-03 23:54:04,214 - INFO  - Training [52][   80/  196]   Loss 0.014662   Top1 99.521484   Top5 100.000000   BatchTime 0.147212   LR 0.000010   
2022-11-03 23:54:06,078 - INFO  - Training [52][  100/  196]   Loss 0.014761   Top1 99.507812   Top5 100.000000   BatchTime 0.136408   LR 0.000010   
2022-11-03 23:54:08,110 - INFO  - Training [52][  120/  196]   Loss 0.014369   Top1 99.527995   Top5 100.000000   BatchTime 0.130608   LR 0.000010   
2022-11-03 23:54:10,123 - INFO  - Training [52][  140/  196]   Loss 0.013931   Top1 99.553571   Top5 100.000000   BatchTime 0.126326   LR 0.000010   
2022-11-03 23:54:12,154 - INFO  - Training [52][  160/  196]   Loss 0.013903   Top1 99.553223   Top5 100.000000   BatchTime 0.123230   LR 0.000010   
2022-11-03 23:54:14,000 - INFO  - Training [52][  180/  196]   Loss 0.013914   Top1 99.559462   Top5 100.000000   BatchTime 0.119793   LR 0.000010   
2022-11-03 23:54:16,182 - INFO  - ==> Top1: 99.554    Top5: 100.000    Loss: 0.014

2022-11-03 23:54:16,183 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:54:19,049 - INFO  - Validation [52][   20/   40]   Loss 0.473888   Top1 90.781250   Top5 99.648438   BatchTime 0.143231   
2022-11-03 23:54:20,175 - INFO  - Validation [52][   40/   40]   Loss 0.451853   Top1 90.910000   Top5 99.710000   BatchTime 0.099776   
2022-11-03 23:54:20,432 - INFO  - ==> Top1: 90.910    Top5: 99.710    Loss: 0.452

2022-11-03 23:54:20,479 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:54:20,480 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:54:20,480 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:54:20,608 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:54:20,608 - INFO  - >>>>>>>> Epoch  53
2022-11-03 23:54:20,610 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:54:25,037 - INFO  - Training [53][   20/  196]   Loss 0.013318   Top1 99.628906   Top5 100.000000   BatchTime 0.221343   LR 0.000010   
2022-11-03 23:54:27,508 - INFO  - Training [53][   40/  196]   Loss 0.012612   Top1 99.619141   Top5 100.000000   BatchTime 0.172454   LR 0.000010   
2022-11-03 23:54:29,978 - INFO  - Training [53][   60/  196]   Loss 0.012545   Top1 99.609375   Top5 100.000000   BatchTime 0.156133   LR 0.000010   
2022-11-03 23:54:32,460 - INFO  - Training [53][   80/  196]   Loss 0.012752   Top1 99.609375   Top5 100.000000   BatchTime 0.148129   LR 0.000010   
2022-11-03 23:54:34,933 - INFO  - Training [53][  100/  196]   Loss 0.013046   Top1 99.574219   Top5 100.000000   BatchTime 0.143233   LR 0.000010   
2022-11-03 23:54:37,400 - INFO  - Training [53][  120/  196]   Loss 0.012973   Top1 99.576823   Top5 100.000000   BatchTime 0.139918   LR 0.000010   
2022-11-03 23:54:39,878 - INFO  - Training [53][  140/  196]   Loss 0.012894   Top1 99.584263   Top5 100.000000   BatchTime 0.137626   LR 0.000010   
2022-11-03 23:54:42,346 - INFO  - Training [53][  160/  196]   Loss 0.013271   Top1 99.572754   Top5 100.000000   BatchTime 0.135848   LR 0.000010   
2022-11-03 23:54:44,812 - INFO  - Training [53][  180/  196]   Loss 0.013275   Top1 99.568142   Top5 100.000000   BatchTime 0.134456   LR 0.000010   
2022-11-03 23:54:46,989 - INFO  - ==> Top1: 99.552    Top5: 100.000    Loss: 0.014

2022-11-03 23:54:46,990 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:54:49,908 - INFO  - Validation [53][   20/   40]   Loss 0.464275   Top1 90.820312   Top5 99.628906   BatchTime 0.145855   
2022-11-03 23:54:51,037 - INFO  - Validation [53][   40/   40]   Loss 0.446518   Top1 90.960000   Top5 99.650000   BatchTime 0.101159   
2022-11-03 23:54:51,284 - INFO  - ==> Top1: 90.960    Top5: 99.650    Loss: 0.447

2022-11-03 23:54:51,314 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:54:51,315 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:54:51,315 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:54:51,420 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:54:51,420 - INFO  - >>>>>>>> Epoch  54
2022-11-03 23:54:51,422 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:54:55,763 - INFO  - Training [54][   20/  196]   Loss 0.015562   Top1 99.492188   Top5 100.000000   BatchTime 0.217075   LR 0.000010   
2022-11-03 23:54:57,780 - INFO  - Training [54][   40/  196]   Loss 0.014916   Top1 99.541016   Top5 100.000000   BatchTime 0.158950   LR 0.000010   
2022-11-03 23:54:59,795 - INFO  - Training [54][   60/  196]   Loss 0.014354   Top1 99.537760   Top5 100.000000   BatchTime 0.139556   LR 0.000010   
2022-11-03 23:55:01,966 - INFO  - Training [54][   80/  196]   Loss 0.014072   Top1 99.545898   Top5 100.000000   BatchTime 0.131797   LR 0.000010   
2022-11-03 23:55:04,013 - INFO  - Training [54][  100/  196]   Loss 0.014463   Top1 99.531250   Top5 100.000000   BatchTime 0.125910   LR 0.000010   
2022-11-03 23:55:05,968 - INFO  - Training [54][  120/  196]   Loss 0.014539   Top1 99.527995   Top5 99.996745   BatchTime 0.121218   LR 0.000010   
2022-11-03 23:55:08,448 - INFO  - Training [54][  140/  196]   Loss 0.015013   Top1 99.520089   Top5 99.997210   BatchTime 0.121616   LR 0.000010   
2022-11-03 23:55:10,919 - INFO  - Training [54][  160/  196]   Loss 0.014636   Top1 99.526367   Top5 99.997559   BatchTime 0.121854   LR 0.000010   
2022-11-03 23:55:13,369 - INFO  - Training [54][  180/  196]   Loss 0.014866   Top1 99.516059   Top5 99.997830   BatchTime 0.121926   LR 0.000010   
2022-11-03 23:55:15,543 - INFO  - ==> Top1: 99.512    Top5: 99.998    Loss: 0.015

2022-11-03 23:55:15,543 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:55:18,430 - INFO  - Validation [54][   20/   40]   Loss 0.473156   Top1 90.468750   Top5 99.570312   BatchTime 0.144260   
2022-11-03 23:55:19,558 - INFO  - Validation [54][   40/   40]   Loss 0.451864   Top1 90.700000   Top5 99.650000   BatchTime 0.100351   
2022-11-03 23:55:19,805 - INFO  - ==> Top1: 90.700    Top5: 99.650    Loss: 0.452

2022-11-03 23:55:19,843 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:55:19,843 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:55:19,843 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:55:19,947 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:55:19,947 - INFO  - >>>>>>>> Epoch  55
2022-11-03 23:55:19,949 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:55:24,295 - INFO  - Training [55][   20/  196]   Loss 0.014763   Top1 99.531250   Top5 100.000000   BatchTime 0.217305   LR 0.000010   
2022-11-03 23:55:26,773 - INFO  - Training [55][   40/  196]   Loss 0.013232   Top1 99.580078   Top5 100.000000   BatchTime 0.170601   LR 0.000010   
2022-11-03 23:55:29,246 - INFO  - Training [55][   60/  196]   Loss 0.012916   Top1 99.576823   Top5 100.000000   BatchTime 0.154946   LR 0.000010   
2022-11-03 23:55:31,727 - INFO  - Training [55][   80/  196]   Loss 0.013382   Top1 99.584961   Top5 100.000000   BatchTime 0.147222   LR 0.000010   
2022-11-03 23:55:34,209 - INFO  - Training [55][  100/  196]   Loss 0.013879   Top1 99.570312   Top5 100.000000   BatchTime 0.142601   LR 0.000010   
2022-11-03 23:55:36,678 - INFO  - Training [55][  120/  196]   Loss 0.013911   Top1 99.567057   Top5 100.000000   BatchTime 0.139409   LR 0.000010   
2022-11-03 23:55:39,143 - INFO  - Training [55][  140/  196]   Loss 0.014376   Top1 99.542411   Top5 100.000000   BatchTime 0.137099   LR 0.000010   
2022-11-03 23:55:41,604 - INFO  - Training [55][  160/  196]   Loss 0.015036   Top1 99.519043   Top5 100.000000   BatchTime 0.135338   LR 0.000010   
2022-11-03 23:55:44,069 - INFO  - Training [55][  180/  196]   Loss 0.014787   Top1 99.535590   Top5 100.000000   BatchTime 0.133995   LR 0.000010   
2022-11-03 23:55:46,239 - INFO  - ==> Top1: 99.530    Top5: 100.000    Loss: 0.015

2022-11-03 23:55:46,239 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:55:49,120 - INFO  - Validation [55][   20/   40]   Loss 0.471143   Top1 90.566406   Top5 99.628906   BatchTime 0.143969   
2022-11-03 23:55:49,962 - INFO  - Validation [55][   40/   40]   Loss 0.450118   Top1 90.740000   Top5 99.670000   BatchTime 0.093028   
2022-11-03 23:55:50,237 - INFO  - ==> Top1: 90.740    Top5: 99.670    Loss: 0.450

2022-11-03 23:55:50,262 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:55:50,263 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:55:50,263 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:55:50,366 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:55:50,366 - INFO  - >>>>>>>> Epoch  56
2022-11-03 23:55:50,368 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:55:54,386 - INFO  - Training [56][   20/  196]   Loss 0.011724   Top1 99.667969   Top5 100.000000   BatchTime 0.200925   LR 0.000010   
2022-11-03 23:55:56,461 - INFO  - Training [56][   40/  196]   Loss 0.013904   Top1 99.560547   Top5 100.000000   BatchTime 0.152326   LR 0.000010   
2022-11-03 23:55:58,289 - INFO  - Training [56][   60/  196]   Loss 0.014362   Top1 99.537760   Top5 100.000000   BatchTime 0.132014   LR 0.000010   
2022-11-03 23:56:00,801 - INFO  - Training [56][   80/  196]   Loss 0.015226   Top1 99.521484   Top5 100.000000   BatchTime 0.130414   LR 0.000010   
2022-11-03 23:56:03,281 - INFO  - Training [56][  100/  196]   Loss 0.014843   Top1 99.535156   Top5 100.000000   BatchTime 0.129128   LR 0.000010   
2022-11-03 23:56:05,766 - INFO  - Training [56][  120/  196]   Loss 0.015429   Top1 99.524740   Top5 100.000000   BatchTime 0.128317   LR 0.000010   
2022-11-03 23:56:08,233 - INFO  - Training [56][  140/  196]   Loss 0.015008   Top1 99.536830   Top5 100.000000   BatchTime 0.127607   LR 0.000010   
2022-11-03 23:56:10,703 - INFO  - Training [56][  160/  196]   Loss 0.015043   Top1 99.548340   Top5 100.000000   BatchTime 0.127089   LR 0.000010   
2022-11-03 23:56:13,171 - INFO  - Training [56][  180/  196]   Loss 0.014870   Top1 99.539931   Top5 100.000000   BatchTime 0.126681   LR 0.000010   
2022-11-03 23:56:15,366 - INFO  - ==> Top1: 99.548    Top5: 100.000    Loss: 0.015

2022-11-03 23:56:15,366 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:56:18,252 - INFO  - Validation [56][   20/   40]   Loss 0.470312   Top1 90.566406   Top5 99.609375   BatchTime 0.144176   
2022-11-03 23:56:19,407 - INFO  - Validation [56][   40/   40]   Loss 0.449467   Top1 90.800000   Top5 99.660000   BatchTime 0.100975   
2022-11-03 23:56:19,659 - INFO  - ==> Top1: 90.800    Top5: 99.660    Loss: 0.449

2022-11-03 23:56:19,705 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:56:19,706 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:56:19,706 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:56:19,808 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:56:19,808 - INFO  - >>>>>>>> Epoch  57
2022-11-03 23:56:19,810 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:56:24,202 - INFO  - Training [57][   20/  196]   Loss 0.011905   Top1 99.589844   Top5 100.000000   BatchTime 0.219582   LR 0.000010   
2022-11-03 23:56:26,695 - INFO  - Training [57][   40/  196]   Loss 0.011209   Top1 99.658203   Top5 100.000000   BatchTime 0.172121   LR 0.000010   
2022-11-03 23:56:29,180 - INFO  - Training [57][   60/  196]   Loss 0.010963   Top1 99.641927   Top5 100.000000   BatchTime 0.156174   LR 0.000010   
2022-11-03 23:56:31,660 - INFO  - Training [57][   80/  196]   Loss 0.011731   Top1 99.614258   Top5 100.000000   BatchTime 0.148121   LR 0.000010   
2022-11-03 23:56:34,133 - INFO  - Training [57][  100/  196]   Loss 0.012104   Top1 99.621094   Top5 100.000000   BatchTime 0.143234   LR 0.000010   
2022-11-03 23:56:36,615 - INFO  - Training [57][  120/  196]   Loss 0.012148   Top1 99.606120   Top5 100.000000   BatchTime 0.140038   LR 0.000010   
2022-11-03 23:56:39,071 - INFO  - Training [57][  140/  196]   Loss 0.012361   Top1 99.589844   Top5 100.000000   BatchTime 0.137577   LR 0.000010   
2022-11-03 23:56:41,521 - INFO  - Training [57][  160/  196]   Loss 0.012457   Top1 99.584961   Top5 100.000000   BatchTime 0.135693   LR 0.000010   
2022-11-03 23:56:43,982 - INFO  - Training [57][  180/  196]   Loss 0.012333   Top1 99.592014   Top5 100.000000   BatchTime 0.134289   LR 0.000010   
2022-11-03 23:56:45,532 - INFO  - ==> Top1: 99.580    Top5: 100.000    Loss: 0.013

2022-11-03 23:56:45,533 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:56:48,226 - INFO  - Validation [57][   20/   40]   Loss 0.468328   Top1 90.527344   Top5 99.648438   BatchTime 0.134540   
2022-11-03 23:56:49,046 - INFO  - Validation [57][   40/   40]   Loss 0.449786   Top1 90.780000   Top5 99.670000   BatchTime 0.087789   
2022-11-03 23:56:49,296 - INFO  - ==> Top1: 90.780    Top5: 99.670    Loss: 0.450

2022-11-03 23:56:49,321 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:56:49,322 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:56:49,322 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:56:49,398 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:56:49,398 - INFO  - >>>>>>>> Epoch  58
2022-11-03 23:56:49,400 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:56:53,912 - INFO  - Training [58][   20/  196]   Loss 0.010880   Top1 99.687500   Top5 100.000000   BatchTime 0.225615   LR 0.000010   
2022-11-03 23:56:56,387 - INFO  - Training [58][   40/  196]   Loss 0.011557   Top1 99.648438   Top5 100.000000   BatchTime 0.174669   LR 0.000010   
2022-11-03 23:56:58,866 - INFO  - Training [58][   60/  196]   Loss 0.012375   Top1 99.570312   Top5 100.000000   BatchTime 0.157776   LR 0.000010   
2022-11-03 23:57:01,350 - INFO  - Training [58][   80/  196]   Loss 0.012639   Top1 99.560547   Top5 100.000000   BatchTime 0.149377   LR 0.000010   
2022-11-03 23:57:03,828 - INFO  - Training [58][  100/  196]   Loss 0.012828   Top1 99.558594   Top5 100.000000   BatchTime 0.144275   LR 0.000010   
2022-11-03 23:57:06,436 - INFO  - Training [58][  120/  196]   Loss 0.012940   Top1 99.550781   Top5 100.000000   BatchTime 0.141969   LR 0.000010   
2022-11-03 23:57:08,919 - INFO  - Training [58][  140/  196]   Loss 0.013509   Top1 99.536830   Top5 100.000000   BatchTime 0.139420   LR 0.000010   
2022-11-03 23:57:11,374 - INFO  - Training [58][  160/  196]   Loss 0.013708   Top1 99.526367   Top5 100.000000   BatchTime 0.137338   LR 0.000010   
2022-11-03 23:57:13,824 - INFO  - Training [58][  180/  196]   Loss 0.013653   Top1 99.522569   Top5 100.000000   BatchTime 0.135687   LR 0.000010   
2022-11-03 23:57:16,008 - INFO  - ==> Top1: 99.508    Top5: 100.000    Loss: 0.014

2022-11-03 23:57:16,009 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:57:18,869 - INFO  - Validation [58][   20/   40]   Loss 0.474386   Top1 90.820312   Top5 99.648438   BatchTime 0.142943   
2022-11-03 23:57:19,984 - INFO  - Validation [58][   40/   40]   Loss 0.448145   Top1 90.940000   Top5 99.670000   BatchTime 0.099342   
2022-11-03 23:57:20,246 - INFO  - ==> Top1: 90.940    Top5: 99.670    Loss: 0.448

2022-11-03 23:57:20,274 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:57:20,274 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:57:20,275 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:57:20,362 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:57:20,362 - INFO  - >>>>>>>> Epoch  59
2022-11-03 23:57:20,363 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:57:24,718 - INFO  - Training [59][   20/  196]   Loss 0.013031   Top1 99.628906   Top5 100.000000   BatchTime 0.217739   LR 0.000010   
2022-11-03 23:57:27,187 - INFO  - Training [59][   40/  196]   Loss 0.011242   Top1 99.687500   Top5 100.000000   BatchTime 0.170576   LR 0.000010   
2022-11-03 23:57:29,667 - INFO  - Training [59][   60/  196]   Loss 0.013459   Top1 99.615885   Top5 100.000000   BatchTime 0.155047   LR 0.000010   
2022-11-03 23:57:32,134 - INFO  - Training [59][   80/  196]   Loss 0.013413   Top1 99.594727   Top5 100.000000   BatchTime 0.147124   LR 0.000010   
2022-11-03 23:57:34,590 - INFO  - Training [59][  100/  196]   Loss 0.013688   Top1 99.593750   Top5 100.000000   BatchTime 0.142258   LR 0.000010   
2022-11-03 23:57:36,975 - INFO  - Training [59][  120/  196]   Loss 0.014569   Top1 99.537760   Top5 100.000000   BatchTime 0.138426   LR 0.000010   
2022-11-03 23:57:38,818 - INFO  - Training [59][  140/  196]   Loss 0.014477   Top1 99.545201   Top5 100.000000   BatchTime 0.131816   LR 0.000010   
2022-11-03 23:57:40,836 - INFO  - Training [59][  160/  196]   Loss 0.014414   Top1 99.553223   Top5 100.000000   BatchTime 0.127951   LR 0.000010   
2022-11-03 23:57:42,864 - INFO  - Training [59][  180/  196]   Loss 0.014685   Top1 99.546441   Top5 100.000000   BatchTime 0.124999   LR 0.000010   
2022-11-03 23:57:44,629 - INFO  - ==> Top1: 99.548    Top5: 100.000    Loss: 0.014

2022-11-03 23:57:44,630 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:57:47,626 - INFO  - Validation [59][   20/   40]   Loss 0.469721   Top1 90.703125   Top5 99.628906   BatchTime 0.149744   
2022-11-03 23:57:48,773 - INFO  - Validation [59][   40/   40]   Loss 0.454431   Top1 90.770000   Top5 99.690000   BatchTime 0.103530   
2022-11-03 23:57:49,023 - INFO  - ==> Top1: 90.770    Top5: 99.690    Loss: 0.454

2022-11-03 23:57:49,052 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 91.040   Top5: 99.670] Sparsity : 0.775
2022-11-03 23:57:49,053 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.010   Top5: 99.680] Sparsity : 0.775
2022-11-03 23:57:49,053 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 91.010   Top5: 99.660] Sparsity : 0.775
2022-11-03 23:57:49,151 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_20221103-232758/MobileNetv2_cifar10_a8w8_hard_pruning_5_epoch60_checkpoint.pth.tar

2022-11-03 23:57:49,152 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 23:57:49,152 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:57:52,074 - INFO  - Validation [   20/   40]   Loss 0.469721   Top1 90.703125   Top5 99.628906   BatchTime 0.146030   
2022-11-03 23:57:53,173 - INFO  - Validation [   40/   40]   Loss 0.454431   Top1 90.770000   Top5 99.690000   BatchTime 0.100499   
2022-11-03 23:57:53,440 - INFO  - ==> Top1: 90.770    Top5: 99.690    Loss: 0.454

2022-11-03 23:57:53,473 - INFO  - Program completed successfully ... exiting ...
2022-11-03 23:57:53,473 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
