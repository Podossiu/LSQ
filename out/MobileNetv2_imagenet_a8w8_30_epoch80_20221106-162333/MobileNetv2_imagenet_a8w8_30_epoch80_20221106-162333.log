2022-11-06 16:23:33,383 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-162333/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-162333.log
2022-11-06 16:23:34,362 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-162333/tb_runs
2022-11-06 16:23:36,568 - INFO  - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
2022-11-06 16:23:38,101 - INFO  - Created `MobileNetv2` model for `imagenet` dataset
          Use pre-trained model = True
2022-11-06 16:23:40,320 - INFO  - Inserted quantizers into the original model
2022-11-06 16:23:40,491 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.05
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-06 16:23:40,491 - INFO  - LR scheduler: `CosineLr`
    Update per batch: True
             Group 0: 0.05

2022-11-06 16:23:40,491 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-06 16:23:40,491 - INFO  - Validation: 50000 samples (128 per mini-batch)
2022-11-06 16:23:52,653 - INFO  - Validation [   20/  391]   Loss 27.609890   Top1 0.000000   Top5 0.117188   BatchTime 0.608048   
2022-11-06 16:23:56,196 - INFO  - Validation [   40/  391]   Loss 28.591004   Top1 0.000000   Top5 0.058594   BatchTime 0.392599   
2022-11-06 16:23:59,720 - INFO  - Validation [   60/  391]   Loss 27.567062   Top1 0.000000   Top5 0.403646   BatchTime 0.320468   
2022-11-06 16:24:03,258 - INFO  - Validation [   80/  391]   Loss 24.924523   Top1 0.000000   Top5 0.419922   BatchTime 0.284572   
2022-11-06 16:24:06,807 - INFO  - Validation [  100/  391]   Loss 23.307600   Top1 0.000000   Top5 0.335938   BatchTime 0.263152   
2022-11-06 16:24:10,350 - INFO  - Validation [  120/  391]   Loss 23.457049   Top1 0.312500   Top5 0.657552   BatchTime 0.248813   
2022-11-06 16:24:13,887 - INFO  - Validation [  140/  391]   Loss 24.179314   Top1 0.267857   Top5 0.563616   BatchTime 0.238537   
2022-11-06 16:24:17,428 - INFO  - Validation [  160/  391]   Loss 24.201449   Top1 0.234375   Top5 0.493164   BatchTime 0.230848   
2022-11-06 16:24:20,951 - INFO  - Validation [  180/  391]   Loss 24.038137   Top1 0.208333   Top5 0.438368   BatchTime 0.224771   
2022-11-06 16:24:24,467 - INFO  - Validation [  200/  391]   Loss 24.115841   Top1 0.187500   Top5 0.394531   BatchTime 0.219876   
2022-11-06 16:24:28,042 - INFO  - Validation [  220/  391]   Loss 24.233748   Top1 0.184659   Top5 0.529119   BatchTime 0.216135   
2022-11-06 16:24:31,575 - INFO  - Validation [  240/  391]   Loss 24.254343   Top1 0.169271   Top5 0.488281   BatchTime 0.212843   
2022-11-06 16:24:35,133 - INFO  - Validation [  260/  391]   Loss 24.264850   Top1 0.156250   Top5 0.450721   BatchTime 0.210156   
2022-11-06 16:24:38,664 - INFO  - Validation [  280/  391]   Loss 24.328493   Top1 0.145089   Top5 0.502232   BatchTime 0.207757   
2022-11-06 16:24:42,186 - INFO  - Validation [  300/  391]   Loss 24.268197   Top1 0.135417   Top5 0.611979   BatchTime 0.205646   
2022-11-06 16:24:45,704 - INFO  - Validation [  320/  391]   Loss 24.314753   Top1 0.126953   Top5 0.573730   BatchTime 0.203787   
2022-11-06 16:24:49,110 - INFO  - Validation [  340/  391]   Loss 24.194326   Top1 0.119485   Top5 0.562960   BatchTime 0.201816   
2022-11-06 16:24:52,446 - INFO  - Validation [  360/  391]   Loss 24.101134   Top1 0.112847   Top5 0.531684   BatchTime 0.199872   
2022-11-06 16:24:55,772 - INFO  - Validation [  380/  391]   Loss 24.285498   Top1 0.106908   Top5 0.503701   BatchTime 0.198105   
2022-11-06 16:24:58,003 - INFO  - ==> Top1: 0.104    Top5: 0.490    Loss: 24.380

2022-11-06 16:24:58,028 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 0.104   Top5: 0.490] Sparsity : 0.060
2022-11-06 16:24:58,028 - INFO  - >>>>>>>> Epoch   0
2022-11-06 16:24:58,029 - INFO  - Training: 1281167 samples (128 per mini-batch)
2022-11-06 16:25:13,122 - INFO  - Training [0][   20/10010]   Loss 7.281072   Top1 0.976562   Top5 4.101562   BatchTime 0.754619   LR 0.050000   
2022-11-06 16:25:22,025 - INFO  - Training [0][   40/10010]   Loss 7.131259   Top1 0.703125   Top5 3.066406   BatchTime 0.599892   LR 0.049998   
2022-11-06 16:25:30,946 - INFO  - Training [0][   60/10010]   Loss 6.992555   Top1 0.651042   Top5 2.864583   BatchTime 0.548613   LR 0.049995   
2022-11-06 16:25:39,845 - INFO  - Training [0][   80/10010]   Loss 6.866402   Top1 0.722656   Top5 3.007812   BatchTime 0.522697   LR 0.049991   
2022-11-06 16:25:48,752 - INFO  - Training [0][  100/10010]   Loss 6.754434   Top1 0.820312   Top5 3.328125   BatchTime 0.507230   LR 0.049987   
2022-11-06 16:25:57,655 - INFO  - Training [0][  120/10010]   Loss 6.676119   Top1 0.930990   Top5 3.567708   BatchTime 0.496879   LR 0.049981   
2022-11-06 16:26:06,550 - INFO  - Training [0][  140/10010]   Loss 6.604322   Top1 0.998884   Top5 3.850446   BatchTime 0.489432   LR 0.049974   
2022-11-06 16:26:15,481 - INFO  - Training [0][  160/10010]   Loss 6.541050   Top1 1.147461   Top5 4.218750   BatchTime 0.484074   LR 0.049966   
2022-11-06 16:26:24,397 - INFO  - Training [0][  180/10010]   Loss 6.491510   Top1 1.245660   Top5 4.505208   BatchTime 0.479819   LR 0.049956   
2022-11-06 16:26:33,307 - INFO  - Training [0][  200/10010]   Loss 6.447882   Top1 1.328125   Top5 4.769531   BatchTime 0.476387   LR 0.049946   
2022-11-06 16:26:42,221 - INFO  - Training [0][  220/10010]   Loss 6.404742   Top1 1.402699   Top5 5.092330   BatchTime 0.473596   LR 0.049935   
2022-11-06 16:26:51,133 - INFO  - Training [0][  240/10010]   Loss 6.364722   Top1 1.513672   Top5 5.426432   BatchTime 0.471264   LR 0.049922   
2022-11-06 16:27:00,045 - INFO  - Training [0][  260/10010]   Loss 6.334982   Top1 1.610577   Top5 5.667067   BatchTime 0.469288   LR 0.049909   
2022-11-06 16:27:08,964 - INFO  - Training [0][  280/10010]   Loss 6.304673   Top1 1.626674   Top5 5.828683   BatchTime 0.467623   LR 0.049894   
2022-11-06 16:27:17,872 - INFO  - Training [0][  300/10010]   Loss 6.269328   Top1 1.708333   Top5 6.096354   BatchTime 0.466140   LR 0.049878   
