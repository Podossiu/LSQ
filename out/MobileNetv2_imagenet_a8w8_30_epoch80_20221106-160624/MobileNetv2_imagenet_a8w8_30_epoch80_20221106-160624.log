2022-11-06 16:06:24,239 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-160624/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-160624.log
2022-11-06 16:06:25,214 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_imagenet_a8w8_30_epoch80_20221106-160624/tb_runs
2022-11-06 16:06:27,457 - INFO  - Dataset `imagenet` size:
          Training Set = 1281167 (10010)
        Validation Set = 50000 (391)
              Test Set = 50000 (391)
2022-11-06 16:06:28,997 - INFO  - Created `MobileNetv2` model for `imagenet` dataset
          Use pre-trained model = True
2022-11-06 16:06:31,232 - INFO  - Inserted quantizers into the original model
2022-11-06 16:06:31,404 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               initial_lr: 0.05
               lr: 0.05
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-06 16:06:31,405 - INFO  - LR scheduler: <torch.optim.lr_scheduler.CosineAnnealingWarmRestarts object at 0x7f21605e0fd0>

2022-11-06 16:06:31,405 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-06 16:06:31,405 - INFO  - Validation: 50000 samples (128 per mini-batch)
2022-11-06 16:06:43,782 - INFO  - Validation [   20/  391]   Loss 27.609890   Top1 0.000000   Top5 0.117188   BatchTime 0.618808   
2022-11-06 16:06:47,307 - INFO  - Validation [   40/  391]   Loss 28.591004   Top1 0.000000   Top5 0.058594   BatchTime 0.397531   
2022-11-06 16:06:50,863 - INFO  - Validation [   60/  391]   Loss 27.567062   Top1 0.000000   Top5 0.403646   BatchTime 0.324291   
2022-11-06 16:06:54,404 - INFO  - Validation [   80/  391]   Loss 24.924523   Top1 0.000000   Top5 0.419922   BatchTime 0.287487   
2022-11-06 16:06:57,933 - INFO  - Validation [  100/  391]   Loss 23.307600   Top1 0.000000   Top5 0.335938   BatchTime 0.265279   
2022-11-06 16:07:01,468 - INFO  - Validation [  120/  391]   Loss 23.457049   Top1 0.312500   Top5 0.657552   BatchTime 0.250520   
2022-11-06 16:07:05,018 - INFO  - Validation [  140/  391]   Loss 24.179314   Top1 0.267857   Top5 0.563616   BatchTime 0.240092   
2022-11-06 16:07:08,561 - INFO  - Validation [  160/  391]   Loss 24.201449   Top1 0.234375   Top5 0.493164   BatchTime 0.232220   
2022-11-06 16:07:12,113 - INFO  - Validation [  180/  391]   Loss 24.038137   Top1 0.208333   Top5 0.438368   BatchTime 0.226156   
2022-11-06 16:07:15,662 - INFO  - Validation [  200/  391]   Loss 24.115841   Top1 0.187500   Top5 0.394531   BatchTime 0.221282   
2022-11-06 16:07:19,234 - INFO  - Validation [  220/  391]   Loss 24.233748   Top1 0.184659   Top5 0.529119   BatchTime 0.217403   
2022-11-06 16:07:22,760 - INFO  - Validation [  240/  391]   Loss 24.254343   Top1 0.169271   Top5 0.488281   BatchTime 0.213975   
2022-11-06 16:07:26,344 - INFO  - Validation [  260/  391]   Loss 24.264850   Top1 0.156250   Top5 0.450721   BatchTime 0.211303   
2022-11-06 16:07:29,888 - INFO  - Validation [  280/  391]   Loss 24.328493   Top1 0.145089   Top5 0.502232   BatchTime 0.208866   
2022-11-06 16:07:33,434 - INFO  - Validation [  300/  391]   Loss 24.268197   Top1 0.135417   Top5 0.611979   BatchTime 0.206761   
2022-11-06 16:07:36,977 - INFO  - Validation [  320/  391]   Loss 24.314753   Top1 0.126953   Top5 0.573730   BatchTime 0.204911   
2022-11-06 16:07:40,394 - INFO  - Validation [  340/  391]   Loss 24.194326   Top1 0.119485   Top5 0.562960   BatchTime 0.202908   
2022-11-06 16:07:43,728 - INFO  - Validation [  360/  391]   Loss 24.101134   Top1 0.112847   Top5 0.531684   BatchTime 0.200897   
2022-11-06 16:07:47,060 - INFO  - Validation [  380/  391]   Loss 24.285498   Top1 0.106908   Top5 0.503701   BatchTime 0.199091   
2022-11-06 16:07:49,297 - INFO  - ==> Top1: 0.104    Top5: 0.490    Loss: 24.380

2022-11-06 16:07:49,322 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 0.104   Top5: 0.490] Sparsity : 0.060
2022-11-06 16:07:49,322 - INFO  - >>>>>>>> Epoch   0
2022-11-06 16:07:49,322 - INFO  - Training: 1281167 samples (128 per mini-batch)
2022-11-06 16:08:04,054 - INFO  - Training [0][   20/10010]   Loss 7.282508   Top1 1.054688   Top5 3.750000   BatchTime 0.736554   LR 0.050000   
2022-11-06 16:08:12,956 - INFO  - Training [0][   40/10010]   Loss 7.104260   Top1 0.683594   Top5 2.910156   BatchTime 0.590837   LR 0.050000   
2022-11-06 16:08:21,865 - INFO  - Training [0][   60/10010]   Loss 6.975539   Top1 0.611979   Top5 2.591146   BatchTime 0.542375   LR 0.050000   
2022-11-06 16:08:30,779 - INFO  - Training [0][   80/10010]   Loss 6.866246   Top1 0.664062   Top5 2.656250   BatchTime 0.518199   LR 0.050000   
2022-11-06 16:08:39,676 - INFO  - Training [0][  100/10010]   Loss 6.778104   Top1 0.679688   Top5 2.812500   BatchTime 0.503528   LR 0.050000   
2022-11-06 16:08:48,580 - INFO  - Training [0][  120/10010]   Loss 6.707448   Top1 0.807292   Top5 3.177083   BatchTime 0.493806   LR 0.050000   
2022-11-06 16:08:57,489 - INFO  - Training [0][  140/10010]   Loss 6.646622   Top1 0.859375   Top5 3.404018   BatchTime 0.486898   LR 0.050000   
2022-11-06 16:09:06,394 - INFO  - Training [0][  160/10010]   Loss 6.594379   Top1 0.947266   Top5 3.671875   BatchTime 0.481696   LR 0.050000   
2022-11-06 16:09:15,512 - INFO  - Training [0][  180/10010]   Loss 6.551073   Top1 1.050347   Top5 3.953993   BatchTime 0.478825   LR 0.050000   
2022-11-06 16:09:24,426 - INFO  - Training [0][  200/10010]   Loss 6.511810   Top1 1.113281   Top5 4.207031   BatchTime 0.475513   LR 0.050000   
2022-11-06 16:09:33,347 - INFO  - Training [0][  220/10010]   Loss 6.477096   Top1 1.164773   Top5 4.410511   BatchTime 0.472837   LR 0.050000   
2022-11-06 16:09:42,290 - INFO  - Training [0][  240/10010]   Loss 6.440491   Top1 1.233724   Top5 4.661458   BatchTime 0.470695   LR 0.050000   
2022-11-06 16:09:51,260 - INFO  - Training [0][  260/10010]   Loss 6.414406   Top1 1.286058   Top5 4.810697   BatchTime 0.468989   LR 0.050000   
2022-11-06 16:10:00,175 - INFO  - Training [0][  280/10010]   Loss 6.388227   Top1 1.297433   Top5 4.952567   BatchTime 0.467329   LR 0.050000   
2022-11-06 16:10:09,096 - INFO  - Training [0][  300/10010]   Loss 6.357495   Top1 1.356771   Top5 5.187500   BatchTime 0.465908   LR 0.050000   
2022-11-06 16:10:18,015 - INFO  - Training [0][  320/10010]   Loss 6.327235   Top1 1.430664   Top5 5.427246   BatchTime 0.464660   LR 0.050000   
2022-11-06 16:10:26,971 - INFO  - Training [0][  340/10010]   Loss 6.298789   Top1 1.530331   Top5 5.749081   BatchTime 0.463667   LR 0.050000   
2022-11-06 16:10:35,902 - INFO  - Training [0][  360/10010]   Loss 6.272755   Top1 1.610243   Top5 5.987413   BatchTime 0.462717   LR 0.050000   
2022-11-06 16:10:44,867 - INFO  - Training [0][  380/10010]   Loss 6.252367   Top1 1.669408   Top5 6.165707   BatchTime 0.461955   LR 0.050000   
2022-11-06 16:10:53,794 - INFO  - Training [0][  400/10010]   Loss 6.230449   Top1 1.748047   Top5 6.394531   BatchTime 0.461175   LR 0.050000   
2022-11-06 16:11:02,727 - INFO  - Training [0][  420/10010]   Loss 6.206876   Top1 1.813616   Top5 6.670387   BatchTime 0.460483   LR 0.050001   
2022-11-06 16:11:11,647 - INFO  - Training [0][  440/10010]   Loss 6.187065   Top1 1.887429   Top5 6.853693   BatchTime 0.459824   LR 0.050001   
2022-11-06 16:11:20,575 - INFO  - Training [0][  460/10010]   Loss 6.167913   Top1 1.937840   Top5 7.019361   BatchTime 0.459241   LR 0.050001   
2022-11-06 16:11:29,490 - INFO  - Training [0][  480/10010]   Loss 6.150301   Top1 1.998698   Top5 7.224935   BatchTime 0.458679   LR 0.050001   
2022-11-06 16:11:38,429 - INFO  - Training [0][  500/10010]   Loss 6.132817   Top1 2.071875   Top5 7.425000   BatchTime 0.458210   LR 0.050001   
2022-11-06 16:11:47,372 - INFO  - Training [0][  520/10010]   Loss 6.114248   Top1 2.160457   Top5 7.651743   BatchTime 0.457784   LR 0.050001   
2022-11-06 16:11:56,298 - INFO  - Training [0][  540/10010]   Loss 6.095819   Top1 2.233796   Top5 7.861690   BatchTime 0.457359   LR 0.050001   
2022-11-06 16:12:05,265 - INFO  - Training [0][  560/10010]   Loss 6.080513   Top1 2.280971   Top5 8.010603   BatchTime 0.457036   LR 0.050001   
2022-11-06 16:12:14,215 - INFO  - Training [0][  580/10010]   Loss 6.063968   Top1 2.359914   Top5 8.221983   BatchTime 0.456707   LR 0.050001   
2022-11-06 16:12:23,142 - INFO  - Training [0][  600/10010]   Loss 6.047937   Top1 2.403646   Top5 8.401042   BatchTime 0.456362   LR 0.050001   
