2022-11-03 22:41:02,241 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102.log
2022-11-03 22:41:03,311 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/tb_runs
2022-11-03 22:41:04,431 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (391)
        Validation Set = 10000 (79)
              Test Set = 10000 (79)
2022-11-03 22:41:05,989 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = True
2022-11-03 22:41:08,141 - INFO  - Inserted quantizers into the original model
2022-11-03 22:41:08,308 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 22:41:08,308 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 22:41:08,308 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 22:41:08,308 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:41:11,444 - INFO  - Validation [   20/   79]   Loss 2.545371   Top1 10.429688   Top5 49.101562   BatchTime 0.156761   
2022-11-03 22:41:11,959 - INFO  - Validation [   40/   79]   Loss 2.549466   Top1 10.175781   Top5 49.941406   BatchTime 0.091258   
2022-11-03 22:41:12,483 - INFO  - Validation [   60/   79]   Loss 2.541519   Top1 10.117188   Top5 50.377604   BatchTime 0.069569   
2022-11-03 22:41:13,255 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.546

2022-11-03 22:41:13,281 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 22:41:13,281 - INFO  - >>>>>>>> Epoch   0
2022-11-03 22:41:13,282 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:41:17,183 - INFO  - Training [0][   20/  391]   Loss 1.646139   Top1 67.421875   Top5 96.171875   BatchTime 0.195054   LR 0.010000   
2022-11-03 22:41:18,811 - INFO  - Training [0][   40/  391]   Loss 1.375846   Top1 68.964844   Top5 96.640625   BatchTime 0.138221   LR 0.010000   
2022-11-03 22:41:20,400 - INFO  - Training [0][   60/  391]   Loss 1.194387   Top1 70.729167   Top5 97.083333   BatchTime 0.118623   LR 0.010000   
2022-11-03 22:41:22,163 - INFO  - Training [0][   80/  391]   Loss 1.063736   Top1 72.304688   Top5 97.500000   BatchTime 0.111008   LR 0.010000   
2022-11-03 22:41:24,159 - INFO  - Training [0][  100/  391]   Loss 0.967177   Top1 73.843750   Top5 97.796875   BatchTime 0.108766   LR 0.010000   
2022-11-03 22:41:26,171 - INFO  - Training [0][  120/  391]   Loss 0.895267   Top1 75.175781   Top5 98.046875   BatchTime 0.107407   LR 0.010000   
2022-11-03 22:41:28,197 - INFO  - Training [0][  140/  391]   Loss 0.835731   Top1 76.439732   Top5 98.253348   BatchTime 0.106534   LR 0.010000   
2022-11-03 22:41:30,186 - INFO  - Training [0][  160/  391]   Loss 0.793395   Top1 77.172852   Top5 98.413086   BatchTime 0.105648   LR 0.010000   
2022-11-03 22:41:32,198 - INFO  - Training [0][  180/  391]   Loss 0.755950   Top1 77.929688   Top5 98.519965   BatchTime 0.105087   LR 0.010000   
2022-11-03 22:41:34,199 - INFO  - Training [0][  200/  391]   Loss 0.728185   Top1 78.460938   Top5 98.582031   BatchTime 0.104581   LR 0.010000   
2022-11-03 22:41:36,179 - INFO  - Training [0][  220/  391]   Loss 0.702529   Top1 78.991477   Top5 98.647017   BatchTime 0.104076   LR 0.010000   
2022-11-03 22:41:38,173 - INFO  - Training [0][  240/  391]   Loss 0.680059   Top1 79.466146   Top5 98.723958   BatchTime 0.103711   LR 0.010000   
2022-11-03 22:41:40,150 - INFO  - Training [0][  260/  391]   Loss 0.659342   Top1 79.891827   Top5 98.786058   BatchTime 0.103335   LR 0.010000   
2022-11-03 22:41:42,162 - INFO  - Training [0][  280/  391]   Loss 0.642410   Top1 80.228795   Top5 98.844866   BatchTime 0.103141   LR 0.010000   
2022-11-03 22:41:44,160 - INFO  - Training [0][  300/  391]   Loss 0.625705   Top1 80.609375   Top5 98.882812   BatchTime 0.102925   LR 0.010000   
2022-11-03 22:41:46,153 - INFO  - Training [0][  320/  391]   Loss 0.611002   Top1 80.983887   Top5 98.928223   BatchTime 0.102720   LR 0.010000   
2022-11-03 22:41:48,123 - INFO  - Training [0][  340/  391]   Loss 0.596504   Top1 81.353401   Top5 98.982077   BatchTime 0.102470   LR 0.010000   
2022-11-03 22:41:50,096 - INFO  - Training [0][  360/  391]   Loss 0.583108   Top1 81.703559   Top5 99.029948   BatchTime 0.102258   LR 0.010000   
2022-11-03 22:41:52,141 - INFO  - Training [0][  380/  391]   Loss 0.572872   Top1 81.990132   Top5 99.060444   BatchTime 0.102259   LR 0.010000   
2022-11-03 22:41:53,800 - INFO  - ==> Top1: 82.194    Top5: 99.072    Loss: 0.567

2022-11-03 22:41:53,801 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:41:56,500 - INFO  - Validation [0][   20/   79]   Loss 0.459141   Top1 84.726562   Top5 99.492188   BatchTime 0.134865   
2022-11-03 22:41:57,375 - INFO  - Validation [0][   40/   79]   Loss 0.462543   Top1 84.550781   Top5 99.296875   BatchTime 0.089300   
2022-11-03 22:41:58,236 - INFO  - Validation [0][   60/   79]   Loss 0.462555   Top1 84.570312   Top5 99.322917   BatchTime 0.073885   
2022-11-03 22:41:59,281 - INFO  - ==> Top1: 84.700    Top5: 99.340    Loss: 0.461

2022-11-03 22:41:59,308 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.700   Top5: 99.340] Sparsity : 0.583
2022-11-03 22:41:59,308 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 22:41:59,370 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:41:59,370 - INFO  - >>>>>>>> Epoch   1
2022-11-03 22:41:59,371 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:42:03,122 - INFO  - Training [1][   20/  391]   Loss 0.315590   Top1 89.648438   Top5 99.687500   BatchTime 0.187532   LR 0.010000   
2022-11-03 22:42:04,764 - INFO  - Training [1][   40/  391]   Loss 0.303323   Top1 89.492188   Top5 99.726562   BatchTime 0.134820   LR 0.010000   
2022-11-03 22:42:06,481 - INFO  - Training [1][   60/  391]   Loss 0.305401   Top1 89.296875   Top5 99.765625   BatchTime 0.118494   LR 0.010000   
2022-11-03 22:42:08,377 - INFO  - Training [1][   80/  391]   Loss 0.307119   Top1 89.121094   Top5 99.785156   BatchTime 0.112569   LR 0.010000   
2022-11-03 22:42:10,383 - INFO  - Training [1][  100/  391]   Loss 0.304841   Top1 89.257812   Top5 99.765625   BatchTime 0.110118   LR 0.010000   
2022-11-03 22:42:12,403 - INFO  - Training [1][  120/  391]   Loss 0.306545   Top1 89.140625   Top5 99.778646   BatchTime 0.108596   LR 0.010000   
2022-11-03 22:42:14,415 - INFO  - Training [1][  140/  391]   Loss 0.303724   Top1 89.308036   Top5 99.782366   BatchTime 0.107453   LR 0.010000   
2022-11-03 22:42:16,421 - INFO  - Training [1][  160/  391]   Loss 0.302247   Top1 89.384766   Top5 99.780273   BatchTime 0.106557   LR 0.010000   
2022-11-03 22:42:18,429 - INFO  - Training [1][  180/  391]   Loss 0.300172   Top1 89.509549   Top5 99.778646   BatchTime 0.105874   LR 0.010000   
2022-11-03 22:42:20,421 - INFO  - Training [1][  200/  391]   Loss 0.299101   Top1 89.515625   Top5 99.781250   BatchTime 0.105249   LR 0.010000   
2022-11-03 22:42:22,433 - INFO  - Training [1][  220/  391]   Loss 0.298481   Top1 89.573864   Top5 99.776278   BatchTime 0.104825   LR 0.010000   
2022-11-03 22:42:24,447 - INFO  - Training [1][  240/  391]   Loss 0.296241   Top1 89.638672   Top5 99.781901   BatchTime 0.104481   LR 0.010000   
2022-11-03 22:42:26,460 - INFO  - Training [1][  260/  391]   Loss 0.293476   Top1 89.717548   Top5 99.795673   BatchTime 0.104186   LR 0.010000   
2022-11-03 22:42:28,489 - INFO  - Training [1][  280/  391]   Loss 0.290806   Top1 89.799107   Top5 99.807478   BatchTime 0.103989   LR 0.010000   
2022-11-03 22:42:30,493 - INFO  - Training [1][  300/  391]   Loss 0.288208   Top1 89.872396   Top5 99.817708   BatchTime 0.103737   LR 0.010000   
2022-11-03 22:42:32,496 - INFO  - Training [1][  320/  391]   Loss 0.285974   Top1 89.943848   Top5 99.819336   BatchTime 0.103514   LR 0.010000   
2022-11-03 22:42:34,498 - INFO  - Training [1][  340/  391]   Loss 0.284711   Top1 89.986213   Top5 99.818474   BatchTime 0.103313   LR 0.010000   
2022-11-03 22:42:36,492 - INFO  - Training [1][  360/  391]   Loss 0.283211   Top1 90.028212   Top5 99.817708   BatchTime 0.103112   LR 0.010000   
2022-11-03 22:42:38,473 - INFO  - Training [1][  380/  391]   Loss 0.281186   Top1 90.102796   Top5 99.821135   BatchTime 0.102897   LR 0.010000   
2022-11-03 22:42:39,808 - INFO  - ==> Top1: 90.150    Top5: 99.824    Loss: 0.279

2022-11-03 22:42:39,809 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:42:42,517 - INFO  - Validation [1][   20/   79]   Loss 0.415566   Top1 86.718750   Top5 99.375000   BatchTime 0.135358   
2022-11-03 22:42:43,405 - INFO  - Validation [1][   40/   79]   Loss 0.424437   Top1 86.816406   Top5 99.238281   BatchTime 0.089866   
2022-11-03 22:42:44,310 - INFO  - Validation [1][   60/   79]   Loss 0.413669   Top1 86.927083   Top5 99.335938   BatchTime 0.074994   
2022-11-03 22:42:45,584 - INFO  - ==> Top1: 86.970    Top5: 99.380    Loss: 0.411

2022-11-03 22:42:45,614 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.970   Top5: 99.380] Sparsity : 0.598
2022-11-03 22:42:45,614 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.700   Top5: 99.340] Sparsity : 0.583
2022-11-03 22:42:45,614 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 22:42:45,799 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:42:45,799 - INFO  - >>>>>>>> Epoch   2
2022-11-03 22:42:45,801 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:42:49,445 - INFO  - Training [2][   20/  391]   Loss 0.213478   Top1 92.421875   Top5 99.882812   BatchTime 0.182226   LR 0.010000   
2022-11-03 22:42:51,196 - INFO  - Training [2][   40/  391]   Loss 0.220315   Top1 92.226562   Top5 99.863281   BatchTime 0.134879   LR 0.010000   
2022-11-03 22:42:52,738 - INFO  - Training [2][   60/  391]   Loss 0.220134   Top1 92.395833   Top5 99.830729   BatchTime 0.115614   LR 0.010000   
2022-11-03 22:42:54,724 - INFO  - Training [2][   80/  391]   Loss 0.217245   Top1 92.548828   Top5 99.843750   BatchTime 0.111536   LR 0.010000   
2022-11-03 22:42:56,728 - INFO  - Training [2][  100/  391]   Loss 0.216710   Top1 92.406250   Top5 99.859375   BatchTime 0.109273   LR 0.010000   
2022-11-03 22:42:58,759 - INFO  - Training [2][  120/  391]   Loss 0.215778   Top1 92.434896   Top5 99.863281   BatchTime 0.107980   LR 0.010000   
2022-11-03 22:43:00,765 - INFO  - Training [2][  140/  391]   Loss 0.216296   Top1 92.410714   Top5 99.860491   BatchTime 0.106883   LR 0.010000   
2022-11-03 22:43:02,752 - INFO  - Training [2][  160/  391]   Loss 0.216043   Top1 92.373047   Top5 99.858398   BatchTime 0.105945   LR 0.010000   
2022-11-03 22:43:04,761 - INFO  - Training [2][  180/  391]   Loss 0.215768   Top1 92.417535   Top5 99.869792   BatchTime 0.105334   LR 0.010000   
2022-11-03 22:43:06,768 - INFO  - Training [2][  200/  391]   Loss 0.213565   Top1 92.457031   Top5 99.875000   BatchTime 0.104832   LR 0.010000   
2022-11-03 22:43:08,764 - INFO  - Training [2][  220/  391]   Loss 0.212761   Top1 92.457386   Top5 99.879261   BatchTime 0.104378   LR 0.010000   
2022-11-03 22:43:10,780 - INFO  - Training [2][  240/  391]   Loss 0.211550   Top1 92.513021   Top5 99.889323   BatchTime 0.104077   LR 0.010000   
2022-11-03 22:43:12,793 - INFO  - Training [2][  260/  391]   Loss 0.210714   Top1 92.551082   Top5 99.888822   BatchTime 0.103815   LR 0.010000   
2022-11-03 22:43:14,809 - INFO  - Training [2][  280/  391]   Loss 0.209549   Top1 92.586496   Top5 99.893973   BatchTime 0.103597   LR 0.010000   
2022-11-03 22:43:16,821 - INFO  - Training [2][  300/  391]   Loss 0.209536   Top1 92.606771   Top5 99.893229   BatchTime 0.103398   LR 0.010000   
2022-11-03 22:43:18,833 - INFO  - Training [2][  320/  391]   Loss 0.207676   Top1 92.663574   Top5 99.897461   BatchTime 0.103224   LR 0.010000   
2022-11-03 22:43:20,830 - INFO  - Training [2][  340/  391]   Loss 0.207935   Top1 92.637868   Top5 99.894301   BatchTime 0.103025   LR 0.010000   
2022-11-03 22:43:22,816 - INFO  - Training [2][  360/  391]   Loss 0.207509   Top1 92.673611   Top5 99.893663   BatchTime 0.102817   LR 0.010000   
2022-11-03 22:43:24,797 - INFO  - Training [2][  380/  391]   Loss 0.206658   Top1 92.693257   Top5 99.895148   BatchTime 0.102619   LR 0.010000   
2022-11-03 22:43:26,239 - INFO  - ==> Top1: 92.694    Top5: 99.898    Loss: 0.206

2022-11-03 22:43:26,240 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:43:28,977 - INFO  - Validation [2][   20/   79]   Loss 0.397613   Top1 88.046875   Top5 99.453125   BatchTime 0.136748   
2022-11-03 22:43:29,898 - INFO  - Validation [2][   40/   79]   Loss 0.401425   Top1 87.714844   Top5 99.414062   BatchTime 0.091396   
2022-11-03 22:43:30,795 - INFO  - Validation [2][   60/   79]   Loss 0.401567   Top1 87.565104   Top5 99.427083   BatchTime 0.075890   
2022-11-03 22:43:31,787 - INFO  - ==> Top1: 87.550    Top5: 99.500    Loss: 0.399

2022-11-03 22:43:31,814 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.550   Top5: 99.500] Sparsity : 0.632
2022-11-03 22:43:31,814 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.970   Top5: 99.380] Sparsity : 0.598
2022-11-03 22:43:31,815 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 84.700   Top5: 99.340] Sparsity : 0.583
2022-11-03 22:43:32,001 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:43:32,002 - INFO  - >>>>>>>> Epoch   3
2022-11-03 22:43:32,003 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:43:35,656 - INFO  - Training [3][   20/  391]   Loss 0.169069   Top1 94.257812   Top5 99.921875   BatchTime 0.182643   LR 0.010000   
2022-11-03 22:43:37,365 - INFO  - Training [3][   40/  391]   Loss 0.159748   Top1 94.511719   Top5 99.902344   BatchTime 0.134029   LR 0.010000   
2022-11-03 22:43:38,877 - INFO  - Training [3][   60/  391]   Loss 0.158203   Top1 94.479167   Top5 99.921875   BatchTime 0.114553   LR 0.010000   
2022-11-03 22:43:40,977 - INFO  - Training [3][   80/  391]   Loss 0.162676   Top1 94.355469   Top5 99.892578   BatchTime 0.112172   LR 0.010000   
2022-11-03 22:43:42,991 - INFO  - Training [3][  100/  391]   Loss 0.167317   Top1 94.171875   Top5 99.914062   BatchTime 0.109872   LR 0.010000   
2022-11-03 22:43:45,004 - INFO  - Training [3][  120/  391]   Loss 0.168315   Top1 94.199219   Top5 99.928385   BatchTime 0.108338   LR 0.010000   
2022-11-03 22:43:47,006 - INFO  - Training [3][  140/  391]   Loss 0.169777   Top1 94.068080   Top5 99.933036   BatchTime 0.107160   LR 0.010000   
2022-11-03 22:43:49,010 - INFO  - Training [3][  160/  391]   Loss 0.173088   Top1 93.945312   Top5 99.926758   BatchTime 0.106290   LR 0.010000   
2022-11-03 22:43:51,014 - INFO  - Training [3][  180/  391]   Loss 0.175993   Top1 93.776042   Top5 99.934896   BatchTime 0.105614   LR 0.010000   
2022-11-03 22:43:53,011 - INFO  - Training [3][  200/  391]   Loss 0.177330   Top1 93.746094   Top5 99.925781   BatchTime 0.105034   LR 0.010000   
2022-11-03 22:43:55,012 - INFO  - Training [3][  220/  391]   Loss 0.178653   Top1 93.686080   Top5 99.928977   BatchTime 0.104581   LR 0.010000   
2022-11-03 22:43:56,999 - INFO  - Training [3][  240/  391]   Loss 0.178374   Top1 93.688151   Top5 99.931641   BatchTime 0.104146   LR 0.010000   
2022-11-03 22:43:59,004 - INFO  - Training [3][  260/  391]   Loss 0.180309   Top1 93.644832   Top5 99.930889   BatchTime 0.103846   LR 0.010000   
2022-11-03 22:44:01,021 - INFO  - Training [3][  280/  391]   Loss 0.181786   Top1 93.627232   Top5 99.930246   BatchTime 0.103633   LR 0.010000   
2022-11-03 22:44:03,009 - INFO  - Training [3][  300/  391]   Loss 0.181218   Top1 93.606771   Top5 99.932292   BatchTime 0.103350   LR 0.010000   
2022-11-03 22:44:05,017 - INFO  - Training [3][  320/  391]   Loss 0.181891   Top1 93.586426   Top5 99.936523   BatchTime 0.103165   LR 0.010000   
2022-11-03 22:44:06,988 - INFO  - Training [3][  340/  391]   Loss 0.181894   Top1 93.598346   Top5 99.940257   BatchTime 0.102893   LR 0.010000   
2022-11-03 22:44:08,960 - INFO  - Training [3][  360/  391]   Loss 0.182129   Top1 93.576389   Top5 99.939236   BatchTime 0.102654   LR 0.010000   
2022-11-03 22:44:10,940 - INFO  - Training [3][  380/  391]   Loss 0.181464   Top1 93.606086   Top5 99.938322   BatchTime 0.102462   LR 0.010000   
2022-11-03 22:44:12,274 - INFO  - ==> Top1: 93.604    Top5: 99.940    Loss: 0.182

2022-11-03 22:44:12,275 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:44:14,971 - INFO  - Validation [3][   20/   79]   Loss 0.425066   Top1 87.031250   Top5 99.375000   BatchTime 0.134702   
2022-11-03 22:44:15,868 - INFO  - Validation [3][   40/   79]   Loss 0.418398   Top1 87.460938   Top5 99.335938   BatchTime 0.089786   
2022-11-03 22:44:16,790 - INFO  - Validation [3][   60/   79]   Loss 0.410996   Top1 87.656250   Top5 99.401042   BatchTime 0.075227   
2022-11-03 22:44:17,623 - INFO  - ==> Top1: 87.780    Top5: 99.470    Loss: 0.410

2022-11-03 22:44:17,646 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 87.780   Top5: 99.470] Sparsity : 0.699
2022-11-03 22:44:17,647 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.550   Top5: 99.500] Sparsity : 0.632
2022-11-03 22:44:17,647 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.970   Top5: 99.380] Sparsity : 0.598
2022-11-03 22:44:17,828 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:44:17,828 - INFO  - >>>>>>>> Epoch   4
2022-11-03 22:44:17,829 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:44:21,469 - INFO  - Training [4][   20/  391]   Loss 0.173109   Top1 93.554688   Top5 100.000000   BatchTime 0.181951   LR 0.010000   
2022-11-03 22:44:23,146 - INFO  - Training [4][   40/  391]   Loss 0.180926   Top1 93.261719   Top5 100.000000   BatchTime 0.132913   LR 0.010000   
2022-11-03 22:44:24,811 - INFO  - Training [4][   60/  391]   Loss 0.178997   Top1 93.463542   Top5 99.986979   BatchTime 0.116349   LR 0.010000   
2022-11-03 22:44:26,854 - INFO  - Training [4][   80/  391]   Loss 0.174921   Top1 93.710938   Top5 99.980469   BatchTime 0.112799   LR 0.010000   
2022-11-03 22:44:28,864 - INFO  - Training [4][  100/  391]   Loss 0.174991   Top1 93.718750   Top5 99.984375   BatchTime 0.110343   LR 0.010000   
2022-11-03 22:44:30,869 - INFO  - Training [4][  120/  391]   Loss 0.174255   Top1 93.828125   Top5 99.980469   BatchTime 0.108662   LR 0.010000   
2022-11-03 22:44:32,866 - INFO  - Training [4][  140/  391]   Loss 0.176024   Top1 93.828125   Top5 99.977679   BatchTime 0.107400   LR 0.010000   
2022-11-03 22:44:34,872 - INFO  - Training [4][  160/  391]   Loss 0.174626   Top1 93.862305   Top5 99.965820   BatchTime 0.106514   LR 0.010000   
2022-11-03 22:44:36,871 - INFO  - Training [4][  180/  391]   Loss 0.176987   Top1 93.793403   Top5 99.960938   BatchTime 0.105781   LR 0.010000   
2022-11-03 22:44:38,873 - INFO  - Training [4][  200/  391]   Loss 0.176601   Top1 93.808594   Top5 99.957031   BatchTime 0.105215   LR 0.010000   
2022-11-03 22:44:40,896 - INFO  - Training [4][  220/  391]   Loss 0.176583   Top1 93.813920   Top5 99.957386   BatchTime 0.104845   LR 0.010000   
2022-11-03 22:44:42,904 - INFO  - Training [4][  240/  391]   Loss 0.175575   Top1 93.831380   Top5 99.954427   BatchTime 0.104474   LR 0.010000   
2022-11-03 22:44:44,906 - INFO  - Training [4][  260/  391]   Loss 0.176262   Top1 93.828125   Top5 99.948918   BatchTime 0.104138   LR 0.010000   
2022-11-03 22:44:46,904 - INFO  - Training [4][  280/  391]   Loss 0.176210   Top1 93.842076   Top5 99.946987   BatchTime 0.103834   LR 0.010000   
2022-11-03 22:44:48,914 - INFO  - Training [4][  300/  391]   Loss 0.175742   Top1 93.851562   Top5 99.950521   BatchTime 0.103614   LR 0.010000   
2022-11-03 22:44:50,915 - INFO  - Training [4][  320/  391]   Loss 0.174664   Top1 93.891602   Top5 99.953613   BatchTime 0.103389   LR 0.010000   
2022-11-03 22:44:52,896 - INFO  - Training [4][  340/  391]   Loss 0.173572   Top1 93.913143   Top5 99.956342   BatchTime 0.103133   LR 0.010000   
2022-11-03 22:44:54,873 - INFO  - Training [4][  360/  391]   Loss 0.173217   Top1 93.951823   Top5 99.952257   BatchTime 0.102897   LR 0.010000   
2022-11-03 22:44:56,851 - INFO  - Training [4][  380/  391]   Loss 0.172971   Top1 93.951480   Top5 99.954770   BatchTime 0.102685   LR 0.010000   
2022-11-03 22:44:58,172 - INFO  - ==> Top1: 93.954    Top5: 99.956    Loss: 0.173

2022-11-03 22:44:58,173 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:45:00,851 - INFO  - Validation [4][   20/   79]   Loss 0.391053   Top1 88.828125   Top5 99.375000   BatchTime 0.133795   
2022-11-03 22:45:01,773 - INFO  - Validation [4][   40/   79]   Loss 0.394229   Top1 88.671875   Top5 99.453125   BatchTime 0.089959   
2022-11-03 22:45:02,657 - INFO  - Validation [4][   60/   79]   Loss 0.384645   Top1 88.802083   Top5 99.479167   BatchTime 0.074703   
2022-11-03 22:45:03,499 - INFO  - ==> Top1: 88.720    Top5: 99.540    Loss: 0.380

2022-11-03 22:45:03,523 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.720   Top5: 99.540] Sparsity : 0.723
2022-11-03 22:45:03,524 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 87.780   Top5: 99.470] Sparsity : 0.699
2022-11-03 22:45:03,524 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.550   Top5: 99.500] Sparsity : 0.632
2022-11-03 22:45:03,687 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:45:03,687 - INFO  - >>>>>>>> Epoch   5
2022-11-03 22:45:03,688 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:45:07,399 - INFO  - Training [5][   20/  391]   Loss 0.149415   Top1 94.218750   Top5 99.960938   BatchTime 0.185554   LR 0.010000   
2022-11-03 22:45:09,058 - INFO  - Training [5][   40/  391]   Loss 0.148360   Top1 94.296875   Top5 99.960938   BatchTime 0.134255   LR 0.010000   
2022-11-03 22:45:10,857 - INFO  - Training [5][   60/  391]   Loss 0.152590   Top1 94.309896   Top5 99.973958   BatchTime 0.119482   LR 0.010000   
2022-11-03 22:45:12,857 - INFO  - Training [5][   80/  391]   Loss 0.148535   Top1 94.638672   Top5 99.960938   BatchTime 0.114611   LR 0.010000   
2022-11-03 22:45:14,868 - INFO  - Training [5][  100/  391]   Loss 0.150387   Top1 94.648438   Top5 99.945312   BatchTime 0.111802   LR 0.010000   
2022-11-03 22:45:16,870 - INFO  - Training [5][  120/  391]   Loss 0.152389   Top1 94.622396   Top5 99.941406   BatchTime 0.109849   LR 0.010000   
2022-11-03 22:45:18,879 - INFO  - Training [5][  140/  391]   Loss 0.152377   Top1 94.626116   Top5 99.949777   BatchTime 0.108503   LR 0.010000   
2022-11-03 22:45:20,876 - INFO  - Training [5][  160/  391]   Loss 0.153960   Top1 94.550781   Top5 99.946289   BatchTime 0.107423   LR 0.010000   
2022-11-03 22:45:22,910 - INFO  - Training [5][  180/  391]   Loss 0.155781   Top1 94.474826   Top5 99.947917   BatchTime 0.106785   LR 0.010000   
2022-11-03 22:45:24,911 - INFO  - Training [5][  200/  391]   Loss 0.157766   Top1 94.386719   Top5 99.941406   BatchTime 0.106112   LR 0.010000   
2022-11-03 22:45:26,908 - INFO  - Training [5][  220/  391]   Loss 0.160289   Top1 94.350142   Top5 99.932528   BatchTime 0.105545   LR 0.010000   
2022-11-03 22:45:28,918 - INFO  - Training [5][  240/  391]   Loss 0.160168   Top1 94.397786   Top5 99.931641   BatchTime 0.105122   LR 0.010000   
2022-11-03 22:45:30,925 - INFO  - Training [5][  260/  391]   Loss 0.159862   Top1 94.384014   Top5 99.936899   BatchTime 0.104755   LR 0.010000   
2022-11-03 22:45:32,935 - INFO  - Training [5][  280/  391]   Loss 0.159619   Top1 94.397321   Top5 99.938616   BatchTime 0.104453   LR 0.010000   
2022-11-03 22:45:34,949 - INFO  - Training [5][  300/  391]   Loss 0.158827   Top1 94.437500   Top5 99.940104   BatchTime 0.104200   LR 0.010000   
2022-11-03 22:45:36,947 - INFO  - Training [5][  320/  391]   Loss 0.159431   Top1 94.431152   Top5 99.941406   BatchTime 0.103933   LR 0.010000   
2022-11-03 22:45:38,941 - INFO  - Training [5][  340/  391]   Loss 0.160585   Top1 94.411765   Top5 99.924173   BatchTime 0.103684   LR 0.010000   
2022-11-03 22:45:40,936 - INFO  - Training [5][  360/  391]   Loss 0.159879   Top1 94.431424   Top5 99.926215   BatchTime 0.103466   LR 0.010000   
2022-11-03 22:45:42,929 - INFO  - Training [5][  380/  391]   Loss 0.160021   Top1 94.449013   Top5 99.925987   BatchTime 0.103264   LR 0.010000   
2022-11-03 22:45:44,253 - INFO  - ==> Top1: 94.448    Top5: 99.926    Loss: 0.160

2022-11-03 22:45:44,254 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:45:46,964 - INFO  - Validation [5][   20/   79]   Loss 0.401508   Top1 87.890625   Top5 99.335938   BatchTime 0.135436   
2022-11-03 22:45:47,880 - INFO  - Validation [5][   40/   79]   Loss 0.399188   Top1 88.105469   Top5 99.433594   BatchTime 0.090633   
2022-11-03 22:45:48,625 - INFO  - Validation [5][   60/   79]   Loss 0.388269   Top1 88.554688   Top5 99.479167   BatchTime 0.072827   
2022-11-03 22:45:49,424 - INFO  - ==> Top1: 88.440    Top5: 99.510    Loss: 0.389

2022-11-03 22:45:49,451 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.720   Top5: 99.540] Sparsity : 0.723
2022-11-03 22:45:49,451 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.440   Top5: 99.510] Sparsity : 0.741
2022-11-03 22:45:49,451 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 87.780   Top5: 99.470] Sparsity : 0.699
2022-11-03 22:45:49,559 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:45:49,560 - INFO  - >>>>>>>> Epoch   6
2022-11-03 22:45:49,561 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:45:53,136 - INFO  - Training [6][   20/  391]   Loss 0.141190   Top1 95.039062   Top5 99.960938   BatchTime 0.178738   LR 0.010000   
2022-11-03 22:45:54,789 - INFO  - Training [6][   40/  391]   Loss 0.149297   Top1 94.707031   Top5 99.921875   BatchTime 0.130698   LR 0.010000   
2022-11-03 22:45:56,699 - INFO  - Training [6][   60/  391]   Loss 0.148466   Top1 94.791667   Top5 99.947917   BatchTime 0.118953   LR 0.010000   
2022-11-03 22:45:58,684 - INFO  - Training [6][   80/  391]   Loss 0.147685   Top1 94.873047   Top5 99.951172   BatchTime 0.114029   LR 0.010000   
2022-11-03 22:46:00,681 - INFO  - Training [6][  100/  391]   Loss 0.148722   Top1 94.796875   Top5 99.953125   BatchTime 0.111196   LR 0.010000   
2022-11-03 22:46:02,681 - INFO  - Training [6][  120/  391]   Loss 0.147669   Top1 94.791667   Top5 99.960938   BatchTime 0.109328   LR 0.010000   
2022-11-03 22:46:04,668 - INFO  - Training [6][  140/  391]   Loss 0.146958   Top1 94.832589   Top5 99.960938   BatchTime 0.107901   LR 0.010000   
2022-11-03 22:46:06,674 - INFO  - Training [6][  160/  391]   Loss 0.142912   Top1 94.980469   Top5 99.965820   BatchTime 0.106952   LR 0.010000   
2022-11-03 22:46:08,684 - INFO  - Training [6][  180/  391]   Loss 0.143398   Top1 94.978299   Top5 99.969618   BatchTime 0.106232   LR 0.010000   
2022-11-03 22:46:10,696 - INFO  - Training [6][  200/  391]   Loss 0.143651   Top1 94.992188   Top5 99.957031   BatchTime 0.105670   LR 0.010000   
2022-11-03 22:46:12,700 - INFO  - Training [6][  220/  391]   Loss 0.142124   Top1 95.021307   Top5 99.960938   BatchTime 0.105174   LR 0.010000   
2022-11-03 22:46:14,711 - INFO  - Training [6][  240/  391]   Loss 0.142224   Top1 95.026042   Top5 99.954427   BatchTime 0.104786   LR 0.010000   
2022-11-03 22:46:16,715 - INFO  - Training [6][  260/  391]   Loss 0.141520   Top1 95.033053   Top5 99.957933   BatchTime 0.104433   LR 0.010000   
2022-11-03 22:46:18,737 - INFO  - Training [6][  280/  391]   Loss 0.141234   Top1 95.061384   Top5 99.958147   BatchTime 0.104197   LR 0.010000   
2022-11-03 22:46:20,746 - INFO  - Training [6][  300/  391]   Loss 0.141458   Top1 95.062500   Top5 99.953125   BatchTime 0.103947   LR 0.010000   
2022-11-03 22:46:22,735 - INFO  - Training [6][  320/  391]   Loss 0.141715   Top1 95.070801   Top5 99.956055   BatchTime 0.103665   LR 0.010000   
2022-11-03 22:46:24,739 - INFO  - Training [6][  340/  391]   Loss 0.142948   Top1 95.027574   Top5 99.956342   BatchTime 0.103461   LR 0.010000   
2022-11-03 22:46:26,721 - INFO  - Training [6][  360/  391]   Loss 0.142709   Top1 95.045573   Top5 99.958767   BatchTime 0.103218   LR 0.010000   
2022-11-03 22:46:28,694 - INFO  - Training [6][  380/  391]   Loss 0.143144   Top1 95.018503   Top5 99.958882   BatchTime 0.102979   LR 0.010000   
2022-11-03 22:46:30,003 - INFO  - ==> Top1: 95.016    Top5: 99.956    Loss: 0.143

2022-11-03 22:46:30,004 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:46:32,706 - INFO  - Validation [6][   20/   79]   Loss 0.422120   Top1 88.085938   Top5 99.335938   BatchTime 0.135046   
2022-11-03 22:46:33,623 - INFO  - Validation [6][   40/   79]   Loss 0.412326   Top1 88.339844   Top5 99.335938   BatchTime 0.090430   
2022-11-03 22:46:34,314 - INFO  - Validation [6][   60/   79]   Loss 0.400099   Top1 88.632812   Top5 99.453125   BatchTime 0.071805   
2022-11-03 22:46:35,088 - INFO  - ==> Top1: 88.780    Top5: 99.520    Loss: 0.393

2022-11-03 22:46:35,115 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 88.780   Top5: 99.520] Sparsity : 0.745
2022-11-03 22:46:35,116 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.720   Top5: 99.540] Sparsity : 0.723
2022-11-03 22:46:35,116 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.440   Top5: 99.510] Sparsity : 0.741
2022-11-03 22:46:35,311 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:46:35,312 - INFO  - >>>>>>>> Epoch   7
2022-11-03 22:46:35,312 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:46:38,971 - INFO  - Training [7][   20/  391]   Loss 0.115545   Top1 96.171875   Top5 99.960938   BatchTime 0.182933   LR 0.010000   
2022-11-03 22:46:40,447 - INFO  - Training [7][   40/  391]   Loss 0.123767   Top1 95.703125   Top5 99.980469   BatchTime 0.128363   LR 0.010000   
2022-11-03 22:46:42,453 - INFO  - Training [7][   60/  391]   Loss 0.127144   Top1 95.677083   Top5 99.973958   BatchTime 0.118998   LR 0.010000   
2022-11-03 22:46:44,603 - INFO  - Training [7][   80/  391]   Loss 0.126813   Top1 95.664062   Top5 99.970703   BatchTime 0.116130   LR 0.010000   
2022-11-03 22:46:46,610 - INFO  - Training [7][  100/  391]   Loss 0.125345   Top1 95.726562   Top5 99.968750   BatchTime 0.112978   LR 0.010000   
2022-11-03 22:46:48,569 - INFO  - Training [7][  120/  391]   Loss 0.127929   Top1 95.605469   Top5 99.973958   BatchTime 0.110467   LR 0.010000   
2022-11-03 22:46:50,572 - INFO  - Training [7][  140/  391]   Loss 0.128117   Top1 95.636161   Top5 99.972098   BatchTime 0.108998   LR 0.010000   
2022-11-03 22:46:52,595 - INFO  - Training [7][  160/  391]   Loss 0.126261   Top1 95.673828   Top5 99.970703   BatchTime 0.108013   LR 0.010000   
2022-11-03 22:46:54,605 - INFO  - Training [7][  180/  391]   Loss 0.126174   Top1 95.668403   Top5 99.969618   BatchTime 0.107178   LR 0.010000   
2022-11-03 22:46:56,625 - INFO  - Training [7][  200/  391]   Loss 0.127438   Top1 95.566406   Top5 99.968750   BatchTime 0.106558   LR 0.010000   
2022-11-03 22:46:58,632 - INFO  - Training [7][  220/  391]   Loss 0.128020   Top1 95.522017   Top5 99.968040   BatchTime 0.105995   LR 0.010000   
2022-11-03 22:47:00,644 - INFO  - Training [7][  240/  391]   Loss 0.128704   Top1 95.475260   Top5 99.970703   BatchTime 0.105544   LR 0.010000   
2022-11-03 22:47:02,647 - INFO  - Training [7][  260/  391]   Loss 0.128228   Top1 95.477764   Top5 99.969952   BatchTime 0.105129   LR 0.010000   
2022-11-03 22:47:04,651 - INFO  - Training [7][  280/  391]   Loss 0.129293   Top1 95.438058   Top5 99.972098   BatchTime 0.104778   LR 0.010000   
2022-11-03 22:47:06,637 - INFO  - Training [7][  300/  391]   Loss 0.129915   Top1 95.403646   Top5 99.971354   BatchTime 0.104412   LR 0.010000   
2022-11-03 22:47:08,657 - INFO  - Training [7][  320/  391]   Loss 0.129963   Top1 95.373535   Top5 99.968262   BatchTime 0.104198   LR 0.010000   
2022-11-03 22:47:10,646 - INFO  - Training [7][  340/  391]   Loss 0.129628   Top1 95.374540   Top5 99.963235   BatchTime 0.103920   LR 0.010000   
2022-11-03 22:47:12,625 - INFO  - Training [7][  360/  391]   Loss 0.128270   Top1 95.425347   Top5 99.965278   BatchTime 0.103643   LR 0.010000   
2022-11-03 22:47:14,582 - INFO  - Training [7][  380/  391]   Loss 0.127909   Top1 95.450247   Top5 99.965049   BatchTime 0.103338   LR 0.010000   
2022-11-03 22:47:15,922 - INFO  - ==> Top1: 95.456    Top5: 99.964    Loss: 0.128

2022-11-03 22:47:15,923 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:47:18,658 - INFO  - Validation [7][   20/   79]   Loss 0.403608   Top1 88.789062   Top5 99.453125   BatchTime 0.136642   
2022-11-03 22:47:19,458 - INFO  - Validation [7][   40/   79]   Loss 0.397907   Top1 88.750000   Top5 99.414062   BatchTime 0.088314   
2022-11-03 22:47:19,986 - INFO  - Validation [7][   60/   79]   Loss 0.383094   Top1 88.984375   Top5 99.492188   BatchTime 0.067668   
2022-11-03 22:47:20,731 - INFO  - ==> Top1: 89.030    Top5: 99.530    Loss: 0.380

2022-11-03 22:47:20,756 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:47:20,757 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 88.780   Top5: 99.520] Sparsity : 0.745
2022-11-03 22:47:20,757 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.720   Top5: 99.540] Sparsity : 0.723
2022-11-03 22:47:20,952 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:47:20,953 - INFO  - >>>>>>>> Epoch   8
2022-11-03 22:47:20,954 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:47:24,650 - INFO  - Training [8][   20/  391]   Loss 0.104216   Top1 96.406250   Top5 99.960938   BatchTime 0.184761   LR 0.010000   
2022-11-03 22:47:26,298 - INFO  - Training [8][   40/  391]   Loss 0.106857   Top1 96.308594   Top5 99.980469   BatchTime 0.133592   LR 0.010000   
2022-11-03 22:47:28,331 - INFO  - Training [8][   60/  391]   Loss 0.109216   Top1 96.158854   Top5 99.986979   BatchTime 0.122946   LR 0.010000   
2022-11-03 22:47:30,331 - INFO  - Training [8][   80/  391]   Loss 0.108096   Top1 96.201172   Top5 99.980469   BatchTime 0.117200   LR 0.010000   
2022-11-03 22:47:32,347 - INFO  - Training [8][  100/  391]   Loss 0.109604   Top1 96.125000   Top5 99.984375   BatchTime 0.113919   LR 0.010000   
2022-11-03 22:47:34,332 - INFO  - Training [8][  120/  391]   Loss 0.111796   Top1 96.015625   Top5 99.986979   BatchTime 0.111479   LR 0.010000   
2022-11-03 22:47:36,345 - INFO  - Training [8][  140/  391]   Loss 0.111400   Top1 96.043527   Top5 99.983259   BatchTime 0.109934   LR 0.010000   
2022-11-03 22:47:38,364 - INFO  - Training [8][  160/  391]   Loss 0.112738   Top1 95.986328   Top5 99.975586   BatchTime 0.108810   LR 0.010000   
2022-11-03 22:47:40,391 - INFO  - Training [8][  180/  391]   Loss 0.111224   Top1 96.041667   Top5 99.978299   BatchTime 0.107977   LR 0.010000   
2022-11-03 22:47:42,387 - INFO  - Training [8][  200/  391]   Loss 0.110397   Top1 96.058594   Top5 99.972656   BatchTime 0.107158   LR 0.010000   
2022-11-03 22:47:44,385 - INFO  - Training [8][  220/  391]   Loss 0.111431   Top1 96.036932   Top5 99.975142   BatchTime 0.106500   LR 0.010000   
2022-11-03 22:47:46,379 - INFO  - Training [8][  240/  391]   Loss 0.111389   Top1 96.005859   Top5 99.977214   BatchTime 0.105934   LR 0.010000   
2022-11-03 22:47:48,373 - INFO  - Training [8][  260/  391]   Loss 0.111937   Top1 95.988582   Top5 99.978966   BatchTime 0.105452   LR 0.010000   
2022-11-03 22:47:50,384 - INFO  - Training [8][  280/  391]   Loss 0.112279   Top1 95.987723   Top5 99.980469   BatchTime 0.105102   LR 0.010000   
2022-11-03 22:47:52,398 - INFO  - Training [8][  300/  391]   Loss 0.112445   Top1 96.007812   Top5 99.981771   BatchTime 0.104808   LR 0.010000   
2022-11-03 22:47:54,394 - INFO  - Training [8][  320/  391]   Loss 0.113855   Top1 95.937500   Top5 99.980469   BatchTime 0.104496   LR 0.010000   
2022-11-03 22:47:56,379 - INFO  - Training [8][  340/  391]   Loss 0.113758   Top1 95.923713   Top5 99.981618   BatchTime 0.104187   LR 0.010000   
2022-11-03 22:47:58,352 - INFO  - Training [8][  360/  391]   Loss 0.115237   Top1 95.863715   Top5 99.980469   BatchTime 0.103881   LR 0.010000   
2022-11-03 22:48:00,320 - INFO  - Training [8][  380/  391]   Loss 0.115399   Top1 95.877878   Top5 99.979441   BatchTime 0.103592   LR 0.010000   
2022-11-03 22:48:01,646 - INFO  - ==> Top1: 95.888    Top5: 99.980    Loss: 0.115

2022-11-03 22:48:01,647 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:48:04,357 - INFO  - Validation [8][   20/   79]   Loss 0.385858   Top1 88.867188   Top5 99.492188   BatchTime 0.135473   
2022-11-03 22:48:05,046 - INFO  - Validation [8][   40/   79]   Loss 0.383200   Top1 89.101562   Top5 99.453125   BatchTime 0.084962   
2022-11-03 22:48:05,569 - INFO  - Validation [8][   60/   79]   Loss 0.370806   Top1 89.453125   Top5 99.505208   BatchTime 0.065351   
2022-11-03 22:48:06,325 - INFO  - ==> Top1: 89.430    Top5: 99.550    Loss: 0.374

2022-11-03 22:48:06,348 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:48:06,349 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:48:06,349 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 88.780   Top5: 99.520] Sparsity : 0.745
2022-11-03 22:48:06,546 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:48:06,547 - INFO  - >>>>>>>> Epoch   9
2022-11-03 22:48:06,547 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:48:10,190 - INFO  - Training [9][   20/  391]   Loss 0.101222   Top1 96.171875   Top5 100.000000   BatchTime 0.182143   LR 0.010000   
2022-11-03 22:48:11,812 - INFO  - Training [9][   40/  391]   Loss 0.110611   Top1 96.113281   Top5 100.000000   BatchTime 0.131621   LR 0.010000   
2022-11-03 22:48:13,829 - INFO  - Training [9][   60/  391]   Loss 0.111137   Top1 96.041667   Top5 100.000000   BatchTime 0.121357   LR 0.010000   
2022-11-03 22:48:15,826 - INFO  - Training [9][   80/  391]   Loss 0.113441   Top1 96.054688   Top5 100.000000   BatchTime 0.115983   LR 0.010000   
2022-11-03 22:48:17,845 - INFO  - Training [9][  100/  391]   Loss 0.114384   Top1 96.062500   Top5 99.976562   BatchTime 0.112973   LR 0.010000   
2022-11-03 22:48:19,934 - INFO  - Training [9][  120/  391]   Loss 0.115311   Top1 96.028646   Top5 99.973958   BatchTime 0.111549   LR 0.010000   
2022-11-03 22:48:21,957 - INFO  - Training [9][  140/  391]   Loss 0.114037   Top1 96.021205   Top5 99.977679   BatchTime 0.110063   LR 0.010000   
2022-11-03 22:48:23,969 - INFO  - Training [9][  160/  391]   Loss 0.112553   Top1 96.093750   Top5 99.980469   BatchTime 0.108882   LR 0.010000   
2022-11-03 22:48:26,029 - INFO  - Training [9][  180/  391]   Loss 0.113600   Top1 96.037326   Top5 99.978299   BatchTime 0.108230   LR 0.010000   
2022-11-03 22:48:28,041 - INFO  - Training [9][  200/  391]   Loss 0.112007   Top1 96.093750   Top5 99.980469   BatchTime 0.107468   LR 0.010000   
2022-11-03 22:48:30,060 - INFO  - Training [9][  220/  391]   Loss 0.112366   Top1 96.107955   Top5 99.978693   BatchTime 0.106873   LR 0.010000   
2022-11-03 22:48:32,071 - INFO  - Training [9][  240/  391]   Loss 0.112669   Top1 96.093750   Top5 99.980469   BatchTime 0.106345   LR 0.010000   
2022-11-03 22:48:34,079 - INFO  - Training [9][  260/  391]   Loss 0.114387   Top1 96.009615   Top5 99.981971   BatchTime 0.105888   LR 0.010000   
2022-11-03 22:48:36,117 - INFO  - Training [9][  280/  391]   Loss 0.115851   Top1 95.962612   Top5 99.980469   BatchTime 0.105602   LR 0.010000   
2022-11-03 22:48:38,137 - INFO  - Training [9][  300/  391]   Loss 0.117773   Top1 95.903646   Top5 99.981771   BatchTime 0.105298   LR 0.010000   
2022-11-03 22:48:40,146 - INFO  - Training [9][  320/  391]   Loss 0.119883   Top1 95.808105   Top5 99.980469   BatchTime 0.104993   LR 0.010000   
2022-11-03 22:48:42,144 - INFO  - Training [9][  340/  391]   Loss 0.121425   Top1 95.735294   Top5 99.979320   BatchTime 0.104694   LR 0.010000   
2022-11-03 22:48:44,145 - INFO  - Training [9][  360/  391]   Loss 0.122452   Top1 95.698785   Top5 99.973958   BatchTime 0.104436   LR 0.010000   
2022-11-03 22:48:46,104 - INFO  - Training [9][  380/  391]   Loss 0.124149   Top1 95.649671   Top5 99.973273   BatchTime 0.104094   LR 0.010000   
2022-11-03 22:48:47,428 - INFO  - ==> Top1: 95.606    Top5: 99.974    Loss: 0.125

2022-11-03 22:48:47,429 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:48:50,129 - INFO  - Validation [9][   20/   79]   Loss 0.393650   Top1 88.750000   Top5 99.492188   BatchTime 0.134909   
2022-11-03 22:48:50,738 - INFO  - Validation [9][   40/   79]   Loss 0.401070   Top1 88.261719   Top5 99.414062   BatchTime 0.082680   
2022-11-03 22:48:51,256 - INFO  - Validation [9][   60/   79]   Loss 0.393770   Top1 88.515625   Top5 99.466146   BatchTime 0.063759   
2022-11-03 22:48:52,016 - INFO  - ==> Top1: 88.300    Top5: 99.500    Loss: 0.392

2022-11-03 22:48:52,042 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:48:52,043 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:48:52,043 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 88.780   Top5: 99.520] Sparsity : 0.745
2022-11-03 22:48:52,149 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:48:52,149 - INFO  - >>>>>>>> Epoch  10
2022-11-03 22:48:52,151 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:48:55,757 - INFO  - Training [10][   20/  391]   Loss 0.141013   Top1 95.312500   Top5 99.843750   BatchTime 0.180315   LR 0.010000   
2022-11-03 22:48:57,465 - INFO  - Training [10][   40/  391]   Loss 0.140508   Top1 95.253906   Top5 99.902344   BatchTime 0.132842   LR 0.010000   
2022-11-03 22:48:59,475 - INFO  - Training [10][   60/  391]   Loss 0.136108   Top1 95.442708   Top5 99.908854   BatchTime 0.122075   LR 0.010000   
2022-11-03 22:49:01,487 - INFO  - Training [10][   80/  391]   Loss 0.139598   Top1 95.253906   Top5 99.931641   BatchTime 0.116703   LR 0.010000   
2022-11-03 22:49:03,495 - INFO  - Training [10][  100/  391]   Loss 0.143830   Top1 95.000000   Top5 99.929688   BatchTime 0.113439   LR 0.010000   
2022-11-03 22:49:05,499 - INFO  - Training [10][  120/  391]   Loss 0.148792   Top1 94.811198   Top5 99.941406   BatchTime 0.111231   LR 0.010000   
2022-11-03 22:49:07,505 - INFO  - Training [10][  140/  391]   Loss 0.150913   Top1 94.715402   Top5 99.944196   BatchTime 0.109673   LR 0.010000   
2022-11-03 22:49:09,500 - INFO  - Training [10][  160/  391]   Loss 0.153690   Top1 94.604492   Top5 99.936523   BatchTime 0.108433   LR 0.010000   
2022-11-03 22:49:11,503 - INFO  - Training [10][  180/  391]   Loss 0.153837   Top1 94.631076   Top5 99.930556   BatchTime 0.107509   LR 0.010000   
2022-11-03 22:49:13,513 - INFO  - Training [10][  200/  391]   Loss 0.154602   Top1 94.652344   Top5 99.917969   BatchTime 0.106810   LR 0.010000   
2022-11-03 22:49:15,535 - INFO  - Training [10][  220/  391]   Loss 0.157185   Top1 94.570312   Top5 99.921875   BatchTime 0.106289   LR 0.010000   
2022-11-03 22:49:17,545 - INFO  - Training [10][  240/  391]   Loss 0.159101   Top1 94.508464   Top5 99.925130   BatchTime 0.105808   LR 0.010000   
2022-11-03 22:49:19,553 - INFO  - Training [10][  260/  391]   Loss 0.161701   Top1 94.420072   Top5 99.924880   BatchTime 0.105390   LR 0.010000   
2022-11-03 22:49:21,557 - INFO  - Training [10][  280/  391]   Loss 0.163858   Top1 94.324777   Top5 99.921875   BatchTime 0.105018   LR 0.010000   
2022-11-03 22:49:23,572 - INFO  - Training [10][  300/  391]   Loss 0.164587   Top1 94.286458   Top5 99.927083   BatchTime 0.104735   LR 0.010000   
2022-11-03 22:49:25,589 - INFO  - Training [10][  320/  391]   Loss 0.165429   Top1 94.257812   Top5 99.924316   BatchTime 0.104491   LR 0.010000   
2022-11-03 22:49:27,571 - INFO  - Training [10][  340/  391]   Loss 0.166378   Top1 94.250919   Top5 99.919577   BatchTime 0.104174   LR 0.010000   
2022-11-03 22:49:29,554 - INFO  - Training [10][  360/  391]   Loss 0.166922   Top1 94.203559   Top5 99.924045   BatchTime 0.103895   LR 0.010000   
2022-11-03 22:49:31,506 - INFO  - Training [10][  380/  391]   Loss 0.168703   Top1 94.159128   Top5 99.921875   BatchTime 0.103565   LR 0.010000   
2022-11-03 22:49:32,814 - INFO  - ==> Top1: 94.142    Top5: 99.924    Loss: 0.169

2022-11-03 22:49:32,815 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:49:35,506 - INFO  - Validation [10][   20/   79]   Loss 0.413665   Top1 87.929688   Top5 99.296875   BatchTime 0.134445   
2022-11-03 22:49:36,141 - INFO  - Validation [10][   40/   79]   Loss 0.404842   Top1 88.046875   Top5 99.375000   BatchTime 0.083098   
2022-11-03 22:49:36,662 - INFO  - Validation [10][   60/   79]   Loss 0.397429   Top1 88.125000   Top5 99.440104   BatchTime 0.064079   
2022-11-03 22:49:37,414 - INFO  - ==> Top1: 88.080    Top5: 99.470    Loss: 0.397

2022-11-03 22:49:37,440 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:49:37,441 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:49:37,441 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 88.780   Top5: 99.520] Sparsity : 0.745
2022-11-03 22:49:37,548 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:49:37,549 - INFO  - >>>>>>>> Epoch  11
2022-11-03 22:49:37,551 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:49:41,159 - INFO  - Training [11][   20/  391]   Loss 0.167696   Top1 93.750000   Top5 100.000000   BatchTime 0.180388   LR 0.010000   
2022-11-03 22:49:42,916 - INFO  - Training [11][   40/  391]   Loss 0.167991   Top1 94.062500   Top5 100.000000   BatchTime 0.134133   LR 0.010000   
2022-11-03 22:49:44,952 - INFO  - Training [11][   60/  391]   Loss 0.161673   Top1 94.244792   Top5 99.986979   BatchTime 0.123352   LR 0.010000   
2022-11-03 22:49:46,989 - INFO  - Training [11][   80/  391]   Loss 0.161595   Top1 94.296875   Top5 99.960938   BatchTime 0.117981   LR 0.010000   
2022-11-03 22:49:49,010 - INFO  - Training [11][  100/  391]   Loss 0.162567   Top1 94.289062   Top5 99.945312   BatchTime 0.114585   LR 0.010000   
2022-11-03 22:49:51,002 - INFO  - Training [11][  120/  391]   Loss 0.165647   Top1 94.160156   Top5 99.954427   BatchTime 0.112089   LR 0.010000   
2022-11-03 22:49:53,010 - INFO  - Training [11][  140/  391]   Loss 0.164878   Top1 94.162946   Top5 99.955357   BatchTime 0.110418   LR 0.010000   
2022-11-03 22:49:55,014 - INFO  - Training [11][  160/  391]   Loss 0.166724   Top1 94.111328   Top5 99.951172   BatchTime 0.109145   LR 0.010000   
2022-11-03 22:49:57,109 - INFO  - Training [11][  180/  391]   Loss 0.166731   Top1 94.144965   Top5 99.956597   BatchTime 0.108657   LR 0.010000   
2022-11-03 22:49:59,046 - INFO  - Training [11][  200/  391]   Loss 0.167188   Top1 94.152344   Top5 99.953125   BatchTime 0.107476   LR 0.010000   
2022-11-03 22:50:01,046 - INFO  - Training [11][  220/  391]   Loss 0.166158   Top1 94.183239   Top5 99.943182   BatchTime 0.106793   LR 0.010000   
2022-11-03 22:50:03,074 - INFO  - Training [11][  240/  391]   Loss 0.165935   Top1 94.186198   Top5 99.944661   BatchTime 0.106345   LR 0.010000   
2022-11-03 22:50:05,093 - INFO  - Training [11][  260/  391]   Loss 0.165918   Top1 94.200721   Top5 99.945913   BatchTime 0.105928   LR 0.010000   
2022-11-03 22:50:07,100 - INFO  - Training [11][  280/  391]   Loss 0.165266   Top1 94.241071   Top5 99.941406   BatchTime 0.105531   LR 0.010000   
2022-11-03 22:50:09,103 - INFO  - Training [11][  300/  391]   Loss 0.164630   Top1 94.252604   Top5 99.937500   BatchTime 0.105172   LR 0.010000   
2022-11-03 22:50:11,127 - INFO  - Training [11][  320/  391]   Loss 0.164898   Top1 94.255371   Top5 99.938965   BatchTime 0.104923   LR 0.010000   
2022-11-03 22:50:13,109 - INFO  - Training [11][  340/  391]   Loss 0.166203   Top1 94.216452   Top5 99.937960   BatchTime 0.104581   LR 0.010000   
2022-11-03 22:50:15,080 - INFO  - Training [11][  360/  391]   Loss 0.167188   Top1 94.190538   Top5 99.930556   BatchTime 0.104246   LR 0.010000   
2022-11-03 22:50:17,032 - INFO  - Training [11][  380/  391]   Loss 0.167932   Top1 94.189967   Top5 99.921875   BatchTime 0.103897   LR 0.010000   
2022-11-03 22:50:18,386 - INFO  - ==> Top1: 94.208    Top5: 99.922    Loss: 0.168

2022-11-03 22:50:18,387 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:50:21,054 - INFO  - Validation [11][   20/   79]   Loss 0.366913   Top1 88.671875   Top5 99.414062   BatchTime 0.133264   
2022-11-03 22:50:21,653 - INFO  - Validation [11][   40/   79]   Loss 0.373199   Top1 89.179688   Top5 99.414062   BatchTime 0.081616   
2022-11-03 22:50:22,173 - INFO  - Validation [11][   60/   79]   Loss 0.375073   Top1 89.153646   Top5 99.453125   BatchTime 0.063062   
2022-11-03 22:50:22,951 - INFO  - ==> Top1: 88.850    Top5: 99.470    Loss: 0.379

2022-11-03 22:50:23,012 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:50:23,015 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:50:23,015 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 88.850   Top5: 99.470] Sparsity : 0.814
2022-11-03 22:50:23,146 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:50:23,146 - INFO  - >>>>>>>> Epoch  12
2022-11-03 22:50:23,148 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:50:26,729 - INFO  - Training [12][   20/  391]   Loss 0.156066   Top1 94.609375   Top5 99.843750   BatchTime 0.179059   LR 0.010000   
2022-11-03 22:50:28,494 - INFO  - Training [12][   40/  391]   Loss 0.148606   Top1 94.882812   Top5 99.902344   BatchTime 0.133658   LR 0.010000   
2022-11-03 22:50:30,512 - INFO  - Training [12][   60/  391]   Loss 0.148360   Top1 94.869792   Top5 99.921875   BatchTime 0.122739   LR 0.010000   
2022-11-03 22:50:32,515 - INFO  - Training [12][   80/  391]   Loss 0.147177   Top1 94.863281   Top5 99.941406   BatchTime 0.117087   LR 0.010000   
2022-11-03 22:50:34,530 - INFO  - Training [12][  100/  391]   Loss 0.146488   Top1 94.882812   Top5 99.953125   BatchTime 0.113820   LR 0.010000   
2022-11-03 22:50:36,540 - INFO  - Training [12][  120/  391]   Loss 0.149892   Top1 94.785156   Top5 99.947917   BatchTime 0.111599   LR 0.010000   
2022-11-03 22:50:38,557 - INFO  - Training [12][  140/  391]   Loss 0.149809   Top1 94.765625   Top5 99.955357   BatchTime 0.110061   LR 0.010000   
2022-11-03 22:50:40,579 - INFO  - Training [12][  160/  391]   Loss 0.150193   Top1 94.750977   Top5 99.951172   BatchTime 0.108944   LR 0.010000   
2022-11-03 22:50:42,590 - INFO  - Training [12][  180/  391]   Loss 0.151077   Top1 94.709201   Top5 99.956597   BatchTime 0.108009   LR 0.010000   
2022-11-03 22:50:44,592 - INFO  - Training [12][  200/  391]   Loss 0.152347   Top1 94.625000   Top5 99.960938   BatchTime 0.107219   LR 0.010000   
2022-11-03 22:50:46,596 - INFO  - Training [12][  220/  391]   Loss 0.152070   Top1 94.595170   Top5 99.957386   BatchTime 0.106581   LR 0.010000   
2022-11-03 22:50:48,614 - INFO  - Training [12][  240/  391]   Loss 0.152913   Top1 94.544271   Top5 99.957682   BatchTime 0.106108   LR 0.010000   
2022-11-03 22:50:50,614 - INFO  - Training [12][  260/  391]   Loss 0.153656   Top1 94.495192   Top5 99.954928   BatchTime 0.105637   LR 0.010000   
2022-11-03 22:50:52,609 - INFO  - Training [12][  280/  391]   Loss 0.154415   Top1 94.483817   Top5 99.946987   BatchTime 0.105215   LR 0.010000   
2022-11-03 22:50:54,615 - INFO  - Training [12][  300/  391]   Loss 0.154339   Top1 94.479167   Top5 99.950521   BatchTime 0.104887   LR 0.010000   
2022-11-03 22:50:56,613 - INFO  - Training [12][  320/  391]   Loss 0.154077   Top1 94.497070   Top5 99.948730   BatchTime 0.104577   LR 0.010000   
2022-11-03 22:50:58,593 - INFO  - Training [12][  340/  391]   Loss 0.153081   Top1 94.547335   Top5 99.947151   BatchTime 0.104247   LR 0.010000   
2022-11-03 22:51:00,563 - INFO  - Training [12][  360/  391]   Loss 0.152264   Top1 94.578993   Top5 99.950087   BatchTime 0.103928   LR 0.010000   
2022-11-03 22:51:02,514 - INFO  - Training [12][  380/  391]   Loss 0.152890   Top1 94.557977   Top5 99.946546   BatchTime 0.103594   LR 0.010000   
2022-11-03 22:51:03,838 - INFO  - ==> Top1: 94.556    Top5: 99.946    Loss: 0.153

2022-11-03 22:51:03,839 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:51:06,503 - INFO  - Validation [12][   20/   79]   Loss 0.364233   Top1 88.554688   Top5 99.570312   BatchTime 0.133092   
2022-11-03 22:51:07,022 - INFO  - Validation [12][   40/   79]   Loss 0.386879   Top1 88.554688   Top5 99.453125   BatchTime 0.079529   
2022-11-03 22:51:07,540 - INFO  - Validation [12][   60/   79]   Loss 0.383983   Top1 88.750000   Top5 99.492188   BatchTime 0.061650   
2022-11-03 22:51:08,333 - INFO  - ==> Top1: 88.630    Top5: 99.540    Loss: 0.382

2022-11-03 22:51:08,389 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:51:08,390 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:51:08,390 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 88.850   Top5: 99.470] Sparsity : 0.814
2022-11-03 22:51:08,472 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:51:08,472 - INFO  - >>>>>>>> Epoch  13
2022-11-03 22:51:08,474 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:51:12,051 - INFO  - Training [13][   20/  391]   Loss 0.129696   Top1 95.468750   Top5 99.960938   BatchTime 0.178871   LR 0.010000   
2022-11-03 22:51:13,902 - INFO  - Training [13][   40/  391]   Loss 0.125477   Top1 95.644531   Top5 99.960938   BatchTime 0.135716   LR 0.010000   
2022-11-03 22:51:15,916 - INFO  - Training [13][   60/  391]   Loss 0.124797   Top1 95.729167   Top5 99.960938   BatchTime 0.124038   LR 0.010000   
2022-11-03 22:51:17,944 - INFO  - Training [13][   80/  391]   Loss 0.133289   Top1 95.302734   Top5 99.941406   BatchTime 0.118378   LR 0.010000   
2022-11-03 22:51:19,983 - INFO  - Training [13][  100/  391]   Loss 0.134372   Top1 95.257812   Top5 99.945312   BatchTime 0.115085   LR 0.010000   
2022-11-03 22:51:21,968 - INFO  - Training [13][  120/  391]   Loss 0.136596   Top1 95.195312   Top5 99.941406   BatchTime 0.112451   LR 0.010000   
2022-11-03 22:51:23,951 - INFO  - Training [13][  140/  391]   Loss 0.136768   Top1 95.245536   Top5 99.944196   BatchTime 0.110552   LR 0.010000   
2022-11-03 22:51:25,967 - INFO  - Training [13][  160/  391]   Loss 0.138502   Top1 95.175781   Top5 99.946289   BatchTime 0.109329   LR 0.010000   
2022-11-03 22:51:27,955 - INFO  - Training [13][  180/  391]   Loss 0.138508   Top1 95.190972   Top5 99.947917   BatchTime 0.108228   LR 0.010000   
2022-11-03 22:51:29,953 - INFO  - Training [13][  200/  391]   Loss 0.138784   Top1 95.144531   Top5 99.949219   BatchTime 0.107392   LR 0.010000   
2022-11-03 22:51:31,960 - INFO  - Training [13][  220/  391]   Loss 0.137755   Top1 95.191761   Top5 99.950284   BatchTime 0.106751   LR 0.010000   
2022-11-03 22:51:33,985 - INFO  - Training [13][  240/  391]   Loss 0.138721   Top1 95.143229   Top5 99.954427   BatchTime 0.106293   LR 0.010000   
2022-11-03 22:51:36,088 - INFO  - Training [13][  260/  391]   Loss 0.138789   Top1 95.123197   Top5 99.951923   BatchTime 0.106207   LR 0.010000   
2022-11-03 22:51:38,084 - INFO  - Training [13][  280/  391]   Loss 0.138287   Top1 95.156250   Top5 99.944196   BatchTime 0.105749   LR 0.010000   
2022-11-03 22:51:40,099 - INFO  - Training [13][  300/  391]   Loss 0.138902   Top1 95.148438   Top5 99.942708   BatchTime 0.105414   LR 0.010000   
2022-11-03 22:51:42,112 - INFO  - Training [13][  320/  391]   Loss 0.139533   Top1 95.134277   Top5 99.943848   BatchTime 0.105119   LR 0.010000   
2022-11-03 22:51:44,090 - INFO  - Training [13][  340/  391]   Loss 0.139466   Top1 95.153952   Top5 99.944853   BatchTime 0.104750   LR 0.010000   
2022-11-03 22:51:46,070 - INFO  - Training [13][  360/  391]   Loss 0.139207   Top1 95.158420   Top5 99.941406   BatchTime 0.104431   LR 0.010000   
2022-11-03 22:51:48,021 - INFO  - Training [13][  380/  391]   Loss 0.139024   Top1 95.168586   Top5 99.942434   BatchTime 0.104070   LR 0.010000   
2022-11-03 22:51:49,336 - INFO  - ==> Top1: 95.140    Top5: 99.940    Loss: 0.140

2022-11-03 22:51:49,337 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:51:51,982 - INFO  - Validation [13][   20/   79]   Loss 0.413832   Top1 87.812500   Top5 99.375000   BatchTime 0.132187   
2022-11-03 22:51:52,504 - INFO  - Validation [13][   40/   79]   Loss 0.418274   Top1 88.183594   Top5 99.433594   BatchTime 0.079152   
2022-11-03 22:51:53,024 - INFO  - Validation [13][   60/   79]   Loss 0.411323   Top1 88.502604   Top5 99.505208   BatchTime 0.061437   
2022-11-03 22:51:53,884 - INFO  - ==> Top1: 88.310    Top5: 99.490    Loss: 0.412

2022-11-03 22:51:53,917 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:51:53,918 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:51:53,918 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 88.850   Top5: 99.470] Sparsity : 0.814
2022-11-03 22:51:54,022 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:51:54,022 - INFO  - >>>>>>>> Epoch  14
2022-11-03 22:51:54,025 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:51:57,528 - INFO  - Training [14][   20/  391]   Loss 0.114947   Top1 95.859375   Top5 99.960938   BatchTime 0.175150   LR 0.010000   
2022-11-03 22:51:59,387 - INFO  - Training [14][   40/  391]   Loss 0.115704   Top1 95.976562   Top5 99.980469   BatchTime 0.134052   LR 0.010000   
2022-11-03 22:52:01,402 - INFO  - Training [14][   60/  391]   Loss 0.120911   Top1 95.794271   Top5 99.973958   BatchTime 0.122957   LR 0.010000   
2022-11-03 22:52:03,402 - INFO  - Training [14][   80/  391]   Loss 0.122246   Top1 95.693359   Top5 99.980469   BatchTime 0.117217   LR 0.010000   
2022-11-03 22:52:05,421 - INFO  - Training [14][  100/  391]   Loss 0.124357   Top1 95.617188   Top5 99.984375   BatchTime 0.113964   LR 0.010000   
2022-11-03 22:52:07,430 - INFO  - Training [14][  120/  391]   Loss 0.127031   Top1 95.572917   Top5 99.980469   BatchTime 0.111707   LR 0.010000   
2022-11-03 22:52:09,427 - INFO  - Training [14][  140/  391]   Loss 0.126939   Top1 95.524554   Top5 99.977679   BatchTime 0.110014   LR 0.010000   
2022-11-03 22:52:11,438 - INFO  - Training [14][  160/  391]   Loss 0.128742   Top1 95.454102   Top5 99.975586   BatchTime 0.108827   LR 0.010000   
2022-11-03 22:52:13,459 - INFO  - Training [14][  180/  391]   Loss 0.127980   Top1 95.486111   Top5 99.978299   BatchTime 0.107963   LR 0.010000   
2022-11-03 22:52:15,451 - INFO  - Training [14][  200/  391]   Loss 0.129432   Top1 95.457031   Top5 99.976562   BatchTime 0.107128   LR 0.010000   
2022-11-03 22:52:17,463 - INFO  - Training [14][  220/  391]   Loss 0.130252   Top1 95.440341   Top5 99.978693   BatchTime 0.106535   LR 0.010000   
2022-11-03 22:52:19,472 - INFO  - Training [14][  240/  391]   Loss 0.130451   Top1 95.432943   Top5 99.973958   BatchTime 0.106026   LR 0.010000   
2022-11-03 22:52:21,483 - INFO  - Training [14][  260/  391]   Loss 0.130835   Top1 95.426683   Top5 99.972957   BatchTime 0.105606   LR 0.010000   
2022-11-03 22:52:23,468 - INFO  - Training [14][  280/  391]   Loss 0.130958   Top1 95.401786   Top5 99.974888   BatchTime 0.105153   LR 0.010000   
2022-11-03 22:52:25,478 - INFO  - Training [14][  300/  391]   Loss 0.131141   Top1 95.385417   Top5 99.973958   BatchTime 0.104843   LR 0.010000   
2022-11-03 22:52:27,489 - INFO  - Training [14][  320/  391]   Loss 0.131432   Top1 95.375977   Top5 99.973145   BatchTime 0.104574   LR 0.010000   
2022-11-03 22:52:29,476 - INFO  - Training [14][  340/  391]   Loss 0.132207   Top1 95.358456   Top5 99.963235   BatchTime 0.104267   LR 0.010000   
2022-11-03 22:52:31,448 - INFO  - Training [14][  360/  391]   Loss 0.132990   Top1 95.342882   Top5 99.960938   BatchTime 0.103952   LR 0.010000   
2022-11-03 22:52:33,401 - INFO  - Training [14][  380/  391]   Loss 0.133225   Top1 95.349507   Top5 99.958882   BatchTime 0.103618   LR 0.010000   
2022-11-03 22:52:34,736 - INFO  - ==> Top1: 95.336    Top5: 99.958    Loss: 0.133

2022-11-03 22:52:34,737 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:52:37,258 - INFO  - Validation [14][   20/   79]   Loss 0.371416   Top1 89.179688   Top5 99.570312   BatchTime 0.126011   
2022-11-03 22:52:37,782 - INFO  - Validation [14][   40/   79]   Loss 0.378811   Top1 89.101562   Top5 99.531250   BatchTime 0.076097   
2022-11-03 22:52:38,300 - INFO  - Validation [14][   60/   79]   Loss 0.376586   Top1 89.218750   Top5 99.531250   BatchTime 0.059364   
2022-11-03 22:52:39,196 - INFO  - ==> Top1: 89.110    Top5: 99.520    Loss: 0.377

2022-11-03 22:52:39,227 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:52:39,228 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 89.110   Top5: 99.520] Sparsity : 0.819
2022-11-03 22:52:39,228 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.030   Top5: 99.530] Sparsity : 0.750
2022-11-03 22:52:39,300 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:52:39,300 - INFO  - >>>>>>>> Epoch  15
2022-11-03 22:52:39,301 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:52:42,880 - INFO  - Training [15][   20/  391]   Loss 0.110254   Top1 95.820312   Top5 99.960938   BatchTime 0.178931   LR 0.010000   
2022-11-03 22:52:44,817 - INFO  - Training [15][   40/  391]   Loss 0.114375   Top1 95.605469   Top5 99.980469   BatchTime 0.137876   LR 0.010000   
2022-11-03 22:52:46,820 - INFO  - Training [15][   60/  391]   Loss 0.116606   Top1 95.559896   Top5 99.986979   BatchTime 0.125302   LR 0.010000   
2022-11-03 22:52:48,820 - INFO  - Training [15][   80/  391]   Loss 0.120426   Top1 95.517578   Top5 99.980469   BatchTime 0.118987   LR 0.010000   
2022-11-03 22:52:50,814 - INFO  - Training [15][  100/  391]   Loss 0.121809   Top1 95.570312   Top5 99.984375   BatchTime 0.115128   LR 0.010000   
2022-11-03 22:52:52,828 - INFO  - Training [15][  120/  391]   Loss 0.120167   Top1 95.631510   Top5 99.986979   BatchTime 0.112720   LR 0.010000   
2022-11-03 22:52:54,841 - INFO  - Training [15][  140/  391]   Loss 0.121642   Top1 95.513393   Top5 99.988839   BatchTime 0.110998   LR 0.010000   
2022-11-03 22:52:56,856 - INFO  - Training [15][  160/  391]   Loss 0.121170   Top1 95.576172   Top5 99.985352   BatchTime 0.109714   LR 0.010000   
2022-11-03 22:52:58,873 - INFO  - Training [15][  180/  391]   Loss 0.123266   Top1 95.503472   Top5 99.986979   BatchTime 0.108730   LR 0.010000   
2022-11-03 22:53:00,880 - INFO  - Training [15][  200/  391]   Loss 0.122664   Top1 95.566406   Top5 99.988281   BatchTime 0.107891   LR 0.010000   
2022-11-03 22:53:02,883 - INFO  - Training [15][  220/  391]   Loss 0.124378   Top1 95.511364   Top5 99.978693   BatchTime 0.107189   LR 0.010000   
2022-11-03 22:53:04,893 - INFO  - Training [15][  240/  391]   Loss 0.124914   Top1 95.524089   Top5 99.970703   BatchTime 0.106631   LR 0.010000   
2022-11-03 22:53:06,903 - INFO  - Training [15][  260/  391]   Loss 0.123591   Top1 95.591947   Top5 99.972957   BatchTime 0.106157   LR 0.010000   
2022-11-03 22:53:08,902 - INFO  - Training [15][  280/  391]   Loss 0.125164   Top1 95.516183   Top5 99.972098   BatchTime 0.105713   LR 0.010000   
2022-11-03 22:53:10,895 - INFO  - Training [15][  300/  391]   Loss 0.125114   Top1 95.505208   Top5 99.971354   BatchTime 0.105309   LR 0.010000   
2022-11-03 22:53:13,050 - INFO  - Training [15][  320/  391]   Loss 0.125402   Top1 95.507812   Top5 99.968262   BatchTime 0.105463   LR 0.010000   
2022-11-03 22:53:14,971 - INFO  - Training [15][  340/  391]   Loss 0.125272   Top1 95.535386   Top5 99.967831   BatchTime 0.104909   LR 0.010000   
2022-11-03 22:53:16,940 - INFO  - Training [15][  360/  391]   Loss 0.125348   Top1 95.527344   Top5 99.965278   BatchTime 0.104551   LR 0.010000   
2022-11-03 22:53:18,903 - INFO  - Training [15][  380/  391]   Loss 0.125494   Top1 95.540707   Top5 99.962993   BatchTime 0.104213   LR 0.010000   
2022-11-03 22:53:20,230 - INFO  - ==> Top1: 95.550    Top5: 99.964    Loss: 0.126

2022-11-03 22:53:20,231 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:53:22,725 - INFO  - Validation [15][   20/   79]   Loss 0.369048   Top1 89.570312   Top5 99.687500   BatchTime 0.124590   
2022-11-03 22:53:23,249 - INFO  - Validation [15][   40/   79]   Loss 0.378139   Top1 89.550781   Top5 99.589844   BatchTime 0.075410   
2022-11-03 22:53:23,771 - INFO  - Validation [15][   60/   79]   Loss 0.375007   Top1 89.557292   Top5 99.622396   BatchTime 0.058967   
2022-11-03 22:53:24,717 - INFO  - ==> Top1: 89.430    Top5: 99.640    Loss: 0.373

2022-11-03 22:53:24,748 - INFO  - Scoreboard best 1 ==> Epoch [15][Top1: 89.430   Top5: 99.640] Sparsity : 0.820
2022-11-03 22:53:24,749 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:53:24,749 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 89.110   Top5: 99.520] Sparsity : 0.819
2022-11-03 22:53:24,933 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:53:24,933 - INFO  - >>>>>>>> Epoch  16
2022-11-03 22:53:24,934 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:53:28,448 - INFO  - Training [16][   20/  391]   Loss 0.126831   Top1 95.468750   Top5 99.960938   BatchTime 0.175715   LR 0.010000   
2022-11-03 22:53:30,613 - INFO  - Training [16][   40/  391]   Loss 0.112586   Top1 95.996094   Top5 99.980469   BatchTime 0.141977   LR 0.010000   
2022-11-03 22:53:32,633 - INFO  - Training [16][   60/  391]   Loss 0.114667   Top1 95.976562   Top5 99.960938   BatchTime 0.128325   LR 0.010000   
2022-11-03 22:53:34,626 - INFO  - Training [16][   80/  391]   Loss 0.117616   Top1 95.888672   Top5 99.970703   BatchTime 0.121153   LR 0.010000   
2022-11-03 22:53:36,609 - INFO  - Training [16][  100/  391]   Loss 0.117095   Top1 95.898438   Top5 99.976562   BatchTime 0.116752   LR 0.010000   
2022-11-03 22:53:38,610 - INFO  - Training [16][  120/  391]   Loss 0.119673   Top1 95.768229   Top5 99.980469   BatchTime 0.113965   LR 0.010000   
2022-11-03 22:53:40,623 - INFO  - Training [16][  140/  391]   Loss 0.119644   Top1 95.786830   Top5 99.977679   BatchTime 0.112067   LR 0.010000   
2022-11-03 22:53:42,651 - INFO  - Training [16][  160/  391]   Loss 0.118961   Top1 95.820312   Top5 99.980469   BatchTime 0.110734   LR 0.010000   
2022-11-03 22:53:44,656 - INFO  - Training [16][  180/  391]   Loss 0.120762   Top1 95.768229   Top5 99.982639   BatchTime 0.109563   LR 0.010000   
2022-11-03 22:53:46,678 - INFO  - Training [16][  200/  391]   Loss 0.119797   Top1 95.769531   Top5 99.984375   BatchTime 0.108720   LR 0.010000   
2022-11-03 22:53:48,686 - INFO  - Training [16][  220/  391]   Loss 0.120924   Top1 95.759943   Top5 99.985795   BatchTime 0.107964   LR 0.010000   
2022-11-03 22:53:50,688 - INFO  - Training [16][  240/  391]   Loss 0.121200   Top1 95.755208   Top5 99.977214   BatchTime 0.107308   LR 0.010000   
2022-11-03 22:53:52,687 - INFO  - Training [16][  260/  391]   Loss 0.121646   Top1 95.754207   Top5 99.972957   BatchTime 0.106741   LR 0.010000   
2022-11-03 22:53:54,681 - INFO  - Training [16][  280/  391]   Loss 0.122505   Top1 95.731027   Top5 99.972098   BatchTime 0.106238   LR 0.010000   
2022-11-03 22:53:56,700 - INFO  - Training [16][  300/  391]   Loss 0.122316   Top1 95.716146   Top5 99.971354   BatchTime 0.105884   LR 0.010000   
2022-11-03 22:53:58,697 - INFO  - Training [16][  320/  391]   Loss 0.122641   Top1 95.698242   Top5 99.963379   BatchTime 0.105507   LR 0.010000   
2022-11-03 22:54:00,672 - INFO  - Training [16][  340/  391]   Loss 0.122857   Top1 95.703125   Top5 99.963235   BatchTime 0.105110   LR 0.010000   
2022-11-03 22:54:02,646 - INFO  - Training [16][  360/  391]   Loss 0.122956   Top1 95.683594   Top5 99.963108   BatchTime 0.104753   LR 0.010000   
2022-11-03 22:54:04,599 - INFO  - Training [16][  380/  391]   Loss 0.122125   Top1 95.723684   Top5 99.962993   BatchTime 0.104380   LR 0.010000   
2022-11-03 22:54:05,932 - INFO  - ==> Top1: 95.708    Top5: 99.964    Loss: 0.122

2022-11-03 22:54:05,933 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:54:08,437 - INFO  - Validation [16][   20/   79]   Loss 0.374897   Top1 89.140625   Top5 99.570312   BatchTime 0.125133   
2022-11-03 22:54:08,961 - INFO  - Validation [16][   40/   79]   Loss 0.384250   Top1 89.218750   Top5 99.375000   BatchTime 0.075657   
2022-11-03 22:54:09,658 - INFO  - Validation [16][   60/   79]   Loss 0.379784   Top1 89.244792   Top5 99.427083   BatchTime 0.062057   
2022-11-03 22:54:10,590 - INFO  - ==> Top1: 89.290    Top5: 99.460    Loss: 0.379

2022-11-03 22:54:10,622 - INFO  - Scoreboard best 1 ==> Epoch [15][Top1: 89.430   Top5: 99.640] Sparsity : 0.820
2022-11-03 22:54:10,623 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:54:10,623 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.290   Top5: 99.460] Sparsity : 0.821
2022-11-03 22:54:10,716 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:54:10,716 - INFO  - >>>>>>>> Epoch  17
2022-11-03 22:54:10,718 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:54:14,442 - INFO  - Training [17][   20/  391]   Loss 0.090450   Top1 96.875000   Top5 99.960938   BatchTime 0.186191   LR 0.010000   
2022-11-03 22:54:16,455 - INFO  - Training [17][   40/  391]   Loss 0.104303   Top1 96.171875   Top5 99.980469   BatchTime 0.143425   LR 0.010000   
2022-11-03 22:54:18,460 - INFO  - Training [17][   60/  391]   Loss 0.101624   Top1 96.367188   Top5 99.973958   BatchTime 0.129041   LR 0.010000   
2022-11-03 22:54:20,475 - INFO  - Training [17][   80/  391]   Loss 0.106218   Top1 96.318359   Top5 99.970703   BatchTime 0.121966   LR 0.010000   
2022-11-03 22:54:22,466 - INFO  - Training [17][  100/  391]   Loss 0.106939   Top1 96.273438   Top5 99.968750   BatchTime 0.117476   LR 0.010000   
2022-11-03 22:54:24,473 - INFO  - Training [17][  120/  391]   Loss 0.109976   Top1 96.158854   Top5 99.973958   BatchTime 0.114622   LR 0.010000   
2022-11-03 22:54:26,488 - INFO  - Training [17][  140/  391]   Loss 0.110460   Top1 96.155134   Top5 99.972098   BatchTime 0.112643   LR 0.010000   
2022-11-03 22:54:28,493 - INFO  - Training [17][  160/  391]   Loss 0.110475   Top1 96.171875   Top5 99.975586   BatchTime 0.111096   LR 0.010000   
2022-11-03 22:54:30,506 - INFO  - Training [17][  180/  391]   Loss 0.111414   Top1 96.141493   Top5 99.973958   BatchTime 0.109932   LR 0.010000   
2022-11-03 22:54:32,542 - INFO  - Training [17][  200/  391]   Loss 0.111367   Top1 96.128906   Top5 99.976562   BatchTime 0.109117   LR 0.010000   
2022-11-03 22:54:34,552 - INFO  - Training [17][  220/  391]   Loss 0.112610   Top1 96.051136   Top5 99.975142   BatchTime 0.108335   LR 0.010000   
2022-11-03 22:54:36,563 - INFO  - Training [17][  240/  391]   Loss 0.113309   Top1 96.031901   Top5 99.970703   BatchTime 0.107686   LR 0.010000   
2022-11-03 22:54:38,585 - INFO  - Training [17][  260/  391]   Loss 0.114143   Top1 96.009615   Top5 99.966947   BatchTime 0.107180   LR 0.010000   
2022-11-03 22:54:40,592 - INFO  - Training [17][  280/  391]   Loss 0.114119   Top1 96.001674   Top5 99.966518   BatchTime 0.106691   LR 0.010000   
2022-11-03 22:54:42,608 - INFO  - Training [17][  300/  391]   Loss 0.114055   Top1 96.010417   Top5 99.968750   BatchTime 0.106299   LR 0.010000   
2022-11-03 22:54:44,618 - INFO  - Training [17][  320/  391]   Loss 0.114328   Top1 96.022949   Top5 99.968262   BatchTime 0.105936   LR 0.010000   
2022-11-03 22:54:46,636 - INFO  - Training [17][  340/  391]   Loss 0.115375   Top1 95.969669   Top5 99.965533   BatchTime 0.105639   LR 0.010000   
2022-11-03 22:54:48,594 - INFO  - Training [17][  360/  391]   Loss 0.114889   Top1 96.006944   Top5 99.965278   BatchTime 0.105210   LR 0.010000   
2022-11-03 22:54:50,611 - INFO  - Training [17][  380/  391]   Loss 0.114425   Top1 96.021793   Top5 99.967105   BatchTime 0.104979   LR 0.010000   
2022-11-03 22:54:51,941 - INFO  - ==> Top1: 96.012    Top5: 99.966    Loss: 0.115

2022-11-03 22:54:51,941 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:54:54,467 - INFO  - Validation [17][   20/   79]   Loss 0.367631   Top1 89.960938   Top5 99.648438   BatchTime 0.126222   
2022-11-03 22:54:55,109 - INFO  - Validation [17][   40/   79]   Loss 0.378620   Top1 89.570312   Top5 99.570312   BatchTime 0.079160   
2022-11-03 22:54:55,816 - INFO  - Validation [17][   60/   79]   Loss 0.365660   Top1 89.934896   Top5 99.583333   BatchTime 0.064545   
2022-11-03 22:54:56,734 - INFO  - ==> Top1: 89.900    Top5: 99.600    Loss: 0.363

2022-11-03 22:54:56,763 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:54:56,764 - INFO  - Scoreboard best 2 ==> Epoch [15][Top1: 89.430   Top5: 99.640] Sparsity : 0.820
2022-11-03 22:54:56,764 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.430   Top5: 99.550] Sparsity : 0.769
2022-11-03 22:54:56,962 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 22:54:56,962 - INFO  - >>>>>>>> Epoch  18
2022-11-03 22:54:56,963 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:55:00,820 - INFO  - Training [18][   20/  391]   Loss 0.099519   Top1 96.406250   Top5 100.000000   BatchTime 0.192823   LR 0.010000   
2022-11-03 22:55:02,847 - INFO  - Training [18][   40/  391]   Loss 0.107396   Top1 96.074219   Top5 100.000000   BatchTime 0.147083   LR 0.010000   
2022-11-03 22:55:04,897 - INFO  - Training [18][   60/  391]   Loss 0.100388   Top1 96.380208   Top5 100.000000   BatchTime 0.132230   LR 0.010000   
2022-11-03 22:55:06,926 - INFO  - Training [18][   80/  391]   Loss 0.101542   Top1 96.250000   Top5 100.000000   BatchTime 0.124531   LR 0.010000   
2022-11-03 22:55:08,940 - INFO  - Training [18][  100/  391]   Loss 0.100274   Top1 96.281250   Top5 100.000000   BatchTime 0.119759   LR 0.010000   
2022-11-03 22:55:10,938 - INFO  - Training [18][  120/  391]   Loss 0.100845   Top1 96.282552   Top5 100.000000   BatchTime 0.116451   LR 0.010000   
2022-11-03 22:55:12,959 - INFO  - Training [18][  140/  391]   Loss 0.101237   Top1 96.261161   Top5 100.000000   BatchTime 0.114248   LR 0.010000   
2022-11-03 22:55:14,970 - INFO  - Training [18][  160/  391]   Loss 0.101812   Top1 96.274414   Top5 99.995117   BatchTime 0.112538   LR 0.010000   
2022-11-03 22:55:16,980 - INFO  - Training [18][  180/  391]   Loss 0.100750   Top1 96.323785   Top5 99.995660   BatchTime 0.111202   LR 0.010000   
2022-11-03 22:55:18,980 - INFO  - Training [18][  200/  391]   Loss 0.102394   Top1 96.289062   Top5 99.988281   BatchTime 0.110078   LR 0.010000   
2022-11-03 22:55:20,999 - INFO  - Training [18][  220/  391]   Loss 0.105091   Top1 96.214489   Top5 99.989347   BatchTime 0.109252   LR 0.010000   
2022-11-03 22:55:23,023 - INFO  - Training [18][  240/  391]   Loss 0.107016   Top1 96.149089   Top5 99.977214   BatchTime 0.108579   LR 0.010000   
2022-11-03 22:55:25,016 - INFO  - Training [18][  260/  391]   Loss 0.108190   Top1 96.120793   Top5 99.978966   BatchTime 0.107894   LR 0.010000   
2022-11-03 22:55:27,007 - INFO  - Training [18][  280/  391]   Loss 0.107910   Top1 96.138393   Top5 99.977679   BatchTime 0.107296   LR 0.010000   
2022-11-03 22:55:29,004 - INFO  - Training [18][  300/  391]   Loss 0.106923   Top1 96.195312   Top5 99.976562   BatchTime 0.106800   LR 0.010000   
2022-11-03 22:55:31,013 - INFO  - Training [18][  320/  391]   Loss 0.106539   Top1 96.193848   Top5 99.975586   BatchTime 0.106403   LR 0.010000   
2022-11-03 22:55:32,990 - INFO  - Training [18][  340/  391]   Loss 0.107050   Top1 96.187960   Top5 99.972426   BatchTime 0.105958   LR 0.010000   
2022-11-03 22:55:34,936 - INFO  - Training [18][  360/  391]   Loss 0.107579   Top1 96.161024   Top5 99.973958   BatchTime 0.105477   LR 0.010000   
2022-11-03 22:55:36,886 - INFO  - Training [18][  380/  391]   Loss 0.108097   Top1 96.163651   Top5 99.975329   BatchTime 0.105058   LR 0.010000   
2022-11-03 22:55:38,207 - INFO  - ==> Top1: 96.150    Top5: 99.976    Loss: 0.109

2022-11-03 22:55:38,208 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:55:40,829 - INFO  - Validation [18][   20/   79]   Loss 0.380180   Top1 89.687500   Top5 99.492188   BatchTime 0.130947   
2022-11-03 22:55:41,523 - INFO  - Validation [18][   40/   79]   Loss 0.385141   Top1 89.589844   Top5 99.472656   BatchTime 0.082834   
2022-11-03 22:55:42,226 - INFO  - Validation [18][   60/   79]   Loss 0.379948   Top1 89.674479   Top5 99.492188   BatchTime 0.066936   
2022-11-03 22:55:43,165 - INFO  - ==> Top1: 89.660    Top5: 99.540    Loss: 0.374

2022-11-03 22:55:43,200 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:55:43,200 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 22:55:43,201 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 89.430   Top5: 99.640] Sparsity : 0.820
2022-11-03 22:55:43,280 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:55:43,280 - INFO  - >>>>>>>> Epoch  19
2022-11-03 22:55:43,281 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:55:47,265 - INFO  - Training [19][   20/  391]   Loss 0.118269   Top1 95.976562   Top5 100.000000   BatchTime 0.199221   LR 0.010000   
2022-11-03 22:55:49,271 - INFO  - Training [19][   40/  391]   Loss 0.104916   Top1 96.503906   Top5 100.000000   BatchTime 0.149761   LR 0.010000   
2022-11-03 22:55:51,316 - INFO  - Training [19][   60/  391]   Loss 0.103059   Top1 96.471354   Top5 100.000000   BatchTime 0.133921   LR 0.010000   
2022-11-03 22:55:53,335 - INFO  - Training [19][   80/  391]   Loss 0.101717   Top1 96.474609   Top5 100.000000   BatchTime 0.125676   LR 0.010000   
2022-11-03 22:55:55,357 - INFO  - Training [19][  100/  391]   Loss 0.101782   Top1 96.460938   Top5 100.000000   BatchTime 0.120763   LR 0.010000   
2022-11-03 22:55:57,364 - INFO  - Training [19][  120/  391]   Loss 0.102622   Top1 96.451823   Top5 100.000000   BatchTime 0.117357   LR 0.010000   
2022-11-03 22:55:59,395 - INFO  - Training [19][  140/  391]   Loss 0.102986   Top1 96.434152   Top5 100.000000   BatchTime 0.115101   LR 0.010000   
2022-11-03 22:56:01,405 - INFO  - Training [19][  160/  391]   Loss 0.102717   Top1 96.435547   Top5 100.000000   BatchTime 0.113271   LR 0.010000   
2022-11-03 22:56:03,429 - INFO  - Training [19][  180/  391]   Loss 0.101861   Top1 96.432292   Top5 100.000000   BatchTime 0.111931   LR 0.010000   
2022-11-03 22:56:05,450 - INFO  - Training [19][  200/  391]   Loss 0.101642   Top1 96.453125   Top5 100.000000   BatchTime 0.110843   LR 0.010000   
2022-11-03 22:56:07,450 - INFO  - Training [19][  220/  391]   Loss 0.101706   Top1 96.448864   Top5 99.996449   BatchTime 0.109856   LR 0.010000   
2022-11-03 22:56:09,456 - INFO  - Training [19][  240/  391]   Loss 0.102989   Top1 96.419271   Top5 99.996745   BatchTime 0.109061   LR 0.010000   
2022-11-03 22:56:11,468 - INFO  - Training [19][  260/  391]   Loss 0.103600   Top1 96.400240   Top5 99.993990   BatchTime 0.108409   LR 0.010000   
2022-11-03 22:56:13,479 - INFO  - Training [19][  280/  391]   Loss 0.102670   Top1 96.420201   Top5 99.991629   BatchTime 0.107848   LR 0.010000   
2022-11-03 22:56:15,487 - INFO  - Training [19][  300/  391]   Loss 0.103206   Top1 96.419271   Top5 99.992188   BatchTime 0.107351   LR 0.010000   
2022-11-03 22:56:17,504 - INFO  - Training [19][  320/  391]   Loss 0.103527   Top1 96.420898   Top5 99.992676   BatchTime 0.106945   LR 0.010000   
2022-11-03 22:56:19,526 - INFO  - Training [19][  340/  391]   Loss 0.104956   Top1 96.341912   Top5 99.990809   BatchTime 0.106600   LR 0.010000   
2022-11-03 22:56:21,480 - INFO  - Training [19][  360/  391]   Loss 0.105526   Top1 96.293403   Top5 99.991319   BatchTime 0.106107   LR 0.010000   
2022-11-03 22:56:23,429 - INFO  - Training [19][  380/  391]   Loss 0.105721   Top1 96.262336   Top5 99.991776   BatchTime 0.105652   LR 0.010000   
2022-11-03 22:56:24,764 - INFO  - ==> Top1: 96.250    Top5: 99.992    Loss: 0.106

2022-11-03 22:56:24,765 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:56:27,501 - INFO  - Validation [19][   20/   79]   Loss 0.383158   Top1 89.609375   Top5 99.414062   BatchTime 0.136707   
2022-11-03 22:56:28,189 - INFO  - Validation [19][   40/   79]   Loss 0.382092   Top1 89.707031   Top5 99.492188   BatchTime 0.085561   
2022-11-03 22:56:28,881 - INFO  - Validation [19][   60/   79]   Loss 0.377486   Top1 89.726562   Top5 99.557292   BatchTime 0.068578   
2022-11-03 22:56:29,785 - INFO  - ==> Top1: 89.600    Top5: 99.580    Loss: 0.373

2022-11-03 22:56:29,817 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:56:29,818 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 22:56:29,818 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 22:56:29,928 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:56:29,929 - INFO  - >>>>>>>> Epoch  20
2022-11-03 22:56:29,930 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:56:34,072 - INFO  - Training [20][   20/  391]   Loss 0.096073   Top1 96.562500   Top5 99.960938   BatchTime 0.207062   LR 0.010000   
2022-11-03 22:56:36,079 - INFO  - Training [20][   40/  391]   Loss 0.089877   Top1 96.738281   Top5 99.980469   BatchTime 0.153703   LR 0.010000   
2022-11-03 22:56:38,089 - INFO  - Training [20][   60/  391]   Loss 0.089325   Top1 96.783854   Top5 99.986979   BatchTime 0.135972   LR 0.010000   
2022-11-03 22:56:40,086 - INFO  - Training [20][   80/  391]   Loss 0.094950   Top1 96.533203   Top5 99.980469   BatchTime 0.126941   LR 0.010000   
2022-11-03 22:56:42,106 - INFO  - Training [20][  100/  391]   Loss 0.096510   Top1 96.500000   Top5 99.984375   BatchTime 0.121758   LR 0.010000   
2022-11-03 22:56:44,116 - INFO  - Training [20][  120/  391]   Loss 0.096808   Top1 96.536458   Top5 99.973958   BatchTime 0.118210   LR 0.010000   
2022-11-03 22:56:46,140 - INFO  - Training [20][  140/  391]   Loss 0.099379   Top1 96.456473   Top5 99.977679   BatchTime 0.115780   LR 0.010000   
2022-11-03 22:56:48,152 - INFO  - Training [20][  160/  391]   Loss 0.099440   Top1 96.459961   Top5 99.970703   BatchTime 0.113881   LR 0.010000   
2022-11-03 22:56:50,170 - INFO  - Training [20][  180/  391]   Loss 0.099350   Top1 96.471354   Top5 99.969618   BatchTime 0.112443   LR 0.010000   
2022-11-03 22:56:52,178 - INFO  - Training [20][  200/  391]   Loss 0.101031   Top1 96.363281   Top5 99.972656   BatchTime 0.111234   LR 0.010000   
2022-11-03 22:56:54,184 - INFO  - Training [20][  220/  391]   Loss 0.101646   Top1 96.360085   Top5 99.971591   BatchTime 0.110244   LR 0.010000   
2022-11-03 22:56:56,206 - INFO  - Training [20][  240/  391]   Loss 0.102487   Top1 96.324870   Top5 99.973958   BatchTime 0.109481   LR 0.010000   
2022-11-03 22:56:58,232 - INFO  - Training [20][  260/  391]   Loss 0.104406   Top1 96.256010   Top5 99.975962   BatchTime 0.108851   LR 0.010000   
2022-11-03 22:57:00,233 - INFO  - Training [20][  280/  391]   Loss 0.105941   Top1 96.196987   Top5 99.974888   BatchTime 0.108221   LR 0.010000   
2022-11-03 22:57:02,255 - INFO  - Training [20][  300/  391]   Loss 0.106121   Top1 96.171875   Top5 99.973958   BatchTime 0.107747   LR 0.010000   
2022-11-03 22:57:04,260 - INFO  - Training [20][  320/  391]   Loss 0.106459   Top1 96.174316   Top5 99.975586   BatchTime 0.107277   LR 0.010000   
2022-11-03 22:57:06,231 - INFO  - Training [20][  340/  391]   Loss 0.106608   Top1 96.171875   Top5 99.977022   BatchTime 0.106765   LR 0.010000   
2022-11-03 22:57:08,182 - INFO  - Training [20][  360/  391]   Loss 0.107831   Top1 96.134983   Top5 99.978299   BatchTime 0.106251   LR 0.010000   
2022-11-03 22:57:10,133 - INFO  - Training [20][  380/  391]   Loss 0.108989   Top1 96.114309   Top5 99.979441   BatchTime 0.105794   LR 0.010000   
2022-11-03 22:57:11,457 - INFO  - ==> Top1: 96.102    Top5: 99.980    Loss: 0.109

2022-11-03 22:57:11,458 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:57:14,226 - INFO  - Validation [20][   20/   79]   Loss 0.390113   Top1 89.335938   Top5 99.531250   BatchTime 0.138307   
2022-11-03 22:57:14,922 - INFO  - Validation [20][   40/   79]   Loss 0.393693   Top1 89.375000   Top5 99.453125   BatchTime 0.086541   
2022-11-03 22:57:15,613 - INFO  - Validation [20][   60/   79]   Loss 0.387343   Top1 89.557292   Top5 99.505208   BatchTime 0.069212   
2022-11-03 22:57:16,713 - INFO  - ==> Top1: 89.510    Top5: 99.540    Loss: 0.383

2022-11-03 22:57:16,742 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:57:16,742 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 22:57:16,742 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 22:57:16,844 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:57:16,844 - INFO  - >>>>>>>> Epoch  21
2022-11-03 22:57:16,846 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:57:20,896 - INFO  - Training [21][   20/  391]   Loss 0.120251   Top1 95.898438   Top5 99.921875   BatchTime 0.202490   LR 0.010000   
2022-11-03 22:57:22,899 - INFO  - Training [21][   40/  391]   Loss 0.114677   Top1 96.093750   Top5 99.902344   BatchTime 0.151335   LR 0.010000   
2022-11-03 22:57:24,927 - INFO  - Training [21][   60/  391]   Loss 0.119173   Top1 95.872396   Top5 99.921875   BatchTime 0.134686   LR 0.010000   
2022-11-03 22:57:26,939 - INFO  - Training [21][   80/  391]   Loss 0.123724   Top1 95.556641   Top5 99.941406   BatchTime 0.126165   LR 0.010000   
2022-11-03 22:57:28,942 - INFO  - Training [21][  100/  391]   Loss 0.124232   Top1 95.539062   Top5 99.953125   BatchTime 0.120955   LR 0.010000   
2022-11-03 22:57:30,978 - INFO  - Training [21][  120/  391]   Loss 0.126075   Top1 95.488281   Top5 99.941406   BatchTime 0.117763   LR 0.010000   
2022-11-03 22:57:32,967 - INFO  - Training [21][  140/  391]   Loss 0.125115   Top1 95.552455   Top5 99.944196   BatchTime 0.115149   LR 0.010000   
2022-11-03 22:57:34,988 - INFO  - Training [21][  160/  391]   Loss 0.126277   Top1 95.498047   Top5 99.946289   BatchTime 0.113387   LR 0.010000   
2022-11-03 22:57:36,991 - INFO  - Training [21][  180/  391]   Loss 0.125193   Top1 95.551215   Top5 99.947917   BatchTime 0.111914   LR 0.010000   
2022-11-03 22:57:38,990 - INFO  - Training [21][  200/  391]   Loss 0.124669   Top1 95.578125   Top5 99.949219   BatchTime 0.110716   LR 0.010000   
2022-11-03 22:57:40,983 - INFO  - Training [21][  220/  391]   Loss 0.126007   Top1 95.546875   Top5 99.946733   BatchTime 0.109714   LR 0.010000   
2022-11-03 22:57:42,988 - INFO  - Training [21][  240/  391]   Loss 0.125256   Top1 95.556641   Top5 99.951172   BatchTime 0.108923   LR 0.010000   
2022-11-03 22:57:44,996 - INFO  - Training [21][  260/  391]   Loss 0.124993   Top1 95.573918   Top5 99.951923   BatchTime 0.108267   LR 0.010000   
2022-11-03 22:57:46,993 - INFO  - Training [21][  280/  391]   Loss 0.125571   Top1 95.541295   Top5 99.955357   BatchTime 0.107667   LR 0.010000   
2022-11-03 22:57:49,014 - INFO  - Training [21][  300/  391]   Loss 0.126599   Top1 95.497396   Top5 99.953125   BatchTime 0.107227   LR 0.010000   
2022-11-03 22:57:51,033 - INFO  - Training [21][  320/  391]   Loss 0.127121   Top1 95.463867   Top5 99.956055   BatchTime 0.106832   LR 0.010000   
2022-11-03 22:57:53,028 - INFO  - Training [21][  340/  391]   Loss 0.127794   Top1 95.448070   Top5 99.956342   BatchTime 0.106417   LR 0.010000   
2022-11-03 22:57:54,981 - INFO  - Training [21][  360/  391]   Loss 0.128554   Top1 95.392795   Top5 99.958767   BatchTime 0.105930   LR 0.010000   
2022-11-03 22:57:56,937 - INFO  - Training [21][  380/  391]   Loss 0.129610   Top1 95.351562   Top5 99.956826   BatchTime 0.105501   LR 0.010000   
2022-11-03 22:57:58,401 - INFO  - ==> Top1: 95.336    Top5: 99.954    Loss: 0.130

2022-11-03 22:57:58,402 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:58:01,172 - INFO  - Validation [21][   20/   79]   Loss 0.392954   Top1 89.101562   Top5 99.414062   BatchTime 0.138387   
2022-11-03 22:58:01,870 - INFO  - Validation [21][   40/   79]   Loss 0.400266   Top1 89.003906   Top5 99.453125   BatchTime 0.086657   
2022-11-03 22:58:02,564 - INFO  - Validation [21][   60/   79]   Loss 0.396929   Top1 89.127604   Top5 99.531250   BatchTime 0.069332   
2022-11-03 22:58:03,632 - INFO  - ==> Top1: 89.190    Top5: 99.530    Loss: 0.393

2022-11-03 22:58:03,658 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:58:03,659 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 22:58:03,659 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 22:58:03,792 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:58:03,792 - INFO  - >>>>>>>> Epoch  22
2022-11-03 22:58:03,794 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:58:07,887 - INFO  - Training [22][   20/  391]   Loss 0.105967   Top1 96.171875   Top5 100.000000   BatchTime 0.204649   LR 0.010000   
2022-11-03 22:58:09,890 - INFO  - Training [22][   40/  391]   Loss 0.114012   Top1 95.996094   Top5 99.980469   BatchTime 0.152406   LR 0.010000   
2022-11-03 22:58:12,007 - INFO  - Training [22][   60/  391]   Loss 0.117316   Top1 95.833333   Top5 99.973958   BatchTime 0.136882   LR 0.010000   
2022-11-03 22:58:14,068 - INFO  - Training [22][   80/  391]   Loss 0.122460   Top1 95.605469   Top5 99.960938   BatchTime 0.128428   LR 0.010000   
2022-11-03 22:58:16,077 - INFO  - Training [22][  100/  391]   Loss 0.124624   Top1 95.562500   Top5 99.968750   BatchTime 0.122831   LR 0.010000   
2022-11-03 22:58:18,110 - INFO  - Training [22][  120/  391]   Loss 0.125845   Top1 95.540365   Top5 99.973958   BatchTime 0.119301   LR 0.010000   
2022-11-03 22:58:20,128 - INFO  - Training [22][  140/  391]   Loss 0.127382   Top1 95.502232   Top5 99.966518   BatchTime 0.116670   LR 0.010000   
2022-11-03 22:58:22,146 - INFO  - Training [22][  160/  391]   Loss 0.127290   Top1 95.527344   Top5 99.965820   BatchTime 0.114700   LR 0.010000   
2022-11-03 22:58:24,160 - INFO  - Training [22][  180/  391]   Loss 0.127530   Top1 95.499132   Top5 99.969618   BatchTime 0.113142   LR 0.010000   
2022-11-03 22:58:26,186 - INFO  - Training [22][  200/  391]   Loss 0.128223   Top1 95.480469   Top5 99.968750   BatchTime 0.111959   LR 0.010000   
2022-11-03 22:58:28,199 - INFO  - Training [22][  220/  391]   Loss 0.127981   Top1 95.486506   Top5 99.968040   BatchTime 0.110931   LR 0.010000   
2022-11-03 22:58:30,214 - INFO  - Training [22][  240/  391]   Loss 0.126619   Top1 95.524089   Top5 99.970703   BatchTime 0.110081   LR 0.010000   
2022-11-03 22:58:32,224 - INFO  - Training [22][  260/  391]   Loss 0.126935   Top1 95.507812   Top5 99.969952   BatchTime 0.109347   LR 0.010000   
2022-11-03 22:58:34,239 - INFO  - Training [22][  280/  391]   Loss 0.126496   Top1 95.532924   Top5 99.969308   BatchTime 0.108731   LR 0.010000   
2022-11-03 22:58:36,238 - INFO  - Training [22][  300/  391]   Loss 0.127213   Top1 95.476562   Top5 99.971354   BatchTime 0.108144   LR 0.010000   
2022-11-03 22:58:38,237 - INFO  - Training [22][  320/  391]   Loss 0.126889   Top1 95.485840   Top5 99.973145   BatchTime 0.107634   LR 0.010000   
2022-11-03 22:58:40,215 - INFO  - Training [22][  340/  391]   Loss 0.126629   Top1 95.461857   Top5 99.972426   BatchTime 0.107120   LR 0.010000   
2022-11-03 22:58:42,185 - INFO  - Training [22][  360/  391]   Loss 0.126947   Top1 95.442708   Top5 99.971788   BatchTime 0.106640   LR 0.010000   
2022-11-03 22:58:44,133 - INFO  - Training [22][  380/  391]   Loss 0.128146   Top1 95.411184   Top5 99.973273   BatchTime 0.106154   LR 0.010000   
2022-11-03 22:58:45,591 - INFO  - ==> Top1: 95.414    Top5: 99.974    Loss: 0.128

2022-11-03 22:58:45,592 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:58:48,209 - INFO  - Validation [22][   20/   79]   Loss 0.393435   Top1 89.062500   Top5 99.492188   BatchTime 0.130729   
2022-11-03 22:58:48,909 - INFO  - Validation [22][   40/   79]   Loss 0.394641   Top1 88.769531   Top5 99.472656   BatchTime 0.082887   
2022-11-03 22:58:49,596 - INFO  - Validation [22][   60/   79]   Loss 0.383484   Top1 89.283854   Top5 99.531250   BatchTime 0.066698   
2022-11-03 22:58:50,639 - INFO  - ==> Top1: 89.060    Top5: 99.530    Loss: 0.385

2022-11-03 22:58:50,667 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:58:50,668 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 22:58:50,668 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 22:58:50,863 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:58:50,863 - INFO  - >>>>>>>> Epoch  23
2022-11-03 22:58:50,865 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:58:54,971 - INFO  - Training [23][   20/  391]   Loss 0.117790   Top1 95.703125   Top5 99.960938   BatchTime 0.205315   LR 0.010000   
2022-11-03 22:58:57,008 - INFO  - Training [23][   40/  391]   Loss 0.115982   Top1 95.917969   Top5 99.960938   BatchTime 0.153584   LR 0.010000   
2022-11-03 22:58:59,035 - INFO  - Training [23][   60/  391]   Loss 0.117073   Top1 95.963542   Top5 99.973958   BatchTime 0.136166   LR 0.010000   
2022-11-03 22:59:01,066 - INFO  - Training [23][   80/  391]   Loss 0.115760   Top1 95.898438   Top5 99.960938   BatchTime 0.127509   LR 0.010000   
2022-11-03 22:59:03,098 - INFO  - Training [23][  100/  391]   Loss 0.114543   Top1 95.914062   Top5 99.968750   BatchTime 0.122327   LR 0.010000   
2022-11-03 22:59:05,107 - INFO  - Training [23][  120/  391]   Loss 0.113398   Top1 96.022135   Top5 99.973958   BatchTime 0.118680   LR 0.010000   
2022-11-03 22:59:07,118 - INFO  - Training [23][  140/  391]   Loss 0.114011   Top1 95.970982   Top5 99.966518   BatchTime 0.116088   LR 0.010000   
2022-11-03 22:59:09,128 - INFO  - Training [23][  160/  391]   Loss 0.116474   Top1 95.849609   Top5 99.965820   BatchTime 0.114141   LR 0.010000   
2022-11-03 22:59:11,118 - INFO  - Training [23][  180/  391]   Loss 0.116353   Top1 95.881076   Top5 99.965278   BatchTime 0.112516   LR 0.010000   
2022-11-03 22:59:13,122 - INFO  - Training [23][  200/  391]   Loss 0.117882   Top1 95.820312   Top5 99.964844   BatchTime 0.111283   LR 0.010000   
2022-11-03 22:59:15,139 - INFO  - Training [23][  220/  391]   Loss 0.118061   Top1 95.777699   Top5 99.968040   BatchTime 0.110336   LR 0.010000   
2022-11-03 22:59:17,135 - INFO  - Training [23][  240/  391]   Loss 0.118968   Top1 95.751953   Top5 99.967448   BatchTime 0.109458   LR 0.010000   
2022-11-03 22:59:19,157 - INFO  - Training [23][  260/  391]   Loss 0.120195   Top1 95.706130   Top5 99.966947   BatchTime 0.108815   LR 0.010000   
2022-11-03 22:59:21,172 - INFO  - Training [23][  280/  391]   Loss 0.120957   Top1 95.700335   Top5 99.963728   BatchTime 0.108239   LR 0.010000   
2022-11-03 22:59:23,171 - INFO  - Training [23][  300/  391]   Loss 0.121875   Top1 95.653646   Top5 99.958333   BatchTime 0.107686   LR 0.010000   
2022-11-03 22:59:25,200 - INFO  - Training [23][  320/  391]   Loss 0.121303   Top1 95.688477   Top5 99.956055   BatchTime 0.107295   LR 0.010000   
2022-11-03 22:59:27,173 - INFO  - Training [23][  340/  391]   Loss 0.120942   Top1 95.710018   Top5 99.956342   BatchTime 0.106786   LR 0.010000   
2022-11-03 22:59:29,126 - INFO  - Training [23][  360/  391]   Loss 0.121038   Top1 95.683594   Top5 99.958767   BatchTime 0.106278   LR 0.010000   
2022-11-03 22:59:31,080 - INFO  - Training [23][  380/  391]   Loss 0.120500   Top1 95.711349   Top5 99.958882   BatchTime 0.105827   LR 0.010000   
2022-11-03 22:59:32,517 - INFO  - ==> Top1: 95.720    Top5: 99.960    Loss: 0.120

2022-11-03 22:59:32,518 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:59:35,146 - INFO  - Validation [23][   20/   79]   Loss 0.380415   Top1 89.570312   Top5 99.687500   BatchTime 0.131299   
2022-11-03 22:59:35,838 - INFO  - Validation [23][   40/   79]   Loss 0.388949   Top1 89.414062   Top5 99.570312   BatchTime 0.082960   
2022-11-03 22:59:36,537 - INFO  - Validation [23][   60/   79]   Loss 0.394303   Top1 89.361979   Top5 99.557292   BatchTime 0.066952   
2022-11-03 22:59:37,620 - INFO  - ==> Top1: 89.510    Top5: 99.620    Loss: 0.383

2022-11-03 22:59:37,646 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 22:59:37,647 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 22:59:37,647 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 22:59:37,797 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 22:59:37,798 - INFO  - >>>>>>>> Epoch  24
2022-11-03 22:59:37,799 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:59:41,785 - INFO  - Training [24][   20/  391]   Loss 0.110423   Top1 96.210938   Top5 100.000000   BatchTime 0.199273   LR 0.010000   
2022-11-03 22:59:43,805 - INFO  - Training [24][   40/  391]   Loss 0.108991   Top1 96.269531   Top5 99.980469   BatchTime 0.150154   LR 0.010000   
2022-11-03 22:59:45,818 - INFO  - Training [24][   60/  391]   Loss 0.111035   Top1 96.054688   Top5 99.986979   BatchTime 0.133646   LR 0.010000   
2022-11-03 22:59:47,820 - INFO  - Training [24][   80/  391]   Loss 0.108348   Top1 96.162109   Top5 99.990234   BatchTime 0.125259   LR 0.010000   
2022-11-03 22:59:49,823 - INFO  - Training [24][  100/  391]   Loss 0.108823   Top1 96.164062   Top5 99.992188   BatchTime 0.120240   LR 0.010000   
2022-11-03 22:59:51,830 - INFO  - Training [24][  120/  391]   Loss 0.109618   Top1 96.093750   Top5 99.993490   BatchTime 0.116925   LR 0.010000   
2022-11-03 22:59:53,915 - INFO  - Training [24][  140/  391]   Loss 0.108766   Top1 96.049107   Top5 99.988839   BatchTime 0.115109   LR 0.010000   
2022-11-03 22:59:55,919 - INFO  - Training [24][  160/  391]   Loss 0.108097   Top1 96.088867   Top5 99.990234   BatchTime 0.113244   LR 0.010000   
2022-11-03 22:59:57,918 - INFO  - Training [24][  180/  391]   Loss 0.109493   Top1 96.002604   Top5 99.991319   BatchTime 0.111770   LR 0.010000   
2022-11-03 22:59:59,941 - INFO  - Training [24][  200/  391]   Loss 0.113306   Top1 95.867188   Top5 99.984375   BatchTime 0.110705   LR 0.010000   
2022-11-03 23:00:01,965 - INFO  - Training [24][  220/  391]   Loss 0.112854   Top1 95.862926   Top5 99.985795   BatchTime 0.109841   LR 0.010000   
2022-11-03 23:00:03,978 - INFO  - Training [24][  240/  391]   Loss 0.113082   Top1 95.872396   Top5 99.983724   BatchTime 0.109076   LR 0.010000   
2022-11-03 23:00:05,982 - INFO  - Training [24][  260/  391]   Loss 0.112247   Top1 95.940505   Top5 99.981971   BatchTime 0.108393   LR 0.010000   
2022-11-03 23:00:07,987 - INFO  - Training [24][  280/  391]   Loss 0.111692   Top1 95.979353   Top5 99.980469   BatchTime 0.107812   LR 0.010000   
2022-11-03 23:00:09,991 - INFO  - Training [24][  300/  391]   Loss 0.113587   Top1 95.914062   Top5 99.981771   BatchTime 0.107305   LR 0.010000   
2022-11-03 23:00:11,998 - INFO  - Training [24][  320/  391]   Loss 0.114471   Top1 95.888672   Top5 99.980469   BatchTime 0.106870   LR 0.010000   
2022-11-03 23:00:13,965 - INFO  - Training [24][  340/  391]   Loss 0.114144   Top1 95.903033   Top5 99.981618   BatchTime 0.106369   LR 0.010000   
2022-11-03 23:00:15,926 - INFO  - Training [24][  360/  391]   Loss 0.115124   Top1 95.852865   Top5 99.976128   BatchTime 0.105907   LR 0.010000   
2022-11-03 23:00:17,879 - INFO  - Training [24][  380/  391]   Loss 0.115787   Top1 95.824424   Top5 99.977385   BatchTime 0.105472   LR 0.010000   
2022-11-03 23:00:19,321 - INFO  - ==> Top1: 95.824    Top5: 99.978    Loss: 0.116

2022-11-03 23:00:19,322 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:00:21,965 - INFO  - Validation [24][   20/   79]   Loss 0.379836   Top1 89.570312   Top5 99.570312   BatchTime 0.132071   
2022-11-03 23:00:22,662 - INFO  - Validation [24][   40/   79]   Loss 0.376584   Top1 89.492188   Top5 99.492188   BatchTime 0.083472   
2022-11-03 23:00:23,359 - INFO  - Validation [24][   60/   79]   Loss 0.374031   Top1 89.583333   Top5 99.544271   BatchTime 0.067262   
2022-11-03 23:00:24,420 - INFO  - ==> Top1: 89.460    Top5: 99.560    Loss: 0.371

2022-11-03 23:00:24,445 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:00:24,446 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 23:00:24,446 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 23:00:24,556 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:00:24,556 - INFO  - >>>>>>>> Epoch  25
2022-11-03 23:00:24,558 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:00:28,606 - INFO  - Training [25][   20/  391]   Loss 0.112501   Top1 95.703125   Top5 100.000000   BatchTime 0.202393   LR 0.010000   
2022-11-03 23:00:30,643 - INFO  - Training [25][   40/  391]   Loss 0.110183   Top1 95.878906   Top5 99.980469   BatchTime 0.152138   LR 0.010000   
2022-11-03 23:00:32,625 - INFO  - Training [25][   60/  391]   Loss 0.108459   Top1 95.989583   Top5 99.986979   BatchTime 0.134451   LR 0.010000   
2022-11-03 23:00:34,641 - INFO  - Training [25][   80/  391]   Loss 0.109082   Top1 95.888672   Top5 99.990234   BatchTime 0.126045   LR 0.010000   
2022-11-03 23:00:36,635 - INFO  - Training [25][  100/  391]   Loss 0.110052   Top1 95.875000   Top5 99.984375   BatchTime 0.120774   LR 0.010000   
2022-11-03 23:00:38,650 - INFO  - Training [25][  120/  391]   Loss 0.109395   Top1 95.885417   Top5 99.980469   BatchTime 0.117435   LR 0.010000   
2022-11-03 23:00:40,658 - INFO  - Training [25][  140/  391]   Loss 0.108390   Top1 95.959821   Top5 99.977679   BatchTime 0.114998   LR 0.010000   
2022-11-03 23:00:42,700 - INFO  - Training [25][  160/  391]   Loss 0.108424   Top1 95.996094   Top5 99.965820   BatchTime 0.113390   LR 0.010000   
2022-11-03 23:00:44,705 - INFO  - Training [25][  180/  391]   Loss 0.108881   Top1 96.006944   Top5 99.965278   BatchTime 0.111929   LR 0.010000   
2022-11-03 23:00:46,724 - INFO  - Training [25][  200/  391]   Loss 0.108678   Top1 96.011719   Top5 99.953125   BatchTime 0.110829   LR 0.010000   
2022-11-03 23:00:48,738 - INFO  - Training [25][  220/  391]   Loss 0.109685   Top1 95.962358   Top5 99.950284   BatchTime 0.109911   LR 0.010000   
2022-11-03 23:00:50,736 - INFO  - Training [25][  240/  391]   Loss 0.110584   Top1 95.966797   Top5 99.944661   BatchTime 0.109073   LR 0.010000   
2022-11-03 23:00:52,745 - INFO  - Training [25][  260/  391]   Loss 0.110551   Top1 96.000601   Top5 99.948918   BatchTime 0.108410   LR 0.010000   
2022-11-03 23:00:54,757 - INFO  - Training [25][  280/  391]   Loss 0.109813   Top1 96.021205   Top5 99.952567   BatchTime 0.107851   LR 0.010000   
2022-11-03 23:00:56,759 - INFO  - Training [25][  300/  391]   Loss 0.110106   Top1 96.002604   Top5 99.955729   BatchTime 0.107335   LR 0.010000   
2022-11-03 23:00:58,772 - INFO  - Training [25][  320/  391]   Loss 0.110683   Top1 95.969238   Top5 99.956055   BatchTime 0.106917   LR 0.010000   
2022-11-03 23:01:00,745 - INFO  - Training [25][  340/  391]   Loss 0.110450   Top1 95.994945   Top5 99.956342   BatchTime 0.106432   LR 0.010000   
2022-11-03 23:01:02,704 - INFO  - Training [25][  360/  391]   Loss 0.111760   Top1 95.950521   Top5 99.956597   BatchTime 0.105959   LR 0.010000   
2022-11-03 23:01:04,660 - INFO  - Training [25][  380/  391]   Loss 0.112285   Top1 95.929276   Top5 99.958882   BatchTime 0.105531   LR 0.010000   
2022-11-03 23:01:06,102 - INFO  - ==> Top1: 95.924    Top5: 99.960    Loss: 0.113

2022-11-03 23:01:06,103 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:01:08,735 - INFO  - Validation [25][   20/   79]   Loss 0.381800   Top1 90.039062   Top5 99.492188   BatchTime 0.131559   
2022-11-03 23:01:09,430 - INFO  - Validation [25][   40/   79]   Loss 0.387236   Top1 89.589844   Top5 99.414062   BatchTime 0.083132   
2022-11-03 23:01:10,128 - INFO  - Validation [25][   60/   79]   Loss 0.384880   Top1 89.622396   Top5 99.505208   BatchTime 0.067069   
2022-11-03 23:01:11,210 - INFO  - ==> Top1: 89.580    Top5: 99.510    Loss: 0.380

2022-11-03 23:01:11,236 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:01:11,237 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 23:01:11,237 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 23:01:11,352 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:01:11,352 - INFO  - >>>>>>>> Epoch  26
2022-11-03 23:01:11,354 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:01:15,438 - INFO  - Training [26][   20/  391]   Loss 0.110082   Top1 95.976562   Top5 100.000000   BatchTime 0.204200   LR 0.010000   
2022-11-03 23:01:17,452 - INFO  - Training [26][   40/  391]   Loss 0.116854   Top1 95.664062   Top5 100.000000   BatchTime 0.152462   LR 0.010000   
2022-11-03 23:01:19,483 - INFO  - Training [26][   60/  391]   Loss 0.118566   Top1 95.638021   Top5 100.000000   BatchTime 0.135491   LR 0.010000   
2022-11-03 23:01:21,488 - INFO  - Training [26][   80/  391]   Loss 0.121848   Top1 95.556641   Top5 100.000000   BatchTime 0.126679   LR 0.010000   
2022-11-03 23:01:23,508 - INFO  - Training [26][  100/  391]   Loss 0.122135   Top1 95.562500   Top5 100.000000   BatchTime 0.121535   LR 0.010000   
2022-11-03 23:01:25,510 - INFO  - Training [26][  120/  391]   Loss 0.121597   Top1 95.572917   Top5 100.000000   BatchTime 0.117965   LR 0.010000   
2022-11-03 23:01:27,510 - INFO  - Training [26][  140/  391]   Loss 0.123082   Top1 95.507812   Top5 100.000000   BatchTime 0.115400   LR 0.010000   
2022-11-03 23:01:29,613 - INFO  - Training [26][  160/  391]   Loss 0.126008   Top1 95.395508   Top5 100.000000   BatchTime 0.114118   LR 0.010000   
2022-11-03 23:01:31,561 - INFO  - Training [26][  180/  391]   Loss 0.126646   Top1 95.416667   Top5 99.991319   BatchTime 0.112259   LR 0.010000   
2022-11-03 23:01:33,585 - INFO  - Training [26][  200/  391]   Loss 0.125159   Top1 95.492188   Top5 99.992188   BatchTime 0.111153   LR 0.010000   
2022-11-03 23:01:35,562 - INFO  - Training [26][  220/  391]   Loss 0.125933   Top1 95.475852   Top5 99.992898   BatchTime 0.110036   LR 0.010000   
2022-11-03 23:01:37,573 - INFO  - Training [26][  240/  391]   Loss 0.127368   Top1 95.445964   Top5 99.986979   BatchTime 0.109244   LR 0.010000   
2022-11-03 23:01:39,569 - INFO  - Training [26][  260/  391]   Loss 0.127627   Top1 95.423678   Top5 99.978966   BatchTime 0.108516   LR 0.010000   
2022-11-03 23:01:41,576 - INFO  - Training [26][  280/  391]   Loss 0.127917   Top1 95.429688   Top5 99.980469   BatchTime 0.107935   LR 0.010000   
2022-11-03 23:01:43,572 - INFO  - Training [26][  300/  391]   Loss 0.127743   Top1 95.432292   Top5 99.981771   BatchTime 0.107391   LR 0.010000   
2022-11-03 23:01:45,583 - INFO  - Training [26][  320/  391]   Loss 0.129128   Top1 95.378418   Top5 99.982910   BatchTime 0.106963   LR 0.010000   
2022-11-03 23:01:47,554 - INFO  - Training [26][  340/  391]   Loss 0.128731   Top1 95.411305   Top5 99.981618   BatchTime 0.106470   LR 0.010000   
2022-11-03 23:01:49,510 - INFO  - Training [26][  360/  391]   Loss 0.129579   Top1 95.390625   Top5 99.978299   BatchTime 0.105987   LR 0.010000   
2022-11-03 23:01:51,457 - INFO  - Training [26][  380/  391]   Loss 0.130219   Top1 95.388569   Top5 99.977385   BatchTime 0.105534   LR 0.010000   
2022-11-03 23:01:52,992 - INFO  - ==> Top1: 95.374    Top5: 99.974    Loss: 0.131

2022-11-03 23:01:52,993 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:01:55,669 - INFO  - Validation [26][   20/   79]   Loss 0.389176   Top1 89.375000   Top5 99.453125   BatchTime 0.133713   
2022-11-03 23:01:56,373 - INFO  - Validation [26][   40/   79]   Loss 0.388449   Top1 89.335938   Top5 99.355469   BatchTime 0.084448   
2022-11-03 23:01:57,063 - INFO  - Validation [26][   60/   79]   Loss 0.388167   Top1 89.427083   Top5 99.453125   BatchTime 0.067808   
2022-11-03 23:01:58,057 - INFO  - ==> Top1: 89.350    Top5: 99.510    Loss: 0.384

2022-11-03 23:01:58,080 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:01:58,081 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 23:01:58,081 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 23:01:58,272 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:01:58,272 - INFO  - >>>>>>>> Epoch  27
2022-11-03 23:01:58,274 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:02:02,269 - INFO  - Training [27][   20/  391]   Loss 0.138827   Top1 94.609375   Top5 99.960938   BatchTime 0.199743   LR 0.010000   
2022-11-03 23:02:04,293 - INFO  - Training [27][   40/  391]   Loss 0.135858   Top1 94.687500   Top5 99.980469   BatchTime 0.150474   LR 0.010000   
2022-11-03 23:02:06,316 - INFO  - Training [27][   60/  391]   Loss 0.137132   Top1 94.921875   Top5 99.973958   BatchTime 0.134045   LR 0.010000   
2022-11-03 23:02:08,325 - INFO  - Training [27][   80/  391]   Loss 0.133830   Top1 95.126953   Top5 99.980469   BatchTime 0.125638   LR 0.010000   
2022-11-03 23:02:10,347 - INFO  - Training [27][  100/  391]   Loss 0.132823   Top1 95.234375   Top5 99.960938   BatchTime 0.120731   LR 0.010000   
2022-11-03 23:02:12,352 - INFO  - Training [27][  120/  391]   Loss 0.133808   Top1 95.247396   Top5 99.967448   BatchTime 0.117317   LR 0.010000   
2022-11-03 23:02:14,377 - INFO  - Training [27][  140/  391]   Loss 0.132896   Top1 95.262277   Top5 99.972098   BatchTime 0.115024   LR 0.010000   
2022-11-03 23:02:16,380 - INFO  - Training [27][  160/  391]   Loss 0.131523   Top1 95.317383   Top5 99.975586   BatchTime 0.113160   LR 0.010000   
2022-11-03 23:02:18,392 - INFO  - Training [27][  180/  391]   Loss 0.131141   Top1 95.342882   Top5 99.978299   BatchTime 0.111765   LR 0.010000   
2022-11-03 23:02:20,409 - INFO  - Training [27][  200/  391]   Loss 0.132240   Top1 95.304688   Top5 99.980469   BatchTime 0.110674   LR 0.010000   
2022-11-03 23:02:22,410 - INFO  - Training [27][  220/  391]   Loss 0.131088   Top1 95.362216   Top5 99.982244   BatchTime 0.109711   LR 0.010000   
2022-11-03 23:02:24,393 - INFO  - Training [27][  240/  391]   Loss 0.130275   Top1 95.345052   Top5 99.980469   BatchTime 0.108830   LR 0.010000   
2022-11-03 23:02:26,413 - INFO  - Training [27][  260/  391]   Loss 0.130096   Top1 95.342548   Top5 99.981971   BatchTime 0.108227   LR 0.010000   
2022-11-03 23:02:28,437 - INFO  - Training [27][  280/  391]   Loss 0.130043   Top1 95.334821   Top5 99.983259   BatchTime 0.107723   LR 0.010000   
2022-11-03 23:02:30,457 - INFO  - Training [27][  300/  391]   Loss 0.130491   Top1 95.286458   Top5 99.984375   BatchTime 0.107276   LR 0.010000   
2022-11-03 23:02:32,488 - INFO  - Training [27][  320/  391]   Loss 0.130680   Top1 95.270996   Top5 99.982910   BatchTime 0.106918   LR 0.010000   
2022-11-03 23:02:34,451 - INFO  - Training [27][  340/  391]   Loss 0.130430   Top1 95.284926   Top5 99.983915   BatchTime 0.106402   LR 0.010000   
2022-11-03 23:02:36,396 - INFO  - Training [27][  360/  391]   Loss 0.130485   Top1 95.284288   Top5 99.984809   BatchTime 0.105892   LR 0.010000   
2022-11-03 23:02:38,344 - INFO  - Training [27][  380/  391]   Loss 0.131007   Top1 95.271382   Top5 99.983553   BatchTime 0.105447   LR 0.010000   
2022-11-03 23:02:39,782 - INFO  - ==> Top1: 95.274    Top5: 99.982    Loss: 0.131

2022-11-03 23:02:39,783 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:02:42,440 - INFO  - Validation [27][   20/   79]   Loss 0.409836   Top1 88.632812   Top5 99.531250   BatchTime 0.132783   
2022-11-03 23:02:43,138 - INFO  - Validation [27][   40/   79]   Loss 0.407618   Top1 88.593750   Top5 99.453125   BatchTime 0.083836   
2022-11-03 23:02:43,831 - INFO  - Validation [27][   60/   79]   Loss 0.402655   Top1 88.958333   Top5 99.518229   BatchTime 0.067444   
2022-11-03 23:02:44,905 - INFO  - ==> Top1: 88.940    Top5: 99.570    Loss: 0.396

2022-11-03 23:02:44,933 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:02:44,934 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 23:02:44,934 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 23:02:45,066 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:02:45,066 - INFO  - >>>>>>>> Epoch  28
2022-11-03 23:02:45,067 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:02:49,113 - INFO  - Training [28][   20/  391]   Loss 0.125441   Top1 95.820312   Top5 99.960938   BatchTime 0.202287   LR 0.010000   
2022-11-03 23:02:51,119 - INFO  - Training [28][   40/  391]   Loss 0.119644   Top1 95.839844   Top5 99.980469   BatchTime 0.151308   LR 0.010000   
2022-11-03 23:02:53,121 - INFO  - Training [28][   60/  391]   Loss 0.128358   Top1 95.390625   Top5 99.973958   BatchTime 0.134239   LR 0.010000   
2022-11-03 23:02:55,140 - INFO  - Training [28][   80/  391]   Loss 0.126359   Top1 95.556641   Top5 99.970703   BatchTime 0.125907   LR 0.010000   
2022-11-03 23:02:57,139 - INFO  - Training [28][  100/  391]   Loss 0.123654   Top1 95.656250   Top5 99.976562   BatchTime 0.120721   LR 0.010000   
2022-11-03 23:02:59,155 - INFO  - Training [28][  120/  391]   Loss 0.123769   Top1 95.631510   Top5 99.973958   BatchTime 0.117397   LR 0.010000   
2022-11-03 23:03:01,169 - INFO  - Training [28][  140/  391]   Loss 0.120832   Top1 95.809152   Top5 99.972098   BatchTime 0.115014   LR 0.010000   
2022-11-03 23:03:03,170 - INFO  - Training [28][  160/  391]   Loss 0.121700   Top1 95.742188   Top5 99.970703   BatchTime 0.113142   LR 0.010000   
2022-11-03 23:03:05,177 - INFO  - Training [28][  180/  391]   Loss 0.121841   Top1 95.750868   Top5 99.969618   BatchTime 0.111721   LR 0.010000   
2022-11-03 23:03:07,187 - INFO  - Training [28][  200/  391]   Loss 0.122254   Top1 95.738281   Top5 99.968750   BatchTime 0.110598   LR 0.010000   
2022-11-03 23:03:09,274 - INFO  - Training [28][  220/  391]   Loss 0.121719   Top1 95.788352   Top5 99.968040   BatchTime 0.110032   LR 0.010000   
2022-11-03 23:03:11,220 - INFO  - Training [28][  240/  391]   Loss 0.120252   Top1 95.846354   Top5 99.960938   BatchTime 0.108968   LR 0.010000   
2022-11-03 23:03:13,227 - INFO  - Training [28][  260/  391]   Loss 0.119779   Top1 95.847356   Top5 99.960938   BatchTime 0.108308   LR 0.010000   
2022-11-03 23:03:15,213 - INFO  - Training [28][  280/  391]   Loss 0.120009   Top1 95.831473   Top5 99.960938   BatchTime 0.107664   LR 0.010000   
2022-11-03 23:03:17,205 - INFO  - Training [28][  300/  391]   Loss 0.119817   Top1 95.830729   Top5 99.963542   BatchTime 0.107125   LR 0.010000   
2022-11-03 23:03:19,209 - INFO  - Training [28][  320/  391]   Loss 0.121110   Top1 95.781250   Top5 99.960938   BatchTime 0.106692   LR 0.010000   
2022-11-03 23:03:21,177 - INFO  - Training [28][  340/  391]   Loss 0.121666   Top1 95.769761   Top5 99.960938   BatchTime 0.106204   LR 0.010000   
2022-11-03 23:03:23,138 - INFO  - Training [28][  360/  391]   Loss 0.121162   Top1 95.766059   Top5 99.958767   BatchTime 0.105751   LR 0.010000   
2022-11-03 23:03:25,102 - INFO  - Training [28][  380/  391]   Loss 0.121753   Top1 95.762747   Top5 99.958882   BatchTime 0.105354   LR 0.010000   
2022-11-03 23:03:26,630 - INFO  - ==> Top1: 95.746    Top5: 99.960    Loss: 0.122

2022-11-03 23:03:26,631 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:03:29,294 - INFO  - Validation [28][   20/   79]   Loss 0.373312   Top1 89.179688   Top5 99.609375   BatchTime 0.133117   
2022-11-03 23:03:29,988 - INFO  - Validation [28][   40/   79]   Loss 0.375815   Top1 89.296875   Top5 99.609375   BatchTime 0.083900   
2022-11-03 23:03:30,677 - INFO  - Validation [28][   60/   79]   Loss 0.369120   Top1 89.700521   Top5 99.648438   BatchTime 0.067413   
2022-11-03 23:03:31,784 - INFO  - ==> Top1: 89.560    Top5: 99.660    Loss: 0.368

2022-11-03 23:03:31,812 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:03:31,813 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 23:03:31,813 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.600   Top5: 99.580] Sparsity : 0.825
2022-11-03 23:03:31,948 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:03:31,948 - INFO  - >>>>>>>> Epoch  29
2022-11-03 23:03:31,950 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:03:36,034 - INFO  - Training [29][   20/  391]   Loss 0.104757   Top1 96.171875   Top5 100.000000   BatchTime 0.204206   LR 0.010000   
2022-11-03 23:03:38,058 - INFO  - Training [29][   40/  391]   Loss 0.102313   Top1 96.289062   Top5 100.000000   BatchTime 0.152692   LR 0.010000   
2022-11-03 23:03:40,070 - INFO  - Training [29][   60/  391]   Loss 0.103839   Top1 96.184896   Top5 99.986979   BatchTime 0.135332   LR 0.010000   
2022-11-03 23:03:42,111 - INFO  - Training [29][   80/  391]   Loss 0.108060   Top1 95.996094   Top5 99.990234   BatchTime 0.127013   LR 0.010000   
2022-11-03 23:03:44,145 - INFO  - Training [29][  100/  391]   Loss 0.109127   Top1 96.023438   Top5 99.976562   BatchTime 0.121954   LR 0.010000   
2022-11-03 23:03:46,166 - INFO  - Training [29][  120/  391]   Loss 0.108320   Top1 96.041667   Top5 99.980469   BatchTime 0.118463   LR 0.010000   
2022-11-03 23:03:48,179 - INFO  - Training [29][  140/  391]   Loss 0.109587   Top1 96.010045   Top5 99.977679   BatchTime 0.115923   LR 0.010000   
2022-11-03 23:03:50,198 - INFO  - Training [29][  160/  391]   Loss 0.112263   Top1 95.942383   Top5 99.975586   BatchTime 0.114050   LR 0.010000   
2022-11-03 23:03:52,228 - INFO  - Training [29][  180/  391]   Loss 0.113195   Top1 95.885417   Top5 99.978299   BatchTime 0.112653   LR 0.010000   
2022-11-03 23:03:54,237 - INFO  - Training [29][  200/  391]   Loss 0.114340   Top1 95.859375   Top5 99.972656   BatchTime 0.111434   LR 0.010000   
2022-11-03 23:03:56,245 - INFO  - Training [29][  220/  391]   Loss 0.114383   Top1 95.880682   Top5 99.975142   BatchTime 0.110432   LR 0.010000   
2022-11-03 23:03:58,256 - INFO  - Training [29][  240/  391]   Loss 0.114426   Top1 95.878906   Top5 99.977214   BatchTime 0.109609   LR 0.010000   
2022-11-03 23:04:00,281 - INFO  - Training [29][  260/  391]   Loss 0.115146   Top1 95.841346   Top5 99.972957   BatchTime 0.108965   LR 0.010000   
2022-11-03 23:04:02,293 - INFO  - Training [29][  280/  391]   Loss 0.115378   Top1 95.862165   Top5 99.966518   BatchTime 0.108366   LR 0.010000   
2022-11-03 23:04:04,309 - INFO  - Training [29][  300/  391]   Loss 0.113996   Top1 95.929688   Top5 99.968750   BatchTime 0.107863   LR 0.010000   
2022-11-03 23:04:06,320 - INFO  - Training [29][  320/  391]   Loss 0.115180   Top1 95.910645   Top5 99.970703   BatchTime 0.107406   LR 0.010000   
2022-11-03 23:04:08,293 - INFO  - Training [29][  340/  391]   Loss 0.115386   Top1 95.914522   Top5 99.970129   BatchTime 0.106888   LR 0.010000   
2022-11-03 23:04:10,247 - INFO  - Training [29][  360/  391]   Loss 0.115499   Top1 95.922309   Top5 99.971788   BatchTime 0.106379   LR 0.010000   
2022-11-03 23:04:12,209 - INFO  - Training [29][  380/  391]   Loss 0.115794   Top1 95.875822   Top5 99.971217   BatchTime 0.105943   LR 0.010000   
2022-11-03 23:04:13,643 - INFO  - ==> Top1: 95.854    Top5: 99.972    Loss: 0.116

2022-11-03 23:04:13,644 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:04:16,290 - INFO  - Validation [29][   20/   79]   Loss 0.376043   Top1 89.414062   Top5 99.648438   BatchTime 0.132212   
2022-11-03 23:04:16,995 - INFO  - Validation [29][   40/   79]   Loss 0.378178   Top1 89.414062   Top5 99.570312   BatchTime 0.083736   
2022-11-03 23:04:17,692 - INFO  - Validation [29][   60/   79]   Loss 0.368832   Top1 89.648438   Top5 99.609375   BatchTime 0.067436   
2022-11-03 23:04:18,811 - INFO  - ==> Top1: 89.740    Top5: 99.620    Loss: 0.367

2022-11-03 23:04:18,834 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:04:18,835 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 89.740   Top5: 99.620] Sparsity : 0.848
2022-11-03 23:04:18,835 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 89.660   Top5: 99.540] Sparsity : 0.823
2022-11-03 23:04:18,996 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:04:18,996 - INFO  - >>>>>>>> Epoch  30
2022-11-03 23:04:18,998 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:04:23,095 - INFO  - Training [30][   20/  391]   Loss 0.102626   Top1 96.406250   Top5 99.960938   BatchTime 0.204837   LR 0.001000   
2022-11-03 23:04:25,105 - INFO  - Training [30][   40/  391]   Loss 0.101392   Top1 96.328125   Top5 99.980469   BatchTime 0.152673   LR 0.001000   
2022-11-03 23:04:27,118 - INFO  - Training [30][   60/  391]   Loss 0.095439   Top1 96.523438   Top5 99.973958   BatchTime 0.135327   LR 0.001000   
2022-11-03 23:04:29,142 - INFO  - Training [30][   80/  391]   Loss 0.098490   Top1 96.337891   Top5 99.980469   BatchTime 0.126796   LR 0.001000   
2022-11-03 23:04:31,173 - INFO  - Training [30][  100/  391]   Loss 0.099320   Top1 96.289062   Top5 99.984375   BatchTime 0.121748   LR 0.001000   
2022-11-03 23:04:33,206 - INFO  - Training [30][  120/  391]   Loss 0.098273   Top1 96.360677   Top5 99.986979   BatchTime 0.118396   LR 0.001000   
2022-11-03 23:04:35,232 - INFO  - Training [30][  140/  391]   Loss 0.097471   Top1 96.406250   Top5 99.983259   BatchTime 0.115954   LR 0.001000   
2022-11-03 23:04:37,236 - INFO  - Training [30][  160/  391]   Loss 0.096620   Top1 96.489258   Top5 99.985352   BatchTime 0.113987   LR 0.001000   
2022-11-03 23:04:39,235 - INFO  - Training [30][  180/  391]   Loss 0.096748   Top1 96.436632   Top5 99.982639   BatchTime 0.112428   LR 0.001000   
2022-11-03 23:04:41,240 - INFO  - Training [30][  200/  391]   Loss 0.097240   Top1 96.449219   Top5 99.984375   BatchTime 0.111207   LR 0.001000   
2022-11-03 23:04:43,258 - INFO  - Training [30][  220/  391]   Loss 0.097090   Top1 96.473722   Top5 99.985795   BatchTime 0.110271   LR 0.001000   
2022-11-03 23:04:45,258 - INFO  - Training [30][  240/  391]   Loss 0.097201   Top1 96.474609   Top5 99.986979   BatchTime 0.109416   LR 0.001000   
2022-11-03 23:04:47,271 - INFO  - Training [30][  260/  391]   Loss 0.098203   Top1 96.460337   Top5 99.981971   BatchTime 0.108740   LR 0.001000   
2022-11-03 23:04:49,412 - INFO  - Training [30][  280/  391]   Loss 0.098468   Top1 96.459263   Top5 99.983259   BatchTime 0.108621   LR 0.001000   
2022-11-03 23:04:51,439 - INFO  - Training [30][  300/  391]   Loss 0.097634   Top1 96.502604   Top5 99.981771   BatchTime 0.108135   LR 0.001000   
2022-11-03 23:04:53,436 - INFO  - Training [30][  320/  391]   Loss 0.097275   Top1 96.523438   Top5 99.982910   BatchTime 0.107618   LR 0.001000   
2022-11-03 23:04:55,423 - INFO  - Training [30][  340/  391]   Loss 0.096734   Top1 96.534926   Top5 99.983915   BatchTime 0.107130   LR 0.001000   
2022-11-03 23:04:57,379 - INFO  - Training [30][  360/  391]   Loss 0.096851   Top1 96.527778   Top5 99.984809   BatchTime 0.106612   LR 0.001000   
2022-11-03 23:04:59,342 - INFO  - Training [30][  380/  391]   Loss 0.096038   Top1 96.581003   Top5 99.983553   BatchTime 0.106166   LR 0.001000   
2022-11-03 23:05:00,749 - INFO  - ==> Top1: 96.582    Top5: 99.982    Loss: 0.096

2022-11-03 23:05:00,749 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:05:03,393 - INFO  - Validation [30][   20/   79]   Loss 0.358104   Top1 90.546875   Top5 99.648438   BatchTime 0.132111   
2022-11-03 23:05:04,090 - INFO  - Validation [30][   40/   79]   Loss 0.366437   Top1 90.253906   Top5 99.628906   BatchTime 0.083479   
2022-11-03 23:05:04,790 - INFO  - Validation [30][   60/   79]   Loss 0.358299   Top1 90.468750   Top5 99.648438   BatchTime 0.067324   
2022-11-03 23:05:05,743 - INFO  - ==> Top1: 90.260    Top5: 99.690    Loss: 0.356

2022-11-03 23:05:05,769 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.260   Top5: 99.690] Sparsity : 0.848
2022-11-03 23:05:05,770 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:05:05,770 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.740   Top5: 99.620] Sparsity : 0.848
2022-11-03 23:05:05,939 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:05:05,939 - INFO  - >>>>>>>> Epoch  31
2022-11-03 23:05:05,940 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:05:09,920 - INFO  - Training [31][   20/  391]   Loss 0.091271   Top1 96.757812   Top5 100.000000   BatchTime 0.199002   LR 0.001000   
2022-11-03 23:05:11,936 - INFO  - Training [31][   40/  391]   Loss 0.091410   Top1 96.835938   Top5 100.000000   BatchTime 0.149899   LR 0.001000   
2022-11-03 23:05:13,965 - INFO  - Training [31][   60/  391]   Loss 0.092435   Top1 96.757812   Top5 100.000000   BatchTime 0.133752   LR 0.001000   
2022-11-03 23:05:15,967 - INFO  - Training [31][   80/  391]   Loss 0.090692   Top1 96.845703   Top5 99.990234   BatchTime 0.125339   LR 0.001000   
2022-11-03 23:05:17,980 - INFO  - Training [31][  100/  391]   Loss 0.091235   Top1 96.804688   Top5 99.992188   BatchTime 0.120395   LR 0.001000   
2022-11-03 23:05:19,984 - INFO  - Training [31][  120/  391]   Loss 0.090322   Top1 96.855469   Top5 99.986979   BatchTime 0.117032   LR 0.001000   
2022-11-03 23:05:21,988 - INFO  - Training [31][  140/  391]   Loss 0.089372   Top1 96.852679   Top5 99.988839   BatchTime 0.114628   LR 0.001000   
2022-11-03 23:05:24,007 - INFO  - Training [31][  160/  391]   Loss 0.089936   Top1 96.767578   Top5 99.990234   BatchTime 0.112915   LR 0.001000   
2022-11-03 23:05:26,022 - INFO  - Training [31][  180/  391]   Loss 0.088930   Top1 96.818576   Top5 99.991319   BatchTime 0.111565   LR 0.001000   
2022-11-03 23:05:28,071 - INFO  - Training [31][  200/  391]   Loss 0.087869   Top1 96.882812   Top5 99.992188   BatchTime 0.110650   LR 0.001000   
2022-11-03 23:05:30,120 - INFO  - Training [31][  220/  391]   Loss 0.088090   Top1 96.832386   Top5 99.992898   BatchTime 0.109904   LR 0.001000   
2022-11-03 23:05:32,127 - INFO  - Training [31][  240/  391]   Loss 0.087536   Top1 96.858724   Top5 99.993490   BatchTime 0.109111   LR 0.001000   
2022-11-03 23:05:34,145 - INFO  - Training [31][  260/  391]   Loss 0.086963   Top1 96.878005   Top5 99.993990   BatchTime 0.108477   LR 0.001000   
2022-11-03 23:05:36,159 - INFO  - Training [31][  280/  391]   Loss 0.086142   Top1 96.902902   Top5 99.994420   BatchTime 0.107922   LR 0.001000   
2022-11-03 23:05:38,157 - INFO  - Training [31][  300/  391]   Loss 0.086189   Top1 96.898438   Top5 99.994792   BatchTime 0.107389   LR 0.001000   
2022-11-03 23:05:40,177 - INFO  - Training [31][  320/  391]   Loss 0.085463   Top1 96.931152   Top5 99.995117   BatchTime 0.106989   LR 0.001000   
2022-11-03 23:05:42,143 - INFO  - Training [31][  340/  391]   Loss 0.085438   Top1 96.918658   Top5 99.995404   BatchTime 0.106476   LR 0.001000   
2022-11-03 23:05:44,099 - INFO  - Training [31][  360/  391]   Loss 0.085847   Top1 96.922743   Top5 99.995660   BatchTime 0.105994   LR 0.001000   
2022-11-03 23:05:46,044 - INFO  - Training [31][  380/  391]   Loss 0.086627   Top1 96.889391   Top5 99.993832   BatchTime 0.105534   LR 0.001000   
2022-11-03 23:05:47,409 - INFO  - ==> Top1: 96.896    Top5: 99.994    Loss: 0.086

2022-11-03 23:05:47,410 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:05:50,069 - INFO  - Validation [31][   20/   79]   Loss 0.357445   Top1 90.546875   Top5 99.609375   BatchTime 0.132848   
2022-11-03 23:05:50,767 - INFO  - Validation [31][   40/   79]   Loss 0.367186   Top1 90.371094   Top5 99.511719   BatchTime 0.083864   
2022-11-03 23:05:51,460 - INFO  - Validation [31][   60/   79]   Loss 0.356979   Top1 90.742188   Top5 99.570312   BatchTime 0.067473   
2022-11-03 23:05:52,351 - INFO  - ==> Top1: 90.440    Top5: 99.590    Loss: 0.358

2022-11-03 23:05:52,383 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:05:52,384 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.260   Top5: 99.690] Sparsity : 0.848
2022-11-03 23:05:52,384 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 89.900   Top5: 99.600] Sparsity : 0.822
2022-11-03 23:05:52,544 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:05:52,545 - INFO  - >>>>>>>> Epoch  32
2022-11-03 23:05:52,546 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:05:56,513 - INFO  - Training [32][   20/  391]   Loss 0.075228   Top1 97.460938   Top5 100.000000   BatchTime 0.198363   LR 0.001000   
2022-11-03 23:05:58,554 - INFO  - Training [32][   40/  391]   Loss 0.083002   Top1 97.285156   Top5 99.980469   BatchTime 0.150213   LR 0.001000   
2022-11-03 23:06:00,571 - INFO  - Training [32][   60/  391]   Loss 0.082473   Top1 97.330729   Top5 99.986979   BatchTime 0.133751   LR 0.001000   
2022-11-03 23:06:02,592 - INFO  - Training [32][   80/  391]   Loss 0.082722   Top1 97.304688   Top5 99.990234   BatchTime 0.125580   LR 0.001000   
2022-11-03 23:06:04,614 - INFO  - Training [32][  100/  391]   Loss 0.085095   Top1 97.195312   Top5 99.992188   BatchTime 0.120683   LR 0.001000   
2022-11-03 23:06:06,621 - INFO  - Training [32][  120/  391]   Loss 0.084569   Top1 97.200521   Top5 99.993490   BatchTime 0.117295   LR 0.001000   
2022-11-03 23:06:08,611 - INFO  - Training [32][  140/  391]   Loss 0.084346   Top1 97.209821   Top5 99.988839   BatchTime 0.114750   LR 0.001000   
2022-11-03 23:06:10,615 - INFO  - Training [32][  160/  391]   Loss 0.085313   Top1 97.143555   Top5 99.990234   BatchTime 0.112931   LR 0.001000   
2022-11-03 23:06:12,633 - INFO  - Training [32][  180/  391]   Loss 0.084787   Top1 97.122396   Top5 99.982639   BatchTime 0.111593   LR 0.001000   
2022-11-03 23:06:14,636 - INFO  - Training [32][  200/  391]   Loss 0.086148   Top1 97.062500   Top5 99.980469   BatchTime 0.110449   LR 0.001000   
2022-11-03 23:06:16,664 - INFO  - Training [32][  220/  391]   Loss 0.086823   Top1 97.024148   Top5 99.982244   BatchTime 0.109628   LR 0.001000   
2022-11-03 23:06:18,699 - INFO  - Training [32][  240/  391]   Loss 0.086066   Top1 97.047526   Top5 99.983724   BatchTime 0.108972   LR 0.001000   
2022-11-03 23:06:20,726 - INFO  - Training [32][  260/  391]   Loss 0.086224   Top1 97.058293   Top5 99.981971   BatchTime 0.108383   LR 0.001000   
2022-11-03 23:06:22,759 - INFO  - Training [32][  280/  391]   Loss 0.085650   Top1 97.092634   Top5 99.983259   BatchTime 0.107904   LR 0.001000   
2022-11-03 23:06:24,788 - INFO  - Training [32][  300/  391]   Loss 0.085537   Top1 97.080729   Top5 99.981771   BatchTime 0.107471   LR 0.001000   
2022-11-03 23:06:26,902 - INFO  - Training [32][  320/  391]   Loss 0.085025   Top1 97.084961   Top5 99.982910   BatchTime 0.107360   LR 0.001000   
2022-11-03 23:06:28,879 - INFO  - Training [32][  340/  391]   Loss 0.085528   Top1 97.058824   Top5 99.979320   BatchTime 0.106860   LR 0.001000   
2022-11-03 23:06:30,839 - INFO  - Training [32][  360/  391]   Loss 0.085712   Top1 97.057292   Top5 99.978299   BatchTime 0.106368   LR 0.001000   
2022-11-03 23:06:32,786 - INFO  - Training [32][  380/  391]   Loss 0.086259   Top1 97.045641   Top5 99.979441   BatchTime 0.105894   LR 0.001000   
2022-11-03 23:06:34,155 - INFO  - ==> Top1: 97.040    Top5: 99.980    Loss: 0.086

2022-11-03 23:06:34,155 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:06:36,801 - INFO  - Validation [32][   20/   79]   Loss 0.362169   Top1 90.781250   Top5 99.570312   BatchTime 0.132254   
2022-11-03 23:06:37,500 - INFO  - Validation [32][   40/   79]   Loss 0.365793   Top1 90.410156   Top5 99.589844   BatchTime 0.083588   
2022-11-03 23:06:38,193 - INFO  - Validation [32][   60/   79]   Loss 0.356662   Top1 90.625000   Top5 99.622396   BatchTime 0.067278   
2022-11-03 23:06:39,110 - INFO  - ==> Top1: 90.400    Top5: 99.690    Loss: 0.354

2022-11-03 23:06:39,134 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:06:39,135 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 90.400   Top5: 99.690] Sparsity : 0.848
2022-11-03 23:06:39,135 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.260   Top5: 99.690] Sparsity : 0.848
2022-11-03 23:06:39,226 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:06:39,227 - INFO  - >>>>>>>> Epoch  33
2022-11-03 23:06:39,228 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:06:43,276 - INFO  - Training [33][   20/  391]   Loss 0.073816   Top1 97.421875   Top5 99.960938   BatchTime 0.202368   LR 0.001000   
2022-11-03 23:06:45,293 - INFO  - Training [33][   40/  391]   Loss 0.079508   Top1 97.304688   Top5 99.960938   BatchTime 0.151607   LR 0.001000   
2022-11-03 23:06:47,308 - INFO  - Training [33][   60/  391]   Loss 0.075772   Top1 97.421875   Top5 99.973958   BatchTime 0.134662   LR 0.001000   
2022-11-03 23:06:49,332 - INFO  - Training [33][   80/  391]   Loss 0.077262   Top1 97.324219   Top5 99.980469   BatchTime 0.126290   LR 0.001000   
2022-11-03 23:06:51,357 - INFO  - Training [33][  100/  391]   Loss 0.079943   Top1 97.250000   Top5 99.984375   BatchTime 0.121285   LR 0.001000   
2022-11-03 23:06:53,374 - INFO  - Training [33][  120/  391]   Loss 0.080814   Top1 97.213542   Top5 99.986979   BatchTime 0.117876   LR 0.001000   
2022-11-03 23:06:55,405 - INFO  - Training [33][  140/  391]   Loss 0.081288   Top1 97.176339   Top5 99.988839   BatchTime 0.115544   LR 0.001000   
2022-11-03 23:06:57,404 - INFO  - Training [33][  160/  391]   Loss 0.080766   Top1 97.226562   Top5 99.990234   BatchTime 0.113597   LR 0.001000   
2022-11-03 23:06:59,404 - INFO  - Training [33][  180/  391]   Loss 0.081881   Top1 97.183160   Top5 99.991319   BatchTime 0.112084   LR 0.001000   
2022-11-03 23:07:01,413 - INFO  - Training [33][  200/  391]   Loss 0.080579   Top1 97.238281   Top5 99.984375   BatchTime 0.110923   LR 0.001000   
2022-11-03 23:07:03,411 - INFO  - Training [33][  220/  391]   Loss 0.081109   Top1 97.240767   Top5 99.982244   BatchTime 0.109919   LR 0.001000   
2022-11-03 23:07:05,422 - INFO  - Training [33][  240/  391]   Loss 0.080481   Top1 97.239583   Top5 99.983724   BatchTime 0.109137   LR 0.001000   
2022-11-03 23:07:07,433 - INFO  - Training [33][  260/  391]   Loss 0.079705   Top1 97.271635   Top5 99.984976   BatchTime 0.108478   LR 0.001000   
2022-11-03 23:07:09,435 - INFO  - Training [33][  280/  391]   Loss 0.080152   Top1 97.260045   Top5 99.986049   BatchTime 0.107877   LR 0.001000   
2022-11-03 23:07:11,437 - INFO  - Training [33][  300/  391]   Loss 0.080564   Top1 97.247396   Top5 99.986979   BatchTime 0.107360   LR 0.001000   
2022-11-03 23:07:13,447 - INFO  - Training [33][  320/  391]   Loss 0.080164   Top1 97.253418   Top5 99.987793   BatchTime 0.106931   LR 0.001000   
2022-11-03 23:07:15,428 - INFO  - Training [33][  340/  391]   Loss 0.080655   Top1 97.208180   Top5 99.988511   BatchTime 0.106468   LR 0.001000   
2022-11-03 23:07:17,383 - INFO  - Training [33][  360/  391]   Loss 0.080980   Top1 97.200521   Top5 99.986979   BatchTime 0.105984   LR 0.001000   
2022-11-03 23:07:19,348 - INFO  - Training [33][  380/  391]   Loss 0.081515   Top1 97.185444   Top5 99.987664   BatchTime 0.105575   LR 0.001000   
2022-11-03 23:07:20,673 - INFO  - ==> Top1: 97.168    Top5: 99.986    Loss: 0.082

2022-11-03 23:07:20,674 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:07:23,309 - INFO  - Validation [33][   20/   79]   Loss 0.360233   Top1 90.507812   Top5 99.570312   BatchTime 0.131634   
2022-11-03 23:07:24,009 - INFO  - Validation [33][   40/   79]   Loss 0.365863   Top1 90.195312   Top5 99.550781   BatchTime 0.083327   
2022-11-03 23:07:24,704 - INFO  - Validation [33][   60/   79]   Loss 0.357655   Top1 90.651042   Top5 99.609375   BatchTime 0.067136   
2022-11-03 23:07:25,684 - INFO  - ==> Top1: 90.440    Top5: 99.650    Loss: 0.356

2022-11-03 23:07:25,707 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:07:25,707 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:07:25,707 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.400   Top5: 99.690] Sparsity : 0.848
2022-11-03 23:07:25,870 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:07:25,871 - INFO  - >>>>>>>> Epoch  34
2022-11-03 23:07:25,872 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:07:29,926 - INFO  - Training [34][   20/  391]   Loss 0.076739   Top1 97.421875   Top5 99.960938   BatchTime 0.202715   LR 0.001000   
2022-11-03 23:07:31,942 - INFO  - Training [34][   40/  391]   Loss 0.080317   Top1 97.050781   Top5 99.980469   BatchTime 0.151761   LR 0.001000   
2022-11-03 23:07:33,962 - INFO  - Training [34][   60/  391]   Loss 0.078539   Top1 97.161458   Top5 99.986979   BatchTime 0.134831   LR 0.001000   
2022-11-03 23:07:35,997 - INFO  - Training [34][   80/  391]   Loss 0.077994   Top1 97.285156   Top5 99.990234   BatchTime 0.126567   LR 0.001000   
2022-11-03 23:07:38,021 - INFO  - Training [34][  100/  391]   Loss 0.076886   Top1 97.359375   Top5 99.992188   BatchTime 0.121492   LR 0.001000   
2022-11-03 23:07:40,048 - INFO  - Training [34][  120/  391]   Loss 0.078719   Top1 97.291667   Top5 99.993490   BatchTime 0.118137   LR 0.001000   
2022-11-03 23:07:42,073 - INFO  - Training [34][  140/  391]   Loss 0.079090   Top1 97.243304   Top5 99.994420   BatchTime 0.115723   LR 0.001000   
2022-11-03 23:07:44,105 - INFO  - Training [34][  160/  391]   Loss 0.078179   Top1 97.275391   Top5 99.995117   BatchTime 0.113956   LR 0.001000   
2022-11-03 23:07:46,107 - INFO  - Training [34][  180/  391]   Loss 0.078900   Top1 97.296007   Top5 99.995660   BatchTime 0.112416   LR 0.001000   
2022-11-03 23:07:48,123 - INFO  - Training [34][  200/  391]   Loss 0.079275   Top1 97.269531   Top5 99.996094   BatchTime 0.111254   LR 0.001000   
2022-11-03 23:07:50,120 - INFO  - Training [34][  220/  391]   Loss 0.079617   Top1 97.240767   Top5 99.996449   BatchTime 0.110219   LR 0.001000   
2022-11-03 23:07:52,129 - INFO  - Training [34][  240/  391]   Loss 0.079652   Top1 97.236328   Top5 99.996745   BatchTime 0.109404   LR 0.001000   
2022-11-03 23:07:54,140 - INFO  - Training [34][  260/  391]   Loss 0.079936   Top1 97.220553   Top5 99.996995   BatchTime 0.108721   LR 0.001000   
2022-11-03 23:07:56,137 - INFO  - Training [34][  280/  391]   Loss 0.080223   Top1 97.209821   Top5 99.997210   BatchTime 0.108088   LR 0.001000   
2022-11-03 23:07:58,144 - INFO  - Training [34][  300/  391]   Loss 0.080516   Top1 97.190104   Top5 99.997396   BatchTime 0.107573   LR 0.001000   
2022-11-03 23:08:00,149 - INFO  - Training [34][  320/  391]   Loss 0.080288   Top1 97.182617   Top5 99.995117   BatchTime 0.107113   LR 0.001000   
2022-11-03 23:08:02,117 - INFO  - Training [34][  340/  391]   Loss 0.080386   Top1 97.180607   Top5 99.990809   BatchTime 0.106602   LR 0.001000   
2022-11-03 23:08:04,203 - INFO  - Training [34][  360/  391]   Loss 0.080279   Top1 97.180990   Top5 99.989149   BatchTime 0.106474   LR 0.001000   
2022-11-03 23:08:06,153 - INFO  - Training [34][  380/  391]   Loss 0.080431   Top1 97.173109   Top5 99.987664   BatchTime 0.106002   LR 0.001000   
2022-11-03 23:08:07,387 - INFO  - ==> Top1: 97.172    Top5: 99.988    Loss: 0.081

2022-11-03 23:08:07,388 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:08:09,979 - INFO  - Validation [34][   20/   79]   Loss 0.355543   Top1 90.625000   Top5 99.531250   BatchTime 0.129432   
2022-11-03 23:08:10,671 - INFO  - Validation [34][   40/   79]   Loss 0.369412   Top1 90.351562   Top5 99.589844   BatchTime 0.082019   
2022-11-03 23:08:11,380 - INFO  - Validation [34][   60/   79]   Loss 0.361004   Top1 90.585938   Top5 99.609375   BatchTime 0.066492   
2022-11-03 23:08:12,196 - INFO  - ==> Top1: 90.320    Top5: 99.640    Loss: 0.360

2022-11-03 23:08:12,221 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:08:12,221 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:08:12,222 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.400   Top5: 99.690] Sparsity : 0.848
2022-11-03 23:08:12,322 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:08:12,322 - INFO  - >>>>>>>> Epoch  35
2022-11-03 23:08:12,323 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:08:16,311 - INFO  - Training [35][   20/  391]   Loss 0.072903   Top1 97.539062   Top5 100.000000   BatchTime 0.199351   LR 0.001000   
2022-11-03 23:08:18,317 - INFO  - Training [35][   40/  391]   Loss 0.073404   Top1 97.617188   Top5 100.000000   BatchTime 0.149849   LR 0.001000   
2022-11-03 23:08:20,327 - INFO  - Training [35][   60/  391]   Loss 0.073129   Top1 97.500000   Top5 100.000000   BatchTime 0.133388   LR 0.001000   
2022-11-03 23:08:22,341 - INFO  - Training [35][   80/  391]   Loss 0.071626   Top1 97.548828   Top5 100.000000   BatchTime 0.125220   LR 0.001000   
2022-11-03 23:08:24,370 - INFO  - Training [35][  100/  391]   Loss 0.074306   Top1 97.484375   Top5 100.000000   BatchTime 0.120462   LR 0.001000   
2022-11-03 23:08:26,394 - INFO  - Training [35][  120/  391]   Loss 0.077965   Top1 97.343750   Top5 100.000000   BatchTime 0.117254   LR 0.001000   
2022-11-03 23:08:28,418 - INFO  - Training [35][  140/  391]   Loss 0.076533   Top1 97.360491   Top5 100.000000   BatchTime 0.114962   LR 0.001000   
2022-11-03 23:08:30,433 - INFO  - Training [35][  160/  391]   Loss 0.075025   Top1 97.412109   Top5 100.000000   BatchTime 0.113184   LR 0.001000   
2022-11-03 23:08:32,444 - INFO  - Training [35][  180/  391]   Loss 0.075401   Top1 97.378472   Top5 100.000000   BatchTime 0.111779   LR 0.001000   
2022-11-03 23:08:34,470 - INFO  - Training [35][  200/  391]   Loss 0.075307   Top1 97.398438   Top5 99.996094   BatchTime 0.110731   LR 0.001000   
2022-11-03 23:08:36,466 - INFO  - Training [35][  220/  391]   Loss 0.074970   Top1 97.400568   Top5 99.996449   BatchTime 0.109738   LR 0.001000   
2022-11-03 23:08:38,495 - INFO  - Training [35][  240/  391]   Loss 0.075011   Top1 97.360026   Top5 99.993490   BatchTime 0.109045   LR 0.001000   
2022-11-03 23:08:40,506 - INFO  - Training [35][  260/  391]   Loss 0.074826   Top1 97.358774   Top5 99.993990   BatchTime 0.108393   LR 0.001000   
2022-11-03 23:08:42,524 - INFO  - Training [35][  280/  391]   Loss 0.074655   Top1 97.352121   Top5 99.994420   BatchTime 0.107856   LR 0.001000   
2022-11-03 23:08:44,537 - INFO  - Training [35][  300/  391]   Loss 0.074979   Top1 97.346354   Top5 99.994792   BatchTime 0.107376   LR 0.001000   
2022-11-03 23:08:46,544 - INFO  - Training [35][  320/  391]   Loss 0.075387   Top1 97.316895   Top5 99.995117   BatchTime 0.106937   LR 0.001000   
2022-11-03 23:08:48,513 - INFO  - Training [35][  340/  391]   Loss 0.075397   Top1 97.323070   Top5 99.995404   BatchTime 0.106437   LR 0.001000   
2022-11-03 23:08:50,469 - INFO  - Training [35][  360/  391]   Loss 0.075641   Top1 97.313368   Top5 99.995660   BatchTime 0.105958   LR 0.001000   
2022-11-03 23:08:52,430 - INFO  - Training [35][  380/  391]   Loss 0.075800   Top1 97.304688   Top5 99.995888   BatchTime 0.105540   LR 0.001000   
2022-11-03 23:08:53,759 - INFO  - ==> Top1: 97.284    Top5: 99.996    Loss: 0.076

2022-11-03 23:08:53,759 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:08:56,414 - INFO  - Validation [35][   20/   79]   Loss 0.354805   Top1 90.781250   Top5 99.648438   BatchTime 0.132663   
2022-11-03 23:08:57,120 - INFO  - Validation [35][   40/   79]   Loss 0.362829   Top1 90.527344   Top5 99.667969   BatchTime 0.083998   
2022-11-03 23:08:57,857 - INFO  - Validation [35][   60/   79]   Loss 0.356523   Top1 90.559896   Top5 99.674479   BatchTime 0.068272   
2022-11-03 23:08:58,699 - INFO  - ==> Top1: 90.400    Top5: 99.700    Loss: 0.354

2022-11-03 23:08:58,726 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:08:58,727 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:08:58,727 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.400   Top5: 99.700] Sparsity : 0.849
2022-11-03 23:08:58,814 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:08:58,815 - INFO  - >>>>>>>> Epoch  36
2022-11-03 23:08:58,816 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:09:02,822 - INFO  - Training [36][   20/  391]   Loss 0.077367   Top1 97.421875   Top5 100.000000   BatchTime 0.200250   LR 0.001000   
2022-11-03 23:09:04,842 - INFO  - Training [36][   40/  391]   Loss 0.077182   Top1 97.382812   Top5 100.000000   BatchTime 0.150629   LR 0.001000   
2022-11-03 23:09:06,856 - INFO  - Training [36][   60/  391]   Loss 0.073254   Top1 97.500000   Top5 100.000000   BatchTime 0.133990   LR 0.001000   
2022-11-03 23:09:08,910 - INFO  - Training [36][   80/  391]   Loss 0.072357   Top1 97.490234   Top5 100.000000   BatchTime 0.126167   LR 0.001000   
2022-11-03 23:09:10,941 - INFO  - Training [36][  100/  391]   Loss 0.073579   Top1 97.476562   Top5 100.000000   BatchTime 0.121246   LR 0.001000   
2022-11-03 23:09:12,963 - INFO  - Training [36][  120/  391]   Loss 0.074493   Top1 97.363281   Top5 100.000000   BatchTime 0.117881   LR 0.001000   
2022-11-03 23:09:14,991 - INFO  - Training [36][  140/  391]   Loss 0.075617   Top1 97.304688   Top5 100.000000   BatchTime 0.115532   LR 0.001000   
2022-11-03 23:09:17,013 - INFO  - Training [36][  160/  391]   Loss 0.077181   Top1 97.290039   Top5 100.000000   BatchTime 0.113725   LR 0.001000   
2022-11-03 23:09:19,036 - INFO  - Training [36][  180/  391]   Loss 0.076156   Top1 97.291667   Top5 100.000000   BatchTime 0.112326   LR 0.001000   
2022-11-03 23:09:21,048 - INFO  - Training [36][  200/  391]   Loss 0.075296   Top1 97.320312   Top5 100.000000   BatchTime 0.111154   LR 0.001000   
2022-11-03 23:09:23,084 - INFO  - Training [36][  220/  391]   Loss 0.075290   Top1 97.318892   Top5 100.000000   BatchTime 0.110304   LR 0.001000   
2022-11-03 23:09:25,088 - INFO  - Training [36][  240/  391]   Loss 0.075207   Top1 97.314453   Top5 99.993490   BatchTime 0.109461   LR 0.001000   
2022-11-03 23:09:27,088 - INFO  - Training [36][  260/  391]   Loss 0.075520   Top1 97.304688   Top5 99.993990   BatchTime 0.108734   LR 0.001000   
2022-11-03 23:09:29,106 - INFO  - Training [36][  280/  391]   Loss 0.075449   Top1 97.324219   Top5 99.994420   BatchTime 0.108175   LR 0.001000   
2022-11-03 23:09:31,113 - INFO  - Training [36][  300/  391]   Loss 0.075672   Top1 97.320312   Top5 99.994792   BatchTime 0.107651   LR 0.001000   
2022-11-03 23:09:33,123 - INFO  - Training [36][  320/  391]   Loss 0.075948   Top1 97.319336   Top5 99.995117   BatchTime 0.107204   LR 0.001000   
2022-11-03 23:09:35,089 - INFO  - Training [36][  340/  391]   Loss 0.076112   Top1 97.316176   Top5 99.995404   BatchTime 0.106682   LR 0.001000   
2022-11-03 23:09:37,049 - INFO  - Training [36][  360/  391]   Loss 0.076287   Top1 97.304688   Top5 99.995660   BatchTime 0.106199   LR 0.001000   
2022-11-03 23:09:39,000 - INFO  - Training [36][  380/  391]   Loss 0.076214   Top1 97.308799   Top5 99.995888   BatchTime 0.105743   LR 0.001000   
2022-11-03 23:09:40,279 - INFO  - ==> Top1: 97.298    Top5: 99.996    Loss: 0.076

2022-11-03 23:09:40,280 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:09:42,942 - INFO  - Validation [36][   20/   79]   Loss 0.360272   Top1 90.820312   Top5 99.531250   BatchTime 0.133004   
2022-11-03 23:09:43,639 - INFO  - Validation [36][   40/   79]   Loss 0.376147   Top1 90.117188   Top5 99.589844   BatchTime 0.083926   
2022-11-03 23:09:44,319 - INFO  - Validation [36][   60/   79]   Loss 0.367095   Top1 90.273438   Top5 99.609375   BatchTime 0.067291   
2022-11-03 23:09:45,092 - INFO  - ==> Top1: 90.180    Top5: 99.650    Loss: 0.364

2022-11-03 23:09:45,115 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:09:45,116 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:09:45,116 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 90.400   Top5: 99.700] Sparsity : 0.849
2022-11-03 23:09:45,219 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:09:45,219 - INFO  - >>>>>>>> Epoch  37
2022-11-03 23:09:45,221 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:09:49,334 - INFO  - Training [37][   20/  391]   Loss 0.069375   Top1 97.421875   Top5 100.000000   BatchTime 0.205652   LR 0.001000   
2022-11-03 23:09:51,349 - INFO  - Training [37][   40/  391]   Loss 0.067241   Top1 97.558594   Top5 100.000000   BatchTime 0.153194   LR 0.001000   
2022-11-03 23:09:53,376 - INFO  - Training [37][   60/  391]   Loss 0.067841   Top1 97.513021   Top5 100.000000   BatchTime 0.135927   LR 0.001000   
2022-11-03 23:09:55,405 - INFO  - Training [37][   80/  391]   Loss 0.068049   Top1 97.636719   Top5 100.000000   BatchTime 0.127304   LR 0.001000   
2022-11-03 23:09:57,404 - INFO  - Training [37][  100/  391]   Loss 0.070801   Top1 97.484375   Top5 100.000000   BatchTime 0.121831   LR 0.001000   
2022-11-03 23:09:59,418 - INFO  - Training [37][  120/  391]   Loss 0.070804   Top1 97.454427   Top5 100.000000   BatchTime 0.118309   LR 0.001000   
2022-11-03 23:10:01,438 - INFO  - Training [37][  140/  391]   Loss 0.071600   Top1 97.460938   Top5 100.000000   BatchTime 0.115834   LR 0.001000   
2022-11-03 23:10:03,468 - INFO  - Training [37][  160/  391]   Loss 0.071557   Top1 97.480469   Top5 100.000000   BatchTime 0.114041   LR 0.001000   
2022-11-03 23:10:05,502 - INFO  - Training [37][  180/  391]   Loss 0.072652   Top1 97.434896   Top5 100.000000   BatchTime 0.112673   LR 0.001000   
2022-11-03 23:10:07,535 - INFO  - Training [37][  200/  391]   Loss 0.071757   Top1 97.480469   Top5 100.000000   BatchTime 0.111571   LR 0.001000   
2022-11-03 23:10:09,553 - INFO  - Training [37][  220/  391]   Loss 0.071818   Top1 97.475142   Top5 100.000000   BatchTime 0.110598   LR 0.001000   
2022-11-03 23:10:11,573 - INFO  - Training [37][  240/  391]   Loss 0.072503   Top1 97.467448   Top5 100.000000   BatchTime 0.109798   LR 0.001000   
2022-11-03 23:10:13,596 - INFO  - Training [37][  260/  391]   Loss 0.072696   Top1 97.478966   Top5 100.000000   BatchTime 0.109132   LR 0.001000   
2022-11-03 23:10:15,603 - INFO  - Training [37][  280/  391]   Loss 0.073426   Top1 97.441406   Top5 100.000000   BatchTime 0.108507   LR 0.001000   
2022-11-03 23:10:17,626 - INFO  - Training [37][  300/  391]   Loss 0.074463   Top1 97.388021   Top5 100.000000   BatchTime 0.108017   LR 0.001000   
2022-11-03 23:10:19,650 - INFO  - Training [37][  320/  391]   Loss 0.074825   Top1 97.377930   Top5 100.000000   BatchTime 0.107588   LR 0.001000   
2022-11-03 23:10:21,623 - INFO  - Training [37][  340/  391]   Loss 0.074274   Top1 97.398897   Top5 100.000000   BatchTime 0.107062   LR 0.001000   
2022-11-03 23:10:23,581 - INFO  - Training [37][  360/  391]   Loss 0.074259   Top1 97.413194   Top5 99.997830   BatchTime 0.106554   LR 0.001000   
2022-11-03 23:10:25,543 - INFO  - Training [37][  380/  391]   Loss 0.074186   Top1 97.425987   Top5 99.997944   BatchTime 0.106110   LR 0.001000   
2022-11-03 23:10:26,842 - INFO  - ==> Top1: 97.424    Top5: 99.998    Loss: 0.074

2022-11-03 23:10:26,843 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:10:29,465 - INFO  - Validation [37][   20/   79]   Loss 0.368340   Top1 90.781250   Top5 99.531250   BatchTime 0.131018   
2022-11-03 23:10:30,158 - INFO  - Validation [37][   40/   79]   Loss 0.369846   Top1 90.488281   Top5 99.550781   BatchTime 0.082832   
2022-11-03 23:10:30,903 - INFO  - Validation [37][   60/   79]   Loss 0.364491   Top1 90.638021   Top5 99.596354   BatchTime 0.067650   
2022-11-03 23:10:31,664 - INFO  - ==> Top1: 90.450    Top5: 99.640    Loss: 0.361

2022-11-03 23:10:31,687 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 90.450   Top5: 99.640] Sparsity : 0.849
2022-11-03 23:10:31,688 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:10:31,688 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:10:31,867 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:10:31,867 - INFO  - >>>>>>>> Epoch  38
2022-11-03 23:10:31,868 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:10:35,868 - INFO  - Training [38][   20/  391]   Loss 0.075869   Top1 97.656250   Top5 99.960938   BatchTime 0.199980   LR 0.001000   
2022-11-03 23:10:37,891 - INFO  - Training [38][   40/  391]   Loss 0.078355   Top1 97.460938   Top5 99.960938   BatchTime 0.150560   LR 0.001000   
2022-11-03 23:10:39,913 - INFO  - Training [38][   60/  391]   Loss 0.073710   Top1 97.617188   Top5 99.973958   BatchTime 0.134075   LR 0.001000   
2022-11-03 23:10:41,966 - INFO  - Training [38][   80/  391]   Loss 0.074980   Top1 97.617188   Top5 99.980469   BatchTime 0.126227   LR 0.001000   
2022-11-03 23:10:43,978 - INFO  - Training [38][  100/  391]   Loss 0.074012   Top1 97.570312   Top5 99.984375   BatchTime 0.121096   LR 0.001000   
2022-11-03 23:10:45,991 - INFO  - Training [38][  120/  391]   Loss 0.074221   Top1 97.571615   Top5 99.986979   BatchTime 0.117685   LR 0.001000   
2022-11-03 23:10:48,003 - INFO  - Training [38][  140/  391]   Loss 0.074413   Top1 97.555804   Top5 99.988839   BatchTime 0.115248   LR 0.001000   
2022-11-03 23:10:50,019 - INFO  - Training [38][  160/  391]   Loss 0.074648   Top1 97.558594   Top5 99.990234   BatchTime 0.113441   LR 0.001000   
2022-11-03 23:10:52,031 - INFO  - Training [38][  180/  391]   Loss 0.073167   Top1 97.591146   Top5 99.991319   BatchTime 0.112016   LR 0.001000   
2022-11-03 23:10:54,046 - INFO  - Training [38][  200/  391]   Loss 0.073662   Top1 97.566406   Top5 99.992188   BatchTime 0.110888   LR 0.001000   
2022-11-03 23:10:56,067 - INFO  - Training [38][  220/  391]   Loss 0.073439   Top1 97.556818   Top5 99.992898   BatchTime 0.109991   LR 0.001000   
2022-11-03 23:10:58,085 - INFO  - Training [38][  240/  391]   Loss 0.072971   Top1 97.545573   Top5 99.993490   BatchTime 0.109235   LR 0.001000   
2022-11-03 23:11:00,099 - INFO  - Training [38][  260/  391]   Loss 0.073033   Top1 97.518029   Top5 99.990986   BatchTime 0.108579   LR 0.001000   
2022-11-03 23:11:02,105 - INFO  - Training [38][  280/  391]   Loss 0.073155   Top1 97.513951   Top5 99.991629   BatchTime 0.107987   LR 0.001000   
2022-11-03 23:11:04,118 - INFO  - Training [38][  300/  391]   Loss 0.073557   Top1 97.476562   Top5 99.992188   BatchTime 0.107498   LR 0.001000   
2022-11-03 23:11:06,123 - INFO  - Training [38][  320/  391]   Loss 0.073528   Top1 97.478027   Top5 99.990234   BatchTime 0.107044   LR 0.001000   
2022-11-03 23:11:08,097 - INFO  - Training [38][  340/  391]   Loss 0.073221   Top1 97.477022   Top5 99.990809   BatchTime 0.106552   LR 0.001000   
2022-11-03 23:11:10,052 - INFO  - Training [38][  360/  391]   Loss 0.072489   Top1 97.504340   Top5 99.991319   BatchTime 0.106063   LR 0.001000   
2022-11-03 23:11:12,006 - INFO  - Training [38][  380/  391]   Loss 0.072905   Top1 97.500000   Top5 99.991776   BatchTime 0.105623   LR 0.001000   
2022-11-03 23:11:13,178 - INFO  - ==> Top1: 97.496    Top5: 99.990    Loss: 0.073

2022-11-03 23:11:13,179 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:11:15,797 - INFO  - Validation [38][   20/   79]   Loss 0.362071   Top1 90.703125   Top5 99.453125   BatchTime 0.130809   
2022-11-03 23:11:16,492 - INFO  - Validation [38][   40/   79]   Loss 0.368346   Top1 90.449219   Top5 99.531250   BatchTime 0.082775   
2022-11-03 23:11:17,163 - INFO  - Validation [38][   60/   79]   Loss 0.366382   Top1 90.481771   Top5 99.570312   BatchTime 0.066373   
2022-11-03 23:11:17,940 - INFO  - ==> Top1: 90.310    Top5: 99.630    Loss: 0.363

2022-11-03 23:11:17,965 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 90.450   Top5: 99.640] Sparsity : 0.849
2022-11-03 23:11:17,966 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:11:17,966 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.440   Top5: 99.590] Sparsity : 0.848
2022-11-03 23:11:18,068 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:11:18,068 - INFO  - >>>>>>>> Epoch  39
2022-11-03 23:11:18,069 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:11:22,085 - INFO  - Training [39][   20/  391]   Loss 0.081867   Top1 97.265625   Top5 100.000000   BatchTime 0.200766   LR 0.001000   
2022-11-03 23:11:24,105 - INFO  - Training [39][   40/  391]   Loss 0.079860   Top1 97.167969   Top5 100.000000   BatchTime 0.150896   LR 0.001000   
2022-11-03 23:11:26,262 - INFO  - Training [39][   60/  391]   Loss 0.076133   Top1 97.278646   Top5 99.986979   BatchTime 0.136543   LR 0.001000   
2022-11-03 23:11:28,275 - INFO  - Training [39][   80/  391]   Loss 0.076205   Top1 97.324219   Top5 99.990234   BatchTime 0.127563   LR 0.001000   
2022-11-03 23:11:30,300 - INFO  - Training [39][  100/  391]   Loss 0.076336   Top1 97.304688   Top5 99.992188   BatchTime 0.122307   LR 0.001000   
2022-11-03 23:11:32,307 - INFO  - Training [39][  120/  391]   Loss 0.075364   Top1 97.402344   Top5 99.993490   BatchTime 0.118644   LR 0.001000   
2022-11-03 23:11:34,323 - INFO  - Training [39][  140/  391]   Loss 0.074189   Top1 97.427455   Top5 99.988839   BatchTime 0.116098   LR 0.001000   
2022-11-03 23:11:36,261 - INFO  - Training [39][  160/  391]   Loss 0.072768   Top1 97.480469   Top5 99.990234   BatchTime 0.113695   LR 0.001000   
2022-11-03 23:11:38,266 - INFO  - Training [39][  180/  391]   Loss 0.072792   Top1 97.473958   Top5 99.991319   BatchTime 0.112200   LR 0.001000   
2022-11-03 23:11:40,281 - INFO  - Training [39][  200/  391]   Loss 0.071713   Top1 97.500000   Top5 99.992188   BatchTime 0.111056   LR 0.001000   
2022-11-03 23:11:42,291 - INFO  - Training [39][  220/  391]   Loss 0.071995   Top1 97.492898   Top5 99.992898   BatchTime 0.110095   LR 0.001000   
2022-11-03 23:11:44,309 - INFO  - Training [39][  240/  391]   Loss 0.071643   Top1 97.509766   Top5 99.993490   BatchTime 0.109330   LR 0.001000   
2022-11-03 23:11:46,320 - INFO  - Training [39][  260/  391]   Loss 0.072811   Top1 97.484976   Top5 99.993990   BatchTime 0.108654   LR 0.001000   
2022-11-03 23:11:48,316 - INFO  - Training [39][  280/  391]   Loss 0.072404   Top1 97.486049   Top5 99.994420   BatchTime 0.108021   LR 0.001000   
2022-11-03 23:11:50,341 - INFO  - Training [39][  300/  391]   Loss 0.072716   Top1 97.484375   Top5 99.994792   BatchTime 0.107568   LR 0.001000   
2022-11-03 23:11:52,357 - INFO  - Training [39][  320/  391]   Loss 0.072366   Top1 97.492676   Top5 99.995117   BatchTime 0.107148   LR 0.001000   
2022-11-03 23:11:54,324 - INFO  - Training [39][  340/  391]   Loss 0.072401   Top1 97.504596   Top5 99.995404   BatchTime 0.106630   LR 0.001000   
2022-11-03 23:11:56,278 - INFO  - Training [39][  360/  391]   Loss 0.072639   Top1 97.491319   Top5 99.995660   BatchTime 0.106134   LR 0.001000   
2022-11-03 23:11:58,248 - INFO  - Training [39][  380/  391]   Loss 0.073077   Top1 97.458882   Top5 99.995888   BatchTime 0.105732   LR 0.001000   
2022-11-03 23:11:59,428 - INFO  - ==> Top1: 97.458    Top5: 99.996    Loss: 0.073

2022-11-03 23:11:59,429 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:12:02,065 - INFO  - Validation [39][   20/   79]   Loss 0.363924   Top1 90.898438   Top5 99.453125   BatchTime 0.131708   
2022-11-03 23:12:02,764 - INFO  - Validation [39][   40/   79]   Loss 0.371665   Top1 90.625000   Top5 99.472656   BatchTime 0.083336   
2022-11-03 23:12:03,482 - INFO  - Validation [39][   60/   79]   Loss 0.365510   Top1 90.664062   Top5 99.557292   BatchTime 0.067518   
2022-11-03 23:12:04,248 - INFO  - ==> Top1: 90.520    Top5: 99.580    Loss: 0.361

2022-11-03 23:12:04,274 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 90.520   Top5: 99.580] Sparsity : 0.849
2022-11-03 23:12:04,275 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 90.450   Top5: 99.640] Sparsity : 0.849
2022-11-03 23:12:04,275 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:12:04,462 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:12:04,462 - INFO  - >>>>>>>> Epoch  40
2022-11-03 23:12:04,463 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:12:08,408 - INFO  - Training [40][   20/  391]   Loss 0.066279   Top1 97.929688   Top5 100.000000   BatchTime 0.197244   LR 0.001000   
2022-11-03 23:12:10,439 - INFO  - Training [40][   40/  391]   Loss 0.066393   Top1 97.871094   Top5 100.000000   BatchTime 0.149401   LR 0.001000   
2022-11-03 23:12:12,428 - INFO  - Training [40][   60/  391]   Loss 0.067616   Top1 97.812500   Top5 100.000000   BatchTime 0.132754   LR 0.001000   
2022-11-03 23:12:14,423 - INFO  - Training [40][   80/  391]   Loss 0.071455   Top1 97.597656   Top5 99.970703   BatchTime 0.124492   LR 0.001000   
2022-11-03 23:12:16,426 - INFO  - Training [40][  100/  391]   Loss 0.072899   Top1 97.554688   Top5 99.976562   BatchTime 0.119631   LR 0.001000   
2022-11-03 23:12:18,452 - INFO  - Training [40][  120/  391]   Loss 0.071541   Top1 97.584635   Top5 99.980469   BatchTime 0.116574   LR 0.001000   
2022-11-03 23:12:20,467 - INFO  - Training [40][  140/  391]   Loss 0.070724   Top1 97.611607   Top5 99.983259   BatchTime 0.114309   LR 0.001000   
2022-11-03 23:12:22,476 - INFO  - Training [40][  160/  391]   Loss 0.070967   Top1 97.592773   Top5 99.985352   BatchTime 0.112580   LR 0.001000   
2022-11-03 23:12:24,485 - INFO  - Training [40][  180/  391]   Loss 0.070769   Top1 97.599826   Top5 99.986979   BatchTime 0.111231   LR 0.001000   
2022-11-03 23:12:26,507 - INFO  - Training [40][  200/  391]   Loss 0.072411   Top1 97.496094   Top5 99.984375   BatchTime 0.110215   LR 0.001000   
2022-11-03 23:12:28,530 - INFO  - Training [40][  220/  391]   Loss 0.072364   Top1 97.485795   Top5 99.985795   BatchTime 0.109392   LR 0.001000   
2022-11-03 23:12:30,533 - INFO  - Training [40][  240/  391]   Loss 0.072497   Top1 97.483724   Top5 99.986979   BatchTime 0.108623   LR 0.001000   
2022-11-03 23:12:32,536 - INFO  - Training [40][  260/  391]   Loss 0.072415   Top1 97.472957   Top5 99.987981   BatchTime 0.107969   LR 0.001000   
2022-11-03 23:12:34,547 - INFO  - Training [40][  280/  391]   Loss 0.072473   Top1 97.494420   Top5 99.986049   BatchTime 0.107438   LR 0.001000   
2022-11-03 23:12:36,547 - INFO  - Training [40][  300/  391]   Loss 0.072411   Top1 97.515625   Top5 99.984375   BatchTime 0.106945   LR 0.001000   
2022-11-03 23:12:38,541 - INFO  - Training [40][  320/  391]   Loss 0.072533   Top1 97.512207   Top5 99.985352   BatchTime 0.106492   LR 0.001000   
2022-11-03 23:12:40,501 - INFO  - Training [40][  340/  391]   Loss 0.072525   Top1 97.502298   Top5 99.986213   BatchTime 0.105992   LR 0.001000   
2022-11-03 23:12:42,461 - INFO  - Training [40][  360/  391]   Loss 0.072713   Top1 97.493490   Top5 99.986979   BatchTime 0.105547   LR 0.001000   
2022-11-03 23:12:44,411 - INFO  - Training [40][  380/  391]   Loss 0.072878   Top1 97.487664   Top5 99.987664   BatchTime 0.105123   LR 0.001000   
2022-11-03 23:12:45,649 - INFO  - ==> Top1: 97.512    Top5: 99.988    Loss: 0.072

2022-11-03 23:12:45,650 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:12:48,281 - INFO  - Validation [40][   20/   79]   Loss 0.367969   Top1 90.703125   Top5 99.609375   BatchTime 0.131465   
2022-11-03 23:12:48,975 - INFO  - Validation [40][   40/   79]   Loss 0.374579   Top1 90.429688   Top5 99.609375   BatchTime 0.083069   
2022-11-03 23:12:49,644 - INFO  - Validation [40][   60/   79]   Loss 0.369517   Top1 90.585938   Top5 99.635417   BatchTime 0.066541   
2022-11-03 23:12:50,417 - INFO  - ==> Top1: 90.380    Top5: 99.650    Loss: 0.366

2022-11-03 23:12:50,444 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 90.520   Top5: 99.580] Sparsity : 0.849
2022-11-03 23:12:50,445 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 90.450   Top5: 99.640] Sparsity : 0.849
2022-11-03 23:12:50,445 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.440   Top5: 99.650] Sparsity : 0.849
2022-11-03 23:12:50,546 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:12:50,546 - INFO  - >>>>>>>> Epoch  41
2022-11-03 23:12:50,548 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:12:54,561 - INFO  - Training [41][   20/  391]   Loss 0.073304   Top1 97.343750   Top5 99.960938   BatchTime 0.200648   LR 0.001000   
2022-11-03 23:12:56,590 - INFO  - Training [41][   40/  391]   Loss 0.069472   Top1 97.539062   Top5 99.980469   BatchTime 0.151039   LR 0.001000   
2022-11-03 23:12:58,613 - INFO  - Training [41][   60/  391]   Loss 0.073645   Top1 97.356771   Top5 99.986979   BatchTime 0.134417   LR 0.001000   
2022-11-03 23:13:00,629 - INFO  - Training [41][   80/  391]   Loss 0.071474   Top1 97.441406   Top5 99.990234   BatchTime 0.126009   LR 0.001000   
2022-11-03 23:13:02,644 - INFO  - Training [41][  100/  391]   Loss 0.074241   Top1 97.335938   Top5 99.992188   BatchTime 0.120959   LR 0.001000   
2022-11-03 23:13:04,758 - INFO  - Training [41][  120/  391]   Loss 0.073265   Top1 97.389323   Top5 99.993490   BatchTime 0.118417   LR 0.001000   
2022-11-03 23:13:06,769 - INFO  - Training [41][  140/  391]   Loss 0.072581   Top1 97.405134   Top5 99.994420   BatchTime 0.115865   LR 0.001000   
2022-11-03 23:13:08,780 - INFO  - Training [41][  160/  391]   Loss 0.071543   Top1 97.485352   Top5 99.995117   BatchTime 0.113946   LR 0.001000   
2022-11-03 23:13:10,815 - INFO  - Training [41][  180/  391]   Loss 0.072798   Top1 97.447917   Top5 99.995660   BatchTime 0.112589   LR 0.001000   
2022-11-03 23:13:12,811 - INFO  - Training [41][  200/  391]   Loss 0.073073   Top1 97.402344   Top5 99.992188   BatchTime 0.111313   LR 0.001000   
2022-11-03 23:13:14,817 - INFO  - Training [41][  220/  391]   Loss 0.075212   Top1 97.318892   Top5 99.989347   BatchTime 0.110312   LR 0.001000   
2022-11-03 23:13:16,822 - INFO  - Training [41][  240/  391]   Loss 0.074245   Top1 97.356771   Top5 99.990234   BatchTime 0.109474   LR 0.001000   
2022-11-03 23:13:18,822 - INFO  - Training [41][  260/  391]   Loss 0.074227   Top1 97.340745   Top5 99.990986   BatchTime 0.108744   LR 0.001000   
2022-11-03 23:13:20,860 - INFO  - Training [41][  280/  391]   Loss 0.073968   Top1 97.354911   Top5 99.988839   BatchTime 0.108254   LR 0.001000   
2022-11-03 23:13:22,876 - INFO  - Training [41][  300/  391]   Loss 0.072958   Top1 97.419271   Top5 99.989583   BatchTime 0.107756   LR 0.001000   
2022-11-03 23:13:24,873 - INFO  - Training [41][  320/  391]   Loss 0.072348   Top1 97.453613   Top5 99.990234   BatchTime 0.107264   LR 0.001000   
2022-11-03 23:13:26,836 - INFO  - Training [41][  340/  391]   Loss 0.071866   Top1 97.479320   Top5 99.990809   BatchTime 0.106726   LR 0.001000   
2022-11-03 23:13:28,793 - INFO  - Training [41][  360/  391]   Loss 0.071863   Top1 97.495660   Top5 99.991319   BatchTime 0.106235   LR 0.001000   
2022-11-03 23:13:30,822 - INFO  - Training [41][  380/  391]   Loss 0.071774   Top1 97.516447   Top5 99.991776   BatchTime 0.105982   LR 0.001000   
2022-11-03 23:13:31,859 - INFO  - ==> Top1: 97.506    Top5: 99.988    Loss: 0.072

2022-11-03 23:13:31,860 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:13:34,503 - INFO  - Validation [41][   20/   79]   Loss 0.358972   Top1 90.781250   Top5 99.531250   BatchTime 0.132083   
2022-11-03 23:13:35,203 - INFO  - Validation [41][   40/   79]   Loss 0.368704   Top1 90.488281   Top5 99.550781   BatchTime 0.083541   
2022-11-03 23:13:35,870 - INFO  - Validation [41][   60/   79]   Loss 0.359144   Top1 90.677083   Top5 99.609375   BatchTime 0.066800   
2022-11-03 23:13:36,636 - INFO  - ==> Top1: 90.530    Top5: 99.650    Loss: 0.358

2022-11-03 23:13:36,667 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:13:36,668 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.520   Top5: 99.580] Sparsity : 0.849
2022-11-03 23:13:36,668 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.450   Top5: 99.640] Sparsity : 0.849
2022-11-03 23:13:36,857 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:13:36,857 - INFO  - >>>>>>>> Epoch  42
2022-11-03 23:13:36,859 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:13:40,843 - INFO  - Training [42][   20/  391]   Loss 0.073607   Top1 97.031250   Top5 100.000000   BatchTime 0.199174   LR 0.001000   
2022-11-03 23:13:42,867 - INFO  - Training [42][   40/  391]   Loss 0.069207   Top1 97.265625   Top5 100.000000   BatchTime 0.150189   LR 0.001000   
2022-11-03 23:13:44,884 - INFO  - Training [42][   60/  391]   Loss 0.072219   Top1 97.330729   Top5 100.000000   BatchTime 0.133754   LR 0.001000   
2022-11-03 23:13:46,906 - INFO  - Training [42][   80/  391]   Loss 0.072614   Top1 97.246094   Top5 100.000000   BatchTime 0.125583   LR 0.001000   
2022-11-03 23:13:48,925 - INFO  - Training [42][  100/  391]   Loss 0.072073   Top1 97.335938   Top5 100.000000   BatchTime 0.120660   LR 0.001000   
2022-11-03 23:13:50,947 - INFO  - Training [42][  120/  391]   Loss 0.071428   Top1 97.408854   Top5 100.000000   BatchTime 0.117397   LR 0.001000   
2022-11-03 23:13:52,955 - INFO  - Training [42][  140/  391]   Loss 0.070753   Top1 97.433036   Top5 100.000000   BatchTime 0.114972   LR 0.001000   
2022-11-03 23:13:54,989 - INFO  - Training [42][  160/  391]   Loss 0.070405   Top1 97.441406   Top5 100.000000   BatchTime 0.113308   LR 0.001000   
2022-11-03 23:13:57,012 - INFO  - Training [42][  180/  391]   Loss 0.071156   Top1 97.447917   Top5 99.991319   BatchTime 0.111958   LR 0.001000   
2022-11-03 23:13:59,032 - INFO  - Training [42][  200/  391]   Loss 0.070767   Top1 97.457031   Top5 99.992188   BatchTime 0.110865   LR 0.001000   
2022-11-03 23:14:01,025 - INFO  - Training [42][  220/  391]   Loss 0.070694   Top1 97.468040   Top5 99.989347   BatchTime 0.109841   LR 0.001000   
2022-11-03 23:14:03,040 - INFO  - Training [42][  240/  391]   Loss 0.071032   Top1 97.428385   Top5 99.986979   BatchTime 0.109087   LR 0.001000   
2022-11-03 23:14:05,056 - INFO  - Training [42][  260/  391]   Loss 0.070368   Top1 97.469952   Top5 99.987981   BatchTime 0.108449   LR 0.001000   
2022-11-03 23:14:07,073 - INFO  - Training [42][  280/  391]   Loss 0.070121   Top1 97.477679   Top5 99.988839   BatchTime 0.107904   LR 0.001000   
2022-11-03 23:14:09,075 - INFO  - Training [42][  300/  391]   Loss 0.070691   Top1 97.447917   Top5 99.989583   BatchTime 0.107385   LR 0.001000   
2022-11-03 23:14:11,078 - INFO  - Training [42][  320/  391]   Loss 0.070729   Top1 97.451172   Top5 99.987793   BatchTime 0.106932   LR 0.001000   
2022-11-03 23:14:13,051 - INFO  - Training [42][  340/  391]   Loss 0.070371   Top1 97.467831   Top5 99.988511   BatchTime 0.106444   LR 0.001000   
2022-11-03 23:14:15,010 - INFO  - Training [42][  360/  391]   Loss 0.069997   Top1 97.489149   Top5 99.989149   BatchTime 0.105973   LR 0.001000   
2022-11-03 23:14:16,983 - INFO  - Training [42][  380/  391]   Loss 0.069791   Top1 97.483553   Top5 99.989720   BatchTime 0.105587   LR 0.001000   
2022-11-03 23:14:18,017 - INFO  - ==> Top1: 97.468    Top5: 99.990    Loss: 0.070

2022-11-03 23:14:18,018 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:14:20,661 - INFO  - Validation [42][   20/   79]   Loss 0.369959   Top1 90.585938   Top5 99.570312   BatchTime 0.132095   
2022-11-03 23:14:21,345 - INFO  - Validation [42][   40/   79]   Loss 0.374799   Top1 90.390625   Top5 99.550781   BatchTime 0.083154   
2022-11-03 23:14:21,970 - INFO  - Validation [42][   60/   79]   Loss 0.367347   Top1 90.598958   Top5 99.596354   BatchTime 0.065851   
2022-11-03 23:14:22,751 - INFO  - ==> Top1: 90.410    Top5: 99.630    Loss: 0.363

2022-11-03 23:14:22,778 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:14:22,778 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 90.520   Top5: 99.580] Sparsity : 0.849
2022-11-03 23:14:22,779 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.450   Top5: 99.640] Sparsity : 0.849
2022-11-03 23:14:22,879 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:14:22,880 - INFO  - >>>>>>>> Epoch  43
2022-11-03 23:14:22,881 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:14:26,849 - INFO  - Training [43][   20/  391]   Loss 0.065655   Top1 97.812500   Top5 100.000000   BatchTime 0.198380   LR 0.001000   
2022-11-03 23:14:28,866 - INFO  - Training [43][   40/  391]   Loss 0.068245   Top1 97.675781   Top5 99.980469   BatchTime 0.149613   LR 0.001000   
2022-11-03 23:14:30,874 - INFO  - Training [43][   60/  391]   Loss 0.069396   Top1 97.604167   Top5 99.986979   BatchTime 0.133204   LR 0.001000   
2022-11-03 23:14:32,880 - INFO  - Training [43][   80/  391]   Loss 0.067765   Top1 97.675781   Top5 99.980469   BatchTime 0.124984   LR 0.001000   
2022-11-03 23:14:34,887 - INFO  - Training [43][  100/  391]   Loss 0.068114   Top1 97.617188   Top5 99.984375   BatchTime 0.120059   LR 0.001000   
2022-11-03 23:14:36,911 - INFO  - Training [43][  120/  391]   Loss 0.067372   Top1 97.636719   Top5 99.986979   BatchTime 0.116908   LR 0.001000   
2022-11-03 23:14:38,921 - INFO  - Training [43][  140/  391]   Loss 0.066760   Top1 97.689732   Top5 99.988839   BatchTime 0.114565   LR 0.001000   
2022-11-03 23:14:40,920 - INFO  - Training [43][  160/  391]   Loss 0.066637   Top1 97.709961   Top5 99.985352   BatchTime 0.112743   LR 0.001000   
2022-11-03 23:14:42,945 - INFO  - Training [43][  180/  391]   Loss 0.067275   Top1 97.690972   Top5 99.986979   BatchTime 0.111462   LR 0.001000   
2022-11-03 23:14:45,044 - INFO  - Training [43][  200/  391]   Loss 0.067929   Top1 97.656250   Top5 99.984375   BatchTime 0.110812   LR 0.001000   
2022-11-03 23:14:47,061 - INFO  - Training [43][  220/  391]   Loss 0.067896   Top1 97.638494   Top5 99.982244   BatchTime 0.109904   LR 0.001000   
2022-11-03 23:14:49,095 - INFO  - Training [43][  240/  391]   Loss 0.068444   Top1 97.636719   Top5 99.983724   BatchTime 0.109221   LR 0.001000   
2022-11-03 23:14:51,128 - INFO  - Training [43][  260/  391]   Loss 0.068427   Top1 97.644231   Top5 99.984976   BatchTime 0.108639   LR 0.001000   
2022-11-03 23:14:53,134 - INFO  - Training [43][  280/  391]   Loss 0.068016   Top1 97.645089   Top5 99.986049   BatchTime 0.108043   LR 0.001000   
2022-11-03 23:14:55,150 - INFO  - Training [43][  300/  391]   Loss 0.068336   Top1 97.645833   Top5 99.984375   BatchTime 0.107561   LR 0.001000   
2022-11-03 23:14:57,159 - INFO  - Training [43][  320/  391]   Loss 0.068903   Top1 97.626953   Top5 99.985352   BatchTime 0.107117   LR 0.001000   
2022-11-03 23:14:59,131 - INFO  - Training [43][  340/  391]   Loss 0.068894   Top1 97.619485   Top5 99.986213   BatchTime 0.106616   LR 0.001000   
2022-11-03 23:15:01,088 - INFO  - Training [43][  360/  391]   Loss 0.069623   Top1 97.593316   Top5 99.986979   BatchTime 0.106127   LR 0.001000   
2022-11-03 23:15:03,109 - INFO  - Training [43][  380/  391]   Loss 0.069609   Top1 97.584293   Top5 99.985609   BatchTime 0.105859   LR 0.001000   
2022-11-03 23:15:04,188 - INFO  - ==> Top1: 97.566    Top5: 99.986    Loss: 0.070

2022-11-03 23:15:04,189 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:15:06,819 - INFO  - Validation [43][   20/   79]   Loss 0.359828   Top1 90.820312   Top5 99.570312   BatchTime 0.131476   
2022-11-03 23:15:07,521 - INFO  - Validation [43][   40/   79]   Loss 0.367332   Top1 90.546875   Top5 99.609375   BatchTime 0.083277   
2022-11-03 23:15:08,124 - INFO  - Validation [43][   60/   79]   Loss 0.361535   Top1 90.638021   Top5 99.635417   BatchTime 0.065567   
2022-11-03 23:15:08,891 - INFO  - ==> Top1: 90.520    Top5: 99.680    Loss: 0.359

2022-11-03 23:15:08,917 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:15:08,917 - INFO  - Scoreboard best 2 ==> Epoch [43][Top1: 90.520   Top5: 99.680] Sparsity : 0.850
2022-11-03 23:15:08,918 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.520   Top5: 99.580] Sparsity : 0.849
2022-11-03 23:15:09,013 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:15:09,013 - INFO  - >>>>>>>> Epoch  44
2022-11-03 23:15:09,015 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:15:13,029 - INFO  - Training [44][   20/  391]   Loss 0.074185   Top1 97.226562   Top5 100.000000   BatchTime 0.200689   LR 0.001000   
2022-11-03 23:15:15,053 - INFO  - Training [44][   40/  391]   Loss 0.069336   Top1 97.578125   Top5 100.000000   BatchTime 0.150965   LR 0.001000   
2022-11-03 23:15:17,047 - INFO  - Training [44][   60/  391]   Loss 0.072109   Top1 97.330729   Top5 100.000000   BatchTime 0.133872   LR 0.001000   
2022-11-03 23:15:19,070 - INFO  - Training [44][   80/  391]   Loss 0.074232   Top1 97.246094   Top5 99.990234   BatchTime 0.125687   LR 0.001000   
2022-11-03 23:15:21,088 - INFO  - Training [44][  100/  391]   Loss 0.072378   Top1 97.375000   Top5 99.992188   BatchTime 0.120728   LR 0.001000   
2022-11-03 23:15:23,107 - INFO  - Training [44][  120/  391]   Loss 0.072539   Top1 97.363281   Top5 99.993490   BatchTime 0.117431   LR 0.001000   
2022-11-03 23:15:25,113 - INFO  - Training [44][  140/  391]   Loss 0.070951   Top1 97.427455   Top5 99.994420   BatchTime 0.114983   LR 0.001000   
2022-11-03 23:15:27,127 - INFO  - Training [44][  160/  391]   Loss 0.070420   Top1 97.451172   Top5 99.995117   BatchTime 0.113198   LR 0.001000   
2022-11-03 23:15:29,158 - INFO  - Training [44][  180/  391]   Loss 0.072561   Top1 97.361111   Top5 99.995660   BatchTime 0.111905   LR 0.001000   
2022-11-03 23:15:31,178 - INFO  - Training [44][  200/  391]   Loss 0.071333   Top1 97.425781   Top5 99.996094   BatchTime 0.110813   LR 0.001000   
2022-11-03 23:15:33,206 - INFO  - Training [44][  220/  391]   Loss 0.070598   Top1 97.443182   Top5 99.996449   BatchTime 0.109959   LR 0.001000   
2022-11-03 23:15:35,208 - INFO  - Training [44][  240/  391]   Loss 0.070121   Top1 97.441406   Top5 99.996745   BatchTime 0.109138   LR 0.001000   
2022-11-03 23:15:37,240 - INFO  - Training [44][  260/  391]   Loss 0.070016   Top1 97.454928   Top5 99.996995   BatchTime 0.108558   LR 0.001000   
2022-11-03 23:15:39,242 - INFO  - Training [44][  280/  391]   Loss 0.070731   Top1 97.419085   Top5 99.994420   BatchTime 0.107951   LR 0.001000   
2022-11-03 23:15:41,243 - INFO  - Training [44][  300/  391]   Loss 0.070183   Top1 97.460938   Top5 99.994792   BatchTime 0.107424   LR 0.001000   
2022-11-03 23:15:43,254 - INFO  - Training [44][  320/  391]   Loss 0.069832   Top1 97.475586   Top5 99.995117   BatchTime 0.106997   LR 0.001000   
2022-11-03 23:15:45,213 - INFO  - Training [44][  340/  391]   Loss 0.069796   Top1 97.479320   Top5 99.995404   BatchTime 0.106462   LR 0.001000   
2022-11-03 23:15:47,168 - INFO  - Training [44][  360/  391]   Loss 0.069399   Top1 97.489149   Top5 99.993490   BatchTime 0.105979   LR 0.001000   
2022-11-03 23:15:49,152 - INFO  - Training [44][  380/  391]   Loss 0.069634   Top1 97.487664   Top5 99.993832   BatchTime 0.105622   LR 0.001000   
2022-11-03 23:15:50,247 - INFO  - ==> Top1: 97.500    Top5: 99.994    Loss: 0.069

2022-11-03 23:15:50,248 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:15:52,863 - INFO  - Validation [44][   20/   79]   Loss 0.370398   Top1 90.937500   Top5 99.492188   BatchTime 0.130655   
2022-11-03 23:15:53,555 - INFO  - Validation [44][   40/   79]   Loss 0.372600   Top1 90.820312   Top5 99.511719   BatchTime 0.082638   
2022-11-03 23:15:54,212 - INFO  - Validation [44][   60/   79]   Loss 0.369124   Top1 90.820312   Top5 99.583333   BatchTime 0.066041   
2022-11-03 23:15:54,987 - INFO  - ==> Top1: 90.560    Top5: 99.630    Loss: 0.367

2022-11-03 23:15:55,013 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.560   Top5: 99.630] Sparsity : 0.850
2022-11-03 23:15:55,014 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:15:55,014 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.520   Top5: 99.680] Sparsity : 0.850
2022-11-03 23:15:55,211 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:15:55,212 - INFO  - >>>>>>>> Epoch  45
2022-11-03 23:15:55,212 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:15:59,146 - INFO  - Training [45][   20/  391]   Loss 0.064613   Top1 97.617188   Top5 100.000000   BatchTime 0.196685   LR 0.001000   
2022-11-03 23:16:01,137 - INFO  - Training [45][   40/  391]   Loss 0.067171   Top1 97.597656   Top5 100.000000   BatchTime 0.148098   LR 0.001000   
2022-11-03 23:16:03,149 - INFO  - Training [45][   60/  391]   Loss 0.066226   Top1 97.643229   Top5 100.000000   BatchTime 0.132272   LR 0.001000   
2022-11-03 23:16:05,167 - INFO  - Training [45][   80/  391]   Loss 0.064189   Top1 97.763672   Top5 100.000000   BatchTime 0.124434   LR 0.001000   
2022-11-03 23:16:07,166 - INFO  - Training [45][  100/  391]   Loss 0.067680   Top1 97.640625   Top5 100.000000   BatchTime 0.119530   LR 0.001000   
2022-11-03 23:16:09,173 - INFO  - Training [45][  120/  391]   Loss 0.065219   Top1 97.721354   Top5 100.000000   BatchTime 0.116339   LR 0.001000   
2022-11-03 23:16:11,190 - INFO  - Training [45][  140/  391]   Loss 0.066164   Top1 97.689732   Top5 99.994420   BatchTime 0.114120   LR 0.001000   
2022-11-03 23:16:13,203 - INFO  - Training [45][  160/  391]   Loss 0.067137   Top1 97.695312   Top5 99.985352   BatchTime 0.112437   LR 0.001000   
2022-11-03 23:16:15,205 - INFO  - Training [45][  180/  391]   Loss 0.067733   Top1 97.630208   Top5 99.986979   BatchTime 0.111069   LR 0.001000   
2022-11-03 23:16:17,217 - INFO  - Training [45][  200/  391]   Loss 0.067126   Top1 97.652344   Top5 99.988281   BatchTime 0.110020   LR 0.001000   
2022-11-03 23:16:19,316 - INFO  - Training [45][  220/  391]   Loss 0.066933   Top1 97.652699   Top5 99.989347   BatchTime 0.109561   LR 0.001000   
2022-11-03 23:16:21,332 - INFO  - Training [45][  240/  391]   Loss 0.067328   Top1 97.643229   Top5 99.990234   BatchTime 0.108831   LR 0.001000   
2022-11-03 23:16:23,332 - INFO  - Training [45][  260/  391]   Loss 0.067085   Top1 97.650240   Top5 99.990986   BatchTime 0.108149   LR 0.001000   
2022-11-03 23:16:25,331 - INFO  - Training [45][  280/  391]   Loss 0.066909   Top1 97.661830   Top5 99.991629   BatchTime 0.107563   LR 0.001000   
2022-11-03 23:16:27,361 - INFO  - Training [45][  300/  391]   Loss 0.067693   Top1 97.611979   Top5 99.992188   BatchTime 0.107161   LR 0.001000   
2022-11-03 23:16:29,363 - INFO  - Training [45][  320/  391]   Loss 0.068198   Top1 97.622070   Top5 99.992676   BatchTime 0.106718   LR 0.001000   
2022-11-03 23:16:31,273 - INFO  - Training [45][  340/  391]   Loss 0.067802   Top1 97.644761   Top5 99.993107   BatchTime 0.106058   LR 0.001000   
2022-11-03 23:16:33,214 - INFO  - Training [45][  360/  391]   Loss 0.067843   Top1 97.621528   Top5 99.993490   BatchTime 0.105557   LR 0.001000   
2022-11-03 23:16:35,187 - INFO  - Training [45][  380/  391]   Loss 0.068127   Top1 97.608964   Top5 99.991776   BatchTime 0.105194   LR 0.001000   
2022-11-03 23:16:36,215 - INFO  - ==> Top1: 97.596    Top5: 99.992    Loss: 0.068

2022-11-03 23:16:36,216 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:16:38,817 - INFO  - Validation [45][   20/   79]   Loss 0.367265   Top1 90.625000   Top5 99.531250   BatchTime 0.130020   
2022-11-03 23:16:39,505 - INFO  - Validation [45][   40/   79]   Loss 0.375052   Top1 90.429688   Top5 99.570312   BatchTime 0.082199   
2022-11-03 23:16:40,115 - INFO  - Validation [45][   60/   79]   Loss 0.369131   Top1 90.664062   Top5 99.596354   BatchTime 0.064977   
2022-11-03 23:16:40,913 - INFO  - ==> Top1: 90.450    Top5: 99.620    Loss: 0.368

2022-11-03 23:16:40,938 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.560   Top5: 99.630] Sparsity : 0.850
2022-11-03 23:16:40,939 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:16:40,939 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.520   Top5: 99.680] Sparsity : 0.850
2022-11-03 23:16:41,041 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:16:41,041 - INFO  - >>>>>>>> Epoch  46
2022-11-03 23:16:41,043 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:16:45,009 - INFO  - Training [46][   20/  391]   Loss 0.057877   Top1 98.007812   Top5 100.000000   BatchTime 0.198288   LR 0.001000   
2022-11-03 23:16:47,039 - INFO  - Training [46][   40/  391]   Loss 0.066527   Top1 97.695312   Top5 100.000000   BatchTime 0.149904   LR 0.001000   
2022-11-03 23:16:49,058 - INFO  - Training [46][   60/  391]   Loss 0.067444   Top1 97.734375   Top5 99.986979   BatchTime 0.133590   LR 0.001000   
2022-11-03 23:16:51,065 - INFO  - Training [46][   80/  391]   Loss 0.066527   Top1 97.744141   Top5 99.990234   BatchTime 0.125274   LR 0.001000   
2022-11-03 23:16:53,070 - INFO  - Training [46][  100/  391]   Loss 0.066495   Top1 97.742188   Top5 99.992188   BatchTime 0.120267   LR 0.001000   
2022-11-03 23:16:55,088 - INFO  - Training [46][  120/  391]   Loss 0.065572   Top1 97.779948   Top5 99.993490   BatchTime 0.117045   LR 0.001000   
2022-11-03 23:16:57,104 - INFO  - Training [46][  140/  391]   Loss 0.064734   Top1 97.790179   Top5 99.994420   BatchTime 0.114721   LR 0.001000   
2022-11-03 23:16:59,099 - INFO  - Training [46][  160/  391]   Loss 0.064469   Top1 97.783203   Top5 99.995117   BatchTime 0.112849   LR 0.001000   
2022-11-03 23:17:01,119 - INFO  - Training [46][  180/  391]   Loss 0.064640   Top1 97.782118   Top5 99.995660   BatchTime 0.111534   LR 0.001000   
2022-11-03 23:17:03,133 - INFO  - Training [46][  200/  391]   Loss 0.064107   Top1 97.816406   Top5 99.996094   BatchTime 0.110450   LR 0.001000   
2022-11-03 23:17:05,128 - INFO  - Training [46][  220/  391]   Loss 0.065013   Top1 97.755682   Top5 99.996449   BatchTime 0.109475   LR 0.001000   
2022-11-03 23:17:07,120 - INFO  - Training [46][  240/  391]   Loss 0.064867   Top1 97.757161   Top5 99.996745   BatchTime 0.108652   LR 0.001000   
2022-11-03 23:17:09,112 - INFO  - Training [46][  260/  391]   Loss 0.064594   Top1 97.755409   Top5 99.996995   BatchTime 0.107957   LR 0.001000   
2022-11-03 23:17:11,135 - INFO  - Training [46][  280/  391]   Loss 0.063928   Top1 97.756696   Top5 99.994420   BatchTime 0.107469   LR 0.001000   
2022-11-03 23:17:13,147 - INFO  - Training [46][  300/  391]   Loss 0.064765   Top1 97.721354   Top5 99.994792   BatchTime 0.107012   LR 0.001000   
2022-11-03 23:17:15,138 - INFO  - Training [46][  320/  391]   Loss 0.065274   Top1 97.714844   Top5 99.995117   BatchTime 0.106547   LR 0.001000   
2022-11-03 23:17:17,100 - INFO  - Training [46][  340/  391]   Loss 0.065847   Top1 97.660846   Top5 99.993107   BatchTime 0.106048   LR 0.001000   
2022-11-03 23:17:19,047 - INFO  - Training [46][  360/  391]   Loss 0.066125   Top1 97.643229   Top5 99.993490   BatchTime 0.105566   LR 0.001000   
2022-11-03 23:17:21,067 - INFO  - Training [46][  380/  391]   Loss 0.066435   Top1 97.623355   Top5 99.991776   BatchTime 0.105324   LR 0.001000   
2022-11-03 23:17:22,108 - INFO  - ==> Top1: 97.626    Top5: 99.992    Loss: 0.066

2022-11-03 23:17:22,109 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:17:24,701 - INFO  - Validation [46][   20/   79]   Loss 0.363241   Top1 90.703125   Top5 99.531250   BatchTime 0.129523   
2022-11-03 23:17:25,392 - INFO  - Validation [46][   40/   79]   Loss 0.374514   Top1 90.566406   Top5 99.570312   BatchTime 0.082045   
2022-11-03 23:17:26,041 - INFO  - Validation [46][   60/   79]   Loss 0.370686   Top1 90.625000   Top5 99.596354   BatchTime 0.065520   
2022-11-03 23:17:26,808 - INFO  - ==> Top1: 90.390    Top5: 99.620    Loss: 0.369

2022-11-03 23:17:26,834 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.560   Top5: 99.630] Sparsity : 0.850
2022-11-03 23:17:26,835 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:17:26,835 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.520   Top5: 99.680] Sparsity : 0.850
2022-11-03 23:17:26,927 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:17:26,927 - INFO  - >>>>>>>> Epoch  47
2022-11-03 23:17:26,928 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:17:30,910 - INFO  - Training [47][   20/  391]   Loss 0.058174   Top1 98.242188   Top5 100.000000   BatchTime 0.199095   LR 0.001000   
2022-11-03 23:17:32,924 - INFO  - Training [47][   40/  391]   Loss 0.058955   Top1 98.027344   Top5 100.000000   BatchTime 0.149896   LR 0.001000   
2022-11-03 23:17:34,917 - INFO  - Training [47][   60/  391]   Loss 0.063916   Top1 97.864583   Top5 100.000000   BatchTime 0.133148   LR 0.001000   
2022-11-03 23:17:36,926 - INFO  - Training [47][   80/  391]   Loss 0.065807   Top1 97.724609   Top5 99.990234   BatchTime 0.124970   LR 0.001000   
2022-11-03 23:17:38,938 - INFO  - Training [47][  100/  391]   Loss 0.066029   Top1 97.679688   Top5 99.992188   BatchTime 0.120095   LR 0.001000   
2022-11-03 23:17:40,937 - INFO  - Training [47][  120/  391]   Loss 0.067216   Top1 97.604167   Top5 99.993490   BatchTime 0.116744   LR 0.001000   
2022-11-03 23:17:42,955 - INFO  - Training [47][  140/  391]   Loss 0.066675   Top1 97.606027   Top5 99.994420   BatchTime 0.114474   LR 0.001000   
2022-11-03 23:17:44,958 - INFO  - Training [47][  160/  391]   Loss 0.067119   Top1 97.568359   Top5 99.995117   BatchTime 0.112684   LR 0.001000   
2022-11-03 23:17:46,962 - INFO  - Training [47][  180/  391]   Loss 0.066651   Top1 97.621528   Top5 99.995660   BatchTime 0.111298   LR 0.001000   
2022-11-03 23:17:48,971 - INFO  - Training [47][  200/  391]   Loss 0.066642   Top1 97.613281   Top5 99.992188   BatchTime 0.110214   LR 0.001000   
2022-11-03 23:17:50,972 - INFO  - Training [47][  220/  391]   Loss 0.067106   Top1 97.599432   Top5 99.992898   BatchTime 0.109292   LR 0.001000   
2022-11-03 23:17:52,977 - INFO  - Training [47][  240/  391]   Loss 0.066760   Top1 97.639974   Top5 99.993490   BatchTime 0.108538   LR 0.001000   
2022-11-03 23:17:55,076 - INFO  - Training [47][  260/  391]   Loss 0.066654   Top1 97.635216   Top5 99.993990   BatchTime 0.108260   LR 0.001000   
2022-11-03 23:17:57,070 - INFO  - Training [47][  280/  391]   Loss 0.067016   Top1 97.628348   Top5 99.994420   BatchTime 0.107647   LR 0.001000   
2022-11-03 23:17:59,071 - INFO  - Training [47][  300/  391]   Loss 0.067718   Top1 97.601562   Top5 99.994792   BatchTime 0.107141   LR 0.001000   
2022-11-03 23:18:01,056 - INFO  - Training [47][  320/  391]   Loss 0.067326   Top1 97.631836   Top5 99.995117   BatchTime 0.106647   LR 0.001000   
2022-11-03 23:18:03,021 - INFO  - Training [47][  340/  391]   Loss 0.067120   Top1 97.621783   Top5 99.995404   BatchTime 0.106154   LR 0.001000   
2022-11-03 23:18:04,971 - INFO  - Training [47][  360/  391]   Loss 0.067257   Top1 97.621528   Top5 99.995660   BatchTime 0.105674   LR 0.001000   
2022-11-03 23:18:06,952 - INFO  - Training [47][  380/  391]   Loss 0.067473   Top1 97.619243   Top5 99.995888   BatchTime 0.105325   LR 0.001000   
2022-11-03 23:18:08,016 - INFO  - ==> Top1: 97.618    Top5: 99.996    Loss: 0.067

2022-11-03 23:18:08,017 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:18:10,599 - INFO  - Validation [47][   20/   79]   Loss 0.383604   Top1 90.390625   Top5 99.609375   BatchTime 0.129072   
2022-11-03 23:18:11,284 - INFO  - Validation [47][   40/   79]   Loss 0.384480   Top1 90.312500   Top5 99.628906   BatchTime 0.081669   
2022-11-03 23:18:11,863 - INFO  - Validation [47][   60/   79]   Loss 0.373734   Top1 90.664062   Top5 99.635417   BatchTime 0.064093   
2022-11-03 23:18:12,640 - INFO  - ==> Top1: 90.470    Top5: 99.650    Loss: 0.369

2022-11-03 23:18:12,666 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.560   Top5: 99.630] Sparsity : 0.850
2022-11-03 23:18:12,667 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:18:12,667 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.520   Top5: 99.680] Sparsity : 0.850
2022-11-03 23:18:12,764 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:18:12,765 - INFO  - >>>>>>>> Epoch  48
2022-11-03 23:18:12,766 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:18:16,720 - INFO  - Training [48][   20/  391]   Loss 0.064459   Top1 97.578125   Top5 99.960938   BatchTime 0.197673   LR 0.001000   
2022-11-03 23:18:18,733 - INFO  - Training [48][   40/  391]   Loss 0.063557   Top1 97.597656   Top5 99.980469   BatchTime 0.149157   LR 0.001000   
2022-11-03 23:18:20,742 - INFO  - Training [48][   60/  391]   Loss 0.060891   Top1 97.773438   Top5 99.973958   BatchTime 0.132928   LR 0.001000   
2022-11-03 23:18:22,739 - INFO  - Training [48][   80/  391]   Loss 0.062806   Top1 97.773438   Top5 99.980469   BatchTime 0.124649   LR 0.001000   
2022-11-03 23:18:24,744 - INFO  - Training [48][  100/  391]   Loss 0.064014   Top1 97.757812   Top5 99.984375   BatchTime 0.119774   LR 0.001000   
2022-11-03 23:18:26,749 - INFO  - Training [48][  120/  391]   Loss 0.063303   Top1 97.792969   Top5 99.986979   BatchTime 0.116518   LR 0.001000   
2022-11-03 23:18:28,751 - INFO  - Training [48][  140/  391]   Loss 0.064175   Top1 97.762277   Top5 99.988839   BatchTime 0.114171   LR 0.001000   
2022-11-03 23:18:30,766 - INFO  - Training [48][  160/  391]   Loss 0.064979   Top1 97.739258   Top5 99.990234   BatchTime 0.112495   LR 0.001000   
2022-11-03 23:18:32,780 - INFO  - Training [48][  180/  391]   Loss 0.065692   Top1 97.747396   Top5 99.986979   BatchTime 0.111186   LR 0.001000   
2022-11-03 23:18:34,764 - INFO  - Training [48][  200/  391]   Loss 0.065773   Top1 97.734375   Top5 99.988281   BatchTime 0.109985   LR 0.001000   
2022-11-03 23:18:36,762 - INFO  - Training [48][  220/  391]   Loss 0.065892   Top1 97.737926   Top5 99.989347   BatchTime 0.109067   LR 0.001000   
2022-11-03 23:18:38,749 - INFO  - Training [48][  240/  391]   Loss 0.064848   Top1 97.783203   Top5 99.990234   BatchTime 0.108258   LR 0.001000   
2022-11-03 23:18:40,750 - INFO  - Training [48][  260/  391]   Loss 0.065223   Top1 97.761418   Top5 99.990986   BatchTime 0.107625   LR 0.001000   
2022-11-03 23:18:42,757 - INFO  - Training [48][  280/  391]   Loss 0.065321   Top1 97.765067   Top5 99.988839   BatchTime 0.107108   LR 0.001000   
2022-11-03 23:18:44,747 - INFO  - Training [48][  300/  391]   Loss 0.065382   Top1 97.770833   Top5 99.986979   BatchTime 0.106599   LR 0.001000   
2022-11-03 23:18:46,753 - INFO  - Training [48][  320/  391]   Loss 0.064996   Top1 97.790527   Top5 99.987793   BatchTime 0.106206   LR 0.001000   
2022-11-03 23:18:48,712 - INFO  - Training [48][  340/  391]   Loss 0.064915   Top1 97.791820   Top5 99.988511   BatchTime 0.105721   LR 0.001000   
2022-11-03 23:18:50,654 - INFO  - Training [48][  360/  391]   Loss 0.064999   Top1 97.775608   Top5 99.989149   BatchTime 0.105240   LR 0.001000   
2022-11-03 23:18:52,658 - INFO  - Training [48][  380/  391]   Loss 0.064976   Top1 97.765214   Top5 99.989720   BatchTime 0.104975   LR 0.001000   
2022-11-03 23:18:53,757 - INFO  - ==> Top1: 97.748    Top5: 99.990    Loss: 0.066

2022-11-03 23:18:53,758 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:18:56,355 - INFO  - Validation [48][   20/   79]   Loss 0.378735   Top1 90.820312   Top5 99.570312   BatchTime 0.129776   
2022-11-03 23:18:57,049 - INFO  - Validation [48][   40/   79]   Loss 0.383453   Top1 90.488281   Top5 99.589844   BatchTime 0.082232   
2022-11-03 23:18:57,672 - INFO  - Validation [48][   60/   79]   Loss 0.372962   Top1 90.651042   Top5 99.609375   BatchTime 0.065210   
2022-11-03 23:18:58,429 - INFO  - ==> Top1: 90.560    Top5: 99.640    Loss: 0.368

2022-11-03 23:18:58,456 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.560   Top5: 99.640] Sparsity : 0.851
2022-11-03 23:18:58,457 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.560   Top5: 99.630] Sparsity : 0.850
2022-11-03 23:18:58,457 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.530   Top5: 99.650] Sparsity : 0.850
2022-11-03 23:18:58,647 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:18:58,648 - INFO  - >>>>>>>> Epoch  49
2022-11-03 23:18:58,649 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:19:02,622 - INFO  - Training [49][   20/  391]   Loss 0.068837   Top1 97.343750   Top5 100.000000   BatchTime 0.198640   LR 0.001000   
2022-11-03 23:19:04,644 - INFO  - Training [49][   40/  391]   Loss 0.065183   Top1 97.656250   Top5 100.000000   BatchTime 0.149866   LR 0.001000   
2022-11-03 23:19:06,653 - INFO  - Training [49][   60/  391]   Loss 0.066788   Top1 97.526042   Top5 100.000000   BatchTime 0.133404   LR 0.001000   
2022-11-03 23:19:08,654 - INFO  - Training [49][   80/  391]   Loss 0.066472   Top1 97.587891   Top5 99.990234   BatchTime 0.125057   LR 0.001000   
2022-11-03 23:19:10,670 - INFO  - Training [49][  100/  391]   Loss 0.066282   Top1 97.609375   Top5 99.992188   BatchTime 0.120202   LR 0.001000   
2022-11-03 23:19:12,686 - INFO  - Training [49][  120/  391]   Loss 0.066109   Top1 97.578125   Top5 99.993490   BatchTime 0.116968   LR 0.001000   
2022-11-03 23:19:14,702 - INFO  - Training [49][  140/  391]   Loss 0.065167   Top1 97.633929   Top5 99.994420   BatchTime 0.114658   LR 0.001000   
2022-11-03 23:19:16,710 - INFO  - Training [49][  160/  391]   Loss 0.065914   Top1 97.626953   Top5 99.995117   BatchTime 0.112876   LR 0.001000   
2022-11-03 23:19:18,727 - INFO  - Training [49][  180/  391]   Loss 0.066204   Top1 97.608507   Top5 99.995660   BatchTime 0.111543   LR 0.001000   
2022-11-03 23:19:20,739 - INFO  - Training [49][  200/  391]   Loss 0.066504   Top1 97.582031   Top5 99.996094   BatchTime 0.110446   LR 0.001000   
2022-11-03 23:19:22,732 - INFO  - Training [49][  220/  391]   Loss 0.067167   Top1 97.553267   Top5 99.996449   BatchTime 0.109466   LR 0.001000   
2022-11-03 23:19:24,730 - INFO  - Training [49][  240/  391]   Loss 0.066857   Top1 97.555339   Top5 99.996745   BatchTime 0.108666   LR 0.001000   
2022-11-03 23:19:26,749 - INFO  - Training [49][  260/  391]   Loss 0.066065   Top1 97.602163   Top5 99.996995   BatchTime 0.108075   LR 0.001000   
2022-11-03 23:19:28,748 - INFO  - Training [49][  280/  391]   Loss 0.066557   Top1 97.580915   Top5 99.997210   BatchTime 0.107495   LR 0.001000   
2022-11-03 23:19:30,885 - INFO  - Training [49][  300/  391]   Loss 0.066572   Top1 97.596354   Top5 99.997396   BatchTime 0.107449   LR 0.001000   
2022-11-03 23:19:32,871 - INFO  - Training [49][  320/  391]   Loss 0.066472   Top1 97.609863   Top5 99.997559   BatchTime 0.106941   LR 0.001000   
2022-11-03 23:19:34,831 - INFO  - Training [49][  340/  391]   Loss 0.066418   Top1 97.612592   Top5 99.997702   BatchTime 0.106416   LR 0.001000   
2022-11-03 23:19:36,791 - INFO  - Training [49][  360/  391]   Loss 0.066750   Top1 97.601997   Top5 99.997830   BatchTime 0.105947   LR 0.001000   
2022-11-03 23:19:38,785 - INFO  - Training [49][  380/  391]   Loss 0.066759   Top1 97.608964   Top5 99.997944   BatchTime 0.105619   LR 0.001000   
2022-11-03 23:19:39,809 - INFO  - ==> Top1: 97.606    Top5: 99.998    Loss: 0.067

2022-11-03 23:19:39,810 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:19:42,401 - INFO  - Validation [49][   20/   79]   Loss 0.369294   Top1 90.742188   Top5 99.609375   BatchTime 0.129465   
2022-11-03 23:19:43,103 - INFO  - Validation [49][   40/   79]   Loss 0.372537   Top1 90.644531   Top5 99.628906   BatchTime 0.082286   
2022-11-03 23:19:43,691 - INFO  - Validation [49][   60/   79]   Loss 0.365538   Top1 90.794271   Top5 99.622396   BatchTime 0.064662   
2022-11-03 23:19:44,484 - INFO  - ==> Top1: 90.590    Top5: 99.650    Loss: 0.365

2022-11-03 23:19:44,510 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:19:44,511 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 90.560   Top5: 99.640] Sparsity : 0.851
2022-11-03 23:19:44,511 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.560   Top5: 99.630] Sparsity : 0.850
2022-11-03 23:19:44,697 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:19:44,698 - INFO  - >>>>>>>> Epoch  50
2022-11-03 23:19:44,699 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:19:48,684 - INFO  - Training [50][   20/  391]   Loss 0.064400   Top1 97.968750   Top5 100.000000   BatchTime 0.199269   LR 0.001000   
2022-11-03 23:19:50,721 - INFO  - Training [50][   40/  391]   Loss 0.063121   Top1 97.871094   Top5 100.000000   BatchTime 0.150563   LR 0.001000   
2022-11-03 23:19:52,743 - INFO  - Training [50][   60/  391]   Loss 0.062566   Top1 97.916667   Top5 100.000000   BatchTime 0.134066   LR 0.001000   
2022-11-03 23:19:54,736 - INFO  - Training [50][   80/  391]   Loss 0.064154   Top1 97.802734   Top5 99.990234   BatchTime 0.125464   LR 0.001000   
2022-11-03 23:19:56,745 - INFO  - Training [50][  100/  391]   Loss 0.062520   Top1 97.875000   Top5 99.992188   BatchTime 0.120461   LR 0.001000   
2022-11-03 23:19:58,743 - INFO  - Training [50][  120/  391]   Loss 0.063204   Top1 97.851562   Top5 99.993490   BatchTime 0.117030   LR 0.001000   
2022-11-03 23:20:00,740 - INFO  - Training [50][  140/  391]   Loss 0.063717   Top1 97.890625   Top5 99.994420   BatchTime 0.114578   LR 0.001000   
2022-11-03 23:20:02,751 - INFO  - Training [50][  160/  391]   Loss 0.063895   Top1 97.875977   Top5 99.995117   BatchTime 0.112821   LR 0.001000   
2022-11-03 23:20:04,760 - INFO  - Training [50][  180/  391]   Loss 0.064169   Top1 97.890625   Top5 99.995660   BatchTime 0.111447   LR 0.001000   
2022-11-03 23:20:06,769 - INFO  - Training [50][  200/  391]   Loss 0.063674   Top1 97.890625   Top5 99.996094   BatchTime 0.110349   LR 0.001000   
2022-11-03 23:20:08,774 - INFO  - Training [50][  220/  391]   Loss 0.063683   Top1 97.876420   Top5 99.996449   BatchTime 0.109431   LR 0.001000   
2022-11-03 23:20:10,780 - INFO  - Training [50][  240/  391]   Loss 0.062994   Top1 97.887370   Top5 99.993490   BatchTime 0.108667   LR 0.001000   
2022-11-03 23:20:12,788 - INFO  - Training [50][  260/  391]   Loss 0.062779   Top1 97.866587   Top5 99.993990   BatchTime 0.108033   LR 0.001000   
2022-11-03 23:20:14,788 - INFO  - Training [50][  280/  391]   Loss 0.062420   Top1 97.868304   Top5 99.994420   BatchTime 0.107461   LR 0.001000   
2022-11-03 23:20:16,807 - INFO  - Training [50][  300/  391]   Loss 0.062941   Top1 97.846354   Top5 99.994792   BatchTime 0.107024   LR 0.001000   
2022-11-03 23:20:18,820 - INFO  - Training [50][  320/  391]   Loss 0.063387   Top1 97.829590   Top5 99.995117   BatchTime 0.106625   LR 0.001000   
2022-11-03 23:20:20,795 - INFO  - Training [50][  340/  391]   Loss 0.063796   Top1 97.798713   Top5 99.995404   BatchTime 0.106163   LR 0.001000   
2022-11-03 23:20:22,743 - INFO  - Training [50][  360/  391]   Loss 0.063865   Top1 97.795139   Top5 99.995660   BatchTime 0.105677   LR 0.001000   
2022-11-03 23:20:24,710 - INFO  - Training [50][  380/  391]   Loss 0.063455   Top1 97.802220   Top5 99.995888   BatchTime 0.105291   LR 0.001000   
2022-11-03 23:20:25,760 - INFO  - ==> Top1: 97.782    Top5: 99.994    Loss: 0.064

2022-11-03 23:20:25,761 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:20:28,406 - INFO  - Validation [50][   20/   79]   Loss 0.381714   Top1 90.664062   Top5 99.609375   BatchTime 0.132181   
2022-11-03 23:20:29,100 - INFO  - Validation [50][   40/   79]   Loss 0.384129   Top1 90.507812   Top5 99.628906   BatchTime 0.083454   
2022-11-03 23:20:29,721 - INFO  - Validation [50][   60/   79]   Loss 0.371914   Top1 90.703125   Top5 99.661458   BatchTime 0.065979   
2022-11-03 23:20:30,491 - INFO  - ==> Top1: 90.570    Top5: 99.690    Loss: 0.367

2022-11-03 23:20:30,518 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:20:30,518 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:20:30,518 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.560   Top5: 99.640] Sparsity : 0.851
2022-11-03 23:20:30,625 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:20:30,625 - INFO  - >>>>>>>> Epoch  51
2022-11-03 23:20:30,627 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:20:34,557 - INFO  - Training [51][   20/  391]   Loss 0.054286   Top1 98.203125   Top5 100.000000   BatchTime 0.196519   LR 0.001000   
2022-11-03 23:20:36,573 - INFO  - Training [51][   40/  391]   Loss 0.058610   Top1 97.988281   Top5 100.000000   BatchTime 0.148645   LR 0.001000   
2022-11-03 23:20:38,588 - INFO  - Training [51][   60/  391]   Loss 0.058851   Top1 98.059896   Top5 100.000000   BatchTime 0.132684   LR 0.001000   
2022-11-03 23:20:40,623 - INFO  - Training [51][   80/  391]   Loss 0.060980   Top1 98.007812   Top5 100.000000   BatchTime 0.124949   LR 0.001000   
2022-11-03 23:20:42,638 - INFO  - Training [51][  100/  391]   Loss 0.061270   Top1 98.007812   Top5 100.000000   BatchTime 0.120109   LR 0.001000   
2022-11-03 23:20:44,638 - INFO  - Training [51][  120/  391]   Loss 0.061338   Top1 98.020833   Top5 100.000000   BatchTime 0.116760   LR 0.001000   
2022-11-03 23:20:46,641 - INFO  - Training [51][  140/  391]   Loss 0.061826   Top1 97.985491   Top5 100.000000   BatchTime 0.114382   LR 0.001000   
2022-11-03 23:20:48,641 - INFO  - Training [51][  160/  391]   Loss 0.061638   Top1 97.949219   Top5 99.995117   BatchTime 0.112586   LR 0.001000   
2022-11-03 23:20:50,654 - INFO  - Training [51][  180/  391]   Loss 0.062092   Top1 97.929688   Top5 99.995660   BatchTime 0.111259   LR 0.001000   
2022-11-03 23:20:52,666 - INFO  - Training [51][  200/  391]   Loss 0.062829   Top1 97.910156   Top5 99.996094   BatchTime 0.110193   LR 0.001000   
2022-11-03 23:20:54,663 - INFO  - Training [51][  220/  391]   Loss 0.064156   Top1 97.865767   Top5 99.996449   BatchTime 0.109255   LR 0.001000   
2022-11-03 23:20:56,681 - INFO  - Training [51][  240/  391]   Loss 0.063679   Top1 97.871094   Top5 99.996745   BatchTime 0.108557   LR 0.001000   
2022-11-03 23:20:58,688 - INFO  - Training [51][  260/  391]   Loss 0.063596   Top1 97.860577   Top5 99.996995   BatchTime 0.107926   LR 0.001000   
2022-11-03 23:21:00,696 - INFO  - Training [51][  280/  391]   Loss 0.063991   Top1 97.848772   Top5 99.997210   BatchTime 0.107386   LR 0.001000   
2022-11-03 23:21:02,713 - INFO  - Training [51][  300/  391]   Loss 0.064564   Top1 97.807292   Top5 99.997396   BatchTime 0.106952   LR 0.001000   
2022-11-03 23:21:04,698 - INFO  - Training [51][  320/  391]   Loss 0.064697   Top1 97.778320   Top5 99.997559   BatchTime 0.106468   LR 0.001000   
2022-11-03 23:21:06,655 - INFO  - Training [51][  340/  391]   Loss 0.064545   Top1 97.794118   Top5 99.997702   BatchTime 0.105964   LR 0.001000   
2022-11-03 23:21:08,602 - INFO  - Training [51][  360/  391]   Loss 0.064483   Top1 97.799479   Top5 99.997830   BatchTime 0.105485   LR 0.001000   
2022-11-03 23:21:10,687 - INFO  - Training [51][  380/  391]   Loss 0.064763   Top1 97.777549   Top5 99.997944   BatchTime 0.105420   LR 0.001000   
2022-11-03 23:21:11,768 - INFO  - ==> Top1: 97.780    Top5: 99.998    Loss: 0.065

2022-11-03 23:21:11,769 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:21:14,360 - INFO  - Validation [51][   20/   79]   Loss 0.372411   Top1 90.898438   Top5 99.570312   BatchTime 0.129470   
2022-11-03 23:21:15,036 - INFO  - Validation [51][   40/   79]   Loss 0.380835   Top1 90.566406   Top5 99.589844   BatchTime 0.081638   
2022-11-03 23:21:15,629 - INFO  - Validation [51][   60/   79]   Loss 0.372672   Top1 90.664062   Top5 99.583333   BatchTime 0.064320   
2022-11-03 23:21:16,382 - INFO  - ==> Top1: 90.520    Top5: 99.630    Loss: 0.371

2022-11-03 23:21:16,407 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:21:16,408 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:21:16,408 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.560   Top5: 99.640] Sparsity : 0.851
2022-11-03 23:21:16,520 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:21:16,520 - INFO  - >>>>>>>> Epoch  52
2022-11-03 23:21:16,521 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:21:20,519 - INFO  - Training [52][   20/  391]   Loss 0.061428   Top1 97.890625   Top5 100.000000   BatchTime 0.199894   LR 0.001000   
2022-11-03 23:21:22,534 - INFO  - Training [52][   40/  391]   Loss 0.063770   Top1 97.597656   Top5 100.000000   BatchTime 0.150334   LR 0.001000   
2022-11-03 23:21:24,540 - INFO  - Training [52][   60/  391]   Loss 0.065520   Top1 97.656250   Top5 100.000000   BatchTime 0.133652   LR 0.001000   
2022-11-03 23:21:26,558 - INFO  - Training [52][   80/  391]   Loss 0.064157   Top1 97.675781   Top5 100.000000   BatchTime 0.125460   LR 0.001000   
2022-11-03 23:21:28,576 - INFO  - Training [52][  100/  391]   Loss 0.065347   Top1 97.726562   Top5 100.000000   BatchTime 0.120548   LR 0.001000   
2022-11-03 23:21:30,649 - INFO  - Training [52][  120/  391]   Loss 0.065364   Top1 97.734375   Top5 100.000000   BatchTime 0.117731   LR 0.001000   
2022-11-03 23:21:32,668 - INFO  - Training [52][  140/  391]   Loss 0.064551   Top1 97.767857   Top5 100.000000   BatchTime 0.115334   LR 0.001000   
2022-11-03 23:21:34,621 - INFO  - Training [52][  160/  391]   Loss 0.064311   Top1 97.763672   Top5 99.995117   BatchTime 0.113126   LR 0.001000   
2022-11-03 23:21:36,622 - INFO  - Training [52][  180/  391]   Loss 0.063962   Top1 97.777778   Top5 99.995660   BatchTime 0.111668   LR 0.001000   
2022-11-03 23:21:38,624 - INFO  - Training [52][  200/  391]   Loss 0.064153   Top1 97.773438   Top5 99.996094   BatchTime 0.110511   LR 0.001000   
2022-11-03 23:21:40,660 - INFO  - Training [52][  220/  391]   Loss 0.064051   Top1 97.745028   Top5 99.996449   BatchTime 0.109720   LR 0.001000   
2022-11-03 23:21:42,686 - INFO  - Training [52][  240/  391]   Loss 0.063684   Top1 97.763672   Top5 99.996745   BatchTime 0.109017   LR 0.001000   
2022-11-03 23:21:44,686 - INFO  - Training [52][  260/  391]   Loss 0.064031   Top1 97.749399   Top5 99.996995   BatchTime 0.108324   LR 0.001000   
2022-11-03 23:21:46,687 - INFO  - Training [52][  280/  391]   Loss 0.063455   Top1 97.739955   Top5 99.997210   BatchTime 0.107733   LR 0.001000   
2022-11-03 23:21:48,681 - INFO  - Training [52][  300/  391]   Loss 0.063564   Top1 97.731771   Top5 99.997396   BatchTime 0.107199   LR 0.001000   
2022-11-03 23:21:50,688 - INFO  - Training [52][  320/  391]   Loss 0.063797   Top1 97.731934   Top5 99.995117   BatchTime 0.106769   LR 0.001000   
2022-11-03 23:21:52,667 - INFO  - Training [52][  340/  391]   Loss 0.063610   Top1 97.750460   Top5 99.995404   BatchTime 0.106309   LR 0.001000   
2022-11-03 23:21:54,623 - INFO  - Training [52][  360/  391]   Loss 0.063664   Top1 97.749566   Top5 99.995660   BatchTime 0.105836   LR 0.001000   
2022-11-03 23:21:56,651 - INFO  - Training [52][  380/  391]   Loss 0.063872   Top1 97.759046   Top5 99.995888   BatchTime 0.105604   LR 0.001000   
2022-11-03 23:21:57,721 - INFO  - ==> Top1: 97.760    Top5: 99.996    Loss: 0.064

2022-11-03 23:21:57,722 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:22:00,324 - INFO  - Validation [52][   20/   79]   Loss 0.389020   Top1 90.468750   Top5 99.648438   BatchTime 0.130013   
2022-11-03 23:22:01,018 - INFO  - Validation [52][   40/   79]   Loss 0.377783   Top1 90.703125   Top5 99.609375   BatchTime 0.082355   
2022-11-03 23:22:01,626 - INFO  - Validation [52][   60/   79]   Loss 0.370771   Top1 90.729167   Top5 99.635417   BatchTime 0.065030   
2022-11-03 23:22:02,399 - INFO  - ==> Top1: 90.590    Top5: 99.670    Loss: 0.367

2022-11-03 23:22:02,425 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:22:02,426 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:22:02,426 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:22:02,676 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_best.pth.tar

2022-11-03 23:22:02,677 - INFO  - >>>>>>>> Epoch  53
2022-11-03 23:22:02,678 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:22:06,654 - INFO  - Training [53][   20/  391]   Loss 0.074182   Top1 97.539062   Top5 100.000000   BatchTime 0.198764   LR 0.001000   
2022-11-03 23:22:08,657 - INFO  - Training [53][   40/  391]   Loss 0.065411   Top1 97.792969   Top5 100.000000   BatchTime 0.149459   LR 0.001000   
2022-11-03 23:22:10,680 - INFO  - Training [53][   60/  391]   Loss 0.063883   Top1 97.760417   Top5 100.000000   BatchTime 0.133356   LR 0.001000   
2022-11-03 23:22:12,689 - INFO  - Training [53][   80/  391]   Loss 0.061551   Top1 97.880859   Top5 99.990234   BatchTime 0.125129   LR 0.001000   
2022-11-03 23:22:14,695 - INFO  - Training [53][  100/  391]   Loss 0.062441   Top1 97.789062   Top5 99.992188   BatchTime 0.120164   LR 0.001000   
2022-11-03 23:22:16,694 - INFO  - Training [53][  120/  391]   Loss 0.062036   Top1 97.838542   Top5 99.993490   BatchTime 0.116796   LR 0.001000   
2022-11-03 23:22:18,706 - INFO  - Training [53][  140/  391]   Loss 0.062910   Top1 97.840402   Top5 99.994420   BatchTime 0.114478   LR 0.001000   
2022-11-03 23:22:20,736 - INFO  - Training [53][  160/  391]   Loss 0.063435   Top1 97.836914   Top5 99.995117   BatchTime 0.112857   LR 0.001000   
2022-11-03 23:22:22,769 - INFO  - Training [53][  180/  391]   Loss 0.062633   Top1 97.899306   Top5 99.995660   BatchTime 0.111613   LR 0.001000   
2022-11-03 23:22:24,784 - INFO  - Training [53][  200/  391]   Loss 0.062164   Top1 97.933594   Top5 99.992188   BatchTime 0.110523   LR 0.001000   
2022-11-03 23:22:26,822 - INFO  - Training [53][  220/  391]   Loss 0.061957   Top1 97.936790   Top5 99.992898   BatchTime 0.109740   LR 0.001000   
2022-11-03 23:22:28,851 - INFO  - Training [53][  240/  391]   Loss 0.062565   Top1 97.926432   Top5 99.993490   BatchTime 0.109050   LR 0.001000   
2022-11-03 23:22:30,863 - INFO  - Training [53][  260/  391]   Loss 0.063542   Top1 97.869591   Top5 99.993990   BatchTime 0.108400   LR 0.001000   
2022-11-03 23:22:32,877 - INFO  - Training [53][  280/  391]   Loss 0.062774   Top1 97.910156   Top5 99.991629   BatchTime 0.107851   LR 0.001000   
2022-11-03 23:22:34,887 - INFO  - Training [53][  300/  391]   Loss 0.063299   Top1 97.888021   Top5 99.989583   BatchTime 0.107361   LR 0.001000   
2022-11-03 23:22:36,905 - INFO  - Training [53][  320/  391]   Loss 0.063320   Top1 97.861328   Top5 99.990234   BatchTime 0.106956   LR 0.001000   
2022-11-03 23:22:38,867 - INFO  - Training [53][  340/  391]   Loss 0.063031   Top1 97.872243   Top5 99.990809   BatchTime 0.106434   LR 0.001000   
2022-11-03 23:22:40,828 - INFO  - Training [53][  360/  391]   Loss 0.063104   Top1 97.860243   Top5 99.991319   BatchTime 0.105970   LR 0.001000   
2022-11-03 23:22:42,855 - INFO  - Training [53][  380/  391]   Loss 0.063181   Top1 97.843339   Top5 99.991776   BatchTime 0.105726   LR 0.001000   
2022-11-03 23:22:43,939 - INFO  - ==> Top1: 97.830    Top5: 99.990    Loss: 0.064

2022-11-03 23:22:43,940 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:22:46,528 - INFO  - Validation [53][   20/   79]   Loss 0.389278   Top1 90.507812   Top5 99.570312   BatchTime 0.129334   
2022-11-03 23:22:47,208 - INFO  - Validation [53][   40/   79]   Loss 0.391162   Top1 90.449219   Top5 99.531250   BatchTime 0.081656   
2022-11-03 23:22:47,806 - INFO  - Validation [53][   60/   79]   Loss 0.379665   Top1 90.638021   Top5 99.583333   BatchTime 0.064405   
2022-11-03 23:22:48,567 - INFO  - ==> Top1: 90.560    Top5: 99.620    Loss: 0.376

2022-11-03 23:22:48,595 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:22:48,596 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:22:48,596 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:22:48,692 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:22:48,693 - INFO  - >>>>>>>> Epoch  54
2022-11-03 23:22:48,694 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:22:52,801 - INFO  - Training [54][   20/  391]   Loss 0.067180   Top1 97.500000   Top5 100.000000   BatchTime 0.205335   LR 0.001000   
2022-11-03 23:22:54,801 - INFO  - Training [54][   40/  391]   Loss 0.069323   Top1 97.441406   Top5 100.000000   BatchTime 0.152673   LR 0.001000   
2022-11-03 23:22:56,826 - INFO  - Training [54][   60/  391]   Loss 0.067295   Top1 97.500000   Top5 100.000000   BatchTime 0.135526   LR 0.001000   
2022-11-03 23:22:58,831 - INFO  - Training [54][   80/  391]   Loss 0.068458   Top1 97.519531   Top5 100.000000   BatchTime 0.126705   LR 0.001000   
2022-11-03 23:23:00,846 - INFO  - Training [54][  100/  391]   Loss 0.069411   Top1 97.476562   Top5 100.000000   BatchTime 0.121518   LR 0.001000   
2022-11-03 23:23:02,876 - INFO  - Training [54][  120/  391]   Loss 0.069359   Top1 97.460938   Top5 100.000000   BatchTime 0.118178   LR 0.001000   
2022-11-03 23:23:04,893 - INFO  - Training [54][  140/  391]   Loss 0.069594   Top1 97.483259   Top5 100.000000   BatchTime 0.115705   LR 0.001000   
2022-11-03 23:23:06,904 - INFO  - Training [54][  160/  391]   Loss 0.068024   Top1 97.548828   Top5 100.000000   BatchTime 0.113807   LR 0.001000   
2022-11-03 23:23:08,911 - INFO  - Training [54][  180/  391]   Loss 0.069174   Top1 97.521701   Top5 100.000000   BatchTime 0.112313   LR 0.001000   
2022-11-03 23:23:10,908 - INFO  - Training [54][  200/  391]   Loss 0.068639   Top1 97.558594   Top5 100.000000   BatchTime 0.111067   LR 0.001000   
2022-11-03 23:23:12,925 - INFO  - Training [54][  220/  391]   Loss 0.067962   Top1 97.574574   Top5 100.000000   BatchTime 0.110135   LR 0.001000   
2022-11-03 23:23:14,921 - INFO  - Training [54][  240/  391]   Loss 0.067275   Top1 97.620443   Top5 100.000000   BatchTime 0.109274   LR 0.001000   
2022-11-03 23:23:16,941 - INFO  - Training [54][  260/  391]   Loss 0.067208   Top1 97.611178   Top5 100.000000   BatchTime 0.108639   LR 0.001000   
2022-11-03 23:23:18,961 - INFO  - Training [54][  280/  391]   Loss 0.066980   Top1 97.619978   Top5 100.000000   BatchTime 0.108093   LR 0.001000   
2022-11-03 23:23:20,953 - INFO  - Training [54][  300/  391]   Loss 0.066476   Top1 97.666667   Top5 99.997396   BatchTime 0.107526   LR 0.001000   
2022-11-03 23:23:22,955 - INFO  - Training [54][  320/  391]   Loss 0.066340   Top1 97.670898   Top5 99.997559   BatchTime 0.107063   LR 0.001000   
2022-11-03 23:23:24,913 - INFO  - Training [54][  340/  391]   Loss 0.066169   Top1 97.683824   Top5 99.997702   BatchTime 0.106524   LR 0.001000   
2022-11-03 23:23:26,897 - INFO  - Training [54][  360/  391]   Loss 0.066574   Top1 97.675781   Top5 99.997830   BatchTime 0.106116   LR 0.001000   
2022-11-03 23:23:28,889 - INFO  - Training [54][  380/  391]   Loss 0.066736   Top1 97.680921   Top5 99.997944   BatchTime 0.105773   LR 0.001000   
2022-11-03 23:23:29,938 - INFO  - ==> Top1: 97.672    Top5: 99.998    Loss: 0.067

2022-11-03 23:23:29,939 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:23:32,553 - INFO  - Validation [54][   20/   79]   Loss 0.386461   Top1 90.937500   Top5 99.648438   BatchTime 0.130620   
2022-11-03 23:23:33,235 - INFO  - Validation [54][   40/   79]   Loss 0.387357   Top1 90.488281   Top5 99.550781   BatchTime 0.082365   
2022-11-03 23:23:33,787 - INFO  - Validation [54][   60/   79]   Loss 0.378443   Top1 90.807292   Top5 99.609375   BatchTime 0.064114   
2022-11-03 23:23:34,562 - INFO  - ==> Top1: 90.570    Top5: 99.650    Loss: 0.375

2022-11-03 23:23:34,585 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:23:34,586 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:23:34,586 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:23:34,678 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:23:34,678 - INFO  - >>>>>>>> Epoch  55
2022-11-03 23:23:34,680 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:23:38,648 - INFO  - Training [55][   20/  391]   Loss 0.062834   Top1 97.617188   Top5 100.000000   BatchTime 0.198409   LR 0.001000   
2022-11-03 23:23:40,672 - INFO  - Training [55][   40/  391]   Loss 0.060159   Top1 97.812500   Top5 100.000000   BatchTime 0.149798   LR 0.001000   
2022-11-03 23:23:42,708 - INFO  - Training [55][   60/  391]   Loss 0.061062   Top1 97.812500   Top5 100.000000   BatchTime 0.133798   LR 0.001000   
2022-11-03 23:23:44,731 - INFO  - Training [55][   80/  391]   Loss 0.063540   Top1 97.753906   Top5 99.990234   BatchTime 0.125642   LR 0.001000   
2022-11-03 23:23:46,762 - INFO  - Training [55][  100/  391]   Loss 0.064841   Top1 97.710938   Top5 99.992188   BatchTime 0.120814   LR 0.001000   
2022-11-03 23:23:48,769 - INFO  - Training [55][  120/  391]   Loss 0.063754   Top1 97.825521   Top5 99.993490   BatchTime 0.117405   LR 0.001000   
2022-11-03 23:23:50,776 - INFO  - Training [55][  140/  391]   Loss 0.064370   Top1 97.779018   Top5 99.988839   BatchTime 0.114972   LR 0.001000   
2022-11-03 23:23:52,776 - INFO  - Training [55][  160/  391]   Loss 0.063018   Top1 97.827148   Top5 99.990234   BatchTime 0.113099   LR 0.001000   
2022-11-03 23:23:54,783 - INFO  - Training [55][  180/  391]   Loss 0.063269   Top1 97.795139   Top5 99.986979   BatchTime 0.111681   LR 0.001000   
2022-11-03 23:23:56,785 - INFO  - Training [55][  200/  391]   Loss 0.063693   Top1 97.789062   Top5 99.988281   BatchTime 0.110521   LR 0.001000   
2022-11-03 23:23:58,776 - INFO  - Training [55][  220/  391]   Loss 0.063907   Top1 97.776989   Top5 99.989347   BatchTime 0.109524   LR 0.001000   
2022-11-03 23:24:00,783 - INFO  - Training [55][  240/  391]   Loss 0.064628   Top1 97.734375   Top5 99.990234   BatchTime 0.108760   LR 0.001000   
2022-11-03 23:24:02,805 - INFO  - Training [55][  260/  391]   Loss 0.064642   Top1 97.743389   Top5 99.990986   BatchTime 0.108170   LR 0.001000   
2022-11-03 23:24:04,806 - INFO  - Training [55][  280/  391]   Loss 0.064980   Top1 97.734375   Top5 99.991629   BatchTime 0.107591   LR 0.001000   
2022-11-03 23:24:06,798 - INFO  - Training [55][  300/  391]   Loss 0.065355   Top1 97.703125   Top5 99.992188   BatchTime 0.107057   LR 0.001000   
2022-11-03 23:24:08,795 - INFO  - Training [55][  320/  391]   Loss 0.065432   Top1 97.690430   Top5 99.992676   BatchTime 0.106607   LR 0.001000   
2022-11-03 23:24:10,759 - INFO  - Training [55][  340/  391]   Loss 0.065754   Top1 97.672335   Top5 99.993107   BatchTime 0.106114   LR 0.001000   
2022-11-03 23:24:12,708 - INFO  - Training [55][  360/  391]   Loss 0.066091   Top1 97.649740   Top5 99.993490   BatchTime 0.105632   LR 0.001000   
2022-11-03 23:24:14,679 - INFO  - Training [55][  380/  391]   Loss 0.065779   Top1 97.662418   Top5 99.993832   BatchTime 0.105260   LR 0.001000   
2022-11-03 23:24:15,731 - INFO  - ==> Top1: 97.676    Top5: 99.994    Loss: 0.066

2022-11-03 23:24:15,732 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:24:18,337 - INFO  - Validation [55][   20/   79]   Loss 0.386875   Top1 90.273438   Top5 99.648438   BatchTime 0.130215   
2022-11-03 23:24:19,027 - INFO  - Validation [55][   40/   79]   Loss 0.389513   Top1 90.234375   Top5 99.609375   BatchTime 0.082354   
2022-11-03 23:24:19,675 - INFO  - Validation [55][   60/   79]   Loss 0.379481   Top1 90.533854   Top5 99.622396   BatchTime 0.065705   
2022-11-03 23:24:20,445 - INFO  - ==> Top1: 90.390    Top5: 99.660    Loss: 0.375

2022-11-03 23:24:20,473 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:24:20,474 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:24:20,474 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:24:20,580 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:24:20,580 - INFO  - >>>>>>>> Epoch  56
2022-11-03 23:24:20,581 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:24:24,548 - INFO  - Training [56][   20/  391]   Loss 0.070760   Top1 97.226562   Top5 100.000000   BatchTime 0.198321   LR 0.001000   
2022-11-03 23:24:26,554 - INFO  - Training [56][   40/  391]   Loss 0.069164   Top1 97.421875   Top5 100.000000   BatchTime 0.149326   LR 0.001000   
2022-11-03 23:24:28,635 - INFO  - Training [56][   60/  391]   Loss 0.061764   Top1 97.721354   Top5 99.986979   BatchTime 0.134230   LR 0.001000   
2022-11-03 23:24:30,646 - INFO  - Training [56][   80/  391]   Loss 0.060267   Top1 97.841797   Top5 99.990234   BatchTime 0.125808   LR 0.001000   
2022-11-03 23:24:32,644 - INFO  - Training [56][  100/  391]   Loss 0.060934   Top1 97.851562   Top5 99.992188   BatchTime 0.120628   LR 0.001000   
2022-11-03 23:24:34,643 - INFO  - Training [56][  120/  391]   Loss 0.059950   Top1 97.884115   Top5 99.993490   BatchTime 0.117181   LR 0.001000   
2022-11-03 23:24:36,632 - INFO  - Training [56][  140/  391]   Loss 0.061083   Top1 97.823661   Top5 99.994420   BatchTime 0.114647   LR 0.001000   
2022-11-03 23:24:38,637 - INFO  - Training [56][  160/  391]   Loss 0.062711   Top1 97.729492   Top5 99.995117   BatchTime 0.112850   LR 0.001000   
2022-11-03 23:24:40,635 - INFO  - Training [56][  180/  391]   Loss 0.063230   Top1 97.747396   Top5 99.995660   BatchTime 0.111410   LR 0.001000   
2022-11-03 23:24:42,647 - INFO  - Training [56][  200/  391]   Loss 0.062288   Top1 97.785156   Top5 99.996094   BatchTime 0.110330   LR 0.001000   
2022-11-03 23:24:44,648 - INFO  - Training [56][  220/  391]   Loss 0.061898   Top1 97.812500   Top5 99.996449   BatchTime 0.109394   LR 0.001000   
2022-11-03 23:24:46,664 - INFO  - Training [56][  240/  391]   Loss 0.062258   Top1 97.832031   Top5 99.996745   BatchTime 0.108677   LR 0.001000   
2022-11-03 23:24:48,666 - INFO  - Training [56][  260/  391]   Loss 0.063546   Top1 97.785457   Top5 99.996995   BatchTime 0.108018   LR 0.001000   
2022-11-03 23:24:50,653 - INFO  - Training [56][  280/  391]   Loss 0.063882   Top1 97.762277   Top5 99.997210   BatchTime 0.107396   LR 0.001000   
2022-11-03 23:24:52,606 - INFO  - Training [56][  300/  391]   Loss 0.063574   Top1 97.778646   Top5 99.997396   BatchTime 0.106748   LR 0.001000   
2022-11-03 23:24:54,602 - INFO  - Training [56][  320/  391]   Loss 0.063862   Top1 97.746582   Top5 99.997559   BatchTime 0.106312   LR 0.001000   
2022-11-03 23:24:56,553 - INFO  - Training [56][  340/  391]   Loss 0.064593   Top1 97.715993   Top5 99.997702   BatchTime 0.105797   LR 0.001000   
2022-11-03 23:24:58,495 - INFO  - Training [56][  360/  391]   Loss 0.064523   Top1 97.736545   Top5 99.997830   BatchTime 0.105315   LR 0.001000   
2022-11-03 23:25:00,511 - INFO  - Training [56][  380/  391]   Loss 0.064524   Top1 97.748766   Top5 99.997944   BatchTime 0.105077   LR 0.001000   
2022-11-03 23:25:01,628 - INFO  - ==> Top1: 97.734    Top5: 99.998    Loss: 0.065

2022-11-03 23:25:01,629 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:25:04,231 - INFO  - Validation [56][   20/   79]   Loss 0.383922   Top1 90.234375   Top5 99.609375   BatchTime 0.129999   
2022-11-03 23:25:04,923 - INFO  - Validation [56][   40/   79]   Loss 0.380741   Top1 90.000000   Top5 99.589844   BatchTime 0.082307   
2022-11-03 23:25:05,572 - INFO  - Validation [56][   60/   79]   Loss 0.374438   Top1 90.208333   Top5 99.622396   BatchTime 0.065686   
2022-11-03 23:25:06,325 - INFO  - ==> Top1: 90.140    Top5: 99.630    Loss: 0.369

2022-11-03 23:25:06,350 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:25:06,351 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:25:06,351 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:25:06,444 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:25:06,445 - INFO  - >>>>>>>> Epoch  57
2022-11-03 23:25:06,446 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:25:10,418 - INFO  - Training [57][   20/  391]   Loss 0.063825   Top1 97.617188   Top5 100.000000   BatchTime 0.198575   LR 0.001000   
2022-11-03 23:25:12,419 - INFO  - Training [57][   40/  391]   Loss 0.063380   Top1 97.636719   Top5 100.000000   BatchTime 0.149309   LR 0.001000   
2022-11-03 23:25:14,414 - INFO  - Training [57][   60/  391]   Loss 0.063818   Top1 97.643229   Top5 100.000000   BatchTime 0.132793   LR 0.001000   
2022-11-03 23:25:16,428 - INFO  - Training [57][   80/  391]   Loss 0.065019   Top1 97.578125   Top5 100.000000   BatchTime 0.124770   LR 0.001000   
2022-11-03 23:25:18,441 - INFO  - Training [57][  100/  391]   Loss 0.064958   Top1 97.609375   Top5 100.000000   BatchTime 0.119947   LR 0.001000   
2022-11-03 23:25:20,447 - INFO  - Training [57][  120/  391]   Loss 0.065385   Top1 97.597656   Top5 100.000000   BatchTime 0.116671   LR 0.001000   
2022-11-03 23:25:22,461 - INFO  - Training [57][  140/  391]   Loss 0.066977   Top1 97.522321   Top5 100.000000   BatchTime 0.114391   LR 0.001000   
2022-11-03 23:25:24,516 - INFO  - Training [57][  160/  391]   Loss 0.066781   Top1 97.539062   Top5 100.000000   BatchTime 0.112932   LR 0.001000   
2022-11-03 23:25:26,555 - INFO  - Training [57][  180/  391]   Loss 0.066582   Top1 97.552083   Top5 100.000000   BatchTime 0.111714   LR 0.001000   
2022-11-03 23:25:28,570 - INFO  - Training [57][  200/  391]   Loss 0.066941   Top1 97.546875   Top5 100.000000   BatchTime 0.110616   LR 0.001000   
2022-11-03 23:25:30,607 - INFO  - Training [57][  220/  391]   Loss 0.067236   Top1 97.549716   Top5 100.000000   BatchTime 0.109819   LR 0.001000   
2022-11-03 23:25:32,641 - INFO  - Training [57][  240/  391]   Loss 0.068491   Top1 97.506510   Top5 100.000000   BatchTime 0.109143   LR 0.001000   
2022-11-03 23:25:34,664 - INFO  - Training [57][  260/  391]   Loss 0.068416   Top1 97.518029   Top5 100.000000   BatchTime 0.108529   LR 0.001000   
2022-11-03 23:25:36,674 - INFO  - Training [57][  280/  391]   Loss 0.068365   Top1 97.525112   Top5 99.997210   BatchTime 0.107952   LR 0.001000   
2022-11-03 23:25:38,673 - INFO  - Training [57][  300/  391]   Loss 0.068612   Top1 97.520833   Top5 99.997396   BatchTime 0.107421   LR 0.001000   
2022-11-03 23:25:40,673 - INFO  - Training [57][  320/  391]   Loss 0.068763   Top1 97.517090   Top5 99.995117   BatchTime 0.106956   LR 0.001000   
2022-11-03 23:25:42,636 - INFO  - Training [57][  340/  391]   Loss 0.068783   Top1 97.518382   Top5 99.995404   BatchTime 0.106438   LR 0.001000   
2022-11-03 23:25:44,582 - INFO  - Training [57][  360/  391]   Loss 0.069177   Top1 97.500000   Top5 99.995660   BatchTime 0.105931   LR 0.001000   
2022-11-03 23:25:46,595 - INFO  - Training [57][  380/  391]   Loss 0.069220   Top1 97.500000   Top5 99.993832   BatchTime 0.105651   LR 0.001000   
2022-11-03 23:25:47,669 - INFO  - ==> Top1: 97.482    Top5: 99.994    Loss: 0.070

2022-11-03 23:25:47,670 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:25:50,304 - INFO  - Validation [57][   20/   79]   Loss 0.376960   Top1 90.234375   Top5 99.609375   BatchTime 0.131613   
2022-11-03 23:25:50,998 - INFO  - Validation [57][   40/   79]   Loss 0.381780   Top1 90.097656   Top5 99.609375   BatchTime 0.083160   
2022-11-03 23:25:51,618 - INFO  - Validation [57][   60/   79]   Loss 0.376309   Top1 90.208333   Top5 99.622396   BatchTime 0.065783   
2022-11-03 23:25:52,382 - INFO  - ==> Top1: 90.100    Top5: 99.680    Loss: 0.373

2022-11-03 23:25:52,407 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:25:52,407 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:25:52,408 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:25:52,505 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:25:52,506 - INFO  - >>>>>>>> Epoch  58
2022-11-03 23:25:52,507 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:25:56,487 - INFO  - Training [58][   20/  391]   Loss 0.069362   Top1 97.421875   Top5 100.000000   BatchTime 0.199014   LR 0.001000   
2022-11-03 23:25:58,495 - INFO  - Training [58][   40/  391]   Loss 0.076392   Top1 97.148438   Top5 100.000000   BatchTime 0.149689   LR 0.001000   
2022-11-03 23:26:00,506 - INFO  - Training [58][   60/  391]   Loss 0.074807   Top1 97.317708   Top5 100.000000   BatchTime 0.133316   LR 0.001000   
2022-11-03 23:26:02,525 - INFO  - Training [58][   80/  391]   Loss 0.075482   Top1 97.275391   Top5 100.000000   BatchTime 0.125225   LR 0.001000   
2022-11-03 23:26:04,674 - INFO  - Training [58][  100/  391]   Loss 0.073097   Top1 97.320312   Top5 100.000000   BatchTime 0.121664   LR 0.001000   
2022-11-03 23:26:06,671 - INFO  - Training [58][  120/  391]   Loss 0.072443   Top1 97.389323   Top5 100.000000   BatchTime 0.118030   LR 0.001000   
2022-11-03 23:26:08,670 - INFO  - Training [58][  140/  391]   Loss 0.074432   Top1 97.343750   Top5 99.994420   BatchTime 0.115444   LR 0.001000   
2022-11-03 23:26:10,683 - INFO  - Training [58][  160/  391]   Loss 0.074569   Top1 97.348633   Top5 99.995117   BatchTime 0.113600   LR 0.001000   
2022-11-03 23:26:12,703 - INFO  - Training [58][  180/  391]   Loss 0.072431   Top1 97.417535   Top5 99.995660   BatchTime 0.112195   LR 0.001000   
2022-11-03 23:26:14,706 - INFO  - Training [58][  200/  391]   Loss 0.071855   Top1 97.417969   Top5 99.996094   BatchTime 0.110992   LR 0.001000   
2022-11-03 23:26:16,710 - INFO  - Training [58][  220/  391]   Loss 0.071160   Top1 97.439631   Top5 99.996449   BatchTime 0.110013   LR 0.001000   
2022-11-03 23:26:18,720 - INFO  - Training [58][  240/  391]   Loss 0.070783   Top1 97.425130   Top5 99.996745   BatchTime 0.109220   LR 0.001000   
2022-11-03 23:26:20,737 - INFO  - Training [58][  260/  391]   Loss 0.071159   Top1 97.445913   Top5 99.996995   BatchTime 0.108575   LR 0.001000   
2022-11-03 23:26:22,752 - INFO  - Training [58][  280/  391]   Loss 0.072354   Top1 97.385603   Top5 99.997210   BatchTime 0.108015   LR 0.001000   
2022-11-03 23:26:24,772 - INFO  - Training [58][  300/  391]   Loss 0.072437   Top1 97.377604   Top5 99.997396   BatchTime 0.107547   LR 0.001000   
2022-11-03 23:26:26,800 - INFO  - Training [58][  320/  391]   Loss 0.072721   Top1 97.355957   Top5 99.997559   BatchTime 0.107162   LR 0.001000   
2022-11-03 23:26:28,757 - INFO  - Training [58][  340/  391]   Loss 0.072265   Top1 97.385110   Top5 99.997702   BatchTime 0.106615   LR 0.001000   
2022-11-03 23:26:30,689 - INFO  - Training [58][  360/  391]   Loss 0.072223   Top1 97.367622   Top5 99.997830   BatchTime 0.106058   LR 0.001000   
2022-11-03 23:26:32,672 - INFO  - Training [58][  380/  391]   Loss 0.073397   Top1 97.329359   Top5 99.997944   BatchTime 0.105696   LR 0.001000   
2022-11-03 23:26:33,725 - INFO  - ==> Top1: 97.328    Top5: 99.996    Loss: 0.074

2022-11-03 23:26:33,726 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:26:36,339 - INFO  - Validation [58][   20/   79]   Loss 0.391171   Top1 90.078125   Top5 99.492188   BatchTime 0.130564   
2022-11-03 23:26:37,030 - INFO  - Validation [58][   40/   79]   Loss 0.391591   Top1 89.609375   Top5 99.550781   BatchTime 0.082551   
2022-11-03 23:26:37,649 - INFO  - Validation [58][   60/   79]   Loss 0.385253   Top1 89.830729   Top5 99.557292   BatchTime 0.065343   
2022-11-03 23:26:38,417 - INFO  - ==> Top1: 89.770    Top5: 99.580    Loss: 0.382

2022-11-03 23:26:38,443 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:26:38,443 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:26:38,443 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:26:38,551 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:26:38,551 - INFO  - >>>>>>>> Epoch  59
2022-11-03 23:26:38,553 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:26:42,535 - INFO  - Training [59][   20/  391]   Loss 0.070130   Top1 97.617188   Top5 100.000000   BatchTime 0.199093   LR 0.001000   
2022-11-03 23:26:44,565 - INFO  - Training [59][   40/  391]   Loss 0.077027   Top1 97.324219   Top5 99.980469   BatchTime 0.150288   LR 0.001000   
2022-11-03 23:26:46,563 - INFO  - Training [59][   60/  391]   Loss 0.075679   Top1 97.291667   Top5 99.986979   BatchTime 0.133500   LR 0.001000   
2022-11-03 23:26:48,582 - INFO  - Training [59][   80/  391]   Loss 0.074006   Top1 97.392578   Top5 99.990234   BatchTime 0.125358   LR 0.001000   
2022-11-03 23:26:50,591 - INFO  - Training [59][  100/  391]   Loss 0.074103   Top1 97.414062   Top5 99.992188   BatchTime 0.120376   LR 0.001000   
2022-11-03 23:26:52,593 - INFO  - Training [59][  120/  391]   Loss 0.073451   Top1 97.408854   Top5 99.993490   BatchTime 0.116997   LR 0.001000   
2022-11-03 23:26:54,613 - INFO  - Training [59][  140/  391]   Loss 0.072110   Top1 97.483259   Top5 99.983259   BatchTime 0.114715   LR 0.001000   
2022-11-03 23:26:56,637 - INFO  - Training [59][  160/  391]   Loss 0.072331   Top1 97.485352   Top5 99.980469   BatchTime 0.113023   LR 0.001000   
2022-11-03 23:26:58,660 - INFO  - Training [59][  180/  391]   Loss 0.074217   Top1 97.404514   Top5 99.982639   BatchTime 0.111703   LR 0.001000   
2022-11-03 23:27:00,669 - INFO  - Training [59][  200/  391]   Loss 0.075516   Top1 97.351562   Top5 99.984375   BatchTime 0.110576   LR 0.001000   
2022-11-03 23:27:02,684 - INFO  - Training [59][  220/  391]   Loss 0.075668   Top1 97.311790   Top5 99.982244   BatchTime 0.109684   LR 0.001000   
2022-11-03 23:27:04,701 - INFO  - Training [59][  240/  391]   Loss 0.075886   Top1 97.288411   Top5 99.983724   BatchTime 0.108946   LR 0.001000   
2022-11-03 23:27:06,725 - INFO  - Training [59][  260/  391]   Loss 0.075691   Top1 97.292668   Top5 99.984976   BatchTime 0.108352   LR 0.001000   
2022-11-03 23:27:08,756 - INFO  - Training [59][  280/  391]   Loss 0.075612   Top1 97.296317   Top5 99.986049   BatchTime 0.107866   LR 0.001000   
2022-11-03 23:27:10,777 - INFO  - Training [59][  300/  391]   Loss 0.075565   Top1 97.304688   Top5 99.986979   BatchTime 0.107410   LR 0.001000   
2022-11-03 23:27:12,790 - INFO  - Training [59][  320/  391]   Loss 0.076483   Top1 97.263184   Top5 99.985352   BatchTime 0.106988   LR 0.001000   
2022-11-03 23:27:14,750 - INFO  - Training [59][  340/  391]   Loss 0.077774   Top1 97.226562   Top5 99.983915   BatchTime 0.106459   LR 0.001000   
2022-11-03 23:27:16,695 - INFO  - Training [59][  360/  391]   Loss 0.078486   Top1 97.209201   Top5 99.984809   BatchTime 0.105949   LR 0.001000   
2022-11-03 23:27:18,741 - INFO  - Training [59][  380/  391]   Loss 0.078719   Top1 97.206003   Top5 99.985609   BatchTime 0.105757   LR 0.001000   
2022-11-03 23:27:19,835 - INFO  - ==> Top1: 97.192    Top5: 99.986    Loss: 0.079

2022-11-03 23:27:19,836 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:27:22,447 - INFO  - Validation [59][   20/   79]   Loss 0.409734   Top1 89.296875   Top5 99.570312   BatchTime 0.130489   
2022-11-03 23:27:23,145 - INFO  - Validation [59][   40/   79]   Loss 0.404216   Top1 89.687500   Top5 99.550781   BatchTime 0.082700   
2022-11-03 23:27:23,790 - INFO  - Validation [59][   60/   79]   Loss 0.392416   Top1 90.026042   Top5 99.570312   BatchTime 0.065881   
2022-11-03 23:27:24,539 - INFO  - ==> Top1: 89.910    Top5: 99.620    Loss: 0.384

2022-11-03 23:27:24,565 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:27:24,566 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:27:24,566 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:27:24,673 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:27:24,673 - INFO  - >>>>>>>> Epoch  60
2022-11-03 23:27:24,674 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:27:28,289 - INFO  - Training [60][   20/  391]   Loss 0.094001   Top1 96.289062   Top5 100.000000   BatchTime 0.180712   LR 0.000100   
2022-11-03 23:27:29,933 - INFO  - Training [60][   40/  391]   Loss 0.088271   Top1 96.523438   Top5 100.000000   BatchTime 0.131454   LR 0.000100   
2022-11-03 23:27:31,452 - INFO  - Training [60][   60/  391]   Loss 0.085925   Top1 96.705729   Top5 100.000000   BatchTime 0.112956   LR 0.000100   
2022-11-03 23:27:32,964 - INFO  - Training [60][   80/  391]   Loss 0.083312   Top1 96.865234   Top5 100.000000   BatchTime 0.103614   LR 0.000100   
2022-11-03 23:27:34,470 - INFO  - Training [60][  100/  391]   Loss 0.085273   Top1 96.781250   Top5 100.000000   BatchTime 0.097952   LR 0.000100   
2022-11-03 23:27:35,975 - INFO  - Training [60][  120/  391]   Loss 0.083586   Top1 96.835938   Top5 100.000000   BatchTime 0.094173   LR 0.000100   
2022-11-03 23:27:37,484 - INFO  - Training [60][  140/  391]   Loss 0.083095   Top1 96.891741   Top5 100.000000   BatchTime 0.091496   LR 0.000100   
2022-11-03 23:27:39,083 - INFO  - Training [60][  160/  391]   Loss 0.081949   Top1 96.953125   Top5 100.000000   BatchTime 0.090052   LR 0.000100   
2022-11-03 23:27:40,558 - INFO  - Training [60][  180/  391]   Loss 0.080504   Top1 97.026910   Top5 100.000000   BatchTime 0.088241   LR 0.000100   
2022-11-03 23:27:42,042 - INFO  - Training [60][  200/  391]   Loss 0.080566   Top1 96.992188   Top5 100.000000   BatchTime 0.086834   LR 0.000100   
2022-11-03 23:27:43,514 - INFO  - Training [60][  220/  391]   Loss 0.081327   Top1 96.995739   Top5 99.996449   BatchTime 0.085634   LR 0.000100   
2022-11-03 23:27:44,994 - INFO  - Training [60][  240/  391]   Loss 0.079880   Top1 97.063802   Top5 99.996745   BatchTime 0.084661   LR 0.000100   
2022-11-03 23:27:46,452 - INFO  - Training [60][  260/  391]   Loss 0.080653   Top1 97.025240   Top5 99.996995   BatchTime 0.083756   LR 0.000100   
2022-11-03 23:27:47,942 - INFO  - Training [60][  280/  391]   Loss 0.080195   Top1 97.064732   Top5 99.994420   BatchTime 0.083097   LR 0.000100   
2022-11-03 23:27:49,361 - INFO  - Training [60][  300/  391]   Loss 0.080393   Top1 97.075521   Top5 99.992188   BatchTime 0.082287   LR 0.000100   
2022-11-03 23:27:50,773 - INFO  - Training [60][  320/  391]   Loss 0.080629   Top1 97.062988   Top5 99.992676   BatchTime 0.081555   LR 0.000100   
2022-11-03 23:27:52,183 - INFO  - Training [60][  340/  391]   Loss 0.080022   Top1 97.088695   Top5 99.993107   BatchTime 0.080906   LR 0.000100   
2022-11-03 23:27:53,575 - INFO  - Training [60][  360/  391]   Loss 0.080199   Top1 97.068142   Top5 99.993490   BatchTime 0.080278   LR 0.000100   
2022-11-03 23:27:54,952 - INFO  - Training [60][  380/  391]   Loss 0.080058   Top1 97.090872   Top5 99.993832   BatchTime 0.079676   LR 0.000100   
2022-11-03 23:27:56,001 - INFO  - ==> Top1: 97.062    Top5: 99.994    Loss: 0.080

2022-11-03 23:27:56,003 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:27:58,400 - INFO  - Validation [60][   20/   79]   Loss 0.410387   Top1 89.804688   Top5 99.492188   BatchTime 0.119784   
2022-11-03 23:27:58,920 - INFO  - Validation [60][   40/   79]   Loss 0.400739   Top1 89.921875   Top5 99.511719   BatchTime 0.072893   
2022-11-03 23:27:59,438 - INFO  - Validation [60][   60/   79]   Loss 0.390302   Top1 90.156250   Top5 99.557292   BatchTime 0.057236   
2022-11-03 23:28:00,188 - INFO  - ==> Top1: 90.060    Top5: 99.590    Loss: 0.384

2022-11-03 23:28:00,214 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:28:00,215 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:28:00,215 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:28:00,320 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:28:00,321 - INFO  - >>>>>>>> Epoch  61
2022-11-03 23:28:00,322 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:28:03,722 - INFO  - Training [61][   20/  391]   Loss 0.095730   Top1 96.718750   Top5 100.000000   BatchTime 0.169966   LR 0.000100   
2022-11-03 23:28:05,272 - INFO  - Training [61][   40/  391]   Loss 0.092534   Top1 96.796875   Top5 100.000000   BatchTime 0.123733   LR 0.000100   
2022-11-03 23:28:06,984 - INFO  - Training [61][   60/  391]   Loss 0.087419   Top1 96.979167   Top5 100.000000   BatchTime 0.111028   LR 0.000100   
2022-11-03 23:28:08,733 - INFO  - Training [61][   80/  391]   Loss 0.085001   Top1 97.080078   Top5 100.000000   BatchTime 0.105130   LR 0.000100   
2022-11-03 23:28:10,503 - INFO  - Training [61][  100/  391]   Loss 0.082521   Top1 97.125000   Top5 100.000000   BatchTime 0.101802   LR 0.000100   
2022-11-03 23:28:12,304 - INFO  - Training [61][  120/  391]   Loss 0.081980   Top1 97.115885   Top5 100.000000   BatchTime 0.099842   LR 0.000100   
2022-11-03 23:28:14,755 - INFO  - Training [61][  140/  391]   Loss 0.081527   Top1 97.092634   Top5 100.000000   BatchTime 0.103085   LR 0.000100   
2022-11-03 23:28:17,239 - INFO  - Training [61][  160/  391]   Loss 0.081566   Top1 97.133789   Top5 100.000000   BatchTime 0.105728   LR 0.000100   
2022-11-03 23:28:19,733 - INFO  - Training [61][  180/  391]   Loss 0.081844   Top1 97.113715   Top5 100.000000   BatchTime 0.107832   LR 0.000100   
2022-11-03 23:28:22,231 - INFO  - Training [61][  200/  391]   Loss 0.083295   Top1 97.054688   Top5 100.000000   BatchTime 0.109542   LR 0.000100   
2022-11-03 23:28:24,703 - INFO  - Training [61][  220/  391]   Loss 0.083648   Top1 97.034801   Top5 99.996449   BatchTime 0.110820   LR 0.000100   
2022-11-03 23:28:27,188 - INFO  - Training [61][  240/  391]   Loss 0.081938   Top1 97.106120   Top5 99.996745   BatchTime 0.111939   LR 0.000100   
2022-11-03 23:28:29,668 - INFO  - Training [61][  260/  391]   Loss 0.081984   Top1 97.127404   Top5 99.990986   BatchTime 0.112863   LR 0.000100   
2022-11-03 23:28:32,146 - INFO  - Training [61][  280/  391]   Loss 0.081985   Top1 97.109375   Top5 99.991629   BatchTime 0.113654   LR 0.000100   
2022-11-03 23:28:34,619 - INFO  - Training [61][  300/  391]   Loss 0.081932   Top1 97.101562   Top5 99.989583   BatchTime 0.114320   LR 0.000100   
2022-11-03 23:28:36,923 - INFO  - Training [61][  320/  391]   Loss 0.081829   Top1 97.099609   Top5 99.990234   BatchTime 0.114375   LR 0.000100   
2022-11-03 23:28:38,467 - INFO  - Training [61][  340/  391]   Loss 0.081754   Top1 97.116268   Top5 99.990809   BatchTime 0.112189   LR 0.000100   
2022-11-03 23:28:40,189 - INFO  - Training [61][  360/  391]   Loss 0.081963   Top1 97.115885   Top5 99.991319   BatchTime 0.110739   LR 0.000100   
2022-11-03 23:28:41,945 - INFO  - Training [61][  380/  391]   Loss 0.081625   Top1 97.129934   Top5 99.991776   BatchTime 0.109531   LR 0.000100   
2022-11-03 23:28:42,998 - INFO  - ==> Top1: 97.132    Top5: 99.992    Loss: 0.082

2022-11-03 23:28:42,999 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:28:46,269 - INFO  - Validation [61][   20/   79]   Loss 0.411574   Top1 89.765625   Top5 99.531250   BatchTime 0.163407   
2022-11-03 23:28:47,564 - INFO  - Validation [61][   40/   79]   Loss 0.401459   Top1 89.824219   Top5 99.550781   BatchTime 0.114072   
2022-11-03 23:28:48,840 - INFO  - Validation [61][   60/   79]   Loss 0.391786   Top1 90.039062   Top5 99.609375   BatchTime 0.097314   
2022-11-03 23:28:50,298 - INFO  - ==> Top1: 89.870    Top5: 99.650    Loss: 0.385

2022-11-03 23:28:50,345 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:28:50,345 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:28:50,346 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:28:50,452 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:28:50,452 - INFO  - >>>>>>>> Epoch  62
2022-11-03 23:28:50,454 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:28:54,754 - INFO  - Training [62][   20/  391]   Loss 0.077349   Top1 97.304688   Top5 99.921875   BatchTime 0.215004   LR 0.000100   
2022-11-03 23:28:57,236 - INFO  - Training [62][   40/  391]   Loss 0.078215   Top1 97.246094   Top5 99.960938   BatchTime 0.169555   LR 0.000100   
2022-11-03 23:28:59,716 - INFO  - Training [62][   60/  391]   Loss 0.081598   Top1 97.005208   Top5 99.973958   BatchTime 0.154373   LR 0.000100   
2022-11-03 23:29:02,188 - INFO  - Training [62][   80/  391]   Loss 0.080466   Top1 97.021484   Top5 99.970703   BatchTime 0.146672   LR 0.000100   
2022-11-03 23:29:04,663 - INFO  - Training [62][  100/  391]   Loss 0.079878   Top1 97.062500   Top5 99.976562   BatchTime 0.142093   LR 0.000100   
2022-11-03 23:29:06,804 - INFO  - Training [62][  120/  391]   Loss 0.079625   Top1 97.089844   Top5 99.980469   BatchTime 0.136250   LR 0.000100   
2022-11-03 23:29:08,415 - INFO  - Training [62][  140/  391]   Loss 0.081293   Top1 97.075893   Top5 99.977679   BatchTime 0.128294   LR 0.000100   
2022-11-03 23:29:10,183 - INFO  - Training [62][  160/  391]   Loss 0.081536   Top1 97.084961   Top5 99.980469   BatchTime 0.123308   LR 0.000100   
2022-11-03 23:29:11,888 - INFO  - Training [62][  180/  391]   Loss 0.080526   Top1 97.131076   Top5 99.978299   BatchTime 0.119079   LR 0.000100   
2022-11-03 23:29:14,199 - INFO  - Training [62][  200/  391]   Loss 0.082098   Top1 97.070312   Top5 99.976562   BatchTime 0.118724   LR 0.000100   
2022-11-03 23:29:16,777 - INFO  - Training [62][  220/  391]   Loss 0.081335   Top1 97.098722   Top5 99.978693   BatchTime 0.119648   LR 0.000100   
2022-11-03 23:29:19,288 - INFO  - Training [62][  240/  391]   Loss 0.081019   Top1 97.093099   Top5 99.980469   BatchTime 0.120141   LR 0.000100   
2022-11-03 23:29:21,780 - INFO  - Training [62][  260/  391]   Loss 0.080544   Top1 97.133413   Top5 99.981971   BatchTime 0.120484   LR 0.000100   
2022-11-03 23:29:24,254 - INFO  - Training [62][  280/  391]   Loss 0.079626   Top1 97.198661   Top5 99.983259   BatchTime 0.120711   LR 0.000100   
2022-11-03 23:29:26,747 - INFO  - Training [62][  300/  391]   Loss 0.080364   Top1 97.210938   Top5 99.981771   BatchTime 0.120974   LR 0.000100   
2022-11-03 23:29:29,249 - INFO  - Training [62][  320/  391]   Loss 0.080125   Top1 97.219238   Top5 99.982910   BatchTime 0.121233   LR 0.000100   
2022-11-03 23:29:31,715 - INFO  - Training [62][  340/  391]   Loss 0.079787   Top1 97.233456   Top5 99.983915   BatchTime 0.121354   LR 0.000100   
2022-11-03 23:29:34,166 - INFO  - Training [62][  360/  391]   Loss 0.079454   Top1 97.246094   Top5 99.984809   BatchTime 0.121420   LR 0.000100   
2022-11-03 23:29:36,633 - INFO  - Training [62][  380/  391]   Loss 0.079310   Top1 97.243010   Top5 99.985609   BatchTime 0.121521   LR 0.000100   
2022-11-03 23:29:37,942 - INFO  - ==> Top1: 97.226    Top5: 99.986    Loss: 0.080

2022-11-03 23:29:37,943 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:29:40,787 - INFO  - Validation [62][   20/   79]   Loss 0.400381   Top1 89.375000   Top5 99.570312   BatchTime 0.142115   
2022-11-03 23:29:41,334 - INFO  - Validation [62][   40/   79]   Loss 0.394769   Top1 89.667969   Top5 99.570312   BatchTime 0.084752   
2022-11-03 23:29:41,852 - INFO  - Validation [62][   60/   79]   Loss 0.386269   Top1 89.986979   Top5 99.583333   BatchTime 0.065136   
2022-11-03 23:29:42,623 - INFO  - ==> Top1: 89.870    Top5: 99.620    Loss: 0.380

2022-11-03 23:29:42,648 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:29:42,649 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:29:42,649 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:29:42,779 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:29:42,780 - INFO  - >>>>>>>> Epoch  63
2022-11-03 23:29:42,781 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:29:47,263 - INFO  - Training [63][   20/  391]   Loss 0.080428   Top1 97.070312   Top5 99.960938   BatchTime 0.224095   LR 0.000100   
2022-11-03 23:29:49,740 - INFO  - Training [63][   40/  391]   Loss 0.078188   Top1 97.304688   Top5 99.980469   BatchTime 0.173977   LR 0.000100   
2022-11-03 23:29:52,225 - INFO  - Training [63][   60/  391]   Loss 0.083805   Top1 97.122396   Top5 99.986979   BatchTime 0.157396   LR 0.000100   
2022-11-03 23:29:54,706 - INFO  - Training [63][   80/  391]   Loss 0.084203   Top1 97.080078   Top5 99.990234   BatchTime 0.149056   LR 0.000100   
2022-11-03 23:29:57,189 - INFO  - Training [63][  100/  391]   Loss 0.082801   Top1 97.132812   Top5 99.984375   BatchTime 0.144075   LR 0.000100   
2022-11-03 23:29:59,669 - INFO  - Training [63][  120/  391]   Loss 0.082504   Top1 97.122396   Top5 99.986979   BatchTime 0.140731   LR 0.000100   
2022-11-03 23:30:02,137 - INFO  - Training [63][  140/  391]   Loss 0.082833   Top1 97.142857   Top5 99.988839   BatchTime 0.138250   LR 0.000100   
2022-11-03 23:30:04,606 - INFO  - Training [63][  160/  391]   Loss 0.083101   Top1 97.104492   Top5 99.990234   BatchTime 0.136405   LR 0.000100   
2022-11-03 23:30:07,008 - INFO  - Training [63][  180/  391]   Loss 0.082836   Top1 97.118056   Top5 99.986979   BatchTime 0.134590   LR 0.000100   
2022-11-03 23:30:08,566 - INFO  - Training [63][  200/  391]   Loss 0.083130   Top1 97.093750   Top5 99.984375   BatchTime 0.128920   LR 0.000100   
2022-11-03 23:30:10,404 - INFO  - Training [63][  220/  391]   Loss 0.082852   Top1 97.109375   Top5 99.985795   BatchTime 0.125555   LR 0.000100   
2022-11-03 23:30:12,099 - INFO  - Training [63][  240/  391]   Loss 0.082919   Top1 97.073568   Top5 99.986979   BatchTime 0.122156   LR 0.000100   
2022-11-03 23:30:14,264 - INFO  - Training [63][  260/  391]   Loss 0.081808   Top1 97.133413   Top5 99.987981   BatchTime 0.121083   LR 0.000100   
2022-11-03 23:30:16,768 - INFO  - Training [63][  280/  391]   Loss 0.082427   Top1 97.089844   Top5 99.988839   BatchTime 0.121379   LR 0.000100   
2022-11-03 23:30:19,272 - INFO  - Training [63][  300/  391]   Loss 0.081794   Top1 97.125000   Top5 99.989583   BatchTime 0.121634   LR 0.000100   
2022-11-03 23:30:21,764 - INFO  - Training [63][  320/  391]   Loss 0.081986   Top1 97.126465   Top5 99.987793   BatchTime 0.121818   LR 0.000100   
2022-11-03 23:30:24,236 - INFO  - Training [63][  340/  391]   Loss 0.082359   Top1 97.093290   Top5 99.988511   BatchTime 0.121923   LR 0.000100   
2022-11-03 23:30:26,725 - INFO  - Training [63][  360/  391]   Loss 0.082471   Top1 97.089844   Top5 99.986979   BatchTime 0.122064   LR 0.000100   
2022-11-03 23:30:29,200 - INFO  - Training [63][  380/  391]   Loss 0.082109   Top1 97.092928   Top5 99.987664   BatchTime 0.122151   LR 0.000100   
2022-11-03 23:30:30,823 - INFO  - ==> Top1: 97.106    Top5: 99.986    Loss: 0.082

2022-11-03 23:30:30,824 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:30:33,928 - INFO  - Validation [63][   20/   79]   Loss 0.412017   Top1 89.257812   Top5 99.570312   BatchTime 0.155089   
2022-11-03 23:30:35,200 - INFO  - Validation [63][   40/   79]   Loss 0.397687   Top1 89.609375   Top5 99.570312   BatchTime 0.109349   
2022-11-03 23:30:36,297 - INFO  - Validation [63][   60/   79]   Loss 0.388443   Top1 89.804688   Top5 99.596354   BatchTime 0.091188   
2022-11-03 23:30:37,073 - INFO  - ==> Top1: 89.830    Top5: 99.640    Loss: 0.382

2022-11-03 23:30:37,097 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:30:37,098 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:30:37,098 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:30:37,199 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:30:37,199 - INFO  - >>>>>>>> Epoch  64
2022-11-03 23:30:37,200 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:30:40,924 - INFO  - Training [64][   20/  391]   Loss 0.068319   Top1 97.851562   Top5 100.000000   BatchTime 0.186160   LR 0.000100   
2022-11-03 23:30:42,882 - INFO  - Training [64][   40/  391]   Loss 0.073697   Top1 97.500000   Top5 100.000000   BatchTime 0.142032   LR 0.000100   
2022-11-03 23:30:45,374 - INFO  - Training [64][   60/  391]   Loss 0.076505   Top1 97.317708   Top5 100.000000   BatchTime 0.136225   LR 0.000100   
2022-11-03 23:30:47,864 - INFO  - Training [64][   80/  391]   Loss 0.080137   Top1 97.109375   Top5 100.000000   BatchTime 0.133293   LR 0.000100   
2022-11-03 23:30:50,346 - INFO  - Training [64][  100/  391]   Loss 0.079763   Top1 97.140625   Top5 100.000000   BatchTime 0.131456   LR 0.000100   
2022-11-03 23:30:52,794 - INFO  - Training [64][  120/  391]   Loss 0.078093   Top1 97.194010   Top5 100.000000   BatchTime 0.129947   LR 0.000100   
2022-11-03 23:30:55,283 - INFO  - Training [64][  140/  391]   Loss 0.077848   Top1 97.204241   Top5 100.000000   BatchTime 0.129160   LR 0.000100   
2022-11-03 23:30:57,766 - INFO  - Training [64][  160/  391]   Loss 0.078727   Top1 97.153320   Top5 100.000000   BatchTime 0.128530   LR 0.000100   
2022-11-03 23:31:00,243 - INFO  - Training [64][  180/  391]   Loss 0.078405   Top1 97.222222   Top5 99.995660   BatchTime 0.128011   LR 0.000100   
2022-11-03 23:31:02,710 - INFO  - Training [64][  200/  391]   Loss 0.078922   Top1 97.191406   Top5 99.996094   BatchTime 0.127546   LR 0.000100   
2022-11-03 23:31:05,179 - INFO  - Training [64][  220/  391]   Loss 0.079023   Top1 97.201705   Top5 99.996449   BatchTime 0.127175   LR 0.000100   
2022-11-03 23:31:07,406 - INFO  - Training [64][  240/  391]   Loss 0.079798   Top1 97.190755   Top5 99.996745   BatchTime 0.125853   LR 0.000100   
2022-11-03 23:31:09,088 - INFO  - Training [64][  260/  391]   Loss 0.080719   Top1 97.130409   Top5 99.996995   BatchTime 0.122642   LR 0.000100   
2022-11-03 23:31:10,985 - INFO  - Training [64][  280/  391]   Loss 0.080208   Top1 97.145647   Top5 99.997210   BatchTime 0.120655   LR 0.000100   
2022-11-03 23:31:12,721 - INFO  - Training [64][  300/  391]   Loss 0.080149   Top1 97.143229   Top5 99.994792   BatchTime 0.118399   LR 0.000100   
2022-11-03 23:31:15,252 - INFO  - Training [64][  320/  391]   Loss 0.080459   Top1 97.109375   Top5 99.995117   BatchTime 0.118910   LR 0.000100   
2022-11-03 23:31:17,736 - INFO  - Training [64][  340/  391]   Loss 0.080987   Top1 97.086397   Top5 99.995404   BatchTime 0.119220   LR 0.000100   
2022-11-03 23:31:20,212 - INFO  - Training [64][  360/  391]   Loss 0.081276   Top1 97.083333   Top5 99.995660   BatchTime 0.119474   LR 0.000100   
2022-11-03 23:31:22,682 - INFO  - Training [64][  380/  391]   Loss 0.081969   Top1 97.047697   Top5 99.995888   BatchTime 0.119686   LR 0.000100   
2022-11-03 23:31:24,330 - INFO  - ==> Top1: 97.048    Top5: 99.996    Loss: 0.082

2022-11-03 23:31:24,331 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:31:27,454 - INFO  - Validation [64][   20/   79]   Loss 0.407902   Top1 89.609375   Top5 99.570312   BatchTime 0.156090   
2022-11-03 23:31:28,736 - INFO  - Validation [64][   40/   79]   Loss 0.401425   Top1 89.628906   Top5 99.550781   BatchTime 0.110100   
2022-11-03 23:31:30,017 - INFO  - Validation [64][   60/   79]   Loss 0.390699   Top1 89.856771   Top5 99.609375   BatchTime 0.094744   
2022-11-03 23:31:31,537 - INFO  - ==> Top1: 89.760    Top5: 99.650    Loss: 0.384

2022-11-03 23:31:31,606 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:31:31,607 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:31:31,607 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:31:31,708 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:31:31,708 - INFO  - >>>>>>>> Epoch  65
2022-11-03 23:31:31,710 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:31:35,658 - INFO  - Training [65][   20/  391]   Loss 0.073666   Top1 97.460938   Top5 100.000000   BatchTime 0.197385   LR 0.000100   
2022-11-03 23:31:37,329 - INFO  - Training [65][   40/  391]   Loss 0.072429   Top1 97.636719   Top5 100.000000   BatchTime 0.140470   LR 0.000100   
2022-11-03 23:31:39,090 - INFO  - Training [65][   60/  391]   Loss 0.071566   Top1 97.669271   Top5 100.000000   BatchTime 0.123009   LR 0.000100   
2022-11-03 23:31:40,774 - INFO  - Training [65][   80/  391]   Loss 0.072653   Top1 97.617188   Top5 100.000000   BatchTime 0.113305   LR 0.000100   
2022-11-03 23:31:43,147 - INFO  - Training [65][  100/  391]   Loss 0.075655   Top1 97.476562   Top5 99.992188   BatchTime 0.114368   LR 0.000100   
2022-11-03 23:31:45,626 - INFO  - Training [65][  120/  391]   Loss 0.075863   Top1 97.434896   Top5 99.993490   BatchTime 0.115968   LR 0.000100   
2022-11-03 23:31:48,107 - INFO  - Training [65][  140/  391]   Loss 0.077235   Top1 97.405134   Top5 99.983259   BatchTime 0.117120   LR 0.000100   
2022-11-03 23:31:50,586 - INFO  - Training [65][  160/  391]   Loss 0.076275   Top1 97.421875   Top5 99.985352   BatchTime 0.117971   LR 0.000100   
2022-11-03 23:31:53,072 - INFO  - Training [65][  180/  391]   Loss 0.077806   Top1 97.343750   Top5 99.982639   BatchTime 0.118676   LR 0.000100   
2022-11-03 23:31:55,546 - INFO  - Training [65][  200/  391]   Loss 0.078099   Top1 97.332031   Top5 99.984375   BatchTime 0.119179   LR 0.000100   
2022-11-03 23:31:58,038 - INFO  - Training [65][  220/  391]   Loss 0.078268   Top1 97.318892   Top5 99.982244   BatchTime 0.119670   LR 0.000100   
2022-11-03 23:32:00,512 - INFO  - Training [65][  240/  391]   Loss 0.078396   Top1 97.317708   Top5 99.980469   BatchTime 0.120005   LR 0.000100   
2022-11-03 23:32:02,984 - INFO  - Training [65][  260/  391]   Loss 0.078313   Top1 97.310697   Top5 99.981971   BatchTime 0.120281   LR 0.000100   
2022-11-03 23:32:05,461 - INFO  - Training [65][  280/  391]   Loss 0.078587   Top1 97.301897   Top5 99.980469   BatchTime 0.120539   LR 0.000100   
2022-11-03 23:32:07,139 - INFO  - Training [65][  300/  391]   Loss 0.078893   Top1 97.283854   Top5 99.981771   BatchTime 0.118094   LR 0.000100   
2022-11-03 23:32:08,966 - INFO  - Training [65][  320/  391]   Loss 0.078285   Top1 97.307129   Top5 99.980469   BatchTime 0.116422   LR 0.000100   
2022-11-03 23:32:10,783 - INFO  - Training [65][  340/  391]   Loss 0.079378   Top1 97.265625   Top5 99.981618   BatchTime 0.114920   LR 0.000100   
2022-11-03 23:32:12,451 - INFO  - Training [65][  360/  391]   Loss 0.079749   Top1 97.237413   Top5 99.982639   BatchTime 0.113169   LR 0.000100   
2022-11-03 23:32:14,938 - INFO  - Training [65][  380/  391]   Loss 0.080037   Top1 97.240954   Top5 99.983553   BatchTime 0.113757   LR 0.000100   
2022-11-03 23:32:16,546 - INFO  - ==> Top1: 97.248    Top5: 99.984    Loss: 0.080

2022-11-03 23:32:16,546 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:32:19,690 - INFO  - Validation [65][   20/   79]   Loss 0.407568   Top1 89.062500   Top5 99.492188   BatchTime 0.157145   
2022-11-03 23:32:20,963 - INFO  - Validation [65][   40/   79]   Loss 0.401628   Top1 89.335938   Top5 99.511719   BatchTime 0.110378   
2022-11-03 23:32:22,207 - INFO  - Validation [65][   60/   79]   Loss 0.391870   Top1 89.674479   Top5 99.544271   BatchTime 0.094326   
2022-11-03 23:32:23,689 - INFO  - ==> Top1: 89.710    Top5: 99.600    Loss: 0.386

2022-11-03 23:32:23,719 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:32:23,720 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:32:23,720 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:32:23,828 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:32:23,829 - INFO  - >>>>>>>> Epoch  66
2022-11-03 23:32:23,830 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:32:28,136 - INFO  - Training [66][   20/  391]   Loss 0.078908   Top1 97.226562   Top5 100.000000   BatchTime 0.215277   LR 0.000100   
2022-11-03 23:32:30,601 - INFO  - Training [66][   40/  391]   Loss 0.077560   Top1 97.167969   Top5 99.980469   BatchTime 0.169264   LR 0.000100   
2022-11-03 23:32:33,071 - INFO  - Training [66][   60/  391]   Loss 0.076442   Top1 97.278646   Top5 99.986979   BatchTime 0.154012   LR 0.000100   
2022-11-03 23:32:35,075 - INFO  - Training [66][   80/  391]   Loss 0.079294   Top1 97.255859   Top5 99.980469   BatchTime 0.140551   LR 0.000100   
2022-11-03 23:32:36,774 - INFO  - Training [66][  100/  391]   Loss 0.079013   Top1 97.296875   Top5 99.984375   BatchTime 0.129428   LR 0.000100   
2022-11-03 23:32:38,619 - INFO  - Training [66][  120/  391]   Loss 0.079367   Top1 97.311198   Top5 99.980469   BatchTime 0.123232   LR 0.000100   
2022-11-03 23:32:40,097 - INFO  - Training [66][  140/  391]   Loss 0.081402   Top1 97.226562   Top5 99.983259   BatchTime 0.116184   LR 0.000100   
2022-11-03 23:32:42,479 - INFO  - Training [66][  160/  391]   Loss 0.081653   Top1 97.202148   Top5 99.985352   BatchTime 0.116550   LR 0.000100   
2022-11-03 23:32:44,955 - INFO  - Training [66][  180/  391]   Loss 0.081826   Top1 97.161458   Top5 99.986979   BatchTime 0.117355   LR 0.000100   
2022-11-03 23:32:47,451 - INFO  - Training [66][  200/  391]   Loss 0.081919   Top1 97.167969   Top5 99.988281   BatchTime 0.118102   LR 0.000100   
2022-11-03 23:32:49,918 - INFO  - Training [66][  220/  391]   Loss 0.082931   Top1 97.144886   Top5 99.989347   BatchTime 0.118578   LR 0.000100   
2022-11-03 23:32:52,281 - INFO  - Training [66][  240/  391]   Loss 0.082022   Top1 97.161458   Top5 99.990234   BatchTime 0.118541   LR 0.000100   
2022-11-03 23:32:54,760 - INFO  - Training [66][  260/  391]   Loss 0.081951   Top1 97.154447   Top5 99.990986   BatchTime 0.118958   LR 0.000100   
2022-11-03 23:32:57,232 - INFO  - Training [66][  280/  391]   Loss 0.081687   Top1 97.140067   Top5 99.991629   BatchTime 0.119290   LR 0.000100   
2022-11-03 23:32:59,692 - INFO  - Training [66][  300/  391]   Loss 0.081944   Top1 97.135417   Top5 99.986979   BatchTime 0.119535   LR 0.000100   
2022-11-03 23:33:02,157 - INFO  - Training [66][  320/  391]   Loss 0.082298   Top1 97.119141   Top5 99.987793   BatchTime 0.119769   LR 0.000100   
2022-11-03 23:33:04,714 - INFO  - Training [66][  340/  391]   Loss 0.081694   Top1 97.143842   Top5 99.988511   BatchTime 0.120242   LR 0.000100   
2022-11-03 23:33:06,350 - INFO  - Training [66][  360/  391]   Loss 0.081657   Top1 97.146267   Top5 99.989149   BatchTime 0.118107   LR 0.000100   
2022-11-03 23:33:08,086 - INFO  - Training [66][  380/  391]   Loss 0.081374   Top1 97.146382   Top5 99.989720   BatchTime 0.116460   LR 0.000100   
2022-11-03 23:33:09,497 - INFO  - ==> Top1: 97.144    Top5: 99.990    Loss: 0.082

2022-11-03 23:33:09,497 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:33:12,262 - INFO  - Validation [66][   20/   79]   Loss 0.406823   Top1 89.921875   Top5 99.531250   BatchTime 0.138165   
2022-11-03 23:33:13,508 - INFO  - Validation [66][   40/   79]   Loss 0.399425   Top1 89.980469   Top5 99.570312   BatchTime 0.100229   
2022-11-03 23:33:14,807 - INFO  - Validation [66][   60/   79]   Loss 0.389689   Top1 90.182292   Top5 99.609375   BatchTime 0.088484   
2022-11-03 23:33:16,256 - INFO  - ==> Top1: 90.030    Top5: 99.650    Loss: 0.384

2022-11-03 23:33:16,320 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:33:16,321 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:33:16,321 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:33:16,432 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:33:16,432 - INFO  - >>>>>>>> Epoch  67
2022-11-03 23:33:16,433 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:33:20,778 - INFO  - Training [67][   20/  391]   Loss 0.073114   Top1 97.304688   Top5 100.000000   BatchTime 0.217223   LR 0.000100   
2022-11-03 23:33:23,279 - INFO  - Training [67][   40/  391]   Loss 0.077298   Top1 97.265625   Top5 100.000000   BatchTime 0.171129   LR 0.000100   
2022-11-03 23:33:25,779 - INFO  - Training [67][   60/  391]   Loss 0.077038   Top1 97.265625   Top5 100.000000   BatchTime 0.155756   LR 0.000100   
2022-11-03 23:33:28,261 - INFO  - Training [67][   80/  391]   Loss 0.075871   Top1 97.285156   Top5 99.990234   BatchTime 0.147838   LR 0.000100   
2022-11-03 23:33:30,728 - INFO  - Training [67][  100/  391]   Loss 0.079002   Top1 97.171875   Top5 99.992188   BatchTime 0.142940   LR 0.000100   
2022-11-03 23:33:33,211 - INFO  - Training [67][  120/  391]   Loss 0.078572   Top1 97.161458   Top5 99.986979   BatchTime 0.139809   LR 0.000100   
2022-11-03 23:33:35,382 - INFO  - Training [67][  140/  391]   Loss 0.079177   Top1 97.148438   Top5 99.988839   BatchTime 0.135345   LR 0.000100   
2022-11-03 23:33:37,032 - INFO  - Training [67][  160/  391]   Loss 0.080647   Top1 97.114258   Top5 99.990234   BatchTime 0.128742   LR 0.000100   
2022-11-03 23:33:38,788 - INFO  - Training [67][  180/  391]   Loss 0.081722   Top1 97.070312   Top5 99.991319   BatchTime 0.124191   LR 0.000100   
2022-11-03 23:33:40,484 - INFO  - Training [67][  200/  391]   Loss 0.081502   Top1 97.085938   Top5 99.992188   BatchTime 0.120253   LR 0.000100   
2022-11-03 23:33:42,753 - INFO  - Training [67][  220/  391]   Loss 0.080079   Top1 97.105824   Top5 99.992898   BatchTime 0.119632   LR 0.000100   
2022-11-03 23:33:45,245 - INFO  - Training [67][  240/  391]   Loss 0.080310   Top1 97.119141   Top5 99.993490   BatchTime 0.120045   LR 0.000100   
2022-11-03 23:33:47,728 - INFO  - Training [67][  260/  391]   Loss 0.079837   Top1 97.121394   Top5 99.993990   BatchTime 0.120361   LR 0.000100   
2022-11-03 23:33:50,213 - INFO  - Training [67][  280/  391]   Loss 0.079789   Top1 97.140067   Top5 99.988839   BatchTime 0.120638   LR 0.000100   
2022-11-03 23:33:52,695 - INFO  - Training [67][  300/  391]   Loss 0.079376   Top1 97.143229   Top5 99.989583   BatchTime 0.120868   LR 0.000100   
2022-11-03 23:33:55,174 - INFO  - Training [67][  320/  391]   Loss 0.078845   Top1 97.155762   Top5 99.990234   BatchTime 0.121063   LR 0.000100   
2022-11-03 23:33:57,650 - INFO  - Training [67][  340/  391]   Loss 0.079068   Top1 97.134651   Top5 99.988511   BatchTime 0.121222   LR 0.000100   
2022-11-03 23:34:00,113 - INFO  - Training [67][  360/  391]   Loss 0.079154   Top1 97.133247   Top5 99.989149   BatchTime 0.121330   LR 0.000100   
2022-11-03 23:34:02,579 - INFO  - Training [67][  380/  391]   Loss 0.079153   Top1 97.134046   Top5 99.989720   BatchTime 0.121432   LR 0.000100   
2022-11-03 23:34:04,187 - INFO  - ==> Top1: 97.120    Top5: 99.990    Loss: 0.080

2022-11-03 23:34:04,188 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:34:06,699 - INFO  - Validation [67][   20/   79]   Loss 0.413673   Top1 89.335938   Top5 99.492188   BatchTime 0.125506   
2022-11-03 23:34:07,360 - INFO  - Validation [67][   40/   79]   Loss 0.405974   Top1 89.589844   Top5 99.550781   BatchTime 0.079276   
2022-11-03 23:34:08,202 - INFO  - Validation [67][   60/   79]   Loss 0.392296   Top1 90.000000   Top5 99.609375   BatchTime 0.066878   
2022-11-03 23:34:09,360 - INFO  - ==> Top1: 89.840    Top5: 99.630    Loss: 0.387

2022-11-03 23:34:09,389 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:34:09,390 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:34:09,390 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:34:09,505 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:34:09,505 - INFO  - >>>>>>>> Epoch  68
2022-11-03 23:34:09,506 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:34:14,157 - INFO  - Training [68][   20/  391]   Loss 0.083829   Top1 97.031250   Top5 100.000000   BatchTime 0.232498   LR 0.000100   
2022-11-03 23:34:16,657 - INFO  - Training [68][   40/  391]   Loss 0.073683   Top1 97.539062   Top5 100.000000   BatchTime 0.178749   LR 0.000100   
2022-11-03 23:34:19,162 - INFO  - Training [68][   60/  391]   Loss 0.077966   Top1 97.434896   Top5 100.000000   BatchTime 0.160914   LR 0.000100   
2022-11-03 23:34:21,642 - INFO  - Training [68][   80/  391]   Loss 0.082743   Top1 97.158203   Top5 100.000000   BatchTime 0.151686   LR 0.000100   
2022-11-03 23:34:24,131 - INFO  - Training [68][  100/  391]   Loss 0.082928   Top1 97.062500   Top5 100.000000   BatchTime 0.146244   LR 0.000100   
2022-11-03 23:34:26,612 - INFO  - Training [68][  120/  391]   Loss 0.084175   Top1 96.992188   Top5 100.000000   BatchTime 0.142542   LR 0.000100   
2022-11-03 23:34:29,087 - INFO  - Training [68][  140/  391]   Loss 0.082508   Top1 97.053571   Top5 100.000000   BatchTime 0.139856   LR 0.000100   
2022-11-03 23:34:31,560 - INFO  - Training [68][  160/  391]   Loss 0.082291   Top1 97.065430   Top5 100.000000   BatchTime 0.137830   LR 0.000100   
2022-11-03 23:34:34,033 - INFO  - Training [68][  180/  391]   Loss 0.081477   Top1 97.078993   Top5 100.000000   BatchTime 0.136257   LR 0.000100   
2022-11-03 23:34:36,336 - INFO  - Training [68][  200/  391]   Loss 0.080940   Top1 97.093750   Top5 100.000000   BatchTime 0.134144   LR 0.000100   
2022-11-03 23:34:37,977 - INFO  - Training [68][  220/  391]   Loss 0.081672   Top1 97.077415   Top5 99.996449   BatchTime 0.129408   LR 0.000100   
2022-11-03 23:34:39,764 - INFO  - Training [68][  240/  391]   Loss 0.080583   Top1 97.093099   Top5 99.996745   BatchTime 0.126068   LR 0.000100   
2022-11-03 23:34:41,439 - INFO  - Training [68][  260/  391]   Loss 0.080642   Top1 97.103365   Top5 99.993990   BatchTime 0.122813   LR 0.000100   
2022-11-03 23:34:43,710 - INFO  - Training [68][  280/  391]   Loss 0.081035   Top1 97.081473   Top5 99.994420   BatchTime 0.122151   LR 0.000100   
2022-11-03 23:34:46,234 - INFO  - Training [68][  300/  391]   Loss 0.081155   Top1 97.091146   Top5 99.986979   BatchTime 0.122422   LR 0.000100   
2022-11-03 23:34:48,718 - INFO  - Training [68][  320/  391]   Loss 0.081148   Top1 97.097168   Top5 99.987793   BatchTime 0.122534   LR 0.000100   
2022-11-03 23:34:51,194 - INFO  - Training [68][  340/  391]   Loss 0.082184   Top1 97.090993   Top5 99.983915   BatchTime 0.122606   LR 0.000100   
2022-11-03 23:34:53,539 - INFO  - Training [68][  360/  391]   Loss 0.081980   Top1 97.113715   Top5 99.984809   BatchTime 0.122310   LR 0.000100   
2022-11-03 23:34:56,020 - INFO  - Training [68][  380/  391]   Loss 0.082653   Top1 97.080592   Top5 99.985609   BatchTime 0.122402   LR 0.000100   
2022-11-03 23:34:57,618 - INFO  - ==> Top1: 97.090    Top5: 99.986    Loss: 0.083

2022-11-03 23:34:57,619 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:35:00,859 - INFO  - Validation [68][   20/   79]   Loss 0.401344   Top1 89.921875   Top5 99.453125   BatchTime 0.161928   
2022-11-03 23:35:02,123 - INFO  - Validation [68][   40/   79]   Loss 0.397445   Top1 89.746094   Top5 99.531250   BatchTime 0.112554   
2022-11-03 23:35:03,418 - INFO  - Validation [68][   60/   79]   Loss 0.388437   Top1 90.026042   Top5 99.505208   BatchTime 0.096621   
2022-11-03 23:35:04,938 - INFO  - ==> Top1: 89.840    Top5: 99.550    Loss: 0.383

2022-11-03 23:35:04,996 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:35:04,999 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:35:05,000 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:35:05,156 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:35:05,157 - INFO  - >>>>>>>> Epoch  69
2022-11-03 23:35:05,158 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:35:08,970 - INFO  - Training [69][   20/  391]   Loss 0.077121   Top1 96.914062   Top5 100.000000   BatchTime 0.190547   LR 0.000100   
2022-11-03 23:35:10,650 - INFO  - Training [69][   40/  391]   Loss 0.084150   Top1 96.796875   Top5 99.980469   BatchTime 0.137286   LR 0.000100   
2022-11-03 23:35:12,868 - INFO  - Training [69][   60/  391]   Loss 0.081890   Top1 96.875000   Top5 99.986979   BatchTime 0.128496   LR 0.000100   
2022-11-03 23:35:15,346 - INFO  - Training [69][   80/  391]   Loss 0.080964   Top1 96.962891   Top5 99.990234   BatchTime 0.127343   LR 0.000100   
2022-11-03 23:35:17,828 - INFO  - Training [69][  100/  391]   Loss 0.080344   Top1 96.976562   Top5 99.992188   BatchTime 0.126690   LR 0.000100   
2022-11-03 23:35:20,333 - INFO  - Training [69][  120/  391]   Loss 0.081846   Top1 96.920573   Top5 99.993490   BatchTime 0.126454   LR 0.000100   
2022-11-03 23:35:22,821 - INFO  - Training [69][  140/  391]   Loss 0.078960   Top1 97.070312   Top5 99.994420   BatchTime 0.126156   LR 0.000100   
2022-11-03 23:35:25,324 - INFO  - Training [69][  160/  391]   Loss 0.079169   Top1 97.070312   Top5 99.995117   BatchTime 0.126033   LR 0.000100   
2022-11-03 23:35:27,788 - INFO  - Training [69][  180/  391]   Loss 0.078635   Top1 97.113715   Top5 99.995660   BatchTime 0.125714   LR 0.000100   
2022-11-03 23:35:30,267 - INFO  - Training [69][  200/  391]   Loss 0.078172   Top1 97.128906   Top5 99.996094   BatchTime 0.125540   LR 0.000100   
2022-11-03 23:35:32,748 - INFO  - Training [69][  220/  391]   Loss 0.077154   Top1 97.169744   Top5 99.996449   BatchTime 0.125403   LR 0.000100   
2022-11-03 23:35:35,242 - INFO  - Training [69][  240/  391]   Loss 0.077479   Top1 97.190755   Top5 99.993490   BatchTime 0.125344   LR 0.000100   
2022-11-03 23:35:37,124 - INFO  - Training [69][  260/  391]   Loss 0.079028   Top1 97.133413   Top5 99.993990   BatchTime 0.122941   LR 0.000100   
2022-11-03 23:35:38,866 - INFO  - Training [69][  280/  391]   Loss 0.079552   Top1 97.112165   Top5 99.994420   BatchTime 0.120383   LR 0.000100   
2022-11-03 23:35:40,688 - INFO  - Training [69][  300/  391]   Loss 0.079672   Top1 97.104167   Top5 99.989583   BatchTime 0.118428   LR 0.000100   
2022-11-03 23:35:42,151 - INFO  - Training [69][  320/  391]   Loss 0.080150   Top1 97.087402   Top5 99.987793   BatchTime 0.115598   LR 0.000100   
2022-11-03 23:35:44,713 - INFO  - Training [69][  340/  391]   Loss 0.080415   Top1 97.088695   Top5 99.986213   BatchTime 0.116333   LR 0.000100   
2022-11-03 23:35:47,220 - INFO  - Training [69][  360/  391]   Loss 0.080346   Top1 97.085503   Top5 99.986979   BatchTime 0.116835   LR 0.000100   
2022-11-03 23:35:49,685 - INFO  - Training [69][  380/  391]   Loss 0.080201   Top1 97.097039   Top5 99.987664   BatchTime 0.117173   LR 0.000100   
2022-11-03 23:35:51,313 - INFO  - ==> Top1: 97.082    Top5: 99.988    Loss: 0.080

2022-11-03 23:35:51,314 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:35:54,442 - INFO  - Validation [69][   20/   79]   Loss 0.404696   Top1 89.648438   Top5 99.414062   BatchTime 0.156358   
2022-11-03 23:35:55,685 - INFO  - Validation [69][   40/   79]   Loss 0.399608   Top1 89.746094   Top5 99.492188   BatchTime 0.109254   
2022-11-03 23:35:56,944 - INFO  - Validation [69][   60/   79]   Loss 0.391037   Top1 89.934896   Top5 99.518229   BatchTime 0.093824   
2022-11-03 23:35:58,424 - INFO  - ==> Top1: 89.890    Top5: 99.570    Loss: 0.384

2022-11-03 23:35:58,458 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:35:58,458 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:35:58,459 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:35:58,556 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:35:58,557 - INFO  - >>>>>>>> Epoch  70
2022-11-03 23:35:58,558 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:36:02,874 - INFO  - Training [70][   20/  391]   Loss 0.079065   Top1 96.914062   Top5 100.000000   BatchTime 0.215764   LR 0.000010   
2022-11-03 23:36:05,046 - INFO  - Training [70][   40/  391]   Loss 0.085914   Top1 96.835938   Top5 100.000000   BatchTime 0.162203   LR 0.000010   
2022-11-03 23:36:06,683 - INFO  - Training [70][   60/  391]   Loss 0.084845   Top1 96.992188   Top5 100.000000   BatchTime 0.135413   LR 0.000010   
2022-11-03 23:36:08,472 - INFO  - Training [70][   80/  391]   Loss 0.088023   Top1 96.923828   Top5 99.990234   BatchTime 0.123925   LR 0.000010   
2022-11-03 23:36:10,202 - INFO  - Training [70][  100/  391]   Loss 0.087471   Top1 96.945312   Top5 99.992188   BatchTime 0.116438   LR 0.000010   
2022-11-03 23:36:12,636 - INFO  - Training [70][  120/  391]   Loss 0.085518   Top1 97.063802   Top5 99.993490   BatchTime 0.117315   LR 0.000010   
2022-11-03 23:36:15,125 - INFO  - Training [70][  140/  391]   Loss 0.086356   Top1 96.986607   Top5 99.988839   BatchTime 0.118334   LR 0.000010   
2022-11-03 23:36:17,608 - INFO  - Training [70][  160/  391]   Loss 0.084990   Top1 97.036133   Top5 99.990234   BatchTime 0.119058   LR 0.000010   
2022-11-03 23:36:20,101 - INFO  - Training [70][  180/  391]   Loss 0.083645   Top1 97.109375   Top5 99.991319   BatchTime 0.119679   LR 0.000010   
2022-11-03 23:36:22,589 - INFO  - Training [70][  200/  391]   Loss 0.082784   Top1 97.144531   Top5 99.992188   BatchTime 0.120149   LR 0.000010   
2022-11-03 23:36:25,067 - INFO  - Training [70][  220/  391]   Loss 0.083120   Top1 97.112926   Top5 99.992898   BatchTime 0.120490   LR 0.000010   
2022-11-03 23:36:27,555 - INFO  - Training [70][  240/  391]   Loss 0.082949   Top1 97.089844   Top5 99.993490   BatchTime 0.120817   LR 0.000010   
2022-11-03 23:36:30,034 - INFO  - Training [70][  260/  391]   Loss 0.083340   Top1 97.058293   Top5 99.993990   BatchTime 0.121057   LR 0.000010   
2022-11-03 23:36:32,503 - INFO  - Training [70][  280/  391]   Loss 0.082593   Top1 97.075893   Top5 99.994420   BatchTime 0.121229   LR 0.000010   
2022-11-03 23:36:34,993 - INFO  - Training [70][  300/  391]   Loss 0.082230   Top1 97.080729   Top5 99.994792   BatchTime 0.121447   LR 0.000010   
2022-11-03 23:36:36,691 - INFO  - Training [70][  320/  391]   Loss 0.082767   Top1 97.077637   Top5 99.990234   BatchTime 0.119163   LR 0.000010   
2022-11-03 23:36:38,473 - INFO  - Training [70][  340/  391]   Loss 0.082483   Top1 97.081801   Top5 99.988511   BatchTime 0.117395   LR 0.000010   
2022-11-03 23:36:40,257 - INFO  - Training [70][  360/  391]   Loss 0.082224   Top1 97.105035   Top5 99.986979   BatchTime 0.115828   LR 0.000010   
2022-11-03 23:36:42,001 - INFO  - Training [70][  380/  391]   Loss 0.082136   Top1 97.111431   Top5 99.987664   BatchTime 0.114322   LR 0.000010   
2022-11-03 23:36:43,623 - INFO  - ==> Top1: 97.100    Top5: 99.988    Loss: 0.082

2022-11-03 23:36:43,624 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:36:46,709 - INFO  - Validation [70][   20/   79]   Loss 0.411574   Top1 89.609375   Top5 99.531250   BatchTime 0.154163   
2022-11-03 23:36:47,976 - INFO  - Validation [70][   40/   79]   Loss 0.401439   Top1 89.609375   Top5 99.550781   BatchTime 0.108754   
2022-11-03 23:36:49,260 - INFO  - Validation [70][   60/   79]   Loss 0.391523   Top1 89.817708   Top5 99.583333   BatchTime 0.093912   
2022-11-03 23:36:50,726 - INFO  - ==> Top1: 89.740    Top5: 99.600    Loss: 0.384

2022-11-03 23:36:50,783 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:36:50,784 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:36:50,784 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:36:50,897 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:36:50,898 - INFO  - >>>>>>>> Epoch  71
2022-11-03 23:36:50,899 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:36:55,339 - INFO  - Training [71][   20/  391]   Loss 0.076016   Top1 96.992188   Top5 100.000000   BatchTime 0.222020   LR 0.000010   
2022-11-03 23:36:57,824 - INFO  - Training [71][   40/  391]   Loss 0.080509   Top1 97.031250   Top5 99.980469   BatchTime 0.173134   LR 0.000010   
2022-11-03 23:37:00,312 - INFO  - Training [71][   60/  391]   Loss 0.080456   Top1 97.135417   Top5 99.973958   BatchTime 0.156887   LR 0.000010   
2022-11-03 23:37:02,782 - INFO  - Training [71][   80/  391]   Loss 0.079209   Top1 97.148438   Top5 99.980469   BatchTime 0.148545   LR 0.000010   
2022-11-03 23:37:04,793 - INFO  - Training [71][  100/  391]   Loss 0.080395   Top1 97.093750   Top5 99.984375   BatchTime 0.138944   LR 0.000010   
2022-11-03 23:37:06,483 - INFO  - Training [71][  120/  391]   Loss 0.082391   Top1 97.050781   Top5 99.973958   BatchTime 0.129870   LR 0.000010   
2022-11-03 23:37:08,370 - INFO  - Training [71][  140/  391]   Loss 0.082677   Top1 97.047991   Top5 99.977679   BatchTime 0.124790   LR 0.000010   
2022-11-03 23:37:09,898 - INFO  - Training [71][  160/  391]   Loss 0.083664   Top1 97.006836   Top5 99.980469   BatchTime 0.118744   LR 0.000010   
2022-11-03 23:37:12,341 - INFO  - Training [71][  180/  391]   Loss 0.082813   Top1 97.048611   Top5 99.982639   BatchTime 0.119125   LR 0.000010   
2022-11-03 23:37:14,827 - INFO  - Training [71][  200/  391]   Loss 0.082136   Top1 97.082031   Top5 99.984375   BatchTime 0.119639   LR 0.000010   
2022-11-03 23:37:17,318 - INFO  - Training [71][  220/  391]   Loss 0.082053   Top1 97.077415   Top5 99.985795   BatchTime 0.120084   LR 0.000010   
2022-11-03 23:37:19,815 - INFO  - Training [71][  240/  391]   Loss 0.083310   Top1 97.060547   Top5 99.983724   BatchTime 0.120482   LR 0.000010   
2022-11-03 23:37:22,322 - INFO  - Training [71][  260/  391]   Loss 0.082383   Top1 97.097356   Top5 99.984976   BatchTime 0.120857   LR 0.000010   
2022-11-03 23:37:24,796 - INFO  - Training [71][  280/  391]   Loss 0.081812   Top1 97.128906   Top5 99.986049   BatchTime 0.121058   LR 0.000010   
2022-11-03 23:37:27,279 - INFO  - Training [71][  300/  391]   Loss 0.081745   Top1 97.125000   Top5 99.986979   BatchTime 0.121264   LR 0.000010   
2022-11-03 23:37:29,749 - INFO  - Training [71][  320/  391]   Loss 0.081612   Top1 97.124023   Top5 99.987793   BatchTime 0.121406   LR 0.000010   
2022-11-03 23:37:32,212 - INFO  - Training [71][  340/  391]   Loss 0.081505   Top1 97.127757   Top5 99.988511   BatchTime 0.121506   LR 0.000010   
2022-11-03 23:37:34,671 - INFO  - Training [71][  360/  391]   Loss 0.081823   Top1 97.135417   Top5 99.986979   BatchTime 0.121587   LR 0.000010   
2022-11-03 23:37:36,224 - INFO  - Training [71][  380/  391]   Loss 0.081295   Top1 97.160773   Top5 99.987664   BatchTime 0.119274   LR 0.000010   
2022-11-03 23:37:37,462 - INFO  - ==> Top1: 97.152    Top5: 99.988    Loss: 0.081

2022-11-03 23:37:37,463 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:37:40,015 - INFO  - Validation [71][   20/   79]   Loss 0.412221   Top1 89.609375   Top5 99.570312   BatchTime 0.127521   
2022-11-03 23:37:40,646 - INFO  - Validation [71][   40/   79]   Loss 0.399800   Top1 89.785156   Top5 99.589844   BatchTime 0.079545   
2022-11-03 23:37:41,909 - INFO  - Validation [71][   60/   79]   Loss 0.389675   Top1 89.882812   Top5 99.583333   BatchTime 0.074071   
2022-11-03 23:37:43,403 - INFO  - ==> Top1: 89.770    Top5: 99.620    Loss: 0.384

2022-11-03 23:37:43,444 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:37:43,444 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:37:43,444 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:37:43,551 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:37:43,552 - INFO  - >>>>>>>> Epoch  72
2022-11-03 23:37:43,553 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:37:47,876 - INFO  - Training [72][   20/  391]   Loss 0.084030   Top1 97.031250   Top5 100.000000   BatchTime 0.216139   LR 0.000010   
2022-11-03 23:37:50,381 - INFO  - Training [72][   40/  391]   Loss 0.084545   Top1 96.953125   Top5 100.000000   BatchTime 0.170694   LR 0.000010   
2022-11-03 23:37:52,852 - INFO  - Training [72][   60/  391]   Loss 0.085195   Top1 96.992188   Top5 99.986979   BatchTime 0.154978   LR 0.000010   
2022-11-03 23:37:55,361 - INFO  - Training [72][   80/  391]   Loss 0.084617   Top1 96.972656   Top5 99.980469   BatchTime 0.147596   LR 0.000010   
2022-11-03 23:37:57,862 - INFO  - Training [72][  100/  391]   Loss 0.081551   Top1 97.054688   Top5 99.984375   BatchTime 0.143091   LR 0.000010   
2022-11-03 23:38:00,351 - INFO  - Training [72][  120/  391]   Loss 0.080623   Top1 97.089844   Top5 99.986979   BatchTime 0.139981   LR 0.000010   
2022-11-03 23:38:02,829 - INFO  - Training [72][  140/  391]   Loss 0.080662   Top1 97.064732   Top5 99.983259   BatchTime 0.137683   LR 0.000010   
2022-11-03 23:38:04,897 - INFO  - Training [72][  160/  391]   Loss 0.079970   Top1 97.099609   Top5 99.985352   BatchTime 0.133395   LR 0.000010   
2022-11-03 23:38:06,604 - INFO  - Training [72][  180/  391]   Loss 0.081903   Top1 97.057292   Top5 99.986979   BatchTime 0.128060   LR 0.000010   
2022-11-03 23:38:08,445 - INFO  - Training [72][  200/  391]   Loss 0.081461   Top1 97.082031   Top5 99.988281   BatchTime 0.124457   LR 0.000010   
2022-11-03 23:38:09,913 - INFO  - Training [72][  220/  391]   Loss 0.081734   Top1 97.066761   Top5 99.989347   BatchTime 0.119814   LR 0.000010   
2022-11-03 23:38:12,345 - INFO  - Training [72][  240/  391]   Loss 0.081808   Top1 97.070312   Top5 99.983724   BatchTime 0.119963   LR 0.000010   
2022-11-03 23:38:14,843 - INFO  - Training [72][  260/  391]   Loss 0.081461   Top1 97.079327   Top5 99.984976   BatchTime 0.120343   LR 0.000010   
2022-11-03 23:38:17,329 - INFO  - Training [72][  280/  391]   Loss 0.081401   Top1 97.078683   Top5 99.986049   BatchTime 0.120625   LR 0.000010   
2022-11-03 23:38:19,799 - INFO  - Training [72][  300/  391]   Loss 0.081462   Top1 97.091146   Top5 99.986979   BatchTime 0.120816   LR 0.000010   
2022-11-03 23:38:22,290 - INFO  - Training [72][  320/  391]   Loss 0.082181   Top1 97.092285   Top5 99.985352   BatchTime 0.121049   LR 0.000010   
2022-11-03 23:38:24,752 - INFO  - Training [72][  340/  391]   Loss 0.081898   Top1 97.079504   Top5 99.986213   BatchTime 0.121171   LR 0.000010   
2022-11-03 23:38:27,250 - INFO  - Training [72][  360/  391]   Loss 0.082219   Top1 97.083333   Top5 99.984809   BatchTime 0.121377   LR 0.000010   
2022-11-03 23:38:29,701 - INFO  - Training [72][  380/  391]   Loss 0.082975   Top1 97.060033   Top5 99.985609   BatchTime 0.121440   LR 0.000010   
2022-11-03 23:38:31,302 - INFO  - ==> Top1: 97.056    Top5: 99.986    Loss: 0.083

2022-11-03 23:38:31,303 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:38:34,136 - INFO  - Validation [72][   20/   79]   Loss 0.406944   Top1 89.960938   Top5 99.570312   BatchTime 0.141562   
2022-11-03 23:38:34,658 - INFO  - Validation [72][   40/   79]   Loss 0.400457   Top1 89.843750   Top5 99.492188   BatchTime 0.083827   
2022-11-03 23:38:35,186 - INFO  - Validation [72][   60/   79]   Loss 0.392144   Top1 90.026042   Top5 99.544271   BatchTime 0.064694   
2022-11-03 23:38:36,037 - INFO  - ==> Top1: 89.840    Top5: 99.560    Loss: 0.386

2022-11-03 23:38:36,075 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:38:36,076 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:38:36,076 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:38:36,193 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:38:36,194 - INFO  - >>>>>>>> Epoch  73
2022-11-03 23:38:36,195 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:38:39,934 - INFO  - Training [73][   20/  391]   Loss 0.083244   Top1 97.070312   Top5 100.000000   BatchTime 0.186928   LR 0.000010   
2022-11-03 23:38:42,410 - INFO  - Training [73][   40/  391]   Loss 0.082953   Top1 96.933594   Top5 100.000000   BatchTime 0.155367   LR 0.000010   
2022-11-03 23:38:44,887 - INFO  - Training [73][   60/  391]   Loss 0.079743   Top1 97.200521   Top5 99.986979   BatchTime 0.144869   LR 0.000010   
2022-11-03 23:38:47,375 - INFO  - Training [73][   80/  391]   Loss 0.080505   Top1 97.158203   Top5 99.990234   BatchTime 0.139745   LR 0.000010   
2022-11-03 23:38:49,927 - INFO  - Training [73][  100/  391]   Loss 0.079658   Top1 97.210938   Top5 99.992188   BatchTime 0.137318   LR 0.000010   
2022-11-03 23:38:52,423 - INFO  - Training [73][  120/  391]   Loss 0.080396   Top1 97.180990   Top5 99.993490   BatchTime 0.135227   LR 0.000010   
2022-11-03 23:38:54,903 - INFO  - Training [73][  140/  391]   Loss 0.080304   Top1 97.209821   Top5 99.994420   BatchTime 0.133627   LR 0.000010   
2022-11-03 23:38:57,341 - INFO  - Training [73][  160/  391]   Loss 0.080476   Top1 97.187500   Top5 99.995117   BatchTime 0.132158   LR 0.000010   
2022-11-03 23:38:59,806 - INFO  - Training [73][  180/  391]   Loss 0.081620   Top1 97.105035   Top5 99.995660   BatchTime 0.131169   LR 0.000010   
2022-11-03 23:39:02,280 - INFO  - Training [73][  200/  391]   Loss 0.080896   Top1 97.132812   Top5 99.996094   BatchTime 0.130421   LR 0.000010   
2022-11-03 23:39:04,644 - INFO  - Training [73][  220/  391]   Loss 0.081146   Top1 97.141335   Top5 99.996449   BatchTime 0.129312   LR 0.000010   
2022-11-03 23:39:06,223 - INFO  - Training [73][  240/  391]   Loss 0.080876   Top1 97.145182   Top5 99.996745   BatchTime 0.125112   LR 0.000010   
2022-11-03 23:39:08,021 - INFO  - Training [73][  260/  391]   Loss 0.081083   Top1 97.154447   Top5 99.993990   BatchTime 0.122404   LR 0.000010   
2022-11-03 23:39:09,669 - INFO  - Training [73][  280/  391]   Loss 0.080682   Top1 97.159598   Top5 99.994420   BatchTime 0.119546   LR 0.000010   
2022-11-03 23:39:11,746 - INFO  - Training [73][  300/  391]   Loss 0.080449   Top1 97.151042   Top5 99.992188   BatchTime 0.118501   LR 0.000010   
2022-11-03 23:39:14,255 - INFO  - Training [73][  320/  391]   Loss 0.080128   Top1 97.170410   Top5 99.990234   BatchTime 0.118935   LR 0.000010   
2022-11-03 23:39:16,719 - INFO  - Training [73][  340/  391]   Loss 0.079780   Top1 97.182904   Top5 99.990809   BatchTime 0.119185   LR 0.000010   
2022-11-03 23:39:19,185 - INFO  - Training [73][  360/  391]   Loss 0.079689   Top1 97.196181   Top5 99.989149   BatchTime 0.119413   LR 0.000010   
2022-11-03 23:39:21,665 - INFO  - Training [73][  380/  391]   Loss 0.079874   Top1 97.187500   Top5 99.989720   BatchTime 0.119656   LR 0.000010   
2022-11-03 23:39:23,273 - INFO  - ==> Top1: 97.174    Top5: 99.988    Loss: 0.080

2022-11-03 23:39:23,274 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:39:26,364 - INFO  - Validation [73][   20/   79]   Loss 0.403673   Top1 89.648438   Top5 99.531250   BatchTime 0.154407   
2022-11-03 23:39:27,677 - INFO  - Validation [73][   40/   79]   Loss 0.400976   Top1 89.648438   Top5 99.570312   BatchTime 0.110044   
2022-11-03 23:39:28,996 - INFO  - Validation [73][   60/   79]   Loss 0.393098   Top1 89.986979   Top5 99.596354   BatchTime 0.095339   
2022-11-03 23:39:30,477 - INFO  - ==> Top1: 89.920    Top5: 99.620    Loss: 0.386

2022-11-03 23:39:30,520 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:39:30,521 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:39:30,521 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:39:30,629 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:39:30,630 - INFO  - >>>>>>>> Epoch  74
2022-11-03 23:39:30,631 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:39:34,287 - INFO  - Training [74][   20/  391]   Loss 0.094870   Top1 96.875000   Top5 99.960938   BatchTime 0.182782   LR 0.000010   
2022-11-03 23:39:36,066 - INFO  - Training [74][   40/  391]   Loss 0.082515   Top1 97.246094   Top5 99.980469   BatchTime 0.135871   LR 0.000010   
2022-11-03 23:39:37,796 - INFO  - Training [74][   60/  391]   Loss 0.083070   Top1 97.200521   Top5 99.986979   BatchTime 0.119406   LR 0.000010   
2022-11-03 23:39:39,649 - INFO  - Training [74][   80/  391]   Loss 0.083649   Top1 97.167969   Top5 99.970703   BatchTime 0.112711   LR 0.000010   
2022-11-03 23:39:42,147 - INFO  - Training [74][  100/  391]   Loss 0.083103   Top1 97.132812   Top5 99.976562   BatchTime 0.115155   LR 0.000010   
2022-11-03 23:39:44,617 - INFO  - Training [74][  120/  391]   Loss 0.085804   Top1 96.972656   Top5 99.967448   BatchTime 0.116541   LR 0.000010   
2022-11-03 23:39:47,094 - INFO  - Training [74][  140/  391]   Loss 0.084693   Top1 97.014509   Top5 99.972098   BatchTime 0.117585   LR 0.000010   
2022-11-03 23:39:49,593 - INFO  - Training [74][  160/  391]   Loss 0.084683   Top1 97.011719   Top5 99.975586   BatchTime 0.118506   LR 0.000010   
2022-11-03 23:39:52,077 - INFO  - Training [74][  180/  391]   Loss 0.084223   Top1 97.035590   Top5 99.978299   BatchTime 0.119142   LR 0.000010   
2022-11-03 23:39:54,558 - INFO  - Training [74][  200/  391]   Loss 0.083687   Top1 97.054688   Top5 99.980469   BatchTime 0.119632   LR 0.000010   
2022-11-03 23:39:57,028 - INFO  - Training [74][  220/  391]   Loss 0.083995   Top1 97.056108   Top5 99.982244   BatchTime 0.119980   LR 0.000010   
2022-11-03 23:39:59,499 - INFO  - Training [74][  240/  391]   Loss 0.084000   Top1 97.044271   Top5 99.980469   BatchTime 0.120281   LR 0.000010   
2022-11-03 23:40:01,959 - INFO  - Training [74][  260/  391]   Loss 0.083869   Top1 97.049279   Top5 99.981971   BatchTime 0.120489   LR 0.000010   
2022-11-03 23:40:04,158 - INFO  - Training [74][  280/  391]   Loss 0.083854   Top1 97.042411   Top5 99.980469   BatchTime 0.119737   LR 0.000010   
2022-11-03 23:40:05,824 - INFO  - Training [74][  300/  391]   Loss 0.084427   Top1 97.010417   Top5 99.979167   BatchTime 0.117307   LR 0.000010   
2022-11-03 23:40:07,680 - INFO  - Training [74][  320/  391]   Loss 0.084382   Top1 97.016602   Top5 99.975586   BatchTime 0.115775   LR 0.000010   
2022-11-03 23:40:09,273 - INFO  - Training [74][  340/  391]   Loss 0.084296   Top1 97.012868   Top5 99.974724   BatchTime 0.113650   LR 0.000010   
2022-11-03 23:40:11,546 - INFO  - Training [74][  360/  391]   Loss 0.083992   Top1 97.013889   Top5 99.976128   BatchTime 0.113650   LR 0.000010   
2022-11-03 23:40:14,015 - INFO  - Training [74][  380/  391]   Loss 0.084382   Top1 97.004523   Top5 99.977385   BatchTime 0.114164   LR 0.000010   
2022-11-03 23:40:15,627 - INFO  - ==> Top1: 97.006    Top5: 99.978    Loss: 0.085

2022-11-03 23:40:15,627 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:40:18,726 - INFO  - Validation [74][   20/   79]   Loss 0.411191   Top1 89.687500   Top5 99.531250   BatchTime 0.154875   
2022-11-03 23:40:20,017 - INFO  - Validation [74][   40/   79]   Loss 0.400808   Top1 89.843750   Top5 99.609375   BatchTime 0.109697   
2022-11-03 23:40:21,276 - INFO  - Validation [74][   60/   79]   Loss 0.395595   Top1 89.947917   Top5 99.622396   BatchTime 0.094128   
2022-11-03 23:40:22,766 - INFO  - ==> Top1: 89.750    Top5: 99.640    Loss: 0.388

2022-11-03 23:40:22,800 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:40:22,800 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:40:22,801 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:40:23,004 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:40:23,005 - INFO  - >>>>>>>> Epoch  75
2022-11-03 23:40:23,006 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:40:27,307 - INFO  - Training [75][   20/  391]   Loss 0.079173   Top1 97.343750   Top5 100.000000   BatchTime 0.215038   LR 0.000010   
2022-11-03 23:40:29,767 - INFO  - Training [75][   40/  391]   Loss 0.085137   Top1 97.128906   Top5 100.000000   BatchTime 0.169010   LR 0.000010   
2022-11-03 23:40:32,135 - INFO  - Training [75][   60/  391]   Loss 0.083107   Top1 97.122396   Top5 99.986979   BatchTime 0.152145   LR 0.000010   
2022-11-03 23:40:33,737 - INFO  - Training [75][   80/  391]   Loss 0.080153   Top1 97.187500   Top5 99.980469   BatchTime 0.134130   LR 0.000010   
2022-11-03 23:40:35,517 - INFO  - Training [75][  100/  391]   Loss 0.082203   Top1 97.101562   Top5 99.984375   BatchTime 0.125106   LR 0.000010   
2022-11-03 23:40:37,222 - INFO  - Training [75][  120/  391]   Loss 0.081661   Top1 97.076823   Top5 99.980469   BatchTime 0.118465   LR 0.000010   
2022-11-03 23:40:39,328 - INFO  - Training [75][  140/  391]   Loss 0.082430   Top1 97.059152   Top5 99.983259   BatchTime 0.116579   LR 0.000010   
2022-11-03 23:40:41,925 - INFO  - Training [75][  160/  391]   Loss 0.082954   Top1 97.080078   Top5 99.985352   BatchTime 0.118237   LR 0.000010   
2022-11-03 23:40:44,390 - INFO  - Training [75][  180/  391]   Loss 0.083318   Top1 97.074653   Top5 99.978299   BatchTime 0.118796   LR 0.000010   
2022-11-03 23:40:46,869 - INFO  - Training [75][  200/  391]   Loss 0.083577   Top1 97.062500   Top5 99.980469   BatchTime 0.119313   LR 0.000010   
2022-11-03 23:40:49,347 - INFO  - Training [75][  220/  391]   Loss 0.082470   Top1 97.088068   Top5 99.982244   BatchTime 0.119727   LR 0.000010   
2022-11-03 23:40:51,827 - INFO  - Training [75][  240/  391]   Loss 0.082492   Top1 97.086589   Top5 99.983724   BatchTime 0.120084   LR 0.000010   
2022-11-03 23:40:54,315 - INFO  - Training [75][  260/  391]   Loss 0.082565   Top1 97.091346   Top5 99.984976   BatchTime 0.120416   LR 0.000010   
2022-11-03 23:40:56,790 - INFO  - Training [75][  280/  391]   Loss 0.082108   Top1 97.081473   Top5 99.986049   BatchTime 0.120654   LR 0.000010   
2022-11-03 23:40:59,142 - INFO  - Training [75][  300/  391]   Loss 0.082154   Top1 97.059896   Top5 99.986979   BatchTime 0.120449   LR 0.000010   
2022-11-03 23:41:01,599 - INFO  - Training [75][  320/  391]   Loss 0.082783   Top1 97.009277   Top5 99.987793   BatchTime 0.120599   LR 0.000010   
2022-11-03 23:41:03,581 - INFO  - Training [75][  340/  391]   Loss 0.083207   Top1 97.022059   Top5 99.986213   BatchTime 0.119334   LR 0.000010   
2022-11-03 23:41:05,223 - INFO  - Training [75][  360/  391]   Loss 0.083883   Top1 96.983507   Top5 99.986979   BatchTime 0.117265   LR 0.000010   
2022-11-03 23:41:07,087 - INFO  - Training [75][  380/  391]   Loss 0.084034   Top1 96.963405   Top5 99.987664   BatchTime 0.115998   LR 0.000010   
2022-11-03 23:41:08,155 - INFO  - ==> Top1: 96.968    Top5: 99.988    Loss: 0.084

2022-11-03 23:41:08,156 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:41:11,445 - INFO  - Validation [75][   20/   79]   Loss 0.413476   Top1 89.648438   Top5 99.531250   BatchTime 0.164381   
2022-11-03 23:41:12,762 - INFO  - Validation [75][   40/   79]   Loss 0.405262   Top1 89.570312   Top5 99.511719   BatchTime 0.115106   
2022-11-03 23:41:14,080 - INFO  - Validation [75][   60/   79]   Loss 0.397134   Top1 89.674479   Top5 99.570312   BatchTime 0.098709   
2022-11-03 23:41:15,607 - INFO  - ==> Top1: 89.580    Top5: 99.610    Loss: 0.388

2022-11-03 23:41:15,681 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:41:15,682 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:41:15,682 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:41:15,794 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:41:15,794 - INFO  - >>>>>>>> Epoch  76
2022-11-03 23:41:15,796 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:41:20,096 - INFO  - Training [76][   20/  391]   Loss 0.083504   Top1 96.992188   Top5 100.000000   BatchTime 0.215020   LR 0.000010   
2022-11-03 23:41:22,591 - INFO  - Training [76][   40/  391]   Loss 0.079211   Top1 97.128906   Top5 100.000000   BatchTime 0.169880   LR 0.000010   
2022-11-03 23:41:25,048 - INFO  - Training [76][   60/  391]   Loss 0.077435   Top1 97.278646   Top5 100.000000   BatchTime 0.154192   LR 0.000010   
2022-11-03 23:41:27,523 - INFO  - Training [76][   80/  391]   Loss 0.075582   Top1 97.324219   Top5 100.000000   BatchTime 0.146582   LR 0.000010   
2022-11-03 23:41:29,980 - INFO  - Training [76][  100/  391]   Loss 0.075839   Top1 97.265625   Top5 100.000000   BatchTime 0.141842   LR 0.000010   
2022-11-03 23:41:32,043 - INFO  - Training [76][  120/  391]   Loss 0.075056   Top1 97.311198   Top5 100.000000   BatchTime 0.135392   LR 0.000010   
2022-11-03 23:41:33,716 - INFO  - Training [76][  140/  391]   Loss 0.076316   Top1 97.321429   Top5 99.994420   BatchTime 0.128000   LR 0.000010   
2022-11-03 23:41:35,492 - INFO  - Training [76][  160/  391]   Loss 0.078239   Top1 97.216797   Top5 99.995117   BatchTime 0.123096   LR 0.000010   
2022-11-03 23:41:37,166 - INFO  - Training [76][  180/  391]   Loss 0.078382   Top1 97.213542   Top5 99.991319   BatchTime 0.118723   LR 0.000010   
2022-11-03 23:41:39,415 - INFO  - Training [76][  200/  391]   Loss 0.079307   Top1 97.156250   Top5 99.992188   BatchTime 0.118091   LR 0.000010   
2022-11-03 23:41:41,909 - INFO  - Training [76][  220/  391]   Loss 0.079650   Top1 97.144886   Top5 99.992898   BatchTime 0.118695   LR 0.000010   
2022-11-03 23:41:44,387 - INFO  - Training [76][  240/  391]   Loss 0.079005   Top1 97.161458   Top5 99.986979   BatchTime 0.119126   LR 0.000010   
2022-11-03 23:41:46,869 - INFO  - Training [76][  260/  391]   Loss 0.080339   Top1 97.112380   Top5 99.984976   BatchTime 0.119509   LR 0.000010   
2022-11-03 23:41:49,366 - INFO  - Training [76][  280/  391]   Loss 0.080019   Top1 97.131696   Top5 99.983259   BatchTime 0.119890   LR 0.000010   
2022-11-03 23:41:51,847 - INFO  - Training [76][  300/  391]   Loss 0.079566   Top1 97.158854   Top5 99.984375   BatchTime 0.120167   LR 0.000010   
2022-11-03 23:41:54,324 - INFO  - Training [76][  320/  391]   Loss 0.079449   Top1 97.158203   Top5 99.982910   BatchTime 0.120396   LR 0.000010   
2022-11-03 23:41:56,782 - INFO  - Training [76][  340/  391]   Loss 0.079551   Top1 97.159926   Top5 99.981618   BatchTime 0.120544   LR 0.000010   
2022-11-03 23:41:59,243 - INFO  - Training [76][  360/  391]   Loss 0.079885   Top1 97.154948   Top5 99.982639   BatchTime 0.120683   LR 0.000010   
2022-11-03 23:42:01,701 - INFO  - Training [76][  380/  391]   Loss 0.080125   Top1 97.140214   Top5 99.983553   BatchTime 0.120801   LR 0.000010   
2022-11-03 23:42:03,116 - INFO  - ==> Top1: 97.136    Top5: 99.984    Loss: 0.080

2022-11-03 23:42:03,117 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:42:05,844 - INFO  - Validation [76][   20/   79]   Loss 0.401423   Top1 89.843750   Top5 99.570312   BatchTime 0.136298   
2022-11-03 23:42:06,568 - INFO  - Validation [76][   40/   79]   Loss 0.394330   Top1 89.863281   Top5 99.589844   BatchTime 0.086236   
2022-11-03 23:42:07,084 - INFO  - Validation [76][   60/   79]   Loss 0.388743   Top1 90.078125   Top5 99.596354   BatchTime 0.066094   
2022-11-03 23:42:07,831 - INFO  - ==> Top1: 89.970    Top5: 99.620    Loss: 0.380

2022-11-03 23:42:07,853 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:42:07,854 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:42:07,854 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:42:07,945 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:42:07,946 - INFO  - >>>>>>>> Epoch  77
2022-11-03 23:42:07,947 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:42:12,483 - INFO  - Training [77][   20/  391]   Loss 0.076117   Top1 96.914062   Top5 100.000000   BatchTime 0.226812   LR 0.000010   
2022-11-03 23:42:14,957 - INFO  - Training [77][   40/  391]   Loss 0.082097   Top1 96.718750   Top5 99.980469   BatchTime 0.175244   LR 0.000010   
2022-11-03 23:42:17,443 - INFO  - Training [77][   60/  391]   Loss 0.076864   Top1 97.070312   Top5 99.986979   BatchTime 0.158265   LR 0.000010   
2022-11-03 23:42:19,926 - INFO  - Training [77][   80/  391]   Loss 0.080297   Top1 97.021484   Top5 99.990234   BatchTime 0.149733   LR 0.000010   
2022-11-03 23:42:22,390 - INFO  - Training [77][  100/  391]   Loss 0.082613   Top1 97.007812   Top5 99.984375   BatchTime 0.144434   LR 0.000010   
2022-11-03 23:42:24,870 - INFO  - Training [77][  120/  391]   Loss 0.083266   Top1 96.933594   Top5 99.986979   BatchTime 0.141028   LR 0.000010   
2022-11-03 23:42:27,349 - INFO  - Training [77][  140/  391]   Loss 0.081131   Top1 97.047991   Top5 99.983259   BatchTime 0.138582   LR 0.000010   
2022-11-03 23:42:29,816 - INFO  - Training [77][  160/  391]   Loss 0.082060   Top1 97.055664   Top5 99.985352   BatchTime 0.136681   LR 0.000010   
2022-11-03 23:42:32,266 - INFO  - Training [77][  180/  391]   Loss 0.082253   Top1 97.074653   Top5 99.978299   BatchTime 0.135106   LR 0.000010   
2022-11-03 23:42:33,855 - INFO  - Training [77][  200/  391]   Loss 0.081357   Top1 97.117188   Top5 99.976562   BatchTime 0.129540   LR 0.000010   
2022-11-03 23:42:35,656 - INFO  - Training [77][  220/  391]   Loss 0.081214   Top1 97.151989   Top5 99.978693   BatchTime 0.125949   LR 0.000010   
2022-11-03 23:42:37,521 - INFO  - Training [77][  240/  391]   Loss 0.081720   Top1 97.132161   Top5 99.977214   BatchTime 0.123224   LR 0.000010   
2022-11-03 23:42:39,610 - INFO  - Training [77][  260/  391]   Loss 0.081776   Top1 97.106370   Top5 99.978966   BatchTime 0.121781   LR 0.000010   
2022-11-03 23:42:42,100 - INFO  - Training [77][  280/  391]   Loss 0.081654   Top1 97.112165   Top5 99.977679   BatchTime 0.121973   LR 0.000010   
2022-11-03 23:42:44,569 - INFO  - Training [77][  300/  391]   Loss 0.081868   Top1 97.101562   Top5 99.976562   BatchTime 0.122072   LR 0.000010   
2022-11-03 23:42:47,060 - INFO  - Training [77][  320/  391]   Loss 0.082416   Top1 97.087402   Top5 99.975586   BatchTime 0.122225   LR 0.000010   
2022-11-03 23:42:49,525 - INFO  - Training [77][  340/  391]   Loss 0.082799   Top1 97.058824   Top5 99.977022   BatchTime 0.122287   LR 0.000010   
2022-11-03 23:42:52,005 - INFO  - Training [77][  360/  391]   Loss 0.083093   Top1 97.039931   Top5 99.978299   BatchTime 0.122380   LR 0.000010   
2022-11-03 23:42:54,461 - INFO  - Training [77][  380/  391]   Loss 0.083094   Top1 97.027138   Top5 99.979441   BatchTime 0.122403   LR 0.000010   
2022-11-03 23:42:56,077 - INFO  - ==> Top1: 97.018    Top5: 99.980    Loss: 0.083

2022-11-03 23:42:56,078 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:42:59,112 - INFO  - Validation [77][   20/   79]   Loss 0.405994   Top1 89.570312   Top5 99.453125   BatchTime 0.151626   
2022-11-03 23:43:00,319 - INFO  - Validation [77][   40/   79]   Loss 0.402932   Top1 89.609375   Top5 99.492188   BatchTime 0.105974   
2022-11-03 23:43:01,590 - INFO  - Validation [77][   60/   79]   Loss 0.396574   Top1 89.791667   Top5 99.518229   BatchTime 0.091834   
2022-11-03 23:43:02,484 - INFO  - ==> Top1: 89.690    Top5: 99.570    Loss: 0.391

2022-11-03 23:43:02,511 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:43:02,512 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:43:02,512 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:43:02,609 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:43:02,609 - INFO  - >>>>>>>> Epoch  78
2022-11-03 23:43:02,611 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:43:06,397 - INFO  - Training [78][   20/  391]   Loss 0.070390   Top1 97.500000   Top5 100.000000   BatchTime 0.189312   LR 0.000010   
2022-11-03 23:43:08,039 - INFO  - Training [78][   40/  391]   Loss 0.076580   Top1 97.324219   Top5 100.000000   BatchTime 0.135691   LR 0.000010   
2022-11-03 23:43:10,518 - INFO  - Training [78][   60/  391]   Loss 0.080860   Top1 97.122396   Top5 100.000000   BatchTime 0.131792   LR 0.000010   
2022-11-03 23:43:13,013 - INFO  - Training [78][   80/  391]   Loss 0.081214   Top1 97.041016   Top5 100.000000   BatchTime 0.130027   LR 0.000010   
2022-11-03 23:43:15,491 - INFO  - Training [78][  100/  391]   Loss 0.079462   Top1 97.156250   Top5 100.000000   BatchTime 0.128797   LR 0.000010   
2022-11-03 23:43:17,968 - INFO  - Training [78][  120/  391]   Loss 0.080510   Top1 97.187500   Top5 99.993490   BatchTime 0.127973   LR 0.000010   
2022-11-03 23:43:20,451 - INFO  - Training [78][  140/  391]   Loss 0.081474   Top1 97.103795   Top5 99.994420   BatchTime 0.127428   LR 0.000010   
2022-11-03 23:43:22,933 - INFO  - Training [78][  160/  391]   Loss 0.082047   Top1 97.089844   Top5 99.995117   BatchTime 0.127011   LR 0.000010   
2022-11-03 23:43:25,416 - INFO  - Training [78][  180/  391]   Loss 0.081915   Top1 97.100694   Top5 99.995660   BatchTime 0.126694   LR 0.000010   
2022-11-03 23:43:27,875 - INFO  - Training [78][  200/  391]   Loss 0.081670   Top1 97.117188   Top5 99.996094   BatchTime 0.126318   LR 0.000010   
2022-11-03 23:43:30,351 - INFO  - Training [78][  220/  391]   Loss 0.082403   Top1 97.073864   Top5 99.996449   BatchTime 0.126090   LR 0.000010   
2022-11-03 23:43:32,749 - INFO  - Training [78][  240/  391]   Loss 0.082324   Top1 97.067057   Top5 99.996745   BatchTime 0.125572   LR 0.000010   
2022-11-03 23:43:34,335 - INFO  - Training [78][  260/  391]   Loss 0.082505   Top1 97.058293   Top5 99.996995   BatchTime 0.122014   LR 0.000010   
2022-11-03 23:43:36,158 - INFO  - Training [78][  280/  391]   Loss 0.082296   Top1 97.059152   Top5 99.997210   BatchTime 0.119808   LR 0.000010   
2022-11-03 23:43:37,894 - INFO  - Training [78][  300/  391]   Loss 0.083027   Top1 97.033854   Top5 99.994792   BatchTime 0.117608   LR 0.000010   
2022-11-03 23:43:40,069 - INFO  - Training [78][  320/  391]   Loss 0.083022   Top1 97.036133   Top5 99.995117   BatchTime 0.117056   LR 0.000010   
2022-11-03 23:43:42,548 - INFO  - Training [78][  340/  391]   Loss 0.083105   Top1 97.026654   Top5 99.995404   BatchTime 0.117460   LR 0.000010   
2022-11-03 23:43:45,020 - INFO  - Training [78][  360/  391]   Loss 0.083780   Top1 97.024740   Top5 99.993490   BatchTime 0.117800   LR 0.000010   
2022-11-03 23:43:47,489 - INFO  - Training [78][  380/  391]   Loss 0.083481   Top1 97.045641   Top5 99.991776   BatchTime 0.118098   LR 0.000010   
2022-11-03 23:43:49,121 - INFO  - ==> Top1: 97.038    Top5: 99.992    Loss: 0.084

2022-11-03 23:43:49,122 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:43:52,207 - INFO  - Validation [78][   20/   79]   Loss 0.403743   Top1 89.726562   Top5 99.492188   BatchTime 0.154210   
2022-11-03 23:43:53,464 - INFO  - Validation [78][   40/   79]   Loss 0.398660   Top1 89.804688   Top5 99.570312   BatchTime 0.108514   
2022-11-03 23:43:54,749 - INFO  - Validation [78][   60/   79]   Loss 0.393921   Top1 89.973958   Top5 99.583333   BatchTime 0.093758   
2022-11-03 23:43:56,247 - INFO  - ==> Top1: 89.810    Top5: 99.630    Loss: 0.387

2022-11-03 23:43:56,325 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:43:56,326 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:43:56,326 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:43:56,432 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:43:56,432 - INFO  - >>>>>>>> Epoch  79
2022-11-03 23:43:56,433 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:44:00,765 - INFO  - Training [79][   20/  391]   Loss 0.084740   Top1 97.304688   Top5 100.000000   BatchTime 0.216613   LR 0.000010   
2022-11-03 23:44:02,288 - INFO  - Training [79][   40/  391]   Loss 0.087967   Top1 97.089844   Top5 99.980469   BatchTime 0.146377   LR 0.000010   
2022-11-03 23:44:04,136 - INFO  - Training [79][   60/  391]   Loss 0.088797   Top1 97.044271   Top5 99.986979   BatchTime 0.128381   LR 0.000010   
2022-11-03 23:44:05,843 - INFO  - Training [79][   80/  391]   Loss 0.082944   Top1 97.216797   Top5 99.990234   BatchTime 0.117627   LR 0.000010   
2022-11-03 23:44:07,805 - INFO  - Training [79][  100/  391]   Loss 0.083611   Top1 97.117188   Top5 99.992188   BatchTime 0.113717   LR 0.000010   
2022-11-03 23:44:10,294 - INFO  - Training [79][  120/  391]   Loss 0.082677   Top1 97.109375   Top5 99.993490   BatchTime 0.115506   LR 0.000010   
2022-11-03 23:44:12,781 - INFO  - Training [79][  140/  391]   Loss 0.083289   Top1 97.092634   Top5 99.988839   BatchTime 0.116770   LR 0.000010   
2022-11-03 23:44:15,260 - INFO  - Training [79][  160/  391]   Loss 0.082961   Top1 97.114258   Top5 99.990234   BatchTime 0.117668   LR 0.000010   
2022-11-03 23:44:17,743 - INFO  - Training [79][  180/  391]   Loss 0.084604   Top1 97.052951   Top5 99.991319   BatchTime 0.118385   LR 0.000010   
2022-11-03 23:44:20,234 - INFO  - Training [79][  200/  391]   Loss 0.083143   Top1 97.078125   Top5 99.992188   BatchTime 0.119003   LR 0.000010   
2022-11-03 23:44:22,725 - INFO  - Training [79][  220/  391]   Loss 0.084437   Top1 97.020597   Top5 99.992898   BatchTime 0.119508   LR 0.000010   
2022-11-03 23:44:25,192 - INFO  - Training [79][  240/  391]   Loss 0.084933   Top1 96.998698   Top5 99.990234   BatchTime 0.119828   LR 0.000010   
2022-11-03 23:44:27,667 - INFO  - Training [79][  260/  391]   Loss 0.085388   Top1 96.986178   Top5 99.990986   BatchTime 0.120130   LR 0.000010   
2022-11-03 23:44:30,143 - INFO  - Training [79][  280/  391]   Loss 0.085795   Top1 96.969866   Top5 99.991629   BatchTime 0.120390   LR 0.000010   
2022-11-03 23:44:32,283 - INFO  - Training [79][  300/  391]   Loss 0.085831   Top1 96.950521   Top5 99.989583   BatchTime 0.119499   LR 0.000010   
2022-11-03 23:44:33,938 - INFO  - Training [79][  320/  391]   Loss 0.085209   Top1 96.965332   Top5 99.987793   BatchTime 0.117200   LR 0.000010   
2022-11-03 23:44:35,732 - INFO  - Training [79][  340/  391]   Loss 0.085046   Top1 96.973805   Top5 99.988511   BatchTime 0.115583   LR 0.000010   
2022-11-03 23:44:37,232 - INFO  - Training [79][  360/  391]   Loss 0.085462   Top1 96.972656   Top5 99.986979   BatchTime 0.113328   LR 0.000010   
2022-11-03 23:44:39,578 - INFO  - Training [79][  380/  391]   Loss 0.085245   Top1 96.981908   Top5 99.985609   BatchTime 0.113536   LR 0.000010   
2022-11-03 23:44:41,180 - INFO  - ==> Top1: 96.982    Top5: 99.986    Loss: 0.085

2022-11-03 23:44:41,181 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:44:44,256 - INFO  - Validation [79][   20/   79]   Loss 0.415541   Top1 89.414062   Top5 99.531250   BatchTime 0.153645   
2022-11-03 23:44:45,514 - INFO  - Validation [79][   40/   79]   Loss 0.402268   Top1 89.667969   Top5 99.511719   BatchTime 0.108280   
2022-11-03 23:44:46,829 - INFO  - Validation [79][   60/   79]   Loss 0.393444   Top1 89.739583   Top5 99.544271   BatchTime 0.094099   
2022-11-03 23:44:48,310 - INFO  - ==> Top1: 89.610    Top5: 99.610    Loss: 0.385

2022-11-03 23:44:48,344 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.590   Top5: 99.670] Sparsity : 0.854
2022-11-03 23:44:48,345 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.590   Top5: 99.650] Sparsity : 0.852
2022-11-03 23:44:48,345 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.570   Top5: 99.690] Sparsity : 0.852
2022-11-03 23:44:48,459 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_15_epoch80_20221103-224102/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:44:48,459 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 23:44:48,459 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:44:51,540 - INFO  - Validation [   20/   79]   Loss 0.415541   Top1 89.414062   Top5 99.531250   BatchTime 0.153967   
2022-11-03 23:44:52,839 - INFO  - Validation [   40/   79]   Loss 0.402268   Top1 89.667969   Top5 99.511719   BatchTime 0.109472   
2022-11-03 23:44:54,143 - INFO  - Validation [   60/   79]   Loss 0.393444   Top1 89.739583   Top5 99.544271   BatchTime 0.094713   
2022-11-03 23:44:55,619 - INFO  - ==> Top1: 89.610    Top5: 99.610    Loss: 0.385

2022-11-03 23:44:55,714 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_15_epoch80_checkpoint.pth.tar

2022-11-03 23:44:55,715 - INFO  - Program completed successfully ... exiting ...
2022-11-03 23:44:55,715 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
