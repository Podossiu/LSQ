2022-11-03 21:09:03,936 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903.log
2022-11-03 21:09:04,990 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/tb_runs
2022-11-03 21:09:06,109 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (391)
        Validation Set = 10000 (79)
              Test Set = 10000 (79)
2022-11-03 21:09:07,962 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = True
2022-11-03 21:09:10,217 - INFO  - Inserted quantizers into the original model
2022-11-03 21:09:10,267 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 21:09:10,272 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 21:09:10,272 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 21:09:10,272 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:09:13,962 - INFO  - Validation [   20/   79]   Loss 2.545371   Top1 10.429688   Top5 49.101562   BatchTime 0.184410   
2022-11-03 21:09:14,642 - INFO  - Validation [   40/   79]   Loss 2.549466   Top1 10.175781   Top5 49.941406   BatchTime 0.109209   
2022-11-03 21:09:15,339 - INFO  - Validation [   60/   79]   Loss 2.541519   Top1 10.117188   Top5 50.377604   BatchTime 0.084416   
2022-11-03 21:09:16,052 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.546

2022-11-03 21:09:16,102 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 21:09:16,102 - INFO  - >>>>>>>> Epoch   0
2022-11-03 21:09:16,103 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:09:20,529 - INFO  - Training [0][   20/  391]   Loss 1.657686   Top1 68.007812   Top5 96.523438   BatchTime 0.221308   LR 0.010000   
2022-11-03 21:09:22,540 - INFO  - Training [0][   40/  391]   Loss 1.388809   Top1 69.082031   Top5 96.738281   BatchTime 0.160942   LR 0.010000   
2022-11-03 21:09:24,576 - INFO  - Training [0][   60/  391]   Loss 1.193106   Top1 70.898438   Top5 97.252604   BatchTime 0.141221   LR 0.010000   
2022-11-03 21:09:26,577 - INFO  - Training [0][   80/  391]   Loss 1.062129   Top1 72.519531   Top5 97.666016   BatchTime 0.130930   LR 0.010000   
2022-11-03 21:09:28,607 - INFO  - Training [0][  100/  391]   Loss 0.962900   Top1 74.007812   Top5 97.859375   BatchTime 0.125042   LR 0.010000   
2022-11-03 21:09:30,619 - INFO  - Training [0][  120/  391]   Loss 0.888068   Top1 75.299479   Top5 98.144531   BatchTime 0.120967   LR 0.010000   
2022-11-03 21:09:32,627 - INFO  - Training [0][  140/  391]   Loss 0.831881   Top1 76.294643   Top5 98.331473   BatchTime 0.118028   LR 0.010000   
2022-11-03 21:09:34,661 - INFO  - Training [0][  160/  391]   Loss 0.785371   Top1 77.124023   Top5 98.471680   BatchTime 0.115989   LR 0.010000   
2022-11-03 21:09:36,684 - INFO  - Training [0][  180/  391]   Loss 0.746292   Top1 78.038194   Top5 98.576389   BatchTime 0.114339   LR 0.010000   
2022-11-03 21:09:38,715 - INFO  - Training [0][  200/  391]   Loss 0.717965   Top1 78.628906   Top5 98.664062   BatchTime 0.113057   LR 0.010000   
2022-11-03 21:09:40,734 - INFO  - Training [0][  220/  391]   Loss 0.691885   Top1 79.225852   Top5 98.735795   BatchTime 0.111959   LR 0.010000   
2022-11-03 21:09:42,745 - INFO  - Training [0][  240/  391]   Loss 0.670878   Top1 79.645182   Top5 98.798828   BatchTime 0.111005   LR 0.010000   
2022-11-03 21:09:44,785 - INFO  - Training [0][  260/  391]   Loss 0.647838   Top1 80.210337   Top5 98.873197   BatchTime 0.110314   LR 0.010000   
2022-11-03 21:09:46,794 - INFO  - Training [0][  280/  391]   Loss 0.630346   Top1 80.613839   Top5 98.914621   BatchTime 0.109610   LR 0.010000   
2022-11-03 21:09:48,802 - INFO  - Training [0][  300/  391]   Loss 0.614869   Top1 80.971354   Top5 98.955729   BatchTime 0.108995   LR 0.010000   
2022-11-03 21:09:50,809 - INFO  - Training [0][  320/  391]   Loss 0.599837   Top1 81.325684   Top5 98.996582   BatchTime 0.108455   LR 0.010000   
2022-11-03 21:09:52,778 - INFO  - Training [0][  340/  391]   Loss 0.585682   Top1 81.652114   Top5 99.039522   BatchTime 0.107866   LR 0.010000   
2022-11-03 21:09:54,731 - INFO  - Training [0][  360/  391]   Loss 0.572151   Top1 81.987847   Top5 99.084201   BatchTime 0.107297   LR 0.010000   
2022-11-03 21:09:56,819 - INFO  - Training [0][  380/  391]   Loss 0.561099   Top1 82.284128   Top5 99.120066   BatchTime 0.107147   LR 0.010000   
2022-11-03 21:09:58,097 - INFO  - ==> Top1: 82.450    Top5: 99.134    Loss: 0.555

2022-11-03 21:09:58,098 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:10:00,709 - INFO  - Validation [0][   20/   79]   Loss 0.453076   Top1 85.117188   Top5 99.296875   BatchTime 0.130437   
2022-11-03 21:10:01,276 - INFO  - Validation [0][   40/   79]   Loss 0.460756   Top1 84.843750   Top5 99.199219   BatchTime 0.079408   
2022-11-03 21:10:01,814 - INFO  - Validation [0][   60/   79]   Loss 0.457401   Top1 84.778646   Top5 99.231771   BatchTime 0.061900   
2022-11-03 21:10:02,580 - INFO  - ==> Top1: 84.760    Top5: 99.270    Loss: 0.454

2022-11-03 21:10:02,606 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.760   Top5: 99.270] Sparsity : 0.541
2022-11-03 21:10:02,607 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 21:10:02,734 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:10:02,734 - INFO  - >>>>>>>> Epoch   1
2022-11-03 21:10:02,737 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:10:06,717 - INFO  - Training [1][   20/  391]   Loss 0.326480   Top1 89.101562   Top5 99.570312   BatchTime 0.198975   LR 0.010000   
2022-11-03 21:10:08,733 - INFO  - Training [1][   40/  391]   Loss 0.306838   Top1 89.316406   Top5 99.589844   BatchTime 0.149893   LR 0.010000   
2022-11-03 21:10:10,735 - INFO  - Training [1][   60/  391]   Loss 0.306060   Top1 89.492188   Top5 99.713542   BatchTime 0.133302   LR 0.010000   
2022-11-03 21:10:12,742 - INFO  - Training [1][   80/  391]   Loss 0.305363   Top1 89.560547   Top5 99.707031   BatchTime 0.125056   LR 0.010000   
2022-11-03 21:10:14,754 - INFO  - Training [1][  100/  391]   Loss 0.302778   Top1 89.437500   Top5 99.750000   BatchTime 0.120165   LR 0.010000   
2022-11-03 21:10:16,740 - INFO  - Training [1][  120/  391]   Loss 0.300678   Top1 89.394531   Top5 99.739583   BatchTime 0.116688   LR 0.010000   
2022-11-03 21:10:18,762 - INFO  - Training [1][  140/  391]   Loss 0.297706   Top1 89.481027   Top5 99.765625   BatchTime 0.114459   LR 0.010000   
2022-11-03 21:10:20,772 - INFO  - Training [1][  160/  391]   Loss 0.296524   Top1 89.541016   Top5 99.765625   BatchTime 0.112716   LR 0.010000   
2022-11-03 21:10:22,816 - INFO  - Training [1][  180/  391]   Loss 0.294960   Top1 89.635417   Top5 99.774306   BatchTime 0.111545   LR 0.010000   
2022-11-03 21:10:24,833 - INFO  - Training [1][  200/  391]   Loss 0.294386   Top1 89.621094   Top5 99.781250   BatchTime 0.110476   LR 0.010000   
2022-11-03 21:10:26,828 - INFO  - Training [1][  220/  391]   Loss 0.295132   Top1 89.616477   Top5 99.762074   BatchTime 0.109500   LR 0.010000   
2022-11-03 21:10:28,832 - INFO  - Training [1][  240/  391]   Loss 0.294087   Top1 89.606120   Top5 99.768880   BatchTime 0.108724   LR 0.010000   
2022-11-03 21:10:30,841 - INFO  - Training [1][  260/  391]   Loss 0.293607   Top1 89.636418   Top5 99.771635   BatchTime 0.108091   LR 0.010000   
2022-11-03 21:10:32,833 - INFO  - Training [1][  280/  391]   Loss 0.290147   Top1 89.723772   Top5 99.779576   BatchTime 0.107482   LR 0.010000   
2022-11-03 21:10:34,823 - INFO  - Training [1][  300/  391]   Loss 0.287592   Top1 89.833333   Top5 99.781250   BatchTime 0.106950   LR 0.010000   
2022-11-03 21:10:36,815 - INFO  - Training [1][  320/  391]   Loss 0.285000   Top1 89.914551   Top5 99.780273   BatchTime 0.106492   LR 0.010000   
2022-11-03 21:10:38,803 - INFO  - Training [1][  340/  391]   Loss 0.282628   Top1 90.011489   Top5 99.784007   BatchTime 0.106072   LR 0.010000   
2022-11-03 21:10:40,743 - INFO  - Training [1][  360/  391]   Loss 0.280749   Top1 90.093316   Top5 99.787326   BatchTime 0.105568   LR 0.010000   
2022-11-03 21:10:42,545 - INFO  - Training [1][  380/  391]   Loss 0.278728   Top1 90.185033   Top5 99.786184   BatchTime 0.104754   LR 0.010000   
2022-11-03 21:10:43,605 - INFO  - ==> Top1: 90.246    Top5: 99.788    Loss: 0.277

2022-11-03 21:10:43,606 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:10:46,213 - INFO  - Validation [1][   20/   79]   Loss 0.406286   Top1 86.992188   Top5 99.531250   BatchTime 0.130133   
2022-11-03 21:10:46,764 - INFO  - Validation [1][   40/   79]   Loss 0.415960   Top1 86.894531   Top5 99.375000   BatchTime 0.078842   
2022-11-03 21:10:47,282 - INFO  - Validation [1][   60/   79]   Loss 0.411000   Top1 87.135417   Top5 99.427083   BatchTime 0.061192   
2022-11-03 21:10:48,032 - INFO  - ==> Top1: 86.980    Top5: 99.470    Loss: 0.410

2022-11-03 21:10:48,055 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.980   Top5: 99.470] Sparsity : 0.586
2022-11-03 21:10:48,055 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.760   Top5: 99.270] Sparsity : 0.541
2022-11-03 21:10:48,055 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 21:10:48,274 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:10:48,274 - INFO  - >>>>>>>> Epoch   2
2022-11-03 21:10:48,276 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:10:52,173 - INFO  - Training [2][   20/  391]   Loss 0.203860   Top1 93.203125   Top5 99.882812   BatchTime 0.194839   LR 0.010000   
2022-11-03 21:10:54,192 - INFO  - Training [2][   40/  391]   Loss 0.213254   Top1 92.832031   Top5 99.882812   BatchTime 0.147891   LR 0.010000   
2022-11-03 21:10:56,211 - INFO  - Training [2][   60/  391]   Loss 0.214575   Top1 92.565104   Top5 99.869792   BatchTime 0.132238   LR 0.010000   
2022-11-03 21:10:58,231 - INFO  - Training [2][   80/  391]   Loss 0.210873   Top1 92.705078   Top5 99.863281   BatchTime 0.124438   LR 0.010000   
2022-11-03 21:11:00,254 - INFO  - Training [2][  100/  391]   Loss 0.208155   Top1 92.820312   Top5 99.851562   BatchTime 0.119775   LR 0.010000   
2022-11-03 21:11:02,284 - INFO  - Training [2][  120/  391]   Loss 0.210079   Top1 92.656250   Top5 99.869792   BatchTime 0.116728   LR 0.010000   
2022-11-03 21:11:04,317 - INFO  - Training [2][  140/  391]   Loss 0.210864   Top1 92.639509   Top5 99.860491   BatchTime 0.114575   LR 0.010000   
2022-11-03 21:11:06,335 - INFO  - Training [2][  160/  391]   Loss 0.211396   Top1 92.626953   Top5 99.873047   BatchTime 0.112866   LR 0.010000   
2022-11-03 21:11:08,345 - INFO  - Training [2][  180/  391]   Loss 0.212109   Top1 92.586806   Top5 99.869792   BatchTime 0.111489   LR 0.010000   
2022-11-03 21:11:10,347 - INFO  - Training [2][  200/  391]   Loss 0.210984   Top1 92.636719   Top5 99.875000   BatchTime 0.110351   LR 0.010000   
2022-11-03 21:11:12,358 - INFO  - Training [2][  220/  391]   Loss 0.211483   Top1 92.517756   Top5 99.875710   BatchTime 0.109462   LR 0.010000   
2022-11-03 21:11:14,358 - INFO  - Training [2][  240/  391]   Loss 0.210711   Top1 92.519531   Top5 99.882812   BatchTime 0.108673   LR 0.010000   
2022-11-03 21:11:16,396 - INFO  - Training [2][  260/  391]   Loss 0.210357   Top1 92.560096   Top5 99.885817   BatchTime 0.108151   LR 0.010000   
2022-11-03 21:11:18,413 - INFO  - Training [2][  280/  391]   Loss 0.209477   Top1 92.580915   Top5 99.888393   BatchTime 0.107628   LR 0.010000   
2022-11-03 21:11:20,449 - INFO  - Training [2][  300/  391]   Loss 0.208240   Top1 92.632812   Top5 99.890625   BatchTime 0.107239   LR 0.010000   
2022-11-03 21:11:22,459 - INFO  - Training [2][  320/  391]   Loss 0.206792   Top1 92.685547   Top5 99.890137   BatchTime 0.106819   LR 0.010000   
2022-11-03 21:11:24,431 - INFO  - Training [2][  340/  391]   Loss 0.206025   Top1 92.748162   Top5 99.887408   BatchTime 0.106336   LR 0.010000   
2022-11-03 21:11:26,400 - INFO  - Training [2][  360/  391]   Loss 0.204607   Top1 92.829861   Top5 99.884983   BatchTime 0.105898   LR 0.010000   
2022-11-03 21:11:28,195 - INFO  - Training [2][  380/  391]   Loss 0.203803   Top1 92.833059   Top5 99.888980   BatchTime 0.105046   LR 0.010000   
2022-11-03 21:11:29,278 - INFO  - ==> Top1: 92.856    Top5: 99.892    Loss: 0.203

2022-11-03 21:11:29,279 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:11:32,202 - INFO  - Validation [2][   20/   79]   Loss 0.392760   Top1 87.460938   Top5 99.375000   BatchTime 0.145883   
2022-11-03 21:11:32,723 - INFO  - Validation [2][   40/   79]   Loss 0.393974   Top1 87.558594   Top5 99.453125   BatchTime 0.085961   
2022-11-03 21:11:33,242 - INFO  - Validation [2][   60/   79]   Loss 0.386415   Top1 87.903646   Top5 99.492188   BatchTime 0.065968   
2022-11-03 21:11:34,067 - INFO  - ==> Top1: 87.960    Top5: 99.550    Loss: 0.385

2022-11-03 21:11:34,103 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.960   Top5: 99.550] Sparsity : 0.596
2022-11-03 21:11:34,140 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.980   Top5: 99.470] Sparsity : 0.586
2022-11-03 21:11:34,140 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 84.760   Top5: 99.270] Sparsity : 0.541
2022-11-03 21:11:34,407 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:11:34,407 - INFO  - >>>>>>>> Epoch   3
2022-11-03 21:11:34,408 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:11:38,297 - INFO  - Training [3][   20/  391]   Loss 0.154274   Top1 94.531250   Top5 99.960938   BatchTime 0.194449   LR 0.010000   
2022-11-03 21:11:40,304 - INFO  - Training [3][   40/  391]   Loss 0.152196   Top1 94.667969   Top5 99.960938   BatchTime 0.147381   LR 0.010000   
2022-11-03 21:11:42,333 - INFO  - Training [3][   60/  391]   Loss 0.155208   Top1 94.596354   Top5 99.973958   BatchTime 0.132074   LR 0.010000   
2022-11-03 21:11:44,357 - INFO  - Training [3][   80/  391]   Loss 0.152790   Top1 94.726562   Top5 99.980469   BatchTime 0.124354   LR 0.010000   
2022-11-03 21:11:46,388 - INFO  - Training [3][  100/  391]   Loss 0.155400   Top1 94.593750   Top5 99.976562   BatchTime 0.119794   LR 0.010000   
2022-11-03 21:11:48,394 - INFO  - Training [3][  120/  391]   Loss 0.156381   Top1 94.576823   Top5 99.980469   BatchTime 0.116543   LR 0.010000   
2022-11-03 21:11:50,403 - INFO  - Training [3][  140/  391]   Loss 0.157317   Top1 94.525670   Top5 99.972098   BatchTime 0.114242   LR 0.010000   
2022-11-03 21:11:52,407 - INFO  - Training [3][  160/  391]   Loss 0.158995   Top1 94.458008   Top5 99.970703   BatchTime 0.112489   LR 0.010000   
2022-11-03 21:11:54,359 - INFO  - Training [3][  180/  391]   Loss 0.159601   Top1 94.431424   Top5 99.969618   BatchTime 0.110833   LR 0.010000   
2022-11-03 21:11:56,376 - INFO  - Training [3][  200/  391]   Loss 0.159735   Top1 94.406250   Top5 99.964844   BatchTime 0.109833   LR 0.010000   
2022-11-03 21:11:58,387 - INFO  - Training [3][  220/  391]   Loss 0.161035   Top1 94.353693   Top5 99.964489   BatchTime 0.108990   LR 0.010000   
2022-11-03 21:12:00,384 - INFO  - Training [3][  240/  391]   Loss 0.161338   Top1 94.345703   Top5 99.964193   BatchTime 0.108228   LR 0.010000   
2022-11-03 21:12:02,380 - INFO  - Training [3][  260/  391]   Loss 0.162678   Top1 94.311899   Top5 99.957933   BatchTime 0.107581   LR 0.010000   
2022-11-03 21:12:04,377 - INFO  - Training [3][  280/  391]   Loss 0.164157   Top1 94.268973   Top5 99.955357   BatchTime 0.107030   LR 0.010000   
2022-11-03 21:12:06,374 - INFO  - Training [3][  300/  391]   Loss 0.163585   Top1 94.278646   Top5 99.958333   BatchTime 0.106549   LR 0.010000   
2022-11-03 21:12:08,357 - INFO  - Training [3][  320/  391]   Loss 0.163496   Top1 94.270020   Top5 99.958496   BatchTime 0.106087   LR 0.010000   
2022-11-03 21:12:10,325 - INFO  - Training [3][  340/  391]   Loss 0.163414   Top1 94.276195   Top5 99.960938   BatchTime 0.105635   LR 0.010000   
2022-11-03 21:12:12,275 - INFO  - Training [3][  360/  391]   Loss 0.164133   Top1 94.266493   Top5 99.958767   BatchTime 0.105182   LR 0.010000   
2022-11-03 21:12:13,999 - INFO  - Training [3][  380/  391]   Loss 0.162962   Top1 94.313322   Top5 99.954770   BatchTime 0.104184   LR 0.010000   
2022-11-03 21:12:15,114 - INFO  - ==> Top1: 94.304    Top5: 99.954    Loss: 0.163

2022-11-03 21:12:15,116 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:12:17,696 - INFO  - Validation [3][   20/   79]   Loss 0.401909   Top1 87.851562   Top5 99.609375   BatchTime 0.128935   
2022-11-03 21:12:18,234 - INFO  - Validation [3][   40/   79]   Loss 0.403725   Top1 87.988281   Top5 99.433594   BatchTime 0.077914   
2022-11-03 21:12:18,761 - INFO  - Validation [3][   60/   79]   Loss 0.391086   Top1 88.411458   Top5 99.440104   BatchTime 0.060719   
2022-11-03 21:12:19,520 - INFO  - ==> Top1: 88.420    Top5: 99.490    Loss: 0.389

2022-11-03 21:12:19,544 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 88.420   Top5: 99.490] Sparsity : 0.622
2022-11-03 21:12:19,545 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.960   Top5: 99.550] Sparsity : 0.596
2022-11-03 21:12:19,545 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.980   Top5: 99.470] Sparsity : 0.586
2022-11-03 21:12:19,747 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:12:19,747 - INFO  - >>>>>>>> Epoch   4
2022-11-03 21:12:19,750 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:12:23,741 - INFO  - Training [4][   20/  391]   Loss 0.152084   Top1 94.570312   Top5 100.000000   BatchTime 0.199531   LR 0.010000   
2022-11-03 21:12:25,758 - INFO  - Training [4][   40/  391]   Loss 0.153661   Top1 94.453125   Top5 100.000000   BatchTime 0.150198   LR 0.010000   
2022-11-03 21:12:27,782 - INFO  - Training [4][   60/  391]   Loss 0.148386   Top1 94.726562   Top5 100.000000   BatchTime 0.133857   LR 0.010000   
2022-11-03 21:12:29,798 - INFO  - Training [4][   80/  391]   Loss 0.143358   Top1 94.882812   Top5 100.000000   BatchTime 0.125593   LR 0.010000   
2022-11-03 21:12:31,798 - INFO  - Training [4][  100/  391]   Loss 0.146192   Top1 94.820312   Top5 99.984375   BatchTime 0.120476   LR 0.010000   
2022-11-03 21:12:33,817 - INFO  - Training [4][  120/  391]   Loss 0.145286   Top1 94.876302   Top5 99.986979   BatchTime 0.117220   LR 0.010000   
2022-11-03 21:12:35,852 - INFO  - Training [4][  140/  391]   Loss 0.146991   Top1 94.776786   Top5 99.988839   BatchTime 0.115013   LR 0.010000   
2022-11-03 21:12:37,878 - INFO  - Training [4][  160/  391]   Loss 0.145216   Top1 94.848633   Top5 99.980469   BatchTime 0.113296   LR 0.010000   
2022-11-03 21:12:39,909 - INFO  - Training [4][  180/  391]   Loss 0.146392   Top1 94.791667   Top5 99.978299   BatchTime 0.111991   LR 0.010000   
2022-11-03 21:12:41,924 - INFO  - Training [4][  200/  391]   Loss 0.147030   Top1 94.789062   Top5 99.976562   BatchTime 0.110869   LR 0.010000   
2022-11-03 21:12:43,945 - INFO  - Training [4][  220/  391]   Loss 0.146803   Top1 94.808239   Top5 99.975142   BatchTime 0.109976   LR 0.010000   
2022-11-03 21:12:45,941 - INFO  - Training [4][  240/  391]   Loss 0.145815   Top1 94.833984   Top5 99.977214   BatchTime 0.109127   LR 0.010000   
2022-11-03 21:12:47,961 - INFO  - Training [4][  260/  391]   Loss 0.145971   Top1 94.843750   Top5 99.969952   BatchTime 0.108501   LR 0.010000   
2022-11-03 21:12:49,964 - INFO  - Training [4][  280/  391]   Loss 0.145840   Top1 94.852121   Top5 99.972098   BatchTime 0.107906   LR 0.010000   
2022-11-03 21:12:51,957 - INFO  - Training [4][  300/  391]   Loss 0.144528   Top1 94.906250   Top5 99.973958   BatchTime 0.107353   LR 0.010000   
2022-11-03 21:12:53,962 - INFO  - Training [4][  320/  391]   Loss 0.143368   Top1 94.938965   Top5 99.975586   BatchTime 0.106912   LR 0.010000   
2022-11-03 21:12:55,935 - INFO  - Training [4][  340/  391]   Loss 0.142129   Top1 94.972426   Top5 99.974724   BatchTime 0.106423   LR 0.010000   
2022-11-03 21:12:57,883 - INFO  - Training [4][  360/  391]   Loss 0.141735   Top1 94.960938   Top5 99.976128   BatchTime 0.105923   LR 0.010000   
2022-11-03 21:12:59,628 - INFO  - Training [4][  380/  391]   Loss 0.141708   Top1 94.952714   Top5 99.975329   BatchTime 0.104941   LR 0.010000   
2022-11-03 21:13:00,792 - INFO  - ==> Top1: 94.958    Top5: 99.976    Loss: 0.142

2022-11-03 21:13:00,793 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:13:03,348 - INFO  - Validation [4][   20/   79]   Loss 0.374780   Top1 88.398438   Top5 99.492188   BatchTime 0.127710   
2022-11-03 21:13:03,872 - INFO  - Validation [4][   40/   79]   Loss 0.386275   Top1 88.574219   Top5 99.453125   BatchTime 0.076953   
2022-11-03 21:13:04,392 - INFO  - Validation [4][   60/   79]   Loss 0.372615   Top1 88.854167   Top5 99.505208   BatchTime 0.059979   
2022-11-03 21:13:05,167 - INFO  - ==> Top1: 88.870    Top5: 99.580    Loss: 0.373

2022-11-03 21:13:05,207 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.870   Top5: 99.580] Sparsity : 0.663
2022-11-03 21:13:05,208 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 88.420   Top5: 99.490] Sparsity : 0.622
2022-11-03 21:13:05,208 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.960   Top5: 99.550] Sparsity : 0.596
2022-11-03 21:13:05,395 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:13:05,395 - INFO  - >>>>>>>> Epoch   5
2022-11-03 21:13:05,397 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:13:09,464 - INFO  - Training [5][   20/  391]   Loss 0.122914   Top1 95.859375   Top5 100.000000   BatchTime 0.203336   LR 0.010000   
2022-11-03 21:13:11,504 - INFO  - Training [5][   40/  391]   Loss 0.119514   Top1 96.074219   Top5 100.000000   BatchTime 0.152676   LR 0.010000   
2022-11-03 21:13:13,526 - INFO  - Training [5][   60/  391]   Loss 0.124517   Top1 95.729167   Top5 99.986979   BatchTime 0.135491   LR 0.010000   
2022-11-03 21:13:15,559 - INFO  - Training [5][   80/  391]   Loss 0.124096   Top1 95.703125   Top5 99.990234   BatchTime 0.127027   LR 0.010000   
2022-11-03 21:13:17,594 - INFO  - Training [5][  100/  391]   Loss 0.124761   Top1 95.804688   Top5 99.960938   BatchTime 0.121965   LR 0.010000   
2022-11-03 21:13:19,608 - INFO  - Training [5][  120/  391]   Loss 0.127032   Top1 95.664062   Top5 99.967448   BatchTime 0.118427   LR 0.010000   
2022-11-03 21:13:21,624 - INFO  - Training [5][  140/  391]   Loss 0.127947   Top1 95.591518   Top5 99.972098   BatchTime 0.115907   LR 0.010000   
2022-11-03 21:13:23,652 - INFO  - Training [5][  160/  391]   Loss 0.129796   Top1 95.522461   Top5 99.965820   BatchTime 0.114091   LR 0.010000   
2022-11-03 21:13:25,661 - INFO  - Training [5][  180/  391]   Loss 0.130784   Top1 95.490451   Top5 99.960938   BatchTime 0.112577   LR 0.010000   
2022-11-03 21:13:27,658 - INFO  - Training [5][  200/  391]   Loss 0.131145   Top1 95.500000   Top5 99.960938   BatchTime 0.111303   LR 0.010000   
2022-11-03 21:13:29,660 - INFO  - Training [5][  220/  391]   Loss 0.132860   Top1 95.440341   Top5 99.957386   BatchTime 0.110285   LR 0.010000   
2022-11-03 21:13:31,662 - INFO  - Training [5][  240/  391]   Loss 0.132510   Top1 95.488281   Top5 99.954427   BatchTime 0.109438   LR 0.010000   
2022-11-03 21:13:33,658 - INFO  - Training [5][  260/  391]   Loss 0.132930   Top1 95.450721   Top5 99.957933   BatchTime 0.108694   LR 0.010000   
2022-11-03 21:13:35,667 - INFO  - Training [5][  280/  391]   Loss 0.132961   Top1 95.429688   Top5 99.952567   BatchTime 0.108104   LR 0.010000   
2022-11-03 21:13:37,676 - INFO  - Training [5][  300/  391]   Loss 0.133534   Top1 95.388021   Top5 99.950521   BatchTime 0.107593   LR 0.010000   
2022-11-03 21:13:39,648 - INFO  - Training [5][  320/  391]   Loss 0.134101   Top1 95.363770   Top5 99.946289   BatchTime 0.107033   LR 0.010000   
2022-11-03 21:13:41,607 - INFO  - Training [5][  340/  391]   Loss 0.135287   Top1 95.326287   Top5 99.937960   BatchTime 0.106500   LR 0.010000   
2022-11-03 21:13:43,565 - INFO  - Training [5][  360/  391]   Loss 0.135363   Top1 95.310330   Top5 99.934896   BatchTime 0.106022   LR 0.010000   
2022-11-03 21:13:45,305 - INFO  - Training [5][  380/  391]   Loss 0.135831   Top1 95.285773   Top5 99.936266   BatchTime 0.105019   LR 0.010000   
2022-11-03 21:13:46,470 - INFO  - ==> Top1: 95.250    Top5: 99.936    Loss: 0.137

2022-11-03 21:13:46,471 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:13:49,004 - INFO  - Validation [5][   20/   79]   Loss 0.389343   Top1 89.023438   Top5 99.531250   BatchTime 0.126610   
2022-11-03 21:13:49,539 - INFO  - Validation [5][   40/   79]   Loss 0.393205   Top1 88.847656   Top5 99.511719   BatchTime 0.076670   
2022-11-03 21:13:50,067 - INFO  - Validation [5][   60/   79]   Loss 0.382686   Top1 89.023438   Top5 99.544271   BatchTime 0.059911   
2022-11-03 21:13:51,011 - INFO  - ==> Top1: 88.850    Top5: 99.590    Loss: 0.382

2022-11-03 21:13:51,043 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.870   Top5: 99.580] Sparsity : 0.663
2022-11-03 21:13:51,044 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.850   Top5: 99.590] Sparsity : 0.697
2022-11-03 21:13:51,044 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 88.420   Top5: 99.490] Sparsity : 0.622
2022-11-03 21:13:51,151 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:13:51,152 - INFO  - >>>>>>>> Epoch   6
2022-11-03 21:13:51,153 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:13:55,094 - INFO  - Training [6][   20/  391]   Loss 0.141138   Top1 95.195312   Top5 99.882812   BatchTime 0.197020   LR 0.010000   
2022-11-03 21:13:57,166 - INFO  - Training [6][   40/  391]   Loss 0.133950   Top1 95.214844   Top5 99.921875   BatchTime 0.150310   LR 0.010000   
2022-11-03 21:13:59,194 - INFO  - Training [6][   60/  391]   Loss 0.131423   Top1 95.312500   Top5 99.934896   BatchTime 0.134008   LR 0.010000   
2022-11-03 21:14:01,199 - INFO  - Training [6][   80/  391]   Loss 0.129609   Top1 95.332031   Top5 99.941406   BatchTime 0.125570   LR 0.010000   
2022-11-03 21:14:03,215 - INFO  - Training [6][  100/  391]   Loss 0.131260   Top1 95.304688   Top5 99.945312   BatchTime 0.120615   LR 0.010000   
2022-11-03 21:14:05,262 - INFO  - Training [6][  120/  391]   Loss 0.132892   Top1 95.273438   Top5 99.947917   BatchTime 0.117572   LR 0.010000   
2022-11-03 21:14:07,265 - INFO  - Training [6][  140/  391]   Loss 0.132918   Top1 95.351562   Top5 99.955357   BatchTime 0.115080   LR 0.010000   
2022-11-03 21:14:09,293 - INFO  - Training [6][  160/  391]   Loss 0.129282   Top1 95.478516   Top5 99.960938   BatchTime 0.113372   LR 0.010000   
2022-11-03 21:14:11,317 - INFO  - Training [6][  180/  391]   Loss 0.129553   Top1 95.486111   Top5 99.956597   BatchTime 0.112018   LR 0.010000   
2022-11-03 21:14:13,335 - INFO  - Training [6][  200/  391]   Loss 0.129653   Top1 95.507812   Top5 99.957031   BatchTime 0.110904   LR 0.010000   
2022-11-03 21:14:15,481 - INFO  - Training [6][  220/  391]   Loss 0.129933   Top1 95.472301   Top5 99.957386   BatchTime 0.110577   LR 0.010000   
2022-11-03 21:14:17,513 - INFO  - Training [6][  240/  391]   Loss 0.129982   Top1 95.462240   Top5 99.957682   BatchTime 0.109829   LR 0.010000   
2022-11-03 21:14:19,511 - INFO  - Training [6][  260/  391]   Loss 0.129243   Top1 95.507812   Top5 99.957933   BatchTime 0.109065   LR 0.010000   
2022-11-03 21:14:21,522 - INFO  - Training [6][  280/  391]   Loss 0.128114   Top1 95.552455   Top5 99.960938   BatchTime 0.108456   LR 0.010000   
2022-11-03 21:14:23,531 - INFO  - Training [6][  300/  391]   Loss 0.128662   Top1 95.572917   Top5 99.963542   BatchTime 0.107925   LR 0.010000   
2022-11-03 21:14:25,519 - INFO  - Training [6][  320/  391]   Loss 0.128420   Top1 95.585938   Top5 99.965820   BatchTime 0.107389   LR 0.010000   
2022-11-03 21:14:27,488 - INFO  - Training [6][  340/  391]   Loss 0.128507   Top1 95.585938   Top5 99.965533   BatchTime 0.106864   LR 0.010000   
2022-11-03 21:14:29,460 - INFO  - Training [6][  360/  391]   Loss 0.127963   Top1 95.629340   Top5 99.967448   BatchTime 0.106405   LR 0.010000   
2022-11-03 21:14:31,042 - INFO  - Training [6][  380/  391]   Loss 0.127884   Top1 95.614720   Top5 99.962993   BatchTime 0.104969   LR 0.010000   
2022-11-03 21:14:32,264 - INFO  - ==> Top1: 95.606    Top5: 99.962    Loss: 0.128

2022-11-03 21:14:32,265 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:14:34,814 - INFO  - Validation [6][   20/   79]   Loss 0.380793   Top1 88.906250   Top5 99.531250   BatchTime 0.127375   
2022-11-03 21:14:35,339 - INFO  - Validation [6][   40/   79]   Loss 0.397136   Top1 88.964844   Top5 99.472656   BatchTime 0.076808   
2022-11-03 21:14:35,893 - INFO  - Validation [6][   60/   79]   Loss 0.387967   Top1 88.971354   Top5 99.505208   BatchTime 0.060433   
2022-11-03 21:14:36,998 - INFO  - ==> Top1: 88.910    Top5: 99.560    Loss: 0.385

2022-11-03 21:14:37,049 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 88.910   Top5: 99.560] Sparsity : 0.703
2022-11-03 21:14:37,049 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.870   Top5: 99.580] Sparsity : 0.663
2022-11-03 21:14:37,049 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.850   Top5: 99.590] Sparsity : 0.697
2022-11-03 21:14:37,228 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:14:37,228 - INFO  - >>>>>>>> Epoch   7
2022-11-03 21:14:37,229 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:14:41,156 - INFO  - Training [7][   20/  391]   Loss 0.112433   Top1 96.132812   Top5 100.000000   BatchTime 0.196335   LR 0.010000   
2022-11-03 21:14:43,196 - INFO  - Training [7][   40/  391]   Loss 0.117170   Top1 95.917969   Top5 100.000000   BatchTime 0.149163   LR 0.010000   
2022-11-03 21:14:45,338 - INFO  - Training [7][   60/  391]   Loss 0.120448   Top1 95.820312   Top5 99.986979   BatchTime 0.135139   LR 0.010000   
2022-11-03 21:14:47,347 - INFO  - Training [7][   80/  391]   Loss 0.120392   Top1 95.742188   Top5 99.990234   BatchTime 0.126471   LR 0.010000   
2022-11-03 21:14:49,383 - INFO  - Training [7][  100/  391]   Loss 0.120177   Top1 95.796875   Top5 99.992188   BatchTime 0.121531   LR 0.010000   
2022-11-03 21:14:51,433 - INFO  - Training [7][  120/  391]   Loss 0.118707   Top1 95.872396   Top5 99.993490   BatchTime 0.118358   LR 0.010000   
2022-11-03 21:14:53,437 - INFO  - Training [7][  140/  391]   Loss 0.119939   Top1 95.814732   Top5 99.994420   BatchTime 0.115765   LR 0.010000   
2022-11-03 21:14:55,442 - INFO  - Training [7][  160/  391]   Loss 0.117673   Top1 95.908203   Top5 99.990234   BatchTime 0.113824   LR 0.010000   
2022-11-03 21:14:57,438 - INFO  - Training [7][  180/  391]   Loss 0.117805   Top1 95.907118   Top5 99.991319   BatchTime 0.112268   LR 0.010000   
2022-11-03 21:14:59,451 - INFO  - Training [7][  200/  391]   Loss 0.118652   Top1 95.871094   Top5 99.984375   BatchTime 0.111104   LR 0.010000   
2022-11-03 21:15:01,439 - INFO  - Training [7][  220/  391]   Loss 0.118288   Top1 95.877131   Top5 99.985795   BatchTime 0.110039   LR 0.010000   
2022-11-03 21:15:03,453 - INFO  - Training [7][  240/  391]   Loss 0.118747   Top1 95.836589   Top5 99.986979   BatchTime 0.109262   LR 0.010000   
2022-11-03 21:15:05,459 - INFO  - Training [7][  260/  391]   Loss 0.119100   Top1 95.826322   Top5 99.984976   BatchTime 0.108574   LR 0.010000   
2022-11-03 21:15:07,476 - INFO  - Training [7][  280/  391]   Loss 0.119368   Top1 95.786830   Top5 99.986049   BatchTime 0.108022   LR 0.010000   
2022-11-03 21:15:09,454 - INFO  - Training [7][  300/  391]   Loss 0.120077   Top1 95.752604   Top5 99.979167   BatchTime 0.107414   LR 0.010000   
2022-11-03 21:15:11,430 - INFO  - Training [7][  320/  391]   Loss 0.120378   Top1 95.761719   Top5 99.980469   BatchTime 0.106873   LR 0.010000   
2022-11-03 21:15:13,416 - INFO  - Training [7][  340/  391]   Loss 0.120711   Top1 95.721507   Top5 99.981618   BatchTime 0.106429   LR 0.010000   
2022-11-03 21:15:15,302 - INFO  - Training [7][  360/  391]   Loss 0.119656   Top1 95.763889   Top5 99.980469   BatchTime 0.105754   LR 0.010000   
2022-11-03 21:15:16,876 - INFO  - Training [7][  380/  391]   Loss 0.119131   Top1 95.777138   Top5 99.979441   BatchTime 0.104330   LR 0.010000   
2022-11-03 21:15:18,063 - INFO  - ==> Top1: 95.772    Top5: 99.980    Loss: 0.119

2022-11-03 21:15:18,064 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:15:20,616 - INFO  - Validation [7][   20/   79]   Loss 0.391114   Top1 88.828125   Top5 99.531250   BatchTime 0.127535   
2022-11-03 21:15:21,141 - INFO  - Validation [7][   40/   79]   Loss 0.402573   Top1 88.691406   Top5 99.492188   BatchTime 0.076880   
2022-11-03 21:15:21,860 - INFO  - Validation [7][   60/   79]   Loss 0.384853   Top1 89.088542   Top5 99.557292   BatchTime 0.063239   
2022-11-03 21:15:23,010 - INFO  - ==> Top1: 88.900    Top5: 99.570    Loss: 0.383

2022-11-03 21:15:23,055 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 88.910   Top5: 99.560] Sparsity : 0.703
2022-11-03 21:15:23,056 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.900   Top5: 99.570] Sparsity : 0.729
2022-11-03 21:15:23,056 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.870   Top5: 99.580] Sparsity : 0.663
2022-11-03 21:15:23,159 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:15:23,159 - INFO  - >>>>>>>> Epoch   8
2022-11-03 21:15:23,160 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:15:27,048 - INFO  - Training [8][   20/  391]   Loss 0.105092   Top1 96.601562   Top5 99.960938   BatchTime 0.194419   LR 0.010000   
2022-11-03 21:15:29,054 - INFO  - Training [8][   40/  391]   Loss 0.106828   Top1 96.289062   Top5 99.980469   BatchTime 0.147356   LR 0.010000   
2022-11-03 21:15:31,073 - INFO  - Training [8][   60/  391]   Loss 0.110978   Top1 96.119792   Top5 99.973958   BatchTime 0.131879   LR 0.010000   
2022-11-03 21:15:33,096 - INFO  - Training [8][   80/  391]   Loss 0.110032   Top1 96.123047   Top5 99.980469   BatchTime 0.124192   LR 0.010000   
2022-11-03 21:15:35,110 - INFO  - Training [8][  100/  391]   Loss 0.110661   Top1 96.101562   Top5 99.976562   BatchTime 0.119499   LR 0.010000   
2022-11-03 21:15:37,154 - INFO  - Training [8][  120/  391]   Loss 0.112014   Top1 95.996094   Top5 99.980469   BatchTime 0.116617   LR 0.010000   
2022-11-03 21:15:39,181 - INFO  - Training [8][  140/  391]   Loss 0.112778   Top1 95.937500   Top5 99.977679   BatchTime 0.114436   LR 0.010000   
2022-11-03 21:15:41,194 - INFO  - Training [8][  160/  391]   Loss 0.114175   Top1 95.903320   Top5 99.975586   BatchTime 0.112711   LR 0.010000   
2022-11-03 21:15:43,228 - INFO  - Training [8][  180/  391]   Loss 0.113679   Top1 95.946181   Top5 99.969618   BatchTime 0.111485   LR 0.010000   
2022-11-03 21:15:45,231 - INFO  - Training [8][  200/  391]   Loss 0.113670   Top1 95.949219   Top5 99.968750   BatchTime 0.110353   LR 0.010000   
2022-11-03 21:15:47,245 - INFO  - Training [8][  220/  391]   Loss 0.114012   Top1 95.948153   Top5 99.964489   BatchTime 0.109473   LR 0.010000   
2022-11-03 21:15:49,279 - INFO  - Training [8][  240/  391]   Loss 0.113383   Top1 95.992839   Top5 99.967448   BatchTime 0.108827   LR 0.010000   
2022-11-03 21:15:51,293 - INFO  - Training [8][  260/  391]   Loss 0.113981   Top1 96.006611   Top5 99.963942   BatchTime 0.108203   LR 0.010000   
2022-11-03 21:15:53,298 - INFO  - Training [8][  280/  391]   Loss 0.114750   Top1 96.012835   Top5 99.960938   BatchTime 0.107635   LR 0.010000   
2022-11-03 21:15:55,294 - INFO  - Training [8][  300/  391]   Loss 0.115245   Top1 96.002604   Top5 99.960938   BatchTime 0.107112   LR 0.010000   
2022-11-03 21:15:57,278 - INFO  - Training [8][  320/  391]   Loss 0.116513   Top1 95.939941   Top5 99.963379   BatchTime 0.106615   LR 0.010000   
2022-11-03 21:15:59,227 - INFO  - Training [8][  340/  391]   Loss 0.116362   Top1 95.953585   Top5 99.963235   BatchTime 0.106078   LR 0.010000   
2022-11-03 21:16:01,036 - INFO  - Training [8][  360/  391]   Loss 0.117079   Top1 95.924479   Top5 99.960938   BatchTime 0.105209   LR 0.010000   
2022-11-03 21:16:02,629 - INFO  - Training [8][  380/  391]   Loss 0.116937   Top1 95.918997   Top5 99.960938   BatchTime 0.103864   LR 0.010000   
2022-11-03 21:16:03,770 - INFO  - ==> Top1: 95.908    Top5: 99.962    Loss: 0.117

2022-11-03 21:16:03,771 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:16:06,227 - INFO  - Validation [8][   20/   79]   Loss 0.378327   Top1 89.296875   Top5 99.570312   BatchTime 0.122756   
2022-11-03 21:16:06,750 - INFO  - Validation [8][   40/   79]   Loss 0.389555   Top1 89.296875   Top5 99.394531   BatchTime 0.074452   
2022-11-03 21:16:07,589 - INFO  - Validation [8][   60/   79]   Loss 0.380745   Top1 89.322917   Top5 99.492188   BatchTime 0.063606   
2022-11-03 21:16:08,722 - INFO  - ==> Top1: 89.270    Top5: 99.540    Loss: 0.380

2022-11-03 21:16:08,765 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.270   Top5: 99.540] Sparsity : 0.738
2022-11-03 21:16:08,766 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 88.910   Top5: 99.560] Sparsity : 0.703
2022-11-03 21:16:08,766 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 88.900   Top5: 99.570] Sparsity : 0.729
2022-11-03 21:16:08,957 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:16:08,957 - INFO  - >>>>>>>> Epoch   9
2022-11-03 21:16:08,958 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:16:12,815 - INFO  - Training [9][   20/  391]   Loss 0.110782   Top1 95.976562   Top5 99.960938   BatchTime 0.192850   LR 0.010000   
2022-11-03 21:16:14,813 - INFO  - Training [9][   40/  391]   Loss 0.114100   Top1 96.035156   Top5 99.960938   BatchTime 0.146387   LR 0.010000   
2022-11-03 21:16:16,839 - INFO  - Training [9][   60/  391]   Loss 0.111450   Top1 96.184896   Top5 99.973958   BatchTime 0.131359   LR 0.010000   
2022-11-03 21:16:18,839 - INFO  - Training [9][   80/  391]   Loss 0.111069   Top1 96.123047   Top5 99.980469   BatchTime 0.123514   LR 0.010000   
2022-11-03 21:16:20,845 - INFO  - Training [9][  100/  391]   Loss 0.109106   Top1 96.234375   Top5 99.976562   BatchTime 0.118870   LR 0.010000   
2022-11-03 21:16:22,966 - INFO  - Training [9][  120/  391]   Loss 0.110326   Top1 96.119792   Top5 99.980469   BatchTime 0.116737   LR 0.010000   
2022-11-03 21:16:24,974 - INFO  - Training [9][  140/  391]   Loss 0.110109   Top1 96.110491   Top5 99.983259   BatchTime 0.114397   LR 0.010000   
2022-11-03 21:16:26,986 - INFO  - Training [9][  160/  391]   Loss 0.111432   Top1 96.054688   Top5 99.970703   BatchTime 0.112674   LR 0.010000   
2022-11-03 21:16:28,996 - INFO  - Training [9][  180/  391]   Loss 0.112532   Top1 96.028646   Top5 99.969618   BatchTime 0.111321   LR 0.010000   
2022-11-03 21:16:31,009 - INFO  - Training [9][  200/  391]   Loss 0.111713   Top1 96.054688   Top5 99.972656   BatchTime 0.110254   LR 0.010000   
2022-11-03 21:16:33,026 - INFO  - Training [9][  220/  391]   Loss 0.111449   Top1 96.051136   Top5 99.971591   BatchTime 0.109397   LR 0.010000   
2022-11-03 21:16:35,033 - INFO  - Training [9][  240/  391]   Loss 0.110624   Top1 96.090495   Top5 99.973958   BatchTime 0.108642   LR 0.010000   
2022-11-03 21:16:37,066 - INFO  - Training [9][  260/  391]   Loss 0.111902   Top1 96.045673   Top5 99.975962   BatchTime 0.108104   LR 0.010000   
2022-11-03 21:16:39,095 - INFO  - Training [9][  280/  391]   Loss 0.111839   Top1 96.051897   Top5 99.977679   BatchTime 0.107629   LR 0.010000   
2022-11-03 21:16:41,076 - INFO  - Training [9][  300/  391]   Loss 0.111320   Top1 96.067708   Top5 99.979167   BatchTime 0.107057   LR 0.010000   
2022-11-03 21:16:43,061 - INFO  - Training [9][  320/  391]   Loss 0.112977   Top1 96.010742   Top5 99.978027   BatchTime 0.106570   LR 0.010000   
2022-11-03 21:16:45,026 - INFO  - Training [9][  340/  391]   Loss 0.113022   Top1 95.994945   Top5 99.979320   BatchTime 0.106081   LR 0.010000   
2022-11-03 21:16:46,750 - INFO  - Training [9][  360/  391]   Loss 0.112989   Top1 96.006944   Top5 99.980469   BatchTime 0.104976   LR 0.010000   
2022-11-03 21:16:48,370 - INFO  - Training [9][  380/  391]   Loss 0.113302   Top1 95.986842   Top5 99.975329   BatchTime 0.103713   LR 0.010000   
2022-11-03 21:16:49,506 - INFO  - ==> Top1: 95.968    Top5: 99.976    Loss: 0.113

2022-11-03 21:16:49,507 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:16:52,054 - INFO  - Validation [9][   20/   79]   Loss 0.384043   Top1 89.531250   Top5 99.570312   BatchTime 0.127272   
2022-11-03 21:16:52,702 - INFO  - Validation [9][   40/   79]   Loss 0.391877   Top1 89.433594   Top5 99.472656   BatchTime 0.079833   
2022-11-03 21:16:53,579 - INFO  - Validation [9][   60/   79]   Loss 0.379024   Top1 89.830729   Top5 99.544271   BatchTime 0.067844   
2022-11-03 21:16:54,709 - INFO  - ==> Top1: 89.590    Top5: 99.620    Loss: 0.381

2022-11-03 21:16:54,757 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:16:54,758 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.270   Top5: 99.540] Sparsity : 0.738
2022-11-03 21:16:54,758 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 88.910   Top5: 99.560] Sparsity : 0.703
2022-11-03 21:16:54,943 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:16:54,943 - INFO  - >>>>>>>> Epoch  10
2022-11-03 21:16:54,944 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:16:58,796 - INFO  - Training [10][   20/  391]   Loss 0.094540   Top1 96.601562   Top5 100.000000   BatchTime 0.192591   LR 0.010000   
2022-11-03 21:17:00,805 - INFO  - Training [10][   40/  391]   Loss 0.095421   Top1 96.640625   Top5 99.980469   BatchTime 0.146512   LR 0.010000   
2022-11-03 21:17:02,797 - INFO  - Training [10][   60/  391]   Loss 0.095708   Top1 96.731771   Top5 99.973958   BatchTime 0.130873   LR 0.010000   
2022-11-03 21:17:04,809 - INFO  - Training [10][   80/  391]   Loss 0.093302   Top1 96.738281   Top5 99.980469   BatchTime 0.123299   LR 0.010000   
2022-11-03 21:17:06,838 - INFO  - Training [10][  100/  391]   Loss 0.093559   Top1 96.726562   Top5 99.984375   BatchTime 0.118930   LR 0.010000   
2022-11-03 21:17:08,842 - INFO  - Training [10][  120/  391]   Loss 0.095003   Top1 96.679688   Top5 99.973958   BatchTime 0.115810   LR 0.010000   
2022-11-03 21:17:10,840 - INFO  - Training [10][  140/  391]   Loss 0.095519   Top1 96.618304   Top5 99.977679   BatchTime 0.113538   LR 0.010000   
2022-11-03 21:17:12,874 - INFO  - Training [10][  160/  391]   Loss 0.096053   Top1 96.586914   Top5 99.980469   BatchTime 0.112054   LR 0.010000   
2022-11-03 21:17:14,902 - INFO  - Training [10][  180/  391]   Loss 0.096047   Top1 96.618924   Top5 99.973958   BatchTime 0.110874   LR 0.010000   
2022-11-03 21:17:16,911 - INFO  - Training [10][  200/  391]   Loss 0.096322   Top1 96.656250   Top5 99.968750   BatchTime 0.109832   LR 0.010000   
2022-11-03 21:17:18,919 - INFO  - Training [10][  220/  391]   Loss 0.097769   Top1 96.608665   Top5 99.971591   BatchTime 0.108974   LR 0.010000   
2022-11-03 21:17:20,940 - INFO  - Training [10][  240/  391]   Loss 0.098461   Top1 96.572266   Top5 99.973958   BatchTime 0.108313   LR 0.010000   
2022-11-03 21:17:22,954 - INFO  - Training [10][  260/  391]   Loss 0.099299   Top1 96.514423   Top5 99.972957   BatchTime 0.107728   LR 0.010000   
2022-11-03 21:17:24,962 - INFO  - Training [10][  280/  391]   Loss 0.100008   Top1 96.501116   Top5 99.972098   BatchTime 0.107203   LR 0.010000   
2022-11-03 21:17:26,939 - INFO  - Training [10][  300/  391]   Loss 0.100302   Top1 96.489583   Top5 99.973958   BatchTime 0.106646   LR 0.010000   
2022-11-03 21:17:28,910 - INFO  - Training [10][  320/  391]   Loss 0.099937   Top1 96.516113   Top5 99.975586   BatchTime 0.106141   LR 0.010000   
2022-11-03 21:17:30,911 - INFO  - Training [10][  340/  391]   Loss 0.100533   Top1 96.505055   Top5 99.977022   BatchTime 0.105781   LR 0.010000   
2022-11-03 21:17:32,502 - INFO  - Training [10][  360/  391]   Loss 0.101362   Top1 96.458333   Top5 99.978299   BatchTime 0.104324   LR 0.010000   
2022-11-03 21:17:34,198 - INFO  - Training [10][  380/  391]   Loss 0.100983   Top1 96.467928   Top5 99.979441   BatchTime 0.103297   LR 0.010000   
2022-11-03 21:17:35,319 - INFO  - ==> Top1: 96.442    Top5: 99.980    Loss: 0.101

2022-11-03 21:17:35,320 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:17:37,861 - INFO  - Validation [10][   20/   79]   Loss 0.397321   Top1 89.453125   Top5 99.375000   BatchTime 0.126902   
2022-11-03 21:17:38,691 - INFO  - Validation [10][   40/   79]   Loss 0.396490   Top1 89.414062   Top5 99.355469   BatchTime 0.084209   
2022-11-03 21:17:39,585 - INFO  - Validation [10][   60/   79]   Loss 0.386715   Top1 89.700521   Top5 99.414062   BatchTime 0.071036   
2022-11-03 21:17:40,695 - INFO  - ==> Top1: 89.680    Top5: 99.500    Loss: 0.384

2022-11-03 21:17:40,736 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:17:40,736 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:17:40,736 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.270   Top5: 99.540] Sparsity : 0.738
2022-11-03 21:17:40,926 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:17:40,926 - INFO  - >>>>>>>> Epoch  11
2022-11-03 21:17:40,927 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:17:44,830 - INFO  - Training [11][   20/  391]   Loss 0.096924   Top1 96.679688   Top5 100.000000   BatchTime 0.195162   LR 0.010000   
2022-11-03 21:17:46,851 - INFO  - Training [11][   40/  391]   Loss 0.101196   Top1 96.425781   Top5 100.000000   BatchTime 0.148093   LR 0.010000   
2022-11-03 21:17:48,867 - INFO  - Training [11][   60/  391]   Loss 0.098929   Top1 96.367188   Top5 100.000000   BatchTime 0.132327   LR 0.010000   
2022-11-03 21:17:50,896 - INFO  - Training [11][   80/  391]   Loss 0.100444   Top1 96.289062   Top5 100.000000   BatchTime 0.124615   LR 0.010000   
2022-11-03 21:17:52,925 - INFO  - Training [11][  100/  391]   Loss 0.098174   Top1 96.351562   Top5 99.992188   BatchTime 0.119976   LR 0.010000   
2022-11-03 21:17:54,943 - INFO  - Training [11][  120/  391]   Loss 0.100338   Top1 96.302083   Top5 99.993490   BatchTime 0.116798   LR 0.010000   
2022-11-03 21:17:56,982 - INFO  - Training [11][  140/  391]   Loss 0.099854   Top1 96.367188   Top5 99.994420   BatchTime 0.114677   LR 0.010000   
2022-11-03 21:17:58,972 - INFO  - Training [11][  160/  391]   Loss 0.101519   Top1 96.352539   Top5 99.990234   BatchTime 0.112781   LR 0.010000   
2022-11-03 21:18:01,127 - INFO  - Training [11][  180/  391]   Loss 0.102481   Top1 96.328125   Top5 99.986979   BatchTime 0.112221   LR 0.010000   
2022-11-03 21:18:03,121 - INFO  - Training [11][  200/  391]   Loss 0.102952   Top1 96.343750   Top5 99.984375   BatchTime 0.110969   LR 0.010000   
2022-11-03 21:18:05,139 - INFO  - Training [11][  220/  391]   Loss 0.102366   Top1 96.370739   Top5 99.985795   BatchTime 0.110051   LR 0.010000   
2022-11-03 21:18:07,174 - INFO  - Training [11][  240/  391]   Loss 0.102521   Top1 96.370443   Top5 99.986979   BatchTime 0.109360   LR 0.010000   
2022-11-03 21:18:09,190 - INFO  - Training [11][  260/  391]   Loss 0.102777   Top1 96.361178   Top5 99.987981   BatchTime 0.108702   LR 0.010000   
2022-11-03 21:18:11,197 - INFO  - Training [11][  280/  391]   Loss 0.103346   Top1 96.353237   Top5 99.986049   BatchTime 0.108103   LR 0.010000   
2022-11-03 21:18:13,207 - INFO  - Training [11][  300/  391]   Loss 0.104093   Top1 96.312500   Top5 99.986979   BatchTime 0.107597   LR 0.010000   
2022-11-03 21:18:15,187 - INFO  - Training [11][  320/  391]   Loss 0.104256   Top1 96.311035   Top5 99.985352   BatchTime 0.107060   LR 0.010000   
2022-11-03 21:18:17,125 - INFO  - Training [11][  340/  391]   Loss 0.104753   Top1 96.277574   Top5 99.983915   BatchTime 0.106461   LR 0.010000   
2022-11-03 21:18:18,686 - INFO  - Training [11][  360/  391]   Loss 0.105527   Top1 96.273872   Top5 99.980469   BatchTime 0.104883   LR 0.010000   
2022-11-03 21:18:20,320 - INFO  - Training [11][  380/  391]   Loss 0.106410   Top1 96.241776   Top5 99.979441   BatchTime 0.103664   LR 0.010000   
2022-11-03 21:18:21,467 - INFO  - ==> Top1: 96.226    Top5: 99.980    Loss: 0.107

2022-11-03 21:18:21,468 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:18:24,068 - INFO  - Validation [11][   20/   79]   Loss 0.394683   Top1 88.945312   Top5 99.726562   BatchTime 0.129936   
2022-11-03 21:18:24,954 - INFO  - Validation [11][   40/   79]   Loss 0.390612   Top1 88.964844   Top5 99.531250   BatchTime 0.087128   
2022-11-03 21:18:25,826 - INFO  - Validation [11][   60/   79]   Loss 0.376785   Top1 89.505208   Top5 99.544271   BatchTime 0.072613   
2022-11-03 21:18:26,928 - INFO  - ==> Top1: 89.490    Top5: 99.570    Loss: 0.377

2022-11-03 21:18:26,979 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:18:26,980 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:18:26,980 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.490   Top5: 99.570] Sparsity : 0.771
2022-11-03 21:18:27,091 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:18:27,091 - INFO  - >>>>>>>> Epoch  12
2022-11-03 21:18:27,093 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:18:31,024 - INFO  - Training [12][   20/  391]   Loss 0.100220   Top1 96.093750   Top5 99.960938   BatchTime 0.196535   LR 0.010000   
2022-11-03 21:18:33,029 - INFO  - Training [12][   40/  391]   Loss 0.095973   Top1 96.523438   Top5 99.980469   BatchTime 0.148406   LR 0.010000   
2022-11-03 21:18:35,059 - INFO  - Training [12][   60/  391]   Loss 0.097224   Top1 96.627604   Top5 99.986979   BatchTime 0.132759   LR 0.010000   
2022-11-03 21:18:37,068 - INFO  - Training [12][   80/  391]   Loss 0.095273   Top1 96.796875   Top5 99.970703   BatchTime 0.124684   LR 0.010000   
2022-11-03 21:18:39,086 - INFO  - Training [12][  100/  391]   Loss 0.098701   Top1 96.671875   Top5 99.976562   BatchTime 0.119926   LR 0.010000   
2022-11-03 21:18:41,087 - INFO  - Training [12][  120/  391]   Loss 0.101415   Top1 96.484375   Top5 99.973958   BatchTime 0.116613   LR 0.010000   
2022-11-03 21:18:43,102 - INFO  - Training [12][  140/  391]   Loss 0.102510   Top1 96.434152   Top5 99.972098   BatchTime 0.114349   LR 0.010000   
2022-11-03 21:18:45,107 - INFO  - Training [12][  160/  391]   Loss 0.103434   Top1 96.430664   Top5 99.975586   BatchTime 0.112584   LR 0.010000   
2022-11-03 21:18:47,097 - INFO  - Training [12][  180/  391]   Loss 0.105458   Top1 96.349826   Top5 99.978299   BatchTime 0.111133   LR 0.010000   
2022-11-03 21:18:49,092 - INFO  - Training [12][  200/  391]   Loss 0.107705   Top1 96.222656   Top5 99.980469   BatchTime 0.109994   LR 0.010000   
2022-11-03 21:18:51,072 - INFO  - Training [12][  220/  391]   Loss 0.108816   Top1 96.171875   Top5 99.978693   BatchTime 0.108992   LR 0.010000   
2022-11-03 21:18:53,060 - INFO  - Training [12][  240/  391]   Loss 0.110018   Top1 96.119792   Top5 99.977214   BatchTime 0.108193   LR 0.010000   
2022-11-03 21:18:55,071 - INFO  - Training [12][  260/  391]   Loss 0.111028   Top1 96.105769   Top5 99.978966   BatchTime 0.107607   LR 0.010000   
2022-11-03 21:18:57,087 - INFO  - Training [12][  280/  391]   Loss 0.112766   Top1 96.046317   Top5 99.977679   BatchTime 0.107118   LR 0.010000   
2022-11-03 21:18:59,062 - INFO  - Training [12][  300/  391]   Loss 0.114534   Top1 95.979167   Top5 99.979167   BatchTime 0.106561   LR 0.010000   
2022-11-03 21:19:01,038 - INFO  - Training [12][  320/  391]   Loss 0.115305   Top1 95.932617   Top5 99.978027   BatchTime 0.106076   LR 0.010000   
2022-11-03 21:19:02,975 - INFO  - Training [12][  340/  391]   Loss 0.115180   Top1 95.928309   Top5 99.977022   BatchTime 0.105534   LR 0.010000   
2022-11-03 21:19:04,527 - INFO  - Training [12][  360/  391]   Loss 0.115094   Top1 95.933160   Top5 99.973958   BatchTime 0.103981   LR 0.010000   
2022-11-03 21:19:06,161 - INFO  - Training [12][  380/  391]   Loss 0.116694   Top1 95.871711   Top5 99.973273   BatchTime 0.102809   LR 0.010000   
2022-11-03 21:19:07,272 - INFO  - ==> Top1: 95.860    Top5: 99.966    Loss: 0.117

2022-11-03 21:19:07,273 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:19:09,923 - INFO  - Validation [12][   20/   79]   Loss 0.399262   Top1 88.515625   Top5 99.609375   BatchTime 0.132394   
2022-11-03 21:19:10,831 - INFO  - Validation [12][   40/   79]   Loss 0.411568   Top1 88.574219   Top5 99.472656   BatchTime 0.088917   
2022-11-03 21:19:11,750 - INFO  - Validation [12][   60/   79]   Loss 0.405387   Top1 88.867188   Top5 99.492188   BatchTime 0.074583   
2022-11-03 21:19:12,868 - INFO  - ==> Top1: 88.760    Top5: 99.540    Loss: 0.401

2022-11-03 21:19:12,909 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:19:12,910 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:19:12,910 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.490   Top5: 99.570] Sparsity : 0.771
2022-11-03 21:19:13,015 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:19:13,016 - INFO  - >>>>>>>> Epoch  13
2022-11-03 21:19:13,017 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:19:16,864 - INFO  - Training [13][   20/  391]   Loss 0.112822   Top1 95.976562   Top5 100.000000   BatchTime 0.192322   LR 0.010000   
2022-11-03 21:19:18,872 - INFO  - Training [13][   40/  391]   Loss 0.108976   Top1 95.800781   Top5 100.000000   BatchTime 0.146364   LR 0.010000   
2022-11-03 21:19:20,868 - INFO  - Training [13][   60/  391]   Loss 0.111774   Top1 95.690104   Top5 100.000000   BatchTime 0.130840   LR 0.010000   
2022-11-03 21:19:22,883 - INFO  - Training [13][   80/  391]   Loss 0.114052   Top1 95.634766   Top5 100.000000   BatchTime 0.123323   LR 0.010000   
2022-11-03 21:19:24,895 - INFO  - Training [13][  100/  391]   Loss 0.113506   Top1 95.757812   Top5 100.000000   BatchTime 0.118778   LR 0.010000   
2022-11-03 21:19:26,892 - INFO  - Training [13][  120/  391]   Loss 0.115334   Top1 95.709635   Top5 99.986979   BatchTime 0.115621   LR 0.010000   
2022-11-03 21:19:28,891 - INFO  - Training [13][  140/  391]   Loss 0.115835   Top1 95.770089   Top5 99.983259   BatchTime 0.113379   LR 0.010000   
2022-11-03 21:19:30,886 - INFO  - Training [13][  160/  391]   Loss 0.117219   Top1 95.732422   Top5 99.985352   BatchTime 0.111678   LR 0.010000   
2022-11-03 21:19:32,893 - INFO  - Training [13][  180/  391]   Loss 0.117697   Top1 95.724826   Top5 99.986979   BatchTime 0.110420   LR 0.010000   
2022-11-03 21:19:34,884 - INFO  - Training [13][  200/  391]   Loss 0.118427   Top1 95.707031   Top5 99.988281   BatchTime 0.109330   LR 0.010000   
2022-11-03 21:19:37,025 - INFO  - Training [13][  220/  391]   Loss 0.118033   Top1 95.756392   Top5 99.985795   BatchTime 0.109122   LR 0.010000   
2022-11-03 21:19:39,018 - INFO  - Training [13][  240/  391]   Loss 0.118209   Top1 95.758464   Top5 99.983724   BatchTime 0.108336   LR 0.010000   
2022-11-03 21:19:41,040 - INFO  - Training [13][  260/  391]   Loss 0.118755   Top1 95.763221   Top5 99.978966   BatchTime 0.107777   LR 0.010000   
2022-11-03 21:19:43,024 - INFO  - Training [13][  280/  391]   Loss 0.118604   Top1 95.789621   Top5 99.980469   BatchTime 0.107164   LR 0.010000   
2022-11-03 21:19:44,985 - INFO  - Training [13][  300/  391]   Loss 0.118444   Top1 95.778646   Top5 99.981771   BatchTime 0.106557   LR 0.010000   
2022-11-03 21:19:46,967 - INFO  - Training [13][  320/  391]   Loss 0.118867   Top1 95.764160   Top5 99.980469   BatchTime 0.106091   LR 0.010000   
2022-11-03 21:19:48,785 - INFO  - Training [13][  340/  391]   Loss 0.119183   Top1 95.755974   Top5 99.974724   BatchTime 0.105197   LR 0.010000   
2022-11-03 21:19:50,415 - INFO  - Training [13][  360/  391]   Loss 0.120404   Top1 95.722656   Top5 99.973958   BatchTime 0.103879   LR 0.010000   
2022-11-03 21:19:52,013 - INFO  - Training [13][  380/  391]   Loss 0.120752   Top1 95.701069   Top5 99.975329   BatchTime 0.102617   LR 0.010000   
2022-11-03 21:19:53,113 - INFO  - ==> Top1: 95.694    Top5: 99.976    Loss: 0.121

2022-11-03 21:19:53,114 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:19:55,945 - INFO  - Validation [13][   20/   79]   Loss 0.398741   Top1 88.632812   Top5 99.453125   BatchTime 0.141480   
2022-11-03 21:19:56,849 - INFO  - Validation [13][   40/   79]   Loss 0.406654   Top1 88.496094   Top5 99.414062   BatchTime 0.093344   
2022-11-03 21:19:57,768 - INFO  - Validation [13][   60/   79]   Loss 0.389917   Top1 88.958333   Top5 99.518229   BatchTime 0.077536   
2022-11-03 21:19:58,892 - INFO  - ==> Top1: 89.030    Top5: 99.560    Loss: 0.385

2022-11-03 21:19:58,943 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:19:58,944 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:19:58,944 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.490   Top5: 99.570] Sparsity : 0.771
2022-11-03 21:19:59,051 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:19:59,052 - INFO  - >>>>>>>> Epoch  14
2022-11-03 21:19:59,053 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:20:02,946 - INFO  - Training [14][   20/  391]   Loss 0.108240   Top1 96.015625   Top5 100.000000   BatchTime 0.194614   LR 0.010000   
2022-11-03 21:20:04,955 - INFO  - Training [14][   40/  391]   Loss 0.101654   Top1 96.347656   Top5 100.000000   BatchTime 0.147528   LR 0.010000   
2022-11-03 21:20:06,972 - INFO  - Training [14][   60/  391]   Loss 0.107146   Top1 96.158854   Top5 99.973958   BatchTime 0.131970   LR 0.010000   
2022-11-03 21:20:08,951 - INFO  - Training [14][   80/  391]   Loss 0.112395   Top1 96.064453   Top5 99.970703   BatchTime 0.123718   LR 0.010000   
2022-11-03 21:20:10,945 - INFO  - Training [14][  100/  391]   Loss 0.113216   Top1 96.015625   Top5 99.960938   BatchTime 0.118914   LR 0.010000   
2022-11-03 21:20:12,967 - INFO  - Training [14][  120/  391]   Loss 0.115758   Top1 95.996094   Top5 99.947917   BatchTime 0.115946   LR 0.010000   
2022-11-03 21:20:14,975 - INFO  - Training [14][  140/  391]   Loss 0.116312   Top1 95.982143   Top5 99.955357   BatchTime 0.113726   LR 0.010000   
2022-11-03 21:20:16,988 - INFO  - Training [14][  160/  391]   Loss 0.115881   Top1 95.937500   Top5 99.960938   BatchTime 0.112089   LR 0.010000   
2022-11-03 21:20:19,001 - INFO  - Training [14][  180/  391]   Loss 0.116328   Top1 95.954861   Top5 99.960938   BatchTime 0.110818   LR 0.010000   
2022-11-03 21:20:21,023 - INFO  - Training [14][  200/  391]   Loss 0.117277   Top1 95.910156   Top5 99.960938   BatchTime 0.109847   LR 0.010000   
2022-11-03 21:20:23,024 - INFO  - Training [14][  220/  391]   Loss 0.118383   Top1 95.905540   Top5 99.960938   BatchTime 0.108955   LR 0.010000   
2022-11-03 21:20:25,026 - INFO  - Training [14][  240/  391]   Loss 0.118375   Top1 95.882161   Top5 99.964193   BatchTime 0.108217   LR 0.010000   
2022-11-03 21:20:27,033 - INFO  - Training [14][  260/  391]   Loss 0.117810   Top1 95.907452   Top5 99.963942   BatchTime 0.107614   LR 0.010000   
2022-11-03 21:20:29,008 - INFO  - Training [14][  280/  391]   Loss 0.118194   Top1 95.887277   Top5 99.966518   BatchTime 0.106978   LR 0.010000   
2022-11-03 21:20:30,976 - INFO  - Training [14][  300/  391]   Loss 0.118869   Top1 95.856771   Top5 99.966146   BatchTime 0.106405   LR 0.010000   
2022-11-03 21:20:32,942 - INFO  - Training [14][  320/  391]   Loss 0.119649   Top1 95.825195   Top5 99.963379   BatchTime 0.105900   LR 0.010000   
2022-11-03 21:20:34,708 - INFO  - Training [14][  340/  391]   Loss 0.121975   Top1 95.721507   Top5 99.963235   BatchTime 0.104864   LR 0.010000   
2022-11-03 21:20:36,330 - INFO  - Training [14][  360/  391]   Loss 0.122847   Top1 95.703125   Top5 99.960938   BatchTime 0.103545   LR 0.010000   
2022-11-03 21:20:37,909 - INFO  - Training [14][  380/  391]   Loss 0.122628   Top1 95.711349   Top5 99.960938   BatchTime 0.102250   LR 0.010000   
2022-11-03 21:20:39,051 - INFO  - ==> Top1: 95.698    Top5: 99.960    Loss: 0.123

2022-11-03 21:20:39,052 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:20:41,908 - INFO  - Validation [14][   20/   79]   Loss 0.387380   Top1 88.710938   Top5 99.687500   BatchTime 0.142724   
2022-11-03 21:20:42,807 - INFO  - Validation [14][   40/   79]   Loss 0.392526   Top1 88.750000   Top5 99.648438   BatchTime 0.093825   
2022-11-03 21:20:43,704 - INFO  - Validation [14][   60/   79]   Loss 0.376449   Top1 89.179688   Top5 99.635417   BatchTime 0.077506   
2022-11-03 21:20:44,833 - INFO  - ==> Top1: 89.180    Top5: 99.670    Loss: 0.373

2022-11-03 21:20:44,866 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:20:44,866 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:20:44,866 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.490   Top5: 99.570] Sparsity : 0.771
2022-11-03 21:20:44,964 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:20:44,964 - INFO  - >>>>>>>> Epoch  15
2022-11-03 21:20:44,965 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:20:48,801 - INFO  - Training [15][   20/  391]   Loss 0.115388   Top1 95.781250   Top5 99.921875   BatchTime 0.191804   LR 0.010000   
2022-11-03 21:20:50,783 - INFO  - Training [15][   40/  391]   Loss 0.111315   Top1 95.996094   Top5 99.941406   BatchTime 0.145431   LR 0.010000   
2022-11-03 21:20:52,801 - INFO  - Training [15][   60/  391]   Loss 0.105501   Top1 96.263021   Top5 99.947917   BatchTime 0.130601   LR 0.010000   
2022-11-03 21:20:54,807 - INFO  - Training [15][   80/  391]   Loss 0.107716   Top1 96.230469   Top5 99.960938   BatchTime 0.123023   LR 0.010000   
2022-11-03 21:20:56,829 - INFO  - Training [15][  100/  391]   Loss 0.108265   Top1 96.148438   Top5 99.968750   BatchTime 0.118632   LR 0.010000   
2022-11-03 21:20:58,825 - INFO  - Training [15][  120/  391]   Loss 0.108322   Top1 96.132812   Top5 99.973958   BatchTime 0.115492   LR 0.010000   
2022-11-03 21:21:00,817 - INFO  - Training [15][  140/  391]   Loss 0.109531   Top1 96.082589   Top5 99.972098   BatchTime 0.113221   LR 0.010000   
2022-11-03 21:21:02,800 - INFO  - Training [15][  160/  391]   Loss 0.110996   Top1 96.044922   Top5 99.965820   BatchTime 0.111467   LR 0.010000   
2022-11-03 21:21:04,799 - INFO  - Training [15][  180/  391]   Loss 0.113008   Top1 96.015625   Top5 99.956597   BatchTime 0.110185   LR 0.010000   
2022-11-03 21:21:06,778 - INFO  - Training [15][  200/  391]   Loss 0.113080   Top1 96.027344   Top5 99.960938   BatchTime 0.109063   LR 0.010000   
2022-11-03 21:21:08,772 - INFO  - Training [15][  220/  391]   Loss 0.114425   Top1 95.962358   Top5 99.957386   BatchTime 0.108209   LR 0.010000   
2022-11-03 21:21:10,758 - INFO  - Training [15][  240/  391]   Loss 0.113649   Top1 95.999349   Top5 99.957682   BatchTime 0.107466   LR 0.010000   
2022-11-03 21:21:12,766 - INFO  - Training [15][  260/  391]   Loss 0.113255   Top1 96.006611   Top5 99.957933   BatchTime 0.106925   LR 0.010000   
2022-11-03 21:21:14,824 - INFO  - Training [15][  280/  391]   Loss 0.114253   Top1 95.968192   Top5 99.960938   BatchTime 0.106636   LR 0.010000   
2022-11-03 21:21:16,792 - INFO  - Training [15][  300/  391]   Loss 0.114072   Top1 95.973958   Top5 99.960938   BatchTime 0.106086   LR 0.010000   
2022-11-03 21:21:18,776 - INFO  - Training [15][  320/  391]   Loss 0.114103   Top1 95.969238   Top5 99.963379   BatchTime 0.105655   LR 0.010000   
2022-11-03 21:21:20,463 - INFO  - Training [15][  340/  391]   Loss 0.114867   Top1 95.967371   Top5 99.960938   BatchTime 0.104404   LR 0.010000   
2022-11-03 21:21:22,091 - INFO  - Training [15][  360/  391]   Loss 0.116043   Top1 95.920139   Top5 99.963108   BatchTime 0.103125   LR 0.010000   
2022-11-03 21:21:23,674 - INFO  - Training [15][  380/  391]   Loss 0.116242   Top1 95.906661   Top5 99.962993   BatchTime 0.101864   LR 0.010000   
2022-11-03 21:21:25,042 - INFO  - ==> Top1: 95.916    Top5: 99.962    Loss: 0.116

2022-11-03 21:21:25,043 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:21:27,919 - INFO  - Validation [15][   20/   79]   Loss 0.363612   Top1 89.921875   Top5 99.687500   BatchTime 0.143712   
2022-11-03 21:21:28,816 - INFO  - Validation [15][   40/   79]   Loss 0.387896   Top1 89.492188   Top5 99.589844   BatchTime 0.094281   
2022-11-03 21:21:29,708 - INFO  - Validation [15][   60/   79]   Loss 0.384264   Top1 89.570312   Top5 99.596354   BatchTime 0.077721   
2022-11-03 21:21:30,837 - INFO  - ==> Top1: 89.200    Top5: 99.640    Loss: 0.383

2022-11-03 21:21:30,867 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:21:30,867 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:21:30,867 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.490   Top5: 99.570] Sparsity : 0.771
2022-11-03 21:21:30,960 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:21:30,960 - INFO  - >>>>>>>> Epoch  16
2022-11-03 21:21:30,962 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:21:34,828 - INFO  - Training [16][   20/  391]   Loss 0.110246   Top1 96.289062   Top5 100.000000   BatchTime 0.193318   LR 0.010000   
2022-11-03 21:21:36,859 - INFO  - Training [16][   40/  391]   Loss 0.101646   Top1 96.542969   Top5 100.000000   BatchTime 0.147438   LR 0.010000   
2022-11-03 21:21:38,900 - INFO  - Training [16][   60/  391]   Loss 0.099241   Top1 96.653646   Top5 99.973958   BatchTime 0.132306   LR 0.010000   
2022-11-03 21:21:40,912 - INFO  - Training [16][   80/  391]   Loss 0.098862   Top1 96.660156   Top5 99.970703   BatchTime 0.124370   LR 0.010000   
2022-11-03 21:21:42,916 - INFO  - Training [16][  100/  391]   Loss 0.098602   Top1 96.617188   Top5 99.968750   BatchTime 0.119542   LR 0.010000   
2022-11-03 21:21:44,921 - INFO  - Training [16][  120/  391]   Loss 0.099296   Top1 96.569010   Top5 99.973958   BatchTime 0.116325   LR 0.010000   
2022-11-03 21:21:46,931 - INFO  - Training [16][  140/  391]   Loss 0.101264   Top1 96.529018   Top5 99.972098   BatchTime 0.114063   LR 0.010000   
2022-11-03 21:21:48,938 - INFO  - Training [16][  160/  391]   Loss 0.101331   Top1 96.533203   Top5 99.975586   BatchTime 0.112346   LR 0.010000   
2022-11-03 21:21:50,961 - INFO  - Training [16][  180/  391]   Loss 0.102291   Top1 96.453993   Top5 99.978299   BatchTime 0.111103   LR 0.010000   
2022-11-03 21:21:52,976 - INFO  - Training [16][  200/  391]   Loss 0.102256   Top1 96.476562   Top5 99.976562   BatchTime 0.110066   LR 0.010000   
2022-11-03 21:21:54,988 - INFO  - Training [16][  220/  391]   Loss 0.103117   Top1 96.438210   Top5 99.978693   BatchTime 0.109208   LR 0.010000   
2022-11-03 21:21:56,998 - INFO  - Training [16][  240/  391]   Loss 0.104564   Top1 96.383464   Top5 99.977214   BatchTime 0.108482   LR 0.010000   
2022-11-03 21:21:59,001 - INFO  - Training [16][  260/  391]   Loss 0.105020   Top1 96.373197   Top5 99.975962   BatchTime 0.107842   LR 0.010000   
2022-11-03 21:22:00,969 - INFO  - Training [16][  280/  391]   Loss 0.105600   Top1 96.356027   Top5 99.974888   BatchTime 0.107168   LR 0.010000   
2022-11-03 21:22:02,946 - INFO  - Training [16][  300/  391]   Loss 0.105738   Top1 96.333333   Top5 99.976562   BatchTime 0.106612   LR 0.010000   
2022-11-03 21:22:04,932 - INFO  - Training [16][  320/  391]   Loss 0.105631   Top1 96.308594   Top5 99.978027   BatchTime 0.106154   LR 0.010000   
2022-11-03 21:22:06,602 - INFO  - Training [16][  340/  391]   Loss 0.106079   Top1 96.263787   Top5 99.979320   BatchTime 0.104822   LR 0.010000   
2022-11-03 21:22:08,272 - INFO  - Training [16][  360/  391]   Loss 0.106171   Top1 96.256510   Top5 99.978299   BatchTime 0.103636   LR 0.010000   
2022-11-03 21:22:09,884 - INFO  - Training [16][  380/  391]   Loss 0.105156   Top1 96.276727   Top5 99.977385   BatchTime 0.102424   LR 0.010000   
2022-11-03 21:22:11,186 - INFO  - ==> Top1: 96.274    Top5: 99.978    Loss: 0.105

2022-11-03 21:22:11,187 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:22:14,094 - INFO  - Validation [16][   20/   79]   Loss 0.376231   Top1 89.882812   Top5 99.609375   BatchTime 0.145276   
2022-11-03 21:22:15,006 - INFO  - Validation [16][   40/   79]   Loss 0.392715   Top1 89.531250   Top5 99.472656   BatchTime 0.095455   
2022-11-03 21:22:15,940 - INFO  - Validation [16][   60/   79]   Loss 0.385508   Top1 89.661458   Top5 99.505208   BatchTime 0.079192   
2022-11-03 21:22:17,072 - INFO  - ==> Top1: 89.570    Top5: 99.560    Loss: 0.383

2022-11-03 21:22:17,117 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:22:17,117 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:22:17,117 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.570   Top5: 99.560] Sparsity : 0.801
2022-11-03 21:22:17,224 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:22:17,225 - INFO  - >>>>>>>> Epoch  17
2022-11-03 21:22:17,226 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:22:21,073 - INFO  - Training [17][   20/  391]   Loss 0.081544   Top1 96.992188   Top5 100.000000   BatchTime 0.192347   LR 0.010000   
2022-11-03 21:22:23,118 - INFO  - Training [17][   40/  391]   Loss 0.094905   Top1 96.640625   Top5 99.980469   BatchTime 0.147292   LR 0.010000   
2022-11-03 21:22:25,118 - INFO  - Training [17][   60/  391]   Loss 0.093607   Top1 96.614583   Top5 99.973958   BatchTime 0.131532   LR 0.010000   
2022-11-03 21:22:27,140 - INFO  - Training [17][   80/  391]   Loss 0.090742   Top1 96.738281   Top5 99.980469   BatchTime 0.123921   LR 0.010000   
2022-11-03 21:22:29,141 - INFO  - Training [17][  100/  391]   Loss 0.092202   Top1 96.640625   Top5 99.984375   BatchTime 0.119149   LR 0.010000   
2022-11-03 21:22:31,161 - INFO  - Training [17][  120/  391]   Loss 0.097137   Top1 96.471354   Top5 99.980469   BatchTime 0.116122   LR 0.010000   
2022-11-03 21:22:33,155 - INFO  - Training [17][  140/  391]   Loss 0.098148   Top1 96.456473   Top5 99.983259   BatchTime 0.113775   LR 0.010000   
2022-11-03 21:22:35,142 - INFO  - Training [17][  160/  391]   Loss 0.098605   Top1 96.484375   Top5 99.985352   BatchTime 0.111969   LR 0.010000   
2022-11-03 21:22:37,147 - INFO  - Training [17][  180/  391]   Loss 0.098267   Top1 96.497396   Top5 99.986979   BatchTime 0.110671   LR 0.010000   
2022-11-03 21:22:39,180 - INFO  - Training [17][  200/  391]   Loss 0.098749   Top1 96.476562   Top5 99.988281   BatchTime 0.109769   LR 0.010000   
2022-11-03 21:22:41,182 - INFO  - Training [17][  220/  391]   Loss 0.098397   Top1 96.470170   Top5 99.989347   BatchTime 0.108889   LR 0.010000   
2022-11-03 21:22:43,188 - INFO  - Training [17][  240/  391]   Loss 0.099011   Top1 96.448568   Top5 99.990234   BatchTime 0.108171   LR 0.010000   
2022-11-03 21:22:45,191 - INFO  - Training [17][  260/  391]   Loss 0.100102   Top1 96.427284   Top5 99.990986   BatchTime 0.107556   LR 0.010000   
2022-11-03 21:22:47,186 - INFO  - Training [17][  280/  391]   Loss 0.100119   Top1 96.428571   Top5 99.991629   BatchTime 0.106997   LR 0.010000   
2022-11-03 21:22:49,163 - INFO  - Training [17][  300/  391]   Loss 0.100232   Top1 96.440104   Top5 99.992188   BatchTime 0.106453   LR 0.010000   
2022-11-03 21:22:51,191 - INFO  - Training [17][  320/  391]   Loss 0.100477   Top1 96.433105   Top5 99.990234   BatchTime 0.106136   LR 0.010000   
2022-11-03 21:22:52,822 - INFO  - Training [17][  340/  391]   Loss 0.101537   Top1 96.406250   Top5 99.988511   BatchTime 0.104692   LR 0.010000   
2022-11-03 21:22:54,531 - INFO  - Training [17][  360/  391]   Loss 0.101322   Top1 96.399740   Top5 99.989149   BatchTime 0.103623   LR 0.010000   
2022-11-03 21:22:56,164 - INFO  - Training [17][  380/  391]   Loss 0.101585   Top1 96.406250   Top5 99.987664   BatchTime 0.102465   LR 0.010000   
2022-11-03 21:22:57,363 - INFO  - ==> Top1: 96.386    Top5: 99.988    Loss: 0.102

2022-11-03 21:22:57,364 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:23:00,200 - INFO  - Validation [17][   20/   79]   Loss 0.380839   Top1 89.414062   Top5 99.765625   BatchTime 0.141724   
2022-11-03 21:23:01,098 - INFO  - Validation [17][   40/   79]   Loss 0.396295   Top1 89.453125   Top5 99.589844   BatchTime 0.093335   
2022-11-03 21:23:01,965 - INFO  - Validation [17][   60/   79]   Loss 0.391365   Top1 89.570312   Top5 99.583333   BatchTime 0.076667   
2022-11-03 21:23:03,094 - INFO  - ==> Top1: 89.550    Top5: 99.600    Loss: 0.388

2022-11-03 21:23:03,124 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:23:03,125 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:23:03,125 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.570   Top5: 99.560] Sparsity : 0.801
2022-11-03 21:23:03,237 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:23:03,238 - INFO  - >>>>>>>> Epoch  18
2022-11-03 21:23:03,239 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:23:07,142 - INFO  - Training [18][   20/  391]   Loss 0.088879   Top1 97.148438   Top5 100.000000   BatchTime 0.195118   LR 0.010000   
2022-11-03 21:23:09,163 - INFO  - Training [18][   40/  391]   Loss 0.101094   Top1 96.679688   Top5 99.980469   BatchTime 0.148088   LR 0.010000   
2022-11-03 21:23:11,212 - INFO  - Training [18][   60/  391]   Loss 0.093224   Top1 96.783854   Top5 99.986979   BatchTime 0.132866   LR 0.010000   
2022-11-03 21:23:13,222 - INFO  - Training [18][   80/  391]   Loss 0.095022   Top1 96.650391   Top5 99.990234   BatchTime 0.124777   LR 0.010000   
2022-11-03 21:23:15,240 - INFO  - Training [18][  100/  391]   Loss 0.095162   Top1 96.718750   Top5 99.992188   BatchTime 0.119999   LR 0.010000   
2022-11-03 21:23:17,249 - INFO  - Training [18][  120/  391]   Loss 0.094455   Top1 96.757812   Top5 99.993490   BatchTime 0.116743   LR 0.010000   
2022-11-03 21:23:19,270 - INFO  - Training [18][  140/  391]   Loss 0.094688   Top1 96.746652   Top5 99.994420   BatchTime 0.114502   LR 0.010000   
2022-11-03 21:23:21,278 - INFO  - Training [18][  160/  391]   Loss 0.094129   Top1 96.772461   Top5 99.995117   BatchTime 0.112741   LR 0.010000   
2022-11-03 21:23:23,290 - INFO  - Training [18][  180/  391]   Loss 0.093683   Top1 96.783854   Top5 99.995660   BatchTime 0.111387   LR 0.010000   
2022-11-03 21:23:25,312 - INFO  - Training [18][  200/  391]   Loss 0.094246   Top1 96.773438   Top5 99.992188   BatchTime 0.110363   LR 0.010000   
2022-11-03 21:23:27,355 - INFO  - Training [18][  220/  391]   Loss 0.096859   Top1 96.622869   Top5 99.992898   BatchTime 0.109615   LR 0.010000   
2022-11-03 21:23:29,360 - INFO  - Training [18][  240/  391]   Loss 0.097426   Top1 96.569010   Top5 99.990234   BatchTime 0.108833   LR 0.010000   
2022-11-03 21:23:31,359 - INFO  - Training [18][  260/  391]   Loss 0.096742   Top1 96.601562   Top5 99.990986   BatchTime 0.108149   LR 0.010000   
2022-11-03 21:23:33,333 - INFO  - Training [18][  280/  391]   Loss 0.096053   Top1 96.623884   Top5 99.988839   BatchTime 0.107475   LR 0.010000   
2022-11-03 21:23:35,312 - INFO  - Training [18][  300/  391]   Loss 0.095621   Top1 96.645833   Top5 99.989583   BatchTime 0.106907   LR 0.010000   
2022-11-03 21:23:37,319 - INFO  - Training [18][  320/  391]   Loss 0.096556   Top1 96.618652   Top5 99.987793   BatchTime 0.106495   LR 0.010000   
2022-11-03 21:23:38,835 - INFO  - Training [18][  340/  391]   Loss 0.097266   Top1 96.583180   Top5 99.988511   BatchTime 0.104689   LR 0.010000   
2022-11-03 21:23:40,570 - INFO  - Training [18][  360/  391]   Loss 0.097744   Top1 96.573351   Top5 99.986979   BatchTime 0.103694   LR 0.010000   
2022-11-03 21:23:42,237 - INFO  - Training [18][  380/  391]   Loss 0.097535   Top1 96.576891   Top5 99.985609   BatchTime 0.102623   LR 0.010000   
2022-11-03 21:23:43,493 - INFO  - ==> Top1: 96.586    Top5: 99.986    Loss: 0.098

2022-11-03 21:23:43,494 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:23:46,338 - INFO  - Validation [18][   20/   79]   Loss 0.398528   Top1 88.476562   Top5 99.765625   BatchTime 0.142104   
2022-11-03 21:23:47,245 - INFO  - Validation [18][   40/   79]   Loss 0.407392   Top1 88.828125   Top5 99.628906   BatchTime 0.093726   
2022-11-03 21:23:48,134 - INFO  - Validation [18][   60/   79]   Loss 0.394497   Top1 89.153646   Top5 99.622396   BatchTime 0.077290   
2022-11-03 21:23:49,284 - INFO  - ==> Top1: 89.200    Top5: 99.650    Loss: 0.392

2022-11-03 21:23:49,327 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:23:49,328 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:23:49,328 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.570   Top5: 99.560] Sparsity : 0.801
2022-11-03 21:23:49,429 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:23:49,429 - INFO  - >>>>>>>> Epoch  19
2022-11-03 21:23:49,431 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:23:53,256 - INFO  - Training [19][   20/  391]   Loss 0.096974   Top1 96.601562   Top5 100.000000   BatchTime 0.191233   LR 0.010000   
2022-11-03 21:23:55,267 - INFO  - Training [19][   40/  391]   Loss 0.089492   Top1 96.953125   Top5 100.000000   BatchTime 0.145891   LR 0.010000   
2022-11-03 21:23:57,286 - INFO  - Training [19][   60/  391]   Loss 0.087280   Top1 97.018229   Top5 100.000000   BatchTime 0.130924   LR 0.010000   
2022-11-03 21:23:59,302 - INFO  - Training [19][   80/  391]   Loss 0.083887   Top1 97.109375   Top5 100.000000   BatchTime 0.123383   LR 0.010000   
2022-11-03 21:24:01,309 - INFO  - Training [19][  100/  391]   Loss 0.084736   Top1 97.046875   Top5 100.000000   BatchTime 0.118776   LR 0.010000   
2022-11-03 21:24:03,314 - INFO  - Training [19][  120/  391]   Loss 0.087029   Top1 96.972656   Top5 100.000000   BatchTime 0.115694   LR 0.010000   
2022-11-03 21:24:05,325 - INFO  - Training [19][  140/  391]   Loss 0.087745   Top1 96.941964   Top5 100.000000   BatchTime 0.113524   LR 0.010000   
2022-11-03 21:24:07,322 - INFO  - Training [19][  160/  391]   Loss 0.088901   Top1 96.918945   Top5 99.990234   BatchTime 0.111815   LR 0.010000   
2022-11-03 21:24:09,332 - INFO  - Training [19][  180/  391]   Loss 0.086872   Top1 96.970486   Top5 99.991319   BatchTime 0.110562   LR 0.010000   
2022-11-03 21:24:11,339 - INFO  - Training [19][  200/  391]   Loss 0.087510   Top1 96.941406   Top5 99.992188   BatchTime 0.109537   LR 0.010000   
2022-11-03 21:24:13,341 - INFO  - Training [19][  220/  391]   Loss 0.088936   Top1 96.903409   Top5 99.989347   BatchTime 0.108682   LR 0.010000   
2022-11-03 21:24:15,367 - INFO  - Training [19][  240/  391]   Loss 0.090750   Top1 96.848958   Top5 99.986979   BatchTime 0.108066   LR 0.010000   
2022-11-03 21:24:17,378 - INFO  - Training [19][  260/  391]   Loss 0.091134   Top1 96.841947   Top5 99.984976   BatchTime 0.107485   LR 0.010000   
2022-11-03 21:24:19,354 - INFO  - Training [19][  280/  391]   Loss 0.090483   Top1 96.861049   Top5 99.986049   BatchTime 0.106867   LR 0.010000   
2022-11-03 21:24:21,347 - INFO  - Training [19][  300/  391]   Loss 0.091103   Top1 96.830729   Top5 99.986979   BatchTime 0.106384   LR 0.010000   
2022-11-03 21:24:23,320 - INFO  - Training [19][  320/  391]   Loss 0.090877   Top1 96.826172   Top5 99.987793   BatchTime 0.105902   LR 0.010000   
2022-11-03 21:24:24,914 - INFO  - Training [19][  340/  391]   Loss 0.091813   Top1 96.773897   Top5 99.986213   BatchTime 0.104359   LR 0.010000   
2022-11-03 21:24:26,563 - INFO  - Training [19][  360/  391]   Loss 0.092175   Top1 96.755642   Top5 99.986979   BatchTime 0.103144   LR 0.010000   
2022-11-03 21:24:28,239 - INFO  - Training [19][  380/  391]   Loss 0.091650   Top1 96.770148   Top5 99.987664   BatchTime 0.102123   LR 0.010000   
2022-11-03 21:24:29,484 - INFO  - ==> Top1: 96.768    Top5: 99.988    Loss: 0.092

2022-11-03 21:24:29,485 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:24:32,343 - INFO  - Validation [19][   20/   79]   Loss 0.396335   Top1 89.492188   Top5 99.453125   BatchTime 0.142843   
2022-11-03 21:24:33,241 - INFO  - Validation [19][   40/   79]   Loss 0.404642   Top1 89.472656   Top5 99.472656   BatchTime 0.093871   
2022-11-03 21:24:34,140 - INFO  - Validation [19][   60/   79]   Loss 0.394598   Top1 89.726562   Top5 99.531250   BatchTime 0.077565   
2022-11-03 21:24:35,250 - INFO  - ==> Top1: 89.800    Top5: 99.570    Loss: 0.384

2022-11-03 21:24:35,281 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 89.800   Top5: 99.570] Sparsity : 0.805
2022-11-03 21:24:35,282 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:24:35,282 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.590   Top5: 99.620] Sparsity : 0.743
2022-11-03 21:24:35,573 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:24:35,573 - INFO  - >>>>>>>> Epoch  20
2022-11-03 21:24:35,574 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:24:39,476 - INFO  - Training [20][   20/  391]   Loss 0.087863   Top1 96.992188   Top5 99.960938   BatchTime 0.195068   LR 0.001000   
2022-11-03 21:24:41,486 - INFO  - Training [20][   40/  391]   Loss 0.081175   Top1 97.207031   Top5 99.980469   BatchTime 0.147798   LR 0.001000   
2022-11-03 21:24:43,516 - INFO  - Training [20][   60/  391]   Loss 0.076088   Top1 97.304688   Top5 99.986979   BatchTime 0.132359   LR 0.001000   
2022-11-03 21:24:45,535 - INFO  - Training [20][   80/  391]   Loss 0.077865   Top1 97.226562   Top5 99.980469   BatchTime 0.124511   LR 0.001000   
2022-11-03 21:24:47,558 - INFO  - Training [20][  100/  391]   Loss 0.078579   Top1 97.171875   Top5 99.984375   BatchTime 0.119832   LR 0.001000   
2022-11-03 21:24:49,584 - INFO  - Training [20][  120/  391]   Loss 0.078699   Top1 97.265625   Top5 99.967448   BatchTime 0.116742   LR 0.001000   
2022-11-03 21:24:51,601 - INFO  - Training [20][  140/  391]   Loss 0.077478   Top1 97.310268   Top5 99.972098   BatchTime 0.114469   LR 0.001000   
2022-11-03 21:24:53,597 - INFO  - Training [20][  160/  391]   Loss 0.077759   Top1 97.333984   Top5 99.975586   BatchTime 0.112638   LR 0.001000   
2022-11-03 21:24:55,630 - INFO  - Training [20][  180/  391]   Loss 0.076579   Top1 97.378472   Top5 99.978299   BatchTime 0.111418   LR 0.001000   
2022-11-03 21:24:57,648 - INFO  - Training [20][  200/  391]   Loss 0.074863   Top1 97.398438   Top5 99.980469   BatchTime 0.110363   LR 0.001000   
2022-11-03 21:24:59,675 - INFO  - Training [20][  220/  391]   Loss 0.074964   Top1 97.393466   Top5 99.978693   BatchTime 0.109544   LR 0.001000   
2022-11-03 21:25:01,695 - INFO  - Training [20][  240/  391]   Loss 0.074620   Top1 97.412109   Top5 99.980469   BatchTime 0.108831   LR 0.001000   
2022-11-03 21:25:03,703 - INFO  - Training [20][  260/  391]   Loss 0.074679   Top1 97.385817   Top5 99.981971   BatchTime 0.108185   LR 0.001000   
2022-11-03 21:25:05,677 - INFO  - Training [20][  280/  391]   Loss 0.074271   Top1 97.399554   Top5 99.983259   BatchTime 0.107507   LR 0.001000   
2022-11-03 21:25:07,668 - INFO  - Training [20][  300/  391]   Loss 0.074073   Top1 97.416667   Top5 99.984375   BatchTime 0.106977   LR 0.001000   
2022-11-03 21:25:09,508 - INFO  - Training [20][  320/  391]   Loss 0.073337   Top1 97.446289   Top5 99.985352   BatchTime 0.106040   LR 0.001000   
2022-11-03 21:25:11,146 - INFO  - Training [20][  340/  391]   Loss 0.073423   Top1 97.458640   Top5 99.986213   BatchTime 0.104618   LR 0.001000   
2022-11-03 21:25:12,725 - INFO  - Training [20][  360/  391]   Loss 0.073295   Top1 97.478299   Top5 99.986979   BatchTime 0.103193   LR 0.001000   
2022-11-03 21:25:14,455 - INFO  - Training [20][  380/  391]   Loss 0.072654   Top1 97.497944   Top5 99.987664   BatchTime 0.102314   LR 0.001000   
2022-11-03 21:25:15,531 - INFO  - ==> Top1: 97.518    Top5: 99.988    Loss: 0.073

2022-11-03 21:25:15,532 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:25:18,358 - INFO  - Validation [20][   20/   79]   Loss 0.373127   Top1 90.078125   Top5 99.687500   BatchTime 0.141277   
2022-11-03 21:25:19,253 - INFO  - Validation [20][   40/   79]   Loss 0.380002   Top1 90.136719   Top5 99.589844   BatchTime 0.093013   
2022-11-03 21:25:20,129 - INFO  - Validation [20][   60/   79]   Loss 0.370325   Top1 90.403646   Top5 99.609375   BatchTime 0.076609   
2022-11-03 21:25:21,254 - INFO  - ==> Top1: 90.400    Top5: 99.650    Loss: 0.364

2022-11-03 21:25:21,285 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 90.400   Top5: 99.650] Sparsity : 0.805
2022-11-03 21:25:21,286 - INFO  - Scoreboard best 2 ==> Epoch [19][Top1: 89.800   Top5: 99.570] Sparsity : 0.805
2022-11-03 21:25:21,286 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.680   Top5: 99.500] Sparsity : 0.762
2022-11-03 21:25:21,467 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:25:21,468 - INFO  - >>>>>>>> Epoch  21
2022-11-03 21:25:21,468 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:25:25,378 - INFO  - Training [21][   20/  391]   Loss 0.058587   Top1 98.164062   Top5 100.000000   BatchTime 0.195444   LR 0.001000   
2022-11-03 21:25:27,382 - INFO  - Training [21][   40/  391]   Loss 0.058837   Top1 98.085938   Top5 99.980469   BatchTime 0.147824   LR 0.001000   
2022-11-03 21:25:29,407 - INFO  - Training [21][   60/  391]   Loss 0.061042   Top1 97.981771   Top5 99.986979   BatchTime 0.132297   LR 0.001000   
2022-11-03 21:25:31,418 - INFO  - Training [21][   80/  391]   Loss 0.063102   Top1 97.910156   Top5 99.990234   BatchTime 0.124366   LR 0.001000   
2022-11-03 21:25:33,440 - INFO  - Training [21][  100/  391]   Loss 0.063408   Top1 97.859375   Top5 99.992188   BatchTime 0.119710   LR 0.001000   
2022-11-03 21:25:35,450 - INFO  - Training [21][  120/  391]   Loss 0.065423   Top1 97.753906   Top5 99.993490   BatchTime 0.116511   LR 0.001000   
2022-11-03 21:25:37,456 - INFO  - Training [21][  140/  391]   Loss 0.064368   Top1 97.806920   Top5 99.994420   BatchTime 0.114194   LR 0.001000   
2022-11-03 21:25:39,450 - INFO  - Training [21][  160/  391]   Loss 0.065911   Top1 97.734375   Top5 99.995117   BatchTime 0.112384   LR 0.001000   
2022-11-03 21:25:41,483 - INFO  - Training [21][  180/  391]   Loss 0.066091   Top1 97.703993   Top5 99.995660   BatchTime 0.111191   LR 0.001000   
2022-11-03 21:25:43,495 - INFO  - Training [21][  200/  391]   Loss 0.066475   Top1 97.707031   Top5 99.992188   BatchTime 0.110130   LR 0.001000   
2022-11-03 21:25:45,493 - INFO  - Training [21][  220/  391]   Loss 0.066584   Top1 97.727273   Top5 99.989347   BatchTime 0.109199   LR 0.001000   
2022-11-03 21:25:47,505 - INFO  - Training [21][  240/  391]   Loss 0.065743   Top1 97.760417   Top5 99.990234   BatchTime 0.108484   LR 0.001000   
2022-11-03 21:25:49,486 - INFO  - Training [21][  260/  391]   Loss 0.064992   Top1 97.764423   Top5 99.990986   BatchTime 0.107756   LR 0.001000   
2022-11-03 21:25:51,463 - INFO  - Training [21][  280/  391]   Loss 0.064711   Top1 97.767857   Top5 99.991629   BatchTime 0.107120   LR 0.001000   
2022-11-03 21:25:53,437 - INFO  - Training [21][  300/  391]   Loss 0.064835   Top1 97.778646   Top5 99.989583   BatchTime 0.106558   LR 0.001000   
2022-11-03 21:25:55,305 - INFO  - Training [21][  320/  391]   Loss 0.065137   Top1 97.753906   Top5 99.990234   BatchTime 0.105736   LR 0.001000   
2022-11-03 21:25:56,973 - INFO  - Training [21][  340/  391]   Loss 0.065122   Top1 97.764246   Top5 99.990809   BatchTime 0.104424   LR 0.001000   
2022-11-03 21:25:58,562 - INFO  - Training [21][  360/  391]   Loss 0.065083   Top1 97.762587   Top5 99.991319   BatchTime 0.103034   LR 0.001000   
2022-11-03 21:26:00,230 - INFO  - Training [21][  380/  391]   Loss 0.064941   Top1 97.767270   Top5 99.991776   BatchTime 0.102000   LR 0.001000   
2022-11-03 21:26:01,292 - INFO  - ==> Top1: 97.780    Top5: 99.990    Loss: 0.065

2022-11-03 21:26:01,293 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:26:04,142 - INFO  - Validation [21][   20/   79]   Loss 0.380569   Top1 89.882812   Top5 99.648438   BatchTime 0.142338   
2022-11-03 21:26:05,026 - INFO  - Validation [21][   40/   79]   Loss 0.384589   Top1 90.097656   Top5 99.589844   BatchTime 0.093285   
2022-11-03 21:26:05,955 - INFO  - Validation [21][   60/   79]   Loss 0.375302   Top1 90.299479   Top5 99.622396   BatchTime 0.077661   
2022-11-03 21:26:07,068 - INFO  - ==> Top1: 90.340    Top5: 99.670    Loss: 0.369

2022-11-03 21:26:07,111 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 90.400   Top5: 99.650] Sparsity : 0.805
2022-11-03 21:26:07,112 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 90.340   Top5: 99.670] Sparsity : 0.805
2022-11-03 21:26:07,112 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 89.800   Top5: 99.570] Sparsity : 0.805
2022-11-03 21:26:07,225 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:26:07,225 - INFO  - >>>>>>>> Epoch  22
2022-11-03 21:26:07,226 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:26:11,252 - INFO  - Training [22][   20/  391]   Loss 0.051622   Top1 98.203125   Top5 100.000000   BatchTime 0.201280   LR 0.001000   
2022-11-03 21:26:13,272 - INFO  - Training [22][   40/  391]   Loss 0.057642   Top1 97.929688   Top5 100.000000   BatchTime 0.151133   LR 0.001000   
2022-11-03 21:26:15,289 - INFO  - Training [22][   60/  391]   Loss 0.058568   Top1 97.851562   Top5 100.000000   BatchTime 0.134377   LR 0.001000   
2022-11-03 21:26:17,328 - INFO  - Training [22][   80/  391]   Loss 0.059207   Top1 97.861328   Top5 100.000000   BatchTime 0.126262   LR 0.001000   
2022-11-03 21:26:19,351 - INFO  - Training [22][  100/  391]   Loss 0.060679   Top1 97.851562   Top5 100.000000   BatchTime 0.121245   LR 0.001000   
2022-11-03 21:26:21,363 - INFO  - Training [22][  120/  391]   Loss 0.064772   Top1 97.708333   Top5 100.000000   BatchTime 0.117800   LR 0.001000   
2022-11-03 21:26:23,378 - INFO  - Training [22][  140/  391]   Loss 0.065302   Top1 97.672991   Top5 100.000000   BatchTime 0.115363   LR 0.001000   
2022-11-03 21:26:25,409 - INFO  - Training [22][  160/  391]   Loss 0.066487   Top1 97.636719   Top5 100.000000   BatchTime 0.113641   LR 0.001000   
2022-11-03 21:26:27,423 - INFO  - Training [22][  180/  391]   Loss 0.066600   Top1 97.625868   Top5 100.000000   BatchTime 0.112199   LR 0.001000   
2022-11-03 21:26:29,457 - INFO  - Training [22][  200/  391]   Loss 0.066693   Top1 97.640625   Top5 100.000000   BatchTime 0.111149   LR 0.001000   
2022-11-03 21:26:31,466 - INFO  - Training [22][  220/  391]   Loss 0.066280   Top1 97.620739   Top5 100.000000   BatchTime 0.110177   LR 0.001000   
2022-11-03 21:26:33,462 - INFO  - Training [22][  240/  391]   Loss 0.066030   Top1 97.659505   Top5 100.000000   BatchTime 0.109311   LR 0.001000   
2022-11-03 21:26:35,460 - INFO  - Training [22][  260/  391]   Loss 0.066127   Top1 97.677284   Top5 100.000000   BatchTime 0.108587   LR 0.001000   
2022-11-03 21:26:37,462 - INFO  - Training [22][  280/  391]   Loss 0.066048   Top1 97.675781   Top5 99.997210   BatchTime 0.107981   LR 0.001000   
2022-11-03 21:26:39,454 - INFO  - Training [22][  300/  391]   Loss 0.066320   Top1 97.661458   Top5 99.997396   BatchTime 0.107424   LR 0.001000   
2022-11-03 21:26:41,266 - INFO  - Training [22][  320/  391]   Loss 0.066212   Top1 97.673340   Top5 99.997559   BatchTime 0.106372   LR 0.001000   
2022-11-03 21:26:42,973 - INFO  - Training [22][  340/  391]   Loss 0.065323   Top1 97.709099   Top5 99.997702   BatchTime 0.105134   LR 0.001000   
2022-11-03 21:26:44,599 - INFO  - Training [22][  360/  391]   Loss 0.064894   Top1 97.723524   Top5 99.997830   BatchTime 0.103810   LR 0.001000   
2022-11-03 21:26:46,314 - INFO  - Training [22][  380/  391]   Loss 0.065116   Top1 97.711760   Top5 99.997944   BatchTime 0.102860   LR 0.001000   
2022-11-03 21:26:47,389 - INFO  - ==> Top1: 97.706    Top5: 99.998    Loss: 0.065

2022-11-03 21:26:47,390 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:26:50,181 - INFO  - Validation [22][   20/   79]   Loss 0.377667   Top1 90.195312   Top5 99.609375   BatchTime 0.139488   
2022-11-03 21:26:51,083 - INFO  - Validation [22][   40/   79]   Loss 0.379569   Top1 90.156250   Top5 99.589844   BatchTime 0.092305   
2022-11-03 21:26:51,952 - INFO  - Validation [22][   60/   79]   Loss 0.368510   Top1 90.403646   Top5 99.635417   BatchTime 0.076020   
2022-11-03 21:26:53,095 - INFO  - ==> Top1: 90.390    Top5: 99.650    Loss: 0.363

2022-11-03 21:26:53,131 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 90.400   Top5: 99.650] Sparsity : 0.805
2022-11-03 21:26:53,132 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.390   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:26:53,132 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 90.340   Top5: 99.670] Sparsity : 0.805
2022-11-03 21:26:53,239 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:26:53,240 - INFO  - >>>>>>>> Epoch  23
2022-11-03 21:26:53,241 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:26:57,106 - INFO  - Training [23][   20/  391]   Loss 0.056533   Top1 98.007812   Top5 100.000000   BatchTime 0.193209   LR 0.001000   
2022-11-03 21:26:59,116 - INFO  - Training [23][   40/  391]   Loss 0.055277   Top1 98.085938   Top5 99.980469   BatchTime 0.146866   LR 0.001000   
2022-11-03 21:27:01,146 - INFO  - Training [23][   60/  391]   Loss 0.057710   Top1 98.033854   Top5 99.986979   BatchTime 0.131743   LR 0.001000   
2022-11-03 21:27:03,175 - INFO  - Training [23][   80/  391]   Loss 0.057692   Top1 97.998047   Top5 99.990234   BatchTime 0.124169   LR 0.001000   
2022-11-03 21:27:05,188 - INFO  - Training [23][  100/  391]   Loss 0.055658   Top1 98.109375   Top5 99.992188   BatchTime 0.119463   LR 0.001000   
2022-11-03 21:27:07,192 - INFO  - Training [23][  120/  391]   Loss 0.056774   Top1 98.053385   Top5 99.993490   BatchTime 0.116255   LR 0.001000   
2022-11-03 21:27:09,208 - INFO  - Training [23][  140/  391]   Loss 0.058496   Top1 98.002232   Top5 99.988839   BatchTime 0.114048   LR 0.001000   
2022-11-03 21:27:11,234 - INFO  - Training [23][  160/  391]   Loss 0.058551   Top1 97.978516   Top5 99.990234   BatchTime 0.112454   LR 0.001000   
2022-11-03 21:27:13,237 - INFO  - Training [23][  180/  391]   Loss 0.058909   Top1 97.977431   Top5 99.991319   BatchTime 0.111086   LR 0.001000   
2022-11-03 21:27:15,260 - INFO  - Training [23][  200/  391]   Loss 0.060683   Top1 97.882812   Top5 99.992188   BatchTime 0.110091   LR 0.001000   
2022-11-03 21:27:17,283 - INFO  - Training [23][  220/  391]   Loss 0.060201   Top1 97.904830   Top5 99.992898   BatchTime 0.109275   LR 0.001000   
2022-11-03 21:27:19,310 - INFO  - Training [23][  240/  391]   Loss 0.060308   Top1 97.900391   Top5 99.990234   BatchTime 0.108616   LR 0.001000   
2022-11-03 21:27:21,303 - INFO  - Training [23][  260/  391]   Loss 0.060883   Top1 97.884615   Top5 99.990986   BatchTime 0.107926   LR 0.001000   
2022-11-03 21:27:23,290 - INFO  - Training [23][  280/  391]   Loss 0.060882   Top1 97.896205   Top5 99.991629   BatchTime 0.107315   LR 0.001000   
2022-11-03 21:27:25,252 - INFO  - Training [23][  300/  391]   Loss 0.060949   Top1 97.888021   Top5 99.992188   BatchTime 0.106699   LR 0.001000   
2022-11-03 21:27:27,030 - INFO  - Training [23][  320/  391]   Loss 0.060806   Top1 97.897949   Top5 99.990234   BatchTime 0.105587   LR 0.001000   
2022-11-03 21:27:28,786 - INFO  - Training [23][  340/  391]   Loss 0.060560   Top1 97.904412   Top5 99.990809   BatchTime 0.104540   LR 0.001000   
2022-11-03 21:27:30,388 - INFO  - Training [23][  360/  391]   Loss 0.060834   Top1 97.901476   Top5 99.986979   BatchTime 0.103181   LR 0.001000   
2022-11-03 21:27:32,073 - INFO  - Training [23][  380/  391]   Loss 0.060810   Top1 97.898849   Top5 99.987664   BatchTime 0.102185   LR 0.001000   
2022-11-03 21:27:33,131 - INFO  - ==> Top1: 97.892    Top5: 99.988    Loss: 0.061

2022-11-03 21:27:33,132 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:27:35,953 - INFO  - Validation [23][   20/   79]   Loss 0.371095   Top1 90.117188   Top5 99.687500   BatchTime 0.140972   
2022-11-03 21:27:36,873 - INFO  - Validation [23][   40/   79]   Loss 0.381624   Top1 90.234375   Top5 99.609375   BatchTime 0.093496   
2022-11-03 21:27:37,768 - INFO  - Validation [23][   60/   79]   Loss 0.375617   Top1 90.468750   Top5 99.635417   BatchTime 0.077234   
2022-11-03 21:27:38,897 - INFO  - ==> Top1: 90.460    Top5: 99.650    Loss: 0.369

2022-11-03 21:27:38,944 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.460   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:27:38,945 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.400   Top5: 99.650] Sparsity : 0.805
2022-11-03 21:27:38,945 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 90.390   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:27:39,157 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:27:39,157 - INFO  - >>>>>>>> Epoch  24
2022-11-03 21:27:39,158 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:27:43,097 - INFO  - Training [24][   20/  391]   Loss 0.056716   Top1 97.539062   Top5 100.000000   BatchTime 0.196904   LR 0.001000   
2022-11-03 21:27:45,129 - INFO  - Training [24][   40/  391]   Loss 0.055284   Top1 97.773438   Top5 100.000000   BatchTime 0.149252   LR 0.001000   
2022-11-03 21:27:47,149 - INFO  - Training [24][   60/  391]   Loss 0.056980   Top1 97.812500   Top5 100.000000   BatchTime 0.133175   LR 0.001000   
2022-11-03 21:27:49,253 - INFO  - Training [24][   80/  391]   Loss 0.057599   Top1 97.802734   Top5 100.000000   BatchTime 0.126186   LR 0.001000   
2022-11-03 21:27:51,284 - INFO  - Training [24][  100/  391]   Loss 0.059058   Top1 97.781250   Top5 99.992188   BatchTime 0.121251   LR 0.001000   
2022-11-03 21:27:53,307 - INFO  - Training [24][  120/  391]   Loss 0.059238   Top1 97.825521   Top5 99.993490   BatchTime 0.117906   LR 0.001000   
2022-11-03 21:27:55,338 - INFO  - Training [24][  140/  391]   Loss 0.057645   Top1 97.929688   Top5 99.994420   BatchTime 0.115566   LR 0.001000   
2022-11-03 21:27:57,368 - INFO  - Training [24][  160/  391]   Loss 0.057423   Top1 97.973633   Top5 99.990234   BatchTime 0.113810   LR 0.001000   
2022-11-03 21:27:59,378 - INFO  - Training [24][  180/  391]   Loss 0.057331   Top1 97.981771   Top5 99.991319   BatchTime 0.112331   LR 0.001000   
2022-11-03 21:28:01,402 - INFO  - Training [24][  200/  391]   Loss 0.058395   Top1 97.941406   Top5 99.992188   BatchTime 0.111214   LR 0.001000   
2022-11-03 21:28:03,419 - INFO  - Training [24][  220/  391]   Loss 0.057991   Top1 97.947443   Top5 99.992898   BatchTime 0.110274   LR 0.001000   
2022-11-03 21:28:05,423 - INFO  - Training [24][  240/  391]   Loss 0.057788   Top1 97.958984   Top5 99.990234   BatchTime 0.109432   LR 0.001000   
2022-11-03 21:28:07,401 - INFO  - Training [24][  260/  391]   Loss 0.057494   Top1 97.971755   Top5 99.987981   BatchTime 0.108623   LR 0.001000   
2022-11-03 21:28:09,373 - INFO  - Training [24][  280/  391]   Loss 0.056950   Top1 97.982701   Top5 99.988839   BatchTime 0.107907   LR 0.001000   
2022-11-03 21:28:11,342 - INFO  - Training [24][  300/  391]   Loss 0.058195   Top1 97.932292   Top5 99.989583   BatchTime 0.107276   LR 0.001000   
2022-11-03 21:28:13,042 - INFO  - Training [24][  320/  391]   Loss 0.058725   Top1 97.929688   Top5 99.990234   BatchTime 0.105882   LR 0.001000   
2022-11-03 21:28:14,757 - INFO  - Training [24][  340/  391]   Loss 0.058871   Top1 97.911305   Top5 99.990809   BatchTime 0.104700   LR 0.001000   
2022-11-03 21:28:16,347 - INFO  - Training [24][  360/  391]   Loss 0.059596   Top1 97.890625   Top5 99.991319   BatchTime 0.103298   LR 0.001000   
2022-11-03 21:28:18,023 - INFO  - Training [24][  380/  391]   Loss 0.059343   Top1 97.905016   Top5 99.991776   BatchTime 0.102272   LR 0.001000   
2022-11-03 21:28:19,132 - INFO  - ==> Top1: 97.890    Top5: 99.992    Loss: 0.059

2022-11-03 21:28:19,133 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:28:21,952 - INFO  - Validation [24][   20/   79]   Loss 0.373506   Top1 90.468750   Top5 99.648438   BatchTime 0.140845   
2022-11-03 21:28:22,825 - INFO  - Validation [24][   40/   79]   Loss 0.381251   Top1 90.449219   Top5 99.550781   BatchTime 0.092248   
2022-11-03 21:28:23,729 - INFO  - Validation [24][   60/   79]   Loss 0.373119   Top1 90.677083   Top5 99.596354   BatchTime 0.076565   
2022-11-03 21:28:24,829 - INFO  - ==> Top1: 90.600    Top5: 99.620    Loss: 0.369

2022-11-03 21:28:24,861 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.600   Top5: 99.620] Sparsity : 0.806
2022-11-03 21:28:24,861 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.460   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:28:24,861 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.400   Top5: 99.650] Sparsity : 0.805
2022-11-03 21:28:25,052 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:28:25,052 - INFO  - >>>>>>>> Epoch  25
2022-11-03 21:28:25,053 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:28:28,962 - INFO  - Training [25][   20/  391]   Loss 0.054928   Top1 98.164062   Top5 100.000000   BatchTime 0.195431   LR 0.001000   
2022-11-03 21:28:30,990 - INFO  - Training [25][   40/  391]   Loss 0.055396   Top1 98.066406   Top5 100.000000   BatchTime 0.148424   LR 0.001000   
2022-11-03 21:28:33,005 - INFO  - Training [25][   60/  391]   Loss 0.051122   Top1 98.281250   Top5 100.000000   BatchTime 0.132529   LR 0.001000   
2022-11-03 21:28:35,025 - INFO  - Training [25][   80/  391]   Loss 0.054455   Top1 98.134766   Top5 100.000000   BatchTime 0.124645   LR 0.001000   
2022-11-03 21:28:37,055 - INFO  - Training [25][  100/  391]   Loss 0.054969   Top1 98.132812   Top5 100.000000   BatchTime 0.120016   LR 0.001000   
2022-11-03 21:28:39,083 - INFO  - Training [25][  120/  391]   Loss 0.054085   Top1 98.157552   Top5 100.000000   BatchTime 0.116915   LR 0.001000   
2022-11-03 21:28:41,132 - INFO  - Training [25][  140/  391]   Loss 0.054176   Top1 98.169643   Top5 99.994420   BatchTime 0.114849   LR 0.001000   
2022-11-03 21:28:43,147 - INFO  - Training [25][  160/  391]   Loss 0.055065   Top1 98.144531   Top5 99.990234   BatchTime 0.113085   LR 0.001000   
2022-11-03 21:28:45,161 - INFO  - Training [25][  180/  391]   Loss 0.055763   Top1 98.133681   Top5 99.991319   BatchTime 0.111711   LR 0.001000   
2022-11-03 21:28:47,196 - INFO  - Training [25][  200/  391]   Loss 0.056008   Top1 98.109375   Top5 99.992188   BatchTime 0.110712   LR 0.001000   
2022-11-03 21:28:49,214 - INFO  - Training [25][  220/  391]   Loss 0.056155   Top1 98.096591   Top5 99.992898   BatchTime 0.109819   LR 0.001000   
2022-11-03 21:28:51,230 - INFO  - Training [25][  240/  391]   Loss 0.055873   Top1 98.121745   Top5 99.990234   BatchTime 0.109067   LR 0.001000   
2022-11-03 21:28:53,214 - INFO  - Training [25][  260/  391]   Loss 0.055241   Top1 98.134014   Top5 99.990986   BatchTime 0.108311   LR 0.001000   
2022-11-03 21:28:55,186 - INFO  - Training [25][  280/  391]   Loss 0.055121   Top1 98.130580   Top5 99.991629   BatchTime 0.107615   LR 0.001000   
2022-11-03 21:28:57,242 - INFO  - Training [25][  300/  391]   Loss 0.055190   Top1 98.135417   Top5 99.992188   BatchTime 0.107294   LR 0.001000   
2022-11-03 21:28:58,842 - INFO  - Training [25][  320/  391]   Loss 0.055371   Top1 98.122559   Top5 99.992676   BatchTime 0.105587   LR 0.001000   
2022-11-03 21:29:00,530 - INFO  - Training [25][  340/  391]   Loss 0.055108   Top1 98.147978   Top5 99.993107   BatchTime 0.104341   LR 0.001000   
2022-11-03 21:29:02,105 - INFO  - Training [25][  360/  391]   Loss 0.055837   Top1 98.107639   Top5 99.993490   BatchTime 0.102919   LR 0.001000   
2022-11-03 21:29:03,742 - INFO  - Training [25][  380/  391]   Loss 0.056006   Top1 98.096217   Top5 99.993832   BatchTime 0.101810   LR 0.001000   
2022-11-03 21:29:04,802 - INFO  - ==> Top1: 98.094    Top5: 99.994    Loss: 0.056

2022-11-03 21:29:04,804 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:29:07,603 - INFO  - Validation [25][   20/   79]   Loss 0.375126   Top1 90.429688   Top5 99.570312   BatchTime 0.139866   
2022-11-03 21:29:08,505 - INFO  - Validation [25][   40/   79]   Loss 0.384143   Top1 90.488281   Top5 99.531250   BatchTime 0.092504   
2022-11-03 21:29:09,401 - INFO  - Validation [25][   60/   79]   Loss 0.379932   Top1 90.677083   Top5 99.544271   BatchTime 0.076592   
2022-11-03 21:29:10,530 - INFO  - ==> Top1: 90.700    Top5: 99.560    Loss: 0.375

2022-11-03 21:29:10,566 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:29:10,566 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.600   Top5: 99.620] Sparsity : 0.806
2022-11-03 21:29:10,566 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.460   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:29:10,755 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:29:10,755 - INFO  - >>>>>>>> Epoch  26
2022-11-03 21:29:10,756 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:29:14,670 - INFO  - Training [26][   20/  391]   Loss 0.058700   Top1 97.812500   Top5 100.000000   BatchTime 0.195687   LR 0.001000   
2022-11-03 21:29:16,689 - INFO  - Training [26][   40/  391]   Loss 0.056695   Top1 97.851562   Top5 100.000000   BatchTime 0.148319   LR 0.001000   
2022-11-03 21:29:18,725 - INFO  - Training [26][   60/  391]   Loss 0.055586   Top1 97.825521   Top5 100.000000   BatchTime 0.132816   LR 0.001000   
2022-11-03 21:29:20,746 - INFO  - Training [26][   80/  391]   Loss 0.056907   Top1 97.753906   Top5 100.000000   BatchTime 0.124869   LR 0.001000   
2022-11-03 21:29:22,787 - INFO  - Training [26][  100/  391]   Loss 0.057233   Top1 97.820312   Top5 99.992188   BatchTime 0.120300   LR 0.001000   
2022-11-03 21:29:24,913 - INFO  - Training [26][  120/  391]   Loss 0.056188   Top1 97.871094   Top5 99.993490   BatchTime 0.117969   LR 0.001000   
2022-11-03 21:29:26,938 - INFO  - Training [26][  140/  391]   Loss 0.055961   Top1 97.862723   Top5 99.994420   BatchTime 0.115584   LR 0.001000   
2022-11-03 21:29:28,980 - INFO  - Training [26][  160/  391]   Loss 0.056920   Top1 97.895508   Top5 99.990234   BatchTime 0.113898   LR 0.001000   
2022-11-03 21:29:30,987 - INFO  - Training [26][  180/  391]   Loss 0.057461   Top1 97.903646   Top5 99.991319   BatchTime 0.112390   LR 0.001000   
2022-11-03 21:29:32,991 - INFO  - Training [26][  200/  391]   Loss 0.056621   Top1 97.929688   Top5 99.992188   BatchTime 0.111170   LR 0.001000   
2022-11-03 21:29:34,994 - INFO  - Training [26][  220/  391]   Loss 0.057146   Top1 97.908381   Top5 99.989347   BatchTime 0.110168   LR 0.001000   
2022-11-03 21:29:36,993 - INFO  - Training [26][  240/  391]   Loss 0.056987   Top1 97.923177   Top5 99.986979   BatchTime 0.109319   LR 0.001000   
2022-11-03 21:29:38,973 - INFO  - Training [26][  260/  391]   Loss 0.057278   Top1 97.932692   Top5 99.987981   BatchTime 0.108525   LR 0.001000   
2022-11-03 21:29:40,952 - INFO  - Training [26][  280/  391]   Loss 0.056950   Top1 97.957589   Top5 99.988839   BatchTime 0.107841   LR 0.001000   
2022-11-03 21:29:42,966 - INFO  - Training [26][  300/  391]   Loss 0.055826   Top1 98.005208   Top5 99.989583   BatchTime 0.107365   LR 0.001000   
2022-11-03 21:29:44,625 - INFO  - Training [26][  320/  391]   Loss 0.056752   Top1 97.949219   Top5 99.990234   BatchTime 0.105836   LR 0.001000   
2022-11-03 21:29:46,258 - INFO  - Training [26][  340/  391]   Loss 0.056180   Top1 97.975643   Top5 99.988511   BatchTime 0.104414   LR 0.001000   
2022-11-03 21:29:47,848 - INFO  - Training [26][  360/  391]   Loss 0.056804   Top1 97.953559   Top5 99.989149   BatchTime 0.103031   LR 0.001000   
2022-11-03 21:29:49,431 - INFO  - Training [26][  380/  391]   Loss 0.056608   Top1 97.974918   Top5 99.989720   BatchTime 0.101772   LR 0.001000   
2022-11-03 21:29:50,613 - INFO  - ==> Top1: 97.974    Top5: 99.990    Loss: 0.057

2022-11-03 21:29:50,614 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:29:53,344 - INFO  - Validation [26][   20/   79]   Loss 0.385664   Top1 90.039062   Top5 99.687500   BatchTime 0.136427   
2022-11-03 21:29:54,229 - INFO  - Validation [26][   40/   79]   Loss 0.388544   Top1 90.058594   Top5 99.570312   BatchTime 0.090346   
2022-11-03 21:29:55,132 - INFO  - Validation [26][   60/   79]   Loss 0.381540   Top1 90.273438   Top5 99.622396   BatchTime 0.075273   
2022-11-03 21:29:56,257 - INFO  - ==> Top1: 90.300    Top5: 99.650    Loss: 0.377

2022-11-03 21:29:56,299 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:29:56,299 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.600   Top5: 99.620] Sparsity : 0.806
2022-11-03 21:29:56,300 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.460   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:29:56,408 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:29:56,408 - INFO  - >>>>>>>> Epoch  27
2022-11-03 21:29:56,409 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:30:00,266 - INFO  - Training [27][   20/  391]   Loss 0.051678   Top1 98.007812   Top5 100.000000   BatchTime 0.192802   LR 0.001000   
2022-11-03 21:30:02,309 - INFO  - Training [27][   40/  391]   Loss 0.053494   Top1 98.105469   Top5 100.000000   BatchTime 0.147482   LR 0.001000   
2022-11-03 21:30:04,325 - INFO  - Training [27][   60/  391]   Loss 0.055925   Top1 97.994792   Top5 100.000000   BatchTime 0.131928   LR 0.001000   
2022-11-03 21:30:06,346 - INFO  - Training [27][   80/  391]   Loss 0.054487   Top1 98.115234   Top5 100.000000   BatchTime 0.124205   LR 0.001000   
2022-11-03 21:30:08,356 - INFO  - Training [27][  100/  391]   Loss 0.055371   Top1 98.062500   Top5 100.000000   BatchTime 0.119465   LR 0.001000   
2022-11-03 21:30:10,373 - INFO  - Training [27][  120/  391]   Loss 0.055714   Top1 98.105469   Top5 100.000000   BatchTime 0.116360   LR 0.001000   
2022-11-03 21:30:12,370 - INFO  - Training [27][  140/  391]   Loss 0.055645   Top1 98.097098   Top5 100.000000   BatchTime 0.114002   LR 0.001000   
2022-11-03 21:30:14,362 - INFO  - Training [27][  160/  391]   Loss 0.053826   Top1 98.154297   Top5 100.000000   BatchTime 0.112203   LR 0.001000   
2022-11-03 21:30:16,356 - INFO  - Training [27][  180/  391]   Loss 0.054568   Top1 98.133681   Top5 100.000000   BatchTime 0.110813   LR 0.001000   
2022-11-03 21:30:18,369 - INFO  - Training [27][  200/  391]   Loss 0.055050   Top1 98.105469   Top5 100.000000   BatchTime 0.109793   LR 0.001000   
2022-11-03 21:30:20,359 - INFO  - Training [27][  220/  391]   Loss 0.054742   Top1 98.110795   Top5 100.000000   BatchTime 0.108859   LR 0.001000   
2022-11-03 21:30:22,364 - INFO  - Training [27][  240/  391]   Loss 0.054628   Top1 98.125000   Top5 100.000000   BatchTime 0.108142   LR 0.001000   
2022-11-03 21:30:24,338 - INFO  - Training [27][  260/  391]   Loss 0.054160   Top1 98.158053   Top5 100.000000   BatchTime 0.107416   LR 0.001000   
2022-11-03 21:30:26,309 - INFO  - Training [27][  280/  391]   Loss 0.054429   Top1 98.147321   Top5 99.997210   BatchTime 0.106781   LR 0.001000   
2022-11-03 21:30:28,358 - INFO  - Training [27][  300/  391]   Loss 0.054721   Top1 98.140625   Top5 99.997396   BatchTime 0.106492   LR 0.001000   
2022-11-03 21:30:29,956 - INFO  - Training [27][  320/  391]   Loss 0.055343   Top1 98.122559   Top5 99.995117   BatchTime 0.104830   LR 0.001000   
2022-11-03 21:30:31,615 - INFO  - Training [27][  340/  391]   Loss 0.054894   Top1 98.138787   Top5 99.995404   BatchTime 0.103542   LR 0.001000   
2022-11-03 21:30:33,219 - INFO  - Training [27][  360/  391]   Loss 0.054880   Top1 98.138021   Top5 99.995660   BatchTime 0.102245   LR 0.001000   
2022-11-03 21:30:34,835 - INFO  - Training [27][  380/  391]   Loss 0.054814   Top1 98.139391   Top5 99.993832   BatchTime 0.101117   LR 0.001000   
2022-11-03 21:30:36,022 - INFO  - ==> Top1: 98.140    Top5: 99.994    Loss: 0.055

2022-11-03 21:30:36,023 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:30:38,743 - INFO  - Validation [27][   20/   79]   Loss 0.380512   Top1 90.351562   Top5 99.648438   BatchTime 0.135931   
2022-11-03 21:30:39,631 - INFO  - Validation [27][   40/   79]   Loss 0.388153   Top1 90.312500   Top5 99.589844   BatchTime 0.090167   
2022-11-03 21:30:40,535 - INFO  - Validation [27][   60/   79]   Loss 0.378043   Top1 90.507812   Top5 99.622396   BatchTime 0.075162   
2022-11-03 21:30:41,643 - INFO  - ==> Top1: 90.440    Top5: 99.630    Loss: 0.373

2022-11-03 21:30:41,675 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:30:41,676 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.600   Top5: 99.620] Sparsity : 0.806
2022-11-03 21:30:41,676 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.460   Top5: 99.650] Sparsity : 0.806
2022-11-03 21:30:41,784 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:30:41,785 - INFO  - >>>>>>>> Epoch  28
2022-11-03 21:30:41,786 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:30:45,635 - INFO  - Training [28][   20/  391]   Loss 0.054429   Top1 97.851562   Top5 100.000000   BatchTime 0.192449   LR 0.001000   
2022-11-03 21:30:47,652 - INFO  - Training [28][   40/  391]   Loss 0.051063   Top1 98.027344   Top5 100.000000   BatchTime 0.146630   LR 0.001000   
2022-11-03 21:30:49,658 - INFO  - Training [28][   60/  391]   Loss 0.058025   Top1 97.708333   Top5 100.000000   BatchTime 0.131197   LR 0.001000   
2022-11-03 21:30:51,664 - INFO  - Training [28][   80/  391]   Loss 0.057018   Top1 97.802734   Top5 100.000000   BatchTime 0.123468   LR 0.001000   
2022-11-03 21:30:53,653 - INFO  - Training [28][  100/  391]   Loss 0.057626   Top1 97.773438   Top5 100.000000   BatchTime 0.118665   LR 0.001000   
2022-11-03 21:30:55,657 - INFO  - Training [28][  120/  391]   Loss 0.057666   Top1 97.805990   Top5 100.000000   BatchTime 0.115587   LR 0.001000   
2022-11-03 21:30:57,667 - INFO  - Training [28][  140/  391]   Loss 0.056488   Top1 97.890625   Top5 100.000000   BatchTime 0.113431   LR 0.001000   
2022-11-03 21:30:59,769 - INFO  - Training [28][  160/  391]   Loss 0.056190   Top1 97.939453   Top5 100.000000   BatchTime 0.112389   LR 0.001000   
2022-11-03 21:31:01,810 - INFO  - Training [28][  180/  391]   Loss 0.056323   Top1 97.955729   Top5 100.000000   BatchTime 0.111242   LR 0.001000   
2022-11-03 21:31:03,850 - INFO  - Training [28][  200/  391]   Loss 0.055480   Top1 97.996094   Top5 100.000000   BatchTime 0.110315   LR 0.001000   
2022-11-03 21:31:05,880 - INFO  - Training [28][  220/  391]   Loss 0.055368   Top1 98.011364   Top5 100.000000   BatchTime 0.109514   LR 0.001000   
2022-11-03 21:31:07,896 - INFO  - Training [28][  240/  391]   Loss 0.054859   Top1 98.030599   Top5 100.000000   BatchTime 0.108788   LR 0.001000   
2022-11-03 21:31:09,915 - INFO  - Training [28][  260/  391]   Loss 0.055280   Top1 98.016827   Top5 100.000000   BatchTime 0.108185   LR 0.001000   
2022-11-03 21:31:11,902 - INFO  - Training [28][  280/  391]   Loss 0.055352   Top1 98.010603   Top5 100.000000   BatchTime 0.107552   LR 0.001000   
2022-11-03 21:31:13,902 - INFO  - Training [28][  300/  391]   Loss 0.054796   Top1 98.044271   Top5 100.000000   BatchTime 0.107050   LR 0.001000   
2022-11-03 21:31:15,410 - INFO  - Training [28][  320/  391]   Loss 0.055479   Top1 98.029785   Top5 100.000000   BatchTime 0.105071   LR 0.001000   
2022-11-03 21:31:17,089 - INFO  - Training [28][  340/  391]   Loss 0.056039   Top1 98.023897   Top5 99.997702   BatchTime 0.103829   LR 0.001000   
2022-11-03 21:31:18,683 - INFO  - Training [28][  360/  391]   Loss 0.055372   Top1 98.051215   Top5 99.995660   BatchTime 0.102487   LR 0.001000   
2022-11-03 21:31:20,396 - INFO  - Training [28][  380/  391]   Loss 0.055513   Top1 98.038651   Top5 99.995888   BatchTime 0.101601   LR 0.001000   
2022-11-03 21:31:21,571 - INFO  - ==> Top1: 98.046    Top5: 99.996    Loss: 0.055

2022-11-03 21:31:21,572 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:31:24,285 - INFO  - Validation [28][   20/   79]   Loss 0.376716   Top1 90.390625   Top5 99.765625   BatchTime 0.135543   
2022-11-03 21:31:25,152 - INFO  - Validation [28][   40/   79]   Loss 0.380336   Top1 90.312500   Top5 99.648438   BatchTime 0.089453   
2022-11-03 21:31:26,056 - INFO  - Validation [28][   60/   79]   Loss 0.376600   Top1 90.520833   Top5 99.674479   BatchTime 0.074705   
2022-11-03 21:31:27,160 - INFO  - ==> Top1: 90.460    Top5: 99.670    Loss: 0.373

2022-11-03 21:31:27,190 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:31:27,191 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.600   Top5: 99.620] Sparsity : 0.806
2022-11-03 21:31:27,191 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.460   Top5: 99.670] Sparsity : 0.806
2022-11-03 21:31:27,299 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:31:27,299 - INFO  - >>>>>>>> Epoch  29
2022-11-03 21:31:27,300 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:31:31,257 - INFO  - Training [29][   20/  391]   Loss 0.051554   Top1 97.695312   Top5 100.000000   BatchTime 0.197814   LR 0.001000   
2022-11-03 21:31:33,257 - INFO  - Training [29][   40/  391]   Loss 0.048300   Top1 98.046875   Top5 100.000000   BatchTime 0.148929   LR 0.001000   
2022-11-03 21:31:35,260 - INFO  - Training [29][   60/  391]   Loss 0.046580   Top1 98.229167   Top5 100.000000   BatchTime 0.132661   LR 0.001000   
2022-11-03 21:31:37,264 - INFO  - Training [29][   80/  391]   Loss 0.048688   Top1 98.251953   Top5 100.000000   BatchTime 0.124547   LR 0.001000   
2022-11-03 21:31:39,265 - INFO  - Training [29][  100/  391]   Loss 0.049733   Top1 98.250000   Top5 100.000000   BatchTime 0.119643   LR 0.001000   
2022-11-03 21:31:41,297 - INFO  - Training [29][  120/  391]   Loss 0.049341   Top1 98.287760   Top5 100.000000   BatchTime 0.116636   LR 0.001000   
2022-11-03 21:31:43,332 - INFO  - Training [29][  140/  391]   Loss 0.050170   Top1 98.264509   Top5 100.000000   BatchTime 0.114510   LR 0.001000   
2022-11-03 21:31:45,346 - INFO  - Training [29][  160/  391]   Loss 0.051232   Top1 98.227539   Top5 99.995117   BatchTime 0.112787   LR 0.001000   
2022-11-03 21:31:47,363 - INFO  - Training [29][  180/  391]   Loss 0.050989   Top1 98.211806   Top5 99.995660   BatchTime 0.111459   LR 0.001000   
2022-11-03 21:31:49,363 - INFO  - Training [29][  200/  391]   Loss 0.052860   Top1 98.128906   Top5 99.996094   BatchTime 0.110314   LR 0.001000   
2022-11-03 21:31:51,370 - INFO  - Training [29][  220/  391]   Loss 0.052857   Top1 98.114347   Top5 99.996449   BatchTime 0.109405   LR 0.001000   
2022-11-03 21:31:53,367 - INFO  - Training [29][  240/  391]   Loss 0.052632   Top1 98.111979   Top5 99.996745   BatchTime 0.108609   LR 0.001000   
2022-11-03 21:31:55,336 - INFO  - Training [29][  260/  391]   Loss 0.052609   Top1 98.118990   Top5 99.996995   BatchTime 0.107828   LR 0.001000   
2022-11-03 21:31:57,319 - INFO  - Training [29][  280/  391]   Loss 0.052843   Top1 98.122210   Top5 99.997210   BatchTime 0.107208   LR 0.001000   
2022-11-03 21:31:59,296 - INFO  - Training [29][  300/  391]   Loss 0.052106   Top1 98.153646   Top5 99.997396   BatchTime 0.106651   LR 0.001000   
2022-11-03 21:32:00,879 - INFO  - Training [29][  320/  391]   Loss 0.052863   Top1 98.149414   Top5 99.997559   BatchTime 0.104933   LR 0.001000   
2022-11-03 21:32:02,545 - INFO  - Training [29][  340/  391]   Loss 0.052450   Top1 98.159467   Top5 99.997702   BatchTime 0.103660   LR 0.001000   
2022-11-03 21:32:04,123 - INFO  - Training [29][  360/  391]   Loss 0.052279   Top1 98.177083   Top5 99.997830   BatchTime 0.102284   LR 0.001000   
2022-11-03 21:32:05,771 - INFO  - Training [29][  380/  391]   Loss 0.052797   Top1 98.151727   Top5 99.997944   BatchTime 0.101238   LR 0.001000   
2022-11-03 21:32:06,986 - INFO  - ==> Top1: 98.150    Top5: 99.998    Loss: 0.053

2022-11-03 21:32:06,987 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:32:09,712 - INFO  - Validation [29][   20/   79]   Loss 0.380821   Top1 90.546875   Top5 99.570312   BatchTime 0.136180   
2022-11-03 21:32:10,579 - INFO  - Validation [29][   40/   79]   Loss 0.388067   Top1 90.585938   Top5 99.570312   BatchTime 0.089771   
2022-11-03 21:32:11,474 - INFO  - Validation [29][   60/   79]   Loss 0.378891   Top1 90.768229   Top5 99.622396   BatchTime 0.074751   
2022-11-03 21:32:12,581 - INFO  - ==> Top1: 90.610    Top5: 99.630    Loss: 0.376

2022-11-03 21:32:12,610 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:32:12,610 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 90.610   Top5: 99.630] Sparsity : 0.807
2022-11-03 21:32:12,610 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.600   Top5: 99.620] Sparsity : 0.806
2022-11-03 21:32:12,720 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:32:12,720 - INFO  - >>>>>>>> Epoch  30
2022-11-03 21:32:12,722 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:32:16,587 - INFO  - Training [30][   20/  391]   Loss 0.054057   Top1 97.773438   Top5 100.000000   BatchTime 0.193255   LR 0.001000   
2022-11-03 21:32:18,645 - INFO  - Training [30][   40/  391]   Loss 0.048086   Top1 98.164062   Top5 100.000000   BatchTime 0.148080   LR 0.001000   
2022-11-03 21:32:20,653 - INFO  - Training [30][   60/  391]   Loss 0.046504   Top1 98.294271   Top5 100.000000   BatchTime 0.132177   LR 0.001000   
2022-11-03 21:32:22,633 - INFO  - Training [30][   80/  391]   Loss 0.047212   Top1 98.310547   Top5 100.000000   BatchTime 0.123882   LR 0.001000   
2022-11-03 21:32:24,677 - INFO  - Training [30][  100/  391]   Loss 0.047494   Top1 98.367188   Top5 100.000000   BatchTime 0.119549   LR 0.001000   
2022-11-03 21:32:26,681 - INFO  - Training [30][  120/  391]   Loss 0.049199   Top1 98.365885   Top5 100.000000   BatchTime 0.116321   LR 0.001000   
2022-11-03 21:32:28,711 - INFO  - Training [30][  140/  391]   Loss 0.049035   Top1 98.348214   Top5 100.000000   BatchTime 0.114208   LR 0.001000   
2022-11-03 21:32:30,729 - INFO  - Training [30][  160/  391]   Loss 0.048955   Top1 98.325195   Top5 100.000000   BatchTime 0.112544   LR 0.001000   
2022-11-03 21:32:32,730 - INFO  - Training [30][  180/  391]   Loss 0.049172   Top1 98.311632   Top5 100.000000   BatchTime 0.111155   LR 0.001000   
2022-11-03 21:32:34,725 - INFO  - Training [30][  200/  391]   Loss 0.049194   Top1 98.312500   Top5 100.000000   BatchTime 0.110016   LR 0.001000   
2022-11-03 21:32:36,709 - INFO  - Training [30][  220/  391]   Loss 0.049588   Top1 98.274148   Top5 100.000000   BatchTime 0.109031   LR 0.001000   
2022-11-03 21:32:38,837 - INFO  - Training [30][  240/  391]   Loss 0.050274   Top1 98.238932   Top5 100.000000   BatchTime 0.108810   LR 0.001000   
2022-11-03 21:32:40,812 - INFO  - Training [30][  260/  391]   Loss 0.050855   Top1 98.227163   Top5 99.996995   BatchTime 0.108036   LR 0.001000   
2022-11-03 21:32:42,794 - INFO  - Training [30][  280/  391]   Loss 0.050953   Top1 98.222656   Top5 99.997210   BatchTime 0.107396   LR 0.001000   
2022-11-03 21:32:44,719 - INFO  - Training [30][  300/  391]   Loss 0.050810   Top1 98.226562   Top5 99.997396   BatchTime 0.106655   LR 0.001000   
2022-11-03 21:32:46,374 - INFO  - Training [30][  320/  391]   Loss 0.050949   Top1 98.217773   Top5 99.997559   BatchTime 0.105159   LR 0.001000   
2022-11-03 21:32:48,015 - INFO  - Training [30][  340/  391]   Loss 0.051354   Top1 98.193934   Top5 99.997702   BatchTime 0.103800   LR 0.001000   
2022-11-03 21:32:49,731 - INFO  - Training [30][  360/  391]   Loss 0.051419   Top1 98.192274   Top5 99.997830   BatchTime 0.102802   LR 0.001000   
2022-11-03 21:32:51,188 - INFO  - Training [30][  380/  391]   Loss 0.051053   Top1 98.217516   Top5 99.997944   BatchTime 0.101224   LR 0.001000   
2022-11-03 21:32:52,470 - INFO  - ==> Top1: 98.210    Top5: 99.998    Loss: 0.051

2022-11-03 21:32:52,471 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:32:55,211 - INFO  - Validation [30][   20/   79]   Loss 0.382364   Top1 90.625000   Top5 99.570312   BatchTime 0.136902   
2022-11-03 21:32:56,140 - INFO  - Validation [30][   40/   79]   Loss 0.387385   Top1 90.527344   Top5 99.570312   BatchTime 0.091694   
2022-11-03 21:32:57,029 - INFO  - Validation [30][   60/   79]   Loss 0.380630   Top1 90.690104   Top5 99.609375   BatchTime 0.075942   
2022-11-03 21:32:58,146 - INFO  - ==> Top1: 90.620    Top5: 99.620    Loss: 0.378

2022-11-03 21:32:58,178 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:32:58,179 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.620   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:32:58,179 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.610   Top5: 99.630] Sparsity : 0.807
2022-11-03 21:32:58,292 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:32:58,292 - INFO  - >>>>>>>> Epoch  31
2022-11-03 21:32:58,293 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:33:02,160 - INFO  - Training [31][   20/  391]   Loss 0.049256   Top1 98.203125   Top5 100.000000   BatchTime 0.193326   LR 0.001000   
2022-11-03 21:33:04,163 - INFO  - Training [31][   40/  391]   Loss 0.050987   Top1 98.417969   Top5 100.000000   BatchTime 0.146741   LR 0.001000   
2022-11-03 21:33:06,175 - INFO  - Training [31][   60/  391]   Loss 0.050758   Top1 98.359375   Top5 100.000000   BatchTime 0.131356   LR 0.001000   
2022-11-03 21:33:08,181 - INFO  - Training [31][   80/  391]   Loss 0.050855   Top1 98.281250   Top5 100.000000   BatchTime 0.123589   LR 0.001000   
2022-11-03 21:33:10,198 - INFO  - Training [31][  100/  391]   Loss 0.051262   Top1 98.257812   Top5 100.000000   BatchTime 0.119049   LR 0.001000   
2022-11-03 21:33:12,208 - INFO  - Training [31][  120/  391]   Loss 0.052553   Top1 98.170573   Top5 99.993490   BatchTime 0.115950   LR 0.001000   
2022-11-03 21:33:14,226 - INFO  - Training [31][  140/  391]   Loss 0.051990   Top1 98.225446   Top5 99.994420   BatchTime 0.113801   LR 0.001000   
2022-11-03 21:33:16,223 - INFO  - Training [31][  160/  391]   Loss 0.052749   Top1 98.188477   Top5 99.995117   BatchTime 0.112061   LR 0.001000   
2022-11-03 21:33:18,221 - INFO  - Training [31][  180/  391]   Loss 0.053062   Top1 98.133681   Top5 99.991319   BatchTime 0.110707   LR 0.001000   
2022-11-03 21:33:20,231 - INFO  - Training [31][  200/  391]   Loss 0.052446   Top1 98.160156   Top5 99.992188   BatchTime 0.109685   LR 0.001000   
2022-11-03 21:33:22,245 - INFO  - Training [31][  220/  391]   Loss 0.052678   Top1 98.153409   Top5 99.992898   BatchTime 0.108867   LR 0.001000   
2022-11-03 21:33:24,232 - INFO  - Training [31][  240/  391]   Loss 0.052204   Top1 98.160807   Top5 99.993490   BatchTime 0.108075   LR 0.001000   
2022-11-03 21:33:26,225 - INFO  - Training [31][  260/  391]   Loss 0.051495   Top1 98.188101   Top5 99.993990   BatchTime 0.107428   LR 0.001000   
2022-11-03 21:33:28,233 - INFO  - Training [31][  280/  391]   Loss 0.050686   Top1 98.197545   Top5 99.994420   BatchTime 0.106926   LR 0.001000   
2022-11-03 21:33:30,162 - INFO  - Training [31][  300/  391]   Loss 0.050757   Top1 98.218750   Top5 99.994792   BatchTime 0.106225   LR 0.001000   
2022-11-03 21:33:31,763 - INFO  - Training [31][  320/  391]   Loss 0.050634   Top1 98.229980   Top5 99.995117   BatchTime 0.104590   LR 0.001000   
2022-11-03 21:33:33,407 - INFO  - Training [31][  340/  391]   Loss 0.050835   Top1 98.214614   Top5 99.995404   BatchTime 0.103274   LR 0.001000   
2022-11-03 21:33:35,125 - INFO  - Training [31][  360/  391]   Loss 0.050997   Top1 98.200955   Top5 99.995660   BatchTime 0.102308   LR 0.001000   
2022-11-03 21:33:36,581 - INFO  - Training [31][  380/  391]   Loss 0.051273   Top1 98.194901   Top5 99.995888   BatchTime 0.100755   LR 0.001000   
2022-11-03 21:33:37,899 - INFO  - ==> Top1: 98.190    Top5: 99.996    Loss: 0.051

2022-11-03 21:33:37,900 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:33:40,597 - INFO  - Validation [31][   20/   79]   Loss 0.379561   Top1 90.429688   Top5 99.531250   BatchTime 0.134764   
2022-11-03 21:33:41,543 - INFO  - Validation [31][   40/   79]   Loss 0.386659   Top1 90.664062   Top5 99.511719   BatchTime 0.091034   
2022-11-03 21:33:42,447 - INFO  - Validation [31][   60/   79]   Loss 0.378269   Top1 90.768229   Top5 99.570312   BatchTime 0.075752   
2022-11-03 21:33:43,595 - INFO  - ==> Top1: 90.660    Top5: 99.570    Loss: 0.376

2022-11-03 21:33:43,639 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:33:43,640 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:33:43,640 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.620   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:33:43,750 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:33:43,751 - INFO  - >>>>>>>> Epoch  32
2022-11-03 21:33:43,752 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:33:47,614 - INFO  - Training [32][   20/  391]   Loss 0.054065   Top1 98.125000   Top5 100.000000   BatchTime 0.193071   LR 0.001000   
2022-11-03 21:33:49,625 - INFO  - Training [32][   40/  391]   Loss 0.052050   Top1 98.046875   Top5 100.000000   BatchTime 0.146826   LR 0.001000   
2022-11-03 21:33:51,630 - INFO  - Training [32][   60/  391]   Loss 0.053312   Top1 98.046875   Top5 100.000000   BatchTime 0.131293   LR 0.001000   
2022-11-03 21:33:53,652 - INFO  - Training [32][   80/  391]   Loss 0.052506   Top1 98.046875   Top5 100.000000   BatchTime 0.123742   LR 0.001000   
2022-11-03 21:33:55,651 - INFO  - Training [32][  100/  391]   Loss 0.056537   Top1 97.945312   Top5 100.000000   BatchTime 0.118982   LR 0.001000   
2022-11-03 21:33:57,643 - INFO  - Training [32][  120/  391]   Loss 0.054413   Top1 98.033854   Top5 100.000000   BatchTime 0.115755   LR 0.001000   
2022-11-03 21:33:59,640 - INFO  - Training [32][  140/  391]   Loss 0.052967   Top1 98.125000   Top5 100.000000   BatchTime 0.113481   LR 0.001000   
2022-11-03 21:34:01,646 - INFO  - Training [32][  160/  391]   Loss 0.053545   Top1 98.154297   Top5 99.995117   BatchTime 0.111831   LR 0.001000   
2022-11-03 21:34:03,650 - INFO  - Training [32][  180/  391]   Loss 0.053420   Top1 98.151042   Top5 99.991319   BatchTime 0.110539   LR 0.001000   
2022-11-03 21:34:05,657 - INFO  - Training [32][  200/  391]   Loss 0.054005   Top1 98.105469   Top5 99.988281   BatchTime 0.109523   LR 0.001000   
2022-11-03 21:34:07,650 - INFO  - Training [32][  220/  391]   Loss 0.054489   Top1 98.082386   Top5 99.989347   BatchTime 0.108625   LR 0.001000   
2022-11-03 21:34:09,622 - INFO  - Training [32][  240/  391]   Loss 0.054253   Top1 98.098958   Top5 99.990234   BatchTime 0.107789   LR 0.001000   
2022-11-03 21:34:11,615 - INFO  - Training [32][  260/  391]   Loss 0.054423   Top1 98.109976   Top5 99.987981   BatchTime 0.107161   LR 0.001000   
2022-11-03 21:34:13,682 - INFO  - Training [32][  280/  391]   Loss 0.053863   Top1 98.119420   Top5 99.988839   BatchTime 0.106890   LR 0.001000   
2022-11-03 21:34:15,440 - INFO  - Training [32][  300/  391]   Loss 0.054104   Top1 98.106771   Top5 99.989583   BatchTime 0.105624   LR 0.001000   
2022-11-03 21:34:17,082 - INFO  - Training [32][  320/  391]   Loss 0.054143   Top1 98.115234   Top5 99.990234   BatchTime 0.104152   LR 0.001000   
2022-11-03 21:34:18,712 - INFO  - Training [32][  340/  391]   Loss 0.054356   Top1 98.102022   Top5 99.990809   BatchTime 0.102821   LR 0.001000   
2022-11-03 21:34:20,385 - INFO  - Training [32][  360/  391]   Loss 0.054127   Top1 98.114149   Top5 99.989149   BatchTime 0.101755   LR 0.001000   
2022-11-03 21:34:21,793 - INFO  - Training [32][  380/  391]   Loss 0.054048   Top1 98.108553   Top5 99.989720   BatchTime 0.100104   LR 0.001000   
2022-11-03 21:34:23,223 - INFO  - ==> Top1: 98.104    Top5: 99.990    Loss: 0.054

2022-11-03 21:34:23,223 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:34:25,943 - INFO  - Validation [32][   20/   79]   Loss 0.383933   Top1 90.351562   Top5 99.648438   BatchTime 0.135909   
2022-11-03 21:34:26,814 - INFO  - Validation [32][   40/   79]   Loss 0.388713   Top1 90.429688   Top5 99.609375   BatchTime 0.089722   
2022-11-03 21:34:27,703 - INFO  - Validation [32][   60/   79]   Loss 0.382536   Top1 90.559896   Top5 99.635417   BatchTime 0.074628   
2022-11-03 21:34:28,784 - INFO  - ==> Top1: 90.500    Top5: 99.660    Loss: 0.380

2022-11-03 21:34:28,813 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:34:28,814 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:34:28,814 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.620   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:34:28,916 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:34:28,917 - INFO  - >>>>>>>> Epoch  33
2022-11-03 21:34:28,919 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:34:32,813 - INFO  - Training [33][   20/  391]   Loss 0.053084   Top1 98.007812   Top5 100.000000   BatchTime 0.194712   LR 0.001000   
2022-11-03 21:34:34,824 - INFO  - Training [33][   40/  391]   Loss 0.047985   Top1 98.398438   Top5 100.000000   BatchTime 0.147613   LR 0.001000   
2022-11-03 21:34:36,834 - INFO  - Training [33][   60/  391]   Loss 0.046115   Top1 98.515625   Top5 100.000000   BatchTime 0.131913   LR 0.001000   
2022-11-03 21:34:38,868 - INFO  - Training [33][   80/  391]   Loss 0.048284   Top1 98.496094   Top5 99.990234   BatchTime 0.124359   LR 0.001000   
2022-11-03 21:34:40,874 - INFO  - Training [33][  100/  391]   Loss 0.049172   Top1 98.476562   Top5 99.984375   BatchTime 0.119548   LR 0.001000   
2022-11-03 21:34:42,883 - INFO  - Training [33][  120/  391]   Loss 0.049417   Top1 98.476562   Top5 99.986979   BatchTime 0.116364   LR 0.001000   
2022-11-03 21:34:44,893 - INFO  - Training [33][  140/  391]   Loss 0.049420   Top1 98.454241   Top5 99.988839   BatchTime 0.114095   LR 0.001000   
2022-11-03 21:34:46,896 - INFO  - Training [33][  160/  391]   Loss 0.049674   Top1 98.432617   Top5 99.990234   BatchTime 0.112352   LR 0.001000   
2022-11-03 21:34:48,908 - INFO  - Training [33][  180/  391]   Loss 0.049821   Top1 98.398438   Top5 99.991319   BatchTime 0.111050   LR 0.001000   
2022-11-03 21:34:50,906 - INFO  - Training [33][  200/  391]   Loss 0.050110   Top1 98.371094   Top5 99.992188   BatchTime 0.109934   LR 0.001000   
2022-11-03 21:34:52,915 - INFO  - Training [33][  220/  391]   Loss 0.050172   Top1 98.359375   Top5 99.992898   BatchTime 0.109069   LR 0.001000   
2022-11-03 21:34:54,903 - INFO  - Training [33][  240/  391]   Loss 0.049622   Top1 98.356120   Top5 99.993490   BatchTime 0.108264   LR 0.001000   
2022-11-03 21:34:56,891 - INFO  - Training [33][  260/  391]   Loss 0.049020   Top1 98.371394   Top5 99.993990   BatchTime 0.107583   LR 0.001000   
2022-11-03 21:34:58,885 - INFO  - Training [33][  280/  391]   Loss 0.049318   Top1 98.345424   Top5 99.994420   BatchTime 0.107019   LR 0.001000   
2022-11-03 21:35:00,747 - INFO  - Training [33][  300/  391]   Loss 0.049698   Top1 98.325521   Top5 99.994792   BatchTime 0.106089   LR 0.001000   
2022-11-03 21:35:02,356 - INFO  - Training [33][  320/  391]   Loss 0.049670   Top1 98.337402   Top5 99.995117   BatchTime 0.104487   LR 0.001000   
2022-11-03 21:35:03,949 - INFO  - Training [33][  340/  391]   Loss 0.050012   Top1 98.334099   Top5 99.995404   BatchTime 0.103026   LR 0.001000   
2022-11-03 21:35:05,687 - INFO  - Training [33][  360/  391]   Loss 0.050237   Top1 98.322483   Top5 99.993490   BatchTime 0.102130   LR 0.001000   
2022-11-03 21:35:07,120 - INFO  - Training [33][  380/  391]   Loss 0.050826   Top1 98.303865   Top5 99.993832   BatchTime 0.100527   LR 0.001000   
2022-11-03 21:35:08,412 - INFO  - ==> Top1: 98.294    Top5: 99.990    Loss: 0.051

2022-11-03 21:35:08,412 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:35:11,119 - INFO  - Validation [33][   20/   79]   Loss 0.372456   Top1 90.585938   Top5 99.570312   BatchTime 0.135240   
2022-11-03 21:35:12,017 - INFO  - Validation [33][   40/   79]   Loss 0.385673   Top1 90.546875   Top5 99.589844   BatchTime 0.090069   
2022-11-03 21:35:12,906 - INFO  - Validation [33][   60/   79]   Loss 0.384730   Top1 90.664062   Top5 99.596354   BatchTime 0.074873   
2022-11-03 21:35:14,015 - INFO  - ==> Top1: 90.580    Top5: 99.610    Loss: 0.379

2022-11-03 21:35:14,044 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:35:14,045 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:35:14,045 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.620   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:35:14,151 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:35:14,151 - INFO  - >>>>>>>> Epoch  34
2022-11-03 21:35:14,153 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:35:18,005 - INFO  - Training [34][   20/  391]   Loss 0.045921   Top1 98.515625   Top5 100.000000   BatchTime 0.192616   LR 0.001000   
2022-11-03 21:35:20,030 - INFO  - Training [34][   40/  391]   Loss 0.047534   Top1 98.242188   Top5 99.980469   BatchTime 0.146937   LR 0.001000   
2022-11-03 21:35:22,059 - INFO  - Training [34][   60/  391]   Loss 0.047676   Top1 98.203125   Top5 99.986979   BatchTime 0.131770   LR 0.001000   
2022-11-03 21:35:24,091 - INFO  - Training [34][   80/  391]   Loss 0.048020   Top1 98.222656   Top5 99.990234   BatchTime 0.124219   LR 0.001000   
2022-11-03 21:35:26,097 - INFO  - Training [34][  100/  391]   Loss 0.046221   Top1 98.320312   Top5 99.992188   BatchTime 0.119440   LR 0.001000   
2022-11-03 21:35:28,115 - INFO  - Training [34][  120/  391]   Loss 0.045739   Top1 98.352865   Top5 99.993490   BatchTime 0.116346   LR 0.001000   
2022-11-03 21:35:30,137 - INFO  - Training [34][  140/  391]   Loss 0.045852   Top1 98.381696   Top5 99.994420   BatchTime 0.114169   LR 0.001000   
2022-11-03 21:35:32,151 - INFO  - Training [34][  160/  391]   Loss 0.046882   Top1 98.344727   Top5 99.995117   BatchTime 0.112489   LR 0.001000   
2022-11-03 21:35:34,161 - INFO  - Training [34][  180/  391]   Loss 0.047594   Top1 98.320312   Top5 99.995660   BatchTime 0.111153   LR 0.001000   
2022-11-03 21:35:36,158 - INFO  - Training [34][  200/  391]   Loss 0.047294   Top1 98.328125   Top5 99.996094   BatchTime 0.110024   LR 0.001000   
2022-11-03 21:35:38,170 - INFO  - Training [34][  220/  391]   Loss 0.047309   Top1 98.359375   Top5 99.996449   BatchTime 0.109166   LR 0.001000   
2022-11-03 21:35:40,157 - INFO  - Training [34][  240/  391]   Loss 0.046792   Top1 98.378906   Top5 99.996745   BatchTime 0.108348   LR 0.001000   
2022-11-03 21:35:42,132 - INFO  - Training [34][  260/  391]   Loss 0.047225   Top1 98.383413   Top5 99.996995   BatchTime 0.107610   LR 0.001000   
2022-11-03 21:35:44,110 - INFO  - Training [34][  280/  391]   Loss 0.047262   Top1 98.395647   Top5 99.997210   BatchTime 0.106986   LR 0.001000   
2022-11-03 21:35:45,984 - INFO  - Training [34][  300/  391]   Loss 0.047365   Top1 98.388021   Top5 99.997396   BatchTime 0.106100   LR 0.001000   
2022-11-03 21:35:47,621 - INFO  - Training [34][  320/  391]   Loss 0.047979   Top1 98.361816   Top5 99.995117   BatchTime 0.104584   LR 0.001000   
2022-11-03 21:35:49,353 - INFO  - Training [34][  340/  391]   Loss 0.048246   Top1 98.345588   Top5 99.995404   BatchTime 0.103526   LR 0.001000   
2022-11-03 21:35:51,023 - INFO  - Training [34][  360/  391]   Loss 0.048792   Top1 98.326823   Top5 99.995660   BatchTime 0.102415   LR 0.001000   
2022-11-03 21:35:52,441 - INFO  - Training [34][  380/  391]   Loss 0.048618   Top1 98.338816   Top5 99.995888   BatchTime 0.100756   LR 0.001000   
2022-11-03 21:35:53,787 - INFO  - ==> Top1: 98.348    Top5: 99.996    Loss: 0.049

2022-11-03 21:35:53,787 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:35:56,500 - INFO  - Validation [34][   20/   79]   Loss 0.386031   Top1 90.546875   Top5 99.648438   BatchTime 0.135597   
2022-11-03 21:35:57,378 - INFO  - Validation [34][   40/   79]   Loss 0.392377   Top1 90.605469   Top5 99.589844   BatchTime 0.089746   
2022-11-03 21:35:58,258 - INFO  - Validation [34][   60/   79]   Loss 0.388167   Top1 90.729167   Top5 99.596354   BatchTime 0.074489   
2022-11-03 21:35:59,331 - INFO  - ==> Top1: 90.750    Top5: 99.620    Loss: 0.383

2022-11-03 21:35:59,363 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:35:59,364 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:35:59,364 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:35:59,531 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:35:59,531 - INFO  - >>>>>>>> Epoch  35
2022-11-03 21:35:59,532 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:36:03,390 - INFO  - Training [35][   20/  391]   Loss 0.050227   Top1 98.398438   Top5 100.000000   BatchTime 0.192864   LR 0.001000   
2022-11-03 21:36:05,389 - INFO  - Training [35][   40/  391]   Loss 0.049556   Top1 98.398438   Top5 100.000000   BatchTime 0.146423   LR 0.001000   
2022-11-03 21:36:07,394 - INFO  - Training [35][   60/  391]   Loss 0.049465   Top1 98.372396   Top5 100.000000   BatchTime 0.131030   LR 0.001000   
2022-11-03 21:36:09,424 - INFO  - Training [35][   80/  391]   Loss 0.047987   Top1 98.408203   Top5 99.990234   BatchTime 0.123645   LR 0.001000   
2022-11-03 21:36:11,435 - INFO  - Training [35][  100/  391]   Loss 0.049700   Top1 98.289062   Top5 99.992188   BatchTime 0.119025   LR 0.001000   
2022-11-03 21:36:13,440 - INFO  - Training [35][  120/  391]   Loss 0.051438   Top1 98.222656   Top5 99.993490   BatchTime 0.115895   LR 0.001000   
2022-11-03 21:36:15,440 - INFO  - Training [35][  140/  391]   Loss 0.050273   Top1 98.253348   Top5 99.994420   BatchTime 0.113621   LR 0.001000   
2022-11-03 21:36:17,445 - INFO  - Training [35][  160/  391]   Loss 0.050155   Top1 98.281250   Top5 99.995117   BatchTime 0.111950   LR 0.001000   
2022-11-03 21:36:19,431 - INFO  - Training [35][  180/  391]   Loss 0.050674   Top1 98.268229   Top5 99.995660   BatchTime 0.110545   LR 0.001000   
2022-11-03 21:36:21,429 - INFO  - Training [35][  200/  391]   Loss 0.050684   Top1 98.269531   Top5 99.996094   BatchTime 0.109481   LR 0.001000   
2022-11-03 21:36:23,453 - INFO  - Training [35][  220/  391]   Loss 0.050403   Top1 98.267045   Top5 99.996449   BatchTime 0.108726   LR 0.001000   
2022-11-03 21:36:25,466 - INFO  - Training [35][  240/  391]   Loss 0.050491   Top1 98.261719   Top5 99.996745   BatchTime 0.108056   LR 0.001000   
2022-11-03 21:36:27,451 - INFO  - Training [35][  260/  391]   Loss 0.049583   Top1 98.293269   Top5 99.996995   BatchTime 0.107379   LR 0.001000   
2022-11-03 21:36:29,435 - INFO  - Training [35][  280/  391]   Loss 0.050478   Top1 98.258929   Top5 99.997210   BatchTime 0.106794   LR 0.001000   
2022-11-03 21:36:31,361 - INFO  - Training [35][  300/  391]   Loss 0.051093   Top1 98.229167   Top5 99.994792   BatchTime 0.106094   LR 0.001000   
2022-11-03 21:36:33,038 - INFO  - Training [35][  320/  391]   Loss 0.050900   Top1 98.234863   Top5 99.995117   BatchTime 0.104704   LR 0.001000   
2022-11-03 21:36:34,664 - INFO  - Training [35][  340/  391]   Loss 0.050639   Top1 98.239890   Top5 99.995404   BatchTime 0.103327   LR 0.001000   
2022-11-03 21:36:36,346 - INFO  - Training [35][  360/  391]   Loss 0.050733   Top1 98.237847   Top5 99.995660   BatchTime 0.102257   LR 0.001000   
2022-11-03 21:36:37,802 - INFO  - Training [35][  380/  391]   Loss 0.050927   Top1 98.238076   Top5 99.995888   BatchTime 0.100706   LR 0.001000   
2022-11-03 21:36:39,104 - INFO  - ==> Top1: 98.228    Top5: 99.996    Loss: 0.051

2022-11-03 21:36:39,104 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:36:41,825 - INFO  - Validation [35][   20/   79]   Loss 0.383653   Top1 90.312500   Top5 99.609375   BatchTime 0.135926   
2022-11-03 21:36:42,728 - INFO  - Validation [35][   40/   79]   Loss 0.392278   Top1 90.429688   Top5 99.531250   BatchTime 0.090554   
2022-11-03 21:36:43,626 - INFO  - Validation [35][   60/   79]   Loss 0.389545   Top1 90.598958   Top5 99.557292   BatchTime 0.075330   
2022-11-03 21:36:44,781 - INFO  - ==> Top1: 90.560    Top5: 99.580    Loss: 0.383

2022-11-03 21:36:44,820 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:36:44,821 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:36:44,821 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:36:44,924 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:36:44,924 - INFO  - >>>>>>>> Epoch  36
2022-11-03 21:36:44,926 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:36:48,805 - INFO  - Training [36][   20/  391]   Loss 0.049095   Top1 98.242188   Top5 100.000000   BatchTime 0.193920   LR 0.001000   
2022-11-03 21:36:50,844 - INFO  - Training [36][   40/  391]   Loss 0.052313   Top1 98.203125   Top5 100.000000   BatchTime 0.147947   LR 0.001000   
2022-11-03 21:36:52,846 - INFO  - Training [36][   60/  391]   Loss 0.049255   Top1 98.398438   Top5 100.000000   BatchTime 0.131996   LR 0.001000   
2022-11-03 21:36:54,849 - INFO  - Training [36][   80/  391]   Loss 0.048092   Top1 98.417969   Top5 100.000000   BatchTime 0.124025   LR 0.001000   
2022-11-03 21:36:56,856 - INFO  - Training [36][  100/  391]   Loss 0.046540   Top1 98.437500   Top5 100.000000   BatchTime 0.119297   LR 0.001000   
2022-11-03 21:36:58,835 - INFO  - Training [36][  120/  391]   Loss 0.046842   Top1 98.417969   Top5 100.000000   BatchTime 0.115904   LR 0.001000   
2022-11-03 21:37:00,836 - INFO  - Training [36][  140/  391]   Loss 0.048100   Top1 98.348214   Top5 100.000000   BatchTime 0.113637   LR 0.001000   
2022-11-03 21:37:02,841 - INFO  - Training [36][  160/  391]   Loss 0.048171   Top1 98.315430   Top5 100.000000   BatchTime 0.111963   LR 0.001000   
2022-11-03 21:37:04,854 - INFO  - Training [36][  180/  391]   Loss 0.048242   Top1 98.307292   Top5 100.000000   BatchTime 0.110709   LR 0.001000   
2022-11-03 21:37:06,872 - INFO  - Training [36][  200/  391]   Loss 0.048847   Top1 98.269531   Top5 100.000000   BatchTime 0.109727   LR 0.001000   
2022-11-03 21:37:08,874 - INFO  - Training [36][  220/  391]   Loss 0.048279   Top1 98.288352   Top5 100.000000   BatchTime 0.108850   LR 0.001000   
2022-11-03 21:37:10,854 - INFO  - Training [36][  240/  391]   Loss 0.048397   Top1 98.300781   Top5 99.996745   BatchTime 0.108031   LR 0.001000   
2022-11-03 21:37:12,852 - INFO  - Training [36][  260/  391]   Loss 0.048955   Top1 98.266226   Top5 99.996995   BatchTime 0.107405   LR 0.001000   
2022-11-03 21:37:14,844 - INFO  - Training [36][  280/  391]   Loss 0.048919   Top1 98.272879   Top5 99.997210   BatchTime 0.106845   LR 0.001000   
2022-11-03 21:37:16,703 - INFO  - Training [36][  300/  391]   Loss 0.049354   Top1 98.255208   Top5 99.994792   BatchTime 0.105919   LR 0.001000   
2022-11-03 21:37:18,349 - INFO  - Training [36][  320/  391]   Loss 0.049447   Top1 98.244629   Top5 99.995117   BatchTime 0.104443   LR 0.001000   
2022-11-03 21:37:19,946 - INFO  - Training [36][  340/  391]   Loss 0.049229   Top1 98.253676   Top5 99.995404   BatchTime 0.102997   LR 0.001000   
2022-11-03 21:37:21,614 - INFO  - Training [36][  360/  391]   Loss 0.049212   Top1 98.259549   Top5 99.995660   BatchTime 0.101907   LR 0.001000   
2022-11-03 21:37:23,198 - INFO  - Training [36][  380/  391]   Loss 0.049052   Top1 98.260691   Top5 99.995888   BatchTime 0.100713   LR 0.001000   
2022-11-03 21:37:24,608 - INFO  - ==> Top1: 98.268    Top5: 99.996    Loss: 0.049

2022-11-03 21:37:24,609 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:37:27,332 - INFO  - Validation [36][   20/   79]   Loss 0.394846   Top1 90.351562   Top5 99.687500   BatchTime 0.136040   
2022-11-03 21:37:28,227 - INFO  - Validation [36][   40/   79]   Loss 0.398655   Top1 90.488281   Top5 99.648438   BatchTime 0.090410   
2022-11-03 21:37:29,137 - INFO  - Validation [36][   60/   79]   Loss 0.390244   Top1 90.703125   Top5 99.674479   BatchTime 0.075433   
2022-11-03 21:37:30,227 - INFO  - ==> Top1: 90.520    Top5: 99.680    Loss: 0.387

2022-11-03 21:37:30,260 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:37:30,261 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:37:30,261 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:37:30,358 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:37:30,358 - INFO  - >>>>>>>> Epoch  37
2022-11-03 21:37:30,360 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:37:34,246 - INFO  - Training [37][   20/  391]   Loss 0.054917   Top1 97.929688   Top5 100.000000   BatchTime 0.194310   LR 0.001000   
2022-11-03 21:37:36,255 - INFO  - Training [37][   40/  391]   Loss 0.051738   Top1 98.085938   Top5 100.000000   BatchTime 0.147370   LR 0.001000   
2022-11-03 21:37:38,278 - INFO  - Training [37][   60/  391]   Loss 0.051945   Top1 98.059896   Top5 100.000000   BatchTime 0.131970   LR 0.001000   
2022-11-03 21:37:40,297 - INFO  - Training [37][   80/  391]   Loss 0.051175   Top1 98.144531   Top5 100.000000   BatchTime 0.124208   LR 0.001000   
2022-11-03 21:37:42,323 - INFO  - Training [37][  100/  391]   Loss 0.049164   Top1 98.250000   Top5 100.000000   BatchTime 0.119627   LR 0.001000   
2022-11-03 21:37:44,318 - INFO  - Training [37][  120/  391]   Loss 0.048807   Top1 98.216146   Top5 100.000000   BatchTime 0.116312   LR 0.001000   
2022-11-03 21:37:46,312 - INFO  - Training [37][  140/  391]   Loss 0.048928   Top1 98.208705   Top5 100.000000   BatchTime 0.113937   LR 0.001000   
2022-11-03 21:37:48,322 - INFO  - Training [37][  160/  391]   Loss 0.049829   Top1 98.178711   Top5 100.000000   BatchTime 0.112262   LR 0.001000   
2022-11-03 21:37:50,311 - INFO  - Training [37][  180/  391]   Loss 0.049008   Top1 98.220486   Top5 100.000000   BatchTime 0.110834   LR 0.001000   
2022-11-03 21:37:52,322 - INFO  - Training [37][  200/  391]   Loss 0.048264   Top1 98.246094   Top5 100.000000   BatchTime 0.109805   LR 0.001000   
2022-11-03 21:37:54,318 - INFO  - Training [37][  220/  391]   Loss 0.048651   Top1 98.242188   Top5 99.996449   BatchTime 0.108899   LR 0.001000   
2022-11-03 21:37:56,313 - INFO  - Training [37][  240/  391]   Loss 0.048488   Top1 98.238932   Top5 99.996745   BatchTime 0.108135   LR 0.001000   
2022-11-03 21:37:58,281 - INFO  - Training [37][  260/  391]   Loss 0.048446   Top1 98.236178   Top5 99.996995   BatchTime 0.107385   LR 0.001000   
2022-11-03 21:38:00,265 - INFO  - Training [37][  280/  391]   Loss 0.049129   Top1 98.233817   Top5 99.997210   BatchTime 0.106801   LR 0.001000   
2022-11-03 21:38:02,093 - INFO  - Training [37][  300/  391]   Loss 0.049148   Top1 98.244792   Top5 99.997396   BatchTime 0.105775   LR 0.001000   
2022-11-03 21:38:03,729 - INFO  - Training [37][  320/  391]   Loss 0.049510   Top1 98.237305   Top5 99.995117   BatchTime 0.104277   LR 0.001000   
2022-11-03 21:38:05,342 - INFO  - Training [37][  340/  391]   Loss 0.049489   Top1 98.237592   Top5 99.995404   BatchTime 0.102885   LR 0.001000   
2022-11-03 21:38:07,035 - INFO  - Training [37][  360/  391]   Loss 0.049315   Top1 98.246528   Top5 99.995660   BatchTime 0.101873   LR 0.001000   
2022-11-03 21:38:08,499 - INFO  - Training [37][  380/  391]   Loss 0.049455   Top1 98.244243   Top5 99.995888   BatchTime 0.100362   LR 0.001000   
2022-11-03 21:38:09,817 - INFO  - ==> Top1: 98.244    Top5: 99.996    Loss: 0.049

2022-11-03 21:38:09,818 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:38:12,551 - INFO  - Validation [37][   20/   79]   Loss 0.388792   Top1 90.390625   Top5 99.687500   BatchTime 0.136555   
2022-11-03 21:38:13,464 - INFO  - Validation [37][   40/   79]   Loss 0.398113   Top1 90.390625   Top5 99.648438   BatchTime 0.091101   
2022-11-03 21:38:14,383 - INFO  - Validation [37][   60/   79]   Loss 0.389254   Top1 90.716146   Top5 99.674479   BatchTime 0.076057   
2022-11-03 21:38:15,486 - INFO  - ==> Top1: 90.610    Top5: 99.700    Loss: 0.385

2022-11-03 21:38:15,521 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:38:15,522 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:38:15,522 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:38:15,656 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:38:15,656 - INFO  - >>>>>>>> Epoch  38
2022-11-03 21:38:15,657 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:38:19,504 - INFO  - Training [38][   20/  391]   Loss 0.045779   Top1 98.750000   Top5 100.000000   BatchTime 0.192326   LR 0.001000   
2022-11-03 21:38:21,524 - INFO  - Training [38][   40/  391]   Loss 0.045848   Top1 98.671875   Top5 100.000000   BatchTime 0.146683   LR 0.001000   
2022-11-03 21:38:23,522 - INFO  - Training [38][   60/  391]   Loss 0.043072   Top1 98.776042   Top5 100.000000   BatchTime 0.131083   LR 0.001000   
2022-11-03 21:38:25,533 - INFO  - Training [38][   80/  391]   Loss 0.043778   Top1 98.740234   Top5 100.000000   BatchTime 0.123447   LR 0.001000   
2022-11-03 21:38:27,556 - INFO  - Training [38][  100/  391]   Loss 0.043832   Top1 98.687500   Top5 100.000000   BatchTime 0.118983   LR 0.001000   
2022-11-03 21:38:29,563 - INFO  - Training [38][  120/  391]   Loss 0.045149   Top1 98.587240   Top5 100.000000   BatchTime 0.115881   LR 0.001000   
2022-11-03 21:38:31,577 - INFO  - Training [38][  140/  391]   Loss 0.045180   Top1 98.560268   Top5 100.000000   BatchTime 0.113714   LR 0.001000   
2022-11-03 21:38:33,586 - INFO  - Training [38][  160/  391]   Loss 0.045893   Top1 98.525391   Top5 100.000000   BatchTime 0.112056   LR 0.001000   
2022-11-03 21:38:35,588 - INFO  - Training [38][  180/  391]   Loss 0.046141   Top1 98.515625   Top5 100.000000   BatchTime 0.110724   LR 0.001000   
2022-11-03 21:38:37,589 - INFO  - Training [38][  200/  391]   Loss 0.046963   Top1 98.480469   Top5 100.000000   BatchTime 0.109659   LR 0.001000   
2022-11-03 21:38:39,592 - INFO  - Training [38][  220/  391]   Loss 0.046811   Top1 98.469460   Top5 100.000000   BatchTime 0.108793   LR 0.001000   
2022-11-03 21:38:41,566 - INFO  - Training [38][  240/  391]   Loss 0.046856   Top1 98.447266   Top5 100.000000   BatchTime 0.107951   LR 0.001000   
2022-11-03 21:38:43,540 - INFO  - Training [38][  260/  391]   Loss 0.047190   Top1 98.446514   Top5 100.000000   BatchTime 0.107240   LR 0.001000   
2022-11-03 21:38:45,527 - INFO  - Training [38][  280/  391]   Loss 0.047039   Top1 98.440290   Top5 100.000000   BatchTime 0.106676   LR 0.001000   
2022-11-03 21:38:47,384 - INFO  - Training [38][  300/  391]   Loss 0.046831   Top1 98.445312   Top5 100.000000   BatchTime 0.105753   LR 0.001000   
2022-11-03 21:38:49,096 - INFO  - Training [38][  320/  391]   Loss 0.046656   Top1 98.439941   Top5 100.000000   BatchTime 0.104495   LR 0.001000   
2022-11-03 21:38:50,717 - INFO  - Training [38][  340/  391]   Loss 0.046773   Top1 98.428309   Top5 100.000000   BatchTime 0.103117   LR 0.001000   
2022-11-03 21:38:52,356 - INFO  - Training [38][  360/  391]   Loss 0.046059   Top1 98.450521   Top5 100.000000   BatchTime 0.101940   LR 0.001000   
2022-11-03 21:38:53,802 - INFO  - Training [38][  380/  391]   Loss 0.045995   Top1 98.458059   Top5 100.000000   BatchTime 0.100378   LR 0.001000   
2022-11-03 21:38:55,198 - INFO  - ==> Top1: 98.458    Top5: 100.000    Loss: 0.046

2022-11-03 21:38:55,199 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:38:57,924 - INFO  - Validation [38][   20/   79]   Loss 0.380235   Top1 90.546875   Top5 99.648438   BatchTime 0.136172   
2022-11-03 21:38:58,832 - INFO  - Validation [38][   40/   79]   Loss 0.391634   Top1 90.527344   Top5 99.628906   BatchTime 0.090781   
2022-11-03 21:38:59,708 - INFO  - Validation [38][   60/   79]   Loss 0.387797   Top1 90.690104   Top5 99.661458   BatchTime 0.075111   
2022-11-03 21:39:00,809 - INFO  - ==> Top1: 90.590    Top5: 99.680    Loss: 0.384

2022-11-03 21:39:00,837 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:39:00,837 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:39:00,838 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:39:00,934 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:39:00,934 - INFO  - >>>>>>>> Epoch  39
2022-11-03 21:39:00,935 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:39:04,922 - INFO  - Training [39][   20/  391]   Loss 0.045397   Top1 98.476562   Top5 100.000000   BatchTime 0.199339   LR 0.001000   
2022-11-03 21:39:06,912 - INFO  - Training [39][   40/  391]   Loss 0.044114   Top1 98.554688   Top5 100.000000   BatchTime 0.149429   LR 0.001000   
2022-11-03 21:39:08,924 - INFO  - Training [39][   60/  391]   Loss 0.046260   Top1 98.489583   Top5 100.000000   BatchTime 0.133140   LR 0.001000   
2022-11-03 21:39:10,926 - INFO  - Training [39][   80/  391]   Loss 0.050329   Top1 98.300781   Top5 100.000000   BatchTime 0.124890   LR 0.001000   
2022-11-03 21:39:12,927 - INFO  - Training [39][  100/  391]   Loss 0.050372   Top1 98.273438   Top5 100.000000   BatchTime 0.119917   LR 0.001000   
2022-11-03 21:39:14,945 - INFO  - Training [39][  120/  391]   Loss 0.048401   Top1 98.313802   Top5 100.000000   BatchTime 0.116744   LR 0.001000   
2022-11-03 21:39:16,951 - INFO  - Training [39][  140/  391]   Loss 0.049314   Top1 98.281250   Top5 100.000000   BatchTime 0.114396   LR 0.001000   
2022-11-03 21:39:18,949 - INFO  - Training [39][  160/  391]   Loss 0.048998   Top1 98.320312   Top5 100.000000   BatchTime 0.112584   LR 0.001000   
2022-11-03 21:39:20,966 - INFO  - Training [39][  180/  391]   Loss 0.048429   Top1 98.350694   Top5 100.000000   BatchTime 0.111283   LR 0.001000   
2022-11-03 21:39:22,971 - INFO  - Training [39][  200/  391]   Loss 0.048743   Top1 98.335938   Top5 100.000000   BatchTime 0.110177   LR 0.001000   
2022-11-03 21:39:24,978 - INFO  - Training [39][  220/  391]   Loss 0.048804   Top1 98.309659   Top5 99.996449   BatchTime 0.109283   LR 0.001000   
2022-11-03 21:39:26,957 - INFO  - Training [39][  240/  391]   Loss 0.048056   Top1 98.336589   Top5 99.996745   BatchTime 0.108421   LR 0.001000   
2022-11-03 21:39:28,934 - INFO  - Training [39][  260/  391]   Loss 0.048672   Top1 98.332332   Top5 99.996995   BatchTime 0.107687   LR 0.001000   
2022-11-03 21:39:30,920 - INFO  - Training [39][  280/  391]   Loss 0.049060   Top1 98.295201   Top5 99.997210   BatchTime 0.107088   LR 0.001000   
2022-11-03 21:39:32,708 - INFO  - Training [39][  300/  391]   Loss 0.048950   Top1 98.289062   Top5 99.997396   BatchTime 0.105907   LR 0.001000   
2022-11-03 21:39:34,414 - INFO  - Training [39][  320/  391]   Loss 0.048971   Top1 98.293457   Top5 99.995117   BatchTime 0.104619   LR 0.001000   
2022-11-03 21:39:36,017 - INFO  - Training [39][  340/  391]   Loss 0.048666   Top1 98.327206   Top5 99.995404   BatchTime 0.103181   LR 0.001000   
2022-11-03 21:39:37,663 - INFO  - Training [39][  360/  391]   Loss 0.048858   Top1 98.300781   Top5 99.995660   BatchTime 0.102021   LR 0.001000   
2022-11-03 21:39:39,105 - INFO  - Training [39][  380/  391]   Loss 0.048797   Top1 98.297697   Top5 99.995888   BatchTime 0.100444   LR 0.001000   
2022-11-03 21:39:40,335 - INFO  - ==> Top1: 98.304    Top5: 99.996    Loss: 0.049

2022-11-03 21:39:40,336 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:39:42,820 - INFO  - Validation [39][   20/   79]   Loss 0.387769   Top1 90.273438   Top5 99.726562   BatchTime 0.124156   
2022-11-03 21:39:43,333 - INFO  - Validation [39][   40/   79]   Loss 0.395222   Top1 90.410156   Top5 99.609375   BatchTime 0.074897   
2022-11-03 21:39:43,850 - INFO  - Validation [39][   60/   79]   Loss 0.389268   Top1 90.611979   Top5 99.648438   BatchTime 0.058545   
2022-11-03 21:39:44,607 - INFO  - ==> Top1: 90.580    Top5: 99.660    Loss: 0.384

2022-11-03 21:39:44,632 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:39:44,633 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:39:44,634 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.660   Top5: 99.570] Sparsity : 0.807
2022-11-03 21:39:44,748 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:39:44,748 - INFO  - >>>>>>>> Epoch  40
2022-11-03 21:39:44,749 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:39:48,066 - INFO  - Training [40][   20/  391]   Loss 0.042503   Top1 98.828125   Top5 100.000000   BatchTime 0.165847   LR 0.000100   
2022-11-03 21:39:49,529 - INFO  - Training [40][   40/  391]   Loss 0.042162   Top1 98.593750   Top5 100.000000   BatchTime 0.119495   LR 0.000100   
2022-11-03 21:39:51,081 - INFO  - Training [40][   60/  391]   Loss 0.042998   Top1 98.619792   Top5 100.000000   BatchTime 0.105527   LR 0.000100   
2022-11-03 21:39:52,570 - INFO  - Training [40][   80/  391]   Loss 0.046550   Top1 98.486328   Top5 99.990234   BatchTime 0.097755   LR 0.000100   
2022-11-03 21:39:54,100 - INFO  - Training [40][  100/  391]   Loss 0.047769   Top1 98.437500   Top5 99.992188   BatchTime 0.093506   LR 0.000100   
2022-11-03 21:39:55,614 - INFO  - Training [40][  120/  391]   Loss 0.047117   Top1 98.457031   Top5 99.993490   BatchTime 0.090534   LR 0.000100   
2022-11-03 21:39:57,169 - INFO  - Training [40][  140/  391]   Loss 0.046947   Top1 98.426339   Top5 99.994420   BatchTime 0.088711   LR 0.000100   
2022-11-03 21:39:58,672 - INFO  - Training [40][  160/  391]   Loss 0.046884   Top1 98.388672   Top5 99.995117   BatchTime 0.087017   LR 0.000100   
2022-11-03 21:40:00,273 - INFO  - Training [40][  180/  391]   Loss 0.046572   Top1 98.376736   Top5 99.995660   BatchTime 0.086238   LR 0.000100   
2022-11-03 21:40:01,862 - INFO  - Training [40][  200/  391]   Loss 0.046895   Top1 98.378906   Top5 99.996094   BatchTime 0.085559   LR 0.000100   
2022-11-03 21:40:03,505 - INFO  - Training [40][  220/  391]   Loss 0.045902   Top1 98.401989   Top5 99.996449   BatchTime 0.085249   LR 0.000100   
2022-11-03 21:40:05,127 - INFO  - Training [40][  240/  391]   Loss 0.046164   Top1 98.395182   Top5 99.996745   BatchTime 0.084904   LR 0.000100   
2022-11-03 21:40:06,772 - INFO  - Training [40][  260/  391]   Loss 0.046176   Top1 98.386418   Top5 99.996995   BatchTime 0.084699   LR 0.000100   
2022-11-03 21:40:08,693 - INFO  - Training [40][  280/  391]   Loss 0.046549   Top1 98.378906   Top5 99.997210   BatchTime 0.085510   LR 0.000100   
2022-11-03 21:40:10,713 - INFO  - Training [40][  300/  391]   Loss 0.046844   Top1 98.377604   Top5 99.994792   BatchTime 0.086542   LR 0.000100   
2022-11-03 21:40:12,744 - INFO  - Training [40][  320/  391]   Loss 0.046839   Top1 98.386230   Top5 99.995117   BatchTime 0.087481   LR 0.000100   
2022-11-03 21:40:14,765 - INFO  - Training [40][  340/  391]   Loss 0.046684   Top1 98.391544   Top5 99.995404   BatchTime 0.088278   LR 0.000100   
2022-11-03 21:40:16,749 - INFO  - Training [40][  360/  391]   Loss 0.046463   Top1 98.402778   Top5 99.995660   BatchTime 0.088885   LR 0.000100   
2022-11-03 21:40:18,760 - INFO  - Training [40][  380/  391]   Loss 0.046519   Top1 98.410773   Top5 99.995888   BatchTime 0.089501   LR 0.000100   
2022-11-03 21:40:20,100 - INFO  - ==> Top1: 98.408    Top5: 99.996    Loss: 0.047

2022-11-03 21:40:20,101 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:40:22,832 - INFO  - Validation [40][   20/   79]   Loss 0.382097   Top1 90.898438   Top5 99.765625   BatchTime 0.136502   
2022-11-03 21:40:23,731 - INFO  - Validation [40][   40/   79]   Loss 0.396310   Top1 90.625000   Top5 99.648438   BatchTime 0.090709   
2022-11-03 21:40:24,620 - INFO  - Validation [40][   60/   79]   Loss 0.388228   Top1 90.833333   Top5 99.661458   BatchTime 0.075288   
2022-11-03 21:40:25,724 - INFO  - ==> Top1: 90.710    Top5: 99.680    Loss: 0.385

2022-11-03 21:40:25,771 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:40:25,772 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 90.710   Top5: 99.680] Sparsity : 0.808
2022-11-03 21:40:25,772 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.700   Top5: 99.560] Sparsity : 0.806
2022-11-03 21:40:25,853 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:40:25,853 - INFO  - >>>>>>>> Epoch  41
2022-11-03 21:40:25,854 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:40:29,727 - INFO  - Training [41][   20/  391]   Loss 0.048394   Top1 98.164062   Top5 100.000000   BatchTime 0.193652   LR 0.000100   
2022-11-03 21:40:31,744 - INFO  - Training [41][   40/  391]   Loss 0.048942   Top1 98.300781   Top5 100.000000   BatchTime 0.147255   LR 0.000100   
2022-11-03 21:40:33,749 - INFO  - Training [41][   60/  391]   Loss 0.051007   Top1 98.177083   Top5 100.000000   BatchTime 0.131590   LR 0.000100   
2022-11-03 21:40:35,857 - INFO  - Training [41][   80/  391]   Loss 0.048314   Top1 98.222656   Top5 100.000000   BatchTime 0.125039   LR 0.000100   
2022-11-03 21:40:37,872 - INFO  - Training [41][  100/  391]   Loss 0.050647   Top1 98.140625   Top5 100.000000   BatchTime 0.120179   LR 0.000100   
2022-11-03 21:40:39,895 - INFO  - Training [41][  120/  391]   Loss 0.049519   Top1 98.196615   Top5 100.000000   BatchTime 0.117010   LR 0.000100   
2022-11-03 21:40:41,873 - INFO  - Training [41][  140/  391]   Loss 0.048331   Top1 98.275670   Top5 100.000000   BatchTime 0.114421   LR 0.000100   
2022-11-03 21:40:43,817 - INFO  - Training [41][  160/  391]   Loss 0.047841   Top1 98.271484   Top5 100.000000   BatchTime 0.112265   LR 0.000100   
2022-11-03 21:40:45,783 - INFO  - Training [41][  180/  391]   Loss 0.046856   Top1 98.333333   Top5 100.000000   BatchTime 0.110713   LR 0.000100   
2022-11-03 21:40:47,506 - INFO  - Training [41][  200/  391]   Loss 0.047137   Top1 98.296875   Top5 100.000000   BatchTime 0.108259   LR 0.000100   
2022-11-03 21:40:49,170 - INFO  - Training [41][  220/  391]   Loss 0.048355   Top1 98.288352   Top5 100.000000   BatchTime 0.105978   LR 0.000100   
2022-11-03 21:40:50,802 - INFO  - Training [41][  240/  391]   Loss 0.047918   Top1 98.300781   Top5 100.000000   BatchTime 0.103948   LR 0.000100   
2022-11-03 21:40:52,511 - INFO  - Training [41][  260/  391]   Loss 0.047835   Top1 98.320312   Top5 100.000000   BatchTime 0.102523   LR 0.000100   
2022-11-03 21:40:54,267 - INFO  - Training [41][  280/  391]   Loss 0.047082   Top1 98.351004   Top5 100.000000   BatchTime 0.101474   LR 0.000100   
2022-11-03 21:40:56,288 - INFO  - Training [41][  300/  391]   Loss 0.047039   Top1 98.335938   Top5 100.000000   BatchTime 0.101443   LR 0.000100   
2022-11-03 21:40:58,316 - INFO  - Training [41][  320/  391]   Loss 0.046756   Top1 98.347168   Top5 100.000000   BatchTime 0.101442   LR 0.000100   
2022-11-03 21:41:00,312 - INFO  - Training [41][  340/  391]   Loss 0.046757   Top1 98.357077   Top5 100.000000   BatchTime 0.101346   LR 0.000100   
2022-11-03 21:41:02,288 - INFO  - Training [41][  360/  391]   Loss 0.046810   Top1 98.350694   Top5 100.000000   BatchTime 0.101203   LR 0.000100   
2022-11-03 21:41:04,264 - INFO  - Training [41][  380/  391]   Loss 0.047013   Top1 98.349095   Top5 100.000000   BatchTime 0.101078   LR 0.000100   
2022-11-03 21:41:05,606 - INFO  - ==> Top1: 98.330    Top5: 100.000    Loss: 0.048

2022-11-03 21:41:05,607 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:41:08,314 - INFO  - Validation [41][   20/   79]   Loss 0.383688   Top1 90.507812   Top5 99.687500   BatchTime 0.135274   
2022-11-03 21:41:09,199 - INFO  - Validation [41][   40/   79]   Loss 0.389859   Top1 90.683594   Top5 99.628906   BatchTime 0.089760   
2022-11-03 21:41:10,063 - INFO  - Validation [41][   60/   79]   Loss 0.384982   Top1 90.781250   Top5 99.622396   BatchTime 0.074236   
2022-11-03 21:41:11,206 - INFO  - ==> Top1: 90.800    Top5: 99.640    Loss: 0.382

2022-11-03 21:41:11,240 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:41:11,241 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:41:11,241 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 90.710   Top5: 99.680] Sparsity : 0.808
2022-11-03 21:41:11,422 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:41:11,423 - INFO  - >>>>>>>> Epoch  42
2022-11-03 21:41:11,424 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:41:15,257 - INFO  - Training [42][   20/  391]   Loss 0.056390   Top1 97.968750   Top5 100.000000   BatchTime 0.191650   LR 0.000100   
2022-11-03 21:41:17,258 - INFO  - Training [42][   40/  391]   Loss 0.048914   Top1 98.183594   Top5 100.000000   BatchTime 0.145863   LR 0.000100   
2022-11-03 21:41:19,250 - INFO  - Training [42][   60/  391]   Loss 0.048844   Top1 98.242188   Top5 100.000000   BatchTime 0.130437   LR 0.000100   
2022-11-03 21:41:21,258 - INFO  - Training [42][   80/  391]   Loss 0.049313   Top1 98.300781   Top5 100.000000   BatchTime 0.122918   LR 0.000100   
2022-11-03 21:41:23,267 - INFO  - Training [42][  100/  391]   Loss 0.048370   Top1 98.351562   Top5 100.000000   BatchTime 0.118432   LR 0.000100   
2022-11-03 21:41:25,271 - INFO  - Training [42][  120/  391]   Loss 0.048839   Top1 98.307292   Top5 100.000000   BatchTime 0.115393   LR 0.000100   
2022-11-03 21:41:27,246 - INFO  - Training [42][  140/  391]   Loss 0.047857   Top1 98.381696   Top5 100.000000   BatchTime 0.113015   LR 0.000100   
2022-11-03 21:41:29,228 - INFO  - Training [42][  160/  391]   Loss 0.047882   Top1 98.354492   Top5 100.000000   BatchTime 0.111271   LR 0.000100   
2022-11-03 21:41:31,196 - INFO  - Training [42][  180/  391]   Loss 0.047714   Top1 98.350694   Top5 100.000000   BatchTime 0.109844   LR 0.000100   
2022-11-03 21:41:32,801 - INFO  - Training [42][  200/  391]   Loss 0.047912   Top1 98.347656   Top5 100.000000   BatchTime 0.106881   LR 0.000100   
2022-11-03 21:41:34,531 - INFO  - Training [42][  220/  391]   Loss 0.047952   Top1 98.359375   Top5 100.000000   BatchTime 0.105028   LR 0.000100   
2022-11-03 21:41:36,135 - INFO  - Training [42][  240/  391]   Loss 0.047948   Top1 98.352865   Top5 100.000000   BatchTime 0.102959   LR 0.000100   
2022-11-03 21:41:37,860 - INFO  - Training [42][  260/  391]   Loss 0.047629   Top1 98.350361   Top5 100.000000   BatchTime 0.101675   LR 0.000100   
2022-11-03 21:41:39,696 - INFO  - Training [42][  280/  391]   Loss 0.047140   Top1 98.362165   Top5 100.000000   BatchTime 0.100970   LR 0.000100   
2022-11-03 21:41:41,717 - INFO  - Training [42][  300/  391]   Loss 0.047039   Top1 98.361979   Top5 100.000000   BatchTime 0.100975   LR 0.000100   
2022-11-03 21:41:43,737 - INFO  - Training [42][  320/  391]   Loss 0.047095   Top1 98.347168   Top5 100.000000   BatchTime 0.100975   LR 0.000100   
2022-11-03 21:41:45,730 - INFO  - Training [42][  340/  391]   Loss 0.047008   Top1 98.345588   Top5 100.000000   BatchTime 0.100897   LR 0.000100   
2022-11-03 21:41:47,712 - INFO  - Training [42][  360/  391]   Loss 0.046703   Top1 98.359375   Top5 100.000000   BatchTime 0.100798   LR 0.000100   
2022-11-03 21:41:49,682 - INFO  - Training [42][  380/  391]   Loss 0.046835   Top1 98.353207   Top5 100.000000   BatchTime 0.100676   LR 0.000100   
2022-11-03 21:41:51,017 - INFO  - ==> Top1: 98.366    Top5: 100.000    Loss: 0.047

2022-11-03 21:41:51,018 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:41:53,742 - INFO  - Validation [42][   20/   79]   Loss 0.386098   Top1 90.664062   Top5 99.648438   BatchTime 0.136077   
2022-11-03 21:41:54,633 - INFO  - Validation [42][   40/   79]   Loss 0.391262   Top1 90.644531   Top5 99.589844   BatchTime 0.090326   
2022-11-03 21:41:55,531 - INFO  - Validation [42][   60/   79]   Loss 0.388939   Top1 90.677083   Top5 99.609375   BatchTime 0.075180   
2022-11-03 21:41:56,638 - INFO  - ==> Top1: 90.620    Top5: 99.650    Loss: 0.386

2022-11-03 21:41:56,668 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:41:56,669 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:41:56,669 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 90.710   Top5: 99.680] Sparsity : 0.808
2022-11-03 21:41:56,778 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:41:56,778 - INFO  - >>>>>>>> Epoch  43
2022-11-03 21:41:56,780 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:42:00,647 - INFO  - Training [43][   20/  391]   Loss 0.053000   Top1 98.437500   Top5 100.000000   BatchTime 0.193342   LR 0.000100   
2022-11-03 21:42:02,651 - INFO  - Training [43][   40/  391]   Loss 0.053646   Top1 98.261719   Top5 100.000000   BatchTime 0.146778   LR 0.000100   
2022-11-03 21:42:04,652 - INFO  - Training [43][   60/  391]   Loss 0.049413   Top1 98.372396   Top5 100.000000   BatchTime 0.131201   LR 0.000100   
2022-11-03 21:42:06,669 - INFO  - Training [43][   80/  391]   Loss 0.048256   Top1 98.417969   Top5 100.000000   BatchTime 0.123615   LR 0.000100   
2022-11-03 21:42:08,665 - INFO  - Training [43][  100/  391]   Loss 0.048659   Top1 98.382812   Top5 100.000000   BatchTime 0.118848   LR 0.000100   
2022-11-03 21:42:10,752 - INFO  - Training [43][  120/  391]   Loss 0.049692   Top1 98.359375   Top5 100.000000   BatchTime 0.116431   LR 0.000100   
2022-11-03 21:42:12,732 - INFO  - Training [43][  140/  391]   Loss 0.048447   Top1 98.431920   Top5 100.000000   BatchTime 0.113940   LR 0.000100   
2022-11-03 21:42:14,697 - INFO  - Training [43][  160/  391]   Loss 0.047831   Top1 98.452148   Top5 100.000000   BatchTime 0.111984   LR 0.000100   
2022-11-03 21:42:16,727 - INFO  - Training [43][  180/  391]   Loss 0.047705   Top1 98.454861   Top5 100.000000   BatchTime 0.110813   LR 0.000100   
2022-11-03 21:42:18,201 - INFO  - Training [43][  200/  391]   Loss 0.047212   Top1 98.472656   Top5 100.000000   BatchTime 0.107104   LR 0.000100   
2022-11-03 21:42:19,926 - INFO  - Training [43][  220/  391]   Loss 0.046782   Top1 98.469460   Top5 99.996449   BatchTime 0.105208   LR 0.000100   
2022-11-03 21:42:21,599 - INFO  - Training [43][  240/  391]   Loss 0.047171   Top1 98.453776   Top5 99.996745   BatchTime 0.103413   LR 0.000100   
2022-11-03 21:42:23,280 - INFO  - Training [43][  260/  391]   Loss 0.047212   Top1 98.452524   Top5 99.993990   BatchTime 0.101923   LR 0.000100   
2022-11-03 21:42:25,106 - INFO  - Training [43][  280/  391]   Loss 0.046806   Top1 98.465402   Top5 99.994420   BatchTime 0.101162   LR 0.000100   
2022-11-03 21:42:27,115 - INFO  - Training [43][  300/  391]   Loss 0.046936   Top1 98.468750   Top5 99.994792   BatchTime 0.101115   LR 0.000100   
2022-11-03 21:42:29,169 - INFO  - Training [43][  320/  391]   Loss 0.046934   Top1 98.464355   Top5 99.995117   BatchTime 0.101215   LR 0.000100   
2022-11-03 21:42:31,172 - INFO  - Training [43][  340/  391]   Loss 0.046822   Top1 98.469669   Top5 99.995404   BatchTime 0.101150   LR 0.000100   
2022-11-03 21:42:33,151 - INFO  - Training [43][  360/  391]   Loss 0.046782   Top1 98.463542   Top5 99.995660   BatchTime 0.101029   LR 0.000100   
2022-11-03 21:42:35,133 - INFO  - Training [43][  380/  391]   Loss 0.047005   Top1 98.458059   Top5 99.993832   BatchTime 0.100928   LR 0.000100   
2022-11-03 21:42:36,492 - INFO  - ==> Top1: 98.442    Top5: 99.994    Loss: 0.047

2022-11-03 21:42:36,493 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:42:39,205 - INFO  - Validation [43][   20/   79]   Loss 0.384858   Top1 90.390625   Top5 99.609375   BatchTime 0.135512   
2022-11-03 21:42:40,117 - INFO  - Validation [43][   40/   79]   Loss 0.393503   Top1 90.585938   Top5 99.570312   BatchTime 0.090576   
2022-11-03 21:42:40,990 - INFO  - Validation [43][   60/   79]   Loss 0.385885   Top1 90.729167   Top5 99.609375   BatchTime 0.074936   
2022-11-03 21:42:42,143 - INFO  - ==> Top1: 90.650    Top5: 99.630    Loss: 0.381

2022-11-03 21:42:42,189 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:42:42,190 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:42:42,190 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 90.710   Top5: 99.680] Sparsity : 0.808
2022-11-03 21:42:42,297 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:42:42,297 - INFO  - >>>>>>>> Epoch  44
2022-11-03 21:42:42,298 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:42:46,227 - INFO  - Training [44][   20/  391]   Loss 0.051850   Top1 98.164062   Top5 100.000000   BatchTime 0.196457   LR 0.000100   
2022-11-03 21:42:48,260 - INFO  - Training [44][   40/  391]   Loss 0.047358   Top1 98.222656   Top5 99.980469   BatchTime 0.149057   LR 0.000100   
2022-11-03 21:42:50,262 - INFO  - Training [44][   60/  391]   Loss 0.049932   Top1 98.098958   Top5 99.986979   BatchTime 0.132731   LR 0.000100   
2022-11-03 21:42:52,248 - INFO  - Training [44][   80/  391]   Loss 0.050755   Top1 98.105469   Top5 99.990234   BatchTime 0.124371   LR 0.000100   
2022-11-03 21:42:54,258 - INFO  - Training [44][  100/  391]   Loss 0.052380   Top1 98.062500   Top5 99.992188   BatchTime 0.119601   LR 0.000100   
2022-11-03 21:42:56,255 - INFO  - Training [44][  120/  391]   Loss 0.052445   Top1 98.098958   Top5 99.993490   BatchTime 0.116305   LR 0.000100   
2022-11-03 21:42:58,238 - INFO  - Training [44][  140/  391]   Loss 0.050188   Top1 98.186384   Top5 99.994420   BatchTime 0.113854   LR 0.000100   
2022-11-03 21:43:00,214 - INFO  - Training [44][  160/  391]   Loss 0.049325   Top1 98.251953   Top5 99.995117   BatchTime 0.111973   LR 0.000100   
2022-11-03 21:43:02,246 - INFO  - Training [44][  180/  391]   Loss 0.049974   Top1 98.246528   Top5 99.995660   BatchTime 0.110818   LR 0.000100   
2022-11-03 21:43:03,847 - INFO  - Training [44][  200/  391]   Loss 0.049306   Top1 98.257812   Top5 99.996094   BatchTime 0.107743   LR 0.000100   
2022-11-03 21:43:05,602 - INFO  - Training [44][  220/  391]   Loss 0.048662   Top1 98.281250   Top5 99.996449   BatchTime 0.105925   LR 0.000100   
2022-11-03 21:43:07,261 - INFO  - Training [44][  240/  391]   Loss 0.047827   Top1 98.333333   Top5 99.996745   BatchTime 0.104009   LR 0.000100   
2022-11-03 21:43:08,943 - INFO  - Training [44][  260/  391]   Loss 0.047374   Top1 98.347356   Top5 99.996995   BatchTime 0.102477   LR 0.000100   
2022-11-03 21:43:10,778 - INFO  - Training [44][  280/  391]   Loss 0.047700   Top1 98.334263   Top5 99.994420   BatchTime 0.101713   LR 0.000100   
2022-11-03 21:43:12,803 - INFO  - Training [44][  300/  391]   Loss 0.047099   Top1 98.348958   Top5 99.994792   BatchTime 0.101681   LR 0.000100   
2022-11-03 21:43:14,806 - INFO  - Training [44][  320/  391]   Loss 0.047753   Top1 98.325195   Top5 99.995117   BatchTime 0.101584   LR 0.000100   
2022-11-03 21:43:16,801 - INFO  - Training [44][  340/  391]   Loss 0.047792   Top1 98.322610   Top5 99.995404   BatchTime 0.101477   LR 0.000100   
2022-11-03 21:43:18,794 - INFO  - Training [44][  360/  391]   Loss 0.047487   Top1 98.335503   Top5 99.995660   BatchTime 0.101374   LR 0.000100   
2022-11-03 21:43:20,792 - INFO  - Training [44][  380/  391]   Loss 0.047405   Top1 98.336760   Top5 99.995888   BatchTime 0.101298   LR 0.000100   
2022-11-03 21:43:22,143 - INFO  - ==> Top1: 98.352    Top5: 99.996    Loss: 0.047

2022-11-03 21:43:22,144 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:43:24,880 - INFO  - Validation [44][   20/   79]   Loss 0.382820   Top1 90.468750   Top5 99.648438   BatchTime 0.136704   
2022-11-03 21:43:25,754 - INFO  - Validation [44][   40/   79]   Loss 0.391783   Top1 90.585938   Top5 99.609375   BatchTime 0.090206   
2022-11-03 21:43:26,646 - INFO  - Validation [44][   60/   79]   Loss 0.385393   Top1 90.872396   Top5 99.648438   BatchTime 0.075007   
2022-11-03 21:43:27,741 - INFO  - ==> Top1: 90.870    Top5: 99.660    Loss: 0.383

2022-11-03 21:43:27,791 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:43:27,792 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:43:27,792 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:43:28,003 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_best.pth.tar

2022-11-03 21:43:28,003 - INFO  - >>>>>>>> Epoch  45
2022-11-03 21:43:28,004 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:43:31,858 - INFO  - Training [45][   20/  391]   Loss 0.045880   Top1 98.476562   Top5 99.960938   BatchTime 0.192687   LR 0.000100   
2022-11-03 21:43:33,857 - INFO  - Training [45][   40/  391]   Loss 0.045167   Top1 98.437500   Top5 99.980469   BatchTime 0.146330   LR 0.000100   
2022-11-03 21:43:35,856 - INFO  - Training [45][   60/  391]   Loss 0.043200   Top1 98.541667   Top5 99.986979   BatchTime 0.130870   LR 0.000100   
2022-11-03 21:43:37,858 - INFO  - Training [45][   80/  391]   Loss 0.044309   Top1 98.505859   Top5 99.990234   BatchTime 0.123173   LR 0.000100   
2022-11-03 21:43:39,853 - INFO  - Training [45][  100/  391]   Loss 0.046468   Top1 98.437500   Top5 99.984375   BatchTime 0.118486   LR 0.000100   
2022-11-03 21:43:41,848 - INFO  - Training [45][  120/  391]   Loss 0.046142   Top1 98.450521   Top5 99.986979   BatchTime 0.115365   LR 0.000100   
2022-11-03 21:43:43,820 - INFO  - Training [45][  140/  391]   Loss 0.046220   Top1 98.420759   Top5 99.988839   BatchTime 0.112971   LR 0.000100   
2022-11-03 21:43:45,899 - INFO  - Training [45][  160/  391]   Loss 0.045559   Top1 98.437500   Top5 99.990234   BatchTime 0.111842   LR 0.000100   
2022-11-03 21:43:47,892 - INFO  - Training [45][  180/  391]   Loss 0.045383   Top1 98.424479   Top5 99.991319   BatchTime 0.110484   LR 0.000100   
2022-11-03 21:43:49,470 - INFO  - Training [45][  200/  391]   Loss 0.045356   Top1 98.457031   Top5 99.992188   BatchTime 0.107326   LR 0.000100   
2022-11-03 21:43:51,136 - INFO  - Training [45][  220/  391]   Loss 0.044985   Top1 98.458807   Top5 99.992898   BatchTime 0.105142   LR 0.000100   
2022-11-03 21:43:52,799 - INFO  - Training [45][  240/  391]   Loss 0.044639   Top1 98.473307   Top5 99.993490   BatchTime 0.103310   LR 0.000100   
2022-11-03 21:43:54,479 - INFO  - Training [45][  260/  391]   Loss 0.044787   Top1 98.482572   Top5 99.990986   BatchTime 0.101824   LR 0.000100   
2022-11-03 21:43:56,381 - INFO  - Training [45][  280/  391]   Loss 0.045511   Top1 98.440290   Top5 99.991629   BatchTime 0.101345   LR 0.000100   
2022-11-03 21:43:58,372 - INFO  - Training [45][  300/  391]   Loss 0.045824   Top1 98.403646   Top5 99.992188   BatchTime 0.101225   LR 0.000100   
2022-11-03 21:44:00,324 - INFO  - Training [45][  320/  391]   Loss 0.046206   Top1 98.383789   Top5 99.992676   BatchTime 0.100996   LR 0.000100   
2022-11-03 21:44:02,299 - INFO  - Training [45][  340/  391]   Loss 0.045734   Top1 98.409926   Top5 99.993107   BatchTime 0.100866   LR 0.000100   
2022-11-03 21:44:04,274 - INFO  - Training [45][  360/  391]   Loss 0.045744   Top1 98.409288   Top5 99.993490   BatchTime 0.100748   LR 0.000100   
2022-11-03 21:44:06,251 - INFO  - Training [45][  380/  391]   Loss 0.045499   Top1 98.416941   Top5 99.993832   BatchTime 0.100649   LR 0.000100   
2022-11-03 21:44:07,601 - INFO  - ==> Top1: 98.428    Top5: 99.994    Loss: 0.045

2022-11-03 21:44:07,602 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:44:10,289 - INFO  - Validation [45][   20/   79]   Loss 0.384283   Top1 90.585938   Top5 99.687500   BatchTime 0.134300   
2022-11-03 21:44:11,187 - INFO  - Validation [45][   40/   79]   Loss 0.394124   Top1 90.527344   Top5 99.628906   BatchTime 0.089590   
2022-11-03 21:44:12,083 - INFO  - Validation [45][   60/   79]   Loss 0.391074   Top1 90.729167   Top5 99.635417   BatchTime 0.074659   
2022-11-03 21:44:13,218 - INFO  - ==> Top1: 90.690    Top5: 99.660    Loss: 0.387

2022-11-03 21:44:13,259 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:44:13,260 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:44:13,260 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:44:13,365 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:44:13,365 - INFO  - >>>>>>>> Epoch  46
2022-11-03 21:44:13,367 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:44:17,233 - INFO  - Training [46][   20/  391]   Loss 0.050738   Top1 98.281250   Top5 100.000000   BatchTime 0.193325   LR 0.000100   
2022-11-03 21:44:19,265 - INFO  - Training [46][   40/  391]   Loss 0.049259   Top1 98.398438   Top5 99.980469   BatchTime 0.147460   LR 0.000100   
2022-11-03 21:44:21,285 - INFO  - Training [46][   60/  391]   Loss 0.048733   Top1 98.463542   Top5 99.986979   BatchTime 0.131973   LR 0.000100   
2022-11-03 21:44:23,284 - INFO  - Training [46][   80/  391]   Loss 0.048241   Top1 98.437500   Top5 99.990234   BatchTime 0.123968   LR 0.000100   
2022-11-03 21:44:25,299 - INFO  - Training [46][  100/  391]   Loss 0.047613   Top1 98.500000   Top5 99.992188   BatchTime 0.119318   LR 0.000100   
2022-11-03 21:44:27,311 - INFO  - Training [46][  120/  391]   Loss 0.046412   Top1 98.554688   Top5 99.993490   BatchTime 0.116198   LR 0.000100   
2022-11-03 21:44:29,276 - INFO  - Training [46][  140/  391]   Loss 0.046376   Top1 98.515625   Top5 99.994420   BatchTime 0.113637   LR 0.000100   
2022-11-03 21:44:31,272 - INFO  - Training [46][  160/  391]   Loss 0.045615   Top1 98.544922   Top5 99.995117   BatchTime 0.111907   LR 0.000100   
2022-11-03 21:44:33,307 - INFO  - Training [46][  180/  391]   Loss 0.045870   Top1 98.493924   Top5 99.995660   BatchTime 0.110776   LR 0.000100   
2022-11-03 21:44:34,876 - INFO  - Training [46][  200/  391]   Loss 0.045182   Top1 98.519531   Top5 99.992188   BatchTime 0.107544   LR 0.000100   
2022-11-03 21:44:36,488 - INFO  - Training [46][  220/  391]   Loss 0.046306   Top1 98.465909   Top5 99.992898   BatchTime 0.105093   LR 0.000100   
2022-11-03 21:44:38,109 - INFO  - Training [46][  240/  391]   Loss 0.046399   Top1 98.463542   Top5 99.993490   BatchTime 0.103091   LR 0.000100   
2022-11-03 21:44:39,773 - INFO  - Training [46][  260/  391]   Loss 0.046133   Top1 98.461538   Top5 99.993990   BatchTime 0.101560   LR 0.000100   
2022-11-03 21:44:41,608 - INFO  - Training [46][  280/  391]   Loss 0.045145   Top1 98.510045   Top5 99.994420   BatchTime 0.100859   LR 0.000100   
2022-11-03 21:44:43,608 - INFO  - Training [46][  300/  391]   Loss 0.044936   Top1 98.505208   Top5 99.994792   BatchTime 0.100803   LR 0.000100   
2022-11-03 21:44:45,639 - INFO  - Training [46][  320/  391]   Loss 0.044945   Top1 98.508301   Top5 99.995117   BatchTime 0.100848   LR 0.000100   
2022-11-03 21:44:47,636 - INFO  - Training [46][  340/  391]   Loss 0.045250   Top1 98.481158   Top5 99.995404   BatchTime 0.100789   LR 0.000100   
2022-11-03 21:44:49,625 - INFO  - Training [46][  360/  391]   Loss 0.044984   Top1 98.478733   Top5 99.995660   BatchTime 0.100714   LR 0.000100   
2022-11-03 21:44:51,597 - INFO  - Training [46][  380/  391]   Loss 0.045412   Top1 98.468339   Top5 99.995888   BatchTime 0.100605   LR 0.000100   
2022-11-03 21:44:52,934 - INFO  - ==> Top1: 98.486    Top5: 99.996    Loss: 0.045

2022-11-03 21:44:52,935 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:44:55,668 - INFO  - Validation [46][   20/   79]   Loss 0.377792   Top1 90.585938   Top5 99.765625   BatchTime 0.136596   
2022-11-03 21:44:56,569 - INFO  - Validation [46][   40/   79]   Loss 0.388777   Top1 90.507812   Top5 99.687500   BatchTime 0.090822   
2022-11-03 21:44:57,449 - INFO  - Validation [46][   60/   79]   Loss 0.382447   Top1 90.768229   Top5 99.700521   BatchTime 0.075219   
2022-11-03 21:44:58,564 - INFO  - ==> Top1: 90.690    Top5: 99.690    Loss: 0.380

2022-11-03 21:44:58,603 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:44:58,603 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:44:58,604 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:44:58,696 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:44:58,696 - INFO  - >>>>>>>> Epoch  47
2022-11-03 21:44:58,697 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:45:02,596 - INFO  - Training [47][   20/  391]   Loss 0.037753   Top1 98.671875   Top5 100.000000   BatchTime 0.194934   LR 0.000100   
2022-11-03 21:45:04,598 - INFO  - Training [47][   40/  391]   Loss 0.040460   Top1 98.613281   Top5 100.000000   BatchTime 0.147507   LR 0.000100   
2022-11-03 21:45:06,599 - INFO  - Training [47][   60/  391]   Loss 0.044189   Top1 98.541667   Top5 100.000000   BatchTime 0.131698   LR 0.000100   
2022-11-03 21:45:08,593 - INFO  - Training [47][   80/  391]   Loss 0.044309   Top1 98.496094   Top5 100.000000   BatchTime 0.123690   LR 0.000100   
2022-11-03 21:45:10,605 - INFO  - Training [47][  100/  391]   Loss 0.044825   Top1 98.445312   Top5 100.000000   BatchTime 0.119080   LR 0.000100   
2022-11-03 21:45:12,598 - INFO  - Training [47][  120/  391]   Loss 0.046114   Top1 98.385417   Top5 100.000000   BatchTime 0.115837   LR 0.000100   
2022-11-03 21:45:14,557 - INFO  - Training [47][  140/  391]   Loss 0.046719   Top1 98.376116   Top5 100.000000   BatchTime 0.113286   LR 0.000100   
2022-11-03 21:45:16,532 - INFO  - Training [47][  160/  391]   Loss 0.045972   Top1 98.422852   Top5 100.000000   BatchTime 0.111468   LR 0.000100   
2022-11-03 21:45:18,577 - INFO  - Training [47][  180/  391]   Loss 0.044787   Top1 98.467882   Top5 100.000000   BatchTime 0.110442   LR 0.000100   
2022-11-03 21:45:20,122 - INFO  - Training [47][  200/  391]   Loss 0.045062   Top1 98.445312   Top5 100.000000   BatchTime 0.107121   LR 0.000100   
2022-11-03 21:45:21,971 - INFO  - Training [47][  220/  391]   Loss 0.045292   Top1 98.441051   Top5 100.000000   BatchTime 0.105789   LR 0.000100   
2022-11-03 21:45:23,633 - INFO  - Training [47][  240/  391]   Loss 0.045206   Top1 98.450521   Top5 100.000000   BatchTime 0.103898   LR 0.000100   
2022-11-03 21:45:25,276 - INFO  - Training [47][  260/  391]   Loss 0.044937   Top1 98.470553   Top5 100.000000   BatchTime 0.102224   LR 0.000100   
2022-11-03 21:45:27,205 - INFO  - Training [47][  280/  391]   Loss 0.044446   Top1 98.496094   Top5 100.000000   BatchTime 0.101810   LR 0.000100   
2022-11-03 21:45:29,200 - INFO  - Training [47][  300/  391]   Loss 0.044438   Top1 98.489583   Top5 100.000000   BatchTime 0.101674   LR 0.000100   
2022-11-03 21:45:31,190 - INFO  - Training [47][  320/  391]   Loss 0.044048   Top1 98.491211   Top5 100.000000   BatchTime 0.101538   LR 0.000100   
2022-11-03 21:45:33,162 - INFO  - Training [47][  340/  391]   Loss 0.044097   Top1 98.483456   Top5 100.000000   BatchTime 0.101364   LR 0.000100   
2022-11-03 21:45:35,133 - INFO  - Training [47][  360/  391]   Loss 0.044386   Top1 98.470052   Top5 100.000000   BatchTime 0.101208   LR 0.000100   
2022-11-03 21:45:37,092 - INFO  - Training [47][  380/  391]   Loss 0.044646   Top1 98.449836   Top5 100.000000   BatchTime 0.101037   LR 0.000100   
2022-11-03 21:45:38,408 - INFO  - ==> Top1: 98.454    Top5: 100.000    Loss: 0.045

2022-11-03 21:45:38,409 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:45:41,104 - INFO  - Validation [47][   20/   79]   Loss 0.384502   Top1 90.585938   Top5 99.726562   BatchTime 0.134642   
2022-11-03 21:45:41,982 - INFO  - Validation [47][   40/   79]   Loss 0.395317   Top1 90.468750   Top5 99.667969   BatchTime 0.089273   
2022-11-03 21:45:42,886 - INFO  - Validation [47][   60/   79]   Loss 0.388191   Top1 90.625000   Top5 99.700521   BatchTime 0.074593   
2022-11-03 21:45:43,989 - INFO  - ==> Top1: 90.590    Top5: 99.710    Loss: 0.384

2022-11-03 21:45:44,018 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:45:44,019 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:45:44,019 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.750   Top5: 99.620] Sparsity : 0.807
2022-11-03 21:45:44,135 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:45:44,135 - INFO  - >>>>>>>> Epoch  48
2022-11-03 21:45:44,137 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:45:48,003 - INFO  - Training [48][   20/  391]   Loss 0.050109   Top1 98.281250   Top5 100.000000   BatchTime 0.193323   LR 0.000100   
2022-11-03 21:45:50,014 - INFO  - Training [48][   40/  391]   Loss 0.045627   Top1 98.535156   Top5 100.000000   BatchTime 0.146933   LR 0.000100   
2022-11-03 21:45:52,013 - INFO  - Training [48][   60/  391]   Loss 0.046984   Top1 98.502604   Top5 100.000000   BatchTime 0.131264   LR 0.000100   
2022-11-03 21:45:54,014 - INFO  - Training [48][   80/  391]   Loss 0.047004   Top1 98.437500   Top5 100.000000   BatchTime 0.123461   LR 0.000100   
2022-11-03 21:45:56,004 - INFO  - Training [48][  100/  391]   Loss 0.047157   Top1 98.414062   Top5 100.000000   BatchTime 0.118673   LR 0.000100   
2022-11-03 21:45:57,988 - INFO  - Training [48][  120/  391]   Loss 0.046310   Top1 98.463542   Top5 100.000000   BatchTime 0.115426   LR 0.000100   
2022-11-03 21:45:59,946 - INFO  - Training [48][  140/  391]   Loss 0.046710   Top1 98.454241   Top5 100.000000   BatchTime 0.112924   LR 0.000100   
2022-11-03 21:46:01,913 - INFO  - Training [48][  160/  391]   Loss 0.047002   Top1 98.393555   Top5 100.000000   BatchTime 0.111097   LR 0.000100   
2022-11-03 21:46:03,825 - INFO  - Training [48][  180/  391]   Loss 0.046194   Top1 98.454861   Top5 99.995660   BatchTime 0.109378   LR 0.000100   
2022-11-03 21:46:05,458 - INFO  - Training [48][  200/  391]   Loss 0.045884   Top1 98.472656   Top5 99.996094   BatchTime 0.106603   LR 0.000100   
2022-11-03 21:46:07,138 - INFO  - Training [48][  220/  391]   Loss 0.045781   Top1 98.433949   Top5 99.996449   BatchTime 0.104551   LR 0.000100   
2022-11-03 21:46:08,910 - INFO  - Training [48][  240/  391]   Loss 0.045087   Top1 98.473307   Top5 99.996745   BatchTime 0.103220   LR 0.000100   
2022-11-03 21:46:10,392 - INFO  - Training [48][  260/  391]   Loss 0.045858   Top1 98.449519   Top5 99.996995   BatchTime 0.100979   LR 0.000100   
2022-11-03 21:46:12,353 - INFO  - Training [48][  280/  391]   Loss 0.045612   Top1 98.457031   Top5 99.997210   BatchTime 0.100771   LR 0.000100   
2022-11-03 21:46:14,359 - INFO  - Training [48][  300/  391]   Loss 0.044813   Top1 98.484375   Top5 99.997396   BatchTime 0.100739   LR 0.000100   
2022-11-03 21:46:16,375 - INFO  - Training [48][  320/  391]   Loss 0.044707   Top1 98.498535   Top5 99.997559   BatchTime 0.100742   LR 0.000100   
2022-11-03 21:46:18,387 - INFO  - Training [48][  340/  391]   Loss 0.044723   Top1 98.497243   Top5 99.997702   BatchTime 0.100733   LR 0.000100   
2022-11-03 21:46:20,388 - INFO  - Training [48][  360/  391]   Loss 0.045054   Top1 98.480903   Top5 99.997830   BatchTime 0.100696   LR 0.000100   
2022-11-03 21:46:22,381 - INFO  - Training [48][  380/  391]   Loss 0.044854   Top1 98.476562   Top5 99.997944   BatchTime 0.100640   LR 0.000100   
2022-11-03 21:46:23,738 - INFO  - ==> Top1: 98.462    Top5: 99.998    Loss: 0.045

2022-11-03 21:46:23,739 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:46:26,470 - INFO  - Validation [48][   20/   79]   Loss 0.383916   Top1 91.054688   Top5 99.726562   BatchTime 0.136541   
2022-11-03 21:46:27,363 - INFO  - Validation [48][   40/   79]   Loss 0.392522   Top1 90.878906   Top5 99.589844   BatchTime 0.090592   
2022-11-03 21:46:28,260 - INFO  - Validation [48][   60/   79]   Loss 0.389133   Top1 90.911458   Top5 99.609375   BatchTime 0.075336   
2022-11-03 21:46:29,374 - INFO  - ==> Top1: 90.780    Top5: 99.630    Loss: 0.386

2022-11-03 21:46:29,412 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:46:29,413 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:46:29,413 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:46:29,523 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:46:29,524 - INFO  - >>>>>>>> Epoch  49
2022-11-03 21:46:29,525 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:46:33,363 - INFO  - Training [49][   20/  391]   Loss 0.057582   Top1 97.812500   Top5 100.000000   BatchTime 0.191875   LR 0.000100   
2022-11-03 21:46:35,354 - INFO  - Training [49][   40/  391]   Loss 0.050664   Top1 98.183594   Top5 100.000000   BatchTime 0.145726   LR 0.000100   
2022-11-03 21:46:37,369 - INFO  - Training [49][   60/  391]   Loss 0.049686   Top1 98.242188   Top5 100.000000   BatchTime 0.130728   LR 0.000100   
2022-11-03 21:46:39,369 - INFO  - Training [49][   80/  391]   Loss 0.049337   Top1 98.232422   Top5 100.000000   BatchTime 0.123045   LR 0.000100   
2022-11-03 21:46:41,371 - INFO  - Training [49][  100/  391]   Loss 0.050390   Top1 98.210938   Top5 100.000000   BatchTime 0.118459   LR 0.000100   
2022-11-03 21:46:43,374 - INFO  - Training [49][  120/  391]   Loss 0.049114   Top1 98.255208   Top5 100.000000   BatchTime 0.115405   LR 0.000100   
2022-11-03 21:46:45,346 - INFO  - Training [49][  140/  391]   Loss 0.048588   Top1 98.303571   Top5 100.000000   BatchTime 0.113003   LR 0.000100   
2022-11-03 21:46:47,317 - INFO  - Training [49][  160/  391]   Loss 0.048563   Top1 98.295898   Top5 100.000000   BatchTime 0.111195   LR 0.000100   
2022-11-03 21:46:49,273 - INFO  - Training [49][  180/  391]   Loss 0.047971   Top1 98.302951   Top5 100.000000   BatchTime 0.109705   LR 0.000100   
2022-11-03 21:46:50,960 - INFO  - Training [49][  200/  391]   Loss 0.048257   Top1 98.308594   Top5 100.000000   BatchTime 0.107172   LR 0.000100   
2022-11-03 21:46:52,632 - INFO  - Training [49][  220/  391]   Loss 0.049101   Top1 98.267045   Top5 100.000000   BatchTime 0.105030   LR 0.000100   
2022-11-03 21:46:54,382 - INFO  - Training [49][  240/  391]   Loss 0.048600   Top1 98.284505   Top5 100.000000   BatchTime 0.103566   LR 0.000100   
2022-11-03 21:46:56,015 - INFO  - Training [49][  260/  391]   Loss 0.047497   Top1 98.338341   Top5 100.000000   BatchTime 0.101880   LR 0.000100   
2022-11-03 21:46:58,051 - INFO  - Training [49][  280/  391]   Loss 0.047874   Top1 98.331473   Top5 100.000000   BatchTime 0.101874   LR 0.000100   
2022-11-03 21:47:00,038 - INFO  - Training [49][  300/  391]   Loss 0.047829   Top1 98.338542   Top5 100.000000   BatchTime 0.101708   LR 0.000100   
2022-11-03 21:47:02,045 - INFO  - Training [49][  320/  391]   Loss 0.047845   Top1 98.337402   Top5 100.000000   BatchTime 0.101622   LR 0.000100   
2022-11-03 21:47:04,035 - INFO  - Training [49][  340/  391]   Loss 0.047910   Top1 98.336397   Top5 100.000000   BatchTime 0.101496   LR 0.000100   
2022-11-03 21:47:05,998 - INFO  - Training [49][  360/  391]   Loss 0.047781   Top1 98.337674   Top5 100.000000   BatchTime 0.101312   LR 0.000100   
2022-11-03 21:47:07,982 - INFO  - Training [49][  380/  391]   Loss 0.048037   Top1 98.326480   Top5 100.000000   BatchTime 0.101200   LR 0.000100   
2022-11-03 21:47:09,316 - INFO  - ==> Top1: 98.338    Top5: 100.000    Loss: 0.048

2022-11-03 21:47:09,317 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:47:12,067 - INFO  - Validation [49][   20/   79]   Loss 0.388211   Top1 90.468750   Top5 99.726562   BatchTime 0.137393   
2022-11-03 21:47:12,951 - INFO  - Validation [49][   40/   79]   Loss 0.397432   Top1 90.468750   Top5 99.648438   BatchTime 0.090808   
2022-11-03 21:47:13,839 - INFO  - Validation [49][   60/   79]   Loss 0.389556   Top1 90.716146   Top5 99.648438   BatchTime 0.075326   
2022-11-03 21:47:14,943 - INFO  - ==> Top1: 90.670    Top5: 99.660    Loss: 0.384

2022-11-03 21:47:14,973 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:47:14,974 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:47:14,974 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:47:15,077 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:47:15,077 - INFO  - >>>>>>>> Epoch  50
2022-11-03 21:47:15,079 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:47:18,912 - INFO  - Training [50][   20/  391]   Loss 0.041571   Top1 98.515625   Top5 100.000000   BatchTime 0.191662   LR 0.000010   
2022-11-03 21:47:20,908 - INFO  - Training [50][   40/  391]   Loss 0.043887   Top1 98.378906   Top5 100.000000   BatchTime 0.145718   LR 0.000010   
2022-11-03 21:47:22,914 - INFO  - Training [50][   60/  391]   Loss 0.042771   Top1 98.450521   Top5 100.000000   BatchTime 0.130576   LR 0.000010   
2022-11-03 21:47:24,925 - INFO  - Training [50][   80/  391]   Loss 0.043251   Top1 98.408203   Top5 100.000000   BatchTime 0.123071   LR 0.000010   
2022-11-03 21:47:26,922 - INFO  - Training [50][  100/  391]   Loss 0.041423   Top1 98.523438   Top5 100.000000   BatchTime 0.118427   LR 0.000010   
2022-11-03 21:47:28,907 - INFO  - Training [50][  120/  391]   Loss 0.042250   Top1 98.509115   Top5 100.000000   BatchTime 0.115235   LR 0.000010   
2022-11-03 21:47:30,888 - INFO  - Training [50][  140/  391]   Loss 0.042881   Top1 98.482143   Top5 100.000000   BatchTime 0.112921   LR 0.000010   
2022-11-03 21:47:32,848 - INFO  - Training [50][  160/  391]   Loss 0.042986   Top1 98.457031   Top5 100.000000   BatchTime 0.111058   LR 0.000010   
2022-11-03 21:47:34,791 - INFO  - Training [50][  180/  391]   Loss 0.042569   Top1 98.489583   Top5 100.000000   BatchTime 0.109508   LR 0.000010   
2022-11-03 21:47:36,434 - INFO  - Training [50][  200/  391]   Loss 0.042056   Top1 98.519531   Top5 100.000000   BatchTime 0.106772   LR 0.000010   
2022-11-03 21:47:38,073 - INFO  - Training [50][  220/  391]   Loss 0.041797   Top1 98.519176   Top5 100.000000   BatchTime 0.104517   LR 0.000010   
2022-11-03 21:47:39,812 - INFO  - Training [50][  240/  391]   Loss 0.041965   Top1 98.512370   Top5 100.000000   BatchTime 0.103051   LR 0.000010   
2022-11-03 21:47:41,285 - INFO  - Training [50][  260/  391]   Loss 0.042206   Top1 98.512620   Top5 100.000000   BatchTime 0.100792   LR 0.000010   
2022-11-03 21:47:43,324 - INFO  - Training [50][  280/  391]   Loss 0.042081   Top1 98.512835   Top5 100.000000   BatchTime 0.100873   LR 0.000010   
2022-11-03 21:47:45,336 - INFO  - Training [50][  300/  391]   Loss 0.042225   Top1 98.515625   Top5 100.000000   BatchTime 0.100854   LR 0.000010   
2022-11-03 21:47:47,354 - INFO  - Training [50][  320/  391]   Loss 0.042463   Top1 98.503418   Top5 100.000000   BatchTime 0.100858   LR 0.000010   
2022-11-03 21:47:49,371 - INFO  - Training [50][  340/  391]   Loss 0.042640   Top1 98.506434   Top5 100.000000   BatchTime 0.100856   LR 0.000010   
2022-11-03 21:47:51,332 - INFO  - Training [50][  360/  391]   Loss 0.042586   Top1 98.498264   Top5 100.000000   BatchTime 0.100702   LR 0.000010   
2022-11-03 21:47:53,313 - INFO  - Training [50][  380/  391]   Loss 0.042417   Top1 98.511513   Top5 100.000000   BatchTime 0.100615   LR 0.000010   
2022-11-03 21:47:54,678 - INFO  - ==> Top1: 98.498    Top5: 99.998    Loss: 0.043

2022-11-03 21:47:54,679 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:47:57,412 - INFO  - Validation [50][   20/   79]   Loss 0.382667   Top1 90.781250   Top5 99.804688   BatchTime 0.136556   
2022-11-03 21:47:58,315 - INFO  - Validation [50][   40/   79]   Loss 0.392870   Top1 90.527344   Top5 99.707031   BatchTime 0.090857   
2022-11-03 21:47:59,251 - INFO  - Validation [50][   60/   79]   Loss 0.383102   Top1 90.716146   Top5 99.661458   BatchTime 0.076162   
2022-11-03 21:48:00,350 - INFO  - ==> Top1: 90.640    Top5: 99.650    Loss: 0.382

2022-11-03 21:48:00,388 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:48:00,388 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:48:00,388 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:48:00,497 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:48:00,497 - INFO  - >>>>>>>> Epoch  51
2022-11-03 21:48:00,499 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:48:04,349 - INFO  - Training [51][   20/  391]   Loss 0.036229   Top1 98.945312   Top5 100.000000   BatchTime 0.192475   LR 0.000010   
2022-11-03 21:48:06,355 - INFO  - Training [51][   40/  391]   Loss 0.039658   Top1 98.671875   Top5 100.000000   BatchTime 0.146394   LR 0.000010   
2022-11-03 21:48:08,384 - INFO  - Training [51][   60/  391]   Loss 0.041335   Top1 98.606771   Top5 100.000000   BatchTime 0.131411   LR 0.000010   
2022-11-03 21:48:10,366 - INFO  - Training [51][   80/  391]   Loss 0.042418   Top1 98.583984   Top5 100.000000   BatchTime 0.123338   LR 0.000010   
2022-11-03 21:48:12,390 - INFO  - Training [51][  100/  391]   Loss 0.042820   Top1 98.539062   Top5 100.000000   BatchTime 0.118908   LR 0.000010   
2022-11-03 21:48:14,361 - INFO  - Training [51][  120/  391]   Loss 0.043082   Top1 98.535156   Top5 100.000000   BatchTime 0.115517   LR 0.000010   
2022-11-03 21:48:16,323 - INFO  - Training [51][  140/  391]   Loss 0.042776   Top1 98.571429   Top5 100.000000   BatchTime 0.113025   LR 0.000010   
2022-11-03 21:48:18,284 - INFO  - Training [51][  160/  391]   Loss 0.042935   Top1 98.535156   Top5 100.000000   BatchTime 0.111157   LR 0.000010   
2022-11-03 21:48:20,076 - INFO  - Training [51][  180/  391]   Loss 0.043276   Top1 98.537326   Top5 100.000000   BatchTime 0.108757   LR 0.000010   
2022-11-03 21:48:21,721 - INFO  - Training [51][  200/  391]   Loss 0.043527   Top1 98.531250   Top5 100.000000   BatchTime 0.106107   LR 0.000010   
2022-11-03 21:48:23,407 - INFO  - Training [51][  220/  391]   Loss 0.043884   Top1 98.522727   Top5 100.000000   BatchTime 0.104126   LR 0.000010   
2022-11-03 21:48:25,188 - INFO  - Training [51][  240/  391]   Loss 0.044574   Top1 98.499349   Top5 100.000000   BatchTime 0.102867   LR 0.000010   
2022-11-03 21:48:26,693 - INFO  - Training [51][  260/  391]   Loss 0.043822   Top1 98.530649   Top5 100.000000   BatchTime 0.100743   LR 0.000010   
2022-11-03 21:48:28,769 - INFO  - Training [51][  280/  391]   Loss 0.044026   Top1 98.521205   Top5 100.000000   BatchTime 0.100962   LR 0.000010   
2022-11-03 21:48:30,817 - INFO  - Training [51][  300/  391]   Loss 0.044575   Top1 98.489583   Top5 100.000000   BatchTime 0.101059   LR 0.000010   
2022-11-03 21:48:32,799 - INFO  - Training [51][  320/  391]   Loss 0.044880   Top1 98.464355   Top5 100.000000   BatchTime 0.100936   LR 0.000010   
2022-11-03 21:48:34,931 - INFO  - Training [51][  340/  391]   Loss 0.044841   Top1 98.469669   Top5 100.000000   BatchTime 0.101270   LR 0.000010   
2022-11-03 21:48:36,903 - INFO  - Training [51][  360/  391]   Loss 0.044805   Top1 98.465712   Top5 100.000000   BatchTime 0.101119   LR 0.000010   
2022-11-03 21:48:38,876 - INFO  - Training [51][  380/  391]   Loss 0.044880   Top1 98.458059   Top5 100.000000   BatchTime 0.100991   LR 0.000010   
2022-11-03 21:48:40,208 - INFO  - ==> Top1: 98.464    Top5: 100.000    Loss: 0.045

2022-11-03 21:48:40,209 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:48:42,946 - INFO  - Validation [51][   20/   79]   Loss 0.395189   Top1 90.390625   Top5 99.648438   BatchTime 0.136755   
2022-11-03 21:48:43,841 - INFO  - Validation [51][   40/   79]   Loss 0.398757   Top1 90.234375   Top5 99.589844   BatchTime 0.090764   
2022-11-03 21:48:44,728 - INFO  - Validation [51][   60/   79]   Loss 0.391268   Top1 90.585938   Top5 99.596354   BatchTime 0.075284   
2022-11-03 21:48:45,837 - INFO  - ==> Top1: 90.500    Top5: 99.620    Loss: 0.388

2022-11-03 21:48:45,876 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:48:45,877 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:48:45,877 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:48:45,967 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:48:45,968 - INFO  - >>>>>>>> Epoch  52
2022-11-03 21:48:45,969 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:48:49,822 - INFO  - Training [52][   20/  391]   Loss 0.039495   Top1 98.320312   Top5 100.000000   BatchTime 0.192619   LR 0.000010   
2022-11-03 21:48:51,817 - INFO  - Training [52][   40/  391]   Loss 0.047397   Top1 98.183594   Top5 100.000000   BatchTime 0.146205   LR 0.000010   
2022-11-03 21:48:53,825 - INFO  - Training [52][   60/  391]   Loss 0.048367   Top1 98.216146   Top5 100.000000   BatchTime 0.130932   LR 0.000010   
2022-11-03 21:48:55,836 - INFO  - Training [52][   80/  391]   Loss 0.046595   Top1 98.291016   Top5 100.000000   BatchTime 0.123328   LR 0.000010   
2022-11-03 21:48:57,831 - INFO  - Training [52][  100/  391]   Loss 0.047744   Top1 98.250000   Top5 100.000000   BatchTime 0.118619   LR 0.000010   
2022-11-03 21:48:59,816 - INFO  - Training [52][  120/  391]   Loss 0.049126   Top1 98.138021   Top5 100.000000   BatchTime 0.115390   LR 0.000010   
2022-11-03 21:49:01,805 - INFO  - Training [52][  140/  391]   Loss 0.047073   Top1 98.242188   Top5 100.000000   BatchTime 0.113111   LR 0.000010   
2022-11-03 21:49:03,766 - INFO  - Training [52][  160/  391]   Loss 0.046130   Top1 98.325195   Top5 100.000000   BatchTime 0.111227   LR 0.000010   
2022-11-03 21:49:05,462 - INFO  - Training [52][  180/  391]   Loss 0.045779   Top1 98.355035   Top5 100.000000   BatchTime 0.108292   LR 0.000010   
2022-11-03 21:49:07,135 - INFO  - Training [52][  200/  391]   Loss 0.045700   Top1 98.316406   Top5 100.000000   BatchTime 0.105825   LR 0.000010   
2022-11-03 21:49:08,785 - INFO  - Training [52][  220/  391]   Loss 0.045812   Top1 98.309659   Top5 100.000000   BatchTime 0.103706   LR 0.000010   
2022-11-03 21:49:10,457 - INFO  - Training [52][  240/  391]   Loss 0.046227   Top1 98.326823   Top5 100.000000   BatchTime 0.102030   LR 0.000010   
2022-11-03 21:49:12,086 - INFO  - Training [52][  260/  391]   Loss 0.045995   Top1 98.338341   Top5 100.000000   BatchTime 0.100448   LR 0.000010   
2022-11-03 21:49:14,102 - INFO  - Training [52][  280/  391]   Loss 0.045407   Top1 98.359375   Top5 100.000000   BatchTime 0.100471   LR 0.000010   
2022-11-03 21:49:16,100 - INFO  - Training [52][  300/  391]   Loss 0.045361   Top1 98.354167   Top5 100.000000   BatchTime 0.100433   LR 0.000010   
2022-11-03 21:49:18,106 - INFO  - Training [52][  320/  391]   Loss 0.045903   Top1 98.342285   Top5 100.000000   BatchTime 0.100427   LR 0.000010   
2022-11-03 21:49:20,096 - INFO  - Training [52][  340/  391]   Loss 0.045518   Top1 98.359375   Top5 100.000000   BatchTime 0.100372   LR 0.000010   
2022-11-03 21:49:22,087 - INFO  - Training [52][  360/  391]   Loss 0.045249   Top1 98.370226   Top5 100.000000   BatchTime 0.100324   LR 0.000010   
2022-11-03 21:49:24,058 - INFO  - Training [52][  380/  391]   Loss 0.045197   Top1 98.386102   Top5 100.000000   BatchTime 0.100231   LR 0.000010   
2022-11-03 21:49:25,388 - INFO  - ==> Top1: 98.368    Top5: 100.000    Loss: 0.046

2022-11-03 21:49:25,389 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:49:28,080 - INFO  - Validation [52][   20/   79]   Loss 0.383165   Top1 90.820312   Top5 99.648438   BatchTime 0.134451   
2022-11-03 21:49:28,960 - INFO  - Validation [52][   40/   79]   Loss 0.393744   Top1 90.742188   Top5 99.648438   BatchTime 0.089238   
2022-11-03 21:49:29,835 - INFO  - Validation [52][   60/   79]   Loss 0.388301   Top1 90.859375   Top5 99.661458   BatchTime 0.074070   
2022-11-03 21:49:30,931 - INFO  - ==> Top1: 90.750    Top5: 99.680    Loss: 0.385

2022-11-03 21:49:30,970 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:49:30,971 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:49:30,971 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:49:31,068 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:49:31,068 - INFO  - >>>>>>>> Epoch  53
2022-11-03 21:49:31,069 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:49:34,914 - INFO  - Training [53][   20/  391]   Loss 0.043571   Top1 98.515625   Top5 100.000000   BatchTime 0.192238   LR 0.000010   
2022-11-03 21:49:36,917 - INFO  - Training [53][   40/  391]   Loss 0.045392   Top1 98.457031   Top5 99.980469   BatchTime 0.146200   LR 0.000010   
2022-11-03 21:49:38,909 - INFO  - Training [53][   60/  391]   Loss 0.043504   Top1 98.554688   Top5 99.986979   BatchTime 0.130657   LR 0.000010   
2022-11-03 21:49:40,902 - INFO  - Training [53][   80/  391]   Loss 0.042732   Top1 98.564453   Top5 99.990234   BatchTime 0.122911   LR 0.000010   
2022-11-03 21:49:42,885 - INFO  - Training [53][  100/  391]   Loss 0.045314   Top1 98.492188   Top5 99.992188   BatchTime 0.118157   LR 0.000010   
2022-11-03 21:49:44,871 - INFO  - Training [53][  120/  391]   Loss 0.045355   Top1 98.463542   Top5 99.993490   BatchTime 0.115011   LR 0.000010   
2022-11-03 21:49:46,850 - INFO  - Training [53][  140/  391]   Loss 0.045299   Top1 98.476562   Top5 99.994420   BatchTime 0.112716   LR 0.000010   
2022-11-03 21:49:48,822 - INFO  - Training [53][  160/  391]   Loss 0.045920   Top1 98.461914   Top5 99.995117   BatchTime 0.110952   LR 0.000010   
2022-11-03 21:49:50,547 - INFO  - Training [53][  180/  391]   Loss 0.045912   Top1 98.446181   Top5 99.995660   BatchTime 0.108208   LR 0.000010   
2022-11-03 21:49:52,200 - INFO  - Training [53][  200/  391]   Loss 0.046286   Top1 98.425781   Top5 99.996094   BatchTime 0.105651   LR 0.000010   
2022-11-03 21:49:53,861 - INFO  - Training [53][  220/  391]   Loss 0.046250   Top1 98.416193   Top5 99.996449   BatchTime 0.103597   LR 0.000010   
2022-11-03 21:49:55,616 - INFO  - Training [53][  240/  391]   Loss 0.045719   Top1 98.430990   Top5 99.996745   BatchTime 0.102278   LR 0.000010   
2022-11-03 21:49:57,325 - INFO  - Training [53][  260/  391]   Loss 0.046285   Top1 98.410457   Top5 99.996995   BatchTime 0.100983   LR 0.000010   
2022-11-03 21:49:59,329 - INFO  - Training [53][  280/  391]   Loss 0.045901   Top1 98.434710   Top5 99.997210   BatchTime 0.100927   LR 0.000010   
2022-11-03 21:50:01,323 - INFO  - Training [53][  300/  391]   Loss 0.046587   Top1 98.416667   Top5 99.994792   BatchTime 0.100846   LR 0.000010   
2022-11-03 21:50:03,312 - INFO  - Training [53][  320/  391]   Loss 0.046076   Top1 98.437500   Top5 99.995117   BatchTime 0.100757   LR 0.000010   
2022-11-03 21:50:05,293 - INFO  - Training [53][  340/  391]   Loss 0.045841   Top1 98.428309   Top5 99.995404   BatchTime 0.100657   LR 0.000010   
2022-11-03 21:50:07,271 - INFO  - Training [53][  360/  391]   Loss 0.045920   Top1 98.430990   Top5 99.993490   BatchTime 0.100559   LR 0.000010   
2022-11-03 21:50:09,249 - INFO  - Training [53][  380/  391]   Loss 0.045522   Top1 98.439556   Top5 99.993832   BatchTime 0.100473   LR 0.000010   
2022-11-03 21:50:10,722 - INFO  - ==> Top1: 98.440    Top5: 99.994    Loss: 0.045

2022-11-03 21:50:10,723 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:50:13,448 - INFO  - Validation [53][   20/   79]   Loss 0.384578   Top1 90.507812   Top5 99.687500   BatchTime 0.136218   
2022-11-03 21:50:14,342 - INFO  - Validation [53][   40/   79]   Loss 0.394717   Top1 90.605469   Top5 99.609375   BatchTime 0.090460   
2022-11-03 21:50:15,235 - INFO  - Validation [53][   60/   79]   Loss 0.389364   Top1 90.755208   Top5 99.622396   BatchTime 0.075184   
2022-11-03 21:50:16,346 - INFO  - ==> Top1: 90.650    Top5: 99.640    Loss: 0.386

2022-11-03 21:50:16,388 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:50:16,389 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:50:16,389 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:50:16,493 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:50:16,493 - INFO  - >>>>>>>> Epoch  54
2022-11-03 21:50:16,494 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:50:20,373 - INFO  - Training [54][   20/  391]   Loss 0.048618   Top1 98.203125   Top5 100.000000   BatchTime 0.193975   LR 0.000010   
2022-11-03 21:50:22,300 - INFO  - Training [54][   40/  391]   Loss 0.049863   Top1 98.105469   Top5 100.000000   BatchTime 0.145156   LR 0.000010   
2022-11-03 21:50:24,302 - INFO  - Training [54][   60/  391]   Loss 0.048357   Top1 98.151042   Top5 100.000000   BatchTime 0.130137   LR 0.000010   
2022-11-03 21:50:26,320 - INFO  - Training [54][   80/  391]   Loss 0.049325   Top1 98.222656   Top5 100.000000   BatchTime 0.122821   LR 0.000010   
2022-11-03 21:50:28,325 - INFO  - Training [54][  100/  391]   Loss 0.049645   Top1 98.203125   Top5 100.000000   BatchTime 0.118313   LR 0.000010   
2022-11-03 21:50:30,287 - INFO  - Training [54][  120/  391]   Loss 0.048536   Top1 98.229167   Top5 100.000000   BatchTime 0.114942   LR 0.000010   
2022-11-03 21:50:32,255 - INFO  - Training [54][  140/  391]   Loss 0.047370   Top1 98.275670   Top5 100.000000   BatchTime 0.112576   LR 0.000010   
2022-11-03 21:50:34,241 - INFO  - Training [54][  160/  391]   Loss 0.046848   Top1 98.286133   Top5 100.000000   BatchTime 0.110920   LR 0.000010   
2022-11-03 21:50:35,953 - INFO  - Training [54][  180/  391]   Loss 0.046956   Top1 98.307292   Top5 99.995660   BatchTime 0.108104   LR 0.000010   
2022-11-03 21:50:37,678 - INFO  - Training [54][  200/  391]   Loss 0.048036   Top1 98.257812   Top5 99.996094   BatchTime 0.105918   LR 0.000010   
2022-11-03 21:50:39,308 - INFO  - Training [54][  220/  391]   Loss 0.047748   Top1 98.274148   Top5 99.996449   BatchTime 0.103697   LR 0.000010   
2022-11-03 21:50:41,000 - INFO  - Training [54][  240/  391]   Loss 0.047301   Top1 98.310547   Top5 99.993490   BatchTime 0.102106   LR 0.000010   
2022-11-03 21:50:42,837 - INFO  - Training [54][  260/  391]   Loss 0.046721   Top1 98.362380   Top5 99.993990   BatchTime 0.101319   LR 0.000010   
2022-11-03 21:50:44,826 - INFO  - Training [54][  280/  391]   Loss 0.046758   Top1 98.359375   Top5 99.994420   BatchTime 0.101183   LR 0.000010   
2022-11-03 21:50:46,823 - INFO  - Training [54][  300/  391]   Loss 0.046621   Top1 98.369792   Top5 99.992188   BatchTime 0.101095   LR 0.000010   
2022-11-03 21:50:48,820 - INFO  - Training [54][  320/  391]   Loss 0.046287   Top1 98.395996   Top5 99.992676   BatchTime 0.101017   LR 0.000010   
2022-11-03 21:50:50,802 - INFO  - Training [54][  340/  391]   Loss 0.046006   Top1 98.414522   Top5 99.993107   BatchTime 0.100903   LR 0.000010   
2022-11-03 21:50:52,787 - INFO  - Training [54][  360/  391]   Loss 0.045916   Top1 98.411458   Top5 99.993490   BatchTime 0.100812   LR 0.000010   
2022-11-03 21:50:54,769 - INFO  - Training [54][  380/  391]   Loss 0.045955   Top1 98.412829   Top5 99.993832   BatchTime 0.100723   LR 0.000010   
2022-11-03 21:50:56,114 - INFO  - ==> Top1: 98.406    Top5: 99.994    Loss: 0.046

2022-11-03 21:50:56,115 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:50:58,802 - INFO  - Validation [54][   20/   79]   Loss 0.382240   Top1 91.054688   Top5 99.765625   BatchTime 0.134288   
2022-11-03 21:50:59,685 - INFO  - Validation [54][   40/   79]   Loss 0.397556   Top1 90.507812   Top5 99.648438   BatchTime 0.089217   
2022-11-03 21:51:00,576 - INFO  - Validation [54][   60/   79]   Loss 0.390900   Top1 90.742188   Top5 99.674479   BatchTime 0.074320   
2022-11-03 21:51:01,668 - INFO  - ==> Top1: 90.560    Top5: 99.680    Loss: 0.387

2022-11-03 21:51:01,714 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:51:01,715 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:51:01,715 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:51:01,826 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:51:01,827 - INFO  - >>>>>>>> Epoch  55
2022-11-03 21:51:01,828 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:51:05,650 - INFO  - Training [55][   20/  391]   Loss 0.048049   Top1 98.476562   Top5 100.000000   BatchTime 0.191092   LR 0.000010   
2022-11-03 21:51:07,640 - INFO  - Training [55][   40/  391]   Loss 0.049620   Top1 98.203125   Top5 100.000000   BatchTime 0.145303   LR 0.000010   
2022-11-03 21:51:09,643 - INFO  - Training [55][   60/  391]   Loss 0.047652   Top1 98.294271   Top5 100.000000   BatchTime 0.130243   LR 0.000010   
2022-11-03 21:51:11,650 - INFO  - Training [55][   80/  391]   Loss 0.046598   Top1 98.369141   Top5 100.000000   BatchTime 0.122770   LR 0.000010   
2022-11-03 21:51:13,646 - INFO  - Training [55][  100/  391]   Loss 0.045569   Top1 98.429688   Top5 100.000000   BatchTime 0.118178   LR 0.000010   
2022-11-03 21:51:15,624 - INFO  - Training [55][  120/  391]   Loss 0.043943   Top1 98.522135   Top5 100.000000   BatchTime 0.114964   LR 0.000010   
2022-11-03 21:51:17,587 - INFO  - Training [55][  140/  391]   Loss 0.044724   Top1 98.470982   Top5 100.000000   BatchTime 0.112562   LR 0.000010   
2022-11-03 21:51:19,554 - INFO  - Training [55][  160/  391]   Loss 0.044458   Top1 98.461914   Top5 100.000000   BatchTime 0.110783   LR 0.000010   
2022-11-03 21:51:21,201 - INFO  - Training [55][  180/  391]   Loss 0.043991   Top1 98.480903   Top5 100.000000   BatchTime 0.107625   LR 0.000010   
2022-11-03 21:51:22,954 - INFO  - Training [55][  200/  391]   Loss 0.043845   Top1 98.507812   Top5 100.000000   BatchTime 0.105626   LR 0.000010   
2022-11-03 21:51:24,593 - INFO  - Training [55][  220/  391]   Loss 0.044710   Top1 98.469460   Top5 99.996449   BatchTime 0.103474   LR 0.000010   
2022-11-03 21:51:26,273 - INFO  - Training [55][  240/  391]   Loss 0.045079   Top1 98.437500   Top5 99.996745   BatchTime 0.101852   LR 0.000010   
2022-11-03 21:51:28,117 - INFO  - Training [55][  260/  391]   Loss 0.045318   Top1 98.413462   Top5 99.996995   BatchTime 0.101107   LR 0.000010   
2022-11-03 21:51:30,118 - INFO  - Training [55][  280/  391]   Loss 0.045068   Top1 98.440290   Top5 99.994420   BatchTime 0.101034   LR 0.000010   
2022-11-03 21:51:32,137 - INFO  - Training [55][  300/  391]   Loss 0.045180   Top1 98.437500   Top5 99.994792   BatchTime 0.101027   LR 0.000010   
2022-11-03 21:51:34,131 - INFO  - Training [55][  320/  391]   Loss 0.044970   Top1 98.444824   Top5 99.995117   BatchTime 0.100945   LR 0.000010   
2022-11-03 21:51:36,112 - INFO  - Training [55][  340/  391]   Loss 0.044860   Top1 98.458180   Top5 99.995404   BatchTime 0.100832   LR 0.000010   
2022-11-03 21:51:38,095 - INFO  - Training [55][  360/  391]   Loss 0.045131   Top1 98.446181   Top5 99.995660   BatchTime 0.100739   LR 0.000010   
2022-11-03 21:51:40,087 - INFO  - Training [55][  380/  391]   Loss 0.044656   Top1 98.474507   Top5 99.995888   BatchTime 0.100679   LR 0.000010   
2022-11-03 21:51:41,423 - INFO  - ==> Top1: 98.482    Top5: 99.996    Loss: 0.045

2022-11-03 21:51:41,424 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:51:44,129 - INFO  - Validation [55][   20/   79]   Loss 0.384053   Top1 90.234375   Top5 99.765625   BatchTime 0.135180   
2022-11-03 21:51:45,026 - INFO  - Validation [55][   40/   79]   Loss 0.396333   Top1 90.273438   Top5 99.687500   BatchTime 0.090016   
2022-11-03 21:51:45,912 - INFO  - Validation [55][   60/   79]   Loss 0.387017   Top1 90.468750   Top5 99.674479   BatchTime 0.074772   
2022-11-03 21:51:47,006 - INFO  - ==> Top1: 90.500    Top5: 99.680    Loss: 0.384

2022-11-03 21:51:47,052 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:51:47,053 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:51:47,053 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:51:47,130 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:51:47,131 - INFO  - >>>>>>>> Epoch  56
2022-11-03 21:51:47,132 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:51:50,987 - INFO  - Training [56][   20/  391]   Loss 0.045052   Top1 98.476562   Top5 100.000000   BatchTime 0.192731   LR 0.000010   
2022-11-03 21:51:53,062 - INFO  - Training [56][   40/  391]   Loss 0.047008   Top1 98.437500   Top5 100.000000   BatchTime 0.148263   LR 0.000010   
2022-11-03 21:51:55,059 - INFO  - Training [56][   60/  391]   Loss 0.044843   Top1 98.541667   Top5 99.986979   BatchTime 0.132119   LR 0.000010   
2022-11-03 21:51:57,057 - INFO  - Training [56][   80/  391]   Loss 0.044776   Top1 98.466797   Top5 99.990234   BatchTime 0.124065   LR 0.000010   
2022-11-03 21:51:59,074 - INFO  - Training [56][  100/  391]   Loss 0.045196   Top1 98.476562   Top5 99.992188   BatchTime 0.119415   LR 0.000010   
2022-11-03 21:52:00,995 - INFO  - Training [56][  120/  391]   Loss 0.044775   Top1 98.489583   Top5 99.986979   BatchTime 0.115528   LR 0.000010   
2022-11-03 21:52:02,973 - INFO  - Training [56][  140/  391]   Loss 0.044905   Top1 98.454241   Top5 99.988839   BatchTime 0.113147   LR 0.000010   
2022-11-03 21:52:04,956 - INFO  - Training [56][  160/  391]   Loss 0.045964   Top1 98.413086   Top5 99.990234   BatchTime 0.111402   LR 0.000010   
2022-11-03 21:52:06,599 - INFO  - Training [56][  180/  391]   Loss 0.045442   Top1 98.454861   Top5 99.991319   BatchTime 0.108149   LR 0.000010   
2022-11-03 21:52:08,300 - INFO  - Training [56][  200/  391]   Loss 0.045401   Top1 98.460938   Top5 99.992188   BatchTime 0.105837   LR 0.000010   
2022-11-03 21:52:09,942 - INFO  - Training [56][  220/  391]   Loss 0.045195   Top1 98.462358   Top5 99.992898   BatchTime 0.103682   LR 0.000010   
2022-11-03 21:52:11,686 - INFO  - Training [56][  240/  391]   Loss 0.044454   Top1 98.486328   Top5 99.993490   BatchTime 0.102306   LR 0.000010   
2022-11-03 21:52:13,419 - INFO  - Training [56][  260/  391]   Loss 0.045344   Top1 98.461538   Top5 99.993990   BatchTime 0.101101   LR 0.000010   
2022-11-03 21:52:15,413 - INFO  - Training [56][  280/  391]   Loss 0.044782   Top1 98.487723   Top5 99.994420   BatchTime 0.101001   LR 0.000010   
2022-11-03 21:52:17,438 - INFO  - Training [56][  300/  391]   Loss 0.044383   Top1 98.497396   Top5 99.994792   BatchTime 0.101019   LR 0.000010   
2022-11-03 21:52:19,479 - INFO  - Training [56][  320/  391]   Loss 0.044489   Top1 98.493652   Top5 99.995117   BatchTime 0.101084   LR 0.000010   
2022-11-03 21:52:21,475 - INFO  - Training [56][  340/  391]   Loss 0.044649   Top1 98.488051   Top5 99.995404   BatchTime 0.101006   LR 0.000010   
2022-11-03 21:52:23,446 - INFO  - Training [56][  360/  391]   Loss 0.044636   Top1 98.498264   Top5 99.995660   BatchTime 0.100870   LR 0.000010   
2022-11-03 21:52:25,415 - INFO  - Training [56][  380/  391]   Loss 0.044311   Top1 98.509457   Top5 99.995888   BatchTime 0.100742   LR 0.000010   
2022-11-03 21:52:26,778 - INFO  - ==> Top1: 98.492    Top5: 99.996    Loss: 0.045

2022-11-03 21:52:26,778 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:52:29,490 - INFO  - Validation [56][   20/   79]   Loss 0.392244   Top1 90.585938   Top5 99.726562   BatchTime 0.135510   
2022-11-03 21:52:30,384 - INFO  - Validation [56][   40/   79]   Loss 0.396730   Top1 90.410156   Top5 99.628906   BatchTime 0.090101   
2022-11-03 21:52:31,288 - INFO  - Validation [56][   60/   79]   Loss 0.391304   Top1 90.703125   Top5 99.622396   BatchTime 0.075133   
2022-11-03 21:52:32,386 - INFO  - ==> Top1: 90.560    Top5: 99.640    Loss: 0.388

2022-11-03 21:52:32,422 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:52:32,422 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:52:32,423 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:52:32,533 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:52:32,533 - INFO  - >>>>>>>> Epoch  57
2022-11-03 21:52:32,535 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:52:36,396 - INFO  - Training [57][   20/  391]   Loss 0.041074   Top1 98.789062   Top5 100.000000   BatchTime 0.193060   LR 0.000010   
2022-11-03 21:52:38,407 - INFO  - Training [57][   40/  391]   Loss 0.042606   Top1 98.496094   Top5 100.000000   BatchTime 0.146809   LR 0.000010   
2022-11-03 21:52:40,431 - INFO  - Training [57][   60/  391]   Loss 0.040502   Top1 98.658854   Top5 100.000000   BatchTime 0.131600   LR 0.000010   
2022-11-03 21:52:42,434 - INFO  - Training [57][   80/  391]   Loss 0.043168   Top1 98.583984   Top5 99.990234   BatchTime 0.123740   LR 0.000010   
2022-11-03 21:52:44,443 - INFO  - Training [57][  100/  391]   Loss 0.042867   Top1 98.554688   Top5 99.992188   BatchTime 0.119077   LR 0.000010   
2022-11-03 21:52:46,407 - INFO  - Training [57][  120/  391]   Loss 0.042997   Top1 98.541667   Top5 99.993490   BatchTime 0.115602   LR 0.000010   
2022-11-03 21:52:48,383 - INFO  - Training [57][  140/  391]   Loss 0.044115   Top1 98.482143   Top5 99.994420   BatchTime 0.113200   LR 0.000010   
2022-11-03 21:52:50,327 - INFO  - Training [57][  160/  391]   Loss 0.044578   Top1 98.452148   Top5 99.995117   BatchTime 0.111201   LR 0.000010   
2022-11-03 21:52:52,032 - INFO  - Training [57][  180/  391]   Loss 0.044642   Top1 98.415799   Top5 99.995660   BatchTime 0.108318   LR 0.000010   
2022-11-03 21:52:53,840 - INFO  - Training [57][  200/  391]   Loss 0.045202   Top1 98.371094   Top5 99.996094   BatchTime 0.106523   LR 0.000010   
2022-11-03 21:52:55,460 - INFO  - Training [57][  220/  391]   Loss 0.045071   Top1 98.391335   Top5 99.996449   BatchTime 0.104204   LR 0.000010   
2022-11-03 21:52:57,124 - INFO  - Training [57][  240/  391]   Loss 0.045303   Top1 98.388672   Top5 99.996745   BatchTime 0.102454   LR 0.000010   
2022-11-03 21:52:58,978 - INFO  - Training [57][  260/  391]   Loss 0.044062   Top1 98.434495   Top5 99.996995   BatchTime 0.101703   LR 0.000010   
2022-11-03 21:53:00,988 - INFO  - Training [57][  280/  391]   Loss 0.043954   Top1 98.431920   Top5 99.994420   BatchTime 0.101616   LR 0.000010   
2022-11-03 21:53:02,995 - INFO  - Training [57][  300/  391]   Loss 0.044559   Top1 98.401042   Top5 99.994792   BatchTime 0.101532   LR 0.000010   
2022-11-03 21:53:05,004 - INFO  - Training [57][  320/  391]   Loss 0.044445   Top1 98.413086   Top5 99.995117   BatchTime 0.101463   LR 0.000010   
2022-11-03 21:53:06,982 - INFO  - Training [57][  340/  391]   Loss 0.044460   Top1 98.423713   Top5 99.995404   BatchTime 0.101314   LR 0.000010   
2022-11-03 21:53:08,946 - INFO  - Training [57][  360/  391]   Loss 0.044194   Top1 98.430990   Top5 99.993490   BatchTime 0.101140   LR 0.000010   
2022-11-03 21:53:10,931 - INFO  - Training [57][  380/  391]   Loss 0.044001   Top1 98.443668   Top5 99.993832   BatchTime 0.101040   LR 0.000010   
2022-11-03 21:53:12,257 - INFO  - ==> Top1: 98.444    Top5: 99.994    Loss: 0.044

2022-11-03 21:53:12,258 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:53:14,964 - INFO  - Validation [57][   20/   79]   Loss 0.396047   Top1 90.234375   Top5 99.492188   BatchTime 0.135230   
2022-11-03 21:53:15,875 - INFO  - Validation [57][   40/   79]   Loss 0.398900   Top1 90.390625   Top5 99.511719   BatchTime 0.090384   
2022-11-03 21:53:16,764 - INFO  - Validation [57][   60/   79]   Loss 0.391113   Top1 90.546875   Top5 99.557292   BatchTime 0.075073   
2022-11-03 21:53:17,924 - INFO  - ==> Top1: 90.520    Top5: 99.570    Loss: 0.390

2022-11-03 21:53:17,953 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:53:17,953 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:53:17,953 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:53:18,066 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:53:18,066 - INFO  - >>>>>>>> Epoch  58
2022-11-03 21:53:18,068 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:53:21,920 - INFO  - Training [58][   20/  391]   Loss 0.045026   Top1 98.671875   Top5 100.000000   BatchTime 0.192624   LR 0.000010   
2022-11-03 21:53:23,923 - INFO  - Training [58][   40/  391]   Loss 0.044732   Top1 98.710938   Top5 100.000000   BatchTime 0.146379   LR 0.000010   
2022-11-03 21:53:25,927 - INFO  - Training [58][   60/  391]   Loss 0.043760   Top1 98.697917   Top5 100.000000   BatchTime 0.130975   LR 0.000010   
2022-11-03 21:53:27,942 - INFO  - Training [58][   80/  391]   Loss 0.045330   Top1 98.623047   Top5 100.000000   BatchTime 0.123426   LR 0.000010   
2022-11-03 21:53:30,033 - INFO  - Training [58][  100/  391]   Loss 0.044051   Top1 98.648438   Top5 99.992188   BatchTime 0.119650   LR 0.000010   
2022-11-03 21:53:31,989 - INFO  - Training [58][  120/  391]   Loss 0.043732   Top1 98.665365   Top5 99.993490   BatchTime 0.116004   LR 0.000010   
2022-11-03 21:53:33,960 - INFO  - Training [58][  140/  391]   Loss 0.043779   Top1 98.632812   Top5 99.994420   BatchTime 0.113513   LR 0.000010   
2022-11-03 21:53:35,971 - INFO  - Training [58][  160/  391]   Loss 0.043851   Top1 98.618164   Top5 99.995117   BatchTime 0.111889   LR 0.000010   
2022-11-03 21:53:37,563 - INFO  - Training [58][  180/  391]   Loss 0.043381   Top1 98.619792   Top5 99.995660   BatchTime 0.108306   LR 0.000010   
2022-11-03 21:53:39,193 - INFO  - Training [58][  200/  391]   Loss 0.043730   Top1 98.585938   Top5 99.996094   BatchTime 0.105625   LR 0.000010   
2022-11-03 21:53:40,778 - INFO  - Training [58][  220/  391]   Loss 0.042991   Top1 98.625710   Top5 99.996449   BatchTime 0.103225   LR 0.000010   
2022-11-03 21:53:42,456 - INFO  - Training [58][  240/  391]   Loss 0.042433   Top1 98.632812   Top5 99.996745   BatchTime 0.101616   LR 0.000010   
2022-11-03 21:53:44,337 - INFO  - Training [58][  260/  391]   Loss 0.043129   Top1 98.617788   Top5 99.996995   BatchTime 0.101032   LR 0.000010   
2022-11-03 21:53:46,345 - INFO  - Training [58][  280/  391]   Loss 0.043211   Top1 98.616071   Top5 99.997210   BatchTime 0.100989   LR 0.000010   
2022-11-03 21:53:48,339 - INFO  - Training [58][  300/  391]   Loss 0.043409   Top1 98.598958   Top5 99.997396   BatchTime 0.100900   LR 0.000010   
2022-11-03 21:53:50,324 - INFO  - Training [58][  320/  391]   Loss 0.043612   Top1 98.581543   Top5 99.997559   BatchTime 0.100797   LR 0.000010   
2022-11-03 21:53:52,324 - INFO  - Training [58][  340/  391]   Loss 0.043456   Top1 98.591452   Top5 99.997702   BatchTime 0.100752   LR 0.000010   
2022-11-03 21:53:54,307 - INFO  - Training [58][  360/  391]   Loss 0.043547   Top1 98.595920   Top5 99.997830   BatchTime 0.100663   LR 0.000010   
2022-11-03 21:53:56,273 - INFO  - Training [58][  380/  391]   Loss 0.043813   Top1 98.583470   Top5 99.997944   BatchTime 0.100538   LR 0.000010   
2022-11-03 21:53:57,615 - INFO  - ==> Top1: 98.578    Top5: 99.998    Loss: 0.044

2022-11-03 21:53:57,615 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:54:00,338 - INFO  - Validation [58][   20/   79]   Loss 0.387101   Top1 90.429688   Top5 99.726562   BatchTime 0.136042   
2022-11-03 21:54:01,199 - INFO  - Validation [58][   40/   79]   Loss 0.397566   Top1 90.429688   Top5 99.609375   BatchTime 0.089562   
2022-11-03 21:54:02,096 - INFO  - Validation [58][   60/   79]   Loss 0.390880   Top1 90.677083   Top5 99.648438   BatchTime 0.074660   
2022-11-03 21:54:03,181 - INFO  - ==> Top1: 90.580    Top5: 99.670    Loss: 0.389

2022-11-03 21:54:03,223 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:54:03,224 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:54:03,224 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:54:03,332 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:54:03,332 - INFO  - >>>>>>>> Epoch  59
2022-11-03 21:54:03,334 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:54:07,221 - INFO  - Training [59][   20/  391]   Loss 0.035292   Top1 98.906250   Top5 100.000000   BatchTime 0.194358   LR 0.000010   
2022-11-03 21:54:09,230 - INFO  - Training [59][   40/  391]   Loss 0.044442   Top1 98.574219   Top5 99.980469   BatchTime 0.147408   LR 0.000010   
2022-11-03 21:54:11,242 - INFO  - Training [59][   60/  391]   Loss 0.043734   Top1 98.593750   Top5 99.986979   BatchTime 0.131800   LR 0.000010   
2022-11-03 21:54:13,278 - INFO  - Training [59][   80/  391]   Loss 0.042010   Top1 98.681641   Top5 99.990234   BatchTime 0.124300   LR 0.000010   
2022-11-03 21:54:15,290 - INFO  - Training [59][  100/  391]   Loss 0.042788   Top1 98.625000   Top5 99.992188   BatchTime 0.119560   LR 0.000010   
2022-11-03 21:54:17,257 - INFO  - Training [59][  120/  391]   Loss 0.043079   Top1 98.600260   Top5 99.993490   BatchTime 0.116025   LR 0.000010   
2022-11-03 21:54:19,247 - INFO  - Training [59][  140/  391]   Loss 0.042227   Top1 98.599330   Top5 99.994420   BatchTime 0.113662   LR 0.000010   
2022-11-03 21:54:21,257 - INFO  - Training [59][  160/  391]   Loss 0.042600   Top1 98.579102   Top5 99.995117   BatchTime 0.112017   LR 0.000010   
2022-11-03 21:54:22,785 - INFO  - Training [59][  180/  391]   Loss 0.042906   Top1 98.559028   Top5 99.995660   BatchTime 0.108063   LR 0.000010   
2022-11-03 21:54:24,463 - INFO  - Training [59][  200/  391]   Loss 0.043656   Top1 98.523438   Top5 99.996094   BatchTime 0.105645   LR 0.000010   
2022-11-03 21:54:26,104 - INFO  - Training [59][  220/  391]   Loss 0.043696   Top1 98.504972   Top5 99.996449   BatchTime 0.103500   LR 0.000010   
2022-11-03 21:54:27,774 - INFO  - Training [59][  240/  391]   Loss 0.043829   Top1 98.505859   Top5 99.996745   BatchTime 0.101831   LR 0.000010   
2022-11-03 21:54:29,689 - INFO  - Training [59][  260/  391]   Loss 0.043789   Top1 98.506611   Top5 99.996995   BatchTime 0.101363   LR 0.000010   
2022-11-03 21:54:31,697 - INFO  - Training [59][  280/  391]   Loss 0.043355   Top1 98.510045   Top5 99.997210   BatchTime 0.101294   LR 0.000010   
2022-11-03 21:54:33,693 - INFO  - Training [59][  300/  391]   Loss 0.043343   Top1 98.502604   Top5 99.994792   BatchTime 0.101195   LR 0.000010   
2022-11-03 21:54:35,712 - INFO  - Training [59][  320/  391]   Loss 0.044072   Top1 98.454590   Top5 99.995117   BatchTime 0.101181   LR 0.000010   
2022-11-03 21:54:37,707 - INFO  - Training [59][  340/  391]   Loss 0.044727   Top1 98.428309   Top5 99.995404   BatchTime 0.101096   LR 0.000010   
2022-11-03 21:54:39,676 - INFO  - Training [59][  360/  391]   Loss 0.044765   Top1 98.409288   Top5 99.995660   BatchTime 0.100949   LR 0.000010   
2022-11-03 21:54:41,644 - INFO  - Training [59][  380/  391]   Loss 0.044473   Top1 98.429276   Top5 99.995888   BatchTime 0.100815   LR 0.000010   
2022-11-03 21:54:42,974 - INFO  - ==> Top1: 98.422    Top5: 99.996    Loss: 0.045

2022-11-03 21:54:42,975 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:54:45,712 - INFO  - Validation [59][   20/   79]   Loss 0.382031   Top1 90.507812   Top5 99.765625   BatchTime 0.136777   
2022-11-03 21:54:46,591 - INFO  - Validation [59][   40/   79]   Loss 0.397879   Top1 90.390625   Top5 99.687500   BatchTime 0.090362   
2022-11-03 21:54:47,485 - INFO  - Validation [59][   60/   79]   Loss 0.393126   Top1 90.625000   Top5 99.674479   BatchTime 0.075144   
2022-11-03 21:54:48,589 - INFO  - ==> Top1: 90.520    Top5: 99.660    Loss: 0.389

2022-11-03 21:54:48,625 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 90.870   Top5: 99.660] Sparsity : 0.808
2022-11-03 21:54:48,625 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.640] Sparsity : 0.808
2022-11-03 21:54:48,625 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.780   Top5: 99.630] Sparsity : 0.808
2022-11-03 21:54:48,692 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch60_20221103-210903/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:54:48,693 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 21:54:48,693 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:54:51,386 - INFO  - Validation [   20/   79]   Loss 0.382031   Top1 90.507812   Top5 99.765625   BatchTime 0.134609   
2022-11-03 21:54:52,278 - INFO  - Validation [   40/   79]   Loss 0.397879   Top1 90.390625   Top5 99.687500   BatchTime 0.089587   
2022-11-03 21:54:53,169 - INFO  - Validation [   60/   79]   Loss 0.393126   Top1 90.625000   Top5 99.674479   BatchTime 0.074580   
2022-11-03 21:54:54,294 - INFO  - ==> Top1: 90.520    Top5: 99.660    Loss: 0.389

2022-11-03 21:54:54,374 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar

2022-11-03 21:54:54,375 - INFO  - Program completed successfully ... exiting ...
2022-11-03 21:54:54,375 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
