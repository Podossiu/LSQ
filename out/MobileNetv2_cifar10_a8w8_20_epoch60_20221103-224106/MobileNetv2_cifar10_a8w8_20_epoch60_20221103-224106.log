2022-11-03 22:41:06,666 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106.log
2022-11-03 22:41:07,669 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/tb_runs
2022-11-03 22:41:08,775 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (391)
        Validation Set = 10000 (79)
              Test Set = 10000 (79)
2022-11-03 22:41:10,449 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = True
2022-11-03 22:41:12,612 - INFO  - Inserted quantizers into the original model
2022-11-03 22:41:12,841 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 22:41:12,841 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 22:41:12,841 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 22:41:12,841 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:41:16,508 - INFO  - Validation [   20/   79]   Loss 2.545371   Top1 10.429688   Top5 49.101562   BatchTime 0.183324   
2022-11-03 22:41:17,386 - INFO  - Validation [   40/   79]   Loss 2.549466   Top1 10.175781   Top5 49.941406   BatchTime 0.113624   
2022-11-03 22:41:18,273 - INFO  - Validation [   60/   79]   Loss 2.541519   Top1 10.117188   Top5 50.377604   BatchTime 0.090532   
2022-11-03 22:41:19,400 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.546

2022-11-03 22:41:19,438 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 22:41:19,438 - INFO  - >>>>>>>> Epoch   0
2022-11-03 22:41:19,439 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:41:23,555 - INFO  - Training [0][   20/  391]   Loss 1.547804   Top1 69.296875   Top5 96.757812   BatchTime 0.205804   LR 0.010000   
2022-11-03 22:41:25,564 - INFO  - Training [0][   40/  391]   Loss 1.298149   Top1 70.527344   Top5 97.246094   BatchTime 0.153136   LR 0.010000   
2022-11-03 22:41:27,591 - INFO  - Training [0][   60/  391]   Loss 1.118628   Top1 71.940104   Top5 97.565104   BatchTime 0.135877   LR 0.010000   
2022-11-03 22:41:29,588 - INFO  - Training [0][   80/  391]   Loss 1.001836   Top1 73.535156   Top5 97.949219   BatchTime 0.126868   LR 0.010000   
2022-11-03 22:41:31,589 - INFO  - Training [0][  100/  391]   Loss 0.911430   Top1 74.882812   Top5 98.210938   BatchTime 0.121497   LR 0.010000   
2022-11-03 22:41:33,605 - INFO  - Training [0][  120/  391]   Loss 0.842658   Top1 76.178385   Top5 98.398438   BatchTime 0.118047   LR 0.010000   
2022-11-03 22:41:35,592 - INFO  - Training [0][  140/  391]   Loss 0.793718   Top1 77.170759   Top5 98.504464   BatchTime 0.115378   LR 0.010000   
2022-11-03 22:41:37,575 - INFO  - Training [0][  160/  391]   Loss 0.753082   Top1 77.958984   Top5 98.627930   BatchTime 0.113351   LR 0.010000   
2022-11-03 22:41:39,557 - INFO  - Training [0][  180/  391]   Loss 0.717213   Top1 78.750000   Top5 98.710938   BatchTime 0.111767   LR 0.010000   
2022-11-03 22:41:41,566 - INFO  - Training [0][  200/  391]   Loss 0.692259   Top1 79.214844   Top5 98.761719   BatchTime 0.110634   LR 0.010000   
2022-11-03 22:41:43,548 - INFO  - Training [0][  220/  391]   Loss 0.669018   Top1 79.715909   Top5 98.824574   BatchTime 0.109587   LR 0.010000   
2022-11-03 22:41:45,567 - INFO  - Training [0][  240/  391]   Loss 0.648714   Top1 80.169271   Top5 98.886719   BatchTime 0.108864   LR 0.010000   
2022-11-03 22:41:47,532 - INFO  - Training [0][  260/  391]   Loss 0.628460   Top1 80.646034   Top5 98.948317   BatchTime 0.108047   LR 0.010000   
2022-11-03 22:41:49,501 - INFO  - Training [0][  280/  391]   Loss 0.612703   Top1 81.015625   Top5 98.989955   BatchTime 0.107364   LR 0.010000   
2022-11-03 22:41:51,463 - INFO  - Training [0][  300/  391]   Loss 0.599784   Top1 81.286458   Top5 99.005208   BatchTime 0.106745   LR 0.010000   
2022-11-03 22:41:53,385 - INFO  - Training [0][  320/  391]   Loss 0.585583   Top1 81.652832   Top5 99.047852   BatchTime 0.106081   LR 0.010000   
2022-11-03 22:41:55,003 - INFO  - Training [0][  340/  391]   Loss 0.573082   Top1 81.953125   Top5 99.076287   BatchTime 0.104599   LR 0.010000   
2022-11-03 22:41:56,643 - INFO  - Training [0][  360/  391]   Loss 0.560171   Top1 82.280816   Top5 99.116753   BatchTime 0.103344   LR 0.010000   
2022-11-03 22:41:58,369 - INFO  - Training [0][  380/  391]   Loss 0.550116   Top1 82.571957   Top5 99.140625   BatchTime 0.102447   LR 0.010000   
2022-11-03 22:41:59,782 - INFO  - ==> Top1: 82.714    Top5: 99.150    Loss: 0.545

2022-11-03 22:41:59,783 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:42:02,590 - INFO  - Validation [0][   20/   79]   Loss 0.456158   Top1 85.039062   Top5 99.414062   BatchTime 0.140300   
2022-11-03 22:42:03,482 - INFO  - Validation [0][   40/   79]   Loss 0.458075   Top1 85.039062   Top5 99.257812   BatchTime 0.092449   
2022-11-03 22:42:04,372 - INFO  - Validation [0][   60/   79]   Loss 0.461006   Top1 84.882812   Top5 99.296875   BatchTime 0.076460   
2022-11-03 22:42:05,449 - INFO  - ==> Top1: 84.570    Top5: 99.370    Loss: 0.460

2022-11-03 22:42:05,481 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.570   Top5: 99.370] Sparsity : 0.593
2022-11-03 22:42:05,481 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 22:42:05,545 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:42:05,545 - INFO  - >>>>>>>> Epoch   1
2022-11-03 22:42:05,546 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:42:09,390 - INFO  - Training [1][   20/  391]   Loss 0.334199   Top1 88.359375   Top5 99.726562   BatchTime 0.192167   LR 0.010000   
2022-11-03 22:42:11,403 - INFO  - Training [1][   40/  391]   Loss 0.319475   Top1 89.062500   Top5 99.648438   BatchTime 0.146415   LR 0.010000   
2022-11-03 22:42:13,407 - INFO  - Training [1][   60/  391]   Loss 0.318866   Top1 89.088542   Top5 99.700521   BatchTime 0.131014   LR 0.010000   
2022-11-03 22:42:15,403 - INFO  - Training [1][   80/  391]   Loss 0.318700   Top1 88.955078   Top5 99.707031   BatchTime 0.123208   LR 0.010000   
2022-11-03 22:42:17,420 - INFO  - Training [1][  100/  391]   Loss 0.312545   Top1 89.164062   Top5 99.718750   BatchTime 0.118735   LR 0.010000   
2022-11-03 22:42:19,425 - INFO  - Training [1][  120/  391]   Loss 0.309983   Top1 89.290365   Top5 99.713542   BatchTime 0.115654   LR 0.010000   
2022-11-03 22:42:21,426 - INFO  - Training [1][  140/  391]   Loss 0.304069   Top1 89.531250   Top5 99.743304   BatchTime 0.113423   LR 0.010000   
2022-11-03 22:42:23,439 - INFO  - Training [1][  160/  391]   Loss 0.302743   Top1 89.521484   Top5 99.750977   BatchTime 0.111826   LR 0.010000   
2022-11-03 22:42:25,449 - INFO  - Training [1][  180/  391]   Loss 0.300818   Top1 89.513889   Top5 99.748264   BatchTime 0.110567   LR 0.010000   
2022-11-03 22:42:27,478 - INFO  - Training [1][  200/  391]   Loss 0.298429   Top1 89.582031   Top5 99.738281   BatchTime 0.109656   LR 0.010000   
2022-11-03 22:42:29,490 - INFO  - Training [1][  220/  391]   Loss 0.297907   Top1 89.651989   Top5 99.730114   BatchTime 0.108835   LR 0.010000   
2022-11-03 22:42:31,498 - INFO  - Training [1][  240/  391]   Loss 0.295798   Top1 89.720052   Top5 99.742839   BatchTime 0.108130   LR 0.010000   
2022-11-03 22:42:33,503 - INFO  - Training [1][  260/  391]   Loss 0.293711   Top1 89.786659   Top5 99.759615   BatchTime 0.107524   LR 0.010000   
2022-11-03 22:42:35,496 - INFO  - Training [1][  280/  391]   Loss 0.291411   Top1 89.852121   Top5 99.762835   BatchTime 0.106962   LR 0.010000   
2022-11-03 22:42:37,476 - INFO  - Training [1][  300/  391]   Loss 0.289720   Top1 89.903646   Top5 99.765625   BatchTime 0.106432   LR 0.010000   
2022-11-03 22:42:39,451 - INFO  - Training [1][  320/  391]   Loss 0.288012   Top1 89.914551   Top5 99.772949   BatchTime 0.105950   LR 0.010000   
2022-11-03 22:42:41,054 - INFO  - Training [1][  340/  391]   Loss 0.287279   Top1 89.949449   Top5 99.772518   BatchTime 0.104432   LR 0.010000   
2022-11-03 22:42:42,728 - INFO  - Training [1][  360/  391]   Loss 0.285411   Top1 89.982639   Top5 99.780816   BatchTime 0.103282   LR 0.010000   
2022-11-03 22:42:44,319 - INFO  - Training [1][  380/  391]   Loss 0.284007   Top1 90.010280   Top5 99.786184   BatchTime 0.102032   LR 0.010000   
2022-11-03 22:42:45,634 - INFO  - ==> Top1: 90.036    Top5: 99.792    Loss: 0.283

2022-11-03 22:42:45,636 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:42:48,267 - INFO  - Validation [1][   20/   79]   Loss 0.449490   Top1 85.625000   Top5 99.453125   BatchTime 0.131483   
2022-11-03 22:42:49,177 - INFO  - Validation [1][   40/   79]   Loss 0.449532   Top1 85.800781   Top5 99.375000   BatchTime 0.088487   
2022-11-03 22:42:50,064 - INFO  - Validation [1][   60/   79]   Loss 0.439498   Top1 86.145833   Top5 99.440104   BatchTime 0.073776   
2022-11-03 22:42:51,192 - INFO  - ==> Top1: 86.370    Top5: 99.460    Loss: 0.435

2022-11-03 22:42:51,225 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.370   Top5: 99.460] Sparsity : 0.630
2022-11-03 22:42:51,225 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.570   Top5: 99.370] Sparsity : 0.593
2022-11-03 22:42:51,226 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 22:42:51,408 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:42:51,409 - INFO  - >>>>>>>> Epoch   2
2022-11-03 22:42:51,410 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:42:55,225 - INFO  - Training [2][   20/  391]   Loss 0.221092   Top1 93.046875   Top5 99.765625   BatchTime 0.190740   LR 0.010000   
2022-11-03 22:42:57,230 - INFO  - Training [2][   40/  391]   Loss 0.219095   Top1 92.656250   Top5 99.863281   BatchTime 0.145481   LR 0.010000   
2022-11-03 22:42:59,254 - INFO  - Training [2][   60/  391]   Loss 0.220840   Top1 92.486979   Top5 99.856771   BatchTime 0.130721   LR 0.010000   
2022-11-03 22:43:01,261 - INFO  - Training [2][   80/  391]   Loss 0.219047   Top1 92.402344   Top5 99.824219   BatchTime 0.123138   LR 0.010000   
2022-11-03 22:43:03,258 - INFO  - Training [2][  100/  391]   Loss 0.221442   Top1 92.273438   Top5 99.828125   BatchTime 0.118474   LR 0.010000   
2022-11-03 22:43:05,266 - INFO  - Training [2][  120/  391]   Loss 0.221635   Top1 92.246094   Top5 99.843750   BatchTime 0.115463   LR 0.010000   
2022-11-03 22:43:07,272 - INFO  - Training [2][  140/  391]   Loss 0.221780   Top1 92.293527   Top5 99.860491   BatchTime 0.113294   LR 0.010000   
2022-11-03 22:43:09,267 - INFO  - Training [2][  160/  391]   Loss 0.224275   Top1 92.182617   Top5 99.853516   BatchTime 0.111600   LR 0.010000   
2022-11-03 22:43:11,276 - INFO  - Training [2][  180/  391]   Loss 0.224761   Top1 92.157118   Top5 99.869792   BatchTime 0.110362   LR 0.010000   
2022-11-03 22:43:13,300 - INFO  - Training [2][  200/  391]   Loss 0.223797   Top1 92.218750   Top5 99.875000   BatchTime 0.109447   LR 0.010000   
2022-11-03 22:43:15,307 - INFO  - Training [2][  220/  391]   Loss 0.226984   Top1 92.095170   Top5 99.872159   BatchTime 0.108620   LR 0.010000   
2022-11-03 22:43:17,329 - INFO  - Training [2][  240/  391]   Loss 0.227760   Top1 92.067057   Top5 99.873047   BatchTime 0.107993   LR 0.010000   
2022-11-03 22:43:19,341 - INFO  - Training [2][  260/  391]   Loss 0.228599   Top1 92.043269   Top5 99.867788   BatchTime 0.107423   LR 0.010000   
2022-11-03 22:43:21,328 - INFO  - Training [2][  280/  391]   Loss 0.229196   Top1 92.045201   Top5 99.871652   BatchTime 0.106847   LR 0.010000   
2022-11-03 22:43:23,307 - INFO  - Training [2][  300/  391]   Loss 0.230066   Top1 92.041667   Top5 99.864583   BatchTime 0.106322   LR 0.010000   
2022-11-03 22:43:25,297 - INFO  - Training [2][  320/  391]   Loss 0.230063   Top1 92.019043   Top5 99.858398   BatchTime 0.105893   LR 0.010000   
2022-11-03 22:43:27,085 - INFO  - Training [2][  340/  391]   Loss 0.230986   Top1 91.985294   Top5 99.852941   BatchTime 0.104924   LR 0.010000   
2022-11-03 22:43:28,707 - INFO  - Training [2][  360/  391]   Loss 0.230435   Top1 91.996528   Top5 99.856771   BatchTime 0.103599   LR 0.010000   
2022-11-03 22:43:30,274 - INFO  - Training [2][  380/  391]   Loss 0.229963   Top1 92.010691   Top5 99.849918   BatchTime 0.102272   LR 0.010000   
2022-11-03 22:43:31,507 - INFO  - ==> Top1: 92.008    Top5: 99.854    Loss: 0.230

2022-11-03 22:43:31,508 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:43:34,132 - INFO  - Validation [2][   20/   79]   Loss 0.401712   Top1 87.421875   Top5 99.296875   BatchTime 0.131151   
2022-11-03 22:43:35,005 - INFO  - Validation [2][   40/   79]   Loss 0.409924   Top1 87.519531   Top5 99.199219   BatchTime 0.087395   
2022-11-03 22:43:35,942 - INFO  - Validation [2][   60/   79]   Loss 0.405759   Top1 87.565104   Top5 99.348958   BatchTime 0.073870   
2022-11-03 22:43:37,071 - INFO  - ==> Top1: 87.500    Top5: 99.430    Loss: 0.408

2022-11-03 22:43:37,108 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.500   Top5: 99.430] Sparsity : 0.715
2022-11-03 22:43:37,109 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.370   Top5: 99.460] Sparsity : 0.630
2022-11-03 22:43:37,109 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 84.570   Top5: 99.370] Sparsity : 0.593
2022-11-03 22:43:37,292 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:43:37,292 - INFO  - >>>>>>>> Epoch   3
2022-11-03 22:43:37,293 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:43:41,085 - INFO  - Training [3][   20/  391]   Loss 0.207268   Top1 92.851562   Top5 99.921875   BatchTime 0.189560   LR 0.010000   
2022-11-03 22:43:43,091 - INFO  - Training [3][   40/  391]   Loss 0.199856   Top1 93.242188   Top5 99.902344   BatchTime 0.144951   LR 0.010000   
2022-11-03 22:43:45,102 - INFO  - Training [3][   60/  391]   Loss 0.202058   Top1 93.177083   Top5 99.882812   BatchTime 0.130145   LR 0.010000   
2022-11-03 22:43:47,101 - INFO  - Training [3][   80/  391]   Loss 0.202730   Top1 93.115234   Top5 99.902344   BatchTime 0.122594   LR 0.010000   
2022-11-03 22:43:49,119 - INFO  - Training [3][  100/  391]   Loss 0.208077   Top1 92.843750   Top5 99.914062   BatchTime 0.118259   LR 0.010000   
2022-11-03 22:43:51,124 - INFO  - Training [3][  120/  391]   Loss 0.212017   Top1 92.721354   Top5 99.908854   BatchTime 0.115256   LR 0.010000   
2022-11-03 22:43:53,119 - INFO  - Training [3][  140/  391]   Loss 0.214771   Top1 92.639509   Top5 99.905134   BatchTime 0.113042   LR 0.010000   
2022-11-03 22:43:55,113 - INFO  - Training [3][  160/  391]   Loss 0.216506   Top1 92.631836   Top5 99.892578   BatchTime 0.111373   LR 0.010000   
2022-11-03 22:43:57,105 - INFO  - Training [3][  180/  391]   Loss 0.221621   Top1 92.460938   Top5 99.887153   BatchTime 0.110063   LR 0.010000   
2022-11-03 22:43:59,110 - INFO  - Training [3][  200/  391]   Loss 0.222040   Top1 92.433594   Top5 99.871094   BatchTime 0.109080   LR 0.010000   
2022-11-03 22:44:01,123 - INFO  - Training [3][  220/  391]   Loss 0.223677   Top1 92.382812   Top5 99.868608   BatchTime 0.108313   LR 0.010000   
2022-11-03 22:44:03,109 - INFO  - Training [3][  240/  391]   Loss 0.224812   Top1 92.343750   Top5 99.876302   BatchTime 0.107565   LR 0.010000   
2022-11-03 22:44:05,119 - INFO  - Training [3][  260/  391]   Loss 0.226039   Top1 92.262620   Top5 99.867788   BatchTime 0.107020   LR 0.010000   
2022-11-03 22:44:07,094 - INFO  - Training [3][  280/  391]   Loss 0.227059   Top1 92.207031   Top5 99.871652   BatchTime 0.106430   LR 0.010000   
2022-11-03 22:44:09,066 - INFO  - Training [3][  300/  391]   Loss 0.225985   Top1 92.216146   Top5 99.880208   BatchTime 0.105906   LR 0.010000   
2022-11-03 22:44:11,042 - INFO  - Training [3][  320/  391]   Loss 0.224551   Top1 92.272949   Top5 99.880371   BatchTime 0.105462   LR 0.010000   
2022-11-03 22:44:12,846 - INFO  - Training [3][  340/  391]   Loss 0.224366   Top1 92.267923   Top5 99.885110   BatchTime 0.104566   LR 0.010000   
2022-11-03 22:44:14,370 - INFO  - Training [3][  360/  391]   Loss 0.224463   Top1 92.250434   Top5 99.891493   BatchTime 0.102988   LR 0.010000   
2022-11-03 22:44:15,985 - INFO  - Training [3][  380/  391]   Loss 0.224017   Top1 92.257401   Top5 99.886924   BatchTime 0.101819   LR 0.010000   
2022-11-03 22:44:17,095 - INFO  - ==> Top1: 92.258    Top5: 99.884    Loss: 0.224

2022-11-03 22:44:17,096 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:44:19,569 - INFO  - Validation [3][   20/   79]   Loss 0.423584   Top1 87.265625   Top5 99.296875   BatchTime 0.123572   
2022-11-03 22:44:20,497 - INFO  - Validation [3][   40/   79]   Loss 0.414104   Top1 87.363281   Top5 99.179688   BatchTime 0.084993   
2022-11-03 22:44:21,403 - INFO  - Validation [3][   60/   79]   Loss 0.412683   Top1 87.382812   Top5 99.257812   BatchTime 0.071764   
2022-11-03 22:44:22,526 - INFO  - ==> Top1: 87.590    Top5: 99.360    Loss: 0.403

2022-11-03 22:44:22,562 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 87.590   Top5: 99.360] Sparsity : 0.740
2022-11-03 22:44:22,563 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.500   Top5: 99.430] Sparsity : 0.715
2022-11-03 22:44:22,563 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.370   Top5: 99.460] Sparsity : 0.630
2022-11-03 22:44:22,840 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:44:22,841 - INFO  - >>>>>>>> Epoch   4
2022-11-03 22:44:22,842 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:44:26,651 - INFO  - Training [4][   20/  391]   Loss 0.201467   Top1 92.656250   Top5 99.882812   BatchTime 0.190439   LR 0.010000   
2022-11-03 22:44:28,662 - INFO  - Training [4][   40/  391]   Loss 0.203158   Top1 92.871094   Top5 99.902344   BatchTime 0.145486   LR 0.010000   
2022-11-03 22:44:30,676 - INFO  - Training [4][   60/  391]   Loss 0.199934   Top1 93.072917   Top5 99.921875   BatchTime 0.130555   LR 0.010000   
2022-11-03 22:44:32,669 - INFO  - Training [4][   80/  391]   Loss 0.196938   Top1 93.085938   Top5 99.931641   BatchTime 0.122839   LR 0.010000   
2022-11-03 22:44:34,671 - INFO  - Training [4][  100/  391]   Loss 0.197364   Top1 93.156250   Top5 99.945312   BatchTime 0.118288   LR 0.010000   
2022-11-03 22:44:36,668 - INFO  - Training [4][  120/  391]   Loss 0.199027   Top1 93.072917   Top5 99.941406   BatchTime 0.115214   LR 0.010000   
2022-11-03 22:44:38,668 - INFO  - Training [4][  140/  391]   Loss 0.201855   Top1 93.030134   Top5 99.944196   BatchTime 0.113041   LR 0.010000   
2022-11-03 22:44:40,688 - INFO  - Training [4][  160/  391]   Loss 0.199964   Top1 93.125000   Top5 99.926758   BatchTime 0.111537   LR 0.010000   
2022-11-03 22:44:42,707 - INFO  - Training [4][  180/  391]   Loss 0.198613   Top1 93.107639   Top5 99.921875   BatchTime 0.110359   LR 0.010000   
2022-11-03 22:44:44,707 - INFO  - Training [4][  200/  391]   Loss 0.196892   Top1 93.136719   Top5 99.925781   BatchTime 0.109321   LR 0.010000   
2022-11-03 22:44:46,701 - INFO  - Training [4][  220/  391]   Loss 0.195335   Top1 93.220881   Top5 99.928977   BatchTime 0.108445   LR 0.010000   
2022-11-03 22:44:48,714 - INFO  - Training [4][  240/  391]   Loss 0.192756   Top1 93.297526   Top5 99.931641   BatchTime 0.107799   LR 0.010000   
2022-11-03 22:44:50,715 - INFO  - Training [4][  260/  391]   Loss 0.192335   Top1 93.350361   Top5 99.930889   BatchTime 0.107200   LR 0.010000   
2022-11-03 22:44:52,695 - INFO  - Training [4][  280/  391]   Loss 0.191881   Top1 93.351004   Top5 99.927455   BatchTime 0.106617   LR 0.010000   
2022-11-03 22:44:54,682 - INFO  - Training [4][  300/  391]   Loss 0.190972   Top1 93.401042   Top5 99.924479   BatchTime 0.106131   LR 0.010000   
2022-11-03 22:44:56,660 - INFO  - Training [4][  320/  391]   Loss 0.189618   Top1 93.432617   Top5 99.929199   BatchTime 0.105678   LR 0.010000   
2022-11-03 22:44:58,582 - INFO  - Training [4][  340/  391]   Loss 0.188536   Top1 93.478860   Top5 99.933364   BatchTime 0.105116   LR 0.010000   
2022-11-03 22:45:00,152 - INFO  - Training [4][  360/  391]   Loss 0.188205   Top1 93.478733   Top5 99.934896   BatchTime 0.103635   LR 0.010000   
2022-11-03 22:45:01,745 - INFO  - Training [4][  380/  391]   Loss 0.187744   Top1 93.495066   Top5 99.936266   BatchTime 0.102375   LR 0.010000   
2022-11-03 22:45:02,845 - INFO  - ==> Top1: 93.500    Top5: 99.936    Loss: 0.188

2022-11-03 22:45:02,846 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:45:05,269 - INFO  - Validation [4][   20/   79]   Loss 0.401370   Top1 88.164062   Top5 99.453125   BatchTime 0.121062   
2022-11-03 22:45:06,046 - INFO  - Validation [4][   40/   79]   Loss 0.392270   Top1 88.457031   Top5 99.414062   BatchTime 0.079939   
2022-11-03 22:45:06,850 - INFO  - Validation [4][   60/   79]   Loss 0.387324   Top1 88.346354   Top5 99.492188   BatchTime 0.066697   
2022-11-03 22:45:07,936 - INFO  - ==> Top1: 88.410    Top5: 99.540    Loss: 0.383

2022-11-03 22:45:07,972 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.410   Top5: 99.540] Sparsity : 0.745
2022-11-03 22:45:07,973 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 87.590   Top5: 99.360] Sparsity : 0.740
2022-11-03 22:45:07,973 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.500   Top5: 99.430] Sparsity : 0.715
2022-11-03 22:45:08,160 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:45:08,160 - INFO  - >>>>>>>> Epoch   5
2022-11-03 22:45:08,161 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:45:12,053 - INFO  - Training [5][   20/  391]   Loss 0.174046   Top1 94.335938   Top5 99.921875   BatchTime 0.194593   LR 0.010000   
2022-11-03 22:45:14,066 - INFO  - Training [5][   40/  391]   Loss 0.152183   Top1 95.078125   Top5 99.941406   BatchTime 0.147610   LR 0.010000   
2022-11-03 22:45:16,079 - INFO  - Training [5][   60/  391]   Loss 0.158089   Top1 94.713542   Top5 99.934896   BatchTime 0.131954   LR 0.010000   
2022-11-03 22:45:18,068 - INFO  - Training [5][   80/  391]   Loss 0.155257   Top1 94.687500   Top5 99.941406   BatchTime 0.123834   LR 0.010000   
2022-11-03 22:45:20,079 - INFO  - Training [5][  100/  391]   Loss 0.153881   Top1 94.742188   Top5 99.929688   BatchTime 0.119174   LR 0.010000   
2022-11-03 22:45:22,090 - INFO  - Training [5][  120/  391]   Loss 0.153272   Top1 94.720052   Top5 99.934896   BatchTime 0.116068   LR 0.010000   
2022-11-03 22:45:24,108 - INFO  - Training [5][  140/  391]   Loss 0.152384   Top1 94.743304   Top5 99.938616   BatchTime 0.113906   LR 0.010000   
2022-11-03 22:45:26,107 - INFO  - Training [5][  160/  391]   Loss 0.154932   Top1 94.687500   Top5 99.936523   BatchTime 0.112156   LR 0.010000   
2022-11-03 22:45:28,112 - INFO  - Training [5][  180/  391]   Loss 0.154236   Top1 94.717882   Top5 99.943576   BatchTime 0.110833   LR 0.010000   
2022-11-03 22:45:30,119 - INFO  - Training [5][  200/  391]   Loss 0.154830   Top1 94.625000   Top5 99.949219   BatchTime 0.109788   LR 0.010000   
2022-11-03 22:45:32,126 - INFO  - Training [5][  220/  391]   Loss 0.158061   Top1 94.502841   Top5 99.943182   BatchTime 0.108931   LR 0.010000   
2022-11-03 22:45:34,146 - INFO  - Training [5][  240/  391]   Loss 0.156991   Top1 94.557292   Top5 99.941406   BatchTime 0.108267   LR 0.010000   
2022-11-03 22:45:36,146 - INFO  - Training [5][  260/  391]   Loss 0.156754   Top1 94.561298   Top5 99.945913   BatchTime 0.107631   LR 0.010000   
2022-11-03 22:45:38,153 - INFO  - Training [5][  280/  391]   Loss 0.157078   Top1 94.578683   Top5 99.946987   BatchTime 0.107111   LR 0.010000   
2022-11-03 22:45:40,143 - INFO  - Training [5][  300/  391]   Loss 0.156813   Top1 94.557292   Top5 99.950521   BatchTime 0.106603   LR 0.010000   
2022-11-03 22:45:42,125 - INFO  - Training [5][  320/  391]   Loss 0.156095   Top1 94.577637   Top5 99.943848   BatchTime 0.106135   LR 0.010000   
2022-11-03 22:45:44,209 - INFO  - Training [5][  340/  391]   Loss 0.157354   Top1 94.545037   Top5 99.928768   BatchTime 0.106021   LR 0.010000   
2022-11-03 22:45:45,662 - INFO  - Training [5][  360/  391]   Loss 0.156787   Top1 94.552951   Top5 99.928385   BatchTime 0.104167   LR 0.010000   
2022-11-03 22:45:47,306 - INFO  - Training [5][  380/  391]   Loss 0.157156   Top1 94.520970   Top5 99.928043   BatchTime 0.103011   LR 0.010000   
2022-11-03 22:45:48,409 - INFO  - ==> Top1: 94.498    Top5: 99.930    Loss: 0.158

2022-11-03 22:45:48,410 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:45:50,849 - INFO  - Validation [5][   20/   79]   Loss 0.402134   Top1 88.164062   Top5 99.414062   BatchTime 0.121901   
2022-11-03 22:45:51,414 - INFO  - Validation [5][   40/   79]   Loss 0.399562   Top1 88.398438   Top5 99.355469   BatchTime 0.075068   
2022-11-03 22:45:52,349 - INFO  - Validation [5][   60/   79]   Loss 0.392018   Top1 88.632812   Top5 99.453125   BatchTime 0.065631   
2022-11-03 22:45:53,453 - INFO  - ==> Top1: 88.470    Top5: 99.490    Loss: 0.391

2022-11-03 22:45:53,491 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 88.470   Top5: 99.490] Sparsity : 0.751
2022-11-03 22:45:53,492 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.410   Top5: 99.540] Sparsity : 0.745
2022-11-03 22:45:53,492 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 87.590   Top5: 99.360] Sparsity : 0.740
2022-11-03 22:45:53,677 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:45:53,678 - INFO  - >>>>>>>> Epoch   6
2022-11-03 22:45:53,679 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:45:57,496 - INFO  - Training [6][   20/  391]   Loss 0.155695   Top1 94.101562   Top5 99.921875   BatchTime 0.190843   LR 0.010000   
2022-11-03 22:45:59,485 - INFO  - Training [6][   40/  391]   Loss 0.148453   Top1 94.804688   Top5 99.921875   BatchTime 0.145153   LR 0.010000   
2022-11-03 22:46:01,479 - INFO  - Training [6][   60/  391]   Loss 0.145516   Top1 94.921875   Top5 99.947917   BatchTime 0.130000   LR 0.010000   
2022-11-03 22:46:03,483 - INFO  - Training [6][   80/  391]   Loss 0.143396   Top1 95.009766   Top5 99.941406   BatchTime 0.122549   LR 0.010000   
2022-11-03 22:46:05,469 - INFO  - Training [6][  100/  391]   Loss 0.146371   Top1 94.929688   Top5 99.937500   BatchTime 0.117904   LR 0.010000   
2022-11-03 22:46:07,469 - INFO  - Training [6][  120/  391]   Loss 0.144588   Top1 95.019531   Top5 99.941406   BatchTime 0.114918   LR 0.010000   
2022-11-03 22:46:09,485 - INFO  - Training [6][  140/  391]   Loss 0.145236   Top1 95.011161   Top5 99.949777   BatchTime 0.112898   LR 0.010000   
2022-11-03 22:46:11,499 - INFO  - Training [6][  160/  391]   Loss 0.142803   Top1 95.087891   Top5 99.956055   BatchTime 0.111374   LR 0.010000   
2022-11-03 22:46:13,509 - INFO  - Training [6][  180/  391]   Loss 0.142723   Top1 95.082465   Top5 99.956597   BatchTime 0.110168   LR 0.010000   
2022-11-03 22:46:15,514 - INFO  - Training [6][  200/  391]   Loss 0.143053   Top1 95.105469   Top5 99.953125   BatchTime 0.109176   LR 0.010000   
2022-11-03 22:46:17,521 - INFO  - Training [6][  220/  391]   Loss 0.142508   Top1 95.074574   Top5 99.957386   BatchTime 0.108372   LR 0.010000   
2022-11-03 22:46:19,541 - INFO  - Training [6][  240/  391]   Loss 0.143604   Top1 95.042318   Top5 99.954427   BatchTime 0.107756   LR 0.010000   
2022-11-03 22:46:21,546 - INFO  - Training [6][  260/  391]   Loss 0.143453   Top1 95.036058   Top5 99.951923   BatchTime 0.107181   LR 0.010000   
2022-11-03 22:46:23,543 - INFO  - Training [6][  280/  391]   Loss 0.143090   Top1 95.053013   Top5 99.952567   BatchTime 0.106657   LR 0.010000   
2022-11-03 22:46:25,529 - INFO  - Training [6][  300/  391]   Loss 0.143508   Top1 95.039062   Top5 99.950521   BatchTime 0.106166   LR 0.010000   
2022-11-03 22:46:27,513 - INFO  - Training [6][  320/  391]   Loss 0.143342   Top1 95.065918   Top5 99.953613   BatchTime 0.105731   LR 0.010000   
2022-11-03 22:46:29,477 - INFO  - Training [6][  340/  391]   Loss 0.144477   Top1 95.002298   Top5 99.956342   BatchTime 0.105287   LR 0.010000   
2022-11-03 22:46:31,144 - INFO  - Training [6][  360/  391]   Loss 0.145078   Top1 94.956597   Top5 99.958767   BatchTime 0.104067   LR 0.010000   
2022-11-03 22:46:32,819 - INFO  - Training [6][  380/  391]   Loss 0.146432   Top1 94.893092   Top5 99.960938   BatchTime 0.102998   LR 0.010000   
2022-11-03 22:46:33,942 - INFO  - ==> Top1: 94.876    Top5: 99.958    Loss: 0.147

2022-11-03 22:46:33,943 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:46:36,357 - INFO  - Validation [6][   20/   79]   Loss 0.392419   Top1 88.046875   Top5 99.414062   BatchTime 0.120614   
2022-11-03 22:46:36,882 - INFO  - Validation [6][   40/   79]   Loss 0.394724   Top1 88.339844   Top5 99.394531   BatchTime 0.073447   
2022-11-03 22:46:37,679 - INFO  - Validation [6][   60/   79]   Loss 0.388793   Top1 88.541667   Top5 99.479167   BatchTime 0.062240   
2022-11-03 22:46:38,808 - INFO  - ==> Top1: 88.610    Top5: 99.530    Loss: 0.383

2022-11-03 22:46:38,840 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 88.610   Top5: 99.530] Sparsity : 0.764
2022-11-03 22:46:38,841 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.470   Top5: 99.490] Sparsity : 0.751
2022-11-03 22:46:38,841 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.410   Top5: 99.540] Sparsity : 0.745
2022-11-03 22:46:39,039 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:46:39,039 - INFO  - >>>>>>>> Epoch   7
2022-11-03 22:46:39,040 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:46:42,810 - INFO  - Training [7][   20/  391]   Loss 0.150120   Top1 94.257812   Top5 100.000000   BatchTime 0.188484   LR 0.010000   
2022-11-03 22:46:44,790 - INFO  - Training [7][   40/  391]   Loss 0.158724   Top1 94.394531   Top5 99.941406   BatchTime 0.143746   LR 0.010000   
2022-11-03 22:46:46,825 - INFO  - Training [7][   60/  391]   Loss 0.158347   Top1 94.492188   Top5 99.921875   BatchTime 0.129733   LR 0.010000   
2022-11-03 22:46:48,973 - INFO  - Training [7][   80/  391]   Loss 0.162223   Top1 94.433594   Top5 99.931641   BatchTime 0.124156   LR 0.010000   
2022-11-03 22:46:50,986 - INFO  - Training [7][  100/  391]   Loss 0.160614   Top1 94.429688   Top5 99.929688   BatchTime 0.119458   LR 0.010000   
2022-11-03 22:46:52,997 - INFO  - Training [7][  120/  391]   Loss 0.161658   Top1 94.407552   Top5 99.928385   BatchTime 0.116307   LR 0.010000   
2022-11-03 22:46:55,012 - INFO  - Training [7][  140/  391]   Loss 0.164116   Top1 94.246652   Top5 99.927455   BatchTime 0.114080   LR 0.010000   
2022-11-03 22:46:57,029 - INFO  - Training [7][  160/  391]   Loss 0.164787   Top1 94.272461   Top5 99.907227   BatchTime 0.112424   LR 0.010000   
2022-11-03 22:46:59,038 - INFO  - Training [7][  180/  391]   Loss 0.166794   Top1 94.210069   Top5 99.917535   BatchTime 0.111095   LR 0.010000   
2022-11-03 22:47:01,039 - INFO  - Training [7][  200/  391]   Loss 0.169172   Top1 94.097656   Top5 99.925781   BatchTime 0.109989   LR 0.010000   
2022-11-03 22:47:03,048 - INFO  - Training [7][  220/  391]   Loss 0.170068   Top1 94.080256   Top5 99.921875   BatchTime 0.109124   LR 0.010000   
2022-11-03 22:47:05,054 - INFO  - Training [7][  240/  391]   Loss 0.173522   Top1 93.964844   Top5 99.915365   BatchTime 0.108389   LR 0.010000   
2022-11-03 22:47:07,052 - INFO  - Training [7][  260/  391]   Loss 0.176313   Top1 93.873197   Top5 99.912861   BatchTime 0.107734   LR 0.010000   
2022-11-03 22:47:09,058 - INFO  - Training [7][  280/  391]   Loss 0.178243   Top1 93.822545   Top5 99.910714   BatchTime 0.107204   LR 0.010000   
2022-11-03 22:47:11,050 - INFO  - Training [7][  300/  391]   Loss 0.179369   Top1 93.781250   Top5 99.903646   BatchTime 0.106696   LR 0.010000   
2022-11-03 22:47:13,018 - INFO  - Training [7][  320/  391]   Loss 0.180956   Top1 93.718262   Top5 99.899902   BatchTime 0.106178   LR 0.010000   
2022-11-03 22:47:14,973 - INFO  - Training [7][  340/  391]   Loss 0.181866   Top1 93.690257   Top5 99.887408   BatchTime 0.105683   LR 0.010000   
2022-11-03 22:47:16,718 - INFO  - Training [7][  360/  391]   Loss 0.180946   Top1 93.730469   Top5 99.893663   BatchTime 0.104657   LR 0.010000   
2022-11-03 22:47:18,320 - INFO  - Training [7][  380/  391]   Loss 0.181266   Top1 93.721217   Top5 99.899260   BatchTime 0.103366   LR 0.010000   
2022-11-03 22:47:19,446 - INFO  - ==> Top1: 93.720    Top5: 99.900    Loss: 0.181

2022-11-03 22:47:19,447 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:47:21,953 - INFO  - Validation [7][   20/   79]   Loss 0.400650   Top1 87.812500   Top5 99.492188   BatchTime 0.125196   
2022-11-03 22:47:22,479 - INFO  - Validation [7][   40/   79]   Loss 0.406497   Top1 87.929688   Top5 99.355469   BatchTime 0.075761   
2022-11-03 22:47:23,278 - INFO  - Validation [7][   60/   79]   Loss 0.401811   Top1 88.098958   Top5 99.361979   BatchTime 0.063807   
2022-11-03 22:47:24,368 - INFO  - ==> Top1: 88.060    Top5: 99.390    Loss: 0.396

2022-11-03 22:47:24,403 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 88.610   Top5: 99.530] Sparsity : 0.764
2022-11-03 22:47:24,404 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.470   Top5: 99.490] Sparsity : 0.751
2022-11-03 22:47:24,404 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.410   Top5: 99.540] Sparsity : 0.745
2022-11-03 22:47:24,516 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:47:24,517 - INFO  - >>>>>>>> Epoch   8
2022-11-03 22:47:24,518 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:47:28,329 - INFO  - Training [8][   20/  391]   Loss 0.164266   Top1 94.609375   Top5 99.882812   BatchTime 0.190508   LR 0.010000   
2022-11-03 22:47:30,350 - INFO  - Training [8][   40/  391]   Loss 0.175012   Top1 94.199219   Top5 99.902344   BatchTime 0.145778   LR 0.010000   
2022-11-03 22:47:32,334 - INFO  - Training [8][   60/  391]   Loss 0.170517   Top1 94.192708   Top5 99.895833   BatchTime 0.130265   LR 0.010000   
2022-11-03 22:47:34,337 - INFO  - Training [8][   80/  391]   Loss 0.173031   Top1 94.111328   Top5 99.902344   BatchTime 0.122732   LR 0.010000   
2022-11-03 22:47:36,346 - INFO  - Training [8][  100/  391]   Loss 0.172088   Top1 94.140625   Top5 99.890625   BatchTime 0.118277   LR 0.010000   
2022-11-03 22:47:38,362 - INFO  - Training [8][  120/  391]   Loss 0.173764   Top1 93.958333   Top5 99.902344   BatchTime 0.115362   LR 0.010000   
2022-11-03 22:47:40,387 - INFO  - Training [8][  140/  391]   Loss 0.178361   Top1 93.833705   Top5 99.899554   BatchTime 0.113345   LR 0.010000   
2022-11-03 22:47:42,388 - INFO  - Training [8][  160/  391]   Loss 0.178122   Top1 93.813477   Top5 99.902344   BatchTime 0.111682   LR 0.010000   
2022-11-03 22:47:44,390 - INFO  - Training [8][  180/  391]   Loss 0.175373   Top1 93.914931   Top5 99.904514   BatchTime 0.110398   LR 0.010000   
2022-11-03 22:47:46,381 - INFO  - Training [8][  200/  391]   Loss 0.177153   Top1 93.843750   Top5 99.906250   BatchTime 0.109310   LR 0.010000   
2022-11-03 22:47:48,359 - INFO  - Training [8][  220/  391]   Loss 0.177188   Top1 93.874290   Top5 99.904119   BatchTime 0.108363   LR 0.010000   
2022-11-03 22:47:50,378 - INFO  - Training [8][  240/  391]   Loss 0.175946   Top1 93.902995   Top5 99.905599   BatchTime 0.107745   LR 0.010000   
2022-11-03 22:47:52,389 - INFO  - Training [8][  260/  391]   Loss 0.175347   Top1 93.957332   Top5 99.903846   BatchTime 0.107191   LR 0.010000   
2022-11-03 22:47:54,381 - INFO  - Training [8][  280/  391]   Loss 0.176032   Top1 93.931362   Top5 99.902344   BatchTime 0.106649   LR 0.010000   
2022-11-03 22:47:56,384 - INFO  - Training [8][  300/  391]   Loss 0.175701   Top1 93.937500   Top5 99.901042   BatchTime 0.106216   LR 0.010000   
2022-11-03 22:47:58,358 - INFO  - Training [8][  320/  391]   Loss 0.176685   Top1 93.879395   Top5 99.897461   BatchTime 0.105746   LR 0.010000   
2022-11-03 22:48:00,321 - INFO  - Training [8][  340/  391]   Loss 0.175220   Top1 93.926930   Top5 99.901195   BatchTime 0.105299   LR 0.010000   
2022-11-03 22:48:02,193 - INFO  - Training [8][  360/  391]   Loss 0.176107   Top1 93.895399   Top5 99.898003   BatchTime 0.104650   LR 0.010000   
2022-11-03 22:48:03,732 - INFO  - Training [8][  380/  391]   Loss 0.176482   Top1 93.881579   Top5 99.901316   BatchTime 0.103192   LR 0.010000   
2022-11-03 22:48:04,850 - INFO  - ==> Top1: 93.894    Top5: 99.902    Loss: 0.176

2022-11-03 22:48:04,851 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:48:07,304 - INFO  - Validation [8][   20/   79]   Loss 0.347790   Top1 89.101562   Top5 99.804688   BatchTime 0.122563   
2022-11-03 22:48:07,829 - INFO  - Validation [8][   40/   79]   Loss 0.362174   Top1 89.199219   Top5 99.609375   BatchTime 0.074394   
2022-11-03 22:48:08,444 - INFO  - Validation [8][   60/   79]   Loss 0.363975   Top1 89.062500   Top5 99.583333   BatchTime 0.059849   
2022-11-03 22:48:09,546 - INFO  - ==> Top1: 88.690    Top5: 99.580    Loss: 0.369

2022-11-03 22:48:09,589 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.690   Top5: 99.580] Sparsity : 0.807
2022-11-03 22:48:09,590 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 88.610   Top5: 99.530] Sparsity : 0.764
2022-11-03 22:48:09,590 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.470   Top5: 99.490] Sparsity : 0.751
2022-11-03 22:48:09,795 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:48:09,795 - INFO  - >>>>>>>> Epoch   9
2022-11-03 22:48:09,796 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:48:13,626 - INFO  - Training [9][   20/  391]   Loss 0.159877   Top1 94.375000   Top5 99.960938   BatchTime 0.191464   LR 0.010000   
2022-11-03 22:48:15,628 - INFO  - Training [9][   40/  391]   Loss 0.160960   Top1 94.355469   Top5 99.941406   BatchTime 0.145783   LR 0.010000   
2022-11-03 22:48:17,648 - INFO  - Training [9][   60/  391]   Loss 0.153648   Top1 94.505208   Top5 99.947917   BatchTime 0.130850   LR 0.010000   
2022-11-03 22:48:19,632 - INFO  - Training [9][   80/  391]   Loss 0.159659   Top1 94.296875   Top5 99.941406   BatchTime 0.122942   LR 0.010000   
2022-11-03 22:48:21,660 - INFO  - Training [9][  100/  391]   Loss 0.161253   Top1 94.265625   Top5 99.945312   BatchTime 0.118631   LR 0.010000   
2022-11-03 22:48:23,768 - INFO  - Training [9][  120/  391]   Loss 0.163851   Top1 94.173177   Top5 99.928385   BatchTime 0.116427   LR 0.010000   
2022-11-03 22:48:25,819 - INFO  - Training [9][  140/  391]   Loss 0.161717   Top1 94.296875   Top5 99.933036   BatchTime 0.114445   LR 0.010000   
2022-11-03 22:48:27,843 - INFO  - Training [9][  160/  391]   Loss 0.160550   Top1 94.311523   Top5 99.926758   BatchTime 0.112790   LR 0.010000   
2022-11-03 22:48:29,863 - INFO  - Training [9][  180/  391]   Loss 0.160039   Top1 94.357639   Top5 99.930556   BatchTime 0.111481   LR 0.010000   
2022-11-03 22:48:31,871 - INFO  - Training [9][  200/  391]   Loss 0.159358   Top1 94.382812   Top5 99.937500   BatchTime 0.110372   LR 0.010000   
2022-11-03 22:48:33,884 - INFO  - Training [9][  220/  391]   Loss 0.158221   Top1 94.438920   Top5 99.943182   BatchTime 0.109489   LR 0.010000   
2022-11-03 22:48:35,910 - INFO  - Training [9][  240/  391]   Loss 0.157274   Top1 94.492188   Top5 99.944661   BatchTime 0.108803   LR 0.010000   
2022-11-03 22:48:37,928 - INFO  - Training [9][  260/  391]   Loss 0.157456   Top1 94.477163   Top5 99.945913   BatchTime 0.108196   LR 0.010000   
2022-11-03 22:48:39,942 - INFO  - Training [9][  280/  391]   Loss 0.157161   Top1 94.475446   Top5 99.941406   BatchTime 0.107659   LR 0.010000   
2022-11-03 22:48:41,948 - INFO  - Training [9][  300/  391]   Loss 0.157430   Top1 94.471354   Top5 99.940104   BatchTime 0.107169   LR 0.010000   
2022-11-03 22:48:43,946 - INFO  - Training [9][  320/  391]   Loss 0.158928   Top1 94.389648   Top5 99.931641   BatchTime 0.106714   LR 0.010000   
2022-11-03 22:48:45,911 - INFO  - Training [9][  340/  391]   Loss 0.159564   Top1 94.375000   Top5 99.933364   BatchTime 0.106217   LR 0.010000   
2022-11-03 22:48:47,800 - INFO  - Training [9][  360/  391]   Loss 0.159373   Top1 94.414062   Top5 99.928385   BatchTime 0.105563   LR 0.010000   
2022-11-03 22:48:49,291 - INFO  - Training [9][  380/  391]   Loss 0.160033   Top1 94.379112   Top5 99.932155   BatchTime 0.103932   LR 0.010000   
2022-11-03 22:48:50,449 - INFO  - ==> Top1: 94.384    Top5: 99.930    Loss: 0.161

2022-11-03 22:48:50,450 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:48:52,906 - INFO  - Validation [9][   20/   79]   Loss 0.384872   Top1 88.710938   Top5 99.492188   BatchTime 0.122738   
2022-11-03 22:48:53,435 - INFO  - Validation [9][   40/   79]   Loss 0.386882   Top1 88.613281   Top5 99.550781   BatchTime 0.074603   
2022-11-03 22:48:54,019 - INFO  - Validation [9][   60/   79]   Loss 0.386903   Top1 88.632812   Top5 99.583333   BatchTime 0.059466   
2022-11-03 22:48:55,106 - INFO  - ==> Top1: 88.600    Top5: 99.580    Loss: 0.381

2022-11-03 22:48:55,153 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.690   Top5: 99.580] Sparsity : 0.807
2022-11-03 22:48:55,153 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 88.610   Top5: 99.530] Sparsity : 0.764
2022-11-03 22:48:55,154 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 88.600   Top5: 99.580] Sparsity : 0.809
2022-11-03 22:48:55,258 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:48:55,258 - INFO  - >>>>>>>> Epoch  10
2022-11-03 22:48:55,260 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:48:59,068 - INFO  - Training [10][   20/  391]   Loss 0.149043   Top1 94.960938   Top5 99.921875   BatchTime 0.190376   LR 0.010000   
2022-11-03 22:49:01,083 - INFO  - Training [10][   40/  391]   Loss 0.144221   Top1 95.097656   Top5 99.941406   BatchTime 0.145581   LR 0.010000   
2022-11-03 22:49:03,094 - INFO  - Training [10][   60/  391]   Loss 0.143945   Top1 94.947917   Top5 99.960938   BatchTime 0.130565   LR 0.010000   
2022-11-03 22:49:05,096 - INFO  - Training [10][   80/  391]   Loss 0.141526   Top1 95.078125   Top5 99.960938   BatchTime 0.122951   LR 0.010000   
2022-11-03 22:49:07,101 - INFO  - Training [10][  100/  391]   Loss 0.142572   Top1 95.015625   Top5 99.968750   BatchTime 0.118410   LR 0.010000   
2022-11-03 22:49:09,097 - INFO  - Training [10][  120/  391]   Loss 0.142282   Top1 95.032552   Top5 99.967448   BatchTime 0.115308   LR 0.010000   
2022-11-03 22:49:11,103 - INFO  - Training [10][  140/  391]   Loss 0.143130   Top1 94.994420   Top5 99.972098   BatchTime 0.113160   LR 0.010000   
2022-11-03 22:49:13,101 - INFO  - Training [10][  160/  391]   Loss 0.144384   Top1 94.936523   Top5 99.970703   BatchTime 0.111504   LR 0.010000   
2022-11-03 22:49:15,141 - INFO  - Training [10][  180/  391]   Loss 0.142526   Top1 95.043403   Top5 99.965278   BatchTime 0.110449   LR 0.010000   
2022-11-03 22:49:17,140 - INFO  - Training [10][  200/  391]   Loss 0.142580   Top1 95.093750   Top5 99.957031   BatchTime 0.109399   LR 0.010000   
2022-11-03 22:49:19,146 - INFO  - Training [10][  220/  391]   Loss 0.143624   Top1 95.056818   Top5 99.957386   BatchTime 0.108569   LR 0.010000   
2022-11-03 22:49:21,156 - INFO  - Training [10][  240/  391]   Loss 0.144428   Top1 94.980469   Top5 99.960938   BatchTime 0.107899   LR 0.010000   
2022-11-03 22:49:23,171 - INFO  - Training [10][  260/  391]   Loss 0.145555   Top1 94.915865   Top5 99.951923   BatchTime 0.107350   LR 0.010000   
2022-11-03 22:49:25,173 - INFO  - Training [10][  280/  391]   Loss 0.146421   Top1 94.891183   Top5 99.952567   BatchTime 0.106830   LR 0.010000   
2022-11-03 22:49:27,176 - INFO  - Training [10][  300/  391]   Loss 0.146933   Top1 94.877604   Top5 99.947917   BatchTime 0.106385   LR 0.010000   
2022-11-03 22:49:29,167 - INFO  - Training [10][  320/  391]   Loss 0.146929   Top1 94.877930   Top5 99.948730   BatchTime 0.105957   LR 0.010000   
2022-11-03 22:49:31,119 - INFO  - Training [10][  340/  391]   Loss 0.147027   Top1 94.866728   Top5 99.951746   BatchTime 0.105467   LR 0.010000   
2022-11-03 22:49:33,041 - INFO  - Training [10][  360/  391]   Loss 0.147836   Top1 94.843750   Top5 99.952257   BatchTime 0.104946   LR 0.010000   
2022-11-03 22:49:34,486 - INFO  - Training [10][  380/  391]   Loss 0.147912   Top1 94.821135   Top5 99.954770   BatchTime 0.103225   LR 0.010000   
2022-11-03 22:49:35,697 - INFO  - ==> Top1: 94.830    Top5: 99.956    Loss: 0.147

2022-11-03 22:49:35,698 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:49:38,179 - INFO  - Validation [10][   20/   79]   Loss 0.358742   Top1 89.453125   Top5 99.609375   BatchTime 0.123993   
2022-11-03 22:49:38,706 - INFO  - Validation [10][   40/   79]   Loss 0.366556   Top1 89.394531   Top5 99.511719   BatchTime 0.075163   
2022-11-03 22:49:39,235 - INFO  - Validation [10][   60/   79]   Loss 0.369487   Top1 89.427083   Top5 99.531250   BatchTime 0.058923   
2022-11-03 22:49:40,330 - INFO  - ==> Top1: 89.240    Top5: 99.580    Loss: 0.367

2022-11-03 22:49:40,364 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:49:40,365 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 88.690   Top5: 99.580] Sparsity : 0.807
2022-11-03 22:49:40,365 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 88.610   Top5: 99.530] Sparsity : 0.764
2022-11-03 22:49:40,568 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:49:40,569 - INFO  - >>>>>>>> Epoch  11
2022-11-03 22:49:40,570 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:49:44,443 - INFO  - Training [11][   20/  391]   Loss 0.126214   Top1 95.429688   Top5 99.960938   BatchTime 0.193608   LR 0.010000   
2022-11-03 22:49:46,493 - INFO  - Training [11][   40/  391]   Loss 0.128262   Top1 95.371094   Top5 99.960938   BatchTime 0.148068   LR 0.010000   
2022-11-03 22:49:48,505 - INFO  - Training [11][   60/  391]   Loss 0.128845   Top1 95.377604   Top5 99.973958   BatchTime 0.132242   LR 0.010000   
2022-11-03 22:49:50,504 - INFO  - Training [11][   80/  391]   Loss 0.129715   Top1 95.390625   Top5 99.960938   BatchTime 0.124168   LR 0.010000   
2022-11-03 22:49:52,511 - INFO  - Training [11][  100/  391]   Loss 0.129314   Top1 95.312500   Top5 99.968750   BatchTime 0.119399   LR 0.010000   
2022-11-03 22:49:54,520 - INFO  - Training [11][  120/  391]   Loss 0.130038   Top1 95.234375   Top5 99.967448   BatchTime 0.116243   LR 0.010000   
2022-11-03 22:49:56,519 - INFO  - Training [11][  140/  391]   Loss 0.131579   Top1 95.212054   Top5 99.972098   BatchTime 0.113914   LR 0.010000   
2022-11-03 22:49:58,647 - INFO  - Training [11][  160/  391]   Loss 0.133932   Top1 95.161133   Top5 99.970703   BatchTime 0.112979   LR 0.010000   
2022-11-03 22:50:00,652 - INFO  - Training [11][  180/  391]   Loss 0.133707   Top1 95.217014   Top5 99.969618   BatchTime 0.111562   LR 0.010000   
2022-11-03 22:50:02,678 - INFO  - Training [11][  200/  391]   Loss 0.135373   Top1 95.167969   Top5 99.968750   BatchTime 0.110537   LR 0.010000   
2022-11-03 22:50:04,682 - INFO  - Training [11][  220/  391]   Loss 0.134360   Top1 95.205966   Top5 99.968040   BatchTime 0.109596   LR 0.010000   
2022-11-03 22:50:06,712 - INFO  - Training [11][  240/  391]   Loss 0.134056   Top1 95.250651   Top5 99.964193   BatchTime 0.108920   LR 0.010000   
2022-11-03 22:50:08,700 - INFO  - Training [11][  260/  391]   Loss 0.133688   Top1 95.288462   Top5 99.963942   BatchTime 0.108188   LR 0.010000   
2022-11-03 22:50:10,721 - INFO  - Training [11][  280/  391]   Loss 0.133861   Top1 95.256696   Top5 99.963728   BatchTime 0.107678   LR 0.010000   
2022-11-03 22:50:12,722 - INFO  - Training [11][  300/  391]   Loss 0.134562   Top1 95.218750   Top5 99.966146   BatchTime 0.107170   LR 0.010000   
2022-11-03 22:50:14,694 - INFO  - Training [11][  320/  391]   Loss 0.134118   Top1 95.227051   Top5 99.963379   BatchTime 0.106634   LR 0.010000   
2022-11-03 22:50:16,645 - INFO  - Training [11][  340/  391]   Loss 0.134955   Top1 95.218290   Top5 99.965533   BatchTime 0.106100   LR 0.010000   
2022-11-03 22:50:18,608 - INFO  - Training [11][  360/  391]   Loss 0.135771   Top1 95.203993   Top5 99.967448   BatchTime 0.105658   LR 0.010000   
2022-11-03 22:50:20,026 - INFO  - Training [11][  380/  391]   Loss 0.137038   Top1 95.152138   Top5 99.965049   BatchTime 0.103827   LR 0.010000   
2022-11-03 22:50:21,240 - INFO  - ==> Top1: 95.138    Top5: 99.964    Loss: 0.137

2022-11-03 22:50:21,241 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:50:23,637 - INFO  - Validation [11][   20/   79]   Loss 0.380352   Top1 89.687500   Top5 99.492188   BatchTime 0.119738   
2022-11-03 22:50:24,163 - INFO  - Validation [11][   40/   79]   Loss 0.369744   Top1 89.648438   Top5 99.570312   BatchTime 0.073012   
2022-11-03 22:50:24,688 - INFO  - Validation [11][   60/   79]   Loss 0.369597   Top1 89.674479   Top5 99.518229   BatchTime 0.057429   
2022-11-03 22:50:25,714 - INFO  - ==> Top1: 89.360    Top5: 99.540    Loss: 0.372

2022-11-03 22:50:25,761 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:50:25,762 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:50:25,762 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 88.690   Top5: 99.580] Sparsity : 0.807
2022-11-03 22:50:25,948 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:50:25,948 - INFO  - >>>>>>>> Epoch  12
2022-11-03 22:50:25,949 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:50:29,805 - INFO  - Training [12][   20/  391]   Loss 0.131530   Top1 95.234375   Top5 99.960938   BatchTime 0.192799   LR 0.010000   
2022-11-03 22:50:31,809 - INFO  - Training [12][   40/  391]   Loss 0.126109   Top1 95.605469   Top5 99.980469   BatchTime 0.146499   LR 0.010000   
2022-11-03 22:50:33,817 - INFO  - Training [12][   60/  391]   Loss 0.122221   Top1 95.729167   Top5 99.960938   BatchTime 0.131126   LR 0.010000   
2022-11-03 22:50:35,831 - INFO  - Training [12][   80/  391]   Loss 0.121228   Top1 95.742188   Top5 99.960938   BatchTime 0.123522   LR 0.010000   
2022-11-03 22:50:37,849 - INFO  - Training [12][  100/  391]   Loss 0.123760   Top1 95.601562   Top5 99.960938   BatchTime 0.118994   LR 0.010000   
2022-11-03 22:50:39,865 - INFO  - Training [12][  120/  391]   Loss 0.124721   Top1 95.644531   Top5 99.954427   BatchTime 0.115961   LR 0.010000   
2022-11-03 22:50:41,881 - INFO  - Training [12][  140/  391]   Loss 0.124804   Top1 95.664062   Top5 99.960938   BatchTime 0.113799   LR 0.010000   
2022-11-03 22:50:43,891 - INFO  - Training [12][  160/  391]   Loss 0.125499   Top1 95.634766   Top5 99.965820   BatchTime 0.112132   LR 0.010000   
2022-11-03 22:50:45,893 - INFO  - Training [12][  180/  391]   Loss 0.125740   Top1 95.638021   Top5 99.960938   BatchTime 0.110799   LR 0.010000   
2022-11-03 22:50:47,912 - INFO  - Training [12][  200/  391]   Loss 0.125381   Top1 95.601562   Top5 99.960938   BatchTime 0.109810   LR 0.010000   
2022-11-03 22:50:49,912 - INFO  - Training [12][  220/  391]   Loss 0.125193   Top1 95.607244   Top5 99.964489   BatchTime 0.108921   LR 0.010000   
2022-11-03 22:50:51,916 - INFO  - Training [12][  240/  391]   Loss 0.124713   Top1 95.572917   Top5 99.967448   BatchTime 0.108193   LR 0.010000   
2022-11-03 22:50:53,910 - INFO  - Training [12][  260/  391]   Loss 0.124347   Top1 95.600962   Top5 99.969952   BatchTime 0.107538   LR 0.010000   
2022-11-03 22:50:55,919 - INFO  - Training [12][  280/  391]   Loss 0.125340   Top1 95.580357   Top5 99.963728   BatchTime 0.107033   LR 0.010000   
2022-11-03 22:50:57,904 - INFO  - Training [12][  300/  391]   Loss 0.125749   Top1 95.546875   Top5 99.963542   BatchTime 0.106513   LR 0.010000   
2022-11-03 22:50:59,878 - INFO  - Training [12][  320/  391]   Loss 0.125543   Top1 95.573730   Top5 99.965820   BatchTime 0.106024   LR 0.010000   
2022-11-03 22:51:01,832 - INFO  - Training [12][  340/  391]   Loss 0.125432   Top1 95.562960   Top5 99.965533   BatchTime 0.105535   LR 0.010000   
2022-11-03 22:51:03,829 - INFO  - Training [12][  360/  391]   Loss 0.124432   Top1 95.598958   Top5 99.967448   BatchTime 0.105220   LR 0.010000   
2022-11-03 22:51:05,249 - INFO  - Training [12][  380/  391]   Loss 0.124678   Top1 95.577714   Top5 99.967105   BatchTime 0.103420   LR 0.010000   
2022-11-03 22:51:06,462 - INFO  - ==> Top1: 95.572    Top5: 99.966    Loss: 0.125

2022-11-03 22:51:06,462 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:51:08,964 - INFO  - Validation [12][   20/   79]   Loss 0.367166   Top1 89.960938   Top5 99.687500   BatchTime 0.124980   
2022-11-03 22:51:09,500 - INFO  - Validation [12][   40/   79]   Loss 0.378632   Top1 89.648438   Top5 99.648438   BatchTime 0.075900   
2022-11-03 22:51:10,020 - INFO  - Validation [12][   60/   79]   Loss 0.382682   Top1 89.375000   Top5 99.622396   BatchTime 0.059268   
2022-11-03 22:51:11,036 - INFO  - ==> Top1: 89.240    Top5: 99.630    Loss: 0.381

2022-11-03 22:51:11,071 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:51:11,072 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:51:11,072 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:51:11,173 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:51:11,174 - INFO  - >>>>>>>> Epoch  13
2022-11-03 22:51:11,175 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:51:15,006 - INFO  - Training [13][   20/  391]   Loss 0.111434   Top1 96.406250   Top5 99.960938   BatchTime 0.191547   LR 0.010000   
2022-11-03 22:51:17,023 - INFO  - Training [13][   40/  391]   Loss 0.108539   Top1 96.445312   Top5 99.960938   BatchTime 0.146199   LR 0.010000   
2022-11-03 22:51:19,069 - INFO  - Training [13][   60/  391]   Loss 0.108472   Top1 96.419271   Top5 99.973958   BatchTime 0.131561   LR 0.010000   
2022-11-03 22:51:21,075 - INFO  - Training [13][   80/  391]   Loss 0.117167   Top1 95.986328   Top5 99.960938   BatchTime 0.123747   LR 0.010000   
2022-11-03 22:51:23,060 - INFO  - Training [13][  100/  391]   Loss 0.118547   Top1 95.843750   Top5 99.960938   BatchTime 0.118848   LR 0.010000   
2022-11-03 22:51:25,068 - INFO  - Training [13][  120/  391]   Loss 0.119482   Top1 95.807292   Top5 99.954427   BatchTime 0.115768   LR 0.010000   
2022-11-03 22:51:27,058 - INFO  - Training [13][  140/  391]   Loss 0.118260   Top1 95.820312   Top5 99.960938   BatchTime 0.113448   LR 0.010000   
2022-11-03 22:51:29,046 - INFO  - Training [13][  160/  391]   Loss 0.119238   Top1 95.859375   Top5 99.960938   BatchTime 0.111689   LR 0.010000   
2022-11-03 22:51:31,059 - INFO  - Training [13][  180/  391]   Loss 0.119018   Top1 95.820312   Top5 99.960938   BatchTime 0.110462   LR 0.010000   
2022-11-03 22:51:33,068 - INFO  - Training [13][  200/  391]   Loss 0.118788   Top1 95.835938   Top5 99.960938   BatchTime 0.109461   LR 0.010000   
2022-11-03 22:51:35,053 - INFO  - Training [13][  220/  391]   Loss 0.119125   Top1 95.820312   Top5 99.960938   BatchTime 0.108534   LR 0.010000   
2022-11-03 22:51:37,180 - INFO  - Training [13][  240/  391]   Loss 0.120200   Top1 95.774740   Top5 99.960938   BatchTime 0.108351   LR 0.010000   
2022-11-03 22:51:39,196 - INFO  - Training [13][  260/  391]   Loss 0.120372   Top1 95.763221   Top5 99.963942   BatchTime 0.107769   LR 0.010000   
2022-11-03 22:51:41,204 - INFO  - Training [13][  280/  391]   Loss 0.120216   Top1 95.770089   Top5 99.966518   BatchTime 0.107244   LR 0.010000   
2022-11-03 22:51:43,195 - INFO  - Training [13][  300/  391]   Loss 0.120801   Top1 95.736979   Top5 99.968750   BatchTime 0.106730   LR 0.010000   
2022-11-03 22:51:45,188 - INFO  - Training [13][  320/  391]   Loss 0.121480   Top1 95.700684   Top5 99.970703   BatchTime 0.106287   LR 0.010000   
2022-11-03 22:51:47,142 - INFO  - Training [13][  340/  391]   Loss 0.121764   Top1 95.712316   Top5 99.970129   BatchTime 0.105782   LR 0.010000   
2022-11-03 22:51:49,084 - INFO  - Training [13][  360/  391]   Loss 0.122691   Top1 95.690104   Top5 99.971788   BatchTime 0.105299   LR 0.010000   
2022-11-03 22:51:50,710 - INFO  - Training [13][  380/  391]   Loss 0.123702   Top1 95.647615   Top5 99.971217   BatchTime 0.104037   LR 0.010000   
2022-11-03 22:51:51,860 - INFO  - ==> Top1: 95.624    Top5: 99.970    Loss: 0.124

2022-11-03 22:51:51,861 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:51:54,333 - INFO  - Validation [13][   20/   79]   Loss 0.396842   Top1 88.710938   Top5 99.570312   BatchTime 0.123500   
2022-11-03 22:51:54,855 - INFO  - Validation [13][   40/   79]   Loss 0.396989   Top1 88.789062   Top5 99.433594   BatchTime 0.074819   
2022-11-03 22:51:55,378 - INFO  - Validation [13][   60/   79]   Loss 0.390936   Top1 89.179688   Top5 99.492188   BatchTime 0.058582   
2022-11-03 22:51:56,293 - INFO  - ==> Top1: 89.110    Top5: 99.550    Loss: 0.392

2022-11-03 22:51:56,333 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:51:56,334 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:51:56,334 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:51:56,476 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:51:56,476 - INFO  - >>>>>>>> Epoch  14
2022-11-03 22:51:56,478 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:52:00,300 - INFO  - Training [14][   20/  391]   Loss 0.110964   Top1 96.289062   Top5 100.000000   BatchTime 0.191116   LR 0.010000   
2022-11-03 22:52:02,313 - INFO  - Training [14][   40/  391]   Loss 0.111046   Top1 96.230469   Top5 99.960938   BatchTime 0.145887   LR 0.010000   
2022-11-03 22:52:04,304 - INFO  - Training [14][   60/  391]   Loss 0.116583   Top1 95.937500   Top5 99.947917   BatchTime 0.130427   LR 0.010000   
2022-11-03 22:52:06,339 - INFO  - Training [14][   80/  391]   Loss 0.121593   Top1 95.800781   Top5 99.941406   BatchTime 0.123257   LR 0.010000   
2022-11-03 22:52:08,332 - INFO  - Training [14][  100/  391]   Loss 0.125558   Top1 95.695312   Top5 99.953125   BatchTime 0.118535   LR 0.010000   
2022-11-03 22:52:10,322 - INFO  - Training [14][  120/  391]   Loss 0.128198   Top1 95.592448   Top5 99.934896   BatchTime 0.115365   LR 0.010000   
2022-11-03 22:52:12,352 - INFO  - Training [14][  140/  391]   Loss 0.130434   Top1 95.479911   Top5 99.938616   BatchTime 0.113383   LR 0.010000   
2022-11-03 22:52:14,352 - INFO  - Training [14][  160/  391]   Loss 0.131257   Top1 95.444336   Top5 99.946289   BatchTime 0.111709   LR 0.010000   
2022-11-03 22:52:16,353 - INFO  - Training [14][  180/  391]   Loss 0.133565   Top1 95.342882   Top5 99.952257   BatchTime 0.110415   LR 0.010000   
2022-11-03 22:52:18,369 - INFO  - Training [14][  200/  391]   Loss 0.134550   Top1 95.289062   Top5 99.957031   BatchTime 0.109454   LR 0.010000   
2022-11-03 22:52:20,381 - INFO  - Training [14][  220/  391]   Loss 0.136597   Top1 95.262784   Top5 99.953835   BatchTime 0.108648   LR 0.010000   
2022-11-03 22:52:22,385 - INFO  - Training [14][  240/  391]   Loss 0.137860   Top1 95.221354   Top5 99.947917   BatchTime 0.107945   LR 0.010000   
2022-11-03 22:52:24,376 - INFO  - Training [14][  260/  391]   Loss 0.139033   Top1 95.186298   Top5 99.942909   BatchTime 0.107299   LR 0.010000   
2022-11-03 22:52:26,390 - INFO  - Training [14][  280/  391]   Loss 0.139762   Top1 95.150670   Top5 99.935826   BatchTime 0.106828   LR 0.010000   
2022-11-03 22:52:28,401 - INFO  - Training [14][  300/  391]   Loss 0.140016   Top1 95.135417   Top5 99.940104   BatchTime 0.106408   LR 0.010000   
2022-11-03 22:52:30,366 - INFO  - Training [14][  320/  391]   Loss 0.141824   Top1 95.085449   Top5 99.943848   BatchTime 0.105897   LR 0.010000   
2022-11-03 22:52:32,326 - INFO  - Training [14][  340/  391]   Loss 0.144714   Top1 94.993107   Top5 99.937960   BatchTime 0.105433   LR 0.010000   
2022-11-03 22:52:34,280 - INFO  - Training [14][  360/  391]   Loss 0.147018   Top1 94.900174   Top5 99.937066   BatchTime 0.105003   LR 0.010000   
2022-11-03 22:52:35,823 - INFO  - Training [14][  380/  391]   Loss 0.147823   Top1 94.849918   Top5 99.936266   BatchTime 0.103539   LR 0.010000   
2022-11-03 22:52:36,950 - INFO  - ==> Top1: 94.810    Top5: 99.938    Loss: 0.149

2022-11-03 22:52:36,951 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:52:39,446 - INFO  - Validation [14][   20/   79]   Loss 0.387841   Top1 88.476562   Top5 99.492188   BatchTime 0.124705   
2022-11-03 22:52:39,968 - INFO  - Validation [14][   40/   79]   Loss 0.402598   Top1 88.164062   Top5 99.375000   BatchTime 0.075390   
2022-11-03 22:52:40,489 - INFO  - Validation [14][   60/   79]   Loss 0.394640   Top1 88.606771   Top5 99.453125   BatchTime 0.058945   
2022-11-03 22:52:41,383 - INFO  - ==> Top1: 88.330    Top5: 99.500    Loss: 0.396

2022-11-03 22:52:41,426 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:52:41,427 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:52:41,427 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:52:41,568 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:52:41,568 - INFO  - >>>>>>>> Epoch  15
2022-11-03 22:52:41,569 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:52:45,419 - INFO  - Training [15][   20/  391]   Loss 0.158062   Top1 93.984375   Top5 99.921875   BatchTime 0.192487   LR 0.010000   
2022-11-03 22:52:47,431 - INFO  - Training [15][   40/  391]   Loss 0.165079   Top1 93.554688   Top5 99.960938   BatchTime 0.146532   LR 0.010000   
2022-11-03 22:52:49,420 - INFO  - Training [15][   60/  391]   Loss 0.161124   Top1 93.932292   Top5 99.960938   BatchTime 0.130837   LR 0.010000   
2022-11-03 22:52:51,413 - INFO  - Training [15][   80/  391]   Loss 0.163861   Top1 93.896484   Top5 99.951172   BatchTime 0.123043   LR 0.010000   
2022-11-03 22:52:53,438 - INFO  - Training [15][  100/  391]   Loss 0.165373   Top1 93.953125   Top5 99.953125   BatchTime 0.118682   LR 0.010000   
2022-11-03 22:52:55,445 - INFO  - Training [15][  120/  391]   Loss 0.163065   Top1 94.082031   Top5 99.947917   BatchTime 0.115628   LR 0.010000   
2022-11-03 22:52:57,455 - INFO  - Training [15][  140/  391]   Loss 0.166616   Top1 93.973214   Top5 99.955357   BatchTime 0.113464   LR 0.010000   
2022-11-03 22:52:59,476 - INFO  - Training [15][  160/  391]   Loss 0.167294   Top1 93.969727   Top5 99.951172   BatchTime 0.111913   LR 0.010000   
2022-11-03 22:53:01,483 - INFO  - Training [15][  180/  391]   Loss 0.169315   Top1 93.849826   Top5 99.943576   BatchTime 0.110630   LR 0.010000   
2022-11-03 22:53:03,488 - INFO  - Training [15][  200/  391]   Loss 0.168980   Top1 93.906250   Top5 99.937500   BatchTime 0.109592   LR 0.010000   
2022-11-03 22:53:05,497 - INFO  - Training [15][  220/  391]   Loss 0.171475   Top1 93.913352   Top5 99.939631   BatchTime 0.108759   LR 0.010000   
2022-11-03 22:53:07,501 - INFO  - Training [15][  240/  391]   Loss 0.171799   Top1 93.916016   Top5 99.931641   BatchTime 0.108045   LR 0.010000   
2022-11-03 22:53:09,494 - INFO  - Training [15][  260/  391]   Loss 0.170260   Top1 93.981370   Top5 99.933894   BatchTime 0.107401   LR 0.010000   
2022-11-03 22:53:11,500 - INFO  - Training [15][  280/  391]   Loss 0.171074   Top1 93.936942   Top5 99.933036   BatchTime 0.106892   LR 0.010000   
2022-11-03 22:53:13,452 - INFO  - Training [15][  300/  391]   Loss 0.170339   Top1 93.979167   Top5 99.932292   BatchTime 0.106273   LR 0.010000   
2022-11-03 22:53:15,561 - INFO  - Training [15][  320/  391]   Loss 0.170640   Top1 93.986816   Top5 99.931641   BatchTime 0.106220   LR 0.010000   
2022-11-03 22:53:17,527 - INFO  - Training [15][  340/  391]   Loss 0.170731   Top1 93.988971   Top5 99.935662   BatchTime 0.105756   LR 0.010000   
2022-11-03 22:53:19,487 - INFO  - Training [15][  360/  391]   Loss 0.171383   Top1 93.958333   Top5 99.937066   BatchTime 0.105324   LR 0.010000   
2022-11-03 22:53:21,134 - INFO  - Training [15][  380/  391]   Loss 0.171725   Top1 93.972039   Top5 99.938322   BatchTime 0.104116   LR 0.010000   
2022-11-03 22:53:22,280 - INFO  - ==> Top1: 93.966    Top5: 99.936    Loss: 0.172

2022-11-03 22:53:22,281 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:53:24,789 - INFO  - Validation [15][   20/   79]   Loss 0.394852   Top1 88.750000   Top5 99.414062   BatchTime 0.125334   
2022-11-03 22:53:25,327 - INFO  - Validation [15][   40/   79]   Loss 0.396972   Top1 88.691406   Top5 99.414062   BatchTime 0.076124   
2022-11-03 22:53:25,856 - INFO  - Validation [15][   60/   79]   Loss 0.388625   Top1 88.645833   Top5 99.479167   BatchTime 0.059569   
2022-11-03 22:53:26,616 - INFO  - ==> Top1: 88.550    Top5: 99.510    Loss: 0.386

2022-11-03 22:53:26,644 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:53:26,645 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:53:26,645 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:53:26,747 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:53:26,749 - INFO  - >>>>>>>> Epoch  16
2022-11-03 22:53:26,750 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:53:30,615 - INFO  - Training [16][   20/  391]   Loss 0.151543   Top1 94.570312   Top5 100.000000   BatchTime 0.193197   LR 0.010000   
2022-11-03 22:53:32,636 - INFO  - Training [16][   40/  391]   Loss 0.146911   Top1 94.707031   Top5 99.960938   BatchTime 0.147129   LR 0.010000   
2022-11-03 22:53:34,631 - INFO  - Training [16][   60/  391]   Loss 0.153606   Top1 94.518229   Top5 99.921875   BatchTime 0.131334   LR 0.010000   
2022-11-03 22:53:36,616 - INFO  - Training [16][   80/  391]   Loss 0.157253   Top1 94.570312   Top5 99.921875   BatchTime 0.123313   LR 0.010000   
2022-11-03 22:53:38,612 - INFO  - Training [16][  100/  391]   Loss 0.158942   Top1 94.445312   Top5 99.898438   BatchTime 0.118608   LR 0.010000   
2022-11-03 22:53:40,622 - INFO  - Training [16][  120/  391]   Loss 0.158902   Top1 94.472656   Top5 99.889323   BatchTime 0.115595   LR 0.010000   
2022-11-03 22:53:42,656 - INFO  - Training [16][  140/  391]   Loss 0.160114   Top1 94.414062   Top5 99.899554   BatchTime 0.113611   LR 0.010000   
2022-11-03 22:53:44,658 - INFO  - Training [16][  160/  391]   Loss 0.158931   Top1 94.423828   Top5 99.912109   BatchTime 0.111917   LR 0.010000   
2022-11-03 22:53:46,672 - INFO  - Training [16][  180/  391]   Loss 0.160355   Top1 94.292535   Top5 99.917535   BatchTime 0.110674   LR 0.010000   
2022-11-03 22:53:48,688 - INFO  - Training [16][  200/  391]   Loss 0.159814   Top1 94.304688   Top5 99.921875   BatchTime 0.109684   LR 0.010000   
2022-11-03 22:53:50,693 - INFO  - Training [16][  220/  391]   Loss 0.159933   Top1 94.303977   Top5 99.921875   BatchTime 0.108829   LR 0.010000   
2022-11-03 22:53:52,693 - INFO  - Training [16][  240/  391]   Loss 0.159797   Top1 94.335938   Top5 99.921875   BatchTime 0.108093   LR 0.010000   
2022-11-03 22:53:54,688 - INFO  - Training [16][  260/  391]   Loss 0.159822   Top1 94.378005   Top5 99.927885   BatchTime 0.107448   LR 0.010000   
2022-11-03 22:53:56,697 - INFO  - Training [16][  280/  391]   Loss 0.161561   Top1 94.313616   Top5 99.924665   BatchTime 0.106951   LR 0.010000   
2022-11-03 22:53:58,693 - INFO  - Training [16][  300/  391]   Loss 0.161951   Top1 94.283854   Top5 99.929688   BatchTime 0.106474   LR 0.010000   
2022-11-03 22:54:00,682 - INFO  - Training [16][  320/  391]   Loss 0.161760   Top1 94.299316   Top5 99.924316   BatchTime 0.106034   LR 0.010000   
2022-11-03 22:54:02,638 - INFO  - Training [16][  340/  391]   Loss 0.162285   Top1 94.287684   Top5 99.926471   BatchTime 0.105549   LR 0.010000   
2022-11-03 22:54:04,601 - INFO  - Training [16][  360/  391]   Loss 0.161805   Top1 94.320747   Top5 99.928385   BatchTime 0.105138   LR 0.010000   
2022-11-03 22:54:06,420 - INFO  - Training [16][  380/  391]   Loss 0.160709   Top1 94.368832   Top5 99.932155   BatchTime 0.104392   LR 0.010000   
2022-11-03 22:54:07,461 - INFO  - ==> Top1: 94.332    Top5: 99.930    Loss: 0.161

2022-11-03 22:54:07,462 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:54:09,989 - INFO  - Validation [16][   20/   79]   Loss 0.399983   Top1 88.671875   Top5 99.335938   BatchTime 0.126252   
2022-11-03 22:54:10,670 - INFO  - Validation [16][   40/   79]   Loss 0.410728   Top1 88.164062   Top5 99.375000   BatchTime 0.080147   
2022-11-03 22:54:11,195 - INFO  - Validation [16][   60/   79]   Loss 0.403071   Top1 88.242188   Top5 99.466146   BatchTime 0.062193   
2022-11-03 22:54:11,935 - INFO  - ==> Top1: 88.470    Top5: 99.550    Loss: 0.394

2022-11-03 22:54:11,958 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:54:11,959 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:54:11,959 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:54:12,062 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:54:12,062 - INFO  - >>>>>>>> Epoch  17
2022-11-03 22:54:12,063 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:54:15,962 - INFO  - Training [17][   20/  391]   Loss 0.122526   Top1 95.312500   Top5 100.000000   BatchTime 0.194919   LR 0.010000   
2022-11-03 22:54:17,962 - INFO  - Training [17][   40/  391]   Loss 0.141464   Top1 94.921875   Top5 99.960938   BatchTime 0.147454   LR 0.010000   
2022-11-03 22:54:19,975 - INFO  - Training [17][   60/  391]   Loss 0.142265   Top1 94.882812   Top5 99.947917   BatchTime 0.131861   LR 0.010000   
2022-11-03 22:54:21,974 - INFO  - Training [17][   80/  391]   Loss 0.146302   Top1 94.697266   Top5 99.960938   BatchTime 0.123884   LR 0.010000   
2022-11-03 22:54:23,971 - INFO  - Training [17][  100/  391]   Loss 0.145281   Top1 94.757812   Top5 99.968750   BatchTime 0.119072   LR 0.010000   
2022-11-03 22:54:25,977 - INFO  - Training [17][  120/  391]   Loss 0.150894   Top1 94.459635   Top5 99.960938   BatchTime 0.115945   LR 0.010000   
2022-11-03 22:54:27,990 - INFO  - Training [17][  140/  391]   Loss 0.151171   Top1 94.464286   Top5 99.949777   BatchTime 0.113758   LR 0.010000   
2022-11-03 22:54:30,006 - INFO  - Training [17][  160/  391]   Loss 0.151781   Top1 94.511719   Top5 99.956055   BatchTime 0.112141   LR 0.010000   
2022-11-03 22:54:32,019 - INFO  - Training [17][  180/  391]   Loss 0.151077   Top1 94.505208   Top5 99.952257   BatchTime 0.110864   LR 0.010000   
2022-11-03 22:54:34,047 - INFO  - Training [17][  200/  391]   Loss 0.150478   Top1 94.570312   Top5 99.953125   BatchTime 0.109913   LR 0.010000   
2022-11-03 22:54:36,062 - INFO  - Training [17][  220/  391]   Loss 0.149913   Top1 94.602273   Top5 99.953835   BatchTime 0.109081   LR 0.010000   
2022-11-03 22:54:38,077 - INFO  - Training [17][  240/  391]   Loss 0.151056   Top1 94.547526   Top5 99.954427   BatchTime 0.108386   LR 0.010000   
2022-11-03 22:54:40,089 - INFO  - Training [17][  260/  391]   Loss 0.151697   Top1 94.549279   Top5 99.954928   BatchTime 0.107788   LR 0.010000   
2022-11-03 22:54:42,111 - INFO  - Training [17][  280/  391]   Loss 0.152130   Top1 94.547991   Top5 99.944196   BatchTime 0.107312   LR 0.010000   
2022-11-03 22:54:44,118 - INFO  - Training [17][  300/  391]   Loss 0.152796   Top1 94.515625   Top5 99.942708   BatchTime 0.106846   LR 0.010000   
2022-11-03 22:54:46,127 - INFO  - Training [17][  320/  391]   Loss 0.153498   Top1 94.494629   Top5 99.941406   BatchTime 0.106446   LR 0.010000   
2022-11-03 22:54:48,107 - INFO  - Training [17][  340/  391]   Loss 0.153934   Top1 94.473805   Top5 99.940257   BatchTime 0.106007   LR 0.010000   
2022-11-03 22:54:50,124 - INFO  - Training [17][  360/  391]   Loss 0.153989   Top1 94.474826   Top5 99.937066   BatchTime 0.105721   LR 0.010000   
2022-11-03 22:54:52,096 - INFO  - Training [17][  380/  391]   Loss 0.154430   Top1 94.467516   Top5 99.938322   BatchTime 0.105346   LR 0.010000   
2022-11-03 22:54:53,122 - INFO  - ==> Top1: 94.474    Top5: 99.940    Loss: 0.155

2022-11-03 22:54:53,122 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:54:55,644 - INFO  - Validation [17][   20/   79]   Loss 0.396419   Top1 88.437500   Top5 99.453125   BatchTime 0.126010   
2022-11-03 22:54:56,338 - INFO  - Validation [17][   40/   79]   Loss 0.403003   Top1 88.105469   Top5 99.414062   BatchTime 0.080360   
2022-11-03 22:54:56,982 - INFO  - Validation [17][   60/   79]   Loss 0.391342   Top1 88.463542   Top5 99.479167   BatchTime 0.064297   
2022-11-03 22:54:57,722 - INFO  - ==> Top1: 88.590    Top5: 99.490    Loss: 0.386

2022-11-03 22:54:57,747 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:54:57,747 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:54:57,748 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:54:57,824 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:54:57,824 - INFO  - >>>>>>>> Epoch  18
2022-11-03 22:54:57,825 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:55:01,726 - INFO  - Training [18][   20/  391]   Loss 0.133129   Top1 95.390625   Top5 100.000000   BatchTime 0.195073   LR 0.010000   
2022-11-03 22:55:03,764 - INFO  - Training [18][   40/  391]   Loss 0.143657   Top1 94.941406   Top5 100.000000   BatchTime 0.148485   LR 0.010000   
2022-11-03 22:55:05,813 - INFO  - Training [18][   60/  391]   Loss 0.137836   Top1 95.234375   Top5 100.000000   BatchTime 0.133140   LR 0.010000   
2022-11-03 22:55:07,833 - INFO  - Training [18][   80/  391]   Loss 0.138870   Top1 95.107422   Top5 99.990234   BatchTime 0.125103   LR 0.010000   
2022-11-03 22:55:09,845 - INFO  - Training [18][  100/  391]   Loss 0.137056   Top1 95.093750   Top5 99.976562   BatchTime 0.120198   LR 0.010000   
2022-11-03 22:55:11,851 - INFO  - Training [18][  120/  391]   Loss 0.138419   Top1 95.091146   Top5 99.980469   BatchTime 0.116881   LR 0.010000   
2022-11-03 22:55:13,862 - INFO  - Training [18][  140/  391]   Loss 0.137717   Top1 95.178571   Top5 99.983259   BatchTime 0.114549   LR 0.010000   
2022-11-03 22:55:15,874 - INFO  - Training [18][  160/  391]   Loss 0.136830   Top1 95.229492   Top5 99.975586   BatchTime 0.112807   LR 0.010000   
2022-11-03 22:55:17,881 - INFO  - Training [18][  180/  391]   Loss 0.138495   Top1 95.182292   Top5 99.973958   BatchTime 0.111419   LR 0.010000   
2022-11-03 22:55:19,892 - INFO  - Training [18][  200/  391]   Loss 0.139146   Top1 95.171875   Top5 99.972656   BatchTime 0.110333   LR 0.010000   
2022-11-03 22:55:21,904 - INFO  - Training [18][  220/  391]   Loss 0.140437   Top1 95.120739   Top5 99.975142   BatchTime 0.109450   LR 0.010000   
2022-11-03 22:55:23,918 - INFO  - Training [18][  240/  391]   Loss 0.142539   Top1 95.052083   Top5 99.970703   BatchTime 0.108721   LR 0.010000   
2022-11-03 22:55:25,909 - INFO  - Training [18][  260/  391]   Loss 0.143519   Top1 95.033053   Top5 99.972957   BatchTime 0.108014   LR 0.010000   
2022-11-03 22:55:27,907 - INFO  - Training [18][  280/  391]   Loss 0.143406   Top1 95.044643   Top5 99.974888   BatchTime 0.107435   LR 0.010000   
2022-11-03 22:55:29,912 - INFO  - Training [18][  300/  391]   Loss 0.142605   Top1 95.072917   Top5 99.976562   BatchTime 0.106954   LR 0.010000   
2022-11-03 22:55:31,907 - INFO  - Training [18][  320/  391]   Loss 0.142525   Top1 95.056152   Top5 99.973145   BatchTime 0.106504   LR 0.010000   
2022-11-03 22:55:33,864 - INFO  - Training [18][  340/  391]   Loss 0.143848   Top1 95.000000   Top5 99.972426   BatchTime 0.105997   LR 0.010000   
2022-11-03 22:55:35,814 - INFO  - Training [18][  360/  391]   Loss 0.144656   Top1 94.939236   Top5 99.969618   BatchTime 0.105523   LR 0.010000   
2022-11-03 22:55:37,762 - INFO  - Training [18][  380/  391]   Loss 0.144733   Top1 94.913651   Top5 99.969161   BatchTime 0.105096   LR 0.010000   
2022-11-03 22:55:38,924 - INFO  - ==> Top1: 94.886    Top5: 99.968    Loss: 0.145

2022-11-03 22:55:38,925 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:55:41,492 - INFO  - Validation [18][   20/   79]   Loss 0.395291   Top1 88.867188   Top5 99.375000   BatchTime 0.128259   
2022-11-03 22:55:42,190 - INFO  - Validation [18][   40/   79]   Loss 0.393361   Top1 88.828125   Top5 99.453125   BatchTime 0.081568   
2022-11-03 22:55:42,890 - INFO  - Validation [18][   60/   79]   Loss 0.378223   Top1 89.179688   Top5 99.518229   BatchTime 0.066047   
2022-11-03 22:55:43,755 - INFO  - ==> Top1: 88.980    Top5: 99.560    Loss: 0.378

2022-11-03 22:55:43,778 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:55:43,779 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:55:43,779 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:55:43,879 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:55:43,879 - INFO  - >>>>>>>> Epoch  19
2022-11-03 22:55:43,880 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:55:47,765 - INFO  - Training [19][   20/  391]   Loss 0.150730   Top1 94.687500   Top5 99.921875   BatchTime 0.194216   LR 0.010000   
2022-11-03 22:55:49,783 - INFO  - Training [19][   40/  391]   Loss 0.134561   Top1 95.390625   Top5 99.921875   BatchTime 0.147573   LR 0.010000   
2022-11-03 22:55:51,827 - INFO  - Training [19][   60/  391]   Loss 0.136962   Top1 95.325521   Top5 99.947917   BatchTime 0.132433   LR 0.010000   
2022-11-03 22:55:53,848 - INFO  - Training [19][   80/  391]   Loss 0.134956   Top1 95.292969   Top5 99.960938   BatchTime 0.124589   LR 0.010000   
2022-11-03 22:55:55,853 - INFO  - Training [19][  100/  391]   Loss 0.136143   Top1 95.195312   Top5 99.968750   BatchTime 0.119725   LR 0.010000   
2022-11-03 22:55:57,872 - INFO  - Training [19][  120/  391]   Loss 0.135903   Top1 95.253906   Top5 99.967448   BatchTime 0.116592   LR 0.010000   
2022-11-03 22:55:59,900 - INFO  - Training [19][  140/  391]   Loss 0.137451   Top1 95.167411   Top5 99.966518   BatchTime 0.114422   LR 0.010000   
2022-11-03 22:56:01,919 - INFO  - Training [19][  160/  391]   Loss 0.138965   Top1 95.102539   Top5 99.965820   BatchTime 0.112736   LR 0.010000   
2022-11-03 22:56:03,932 - INFO  - Training [19][  180/  391]   Loss 0.138713   Top1 95.091146   Top5 99.960938   BatchTime 0.111396   LR 0.010000   
2022-11-03 22:56:05,956 - INFO  - Training [19][  200/  391]   Loss 0.140261   Top1 95.062500   Top5 99.960938   BatchTime 0.110375   LR 0.010000   
2022-11-03 22:56:07,951 - INFO  - Training [19][  220/  391]   Loss 0.141753   Top1 95.035511   Top5 99.960938   BatchTime 0.109411   LR 0.010000   
2022-11-03 22:56:09,969 - INFO  - Training [19][  240/  391]   Loss 0.144577   Top1 94.934896   Top5 99.954427   BatchTime 0.108701   LR 0.010000   
2022-11-03 22:56:11,967 - INFO  - Training [19][  260/  391]   Loss 0.146485   Top1 94.858774   Top5 99.954928   BatchTime 0.108021   LR 0.010000   
2022-11-03 22:56:13,980 - INFO  - Training [19][  280/  391]   Loss 0.146357   Top1 94.829799   Top5 99.958147   BatchTime 0.107495   LR 0.010000   
2022-11-03 22:56:15,998 - INFO  - Training [19][  300/  391]   Loss 0.147533   Top1 94.783854   Top5 99.958333   BatchTime 0.107058   LR 0.010000   
2022-11-03 22:56:18,023 - INFO  - Training [19][  320/  391]   Loss 0.148379   Top1 94.738770   Top5 99.958496   BatchTime 0.106694   LR 0.010000   
2022-11-03 22:56:20,016 - INFO  - Training [19][  340/  391]   Loss 0.150443   Top1 94.687500   Top5 99.954044   BatchTime 0.106279   LR 0.010000   
2022-11-03 22:56:21,972 - INFO  - Training [19][  360/  391]   Loss 0.151239   Top1 94.633247   Top5 99.947917   BatchTime 0.105808   LR 0.010000   
2022-11-03 22:56:23,928 - INFO  - Training [19][  380/  391]   Loss 0.151640   Top1 94.619655   Top5 99.948602   BatchTime 0.105387   LR 0.010000   
2022-11-03 22:56:25,225 - INFO  - ==> Top1: 94.580    Top5: 99.944    Loss: 0.153

2022-11-03 22:56:25,226 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:56:27,819 - INFO  - Validation [19][   20/   79]   Loss 0.417603   Top1 87.851562   Top5 99.375000   BatchTime 0.129529   
2022-11-03 22:56:28,502 - INFO  - Validation [19][   40/   79]   Loss 0.416720   Top1 87.949219   Top5 99.355469   BatchTime 0.081857   
2022-11-03 22:56:29,195 - INFO  - Validation [19][   60/   79]   Loss 0.407086   Top1 88.385417   Top5 99.375000   BatchTime 0.066112   
2022-11-03 22:56:30,106 - INFO  - ==> Top1: 88.370    Top5: 99.490    Loss: 0.400

2022-11-03 22:56:30,131 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:56:30,132 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:56:30,132 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.240   Top5: 99.580] Sparsity : 0.811
2022-11-03 22:56:30,216 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:56:30,216 - INFO  - >>>>>>>> Epoch  20
2022-11-03 22:56:30,218 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:56:34,276 - INFO  - Training [20][   20/  391]   Loss 0.164867   Top1 94.335938   Top5 99.921875   BatchTime 0.202920   LR 0.001000   
2022-11-03 22:56:36,277 - INFO  - Training [20][   40/  391]   Loss 0.153200   Top1 94.824219   Top5 99.921875   BatchTime 0.151468   LR 0.001000   
2022-11-03 22:56:38,289 - INFO  - Training [20][   60/  391]   Loss 0.145090   Top1 95.039062   Top5 99.921875   BatchTime 0.134510   LR 0.001000   
2022-11-03 22:56:40,289 - INFO  - Training [20][   80/  391]   Loss 0.147949   Top1 94.892578   Top5 99.912109   BatchTime 0.125885   LR 0.001000   
2022-11-03 22:56:42,306 - INFO  - Training [20][  100/  391]   Loss 0.150567   Top1 94.773438   Top5 99.914062   BatchTime 0.120880   LR 0.001000   
2022-11-03 22:56:44,313 - INFO  - Training [20][  120/  391]   Loss 0.147205   Top1 94.908854   Top5 99.908854   BatchTime 0.117454   LR 0.001000   
2022-11-03 22:56:46,343 - INFO  - Training [20][  140/  391]   Loss 0.145368   Top1 95.000000   Top5 99.921875   BatchTime 0.115181   LR 0.001000   
2022-11-03 22:56:48,360 - INFO  - Training [20][  160/  391]   Loss 0.145871   Top1 94.956055   Top5 99.921875   BatchTime 0.113385   LR 0.001000   
2022-11-03 22:56:50,374 - INFO  - Training [20][  180/  391]   Loss 0.144642   Top1 95.013021   Top5 99.926215   BatchTime 0.111974   LR 0.001000   
2022-11-03 22:56:52,382 - INFO  - Training [20][  200/  391]   Loss 0.144122   Top1 95.019531   Top5 99.929688   BatchTime 0.110817   LR 0.001000   
2022-11-03 22:56:54,381 - INFO  - Training [20][  220/  391]   Loss 0.144901   Top1 95.000000   Top5 99.932528   BatchTime 0.109832   LR 0.001000   
2022-11-03 22:56:56,409 - INFO  - Training [20][  240/  391]   Loss 0.143798   Top1 95.091146   Top5 99.934896   BatchTime 0.109129   LR 0.001000   
2022-11-03 22:56:58,430 - INFO  - Training [20][  260/  391]   Loss 0.143510   Top1 95.090144   Top5 99.933894   BatchTime 0.108506   LR 0.001000   
2022-11-03 22:57:00,441 - INFO  - Training [20][  280/  391]   Loss 0.142749   Top1 95.094866   Top5 99.938616   BatchTime 0.107939   LR 0.001000   
2022-11-03 22:57:02,459 - INFO  - Training [20][  300/  391]   Loss 0.142313   Top1 95.083333   Top5 99.942708   BatchTime 0.107469   LR 0.001000   
2022-11-03 22:57:04,462 - INFO  - Training [20][  320/  391]   Loss 0.142513   Top1 95.087891   Top5 99.941406   BatchTime 0.107010   LR 0.001000   
2022-11-03 22:57:06,425 - INFO  - Training [20][  340/  391]   Loss 0.142448   Top1 95.080423   Top5 99.944853   BatchTime 0.106489   LR 0.001000   
2022-11-03 22:57:08,379 - INFO  - Training [20][  360/  391]   Loss 0.141829   Top1 95.101997   Top5 99.943576   BatchTime 0.106002   LR 0.001000   
2022-11-03 22:57:10,324 - INFO  - Training [20][  380/  391]   Loss 0.140537   Top1 95.143914   Top5 99.946546   BatchTime 0.105540   LR 0.001000   
2022-11-03 22:57:11,745 - INFO  - ==> Top1: 95.138    Top5: 99.948    Loss: 0.141

2022-11-03 22:57:11,745 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:57:14,334 - INFO  - Validation [20][   20/   79]   Loss 0.377790   Top1 88.554688   Top5 99.531250   BatchTime 0.129391   
2022-11-03 22:57:15,027 - INFO  - Validation [20][   40/   79]   Loss 0.374131   Top1 88.984375   Top5 99.531250   BatchTime 0.082028   
2022-11-03 22:57:15,719 - INFO  - Validation [20][   60/   79]   Loss 0.366042   Top1 89.361979   Top5 99.557292   BatchTime 0.066212   
2022-11-03 22:57:16,750 - INFO  - ==> Top1: 89.410    Top5: 99.600    Loss: 0.358

2022-11-03 22:57:16,785 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 89.410   Top5: 99.600] Sparsity : 0.848
2022-11-03 22:57:16,786 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:57:16,786 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.240   Top5: 99.630] Sparsity : 0.815
2022-11-03 22:57:16,972 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:57:16,973 - INFO  - >>>>>>>> Epoch  21
2022-11-03 22:57:16,974 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:57:20,997 - INFO  - Training [21][   20/  391]   Loss 0.124501   Top1 95.585938   Top5 99.960938   BatchTime 0.201143   LR 0.001000   
2022-11-03 22:57:22,999 - INFO  - Training [21][   40/  391]   Loss 0.125631   Top1 95.527344   Top5 99.960938   BatchTime 0.150619   LR 0.001000   
2022-11-03 22:57:25,024 - INFO  - Training [21][   60/  391]   Loss 0.128587   Top1 95.611979   Top5 99.960938   BatchTime 0.134161   LR 0.001000   
2022-11-03 22:57:27,042 - INFO  - Training [21][   80/  391]   Loss 0.131776   Top1 95.458984   Top5 99.960938   BatchTime 0.125846   LR 0.001000   
2022-11-03 22:57:29,055 - INFO  - Training [21][  100/  391]   Loss 0.128382   Top1 95.593750   Top5 99.953125   BatchTime 0.120810   LR 0.001000   
2022-11-03 22:57:31,075 - INFO  - Training [21][  120/  391]   Loss 0.130153   Top1 95.520833   Top5 99.947917   BatchTime 0.117506   LR 0.001000   
2022-11-03 22:57:33,081 - INFO  - Training [21][  140/  391]   Loss 0.127709   Top1 95.608259   Top5 99.949777   BatchTime 0.115046   LR 0.001000   
2022-11-03 22:57:35,084 - INFO  - Training [21][  160/  391]   Loss 0.128018   Top1 95.585938   Top5 99.956055   BatchTime 0.113186   LR 0.001000   
2022-11-03 22:57:37,088 - INFO  - Training [21][  180/  391]   Loss 0.126448   Top1 95.611979   Top5 99.960938   BatchTime 0.111742   LR 0.001000   
2022-11-03 22:57:39,093 - INFO  - Training [21][  200/  391]   Loss 0.125425   Top1 95.625000   Top5 99.960938   BatchTime 0.110592   LR 0.001000   
2022-11-03 22:57:41,089 - INFO  - Training [21][  220/  391]   Loss 0.125372   Top1 95.621449   Top5 99.960938   BatchTime 0.109612   LR 0.001000   
2022-11-03 22:57:43,089 - INFO  - Training [21][  240/  391]   Loss 0.124104   Top1 95.686849   Top5 99.964193   BatchTime 0.108808   LR 0.001000   
2022-11-03 22:57:45,100 - INFO  - Training [21][  260/  391]   Loss 0.124392   Top1 95.667067   Top5 99.966947   BatchTime 0.108174   LR 0.001000   
2022-11-03 22:57:47,090 - INFO  - Training [21][  280/  391]   Loss 0.125695   Top1 95.625000   Top5 99.960938   BatchTime 0.107555   LR 0.001000   
2022-11-03 22:57:49,114 - INFO  - Training [21][  300/  391]   Loss 0.125651   Top1 95.596354   Top5 99.955729   BatchTime 0.107130   LR 0.001000   
2022-11-03 22:57:51,140 - INFO  - Training [21][  320/  391]   Loss 0.126149   Top1 95.588379   Top5 99.956055   BatchTime 0.106766   LR 0.001000   
2022-11-03 22:57:53,126 - INFO  - Training [21][  340/  391]   Loss 0.126463   Top1 95.579044   Top5 99.956342   BatchTime 0.106325   LR 0.001000   
2022-11-03 22:57:55,084 - INFO  - Training [21][  360/  391]   Loss 0.126890   Top1 95.536024   Top5 99.956597   BatchTime 0.105858   LR 0.001000   
2022-11-03 22:57:57,039 - INFO  - Training [21][  380/  391]   Loss 0.127933   Top1 95.493421   Top5 99.952714   BatchTime 0.105433   LR 0.001000   
2022-11-03 22:57:58,464 - INFO  - ==> Top1: 95.494    Top5: 99.950    Loss: 0.128

2022-11-03 22:57:58,465 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:58:01,107 - INFO  - Validation [21][   20/   79]   Loss 0.372772   Top1 89.140625   Top5 99.453125   BatchTime 0.132005   
2022-11-03 22:58:01,802 - INFO  - Validation [21][   40/   79]   Loss 0.376170   Top1 89.140625   Top5 99.492188   BatchTime 0.083381   
2022-11-03 22:58:02,502 - INFO  - Validation [21][   60/   79]   Loss 0.365878   Top1 89.609375   Top5 99.544271   BatchTime 0.067260   
2022-11-03 22:58:03,623 - INFO  - ==> Top1: 89.540    Top5: 99.590    Loss: 0.359

2022-11-03 22:58:03,648 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 89.540   Top5: 99.590] Sparsity : 0.849
2022-11-03 22:58:03,648 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 89.410   Top5: 99.600] Sparsity : 0.848
2022-11-03 22:58:03,648 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.360   Top5: 99.540] Sparsity : 0.813
2022-11-03 22:58:03,865 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:58:03,865 - INFO  - >>>>>>>> Epoch  22
2022-11-03 22:58:03,866 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:58:07,889 - INFO  - Training [22][   20/  391]   Loss 0.113050   Top1 96.132812   Top5 100.000000   BatchTime 0.201122   LR 0.001000   
2022-11-03 22:58:09,889 - INFO  - Training [22][   40/  391]   Loss 0.118515   Top1 95.917969   Top5 100.000000   BatchTime 0.150558   LR 0.001000   
2022-11-03 22:58:11,884 - INFO  - Training [22][   60/  391]   Loss 0.121543   Top1 95.768229   Top5 99.973958   BatchTime 0.133623   LR 0.001000   
2022-11-03 22:58:13,865 - INFO  - Training [22][   80/  391]   Loss 0.125838   Top1 95.527344   Top5 99.960938   BatchTime 0.124979   LR 0.001000   
2022-11-03 22:58:15,983 - INFO  - Training [22][  100/  391]   Loss 0.125639   Top1 95.585938   Top5 99.945312   BatchTime 0.121164   LR 0.001000   
2022-11-03 22:58:18,006 - INFO  - Training [22][  120/  391]   Loss 0.125736   Top1 95.579427   Top5 99.954427   BatchTime 0.117825   LR 0.001000   
2022-11-03 22:58:20,029 - INFO  - Training [22][  140/  391]   Loss 0.126744   Top1 95.563616   Top5 99.955357   BatchTime 0.115447   LR 0.001000   
2022-11-03 22:58:22,046 - INFO  - Training [22][  160/  391]   Loss 0.126488   Top1 95.639648   Top5 99.951172   BatchTime 0.113623   LR 0.001000   
2022-11-03 22:58:24,065 - INFO  - Training [22][  180/  391]   Loss 0.126982   Top1 95.638021   Top5 99.956597   BatchTime 0.112213   LR 0.001000   
2022-11-03 22:58:26,089 - INFO  - Training [22][  200/  391]   Loss 0.127504   Top1 95.609375   Top5 99.953125   BatchTime 0.111112   LR 0.001000   
2022-11-03 22:58:28,096 - INFO  - Training [22][  220/  391]   Loss 0.126736   Top1 95.607244   Top5 99.957386   BatchTime 0.110135   LR 0.001000   
2022-11-03 22:58:30,109 - INFO  - Training [22][  240/  391]   Loss 0.125573   Top1 95.651042   Top5 99.960938   BatchTime 0.109344   LR 0.001000   
2022-11-03 22:58:32,122 - INFO  - Training [22][  260/  391]   Loss 0.125517   Top1 95.661058   Top5 99.963942   BatchTime 0.108673   LR 0.001000   
2022-11-03 22:58:34,133 - INFO  - Training [22][  280/  391]   Loss 0.125355   Top1 95.672433   Top5 99.960938   BatchTime 0.108094   LR 0.001000   
2022-11-03 22:58:36,145 - INFO  - Training [22][  300/  391]   Loss 0.125859   Top1 95.630208   Top5 99.960938   BatchTime 0.107594   LR 0.001000   
2022-11-03 22:58:38,135 - INFO  - Training [22][  320/  391]   Loss 0.124832   Top1 95.668945   Top5 99.960938   BatchTime 0.107087   LR 0.001000   
2022-11-03 22:58:40,120 - INFO  - Training [22][  340/  391]   Loss 0.125655   Top1 95.641085   Top5 99.960938   BatchTime 0.106627   LR 0.001000   
2022-11-03 22:58:42,086 - INFO  - Training [22][  360/  391]   Loss 0.125131   Top1 95.648872   Top5 99.960938   BatchTime 0.106163   LR 0.001000   
2022-11-03 22:58:44,040 - INFO  - Training [22][  380/  391]   Loss 0.126406   Top1 95.594161   Top5 99.962993   BatchTime 0.105718   LR 0.001000   
2022-11-03 22:58:45,447 - INFO  - ==> Top1: 95.594    Top5: 99.964    Loss: 0.126

2022-11-03 22:58:45,448 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:58:48,099 - INFO  - Validation [22][   20/   79]   Loss 0.375069   Top1 89.492188   Top5 99.531250   BatchTime 0.132486   
2022-11-03 22:58:48,803 - INFO  - Validation [22][   40/   79]   Loss 0.373156   Top1 89.550781   Top5 99.531250   BatchTime 0.083845   
2022-11-03 22:58:49,501 - INFO  - Validation [22][   60/   79]   Loss 0.366059   Top1 89.817708   Top5 99.583333   BatchTime 0.067530   
2022-11-03 22:58:50,595 - INFO  - ==> Top1: 89.820    Top5: 99.610    Loss: 0.360

2022-11-03 22:58:50,625 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 22:58:50,625 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 89.540   Top5: 99.590] Sparsity : 0.849
2022-11-03 22:58:50,626 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 89.410   Top5: 99.600] Sparsity : 0.848
2022-11-03 22:58:50,863 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_best.pth.tar

2022-11-03 22:58:50,864 - INFO  - >>>>>>>> Epoch  23
2022-11-03 22:58:50,865 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:58:54,875 - INFO  - Training [23][   20/  391]   Loss 0.127223   Top1 95.195312   Top5 100.000000   BatchTime 0.200478   LR 0.001000   
2022-11-03 22:58:56,907 - INFO  - Training [23][   40/  391]   Loss 0.123186   Top1 95.429688   Top5 99.960938   BatchTime 0.151051   LR 0.001000   
2022-11-03 22:58:58,940 - INFO  - Training [23][   60/  391]   Loss 0.122560   Top1 95.572917   Top5 99.973958   BatchTime 0.134582   LR 0.001000   
2022-11-03 22:59:00,969 - INFO  - Training [23][   80/  391]   Loss 0.124500   Top1 95.527344   Top5 99.970703   BatchTime 0.126290   LR 0.001000   
2022-11-03 22:59:02,992 - INFO  - Training [23][  100/  391]   Loss 0.121954   Top1 95.632812   Top5 99.976562   BatchTime 0.121269   LR 0.001000   
2022-11-03 22:59:05,007 - INFO  - Training [23][  120/  391]   Loss 0.120052   Top1 95.709635   Top5 99.973958   BatchTime 0.117845   LR 0.001000   
2022-11-03 22:59:07,024 - INFO  - Training [23][  140/  391]   Loss 0.120762   Top1 95.725446   Top5 99.955357   BatchTime 0.115417   LR 0.001000   
2022-11-03 22:59:09,028 - INFO  - Training [23][  160/  391]   Loss 0.123507   Top1 95.595703   Top5 99.951172   BatchTime 0.113514   LR 0.001000   
2022-11-03 22:59:11,030 - INFO  - Training [23][  180/  391]   Loss 0.121466   Top1 95.694444   Top5 99.956597   BatchTime 0.112024   LR 0.001000   
2022-11-03 22:59:13,035 - INFO  - Training [23][  200/  391]   Loss 0.121998   Top1 95.695312   Top5 99.957031   BatchTime 0.110849   LR 0.001000   
2022-11-03 22:59:15,037 - INFO  - Training [23][  220/  391]   Loss 0.122621   Top1 95.692472   Top5 99.960938   BatchTime 0.109870   LR 0.001000   
2022-11-03 22:59:17,045 - INFO  - Training [23][  240/  391]   Loss 0.123822   Top1 95.667318   Top5 99.960938   BatchTime 0.109080   LR 0.001000   
2022-11-03 22:59:19,058 - INFO  - Training [23][  260/  391]   Loss 0.124174   Top1 95.673077   Top5 99.963942   BatchTime 0.108433   LR 0.001000   
2022-11-03 22:59:21,078 - INFO  - Training [23][  280/  391]   Loss 0.124138   Top1 95.661272   Top5 99.966518   BatchTime 0.107900   LR 0.001000   
2022-11-03 22:59:23,075 - INFO  - Training [23][  300/  391]   Loss 0.124569   Top1 95.658854   Top5 99.968750   BatchTime 0.107363   LR 0.001000   
2022-11-03 22:59:25,098 - INFO  - Training [23][  320/  391]   Loss 0.123878   Top1 95.700684   Top5 99.970703   BatchTime 0.106975   LR 0.001000   
2022-11-03 22:59:27,078 - INFO  - Training [23][  340/  391]   Loss 0.122856   Top1 95.755974   Top5 99.972426   BatchTime 0.106507   LR 0.001000   
2022-11-03 22:59:29,032 - INFO  - Training [23][  360/  391]   Loss 0.123098   Top1 95.755208   Top5 99.973958   BatchTime 0.106016   LR 0.001000   
2022-11-03 22:59:30,984 - INFO  - Training [23][  380/  391]   Loss 0.123245   Top1 95.721628   Top5 99.975329   BatchTime 0.105573   LR 0.001000   
2022-11-03 22:59:32,437 - INFO  - ==> Top1: 95.732    Top5: 99.974    Loss: 0.123

2022-11-03 22:59:32,439 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:59:35,074 - INFO  - Validation [23][   20/   79]   Loss 0.374280   Top1 89.296875   Top5 99.492188   BatchTime 0.131650   
2022-11-03 22:59:35,772 - INFO  - Validation [23][   40/   79]   Loss 0.375572   Top1 89.218750   Top5 99.433594   BatchTime 0.083283   
2022-11-03 22:59:36,461 - INFO  - Validation [23][   60/   79]   Loss 0.364615   Top1 89.661458   Top5 99.518229   BatchTime 0.066990   
2022-11-03 22:59:37,590 - INFO  - ==> Top1: 89.610    Top5: 99.570    Loss: 0.362

2022-11-03 22:59:37,616 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 22:59:37,617 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 89.610   Top5: 99.570] Sparsity : 0.850
2022-11-03 22:59:37,617 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 89.540   Top5: 99.590] Sparsity : 0.849
2022-11-03 22:59:37,728 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 22:59:37,728 - INFO  - >>>>>>>> Epoch  24
2022-11-03 22:59:37,730 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:59:41,692 - INFO  - Training [24][   20/  391]   Loss 0.132640   Top1 95.195312   Top5 100.000000   BatchTime 0.198092   LR 0.001000   
2022-11-03 22:59:43,703 - INFO  - Training [24][   40/  391]   Loss 0.129796   Top1 95.371094   Top5 99.960938   BatchTime 0.149332   LR 0.001000   
2022-11-03 22:59:45,717 - INFO  - Training [24][   60/  391]   Loss 0.127272   Top1 95.546875   Top5 99.960938   BatchTime 0.133116   LR 0.001000   
2022-11-03 22:59:47,718 - INFO  - Training [24][   80/  391]   Loss 0.122545   Top1 95.683594   Top5 99.960938   BatchTime 0.124845   LR 0.001000   
2022-11-03 22:59:49,724 - INFO  - Training [24][  100/  391]   Loss 0.121621   Top1 95.796875   Top5 99.968750   BatchTime 0.119941   LR 0.001000   
2022-11-03 22:59:51,728 - INFO  - Training [24][  120/  391]   Loss 0.121689   Top1 95.761719   Top5 99.973958   BatchTime 0.116648   LR 0.001000   
2022-11-03 22:59:53,818 - INFO  - Training [24][  140/  391]   Loss 0.120845   Top1 95.770089   Top5 99.977679   BatchTime 0.114915   LR 0.001000   
2022-11-03 22:59:55,817 - INFO  - Training [24][  160/  391]   Loss 0.118614   Top1 95.883789   Top5 99.975586   BatchTime 0.113044   LR 0.001000   
2022-11-03 22:59:57,821 - INFO  - Training [24][  180/  391]   Loss 0.119005   Top1 95.828993   Top5 99.973958   BatchTime 0.111613   LR 0.001000   
2022-11-03 22:59:59,843 - INFO  - Training [24][  200/  391]   Loss 0.121188   Top1 95.738281   Top5 99.976562   BatchTime 0.110562   LR 0.001000   
2022-11-03 23:00:01,857 - INFO  - Training [24][  220/  391]   Loss 0.119803   Top1 95.791903   Top5 99.978693   BatchTime 0.109668   LR 0.001000   
2022-11-03 23:00:03,880 - INFO  - Training [24][  240/  391]   Loss 0.119817   Top1 95.804036   Top5 99.977214   BatchTime 0.108958   LR 0.001000   
2022-11-03 23:00:05,880 - INFO  - Training [24][  260/  391]   Loss 0.118413   Top1 95.829327   Top5 99.978966   BatchTime 0.108266   LR 0.001000   
2022-11-03 23:00:07,886 - INFO  - Training [24][  280/  391]   Loss 0.117836   Top1 95.837054   Top5 99.980469   BatchTime 0.107699   LR 0.001000   
2022-11-03 23:00:09,896 - INFO  - Training [24][  300/  391]   Loss 0.118841   Top1 95.812500   Top5 99.979167   BatchTime 0.107219   LR 0.001000   
2022-11-03 23:00:11,892 - INFO  - Training [24][  320/  391]   Loss 0.118653   Top1 95.817871   Top5 99.980469   BatchTime 0.106755   LR 0.001000   
2022-11-03 23:00:13,871 - INFO  - Training [24][  340/  391]   Loss 0.118855   Top1 95.785846   Top5 99.979320   BatchTime 0.106294   LR 0.001000   
2022-11-03 23:00:15,827 - INFO  - Training [24][  360/  391]   Loss 0.119664   Top1 95.770399   Top5 99.971788   BatchTime 0.105824   LR 0.001000   
2022-11-03 23:00:17,785 - INFO  - Training [24][  380/  391]   Loss 0.119945   Top1 95.748355   Top5 99.973273   BatchTime 0.105406   LR 0.001000   
2022-11-03 23:00:19,225 - INFO  - ==> Top1: 95.766    Top5: 99.974    Loss: 0.120

2022-11-03 23:00:19,226 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:00:21,856 - INFO  - Validation [24][   20/   79]   Loss 0.366483   Top1 89.648438   Top5 99.492188   BatchTime 0.131420   
2022-11-03 23:00:22,562 - INFO  - Validation [24][   40/   79]   Loss 0.373403   Top1 89.433594   Top5 99.433594   BatchTime 0.083368   
2022-11-03 23:00:23,267 - INFO  - Validation [24][   60/   79]   Loss 0.362761   Top1 89.778646   Top5 99.531250   BatchTime 0.067323   
2022-11-03 23:00:24,391 - INFO  - ==> Top1: 89.770    Top5: 99.590    Loss: 0.361

2022-11-03 23:00:24,418 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:00:24,418 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:00:24,419 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 89.610   Top5: 99.570] Sparsity : 0.850
2022-11-03 23:00:24,554 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:00:24,555 - INFO  - >>>>>>>> Epoch  25
2022-11-03 23:00:24,556 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:00:28,516 - INFO  - Training [25][   20/  391]   Loss 0.130360   Top1 95.507812   Top5 99.960938   BatchTime 0.197987   LR 0.001000   
2022-11-03 23:00:30,544 - INFO  - Training [25][   40/  391]   Loss 0.125402   Top1 95.664062   Top5 99.980469   BatchTime 0.149684   LR 0.001000   
2022-11-03 23:00:32,525 - INFO  - Training [25][   60/  391]   Loss 0.119094   Top1 95.833333   Top5 99.986979   BatchTime 0.132798   LR 0.001000   
2022-11-03 23:00:34,540 - INFO  - Training [25][   80/  391]   Loss 0.121064   Top1 95.751953   Top5 99.990234   BatchTime 0.124787   LR 0.001000   
2022-11-03 23:00:36,541 - INFO  - Training [25][  100/  391]   Loss 0.122043   Top1 95.710938   Top5 99.992188   BatchTime 0.119845   LR 0.001000   
2022-11-03 23:00:38,543 - INFO  - Training [25][  120/  391]   Loss 0.119485   Top1 95.761719   Top5 99.993490   BatchTime 0.116556   LR 0.001000   
2022-11-03 23:00:40,556 - INFO  - Training [25][  140/  391]   Loss 0.118444   Top1 95.825893   Top5 99.988839   BatchTime 0.114282   LR 0.001000   
2022-11-03 23:00:42,595 - INFO  - Training [25][  160/  391]   Loss 0.119764   Top1 95.810547   Top5 99.985352   BatchTime 0.112736   LR 0.001000   
2022-11-03 23:00:44,600 - INFO  - Training [25][  180/  391]   Loss 0.119031   Top1 95.820312   Top5 99.982639   BatchTime 0.111353   LR 0.001000   
2022-11-03 23:00:46,631 - INFO  - Training [25][  200/  391]   Loss 0.119187   Top1 95.832031   Top5 99.976562   BatchTime 0.110372   LR 0.001000   
2022-11-03 23:00:48,633 - INFO  - Training [25][  220/  391]   Loss 0.120524   Top1 95.727983   Top5 99.971591   BatchTime 0.109435   LR 0.001000   
2022-11-03 23:00:50,636 - INFO  - Training [25][  240/  391]   Loss 0.119621   Top1 95.761719   Top5 99.970703   BatchTime 0.108662   LR 0.001000   
2022-11-03 23:00:52,646 - INFO  - Training [25][  260/  391]   Loss 0.118884   Top1 95.787260   Top5 99.969952   BatchTime 0.108035   LR 0.001000   
2022-11-03 23:00:54,658 - INFO  - Training [25][  280/  391]   Loss 0.117684   Top1 95.851004   Top5 99.969308   BatchTime 0.107502   LR 0.001000   
2022-11-03 23:00:56,665 - INFO  - Training [25][  300/  391]   Loss 0.117537   Top1 95.856771   Top5 99.971354   BatchTime 0.107026   LR 0.001000   
2022-11-03 23:00:58,668 - INFO  - Training [25][  320/  391]   Loss 0.117823   Top1 95.859375   Top5 99.970703   BatchTime 0.106595   LR 0.001000   
2022-11-03 23:01:00,653 - INFO  - Training [25][  340/  391]   Loss 0.117028   Top1 95.912224   Top5 99.970129   BatchTime 0.106165   LR 0.001000   
2022-11-03 23:01:02,610 - INFO  - Training [25][  360/  391]   Loss 0.117973   Top1 95.889757   Top5 99.971788   BatchTime 0.105701   LR 0.001000   
2022-11-03 23:01:04,563 - INFO  - Training [25][  380/  391]   Loss 0.117743   Top1 95.892270   Top5 99.971217   BatchTime 0.105279   LR 0.001000   
2022-11-03 23:01:06,040 - INFO  - ==> Top1: 95.906    Top5: 99.972    Loss: 0.118

2022-11-03 23:01:06,042 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:01:08,668 - INFO  - Validation [25][   20/   79]   Loss 0.354272   Top1 89.453125   Top5 99.492188   BatchTime 0.131233   
2022-11-03 23:01:09,364 - INFO  - Validation [25][   40/   79]   Loss 0.360681   Top1 89.335938   Top5 99.531250   BatchTime 0.083025   
2022-11-03 23:01:10,061 - INFO  - Validation [25][   60/   79]   Loss 0.355903   Top1 89.726562   Top5 99.544271   BatchTime 0.066963   
2022-11-03 23:01:11,188 - INFO  - ==> Top1: 89.750    Top5: 99.590    Loss: 0.354

2022-11-03 23:01:11,214 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:01:11,215 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:01:11,215 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:01:11,337 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:01:11,338 - INFO  - >>>>>>>> Epoch  26
2022-11-03 23:01:11,339 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:01:15,333 - INFO  - Training [26][   20/  391]   Loss 0.122979   Top1 95.507812   Top5 99.960938   BatchTime 0.199708   LR 0.001000   
2022-11-03 23:01:17,349 - INFO  - Training [26][   40/  391]   Loss 0.117689   Top1 95.507812   Top5 99.980469   BatchTime 0.150247   LR 0.001000   
2022-11-03 23:01:19,381 - INFO  - Training [26][   60/  391]   Loss 0.114964   Top1 95.677083   Top5 99.960938   BatchTime 0.134036   LR 0.001000   
2022-11-03 23:01:21,387 - INFO  - Training [26][   80/  391]   Loss 0.114657   Top1 95.703125   Top5 99.970703   BatchTime 0.125590   LR 0.001000   
2022-11-03 23:01:23,403 - INFO  - Training [26][  100/  391]   Loss 0.113897   Top1 95.726562   Top5 99.968750   BatchTime 0.120633   LR 0.001000   
2022-11-03 23:01:25,412 - INFO  - Training [26][  120/  391]   Loss 0.111770   Top1 95.872396   Top5 99.967448   BatchTime 0.117269   LR 0.001000   
2022-11-03 23:01:27,407 - INFO  - Training [26][  140/  391]   Loss 0.113837   Top1 95.837054   Top5 99.972098   BatchTime 0.114769   LR 0.001000   
2022-11-03 23:01:29,409 - INFO  - Training [26][  160/  391]   Loss 0.115340   Top1 95.839844   Top5 99.960938   BatchTime 0.112934   LR 0.001000   
2022-11-03 23:01:31,558 - INFO  - Training [26][  180/  391]   Loss 0.115886   Top1 95.885417   Top5 99.956597   BatchTime 0.112327   LR 0.001000   
2022-11-03 23:01:33,580 - INFO  - Training [26][  200/  391]   Loss 0.114958   Top1 95.914062   Top5 99.957031   BatchTime 0.111204   LR 0.001000   
2022-11-03 23:01:35,569 - INFO  - Training [26][  220/  391]   Loss 0.114647   Top1 95.916193   Top5 99.960938   BatchTime 0.110133   LR 0.001000   
2022-11-03 23:01:37,560 - INFO  - Training [26][  240/  391]   Loss 0.114030   Top1 95.927734   Top5 99.957682   BatchTime 0.109251   LR 0.001000   
2022-11-03 23:01:39,578 - INFO  - Training [26][  260/  391]   Loss 0.113548   Top1 95.949519   Top5 99.951923   BatchTime 0.108608   LR 0.001000   
2022-11-03 23:01:41,573 - INFO  - Training [26][  280/  391]   Loss 0.113694   Top1 95.915179   Top5 99.955357   BatchTime 0.107976   LR 0.001000   
2022-11-03 23:01:43,575 - INFO  - Training [26][  300/  391]   Loss 0.113206   Top1 95.929688   Top5 99.958333   BatchTime 0.107449   LR 0.001000   
2022-11-03 23:01:45,588 - INFO  - Training [26][  320/  391]   Loss 0.114607   Top1 95.881348   Top5 99.958496   BatchTime 0.107024   LR 0.001000   
2022-11-03 23:01:47,560 - INFO  - Training [26][  340/  391]   Loss 0.114431   Top1 95.889246   Top5 99.960938   BatchTime 0.106528   LR 0.001000   
2022-11-03 23:01:49,515 - INFO  - Training [26][  360/  391]   Loss 0.115085   Top1 95.863715   Top5 99.963108   BatchTime 0.106042   LR 0.001000   
2022-11-03 23:01:51,460 - INFO  - Training [26][  380/  391]   Loss 0.115527   Top1 95.867599   Top5 99.962993   BatchTime 0.105579   LR 0.001000   
2022-11-03 23:01:52,987 - INFO  - ==> Top1: 95.858    Top5: 99.964    Loss: 0.116

2022-11-03 23:01:52,988 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:01:55,552 - INFO  - Validation [26][   20/   79]   Loss 0.375242   Top1 89.335938   Top5 99.531250   BatchTime 0.128129   
2022-11-03 23:01:56,244 - INFO  - Validation [26][   40/   79]   Loss 0.374064   Top1 89.277344   Top5 99.511719   BatchTime 0.081363   
2022-11-03 23:01:56,934 - INFO  - Validation [26][   60/   79]   Loss 0.363261   Top1 89.687500   Top5 99.557292   BatchTime 0.065745   
2022-11-03 23:01:58,027 - INFO  - ==> Top1: 89.670    Top5: 99.600    Loss: 0.361

2022-11-03 23:01:58,056 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:01:58,057 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:01:58,057 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:01:58,187 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:01:58,188 - INFO  - >>>>>>>> Epoch  27
2022-11-03 23:01:58,189 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:02:02,170 - INFO  - Training [27][   20/  391]   Loss 0.126437   Top1 95.468750   Top5 99.960938   BatchTime 0.199037   LR 0.001000   
2022-11-03 23:02:04,200 - INFO  - Training [27][   40/  391]   Loss 0.122099   Top1 95.449219   Top5 99.980469   BatchTime 0.150257   LR 0.001000   
2022-11-03 23:02:06,220 - INFO  - Training [27][   60/  391]   Loss 0.124019   Top1 95.416667   Top5 99.973958   BatchTime 0.133845   LR 0.001000   
2022-11-03 23:02:08,238 - INFO  - Training [27][   80/  391]   Loss 0.119354   Top1 95.693359   Top5 99.980469   BatchTime 0.125607   LR 0.001000   
2022-11-03 23:02:10,246 - INFO  - Training [27][  100/  391]   Loss 0.118107   Top1 95.750000   Top5 99.976562   BatchTime 0.120569   LR 0.001000   
2022-11-03 23:02:12,249 - INFO  - Training [27][  120/  391]   Loss 0.117700   Top1 95.768229   Top5 99.973958   BatchTime 0.117165   LR 0.001000   
2022-11-03 23:02:14,284 - INFO  - Training [27][  140/  391]   Loss 0.116853   Top1 95.731027   Top5 99.977679   BatchTime 0.114958   LR 0.001000   
2022-11-03 23:02:16,292 - INFO  - Training [27][  160/  391]   Loss 0.117822   Top1 95.732422   Top5 99.975586   BatchTime 0.113138   LR 0.001000   
2022-11-03 23:02:18,300 - INFO  - Training [27][  180/  391]   Loss 0.116337   Top1 95.746528   Top5 99.978299   BatchTime 0.111724   LR 0.001000   
2022-11-03 23:02:20,315 - INFO  - Training [27][  200/  391]   Loss 0.118637   Top1 95.664062   Top5 99.972656   BatchTime 0.110626   LR 0.001000   
2022-11-03 23:02:22,316 - INFO  - Training [27][  220/  391]   Loss 0.117935   Top1 95.735085   Top5 99.971591   BatchTime 0.109665   LR 0.001000   
2022-11-03 23:02:24,303 - INFO  - Training [27][  240/  391]   Loss 0.118057   Top1 95.761719   Top5 99.973958   BatchTime 0.108803   LR 0.001000   
2022-11-03 23:02:26,313 - INFO  - Training [27][  260/  391]   Loss 0.116242   Top1 95.820312   Top5 99.975962   BatchTime 0.108166   LR 0.001000   
2022-11-03 23:02:28,336 - INFO  - Training [27][  280/  391]   Loss 0.116661   Top1 95.823103   Top5 99.974888   BatchTime 0.107666   LR 0.001000   
2022-11-03 23:02:30,353 - INFO  - Training [27][  300/  391]   Loss 0.117344   Top1 95.804688   Top5 99.973958   BatchTime 0.107209   LR 0.001000   
2022-11-03 23:02:32,394 - INFO  - Training [27][  320/  391]   Loss 0.117478   Top1 95.812988   Top5 99.973145   BatchTime 0.106887   LR 0.001000   
2022-11-03 23:02:34,349 - INFO  - Training [27][  340/  391]   Loss 0.117256   Top1 95.808824   Top5 99.974724   BatchTime 0.106351   LR 0.001000   
2022-11-03 23:02:36,300 - INFO  - Training [27][  360/  391]   Loss 0.117577   Top1 95.785590   Top5 99.976128   BatchTime 0.105860   LR 0.001000   
2022-11-03 23:02:38,248 - INFO  - Training [27][  380/  391]   Loss 0.117731   Top1 95.760691   Top5 99.977385   BatchTime 0.105416   LR 0.001000   
2022-11-03 23:02:39,753 - INFO  - ==> Top1: 95.768    Top5: 99.974    Loss: 0.118

2022-11-03 23:02:39,754 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:02:42,372 - INFO  - Validation [27][   20/   79]   Loss 0.371816   Top1 89.531250   Top5 99.531250   BatchTime 0.130820   
2022-11-03 23:02:43,070 - INFO  - Validation [27][   40/   79]   Loss 0.375045   Top1 89.394531   Top5 99.433594   BatchTime 0.082853   
2022-11-03 23:02:43,765 - INFO  - Validation [27][   60/   79]   Loss 0.367475   Top1 89.739583   Top5 99.492188   BatchTime 0.066811   
2022-11-03 23:02:44,896 - INFO  - ==> Top1: 89.660    Top5: 99.570    Loss: 0.364

2022-11-03 23:02:44,924 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:02:44,925 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:02:44,925 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:02:45,065 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:02:45,066 - INFO  - >>>>>>>> Epoch  28
2022-11-03 23:02:45,067 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:02:49,019 - INFO  - Training [28][   20/  391]   Loss 0.114163   Top1 95.781250   Top5 99.921875   BatchTime 0.197567   LR 0.001000   
2022-11-03 23:02:51,025 - INFO  - Training [28][   40/  391]   Loss 0.117383   Top1 95.937500   Top5 99.960938   BatchTime 0.148928   LR 0.001000   
2022-11-03 23:02:53,014 - INFO  - Training [28][   60/  391]   Loss 0.123737   Top1 95.690104   Top5 99.973958   BatchTime 0.132444   LR 0.001000   
2022-11-03 23:02:55,037 - INFO  - Training [28][   80/  391]   Loss 0.122039   Top1 95.800781   Top5 99.980469   BatchTime 0.124622   LR 0.001000   
2022-11-03 23:02:57,045 - INFO  - Training [28][  100/  391]   Loss 0.120941   Top1 95.742188   Top5 99.984375   BatchTime 0.119774   LR 0.001000   
2022-11-03 23:02:59,054 - INFO  - Training [28][  120/  391]   Loss 0.122691   Top1 95.709635   Top5 99.980469   BatchTime 0.116552   LR 0.001000   
2022-11-03 23:03:01,070 - INFO  - Training [28][  140/  391]   Loss 0.121005   Top1 95.775670   Top5 99.977679   BatchTime 0.114303   LR 0.001000   
2022-11-03 23:03:03,069 - INFO  - Training [28][  160/  391]   Loss 0.119272   Top1 95.820312   Top5 99.980469   BatchTime 0.112510   LR 0.001000   
2022-11-03 23:03:05,071 - INFO  - Training [28][  180/  391]   Loss 0.118909   Top1 95.807292   Top5 99.978299   BatchTime 0.111128   LR 0.001000   
2022-11-03 23:03:07,087 - INFO  - Training [28][  200/  391]   Loss 0.118064   Top1 95.847656   Top5 99.972656   BatchTime 0.110096   LR 0.001000   
2022-11-03 23:03:09,080 - INFO  - Training [28][  220/  391]   Loss 0.116791   Top1 95.901989   Top5 99.968040   BatchTime 0.109146   LR 0.001000   
2022-11-03 23:03:11,225 - INFO  - Training [28][  240/  391]   Loss 0.116259   Top1 95.927734   Top5 99.967448   BatchTime 0.108988   LR 0.001000   
2022-11-03 23:03:13,215 - INFO  - Training [28][  260/  391]   Loss 0.116572   Top1 95.901442   Top5 99.969952   BatchTime 0.108259   LR 0.001000   
2022-11-03 23:03:15,216 - INFO  - Training [28][  280/  391]   Loss 0.117443   Top1 95.859375   Top5 99.969308   BatchTime 0.107673   LR 0.001000   
2022-11-03 23:03:17,207 - INFO  - Training [28][  300/  391]   Loss 0.117508   Top1 95.880208   Top5 99.968750   BatchTime 0.107130   LR 0.001000   
2022-11-03 23:03:19,210 - INFO  - Training [28][  320/  391]   Loss 0.118023   Top1 95.876465   Top5 99.970703   BatchTime 0.106693   LR 0.001000   
2022-11-03 23:03:21,175 - INFO  - Training [28][  340/  391]   Loss 0.119069   Top1 95.834099   Top5 99.967831   BatchTime 0.106197   LR 0.001000   
2022-11-03 23:03:23,137 - INFO  - Training [28][  360/  391]   Loss 0.118958   Top1 95.828993   Top5 99.967448   BatchTime 0.105747   LR 0.001000   
2022-11-03 23:03:25,106 - INFO  - Training [28][  380/  391]   Loss 0.120213   Top1 95.795641   Top5 99.969161   BatchTime 0.105362   LR 0.001000   
2022-11-03 23:03:26,630 - INFO  - ==> Top1: 95.782    Top5: 99.968    Loss: 0.120

2022-11-03 23:03:26,631 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:03:29,260 - INFO  - Validation [28][   20/   79]   Loss 0.362071   Top1 89.140625   Top5 99.492188   BatchTime 0.131418   
2022-11-03 23:03:29,965 - INFO  - Validation [28][   40/   79]   Loss 0.368215   Top1 89.101562   Top5 99.394531   BatchTime 0.083321   
2022-11-03 23:03:30,655 - INFO  - Validation [28][   60/   79]   Loss 0.364431   Top1 89.466146   Top5 99.453125   BatchTime 0.067051   
2022-11-03 23:03:31,784 - INFO  - ==> Top1: 89.520    Top5: 99.520    Loss: 0.362

2022-11-03 23:03:31,811 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:03:31,812 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:03:31,812 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:03:31,941 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:03:31,941 - INFO  - >>>>>>>> Epoch  29
2022-11-03 23:03:31,942 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:03:35,929 - INFO  - Training [29][   20/  391]   Loss 0.117814   Top1 95.742188   Top5 100.000000   BatchTime 0.199300   LR 0.001000   
2022-11-03 23:03:37,961 - INFO  - Training [29][   40/  391]   Loss 0.123308   Top1 95.507812   Top5 99.960938   BatchTime 0.150462   LR 0.001000   
2022-11-03 23:03:39,971 - INFO  - Training [29][   60/  391]   Loss 0.115920   Top1 95.833333   Top5 99.973958   BatchTime 0.133807   LR 0.001000   
2022-11-03 23:03:42,007 - INFO  - Training [29][   80/  391]   Loss 0.116954   Top1 95.839844   Top5 99.980469   BatchTime 0.125799   LR 0.001000   
2022-11-03 23:03:44,041 - INFO  - Training [29][  100/  391]   Loss 0.117552   Top1 95.859375   Top5 99.968750   BatchTime 0.120978   LR 0.001000   
2022-11-03 23:03:46,065 - INFO  - Training [29][  120/  391]   Loss 0.116606   Top1 95.865885   Top5 99.973958   BatchTime 0.117686   LR 0.001000   
2022-11-03 23:03:48,077 - INFO  - Training [29][  140/  391]   Loss 0.115664   Top1 95.909598   Top5 99.972098   BatchTime 0.115245   LR 0.001000   
2022-11-03 23:03:50,104 - INFO  - Training [29][  160/  391]   Loss 0.117645   Top1 95.820312   Top5 99.965820   BatchTime 0.113505   LR 0.001000   
2022-11-03 23:03:52,128 - INFO  - Training [29][  180/  391]   Loss 0.117641   Top1 95.842014   Top5 99.960938   BatchTime 0.112137   LR 0.001000   
2022-11-03 23:03:54,135 - INFO  - Training [29][  200/  391]   Loss 0.119848   Top1 95.824219   Top5 99.953125   BatchTime 0.110958   LR 0.001000   
2022-11-03 23:03:56,144 - INFO  - Training [29][  220/  391]   Loss 0.120452   Top1 95.795455   Top5 99.953835   BatchTime 0.110004   LR 0.001000   
2022-11-03 23:03:58,162 - INFO  - Training [29][  240/  391]   Loss 0.119977   Top1 95.826823   Top5 99.954427   BatchTime 0.109243   LR 0.001000   
2022-11-03 23:04:00,180 - INFO  - Training [29][  260/  391]   Loss 0.119828   Top1 95.820312   Top5 99.957933   BatchTime 0.108603   LR 0.001000   
2022-11-03 23:04:02,194 - INFO  - Training [29][  280/  391]   Loss 0.120029   Top1 95.789621   Top5 99.960938   BatchTime 0.108040   LR 0.001000   
2022-11-03 23:04:04,204 - INFO  - Training [29][  300/  391]   Loss 0.118933   Top1 95.825521   Top5 99.963542   BatchTime 0.107537   LR 0.001000   
2022-11-03 23:04:06,224 - INFO  - Training [29][  320/  391]   Loss 0.119473   Top1 95.795898   Top5 99.965820   BatchTime 0.107128   LR 0.001000   
2022-11-03 23:04:08,199 - INFO  - Training [29][  340/  391]   Loss 0.119376   Top1 95.788143   Top5 99.967831   BatchTime 0.106633   LR 0.001000   
2022-11-03 23:04:10,150 - INFO  - Training [29][  360/  391]   Loss 0.119550   Top1 95.779080   Top5 99.969618   BatchTime 0.106129   LR 0.001000   
2022-11-03 23:04:12,109 - INFO  - Training [29][  380/  391]   Loss 0.119750   Top1 95.756579   Top5 99.969161   BatchTime 0.105700   LR 0.001000   
2022-11-03 23:04:13,526 - INFO  - ==> Top1: 95.746    Top5: 99.970    Loss: 0.120

2022-11-03 23:04:13,528 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:04:16,211 - INFO  - Validation [29][   20/   79]   Loss 0.377933   Top1 88.906250   Top5 99.570312   BatchTime 0.134045   
2022-11-03 23:04:16,923 - INFO  - Validation [29][   40/   79]   Loss 0.379870   Top1 89.179688   Top5 99.492188   BatchTime 0.084827   
2022-11-03 23:04:17,625 - INFO  - Validation [29][   60/   79]   Loss 0.373334   Top1 89.270833   Top5 99.518229   BatchTime 0.068258   
2022-11-03 23:04:18,778 - INFO  - ==> Top1: 89.260    Top5: 99.570    Loss: 0.374

2022-11-03 23:04:18,809 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:04:18,810 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:04:18,810 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:04:18,996 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:04:18,996 - INFO  - >>>>>>>> Epoch  30
2022-11-03 23:04:18,998 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:04:22,996 - INFO  - Training [30][   20/  391]   Loss 0.119518   Top1 95.507812   Top5 100.000000   BatchTime 0.199884   LR 0.001000   
2022-11-03 23:04:25,015 - INFO  - Training [30][   40/  391]   Loss 0.119987   Top1 95.644531   Top5 100.000000   BatchTime 0.150432   LR 0.001000   
2022-11-03 23:04:27,019 - INFO  - Training [30][   60/  391]   Loss 0.116333   Top1 95.885417   Top5 99.973958   BatchTime 0.133682   LR 0.001000   
2022-11-03 23:04:29,049 - INFO  - Training [30][   80/  391]   Loss 0.116713   Top1 95.869141   Top5 99.980469   BatchTime 0.125631   LR 0.001000   
2022-11-03 23:04:31,082 - INFO  - Training [30][  100/  391]   Loss 0.117875   Top1 95.750000   Top5 99.984375   BatchTime 0.120835   LR 0.001000   
2022-11-03 23:04:33,105 - INFO  - Training [30][  120/  391]   Loss 0.117924   Top1 95.755208   Top5 99.980469   BatchTime 0.117554   LR 0.001000   
2022-11-03 23:04:35,128 - INFO  - Training [30][  140/  391]   Loss 0.119124   Top1 95.742188   Top5 99.983259   BatchTime 0.115216   LR 0.001000   
2022-11-03 23:04:37,143 - INFO  - Training [30][  160/  391]   Loss 0.119942   Top1 95.751953   Top5 99.985352   BatchTime 0.113406   LR 0.001000   
2022-11-03 23:04:39,142 - INFO  - Training [30][  180/  391]   Loss 0.119711   Top1 95.772569   Top5 99.982639   BatchTime 0.111909   LR 0.001000   
2022-11-03 23:04:41,143 - INFO  - Training [30][  200/  391]   Loss 0.120166   Top1 95.757812   Top5 99.984375   BatchTime 0.110725   LR 0.001000   
2022-11-03 23:04:43,155 - INFO  - Training [30][  220/  391]   Loss 0.120379   Top1 95.738636   Top5 99.982244   BatchTime 0.109804   LR 0.001000   
2022-11-03 23:04:45,163 - INFO  - Training [30][  240/  391]   Loss 0.120530   Top1 95.712891   Top5 99.980469   BatchTime 0.109017   LR 0.001000   
2022-11-03 23:04:47,169 - INFO  - Training [30][  260/  391]   Loss 0.121649   Top1 95.679087   Top5 99.981971   BatchTime 0.108349   LR 0.001000   
2022-11-03 23:04:49,118 - INFO  - Training [30][  280/  391]   Loss 0.121896   Top1 95.680804   Top5 99.980469   BatchTime 0.107569   LR 0.001000   
2022-11-03 23:04:51,141 - INFO  - Training [30][  300/  391]   Loss 0.121508   Top1 95.718750   Top5 99.981771   BatchTime 0.107141   LR 0.001000   
2022-11-03 23:04:53,241 - INFO  - Training [30][  320/  391]   Loss 0.121543   Top1 95.703125   Top5 99.980469   BatchTime 0.107007   LR 0.001000   
2022-11-03 23:04:55,232 - INFO  - Training [30][  340/  391]   Loss 0.121868   Top1 95.714614   Top5 99.979320   BatchTime 0.106568   LR 0.001000   
2022-11-03 23:04:57,192 - INFO  - Training [30][  360/  391]   Loss 0.122496   Top1 95.653212   Top5 99.978299   BatchTime 0.106094   LR 0.001000   
2022-11-03 23:04:59,149 - INFO  - Training [30][  380/  391]   Loss 0.122435   Top1 95.647615   Top5 99.975329   BatchTime 0.105659   LR 0.001000   
2022-11-03 23:05:00,453 - INFO  - ==> Top1: 95.630    Top5: 99.974    Loss: 0.123

2022-11-03 23:05:00,454 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:05:03,134 - INFO  - Validation [30][   20/   79]   Loss 0.361802   Top1 89.453125   Top5 99.492188   BatchTime 0.133914   
2022-11-03 23:05:03,833 - INFO  - Validation [30][   40/   79]   Loss 0.372811   Top1 89.355469   Top5 99.375000   BatchTime 0.084436   
2022-11-03 23:05:04,526 - INFO  - Validation [30][   60/   79]   Loss 0.370299   Top1 89.674479   Top5 99.453125   BatchTime 0.067845   
2022-11-03 23:05:05,425 - INFO  - ==> Top1: 89.500    Top5: 99.530    Loss: 0.371

2022-11-03 23:05:05,456 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:05:05,457 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:05:05,457 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:05:05,563 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:05:05,564 - INFO  - >>>>>>>> Epoch  31
2022-11-03 23:05:05,565 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:05:09,518 - INFO  - Training [31][   20/  391]   Loss 0.128980   Top1 95.312500   Top5 100.000000   BatchTime 0.197633   LR 0.001000   
2022-11-03 23:05:11,527 - INFO  - Training [31][   40/  391]   Loss 0.131123   Top1 95.312500   Top5 100.000000   BatchTime 0.149034   LR 0.001000   
2022-11-03 23:05:13,573 - INFO  - Training [31][   60/  391]   Loss 0.132538   Top1 95.195312   Top5 99.973958   BatchTime 0.133462   LR 0.001000   
2022-11-03 23:05:15,572 - INFO  - Training [31][   80/  391]   Loss 0.134074   Top1 95.185547   Top5 99.970703   BatchTime 0.125077   LR 0.001000   
2022-11-03 23:05:17,580 - INFO  - Training [31][  100/  391]   Loss 0.133224   Top1 95.304688   Top5 99.976562   BatchTime 0.120142   LR 0.001000   
2022-11-03 23:05:19,580 - INFO  - Training [31][  120/  391]   Loss 0.133663   Top1 95.345052   Top5 99.967448   BatchTime 0.116784   LR 0.001000   
2022-11-03 23:05:21,582 - INFO  - Training [31][  140/  391]   Loss 0.132967   Top1 95.306920   Top5 99.972098   BatchTime 0.114403   LR 0.001000   
2022-11-03 23:05:23,605 - INFO  - Training [31][  160/  391]   Loss 0.132068   Top1 95.395508   Top5 99.965820   BatchTime 0.112746   LR 0.001000   
2022-11-03 23:05:25,624 - INFO  - Training [31][  180/  391]   Loss 0.130560   Top1 95.464410   Top5 99.969618   BatchTime 0.111431   LR 0.001000   
2022-11-03 23:05:27,656 - INFO  - Training [31][  200/  391]   Loss 0.128882   Top1 95.531250   Top5 99.972656   BatchTime 0.110449   LR 0.001000   
2022-11-03 23:05:29,700 - INFO  - Training [31][  220/  391]   Loss 0.129048   Top1 95.536222   Top5 99.975142   BatchTime 0.109698   LR 0.001000   
2022-11-03 23:05:31,722 - INFO  - Training [31][  240/  391]   Loss 0.128940   Top1 95.504557   Top5 99.970703   BatchTime 0.108984   LR 0.001000   
2022-11-03 23:05:33,742 - INFO  - Training [31][  260/  391]   Loss 0.128327   Top1 95.552885   Top5 99.972957   BatchTime 0.108368   LR 0.001000   
2022-11-03 23:05:35,758 - INFO  - Training [31][  280/  391]   Loss 0.127179   Top1 95.588728   Top5 99.974888   BatchTime 0.107829   LR 0.001000   
2022-11-03 23:05:37,764 - INFO  - Training [31][  300/  391]   Loss 0.126938   Top1 95.575521   Top5 99.976562   BatchTime 0.107326   LR 0.001000   
2022-11-03 23:05:39,772 - INFO  - Training [31][  320/  391]   Loss 0.126040   Top1 95.622559   Top5 99.970703   BatchTime 0.106894   LR 0.001000   
2022-11-03 23:05:41,751 - INFO  - Training [31][  340/  391]   Loss 0.126827   Top1 95.595129   Top5 99.972426   BatchTime 0.106424   LR 0.001000   
2022-11-03 23:05:43,704 - INFO  - Training [31][  360/  391]   Loss 0.126795   Top1 95.609809   Top5 99.973958   BatchTime 0.105937   LR 0.001000   
2022-11-03 23:05:45,660 - INFO  - Training [31][  380/  391]   Loss 0.127458   Top1 95.577714   Top5 99.973273   BatchTime 0.105510   LR 0.001000   
2022-11-03 23:05:46,961 - INFO  - ==> Top1: 95.584    Top5: 99.972    Loss: 0.127

2022-11-03 23:05:46,962 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:05:49,608 - INFO  - Validation [31][   20/   79]   Loss 0.361376   Top1 89.257812   Top5 99.531250   BatchTime 0.132296   
2022-11-03 23:05:50,312 - INFO  - Validation [31][   40/   79]   Loss 0.374426   Top1 89.414062   Top5 99.394531   BatchTime 0.083745   
2022-11-03 23:05:51,010 - INFO  - Validation [31][   60/   79]   Loss 0.371510   Top1 89.674479   Top5 99.453125   BatchTime 0.067464   
2022-11-03 23:05:51,924 - INFO  - ==> Top1: 89.480    Top5: 99.520    Loss: 0.369

2022-11-03 23:05:51,956 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:05:51,957 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:05:51,957 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:05:52,063 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:05:52,063 - INFO  - >>>>>>>> Epoch  32
2022-11-03 23:05:52,065 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:05:56,118 - INFO  - Training [32][   20/  391]   Loss 0.123272   Top1 96.054688   Top5 99.960938   BatchTime 0.202675   LR 0.001000   
2022-11-03 23:05:58,152 - INFO  - Training [32][   40/  391]   Loss 0.125510   Top1 95.644531   Top5 99.941406   BatchTime 0.152170   LR 0.001000   
2022-11-03 23:06:00,168 - INFO  - Training [32][   60/  391]   Loss 0.126552   Top1 95.625000   Top5 99.947917   BatchTime 0.135058   LR 0.001000   
2022-11-03 23:06:02,188 - INFO  - Training [32][   80/  391]   Loss 0.127396   Top1 95.527344   Top5 99.960938   BatchTime 0.126535   LR 0.001000   
2022-11-03 23:06:04,209 - INFO  - Training [32][  100/  391]   Loss 0.133281   Top1 95.265625   Top5 99.960938   BatchTime 0.121441   LR 0.001000   
2022-11-03 23:06:06,217 - INFO  - Training [32][  120/  391]   Loss 0.131943   Top1 95.325521   Top5 99.954427   BatchTime 0.117937   LR 0.001000   
2022-11-03 23:06:08,218 - INFO  - Training [32][  140/  391]   Loss 0.130780   Top1 95.385045   Top5 99.955357   BatchTime 0.115377   LR 0.001000   
2022-11-03 23:06:10,224 - INFO  - Training [32][  160/  391]   Loss 0.131038   Top1 95.366211   Top5 99.956055   BatchTime 0.113492   LR 0.001000   
2022-11-03 23:06:12,229 - INFO  - Training [32][  180/  391]   Loss 0.130930   Top1 95.364583   Top5 99.956597   BatchTime 0.112023   LR 0.001000   
2022-11-03 23:06:14,235 - INFO  - Training [32][  200/  391]   Loss 0.132996   Top1 95.261719   Top5 99.957031   BatchTime 0.110851   LR 0.001000   
2022-11-03 23:06:16,256 - INFO  - Training [32][  220/  391]   Loss 0.133594   Top1 95.248580   Top5 99.953835   BatchTime 0.109958   LR 0.001000   
2022-11-03 23:06:18,296 - INFO  - Training [32][  240/  391]   Loss 0.133266   Top1 95.253906   Top5 99.957682   BatchTime 0.109295   LR 0.001000   
2022-11-03 23:06:20,322 - INFO  - Training [32][  260/  391]   Loss 0.133172   Top1 95.234375   Top5 99.951923   BatchTime 0.108681   LR 0.001000   
2022-11-03 23:06:22,355 - INFO  - Training [32][  280/  391]   Loss 0.132777   Top1 95.251116   Top5 99.955357   BatchTime 0.108178   LR 0.001000   
2022-11-03 23:06:24,369 - INFO  - Training [32][  300/  391]   Loss 0.133269   Top1 95.244792   Top5 99.955729   BatchTime 0.107679   LR 0.001000   
2022-11-03 23:06:26,399 - INFO  - Training [32][  320/  391]   Loss 0.133814   Top1 95.229492   Top5 99.958496   BatchTime 0.107293   LR 0.001000   
2022-11-03 23:06:28,390 - INFO  - Training [32][  340/  391]   Loss 0.135482   Top1 95.199908   Top5 99.956342   BatchTime 0.106836   LR 0.001000   
2022-11-03 23:06:30,344 - INFO  - Training [32][  360/  391]   Loss 0.135742   Top1 95.203993   Top5 99.954427   BatchTime 0.106329   LR 0.001000   
2022-11-03 23:06:32,296 - INFO  - Training [32][  380/  391]   Loss 0.136914   Top1 95.160362   Top5 99.952714   BatchTime 0.105869   LR 0.001000   
2022-11-03 23:06:33,752 - INFO  - ==> Top1: 95.144    Top5: 99.954    Loss: 0.137

2022-11-03 23:06:33,753 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:06:36,371 - INFO  - Validation [32][   20/   79]   Loss 0.393123   Top1 89.062500   Top5 99.570312   BatchTime 0.130827   
2022-11-03 23:06:37,084 - INFO  - Validation [32][   40/   79]   Loss 0.396243   Top1 89.062500   Top5 99.472656   BatchTime 0.083240   
2022-11-03 23:06:37,780 - INFO  - Validation [32][   60/   79]   Loss 0.387301   Top1 89.322917   Top5 99.518229   BatchTime 0.067093   
2022-11-03 23:06:38,679 - INFO  - ==> Top1: 89.200    Top5: 99.590    Loss: 0.385

2022-11-03 23:06:38,710 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:06:38,711 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:06:38,711 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:06:38,816 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:06:38,816 - INFO  - >>>>>>>> Epoch  33
2022-11-03 23:06:38,817 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:06:42,771 - INFO  - Training [33][   20/  391]   Loss 0.143930   Top1 95.000000   Top5 100.000000   BatchTime 0.197702   LR 0.001000   
2022-11-03 23:06:44,789 - INFO  - Training [33][   40/  391]   Loss 0.144330   Top1 94.902344   Top5 99.960938   BatchTime 0.149292   LR 0.001000   
2022-11-03 23:06:46,803 - INFO  - Training [33][   60/  391]   Loss 0.137443   Top1 95.117188   Top5 99.973958   BatchTime 0.133088   LR 0.001000   
2022-11-03 23:06:48,810 - INFO  - Training [33][   80/  391]   Loss 0.137838   Top1 95.146484   Top5 99.970703   BatchTime 0.124908   LR 0.001000   
2022-11-03 23:06:50,853 - INFO  - Training [33][  100/  391]   Loss 0.137698   Top1 95.148438   Top5 99.960938   BatchTime 0.120350   LR 0.001000   
2022-11-03 23:06:52,868 - INFO  - Training [33][  120/  391]   Loss 0.136813   Top1 95.156250   Top5 99.967448   BatchTime 0.117083   LR 0.001000   
2022-11-03 23:06:54,900 - INFO  - Training [33][  140/  391]   Loss 0.136978   Top1 95.145089   Top5 99.972098   BatchTime 0.114874   LR 0.001000   
2022-11-03 23:06:56,905 - INFO  - Training [33][  160/  391]   Loss 0.138949   Top1 95.053711   Top5 99.975586   BatchTime 0.113044   LR 0.001000   
2022-11-03 23:06:58,906 - INFO  - Training [33][  180/  391]   Loss 0.140004   Top1 95.004340   Top5 99.969618   BatchTime 0.111600   LR 0.001000   
2022-11-03 23:07:00,917 - INFO  - Training [33][  200/  391]   Loss 0.141539   Top1 94.929688   Top5 99.964844   BatchTime 0.110496   LR 0.001000   
2022-11-03 23:07:02,914 - INFO  - Training [33][  220/  391]   Loss 0.142583   Top1 94.865057   Top5 99.957386   BatchTime 0.109528   LR 0.001000   
2022-11-03 23:07:04,918 - INFO  - Training [33][  240/  391]   Loss 0.140177   Top1 94.957682   Top5 99.954427   BatchTime 0.108749   LR 0.001000   
2022-11-03 23:07:06,928 - INFO  - Training [33][  260/  391]   Loss 0.140056   Top1 94.960938   Top5 99.957933   BatchTime 0.108115   LR 0.001000   
2022-11-03 23:07:08,936 - INFO  - Training [33][  280/  391]   Loss 0.141463   Top1 94.930246   Top5 99.958147   BatchTime 0.107565   LR 0.001000   
2022-11-03 23:07:10,940 - INFO  - Training [33][  300/  391]   Loss 0.142255   Top1 94.932292   Top5 99.947917   BatchTime 0.107072   LR 0.001000   
2022-11-03 23:07:12,948 - INFO  - Training [33][  320/  391]   Loss 0.142078   Top1 94.941406   Top5 99.951172   BatchTime 0.106656   LR 0.001000   
2022-11-03 23:07:14,938 - INFO  - Training [33][  340/  391]   Loss 0.143114   Top1 94.905790   Top5 99.951746   BatchTime 0.106235   LR 0.001000   
2022-11-03 23:07:16,891 - INFO  - Training [33][  360/  391]   Loss 0.144303   Top1 94.865451   Top5 99.947917   BatchTime 0.105759   LR 0.001000   
2022-11-03 23:07:18,855 - INFO  - Training [33][  380/  391]   Loss 0.145005   Top1 94.837582   Top5 99.950658   BatchTime 0.105361   LR 0.001000   
2022-11-03 23:07:20,168 - INFO  - ==> Top1: 94.848    Top5: 99.950    Loss: 0.145

2022-11-03 23:07:20,169 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:07:22,886 - INFO  - Validation [33][   20/   79]   Loss 0.397115   Top1 88.476562   Top5 99.570312   BatchTime 0.130444   
2022-11-03 23:07:23,590 - INFO  - Validation [33][   40/   79]   Loss 0.394939   Top1 88.945312   Top5 99.492188   BatchTime 0.082814   
2022-11-03 23:07:24,290 - INFO  - Validation [33][   60/   79]   Loss 0.382242   Top1 89.153646   Top5 99.544271   BatchTime 0.066882   
2022-11-03 23:07:25,214 - INFO  - ==> Top1: 89.200    Top5: 99.580    Loss: 0.381

2022-11-03 23:07:25,253 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:07:25,254 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:07:25,254 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:07:25,360 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:07:25,360 - INFO  - >>>>>>>> Epoch  34
2022-11-03 23:07:25,361 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:07:29,319 - INFO  - Training [34][   20/  391]   Loss 0.144907   Top1 95.039062   Top5 99.921875   BatchTime 0.197870   LR 0.001000   
2022-11-03 23:07:31,342 - INFO  - Training [34][   40/  391]   Loss 0.149888   Top1 94.707031   Top5 99.941406   BatchTime 0.149515   LR 0.001000   
2022-11-03 23:07:33,359 - INFO  - Training [34][   60/  391]   Loss 0.143178   Top1 94.986979   Top5 99.947917   BatchTime 0.133303   LR 0.001000   
2022-11-03 23:07:35,395 - INFO  - Training [34][   80/  391]   Loss 0.141282   Top1 94.990234   Top5 99.951172   BatchTime 0.125422   LR 0.001000   
2022-11-03 23:07:37,418 - INFO  - Training [34][  100/  391]   Loss 0.138768   Top1 95.093750   Top5 99.937500   BatchTime 0.120570   LR 0.001000   
2022-11-03 23:07:39,435 - INFO  - Training [34][  120/  391]   Loss 0.142868   Top1 94.947917   Top5 99.941406   BatchTime 0.117283   LR 0.001000   
2022-11-03 23:07:41,472 - INFO  - Training [34][  140/  391]   Loss 0.143064   Top1 94.966518   Top5 99.938616   BatchTime 0.115075   LR 0.001000   
2022-11-03 23:07:43,493 - INFO  - Training [34][  160/  391]   Loss 0.143375   Top1 95.000000   Top5 99.941406   BatchTime 0.113322   LR 0.001000   
2022-11-03 23:07:45,501 - INFO  - Training [34][  180/  391]   Loss 0.145777   Top1 94.809028   Top5 99.943576   BatchTime 0.111887   LR 0.001000   
2022-11-03 23:07:47,517 - INFO  - Training [34][  200/  391]   Loss 0.147587   Top1 94.781250   Top5 99.949219   BatchTime 0.110778   LR 0.001000   
2022-11-03 23:07:49,521 - INFO  - Training [34][  220/  391]   Loss 0.148593   Top1 94.765625   Top5 99.950284   BatchTime 0.109816   LR 0.001000   
2022-11-03 23:07:51,534 - INFO  - Training [34][  240/  391]   Loss 0.148388   Top1 94.762370   Top5 99.951172   BatchTime 0.109053   LR 0.001000   
2022-11-03 23:07:53,536 - INFO  - Training [34][  260/  391]   Loss 0.149935   Top1 94.735577   Top5 99.945913   BatchTime 0.108364   LR 0.001000   
2022-11-03 23:07:55,536 - INFO  - Training [34][  280/  391]   Loss 0.149975   Top1 94.701451   Top5 99.946987   BatchTime 0.107764   LR 0.001000   
2022-11-03 23:07:57,534 - INFO  - Training [34][  300/  391]   Loss 0.150889   Top1 94.682292   Top5 99.947917   BatchTime 0.107242   LR 0.001000   
2022-11-03 23:07:59,552 - INFO  - Training [34][  320/  391]   Loss 0.151353   Top1 94.665527   Top5 99.948730   BatchTime 0.106845   LR 0.001000   
2022-11-03 23:08:01,534 - INFO  - Training [34][  340/  391]   Loss 0.152665   Top1 94.581801   Top5 99.949449   BatchTime 0.106388   LR 0.001000   
2022-11-03 23:08:03,482 - INFO  - Training [34][  360/  391]   Loss 0.154392   Top1 94.518229   Top5 99.947917   BatchTime 0.105890   LR 0.001000   
2022-11-03 23:08:05,365 - INFO  - Training [34][  380/  391]   Loss 0.154770   Top1 94.488076   Top5 99.948602   BatchTime 0.105270   LR 0.001000   
2022-11-03 23:08:06,675 - INFO  - ==> Top1: 94.474    Top5: 99.948    Loss: 0.155

2022-11-03 23:08:06,676 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:08:09,131 - INFO  - Validation [34][   20/   79]   Loss 0.392424   Top1 88.320312   Top5 99.609375   BatchTime 0.122672   
2022-11-03 23:08:09,896 - INFO  - Validation [34][   40/   79]   Loss 0.395064   Top1 88.457031   Top5 99.511719   BatchTime 0.080447   
2022-11-03 23:08:10,587 - INFO  - Validation [34][   60/   79]   Loss 0.394468   Top1 88.593750   Top5 99.518229   BatchTime 0.065156   
2022-11-03 23:08:11,501 - INFO  - ==> Top1: 88.540    Top5: 99.540    Loss: 0.396

2022-11-03 23:08:11,537 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:08:11,538 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:08:11,538 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:08:11,634 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:08:11,634 - INFO  - >>>>>>>> Epoch  35
2022-11-03 23:08:11,636 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:08:15,689 - INFO  - Training [35][   20/  391]   Loss 0.153596   Top1 94.804688   Top5 99.921875   BatchTime 0.202675   LR 0.001000   
2022-11-03 23:08:17,716 - INFO  - Training [35][   40/  391]   Loss 0.154134   Top1 94.570312   Top5 99.960938   BatchTime 0.151993   LR 0.001000   
2022-11-03 23:08:19,723 - INFO  - Training [35][   60/  391]   Loss 0.157207   Top1 94.492188   Top5 99.934896   BatchTime 0.134778   LR 0.001000   
2022-11-03 23:08:21,733 - INFO  - Training [35][   80/  391]   Loss 0.156642   Top1 94.433594   Top5 99.951172   BatchTime 0.126210   LR 0.001000   
2022-11-03 23:08:23,761 - INFO  - Training [35][  100/  391]   Loss 0.156353   Top1 94.453125   Top5 99.945312   BatchTime 0.121252   LR 0.001000   
2022-11-03 23:08:25,785 - INFO  - Training [35][  120/  391]   Loss 0.158320   Top1 94.355469   Top5 99.941406   BatchTime 0.117910   LR 0.001000   
2022-11-03 23:08:27,817 - INFO  - Training [35][  140/  391]   Loss 0.156143   Top1 94.408482   Top5 99.949777   BatchTime 0.115580   LR 0.001000   
2022-11-03 23:08:29,832 - INFO  - Training [35][  160/  391]   Loss 0.156185   Top1 94.414062   Top5 99.956055   BatchTime 0.113727   LR 0.001000   
2022-11-03 23:08:31,843 - INFO  - Training [35][  180/  391]   Loss 0.158177   Top1 94.335938   Top5 99.952257   BatchTime 0.112258   LR 0.001000   
2022-11-03 23:08:33,871 - INFO  - Training [35][  200/  391]   Loss 0.158561   Top1 94.328125   Top5 99.945312   BatchTime 0.111174   LR 0.001000   
2022-11-03 23:08:35,870 - INFO  - Training [35][  220/  391]   Loss 0.157501   Top1 94.396307   Top5 99.943182   BatchTime 0.110153   LR 0.001000   
2022-11-03 23:08:37,890 - INFO  - Training [35][  240/  391]   Loss 0.158226   Top1 94.381510   Top5 99.944661   BatchTime 0.109392   LR 0.001000   
2022-11-03 23:08:39,906 - INFO  - Training [35][  260/  391]   Loss 0.158202   Top1 94.371995   Top5 99.939904   BatchTime 0.108729   LR 0.001000   
2022-11-03 23:08:41,922 - INFO  - Training [35][  280/  391]   Loss 0.159342   Top1 94.358259   Top5 99.941406   BatchTime 0.108162   LR 0.001000   
2022-11-03 23:08:43,937 - INFO  - Training [35][  300/  391]   Loss 0.160100   Top1 94.320312   Top5 99.934896   BatchTime 0.107668   LR 0.001000   
2022-11-03 23:08:45,948 - INFO  - Training [35][  320/  391]   Loss 0.162910   Top1 94.228516   Top5 99.931641   BatchTime 0.107222   LR 0.001000   
2022-11-03 23:08:47,930 - INFO  - Training [35][  340/  391]   Loss 0.162370   Top1 94.276195   Top5 99.928768   BatchTime 0.106745   LR 0.001000   
2022-11-03 23:08:49,885 - INFO  - Training [35][  360/  391]   Loss 0.162801   Top1 94.275174   Top5 99.930556   BatchTime 0.106244   LR 0.001000   
2022-11-03 23:08:51,836 - INFO  - Training [35][  380/  391]   Loss 0.162901   Top1 94.266036   Top5 99.928043   BatchTime 0.105787   LR 0.001000   
2022-11-03 23:08:53,153 - INFO  - ==> Top1: 94.256    Top5: 99.928    Loss: 0.163

2022-11-03 23:08:53,154 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:08:55,665 - INFO  - Validation [35][   20/   79]   Loss 0.407888   Top1 87.734375   Top5 99.453125   BatchTime 0.125485   
2022-11-03 23:08:56,377 - INFO  - Validation [35][   40/   79]   Loss 0.399000   Top1 88.164062   Top5 99.511719   BatchTime 0.080541   
2022-11-03 23:08:57,085 - INFO  - Validation [35][   60/   79]   Loss 0.394034   Top1 88.294271   Top5 99.492188   BatchTime 0.065496   
2022-11-03 23:08:58,017 - INFO  - ==> Top1: 88.230    Top5: 99.520    Loss: 0.396

2022-11-03 23:08:58,049 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:08:58,050 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:08:58,050 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:08:58,152 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:08:58,152 - INFO  - >>>>>>>> Epoch  36
2022-11-03 23:08:58,153 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:09:02,015 - INFO  - Training [36][   20/  391]   Loss 0.177044   Top1 93.437500   Top5 100.000000   BatchTime 0.193081   LR 0.001000   
2022-11-03 23:09:04,035 - INFO  - Training [36][   40/  391]   Loss 0.172284   Top1 93.652344   Top5 99.980469   BatchTime 0.147027   LR 0.001000   
2022-11-03 23:09:06,057 - INFO  - Training [36][   60/  391]   Loss 0.165905   Top1 93.841146   Top5 99.986979   BatchTime 0.131713   LR 0.001000   
2022-11-03 23:09:08,081 - INFO  - Training [36][   80/  391]   Loss 0.163566   Top1 94.013672   Top5 99.980469   BatchTime 0.124092   LR 0.001000   
2022-11-03 23:09:10,129 - INFO  - Training [36][  100/  391]   Loss 0.163185   Top1 94.031250   Top5 99.960938   BatchTime 0.119750   LR 0.001000   
2022-11-03 23:09:12,147 - INFO  - Training [36][  120/  391]   Loss 0.162440   Top1 94.042969   Top5 99.960938   BatchTime 0.116610   LR 0.001000   
2022-11-03 23:09:14,177 - INFO  - Training [36][  140/  391]   Loss 0.165389   Top1 93.922991   Top5 99.949777   BatchTime 0.114448   LR 0.001000   
2022-11-03 23:09:16,205 - INFO  - Training [36][  160/  391]   Loss 0.167952   Top1 93.872070   Top5 99.946289   BatchTime 0.112821   LR 0.001000   
2022-11-03 23:09:18,224 - INFO  - Training [36][  180/  391]   Loss 0.169545   Top1 93.849826   Top5 99.943576   BatchTime 0.111500   LR 0.001000   
2022-11-03 23:09:20,248 - INFO  - Training [36][  200/  391]   Loss 0.169875   Top1 93.824219   Top5 99.949219   BatchTime 0.110471   LR 0.001000   
2022-11-03 23:09:22,273 - INFO  - Training [36][  220/  391]   Loss 0.169490   Top1 93.821023   Top5 99.950284   BatchTime 0.109630   LR 0.001000   
2022-11-03 23:09:24,292 - INFO  - Training [36][  240/  391]   Loss 0.168773   Top1 93.821615   Top5 99.951172   BatchTime 0.108909   LR 0.001000   
2022-11-03 23:09:26,284 - INFO  - Training [36][  260/  391]   Loss 0.169743   Top1 93.795072   Top5 99.942909   BatchTime 0.108191   LR 0.001000   
2022-11-03 23:09:28,286 - INFO  - Training [36][  280/  391]   Loss 0.169833   Top1 93.803013   Top5 99.946987   BatchTime 0.107614   LR 0.001000   
2022-11-03 23:09:30,311 - INFO  - Training [36][  300/  391]   Loss 0.170047   Top1 93.776042   Top5 99.945312   BatchTime 0.107190   LR 0.001000   
2022-11-03 23:09:32,314 - INFO  - Training [36][  320/  391]   Loss 0.170277   Top1 93.793945   Top5 99.943848   BatchTime 0.106750   LR 0.001000   
2022-11-03 23:09:34,309 - INFO  - Training [36][  340/  391]   Loss 0.170247   Top1 93.821232   Top5 99.942555   BatchTime 0.106338   LR 0.001000   
2022-11-03 23:09:36,266 - INFO  - Training [36][  360/  391]   Loss 0.170766   Top1 93.802083   Top5 99.943576   BatchTime 0.105867   LR 0.001000   
2022-11-03 23:09:38,216 - INFO  - Training [36][  380/  391]   Loss 0.170719   Top1 93.830181   Top5 99.946546   BatchTime 0.105426   LR 0.001000   
2022-11-03 23:09:39,530 - INFO  - ==> Top1: 93.818    Top5: 99.946    Loss: 0.171

2022-11-03 23:09:39,531 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:09:42,048 - INFO  - Validation [36][   20/   79]   Loss 0.401592   Top1 88.046875   Top5 99.414062   BatchTime 0.125727   
2022-11-03 23:09:42,799 - INFO  - Validation [36][   40/   79]   Loss 0.399804   Top1 88.398438   Top5 99.433594   BatchTime 0.081644   
2022-11-03 23:09:43,502 - INFO  - Validation [36][   60/   79]   Loss 0.391107   Top1 88.606771   Top5 99.531250   BatchTime 0.066155   
2022-11-03 23:09:44,398 - INFO  - ==> Top1: 88.530    Top5: 99.590    Loss: 0.392

2022-11-03 23:09:44,429 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:09:44,430 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:09:44,430 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:09:44,530 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:09:44,531 - INFO  - >>>>>>>> Epoch  37
2022-11-03 23:09:44,532 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:09:48,467 - INFO  - Training [37][   20/  391]   Loss 0.169771   Top1 94.062500   Top5 99.960938   BatchTime 0.196718   LR 0.001000   
2022-11-03 23:09:50,434 - INFO  - Training [37][   40/  391]   Loss 0.163282   Top1 94.121094   Top5 99.960938   BatchTime 0.147549   LR 0.001000   
2022-11-03 23:09:52,464 - INFO  - Training [37][   60/  391]   Loss 0.163925   Top1 94.218750   Top5 99.973958   BatchTime 0.132200   LR 0.001000   
2022-11-03 23:09:54,492 - INFO  - Training [37][   80/  391]   Loss 0.163572   Top1 94.238281   Top5 99.960938   BatchTime 0.124493   LR 0.001000   
2022-11-03 23:09:56,593 - INFO  - Training [37][  100/  391]   Loss 0.164554   Top1 94.187500   Top5 99.968750   BatchTime 0.120605   LR 0.001000   
2022-11-03 23:09:58,605 - INFO  - Training [37][  120/  391]   Loss 0.164224   Top1 94.205729   Top5 99.967448   BatchTime 0.117270   LR 0.001000   
2022-11-03 23:10:00,622 - INFO  - Training [37][  140/  391]   Loss 0.164138   Top1 94.213170   Top5 99.960938   BatchTime 0.114922   LR 0.001000   
2022-11-03 23:10:02,654 - INFO  - Training [37][  160/  391]   Loss 0.166217   Top1 94.169922   Top5 99.960938   BatchTime 0.113258   LR 0.001000   
2022-11-03 23:10:04,693 - INFO  - Training [37][  180/  391]   Loss 0.165673   Top1 94.171007   Top5 99.965278   BatchTime 0.112000   LR 0.001000   
2022-11-03 23:10:06,725 - INFO  - Training [37][  200/  391]   Loss 0.166150   Top1 94.144531   Top5 99.964844   BatchTime 0.110962   LR 0.001000   
2022-11-03 23:10:08,746 - INFO  - Training [37][  220/  391]   Loss 0.166694   Top1 94.119318   Top5 99.960938   BatchTime 0.110060   LR 0.001000   
2022-11-03 23:10:10,770 - INFO  - Training [37][  240/  391]   Loss 0.168878   Top1 94.042969   Top5 99.960938   BatchTime 0.109323   LR 0.001000   
2022-11-03 23:10:12,782 - INFO  - Training [37][  260/  391]   Loss 0.169976   Top1 93.993389   Top5 99.963942   BatchTime 0.108651   LR 0.001000   
2022-11-03 23:10:14,798 - INFO  - Training [37][  280/  391]   Loss 0.171073   Top1 93.964844   Top5 99.960938   BatchTime 0.108088   LR 0.001000   
2022-11-03 23:10:16,819 - INFO  - Training [37][  300/  391]   Loss 0.172447   Top1 93.921875   Top5 99.958333   BatchTime 0.107621   LR 0.001000   
2022-11-03 23:10:18,838 - INFO  - Training [37][  320/  391]   Loss 0.172787   Top1 93.894043   Top5 99.956055   BatchTime 0.107203   LR 0.001000   
2022-11-03 23:10:20,842 - INFO  - Training [37][  340/  391]   Loss 0.173527   Top1 93.848805   Top5 99.956342   BatchTime 0.106792   LR 0.001000   
2022-11-03 23:10:22,794 - INFO  - Training [37][  360/  391]   Loss 0.173683   Top1 93.841146   Top5 99.950087   BatchTime 0.106282   LR 0.001000   
2022-11-03 23:10:24,762 - INFO  - Training [37][  380/  391]   Loss 0.173711   Top1 93.830181   Top5 99.948602   BatchTime 0.105865   LR 0.001000   
2022-11-03 23:10:26,071 - INFO  - ==> Top1: 93.792    Top5: 99.946    Loss: 0.175

2022-11-03 23:10:26,072 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:10:28,550 - INFO  - Validation [37][   20/   79]   Loss 0.404111   Top1 88.242188   Top5 99.453125   BatchTime 0.123858   
2022-11-03 23:10:29,275 - INFO  - Validation [37][   40/   79]   Loss 0.396450   Top1 88.378906   Top5 99.335938   BatchTime 0.080042   
2022-11-03 23:10:29,972 - INFO  - Validation [37][   60/   79]   Loss 0.388677   Top1 88.489583   Top5 99.401042   BatchTime 0.064980   
2022-11-03 23:10:30,902 - INFO  - ==> Top1: 88.470    Top5: 99.510    Loss: 0.386

2022-11-03 23:10:30,934 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:10:30,935 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:10:30,935 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:10:31,027 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:10:31,027 - INFO  - >>>>>>>> Epoch  38
2022-11-03 23:10:31,029 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:10:34,862 - INFO  - Training [38][   20/  391]   Loss 0.165445   Top1 94.062500   Top5 99.921875   BatchTime 0.191644   LR 0.001000   
2022-11-03 23:10:36,881 - INFO  - Training [38][   40/  391]   Loss 0.162381   Top1 94.160156   Top5 99.941406   BatchTime 0.146296   LR 0.001000   
2022-11-03 23:10:38,907 - INFO  - Training [38][   60/  391]   Loss 0.162401   Top1 94.231771   Top5 99.947917   BatchTime 0.131298   LR 0.001000   
2022-11-03 23:10:40,946 - INFO  - Training [38][   80/  391]   Loss 0.165830   Top1 94.169922   Top5 99.941406   BatchTime 0.123959   LR 0.001000   
2022-11-03 23:10:42,979 - INFO  - Training [38][  100/  391]   Loss 0.168366   Top1 94.039062   Top5 99.953125   BatchTime 0.119499   LR 0.001000   
2022-11-03 23:10:44,994 - INFO  - Training [38][  120/  391]   Loss 0.170806   Top1 93.919271   Top5 99.954427   BatchTime 0.116373   LR 0.001000   
2022-11-03 23:10:47,007 - INFO  - Training [38][  140/  391]   Loss 0.173637   Top1 93.772321   Top5 99.949777   BatchTime 0.114129   LR 0.001000   
2022-11-03 23:10:49,013 - INFO  - Training [38][  160/  391]   Loss 0.172368   Top1 93.867188   Top5 99.951172   BatchTime 0.112401   LR 0.001000   
2022-11-03 23:10:51,029 - INFO  - Training [38][  180/  391]   Loss 0.173081   Top1 93.854167   Top5 99.952257   BatchTime 0.111112   LR 0.001000   
2022-11-03 23:10:53,030 - INFO  - Training [38][  200/  391]   Loss 0.173180   Top1 93.808594   Top5 99.957031   BatchTime 0.110006   LR 0.001000   
2022-11-03 23:10:55,067 - INFO  - Training [38][  220/  391]   Loss 0.173880   Top1 93.799716   Top5 99.953835   BatchTime 0.109264   LR 0.001000   
2022-11-03 23:10:57,069 - INFO  - Training [38][  240/  391]   Loss 0.173555   Top1 93.818359   Top5 99.951172   BatchTime 0.108500   LR 0.001000   
2022-11-03 23:10:59,090 - INFO  - Training [38][  260/  391]   Loss 0.174255   Top1 93.840144   Top5 99.939904   BatchTime 0.107927   LR 0.001000   
2022-11-03 23:11:01,112 - INFO  - Training [38][  280/  391]   Loss 0.174001   Top1 93.833705   Top5 99.935826   BatchTime 0.107437   LR 0.001000   
2022-11-03 23:11:03,108 - INFO  - Training [38][  300/  391]   Loss 0.174312   Top1 93.820312   Top5 99.934896   BatchTime 0.106929   LR 0.001000   
2022-11-03 23:11:05,117 - INFO  - Training [38][  320/  391]   Loss 0.173205   Top1 93.869629   Top5 99.929199   BatchTime 0.106525   LR 0.001000   
2022-11-03 23:11:07,120 - INFO  - Training [38][  340/  391]   Loss 0.172923   Top1 93.883272   Top5 99.933364   BatchTime 0.106147   LR 0.001000   
2022-11-03 23:11:09,080 - INFO  - Training [38][  360/  391]   Loss 0.171993   Top1 93.914931   Top5 99.937066   BatchTime 0.105695   LR 0.001000   
2022-11-03 23:11:11,034 - INFO  - Training [38][  380/  391]   Loss 0.172242   Top1 93.916530   Top5 99.938322   BatchTime 0.105276   LR 0.001000   
2022-11-03 23:11:12,356 - INFO  - ==> Top1: 93.918    Top5: 99.938    Loss: 0.172

2022-11-03 23:11:12,357 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:11:14,803 - INFO  - Validation [38][   20/   79]   Loss 0.396134   Top1 88.320312   Top5 99.335938   BatchTime 0.122246   
2022-11-03 23:11:15,512 - INFO  - Validation [38][   40/   79]   Loss 0.385579   Top1 88.417969   Top5 99.355469   BatchTime 0.078851   
2022-11-03 23:11:16,218 - INFO  - Validation [38][   60/   79]   Loss 0.377126   Top1 88.710938   Top5 99.466146   BatchTime 0.064328   
2022-11-03 23:11:17,128 - INFO  - ==> Top1: 88.820    Top5: 99.560    Loss: 0.374

2022-11-03 23:11:17,163 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:11:17,164 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:11:17,164 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:11:17,264 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:11:17,264 - INFO  - >>>>>>>> Epoch  39
2022-11-03 23:11:17,265 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:11:21,072 - INFO  - Training [39][   20/  391]   Loss 0.179136   Top1 93.554688   Top5 99.804688   BatchTime 0.190334   LR 0.001000   
2022-11-03 23:11:23,104 - INFO  - Training [39][   40/  391]   Loss 0.172288   Top1 93.789062   Top5 99.902344   BatchTime 0.145956   LR 0.001000   
2022-11-03 23:11:25,058 - INFO  - Training [39][   60/  391]   Loss 0.173886   Top1 93.763021   Top5 99.908854   BatchTime 0.129873   LR 0.001000   
2022-11-03 23:11:27,075 - INFO  - Training [39][   80/  391]   Loss 0.178101   Top1 93.671875   Top5 99.902344   BatchTime 0.122612   LR 0.001000   
2022-11-03 23:11:29,089 - INFO  - Training [39][  100/  391]   Loss 0.178504   Top1 93.703125   Top5 99.914062   BatchTime 0.118232   LR 0.001000   
2022-11-03 23:11:31,099 - INFO  - Training [39][  120/  391]   Loss 0.176949   Top1 93.847656   Top5 99.921875   BatchTime 0.115276   LR 0.001000   
2022-11-03 23:11:33,113 - INFO  - Training [39][  140/  391]   Loss 0.177494   Top1 93.906250   Top5 99.916295   BatchTime 0.113193   LR 0.001000   
2022-11-03 23:11:35,227 - INFO  - Training [39][  160/  391]   Loss 0.175313   Top1 93.901367   Top5 99.916992   BatchTime 0.112260   LR 0.001000   
2022-11-03 23:11:37,260 - INFO  - Training [39][  180/  391]   Loss 0.173203   Top1 93.936632   Top5 99.926215   BatchTime 0.111080   LR 0.001000   
2022-11-03 23:11:39,279 - INFO  - Training [39][  200/  391]   Loss 0.171099   Top1 93.988281   Top5 99.925781   BatchTime 0.110066   LR 0.001000   
2022-11-03 23:11:41,288 - INFO  - Training [39][  220/  391]   Loss 0.171265   Top1 94.005682   Top5 99.932528   BatchTime 0.109190   LR 0.001000   
2022-11-03 23:11:43,311 - INFO  - Training [39][  240/  391]   Loss 0.171005   Top1 93.981120   Top5 99.931641   BatchTime 0.108520   LR 0.001000   
2022-11-03 23:11:45,316 - INFO  - Training [39][  260/  391]   Loss 0.173338   Top1 93.888221   Top5 99.930889   BatchTime 0.107886   LR 0.001000   
2022-11-03 23:11:47,325 - INFO  - Training [39][  280/  391]   Loss 0.173253   Top1 93.883929   Top5 99.930246   BatchTime 0.107355   LR 0.001000   
2022-11-03 23:11:49,332 - INFO  - Training [39][  300/  391]   Loss 0.173792   Top1 93.877604   Top5 99.932292   BatchTime 0.106888   LR 0.001000   
2022-11-03 23:11:51,349 - INFO  - Training [39][  320/  391]   Loss 0.173374   Top1 93.886719   Top5 99.934082   BatchTime 0.106510   LR 0.001000   
2022-11-03 23:11:53,344 - INFO  - Training [39][  340/  391]   Loss 0.173074   Top1 93.883272   Top5 99.935662   BatchTime 0.106111   LR 0.001000   
2022-11-03 23:11:55,307 - INFO  - Training [39][  360/  391]   Loss 0.173835   Top1 93.838976   Top5 99.937066   BatchTime 0.105670   LR 0.001000   
2022-11-03 23:11:57,268 - INFO  - Training [39][  380/  391]   Loss 0.174443   Top1 93.817845   Top5 99.934211   BatchTime 0.105268   LR 0.001000   
2022-11-03 23:11:58,582 - INFO  - ==> Top1: 93.798    Top5: 99.930    Loss: 0.175

2022-11-03 23:11:58,583 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:12:01,034 - INFO  - Validation [39][   20/   79]   Loss 0.393221   Top1 88.437500   Top5 99.335938   BatchTime 0.122464   
2022-11-03 23:12:01,711 - INFO  - Validation [39][   40/   79]   Loss 0.383545   Top1 88.808594   Top5 99.335938   BatchTime 0.078174   
2022-11-03 23:12:02,411 - INFO  - Validation [39][   60/   79]   Loss 0.373439   Top1 88.932292   Top5 99.440104   BatchTime 0.063781   
2022-11-03 23:12:03,326 - INFO  - ==> Top1: 88.990    Top5: 99.530    Loss: 0.371

2022-11-03 23:12:03,359 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:12:03,360 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:12:03,360 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:12:03,459 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:12:03,459 - INFO  - >>>>>>>> Epoch  40
2022-11-03 23:12:03,460 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:12:07,298 - INFO  - Training [40][   20/  391]   Loss 0.171101   Top1 93.789062   Top5 99.960938   BatchTime 0.191868   LR 0.000100   
2022-11-03 23:12:09,313 - INFO  - Training [40][   40/  391]   Loss 0.174701   Top1 93.750000   Top5 99.941406   BatchTime 0.146325   LR 0.000100   
2022-11-03 23:12:11,334 - INFO  - Training [40][   60/  391]   Loss 0.169737   Top1 94.114583   Top5 99.947917   BatchTime 0.131225   LR 0.000100   
2022-11-03 23:12:13,331 - INFO  - Training [40][   80/  391]   Loss 0.171764   Top1 94.042969   Top5 99.921875   BatchTime 0.123385   LR 0.000100   
2022-11-03 23:12:15,318 - INFO  - Training [40][  100/  391]   Loss 0.172498   Top1 93.992188   Top5 99.890625   BatchTime 0.118576   LR 0.000100   
2022-11-03 23:12:17,342 - INFO  - Training [40][  120/  391]   Loss 0.172716   Top1 94.036458   Top5 99.889323   BatchTime 0.115682   LR 0.000100   
2022-11-03 23:12:19,367 - INFO  - Training [40][  140/  391]   Loss 0.169161   Top1 94.090402   Top5 99.905134   BatchTime 0.113616   LR 0.000100   
2022-11-03 23:12:21,369 - INFO  - Training [40][  160/  391]   Loss 0.170438   Top1 94.013672   Top5 99.916992   BatchTime 0.111928   LR 0.000100   
2022-11-03 23:12:23,388 - INFO  - Training [40][  180/  391]   Loss 0.170304   Top1 94.032118   Top5 99.917535   BatchTime 0.110708   LR 0.000100   
2022-11-03 23:12:25,394 - INFO  - Training [40][  200/  391]   Loss 0.172149   Top1 93.957031   Top5 99.910156   BatchTime 0.109666   LR 0.000100   
2022-11-03 23:12:27,417 - INFO  - Training [40][  220/  391]   Loss 0.171872   Top1 93.980824   Top5 99.907670   BatchTime 0.108893   LR 0.000100   
2022-11-03 23:12:29,436 - INFO  - Training [40][  240/  391]   Loss 0.172998   Top1 93.922526   Top5 99.908854   BatchTime 0.108229   LR 0.000100   
2022-11-03 23:12:31,434 - INFO  - Training [40][  260/  391]   Loss 0.173511   Top1 93.912260   Top5 99.906851   BatchTime 0.107589   LR 0.000100   
2022-11-03 23:12:33,436 - INFO  - Training [40][  280/  391]   Loss 0.174111   Top1 93.867188   Top5 99.913504   BatchTime 0.107054   LR 0.000100   
2022-11-03 23:12:35,453 - INFO  - Training [40][  300/  391]   Loss 0.173791   Top1 93.877604   Top5 99.914062   BatchTime 0.106639   LR 0.000100   
2022-11-03 23:12:37,453 - INFO  - Training [40][  320/  391]   Loss 0.173030   Top1 93.916016   Top5 99.916992   BatchTime 0.106225   LR 0.000100   
2022-11-03 23:12:39,437 - INFO  - Training [40][  340/  391]   Loss 0.172931   Top1 93.892463   Top5 99.917279   BatchTime 0.105811   LR 0.000100   
2022-11-03 23:12:41,381 - INFO  - Training [40][  360/  391]   Loss 0.172917   Top1 93.880208   Top5 99.921875   BatchTime 0.105334   LR 0.000100   
2022-11-03 23:12:43,350 - INFO  - Training [40][  380/  391]   Loss 0.173292   Top1 93.856908   Top5 99.921875   BatchTime 0.104971   LR 0.000100   
2022-11-03 23:12:44,651 - INFO  - ==> Top1: 93.864    Top5: 99.922    Loss: 0.173

2022-11-03 23:12:44,652 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:12:47,121 - INFO  - Validation [40][   20/   79]   Loss 0.396303   Top1 88.125000   Top5 99.453125   BatchTime 0.123406   
2022-11-03 23:12:47,759 - INFO  - Validation [40][   40/   79]   Loss 0.384465   Top1 88.437500   Top5 99.414062   BatchTime 0.077650   
2022-11-03 23:12:48,455 - INFO  - Validation [40][   60/   79]   Loss 0.375121   Top1 88.632812   Top5 99.505208   BatchTime 0.063371   
2022-11-03 23:12:49,356 - INFO  - ==> Top1: 88.650    Top5: 99.600    Loss: 0.372

2022-11-03 23:12:49,387 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:12:49,388 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:12:49,388 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:12:49,490 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:12:49,490 - INFO  - >>>>>>>> Epoch  41
2022-11-03 23:12:49,491 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:12:53,245 - INFO  - Training [41][   20/  391]   Loss 0.176803   Top1 93.750000   Top5 100.000000   BatchTime 0.187697   LR 0.000100   
2022-11-03 23:12:55,278 - INFO  - Training [41][   40/  391]   Loss 0.177479   Top1 93.808594   Top5 100.000000   BatchTime 0.144660   LR 0.000100   
2022-11-03 23:12:57,307 - INFO  - Training [41][   60/  391]   Loss 0.179662   Top1 93.854167   Top5 99.934896   BatchTime 0.130256   LR 0.000100   
2022-11-03 23:12:59,311 - INFO  - Training [41][   80/  391]   Loss 0.173668   Top1 93.925781   Top5 99.921875   BatchTime 0.122741   LR 0.000100   
2022-11-03 23:13:01,332 - INFO  - Training [41][  100/  391]   Loss 0.175283   Top1 93.867188   Top5 99.921875   BatchTime 0.118403   LR 0.000100   
2022-11-03 23:13:03,360 - INFO  - Training [41][  120/  391]   Loss 0.173410   Top1 93.938802   Top5 99.928385   BatchTime 0.115567   LR 0.000100   
2022-11-03 23:13:05,369 - INFO  - Training [41][  140/  391]   Loss 0.172589   Top1 93.917411   Top5 99.933036   BatchTime 0.113409   LR 0.000100   
2022-11-03 23:13:07,380 - INFO  - Training [41][  160/  391]   Loss 0.170590   Top1 93.974609   Top5 99.936523   BatchTime 0.111802   LR 0.000100   
2022-11-03 23:13:09,386 - INFO  - Training [41][  180/  391]   Loss 0.171340   Top1 93.949653   Top5 99.939236   BatchTime 0.110523   LR 0.000100   
2022-11-03 23:13:11,417 - INFO  - Training [41][  200/  391]   Loss 0.171697   Top1 93.964844   Top5 99.929688   BatchTime 0.109628   LR 0.000100   
2022-11-03 23:13:13,511 - INFO  - Training [41][  220/  391]   Loss 0.171613   Top1 93.952415   Top5 99.914773   BatchTime 0.109176   LR 0.000100   
2022-11-03 23:13:15,520 - INFO  - Training [41][  240/  391]   Loss 0.170559   Top1 93.987630   Top5 99.918620   BatchTime 0.108451   LR 0.000100   
2022-11-03 23:13:17,526 - INFO  - Training [41][  260/  391]   Loss 0.170518   Top1 93.960337   Top5 99.915865   BatchTime 0.107822   LR 0.000100   
2022-11-03 23:13:19,543 - INFO  - Training [41][  280/  391]   Loss 0.170033   Top1 94.009487   Top5 99.916295   BatchTime 0.107326   LR 0.000100   
2022-11-03 23:13:21,564 - INFO  - Training [41][  300/  391]   Loss 0.169655   Top1 94.007812   Top5 99.919271   BatchTime 0.106905   LR 0.000100   
2022-11-03 23:13:23,588 - INFO  - Training [41][  320/  391]   Loss 0.169286   Top1 94.040527   Top5 99.919434   BatchTime 0.106550   LR 0.000100   
2022-11-03 23:13:25,573 - INFO  - Training [41][  340/  391]   Loss 0.168732   Top1 94.064798   Top5 99.921875   BatchTime 0.106118   LR 0.000100   
2022-11-03 23:13:27,523 - INFO  - Training [41][  360/  391]   Loss 0.169474   Top1 94.051649   Top5 99.924045   BatchTime 0.105642   LR 0.000100   
2022-11-03 23:13:29,483 - INFO  - Training [41][  380/  391]   Loss 0.170192   Top1 94.021382   Top5 99.925987   BatchTime 0.105238   LR 0.000100   
2022-11-03 23:13:30,803 - INFO  - ==> Top1: 93.994    Top5: 99.926    Loss: 0.170

2022-11-03 23:13:30,804 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:13:33,264 - INFO  - Validation [41][   20/   79]   Loss 0.399550   Top1 88.398438   Top5 99.492188   BatchTime 0.122918   
2022-11-03 23:13:33,908 - INFO  - Validation [41][   40/   79]   Loss 0.389511   Top1 88.691406   Top5 99.433594   BatchTime 0.077553   
2022-11-03 23:13:34,610 - INFO  - Validation [41][   60/   79]   Loss 0.377265   Top1 88.997396   Top5 99.518229   BatchTime 0.063406   
2022-11-03 23:13:35,533 - INFO  - ==> Top1: 89.060    Top5: 99.620    Loss: 0.373

2022-11-03 23:13:35,563 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:13:35,564 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:13:35,564 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:13:35,659 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:13:35,667 - INFO  - >>>>>>>> Epoch  42
2022-11-03 23:13:35,669 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:13:39,337 - INFO  - Training [42][   20/  391]   Loss 0.180374   Top1 93.710938   Top5 99.960938   BatchTime 0.183399   LR 0.000100   
2022-11-03 23:13:41,353 - INFO  - Training [42][   40/  391]   Loss 0.167474   Top1 94.238281   Top5 99.941406   BatchTime 0.142105   LR 0.000100   
2022-11-03 23:13:43,385 - INFO  - Training [42][   60/  391]   Loss 0.166358   Top1 94.348958   Top5 99.921875   BatchTime 0.128594   LR 0.000100   
2022-11-03 23:13:45,392 - INFO  - Training [42][   80/  391]   Loss 0.168696   Top1 94.355469   Top5 99.892578   BatchTime 0.121536   LR 0.000100   
2022-11-03 23:13:47,415 - INFO  - Training [42][  100/  391]   Loss 0.169072   Top1 94.250000   Top5 99.906250   BatchTime 0.117457   LR 0.000100   
2022-11-03 23:13:49,426 - INFO  - Training [42][  120/  391]   Loss 0.168512   Top1 94.199219   Top5 99.921875   BatchTime 0.114638   LR 0.000100   
2022-11-03 23:13:51,459 - INFO  - Training [42][  140/  391]   Loss 0.166033   Top1 94.274554   Top5 99.927455   BatchTime 0.112780   LR 0.000100   
2022-11-03 23:13:53,466 - INFO  - Training [42][  160/  391]   Loss 0.163929   Top1 94.360352   Top5 99.931641   BatchTime 0.111228   LR 0.000100   
2022-11-03 23:13:55,484 - INFO  - Training [42][  180/  391]   Loss 0.169677   Top1 94.175347   Top5 99.926215   BatchTime 0.110078   LR 0.000100   
2022-11-03 23:13:57,520 - INFO  - Training [42][  200/  391]   Loss 0.167853   Top1 94.257812   Top5 99.929688   BatchTime 0.109254   LR 0.000100   
2022-11-03 23:13:59,529 - INFO  - Training [42][  220/  391]   Loss 0.167915   Top1 94.254261   Top5 99.936080   BatchTime 0.108451   LR 0.000100   
2022-11-03 23:14:01,529 - INFO  - Training [42][  240/  391]   Loss 0.166856   Top1 94.254557   Top5 99.931641   BatchTime 0.107749   LR 0.000100   
2022-11-03 23:14:03,541 - INFO  - Training [42][  260/  391]   Loss 0.165419   Top1 94.311899   Top5 99.936899   BatchTime 0.107198   LR 0.000100   
2022-11-03 23:14:05,558 - INFO  - Training [42][  280/  391]   Loss 0.165513   Top1 94.316406   Top5 99.938616   BatchTime 0.106745   LR 0.000100   
2022-11-03 23:14:07,571 - INFO  - Training [42][  300/  391]   Loss 0.167258   Top1 94.234375   Top5 99.940104   BatchTime 0.106337   LR 0.000100   
2022-11-03 23:14:09,578 - INFO  - Training [42][  320/  391]   Loss 0.167016   Top1 94.233398   Top5 99.934082   BatchTime 0.105963   LR 0.000100   
2022-11-03 23:14:11,572 - INFO  - Training [42][  340/  391]   Loss 0.166320   Top1 94.246324   Top5 99.935662   BatchTime 0.105595   LR 0.000100   
2022-11-03 23:14:13,549 - INFO  - Training [42][  360/  391]   Loss 0.167014   Top1 94.242622   Top5 99.934896   BatchTime 0.105219   LR 0.000100   
2022-11-03 23:14:15,504 - INFO  - Training [42][  380/  391]   Loss 0.166954   Top1 94.212582   Top5 99.934211   BatchTime 0.104828   LR 0.000100   
2022-11-03 23:14:16,820 - INFO  - ==> Top1: 94.226    Top5: 99.934    Loss: 0.167

2022-11-03 23:14:16,821 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:14:19,307 - INFO  - Validation [42][   20/   79]   Loss 0.399893   Top1 88.554688   Top5 99.492188   BatchTime 0.124232   
2022-11-03 23:14:19,936 - INFO  - Validation [42][   40/   79]   Loss 0.384755   Top1 88.750000   Top5 99.414062   BatchTime 0.077842   
2022-11-03 23:14:20,648 - INFO  - Validation [42][   60/   79]   Loss 0.372306   Top1 88.997396   Top5 99.505208   BatchTime 0.063757   
2022-11-03 23:14:21,555 - INFO  - ==> Top1: 89.020    Top5: 99.590    Loss: 0.370

2022-11-03 23:14:21,586 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:14:21,587 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:14:21,587 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:14:21,700 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:14:21,701 - INFO  - >>>>>>>> Epoch  43
2022-11-03 23:14:21,702 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:14:25,435 - INFO  - Training [43][   20/  391]   Loss 0.167647   Top1 93.671875   Top5 99.960938   BatchTime 0.186635   LR 0.000100   
2022-11-03 23:14:27,463 - INFO  - Training [43][   40/  391]   Loss 0.166383   Top1 93.886719   Top5 99.941406   BatchTime 0.144011   LR 0.000100   
2022-11-03 23:14:29,465 - INFO  - Training [43][   60/  391]   Loss 0.165813   Top1 93.854167   Top5 99.947917   BatchTime 0.129379   LR 0.000100   
2022-11-03 23:14:31,470 - INFO  - Training [43][   80/  391]   Loss 0.165393   Top1 93.984375   Top5 99.921875   BatchTime 0.122098   LR 0.000100   
2022-11-03 23:14:33,484 - INFO  - Training [43][  100/  391]   Loss 0.161805   Top1 94.187500   Top5 99.921875   BatchTime 0.117821   LR 0.000100   
2022-11-03 23:14:35,490 - INFO  - Training [43][  120/  391]   Loss 0.161078   Top1 94.244792   Top5 99.934896   BatchTime 0.114897   LR 0.000100   
2022-11-03 23:14:37,518 - INFO  - Training [43][  140/  391]   Loss 0.161328   Top1 94.252232   Top5 99.938616   BatchTime 0.112972   LR 0.000100   
2022-11-03 23:14:39,527 - INFO  - Training [43][  160/  391]   Loss 0.161808   Top1 94.218750   Top5 99.926758   BatchTime 0.111404   LR 0.000100   
2022-11-03 23:14:41,536 - INFO  - Training [43][  180/  391]   Loss 0.160229   Top1 94.283854   Top5 99.934896   BatchTime 0.110189   LR 0.000100   
2022-11-03 23:14:43,535 - INFO  - Training [43][  200/  391]   Loss 0.161423   Top1 94.261719   Top5 99.933594   BatchTime 0.109162   LR 0.000100   
2022-11-03 23:14:45,529 - INFO  - Training [43][  220/  391]   Loss 0.161663   Top1 94.186790   Top5 99.936080   BatchTime 0.108302   LR 0.000100   
2022-11-03 23:14:47,559 - INFO  - Training [43][  240/  391]   Loss 0.162085   Top1 94.166667   Top5 99.941406   BatchTime 0.107734   LR 0.000100   
2022-11-03 23:14:49,605 - INFO  - Training [43][  260/  391]   Loss 0.161987   Top1 94.182692   Top5 99.936899   BatchTime 0.107318   LR 0.000100   
2022-11-03 23:14:51,733 - INFO  - Training [43][  280/  391]   Loss 0.162936   Top1 94.118304   Top5 99.938616   BatchTime 0.107250   LR 0.000100   
2022-11-03 23:14:53,742 - INFO  - Training [43][  300/  391]   Loss 0.162704   Top1 94.130208   Top5 99.937500   BatchTime 0.106797   LR 0.000100   
2022-11-03 23:14:55,754 - INFO  - Training [43][  320/  391]   Loss 0.163163   Top1 94.125977   Top5 99.938965   BatchTime 0.106409   LR 0.000100   
2022-11-03 23:14:57,761 - INFO  - Training [43][  340/  391]   Loss 0.163330   Top1 94.094669   Top5 99.942555   BatchTime 0.106053   LR 0.000100   
2022-11-03 23:14:59,713 - INFO  - Training [43][  360/  391]   Loss 0.163509   Top1 94.077691   Top5 99.941406   BatchTime 0.105583   LR 0.000100   
2022-11-03 23:15:01,674 - INFO  - Training [43][  380/  391]   Loss 0.163952   Top1 94.099507   Top5 99.940378   BatchTime 0.105186   LR 0.000100   
2022-11-03 23:15:03,001 - INFO  - ==> Top1: 94.086    Top5: 99.942    Loss: 0.164

2022-11-03 23:15:03,002 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:15:05,517 - INFO  - Validation [43][   20/   79]   Loss 0.388609   Top1 88.437500   Top5 99.414062   BatchTime 0.125707   
2022-11-03 23:15:06,105 - INFO  - Validation [43][   40/   79]   Loss 0.383854   Top1 88.730469   Top5 99.414062   BatchTime 0.077534   
2022-11-03 23:15:06,817 - INFO  - Validation [43][   60/   79]   Loss 0.375060   Top1 88.932292   Top5 99.505208   BatchTime 0.063567   
2022-11-03 23:15:07,742 - INFO  - ==> Top1: 88.990    Top5: 99.590    Loss: 0.372

2022-11-03 23:15:07,777 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:15:07,778 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:15:07,778 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:15:07,881 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:15:07,882 - INFO  - >>>>>>>> Epoch  44
2022-11-03 23:15:07,883 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:15:11,698 - INFO  - Training [44][   20/  391]   Loss 0.187350   Top1 93.945312   Top5 99.921875   BatchTime 0.190748   LR 0.000100   
2022-11-03 23:15:13,732 - INFO  - Training [44][   40/  391]   Loss 0.181325   Top1 93.906250   Top5 99.921875   BatchTime 0.146213   LR 0.000100   
2022-11-03 23:15:15,758 - INFO  - Training [44][   60/  391]   Loss 0.179262   Top1 93.750000   Top5 99.934896   BatchTime 0.131246   LR 0.000100   
2022-11-03 23:15:17,756 - INFO  - Training [44][   80/  391]   Loss 0.178887   Top1 93.750000   Top5 99.941406   BatchTime 0.123413   LR 0.000100   
2022-11-03 23:15:19,782 - INFO  - Training [44][  100/  391]   Loss 0.175796   Top1 93.890625   Top5 99.953125   BatchTime 0.118983   LR 0.000100   
2022-11-03 23:15:21,804 - INFO  - Training [44][  120/  391]   Loss 0.175367   Top1 93.815104   Top5 99.941406   BatchTime 0.116007   LR 0.000100   
2022-11-03 23:15:23,820 - INFO  - Training [44][  140/  391]   Loss 0.171299   Top1 93.928571   Top5 99.949777   BatchTime 0.113829   LR 0.000100   
2022-11-03 23:15:25,821 - INFO  - Training [44][  160/  391]   Loss 0.171058   Top1 93.940430   Top5 99.951172   BatchTime 0.112109   LR 0.000100   
2022-11-03 23:15:27,847 - INFO  - Training [44][  180/  391]   Loss 0.172092   Top1 93.875868   Top5 99.934896   BatchTime 0.110907   LR 0.000100   
2022-11-03 23:15:29,867 - INFO  - Training [44][  200/  391]   Loss 0.172451   Top1 93.835938   Top5 99.937500   BatchTime 0.109917   LR 0.000100   
2022-11-03 23:15:31,881 - INFO  - Training [44][  220/  391]   Loss 0.170873   Top1 93.920455   Top5 99.936080   BatchTime 0.109078   LR 0.000100   
2022-11-03 23:15:33,904 - INFO  - Training [44][  240/  391]   Loss 0.169990   Top1 93.922526   Top5 99.941406   BatchTime 0.108419   LR 0.000100   
2022-11-03 23:15:35,911 - INFO  - Training [44][  260/  391]   Loss 0.169013   Top1 93.978365   Top5 99.942909   BatchTime 0.107798   LR 0.000100   
2022-11-03 23:15:37,936 - INFO  - Training [44][  280/  391]   Loss 0.169332   Top1 93.948103   Top5 99.946987   BatchTime 0.107330   LR 0.000100   
2022-11-03 23:15:39,940 - INFO  - Training [44][  300/  391]   Loss 0.168538   Top1 93.986979   Top5 99.947917   BatchTime 0.106856   LR 0.000100   
2022-11-03 23:15:41,943 - INFO  - Training [44][  320/  391]   Loss 0.168769   Top1 93.977051   Top5 99.948730   BatchTime 0.106436   LR 0.000100   
2022-11-03 23:15:43,948 - INFO  - Training [44][  340/  391]   Loss 0.168934   Top1 93.991268   Top5 99.951746   BatchTime 0.106070   LR 0.000100   
2022-11-03 23:15:45,898 - INFO  - Training [44][  360/  391]   Loss 0.168467   Top1 93.980035   Top5 99.952257   BatchTime 0.105596   LR 0.000100   
2022-11-03 23:15:47,853 - INFO  - Training [44][  380/  391]   Loss 0.168828   Top1 93.969984   Top5 99.952714   BatchTime 0.105182   LR 0.000100   
2022-11-03 23:15:49,165 - INFO  - ==> Top1: 93.980    Top5: 99.952    Loss: 0.169

2022-11-03 23:15:49,166 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:15:51,606 - INFO  - Validation [44][   20/   79]   Loss 0.392934   Top1 88.515625   Top5 99.609375   BatchTime 0.121967   
2022-11-03 23:15:52,241 - INFO  - Validation [44][   40/   79]   Loss 0.383372   Top1 88.750000   Top5 99.472656   BatchTime 0.076857   
2022-11-03 23:15:52,933 - INFO  - Validation [44][   60/   79]   Loss 0.372676   Top1 88.997396   Top5 99.531250   BatchTime 0.062772   
2022-11-03 23:15:53,847 - INFO  - ==> Top1: 89.040    Top5: 99.610    Loss: 0.371

2022-11-03 23:15:53,877 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:15:53,878 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:15:53,878 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:15:53,976 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:15:53,977 - INFO  - >>>>>>>> Epoch  45
2022-11-03 23:15:53,977 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:15:57,638 - INFO  - Training [45][   20/  391]   Loss 0.147460   Top1 94.687500   Top5 99.960938   BatchTime 0.183009   LR 0.000100   
2022-11-03 23:15:59,637 - INFO  - Training [45][   40/  391]   Loss 0.165233   Top1 94.003906   Top5 99.921875   BatchTime 0.141478   LR 0.000100   
2022-11-03 23:16:01,640 - INFO  - Training [45][   60/  391]   Loss 0.166663   Top1 93.880208   Top5 99.921875   BatchTime 0.127708   LR 0.000100   
2022-11-03 23:16:03,648 - INFO  - Training [45][   80/  391]   Loss 0.163741   Top1 93.974609   Top5 99.912109   BatchTime 0.120877   LR 0.000100   
2022-11-03 23:16:05,666 - INFO  - Training [45][  100/  391]   Loss 0.171503   Top1 93.726562   Top5 99.914062   BatchTime 0.116886   LR 0.000100   
2022-11-03 23:16:07,663 - INFO  - Training [45][  120/  391]   Loss 0.168155   Top1 93.867188   Top5 99.928385   BatchTime 0.114046   LR 0.000100   
2022-11-03 23:16:09,673 - INFO  - Training [45][  140/  391]   Loss 0.168551   Top1 93.822545   Top5 99.938616   BatchTime 0.112110   LR 0.000100   
2022-11-03 23:16:11,696 - INFO  - Training [45][  160/  391]   Loss 0.167864   Top1 93.925781   Top5 99.941406   BatchTime 0.110741   LR 0.000100   
2022-11-03 23:16:13,704 - INFO  - Training [45][  180/  391]   Loss 0.169356   Top1 93.910590   Top5 99.930556   BatchTime 0.109591   LR 0.000100   
2022-11-03 23:16:15,712 - INFO  - Training [45][  200/  391]   Loss 0.170277   Top1 93.890625   Top5 99.929688   BatchTime 0.108669   LR 0.000100   
2022-11-03 23:16:17,712 - INFO  - Training [45][  220/  391]   Loss 0.169989   Top1 93.916903   Top5 99.936080   BatchTime 0.107884   LR 0.000100   
2022-11-03 23:16:19,729 - INFO  - Training [45][  240/  391]   Loss 0.168875   Top1 93.990885   Top5 99.938151   BatchTime 0.107296   LR 0.000100   
2022-11-03 23:16:21,733 - INFO  - Training [45][  260/  391]   Loss 0.167621   Top1 94.047476   Top5 99.933894   BatchTime 0.106750   LR 0.000100   
2022-11-03 23:16:23,733 - INFO  - Training [45][  280/  391]   Loss 0.168498   Top1 94.012277   Top5 99.933036   BatchTime 0.106268   LR 0.000100   
2022-11-03 23:16:25,730 - INFO  - Training [45][  300/  391]   Loss 0.169272   Top1 94.007812   Top5 99.932292   BatchTime 0.105839   LR 0.000100   
2022-11-03 23:16:27,758 - INFO  - Training [45][  320/  391]   Loss 0.169231   Top1 94.028320   Top5 99.934082   BatchTime 0.105563   LR 0.000100   
2022-11-03 23:16:29,761 - INFO  - Training [45][  340/  391]   Loss 0.168497   Top1 94.041820   Top5 99.937960   BatchTime 0.105244   LR 0.000100   
2022-11-03 23:16:31,857 - INFO  - Training [45][  360/  391]   Loss 0.168042   Top1 94.055990   Top5 99.939236   BatchTime 0.105219   LR 0.000100   
2022-11-03 23:16:33,802 - INFO  - Training [45][  380/  391]   Loss 0.167997   Top1 94.068668   Top5 99.938322   BatchTime 0.104800   LR 0.000100   
2022-11-03 23:16:35,099 - INFO  - ==> Top1: 94.072    Top5: 99.938    Loss: 0.168

2022-11-03 23:16:35,100 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:16:37,559 - INFO  - Validation [45][   20/   79]   Loss 0.391858   Top1 88.437500   Top5 99.492188   BatchTime 0.122881   
2022-11-03 23:16:38,165 - INFO  - Validation [45][   40/   79]   Loss 0.383859   Top1 88.769531   Top5 99.472656   BatchTime 0.076593   
2022-11-03 23:16:38,873 - INFO  - Validation [45][   60/   79]   Loss 0.377521   Top1 88.763021   Top5 99.531250   BatchTime 0.062860   
2022-11-03 23:16:39,778 - INFO  - ==> Top1: 88.830    Top5: 99.620    Loss: 0.375

2022-11-03 23:16:39,812 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:16:39,813 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:16:39,813 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:16:39,925 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:16:39,925 - INFO  - >>>>>>>> Epoch  46
2022-11-03 23:16:39,926 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:16:43,709 - INFO  - Training [46][   20/  391]   Loss 0.151304   Top1 94.531250   Top5 99.960938   BatchTime 0.189148   LR 0.000100   
2022-11-03 23:16:45,717 - INFO  - Training [46][   40/  391]   Loss 0.163753   Top1 93.828125   Top5 99.941406   BatchTime 0.144777   LR 0.000100   
2022-11-03 23:16:47,740 - INFO  - Training [46][   60/  391]   Loss 0.161933   Top1 94.114583   Top5 99.921875   BatchTime 0.130234   LR 0.000100   
2022-11-03 23:16:49,760 - INFO  - Training [46][   80/  391]   Loss 0.165153   Top1 93.994141   Top5 99.931641   BatchTime 0.122918   LR 0.000100   
2022-11-03 23:16:51,769 - INFO  - Training [46][  100/  391]   Loss 0.162285   Top1 94.148438   Top5 99.929688   BatchTime 0.118430   LR 0.000100   
2022-11-03 23:16:53,774 - INFO  - Training [46][  120/  391]   Loss 0.160700   Top1 94.140625   Top5 99.934896   BatchTime 0.115398   LR 0.000100   
2022-11-03 23:16:55,786 - INFO  - Training [46][  140/  391]   Loss 0.160042   Top1 94.151786   Top5 99.938616   BatchTime 0.113286   LR 0.000100   
2022-11-03 23:16:57,800 - INFO  - Training [46][  160/  391]   Loss 0.161037   Top1 94.135742   Top5 99.936523   BatchTime 0.111710   LR 0.000100   
2022-11-03 23:16:59,810 - INFO  - Training [46][  180/  391]   Loss 0.164127   Top1 94.019097   Top5 99.939236   BatchTime 0.110464   LR 0.000100   
2022-11-03 23:17:01,827 - INFO  - Training [46][  200/  391]   Loss 0.163033   Top1 94.082031   Top5 99.941406   BatchTime 0.109502   LR 0.000100   
2022-11-03 23:17:03,837 - INFO  - Training [46][  220/  391]   Loss 0.164535   Top1 94.026989   Top5 99.943182   BatchTime 0.108684   LR 0.000100   
2022-11-03 23:17:05,828 - INFO  - Training [46][  240/  391]   Loss 0.163963   Top1 94.055990   Top5 99.944661   BatchTime 0.107922   LR 0.000100   
2022-11-03 23:17:07,824 - INFO  - Training [46][  260/  391]   Loss 0.162999   Top1 94.116587   Top5 99.945913   BatchTime 0.107297   LR 0.000100   
2022-11-03 23:17:09,814 - INFO  - Training [46][  280/  391]   Loss 0.161648   Top1 94.146205   Top5 99.944196   BatchTime 0.106742   LR 0.000100   
2022-11-03 23:17:11,840 - INFO  - Training [46][  300/  391]   Loss 0.162701   Top1 94.106771   Top5 99.940104   BatchTime 0.106376   LR 0.000100   
2022-11-03 23:17:13,835 - INFO  - Training [46][  320/  391]   Loss 0.163692   Top1 94.079590   Top5 99.943848   BatchTime 0.105964   LR 0.000100   
2022-11-03 23:17:15,820 - INFO  - Training [46][  340/  391]   Loss 0.163931   Top1 94.087776   Top5 99.931066   BatchTime 0.105567   LR 0.000100   
2022-11-03 23:17:17,780 - INFO  - Training [46][  360/  391]   Loss 0.163202   Top1 94.114583   Top5 99.934896   BatchTime 0.105148   LR 0.000100   
2022-11-03 23:17:19,725 - INFO  - Training [46][  380/  391]   Loss 0.164371   Top1 94.070724   Top5 99.936266   BatchTime 0.104733   LR 0.000100   
2022-11-03 23:17:21,034 - INFO  - ==> Top1: 94.094    Top5: 99.936    Loss: 0.164

2022-11-03 23:17:21,035 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:17:23,498 - INFO  - Validation [46][   20/   79]   Loss 0.392110   Top1 88.203125   Top5 99.492188   BatchTime 0.123102   
2022-11-03 23:17:24,139 - INFO  - Validation [46][   40/   79]   Loss 0.384223   Top1 88.574219   Top5 99.433594   BatchTime 0.077573   
2022-11-03 23:17:24,841 - INFO  - Validation [46][   60/   79]   Loss 0.373490   Top1 88.893229   Top5 99.518229   BatchTime 0.063413   
2022-11-03 23:17:25,736 - INFO  - ==> Top1: 88.950    Top5: 99.610    Loss: 0.372

2022-11-03 23:17:25,770 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:17:25,771 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:17:25,771 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:17:25,876 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:17:25,877 - INFO  - >>>>>>>> Epoch  47
2022-11-03 23:17:25,878 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:17:29,612 - INFO  - Training [47][   20/  391]   Loss 0.160167   Top1 94.257812   Top5 99.921875   BatchTime 0.186661   LR 0.000100   
2022-11-03 23:17:31,626 - INFO  - Training [47][   40/  391]   Loss 0.162156   Top1 94.082031   Top5 99.960938   BatchTime 0.143688   LR 0.000100   
2022-11-03 23:17:33,621 - INFO  - Training [47][   60/  391]   Loss 0.164771   Top1 94.153646   Top5 99.947917   BatchTime 0.129037   LR 0.000100   
2022-11-03 23:17:35,624 - INFO  - Training [47][   80/  391]   Loss 0.162754   Top1 94.287109   Top5 99.941406   BatchTime 0.121820   LR 0.000100   
2022-11-03 23:17:37,628 - INFO  - Training [47][  100/  391]   Loss 0.165239   Top1 94.132812   Top5 99.945312   BatchTime 0.117493   LR 0.000100   
2022-11-03 23:17:39,639 - INFO  - Training [47][  120/  391]   Loss 0.169887   Top1 94.016927   Top5 99.941406   BatchTime 0.114673   LR 0.000100   
2022-11-03 23:17:41,644 - INFO  - Training [47][  140/  391]   Loss 0.168204   Top1 94.040179   Top5 99.944196   BatchTime 0.112606   LR 0.000100   
2022-11-03 23:17:43,652 - INFO  - Training [47][  160/  391]   Loss 0.167828   Top1 94.086914   Top5 99.946289   BatchTime 0.111084   LR 0.000100   
2022-11-03 23:17:45,649 - INFO  - Training [47][  180/  391]   Loss 0.166549   Top1 94.131944   Top5 99.947917   BatchTime 0.109832   LR 0.000100   
2022-11-03 23:17:47,673 - INFO  - Training [47][  200/  391]   Loss 0.166838   Top1 94.140625   Top5 99.953125   BatchTime 0.108973   LR 0.000100   
2022-11-03 23:17:49,672 - INFO  - Training [47][  220/  391]   Loss 0.166763   Top1 94.140625   Top5 99.943182   BatchTime 0.108150   LR 0.000100   
2022-11-03 23:17:51,670 - INFO  - Training [47][  240/  391]   Loss 0.166682   Top1 94.108073   Top5 99.947917   BatchTime 0.107462   LR 0.000100   
2022-11-03 23:17:53,686 - INFO  - Training [47][  260/  391]   Loss 0.167452   Top1 94.086538   Top5 99.948918   BatchTime 0.106950   LR 0.000100   
2022-11-03 23:17:55,672 - INFO  - Training [47][  280/  391]   Loss 0.166738   Top1 94.101562   Top5 99.944196   BatchTime 0.106405   LR 0.000100   
2022-11-03 23:17:57,674 - INFO  - Training [47][  300/  391]   Loss 0.166883   Top1 94.085938   Top5 99.942708   BatchTime 0.105984   LR 0.000100   
2022-11-03 23:17:59,660 - INFO  - Training [47][  320/  391]   Loss 0.166798   Top1 94.091797   Top5 99.941406   BatchTime 0.105564   LR 0.000100   
2022-11-03 23:18:01,637 - INFO  - Training [47][  340/  391]   Loss 0.167109   Top1 94.094669   Top5 99.940257   BatchTime 0.105170   LR 0.000100   
2022-11-03 23:18:03,603 - INFO  - Training [47][  360/  391]   Loss 0.167148   Top1 94.092882   Top5 99.937066   BatchTime 0.104789   LR 0.000100   
2022-11-03 23:18:05,557 - INFO  - Training [47][  380/  391]   Loss 0.167877   Top1 94.083059   Top5 99.940378   BatchTime 0.104415   LR 0.000100   
2022-11-03 23:18:06,856 - INFO  - ==> Top1: 94.082    Top5: 99.938    Loss: 0.168

2022-11-03 23:18:06,857 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:18:09,295 - INFO  - Validation [47][   20/   79]   Loss 0.385611   Top1 88.710938   Top5 99.414062   BatchTime 0.121821   
2022-11-03 23:18:09,867 - INFO  - Validation [47][   40/   79]   Loss 0.381411   Top1 88.847656   Top5 99.433594   BatchTime 0.075213   
2022-11-03 23:18:10,567 - INFO  - Validation [47][   60/   79]   Loss 0.372459   Top1 88.971354   Top5 99.544271   BatchTime 0.061810   
2022-11-03 23:18:11,481 - INFO  - ==> Top1: 88.990    Top5: 99.630    Loss: 0.371

2022-11-03 23:18:11,514 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:18:11,515 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:18:11,515 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:18:11,607 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:18:11,607 - INFO  - >>>>>>>> Epoch  48
2022-11-03 23:18:11,609 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:18:15,502 - INFO  - Training [48][   20/  391]   Loss 0.175134   Top1 93.203125   Top5 99.921875   BatchTime 0.194619   LR 0.000100   
2022-11-03 23:18:17,522 - INFO  - Training [48][   40/  391]   Loss 0.170912   Top1 93.496094   Top5 99.941406   BatchTime 0.147813   LR 0.000100   
2022-11-03 23:18:19,540 - INFO  - Training [48][   60/  391]   Loss 0.166977   Top1 93.736979   Top5 99.947917   BatchTime 0.132172   LR 0.000100   
2022-11-03 23:18:21,541 - INFO  - Training [48][   80/  391]   Loss 0.162201   Top1 93.925781   Top5 99.951172   BatchTime 0.124141   LR 0.000100   
2022-11-03 23:18:23,549 - INFO  - Training [48][  100/  391]   Loss 0.157646   Top1 94.109375   Top5 99.953125   BatchTime 0.119402   LR 0.000100   
2022-11-03 23:18:25,557 - INFO  - Training [48][  120/  391]   Loss 0.159808   Top1 94.134115   Top5 99.954427   BatchTime 0.116231   LR 0.000100   
2022-11-03 23:18:27,547 - INFO  - Training [48][  140/  391]   Loss 0.161582   Top1 94.073661   Top5 99.944196   BatchTime 0.113840   LR 0.000100   
2022-11-03 23:18:29,556 - INFO  - Training [48][  160/  391]   Loss 0.162208   Top1 94.072266   Top5 99.936523   BatchTime 0.112166   LR 0.000100   
2022-11-03 23:18:31,570 - INFO  - Training [48][  180/  391]   Loss 0.161401   Top1 94.166667   Top5 99.939236   BatchTime 0.110893   LR 0.000100   
2022-11-03 23:18:33,579 - INFO  - Training [48][  200/  391]   Loss 0.161982   Top1 94.164062   Top5 99.941406   BatchTime 0.109849   LR 0.000100   
2022-11-03 23:18:35,559 - INFO  - Training [48][  220/  391]   Loss 0.163426   Top1 94.122869   Top5 99.946733   BatchTime 0.108859   LR 0.000100   
2022-11-03 23:18:37,558 - INFO  - Training [48][  240/  391]   Loss 0.162301   Top1 94.156901   Top5 99.944661   BatchTime 0.108116   LR 0.000100   
2022-11-03 23:18:39,566 - INFO  - Training [48][  260/  391]   Loss 0.163043   Top1 94.122596   Top5 99.948918   BatchTime 0.107524   LR 0.000100   
2022-11-03 23:18:41,548 - INFO  - Training [48][  280/  391]   Loss 0.164683   Top1 94.059710   Top5 99.946987   BatchTime 0.106924   LR 0.000100   
2022-11-03 23:18:43,560 - INFO  - Training [48][  300/  391]   Loss 0.164239   Top1 94.088542   Top5 99.945312   BatchTime 0.106500   LR 0.000100   
2022-11-03 23:18:45,562 - INFO  - Training [48][  320/  391]   Loss 0.163230   Top1 94.150391   Top5 99.943848   BatchTime 0.106101   LR 0.000100   
2022-11-03 23:18:47,546 - INFO  - Training [48][  340/  391]   Loss 0.162398   Top1 94.177390   Top5 99.947151   BatchTime 0.105695   LR 0.000100   
2022-11-03 23:18:49,495 - INFO  - Training [48][  360/  391]   Loss 0.163082   Top1 94.151476   Top5 99.945747   BatchTime 0.105236   LR 0.000100   
2022-11-03 23:18:51,438 - INFO  - Training [48][  380/  391]   Loss 0.162164   Top1 94.183799   Top5 99.944490   BatchTime 0.104810   LR 0.000100   
2022-11-03 23:18:52,749 - INFO  - ==> Top1: 94.138    Top5: 99.944    Loss: 0.163

2022-11-03 23:18:52,750 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:18:55,226 - INFO  - Validation [48][   20/   79]   Loss 0.382857   Top1 88.750000   Top5 99.492188   BatchTime 0.123715   
2022-11-03 23:18:55,882 - INFO  - Validation [48][   40/   79]   Loss 0.377965   Top1 88.828125   Top5 99.355469   BatchTime 0.078248   
2022-11-03 23:18:56,579 - INFO  - Validation [48][   60/   79]   Loss 0.370854   Top1 89.023438   Top5 99.427083   BatchTime 0.063780   
2022-11-03 23:18:57,488 - INFO  - ==> Top1: 88.950    Top5: 99.530    Loss: 0.369

2022-11-03 23:18:57,521 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:18:57,521 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:18:57,522 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:18:57,629 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:18:57,629 - INFO  - >>>>>>>> Epoch  49
2022-11-03 23:18:57,631 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:19:01,402 - INFO  - Training [49][   20/  391]   Loss 0.181889   Top1 93.398438   Top5 99.921875   BatchTime 0.188550   LR 0.000100   
2022-11-03 23:19:03,435 - INFO  - Training [49][   40/  391]   Loss 0.168075   Top1 93.945312   Top5 99.941406   BatchTime 0.145100   LR 0.000100   
2022-11-03 23:19:05,449 - INFO  - Training [49][   60/  391]   Loss 0.167896   Top1 93.997396   Top5 99.947917   BatchTime 0.130310   LR 0.000100   
2022-11-03 23:19:07,461 - INFO  - Training [49][   80/  391]   Loss 0.167214   Top1 94.072266   Top5 99.951172   BatchTime 0.122874   LR 0.000100   
2022-11-03 23:19:09,459 - INFO  - Training [49][  100/  391]   Loss 0.166439   Top1 94.148438   Top5 99.937500   BatchTime 0.118284   LR 0.000100   
2022-11-03 23:19:11,482 - INFO  - Training [49][  120/  391]   Loss 0.168720   Top1 94.055990   Top5 99.934896   BatchTime 0.115422   LR 0.000100   
2022-11-03 23:19:13,499 - INFO  - Training [49][  140/  391]   Loss 0.170245   Top1 93.928571   Top5 99.938616   BatchTime 0.113346   LR 0.000100   
2022-11-03 23:19:15,504 - INFO  - Training [49][  160/  391]   Loss 0.170467   Top1 93.930664   Top5 99.936523   BatchTime 0.111705   LR 0.000100   
2022-11-03 23:19:17,512 - INFO  - Training [49][  180/  391]   Loss 0.170074   Top1 93.919271   Top5 99.943576   BatchTime 0.110450   LR 0.000100   
2022-11-03 23:19:19,538 - INFO  - Training [49][  200/  391]   Loss 0.169452   Top1 93.957031   Top5 99.949219   BatchTime 0.109536   LR 0.000100   
2022-11-03 23:19:21,538 - INFO  - Training [49][  220/  391]   Loss 0.170005   Top1 93.902699   Top5 99.950284   BatchTime 0.108668   LR 0.000100   
2022-11-03 23:19:23,527 - INFO  - Training [49][  240/  391]   Loss 0.168990   Top1 93.912760   Top5 99.951172   BatchTime 0.107898   LR 0.000100   
2022-11-03 23:19:25,546 - INFO  - Training [49][  260/  391]   Loss 0.167680   Top1 93.963341   Top5 99.951923   BatchTime 0.107364   LR 0.000100   
2022-11-03 23:19:27,549 - INFO  - Training [49][  280/  391]   Loss 0.166658   Top1 93.978795   Top5 99.946987   BatchTime 0.106849   LR 0.000100   
2022-11-03 23:19:29,490 - INFO  - Training [49][  300/  391]   Loss 0.166112   Top1 93.989583   Top5 99.945312   BatchTime 0.106197   LR 0.000100   
2022-11-03 23:19:31,485 - INFO  - Training [49][  320/  391]   Loss 0.166225   Top1 93.994141   Top5 99.941406   BatchTime 0.105791   LR 0.000100   
2022-11-03 23:19:33,464 - INFO  - Training [49][  340/  391]   Loss 0.166143   Top1 94.011949   Top5 99.944853   BatchTime 0.105390   LR 0.000100   
2022-11-03 23:19:35,418 - INFO  - Training [49][  360/  391]   Loss 0.167405   Top1 94.010417   Top5 99.945747   BatchTime 0.104962   LR 0.000100   
2022-11-03 23:19:37,379 - INFO  - Training [49][  380/  391]   Loss 0.166977   Top1 94.048109   Top5 99.940378   BatchTime 0.104599   LR 0.000100   
2022-11-03 23:19:38,679 - INFO  - ==> Top1: 94.074    Top5: 99.942    Loss: 0.166

2022-11-03 23:19:38,680 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:19:41,100 - INFO  - Validation [49][   20/   79]   Loss 0.393833   Top1 88.164062   Top5 99.531250   BatchTime 0.120934   
2022-11-03 23:19:41,693 - INFO  - Validation [49][   40/   79]   Loss 0.384093   Top1 88.710938   Top5 99.394531   BatchTime 0.075296   
2022-11-03 23:19:42,399 - INFO  - Validation [49][   60/   79]   Loss 0.375232   Top1 88.867188   Top5 99.492188   BatchTime 0.061955   
2022-11-03 23:19:43,330 - INFO  - ==> Top1: 88.920    Top5: 99.590    Loss: 0.372

2022-11-03 23:19:43,365 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:19:43,366 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:19:43,366 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:19:43,471 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:19:43,471 - INFO  - >>>>>>>> Epoch  50
2022-11-03 23:19:43,472 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:19:47,103 - INFO  - Training [50][   20/  391]   Loss 0.161565   Top1 94.296875   Top5 100.000000   BatchTime 0.181555   LR 0.000010   
2022-11-03 23:19:49,088 - INFO  - Training [50][   40/  391]   Loss 0.152857   Top1 94.511719   Top5 99.980469   BatchTime 0.140400   LR 0.000010   
2022-11-03 23:19:51,128 - INFO  - Training [50][   60/  391]   Loss 0.159584   Top1 94.088542   Top5 99.986979   BatchTime 0.127599   LR 0.000010   
2022-11-03 23:19:53,136 - INFO  - Training [50][   80/  391]   Loss 0.168308   Top1 93.876953   Top5 99.980469   BatchTime 0.120798   LR 0.000010   
2022-11-03 23:19:55,232 - INFO  - Training [50][  100/  391]   Loss 0.164987   Top1 94.007812   Top5 99.984375   BatchTime 0.117598   LR 0.000010   
2022-11-03 23:19:57,251 - INFO  - Training [50][  120/  391]   Loss 0.166839   Top1 93.938802   Top5 99.973958   BatchTime 0.114821   LR 0.000010   
2022-11-03 23:19:59,242 - INFO  - Training [50][  140/  391]   Loss 0.166711   Top1 93.967634   Top5 99.977679   BatchTime 0.112640   LR 0.000010   
2022-11-03 23:20:01,247 - INFO  - Training [50][  160/  391]   Loss 0.167720   Top1 93.935547   Top5 99.970703   BatchTime 0.111089   LR 0.000010   
2022-11-03 23:20:03,262 - INFO  - Training [50][  180/  391]   Loss 0.169281   Top1 93.923611   Top5 99.960938   BatchTime 0.109943   LR 0.000010   
2022-11-03 23:20:05,264 - INFO  - Training [50][  200/  391]   Loss 0.166823   Top1 94.015625   Top5 99.960938   BatchTime 0.108957   LR 0.000010   
2022-11-03 23:20:07,270 - INFO  - Training [50][  220/  391]   Loss 0.167608   Top1 94.002131   Top5 99.957386   BatchTime 0.108169   LR 0.000010   
2022-11-03 23:20:09,273 - INFO  - Training [50][  240/  391]   Loss 0.167153   Top1 94.023438   Top5 99.957682   BatchTime 0.107501   LR 0.000010   
2022-11-03 23:20:11,286 - INFO  - Training [50][  260/  391]   Loss 0.167437   Top1 93.987380   Top5 99.960938   BatchTime 0.106975   LR 0.000010   
2022-11-03 23:20:13,283 - INFO  - Training [50][  280/  391]   Loss 0.166455   Top1 94.023438   Top5 99.963728   BatchTime 0.106465   LR 0.000010   
2022-11-03 23:20:15,300 - INFO  - Training [50][  300/  391]   Loss 0.166770   Top1 93.981771   Top5 99.963542   BatchTime 0.106090   LR 0.000010   
2022-11-03 23:20:17,312 - INFO  - Training [50][  320/  391]   Loss 0.167727   Top1 93.972168   Top5 99.958496   BatchTime 0.105748   LR 0.000010   
2022-11-03 23:20:19,326 - INFO  - Training [50][  340/  391]   Loss 0.167299   Top1 93.991268   Top5 99.960938   BatchTime 0.105450   LR 0.000010   
2022-11-03 23:20:21,288 - INFO  - Training [50][  360/  391]   Loss 0.167309   Top1 93.982205   Top5 99.960938   BatchTime 0.105044   LR 0.000010   
2022-11-03 23:20:23,234 - INFO  - Training [50][  380/  391]   Loss 0.166073   Top1 94.027549   Top5 99.958882   BatchTime 0.104636   LR 0.000010   
2022-11-03 23:20:24,552 - INFO  - ==> Top1: 94.014    Top5: 99.958    Loss: 0.167

2022-11-03 23:20:24,553 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:20:27,072 - INFO  - Validation [50][   20/   79]   Loss 0.387509   Top1 88.593750   Top5 99.453125   BatchTime 0.125887   
2022-11-03 23:20:27,688 - INFO  - Validation [50][   40/   79]   Loss 0.382407   Top1 88.925781   Top5 99.414062   BatchTime 0.078340   
2022-11-03 23:20:28,405 - INFO  - Validation [50][   60/   79]   Loss 0.371773   Top1 88.958333   Top5 99.505208   BatchTime 0.064176   
2022-11-03 23:20:29,320 - INFO  - ==> Top1: 88.950    Top5: 99.600    Loss: 0.371

2022-11-03 23:20:29,353 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:20:29,354 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:20:29,354 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:20:29,455 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:20:29,455 - INFO  - >>>>>>>> Epoch  51
2022-11-03 23:20:29,456 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:20:33,248 - INFO  - Training [51][   20/  391]   Loss 0.171988   Top1 93.476562   Top5 100.000000   BatchTime 0.189568   LR 0.000010   
2022-11-03 23:20:35,265 - INFO  - Training [51][   40/  391]   Loss 0.164216   Top1 94.101562   Top5 100.000000   BatchTime 0.145217   LR 0.000010   
2022-11-03 23:20:37,282 - INFO  - Training [51][   60/  391]   Loss 0.164622   Top1 94.153646   Top5 99.960938   BatchTime 0.130428   LR 0.000010   
2022-11-03 23:20:39,302 - INFO  - Training [51][   80/  391]   Loss 0.168219   Top1 94.013672   Top5 99.931641   BatchTime 0.123060   LR 0.000010   
2022-11-03 23:20:41,327 - INFO  - Training [51][  100/  391]   Loss 0.168987   Top1 94.031250   Top5 99.937500   BatchTime 0.118702   LR 0.000010   
2022-11-03 23:20:43,342 - INFO  - Training [51][  120/  391]   Loss 0.169108   Top1 94.036458   Top5 99.947917   BatchTime 0.115708   LR 0.000010   
2022-11-03 23:20:45,334 - INFO  - Training [51][  140/  391]   Loss 0.167544   Top1 94.068080   Top5 99.944196   BatchTime 0.113408   LR 0.000010   
2022-11-03 23:20:47,335 - INFO  - Training [51][  160/  391]   Loss 0.166753   Top1 94.150391   Top5 99.941406   BatchTime 0.111736   LR 0.000010   
2022-11-03 23:20:49,335 - INFO  - Training [51][  180/  391]   Loss 0.165846   Top1 94.214410   Top5 99.934896   BatchTime 0.110433   LR 0.000010   
2022-11-03 23:20:51,357 - INFO  - Training [51][  200/  391]   Loss 0.164453   Top1 94.281250   Top5 99.933594   BatchTime 0.109499   LR 0.000010   
2022-11-03 23:20:53,366 - INFO  - Training [51][  220/  391]   Loss 0.165245   Top1 94.289773   Top5 99.936080   BatchTime 0.108676   LR 0.000010   
2022-11-03 23:20:55,373 - INFO  - Training [51][  240/  391]   Loss 0.164020   Top1 94.322917   Top5 99.925130   BatchTime 0.107982   LR 0.000010   
2022-11-03 23:20:57,375 - INFO  - Training [51][  260/  391]   Loss 0.164310   Top1 94.278846   Top5 99.930889   BatchTime 0.107378   LR 0.000010   
2022-11-03 23:20:59,386 - INFO  - Training [51][  280/  391]   Loss 0.163628   Top1 94.291295   Top5 99.933036   BatchTime 0.106887   LR 0.000010   
2022-11-03 23:21:01,404 - INFO  - Training [51][  300/  391]   Loss 0.163692   Top1 94.242188   Top5 99.934896   BatchTime 0.106491   LR 0.000010   
2022-11-03 23:21:03,409 - INFO  - Training [51][  320/  391]   Loss 0.163117   Top1 94.240723   Top5 99.938965   BatchTime 0.106100   LR 0.000010   
2022-11-03 23:21:05,392 - INFO  - Training [51][  340/  391]   Loss 0.163063   Top1 94.253217   Top5 99.942555   BatchTime 0.105691   LR 0.000010   
2022-11-03 23:21:07,339 - INFO  - Training [51][  360/  391]   Loss 0.162974   Top1 94.238281   Top5 99.943576   BatchTime 0.105227   LR 0.000010   
2022-11-03 23:21:09,220 - INFO  - Training [51][  380/  391]   Loss 0.163339   Top1 94.226974   Top5 99.938322   BatchTime 0.104640   LR 0.000010   
2022-11-03 23:21:10,536 - INFO  - ==> Top1: 94.250    Top5: 99.938    Loss: 0.163

2022-11-03 23:21:10,537 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:21:12,973 - INFO  - Validation [51][   20/   79]   Loss 0.392831   Top1 88.359375   Top5 99.375000   BatchTime 0.121716   
2022-11-03 23:21:13,500 - INFO  - Validation [51][   40/   79]   Loss 0.385791   Top1 88.789062   Top5 99.316406   BatchTime 0.074017   
2022-11-03 23:21:14,260 - INFO  - Validation [51][   60/   79]   Loss 0.375755   Top1 89.010417   Top5 99.440104   BatchTime 0.062021   
2022-11-03 23:21:15,177 - INFO  - ==> Top1: 89.050    Top5: 99.520    Loss: 0.374

2022-11-03 23:21:15,216 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:21:15,217 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:21:15,217 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:21:15,317 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:21:15,317 - INFO  - >>>>>>>> Epoch  52
2022-11-03 23:21:15,319 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:21:19,016 - INFO  - Training [52][   20/  391]   Loss 0.149709   Top1 94.570312   Top5 99.960938   BatchTime 0.184860   LR 0.000010   
2022-11-03 23:21:21,022 - INFO  - Training [52][   40/  391]   Loss 0.163916   Top1 94.003906   Top5 99.960938   BatchTime 0.142569   LR 0.000010   
2022-11-03 23:21:23,038 - INFO  - Training [52][   60/  391]   Loss 0.169426   Top1 93.971354   Top5 99.934896   BatchTime 0.128658   LR 0.000010   
2022-11-03 23:21:25,037 - INFO  - Training [52][   80/  391]   Loss 0.167188   Top1 93.925781   Top5 99.951172   BatchTime 0.121472   LR 0.000010   
2022-11-03 23:21:27,057 - INFO  - Training [52][  100/  391]   Loss 0.169497   Top1 93.898438   Top5 99.937500   BatchTime 0.117382   LR 0.000010   
2022-11-03 23:21:29,101 - INFO  - Training [52][  120/  391]   Loss 0.172948   Top1 93.756510   Top5 99.934896   BatchTime 0.114847   LR 0.000010   
2022-11-03 23:21:31,165 - INFO  - Training [52][  140/  391]   Loss 0.170569   Top1 93.911830   Top5 99.933036   BatchTime 0.113188   LR 0.000010   
2022-11-03 23:21:33,182 - INFO  - Training [52][  160/  391]   Loss 0.170175   Top1 93.886719   Top5 99.936523   BatchTime 0.111641   LR 0.000010   
2022-11-03 23:21:35,319 - INFO  - Training [52][  180/  391]   Loss 0.167838   Top1 93.953993   Top5 99.939236   BatchTime 0.111110   LR 0.000010   
2022-11-03 23:21:37,329 - INFO  - Training [52][  200/  391]   Loss 0.168528   Top1 93.937500   Top5 99.933594   BatchTime 0.110047   LR 0.000010   
2022-11-03 23:21:39,339 - INFO  - Training [52][  220/  391]   Loss 0.169088   Top1 93.892045   Top5 99.928977   BatchTime 0.109179   LR 0.000010   
2022-11-03 23:21:41,356 - INFO  - Training [52][  240/  391]   Loss 0.168960   Top1 93.909505   Top5 99.928385   BatchTime 0.108488   LR 0.000010   
2022-11-03 23:21:43,380 - INFO  - Training [52][  260/  391]   Loss 0.168905   Top1 93.915264   Top5 99.921875   BatchTime 0.107928   LR 0.000010   
2022-11-03 23:21:45,390 - INFO  - Training [52][  280/  391]   Loss 0.167237   Top1 93.992746   Top5 99.919085   BatchTime 0.107396   LR 0.000010   
2022-11-03 23:21:47,390 - INFO  - Training [52][  300/  391]   Loss 0.166821   Top1 94.013021   Top5 99.921875   BatchTime 0.106902   LR 0.000010   
2022-11-03 23:21:49,385 - INFO  - Training [52][  320/  391]   Loss 0.165920   Top1 94.057617   Top5 99.924316   BatchTime 0.106456   LR 0.000010   
2022-11-03 23:21:51,394 - INFO  - Training [52][  340/  391]   Loss 0.165316   Top1 94.073989   Top5 99.926471   BatchTime 0.106102   LR 0.000010   
2022-11-03 23:21:53,353 - INFO  - Training [52][  360/  391]   Loss 0.163854   Top1 94.108073   Top5 99.928385   BatchTime 0.105648   LR 0.000010   
2022-11-03 23:21:55,301 - INFO  - Training [52][  380/  391]   Loss 0.164263   Top1 94.103618   Top5 99.928043   BatchTime 0.105215   LR 0.000010   
2022-11-03 23:21:56,604 - INFO  - ==> Top1: 94.098    Top5: 99.928    Loss: 0.165

2022-11-03 23:21:56,604 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:21:59,084 - INFO  - Validation [52][   20/   79]   Loss 0.391449   Top1 88.359375   Top5 99.453125   BatchTime 0.123898   
2022-11-03 23:21:59,724 - INFO  - Validation [52][   40/   79]   Loss 0.383770   Top1 88.808594   Top5 99.375000   BatchTime 0.077966   
2022-11-03 23:22:00,426 - INFO  - Validation [52][   60/   79]   Loss 0.374624   Top1 89.049479   Top5 99.453125   BatchTime 0.063680   
2022-11-03 23:22:01,359 - INFO  - ==> Top1: 89.150    Top5: 99.560    Loss: 0.371

2022-11-03 23:22:01,392 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:22:01,393 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:22:01,393 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:22:01,499 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:22:01,500 - INFO  - >>>>>>>> Epoch  53
2022-11-03 23:22:01,501 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:22:05,245 - INFO  - Training [53][   20/  391]   Loss 0.170190   Top1 93.398438   Top5 99.882812   BatchTime 0.187170   LR 0.000010   
2022-11-03 23:22:07,258 - INFO  - Training [53][   40/  391]   Loss 0.161771   Top1 94.062500   Top5 99.921875   BatchTime 0.143917   LR 0.000010   
2022-11-03 23:22:09,270 - INFO  - Training [53][   60/  391]   Loss 0.158240   Top1 94.440104   Top5 99.934896   BatchTime 0.129467   LR 0.000010   
2022-11-03 23:22:11,274 - INFO  - Training [53][   80/  391]   Loss 0.159513   Top1 94.296875   Top5 99.921875   BatchTime 0.122152   LR 0.000010   
2022-11-03 23:22:13,291 - INFO  - Training [53][  100/  391]   Loss 0.161449   Top1 94.226562   Top5 99.914062   BatchTime 0.117895   LR 0.000010   
2022-11-03 23:22:15,290 - INFO  - Training [53][  120/  391]   Loss 0.160251   Top1 94.199219   Top5 99.921875   BatchTime 0.114903   LR 0.000010   
2022-11-03 23:22:17,300 - INFO  - Training [53][  140/  391]   Loss 0.160642   Top1 94.213170   Top5 99.921875   BatchTime 0.112843   LR 0.000010   
2022-11-03 23:22:19,311 - INFO  - Training [53][  160/  391]   Loss 0.164130   Top1 94.091797   Top5 99.916992   BatchTime 0.111309   LR 0.000010   
2022-11-03 23:22:21,332 - INFO  - Training [53][  180/  391]   Loss 0.166453   Top1 94.032118   Top5 99.921875   BatchTime 0.110168   LR 0.000010   
2022-11-03 23:22:23,369 - INFO  - Training [53][  200/  391]   Loss 0.165692   Top1 94.078125   Top5 99.917969   BatchTime 0.109338   LR 0.000010   
2022-11-03 23:22:25,391 - INFO  - Training [53][  220/  391]   Loss 0.164904   Top1 94.140625   Top5 99.918324   BatchTime 0.108585   LR 0.000010   
2022-11-03 23:22:27,432 - INFO  - Training [53][  240/  391]   Loss 0.163841   Top1 94.179688   Top5 99.915365   BatchTime 0.108042   LR 0.000010   
2022-11-03 23:22:29,451 - INFO  - Training [53][  260/  391]   Loss 0.165605   Top1 94.107572   Top5 99.918870   BatchTime 0.107496   LR 0.000010   
2022-11-03 23:22:31,462 - INFO  - Training [53][  280/  391]   Loss 0.164100   Top1 94.135045   Top5 99.924665   BatchTime 0.106999   LR 0.000010   
2022-11-03 23:22:33,479 - INFO  - Training [53][  300/  391]   Loss 0.164494   Top1 94.156250   Top5 99.916667   BatchTime 0.106589   LR 0.000010   
2022-11-03 23:22:35,490 - INFO  - Training [53][  320/  391]   Loss 0.164207   Top1 94.157715   Top5 99.919434   BatchTime 0.106212   LR 0.000010   
2022-11-03 23:22:37,498 - INFO  - Training [53][  340/  391]   Loss 0.163934   Top1 94.159007   Top5 99.912684   BatchTime 0.105869   LR 0.000010   
2022-11-03 23:22:39,459 - INFO  - Training [53][  360/  391]   Loss 0.164914   Top1 94.114583   Top5 99.911024   BatchTime 0.105435   LR 0.000010   
2022-11-03 23:22:41,414 - INFO  - Training [53][  380/  391]   Loss 0.165099   Top1 94.113898   Top5 99.913651   BatchTime 0.105030   LR 0.000010   
2022-11-03 23:22:42,738 - INFO  - ==> Top1: 94.112    Top5: 99.910    Loss: 0.165

2022-11-03 23:22:42,739 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:22:45,198 - INFO  - Validation [53][   20/   79]   Loss 0.389490   Top1 88.593750   Top5 99.414062   BatchTime 0.122841   
2022-11-03 23:22:45,753 - INFO  - Validation [53][   40/   79]   Loss 0.385097   Top1 88.710938   Top5 99.355469   BatchTime 0.075296   
2022-11-03 23:22:46,511 - INFO  - Validation [53][   60/   79]   Loss 0.376734   Top1 88.763021   Top5 99.466146   BatchTime 0.062842   
2022-11-03 23:22:47,415 - INFO  - ==> Top1: 88.810    Top5: 99.580    Loss: 0.374

2022-11-03 23:22:47,445 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:22:47,446 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:22:47,446 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:22:47,552 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:22:47,553 - INFO  - >>>>>>>> Epoch  54
2022-11-03 23:22:47,554 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:22:51,189 - INFO  - Training [54][   20/  391]   Loss 0.177012   Top1 93.554688   Top5 99.921875   BatchTime 0.181727   LR 0.000010   
2022-11-03 23:22:53,198 - INFO  - Training [54][   40/  391]   Loss 0.173866   Top1 93.828125   Top5 99.921875   BatchTime 0.141095   LR 0.000010   
2022-11-03 23:22:55,214 - INFO  - Training [54][   60/  391]   Loss 0.168783   Top1 94.036458   Top5 99.934896   BatchTime 0.127663   LR 0.000010   
2022-11-03 23:22:57,221 - INFO  - Training [54][   80/  391]   Loss 0.171429   Top1 93.818359   Top5 99.951172   BatchTime 0.120831   LR 0.000010   
2022-11-03 23:22:59,238 - INFO  - Training [54][  100/  391]   Loss 0.169987   Top1 93.953125   Top5 99.960938   BatchTime 0.116840   LR 0.000010   
2022-11-03 23:23:01,256 - INFO  - Training [54][  120/  391]   Loss 0.169630   Top1 93.984375   Top5 99.967448   BatchTime 0.114179   LR 0.000010   
2022-11-03 23:23:03,270 - INFO  - Training [54][  140/  391]   Loss 0.169670   Top1 94.001116   Top5 99.955357   BatchTime 0.112254   LR 0.000010   
2022-11-03 23:23:05,296 - INFO  - Training [54][  160/  391]   Loss 0.166026   Top1 94.111328   Top5 99.960938   BatchTime 0.110887   LR 0.000010   
2022-11-03 23:23:07,305 - INFO  - Training [54][  180/  391]   Loss 0.166973   Top1 94.075521   Top5 99.960938   BatchTime 0.109727   LR 0.000010   
2022-11-03 23:23:09,314 - INFO  - Training [54][  200/  391]   Loss 0.167683   Top1 94.089844   Top5 99.953125   BatchTime 0.108795   LR 0.000010   
2022-11-03 23:23:11,413 - INFO  - Training [54][  220/  391]   Loss 0.167018   Top1 94.133523   Top5 99.953835   BatchTime 0.108447   LR 0.000010   
2022-11-03 23:23:13,421 - INFO  - Training [54][  240/  391]   Loss 0.166573   Top1 94.169922   Top5 99.957682   BatchTime 0.107775   LR 0.000010   
2022-11-03 23:23:15,425 - INFO  - Training [54][  260/  391]   Loss 0.167531   Top1 94.131611   Top5 99.957933   BatchTime 0.107195   LR 0.000010   
2022-11-03 23:23:17,445 - INFO  - Training [54][  280/  391]   Loss 0.168287   Top1 94.095982   Top5 99.955357   BatchTime 0.106749   LR 0.000010   
2022-11-03 23:23:19,460 - INFO  - Training [54][  300/  391]   Loss 0.166993   Top1 94.127604   Top5 99.953125   BatchTime 0.106351   LR 0.000010   
2022-11-03 23:23:21,454 - INFO  - Training [54][  320/  391]   Loss 0.166813   Top1 94.123535   Top5 99.956055   BatchTime 0.105935   LR 0.000010   
2022-11-03 23:23:23,449 - INFO  - Training [54][  340/  391]   Loss 0.166902   Top1 94.110754   Top5 99.956342   BatchTime 0.105572   LR 0.000010   
2022-11-03 23:23:25,408 - INFO  - Training [54][  360/  391]   Loss 0.165771   Top1 94.127604   Top5 99.958767   BatchTime 0.105147   LR 0.000010   
2022-11-03 23:23:27,395 - INFO  - Training [54][  380/  391]   Loss 0.166564   Top1 94.111842   Top5 99.956826   BatchTime 0.104841   LR 0.000010   
2022-11-03 23:23:28,711 - INFO  - ==> Top1: 94.116    Top5: 99.958    Loss: 0.167

2022-11-03 23:23:28,712 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:23:31,136 - INFO  - Validation [54][   20/   79]   Loss 0.391292   Top1 88.398438   Top5 99.531250   BatchTime 0.121150   
2022-11-03 23:23:31,656 - INFO  - Validation [54][   40/   79]   Loss 0.384351   Top1 88.769531   Top5 99.394531   BatchTime 0.073579   
2022-11-03 23:23:32,372 - INFO  - Validation [54][   60/   79]   Loss 0.374172   Top1 88.932292   Top5 99.466146   BatchTime 0.060984   
2022-11-03 23:23:33,297 - INFO  - ==> Top1: 88.960    Top5: 99.570    Loss: 0.372

2022-11-03 23:23:33,332 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:23:33,332 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:23:33,332 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:23:33,430 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:23:33,430 - INFO  - >>>>>>>> Epoch  55
2022-11-03 23:23:33,431 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:23:37,237 - INFO  - Training [55][   20/  391]   Loss 0.180679   Top1 93.593750   Top5 99.960938   BatchTime 0.190306   LR 0.000010   
2022-11-03 23:23:39,259 - INFO  - Training [55][   40/  391]   Loss 0.177088   Top1 93.671875   Top5 99.960938   BatchTime 0.145706   LR 0.000010   
2022-11-03 23:23:41,282 - INFO  - Training [55][   60/  391]   Loss 0.169571   Top1 93.880208   Top5 99.960938   BatchTime 0.130855   LR 0.000010   
2022-11-03 23:23:43,318 - INFO  - Training [55][   80/  391]   Loss 0.168524   Top1 93.974609   Top5 99.960938   BatchTime 0.123582   LR 0.000010   
2022-11-03 23:23:45,340 - INFO  - Training [55][  100/  391]   Loss 0.167541   Top1 93.960938   Top5 99.960938   BatchTime 0.119093   LR 0.000010   
2022-11-03 23:23:47,370 - INFO  - Training [55][  120/  391]   Loss 0.168709   Top1 93.945312   Top5 99.947917   BatchTime 0.116159   LR 0.000010   
2022-11-03 23:23:49,377 - INFO  - Training [55][  140/  391]   Loss 0.168714   Top1 93.906250   Top5 99.955357   BatchTime 0.113898   LR 0.000010   
2022-11-03 23:23:51,387 - INFO  - Training [55][  160/  391]   Loss 0.167612   Top1 93.925781   Top5 99.951172   BatchTime 0.112222   LR 0.000010   
2022-11-03 23:23:53,373 - INFO  - Training [55][  180/  391]   Loss 0.165195   Top1 94.053819   Top5 99.952257   BatchTime 0.110787   LR 0.000010   
2022-11-03 23:23:55,387 - INFO  - Training [55][  200/  391]   Loss 0.165288   Top1 94.015625   Top5 99.953125   BatchTime 0.109781   LR 0.000010   
2022-11-03 23:23:57,391 - INFO  - Training [55][  220/  391]   Loss 0.165673   Top1 93.980824   Top5 99.957386   BatchTime 0.108907   LR 0.000010   
2022-11-03 23:23:59,374 - INFO  - Training [55][  240/  391]   Loss 0.166035   Top1 93.958333   Top5 99.951172   BatchTime 0.108093   LR 0.000010   
2022-11-03 23:24:01,382 - INFO  - Training [55][  260/  391]   Loss 0.167316   Top1 93.909255   Top5 99.948918   BatchTime 0.107500   LR 0.000010   
2022-11-03 23:24:03,409 - INFO  - Training [55][  280/  391]   Loss 0.166660   Top1 93.925781   Top5 99.949777   BatchTime 0.107062   LR 0.000010   
2022-11-03 23:24:05,405 - INFO  - Training [55][  300/  391]   Loss 0.166651   Top1 93.924479   Top5 99.953125   BatchTime 0.106577   LR 0.000010   
2022-11-03 23:24:07,409 - INFO  - Training [55][  320/  391]   Loss 0.166695   Top1 93.933105   Top5 99.956055   BatchTime 0.106178   LR 0.000010   
2022-11-03 23:24:09,388 - INFO  - Training [55][  340/  391]   Loss 0.166377   Top1 93.949908   Top5 99.954044   BatchTime 0.105755   LR 0.000010   
2022-11-03 23:24:11,347 - INFO  - Training [55][  360/  391]   Loss 0.167294   Top1 93.914931   Top5 99.956597   BatchTime 0.105321   LR 0.000010   
2022-11-03 23:24:13,291 - INFO  - Training [55][  380/  391]   Loss 0.166763   Top1 93.947368   Top5 99.954770   BatchTime 0.104893   LR 0.000010   
2022-11-03 23:24:14,611 - INFO  - ==> Top1: 93.950    Top5: 99.954    Loss: 0.167

2022-11-03 23:24:14,612 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:24:17,040 - INFO  - Validation [55][   20/   79]   Loss 0.388625   Top1 88.632812   Top5 99.492188   BatchTime 0.121316   
2022-11-03 23:24:17,649 - INFO  - Validation [55][   40/   79]   Loss 0.385975   Top1 88.671875   Top5 99.453125   BatchTime 0.075879   
2022-11-03 23:24:18,348 - INFO  - Validation [55][   60/   79]   Loss 0.376872   Top1 88.841146   Top5 99.531250   BatchTime 0.062243   
2022-11-03 23:24:19,259 - INFO  - ==> Top1: 88.910    Top5: 99.630    Loss: 0.375

2022-11-03 23:24:19,291 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:24:19,292 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:24:19,292 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:24:19,364 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:24:19,364 - INFO  - >>>>>>>> Epoch  56
2022-11-03 23:24:19,366 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:24:23,153 - INFO  - Training [56][   20/  391]   Loss 0.166262   Top1 94.257812   Top5 99.921875   BatchTime 0.189335   LR 0.000010   
2022-11-03 23:24:25,148 - INFO  - Training [56][   40/  391]   Loss 0.166272   Top1 93.886719   Top5 99.941406   BatchTime 0.144544   LR 0.000010   
2022-11-03 23:24:27,150 - INFO  - Training [56][   60/  391]   Loss 0.160438   Top1 94.088542   Top5 99.934896   BatchTime 0.129741   LR 0.000010   
2022-11-03 23:24:29,138 - INFO  - Training [56][   80/  391]   Loss 0.163377   Top1 94.121094   Top5 99.931641   BatchTime 0.122156   LR 0.000010   
2022-11-03 23:24:31,150 - INFO  - Training [56][  100/  391]   Loss 0.163984   Top1 94.101562   Top5 99.921875   BatchTime 0.117840   LR 0.000010   
2022-11-03 23:24:33,142 - INFO  - Training [56][  120/  391]   Loss 0.161285   Top1 94.173177   Top5 99.928385   BatchTime 0.114801   LR 0.000010   
2022-11-03 23:24:35,146 - INFO  - Training [56][  140/  391]   Loss 0.166685   Top1 94.012277   Top5 99.927455   BatchTime 0.112711   LR 0.000010   
2022-11-03 23:24:37,134 - INFO  - Training [56][  160/  391]   Loss 0.166752   Top1 93.989258   Top5 99.931641   BatchTime 0.111049   LR 0.000010   
2022-11-03 23:24:39,136 - INFO  - Training [56][  180/  391]   Loss 0.166227   Top1 94.006076   Top5 99.921875   BatchTime 0.109830   LR 0.000010   
2022-11-03 23:24:41,132 - INFO  - Training [56][  200/  391]   Loss 0.163541   Top1 94.093750   Top5 99.929688   BatchTime 0.108827   LR 0.000010   
2022-11-03 23:24:43,143 - INFO  - Training [56][  220/  391]   Loss 0.164151   Top1 94.083807   Top5 99.928977   BatchTime 0.108075   LR 0.000010   
2022-11-03 23:24:45,155 - INFO  - Training [56][  240/  391]   Loss 0.164227   Top1 94.062500   Top5 99.931641   BatchTime 0.107454   LR 0.000010   
2022-11-03 23:24:47,161 - INFO  - Training [56][  260/  391]   Loss 0.165752   Top1 94.014423   Top5 99.933894   BatchTime 0.106904   LR 0.000010   
2022-11-03 23:24:49,164 - INFO  - Training [56][  280/  391]   Loss 0.165820   Top1 93.995536   Top5 99.930246   BatchTime 0.106422   LR 0.000010   
2022-11-03 23:24:51,297 - INFO  - Training [56][  300/  391]   Loss 0.165532   Top1 94.002604   Top5 99.929688   BatchTime 0.106436   LR 0.000010   
2022-11-03 23:24:53,307 - INFO  - Training [56][  320/  391]   Loss 0.164823   Top1 94.020996   Top5 99.929199   BatchTime 0.106063   LR 0.000010   
2022-11-03 23:24:55,297 - INFO  - Training [56][  340/  391]   Loss 0.165040   Top1 93.998162   Top5 99.933364   BatchTime 0.105678   LR 0.000010   
2022-11-03 23:24:57,235 - INFO  - Training [56][  360/  391]   Loss 0.165851   Top1 93.964844   Top5 99.932726   BatchTime 0.105189   LR 0.000010   
2022-11-03 23:24:59,179 - INFO  - Training [56][  380/  391]   Loss 0.165160   Top1 93.998766   Top5 99.934211   BatchTime 0.104770   LR 0.000010   
2022-11-03 23:25:00,487 - INFO  - ==> Top1: 93.990    Top5: 99.936    Loss: 0.165

2022-11-03 23:25:00,488 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:25:02,989 - INFO  - Validation [56][   20/   79]   Loss 0.395219   Top1 88.554688   Top5 99.453125   BatchTime 0.124977   
2022-11-03 23:25:03,640 - INFO  - Validation [56][   40/   79]   Loss 0.385819   Top1 88.847656   Top5 99.394531   BatchTime 0.078767   
2022-11-03 23:25:04,348 - INFO  - Validation [56][   60/   79]   Loss 0.377631   Top1 88.919271   Top5 99.492188   BatchTime 0.064308   
2022-11-03 23:25:05,244 - INFO  - ==> Top1: 89.020    Top5: 99.590    Loss: 0.375

2022-11-03 23:25:05,278 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:25:05,279 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:25:05,279 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:25:05,385 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:25:05,385 - INFO  - >>>>>>>> Epoch  57
2022-11-03 23:25:05,386 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:25:09,232 - INFO  - Training [57][   20/  391]   Loss 0.166778   Top1 93.984375   Top5 99.960938   BatchTime 0.192290   LR 0.000010   
2022-11-03 23:25:11,218 - INFO  - Training [57][   40/  391]   Loss 0.176202   Top1 93.691406   Top5 99.941406   BatchTime 0.145790   LR 0.000010   
2022-11-03 23:25:13,215 - INFO  - Training [57][   60/  391]   Loss 0.166340   Top1 93.971354   Top5 99.960938   BatchTime 0.130471   LR 0.000010   
2022-11-03 23:25:15,213 - INFO  - Training [57][   80/  391]   Loss 0.165863   Top1 93.964844   Top5 99.970703   BatchTime 0.122828   LR 0.000010   
2022-11-03 23:25:17,231 - INFO  - Training [57][  100/  391]   Loss 0.167900   Top1 93.851562   Top5 99.976562   BatchTime 0.118446   LR 0.000010   
2022-11-03 23:25:19,244 - INFO  - Training [57][  120/  391]   Loss 0.169225   Top1 93.932292   Top5 99.973958   BatchTime 0.115477   LR 0.000010   
2022-11-03 23:25:21,260 - INFO  - Training [57][  140/  391]   Loss 0.168678   Top1 93.917411   Top5 99.960938   BatchTime 0.113383   LR 0.000010   
2022-11-03 23:25:23,286 - INFO  - Training [57][  160/  391]   Loss 0.168223   Top1 93.906250   Top5 99.956055   BatchTime 0.111867   LR 0.000010   
2022-11-03 23:25:25,340 - INFO  - Training [57][  180/  391]   Loss 0.168071   Top1 93.906250   Top5 99.956597   BatchTime 0.110849   LR 0.000010   
2022-11-03 23:25:27,370 - INFO  - Training [57][  200/  391]   Loss 0.166369   Top1 93.992188   Top5 99.960938   BatchTime 0.109915   LR 0.000010   
2022-11-03 23:25:29,394 - INFO  - Training [57][  220/  391]   Loss 0.165484   Top1 93.995028   Top5 99.957386   BatchTime 0.109124   LR 0.000010   
2022-11-03 23:25:31,414 - INFO  - Training [57][  240/  391]   Loss 0.167228   Top1 93.938802   Top5 99.957682   BatchTime 0.108445   LR 0.000010   
2022-11-03 23:25:33,453 - INFO  - Training [57][  260/  391]   Loss 0.166039   Top1 93.969351   Top5 99.954928   BatchTime 0.107945   LR 0.000010   
2022-11-03 23:25:35,466 - INFO  - Training [57][  280/  391]   Loss 0.165072   Top1 93.989955   Top5 99.949777   BatchTime 0.107424   LR 0.000010   
2022-11-03 23:25:37,480 - INFO  - Training [57][  300/  391]   Loss 0.164565   Top1 93.989583   Top5 99.947917   BatchTime 0.106978   LR 0.000010   
2022-11-03 23:25:39,474 - INFO  - Training [57][  320/  391]   Loss 0.163692   Top1 94.033203   Top5 99.948730   BatchTime 0.106520   LR 0.000010   
2022-11-03 23:25:41,464 - INFO  - Training [57][  340/  391]   Loss 0.163618   Top1 94.044118   Top5 99.944853   BatchTime 0.106108   LR 0.000010   
2022-11-03 23:25:43,413 - INFO  - Training [57][  360/  391]   Loss 0.164103   Top1 94.003906   Top5 99.945747   BatchTime 0.105628   LR 0.000010   
2022-11-03 23:25:45,363 - INFO  - Training [57][  380/  391]   Loss 0.164615   Top1 93.974095   Top5 99.946546   BatchTime 0.105198   LR 0.000010   
2022-11-03 23:25:46,668 - INFO  - ==> Top1: 93.950    Top5: 99.948    Loss: 0.165

2022-11-03 23:25:46,669 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:25:49,146 - INFO  - Validation [57][   20/   79]   Loss 0.394929   Top1 88.203125   Top5 99.570312   BatchTime 0.123746   
2022-11-03 23:25:49,770 - INFO  - Validation [57][   40/   79]   Loss 0.388346   Top1 88.554688   Top5 99.414062   BatchTime 0.077474   
2022-11-03 23:25:50,478 - INFO  - Validation [57][   60/   79]   Loss 0.378294   Top1 88.710938   Top5 99.479167   BatchTime 0.063462   
2022-11-03 23:25:51,402 - INFO  - ==> Top1: 88.890    Top5: 99.580    Loss: 0.375

2022-11-03 23:25:51,438 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:25:51,439 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:25:51,439 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:25:51,535 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:25:51,535 - INFO  - >>>>>>>> Epoch  58
2022-11-03 23:25:51,536 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:25:55,285 - INFO  - Training [58][   20/  391]   Loss 0.150499   Top1 94.687500   Top5 99.960938   BatchTime 0.187417   LR 0.000010   
2022-11-03 23:25:57,288 - INFO  - Training [58][   40/  391]   Loss 0.159593   Top1 94.199219   Top5 99.980469   BatchTime 0.143791   LR 0.000010   
2022-11-03 23:25:59,306 - INFO  - Training [58][   60/  391]   Loss 0.158578   Top1 94.218750   Top5 99.986979   BatchTime 0.129498   LR 0.000010   
2022-11-03 23:26:01,323 - INFO  - Training [58][   80/  391]   Loss 0.159301   Top1 94.140625   Top5 99.980469   BatchTime 0.122336   LR 0.000010   
2022-11-03 23:26:03,331 - INFO  - Training [58][  100/  391]   Loss 0.162394   Top1 94.000000   Top5 99.976562   BatchTime 0.117950   LR 0.000010   
2022-11-03 23:26:05,274 - INFO  - Training [58][  120/  391]   Loss 0.164182   Top1 93.971354   Top5 99.980469   BatchTime 0.114483   LR 0.000010   
2022-11-03 23:26:07,267 - INFO  - Training [58][  140/  391]   Loss 0.164632   Top1 94.068080   Top5 99.966518   BatchTime 0.112363   LR 0.000010   
2022-11-03 23:26:09,271 - INFO  - Training [58][  160/  391]   Loss 0.166076   Top1 94.077148   Top5 99.970703   BatchTime 0.110840   LR 0.000010   
2022-11-03 23:26:11,289 - INFO  - Training [58][  180/  391]   Loss 0.164443   Top1 94.144965   Top5 99.965278   BatchTime 0.109734   LR 0.000010   
2022-11-03 23:26:13,298 - INFO  - Training [58][  200/  391]   Loss 0.163924   Top1 94.156250   Top5 99.960938   BatchTime 0.108804   LR 0.000010   
2022-11-03 23:26:15,309 - INFO  - Training [58][  220/  391]   Loss 0.163473   Top1 94.222301   Top5 99.960938   BatchTime 0.108056   LR 0.000010   
2022-11-03 23:26:17,317 - INFO  - Training [58][  240/  391]   Loss 0.163004   Top1 94.254557   Top5 99.951172   BatchTime 0.107416   LR 0.000010   
2022-11-03 23:26:19,326 - INFO  - Training [58][  260/  391]   Loss 0.162831   Top1 94.218750   Top5 99.951923   BatchTime 0.106882   LR 0.000010   
2022-11-03 23:26:21,343 - INFO  - Training [58][  280/  391]   Loss 0.163429   Top1 94.199219   Top5 99.955357   BatchTime 0.106449   LR 0.000010   
2022-11-03 23:26:23,359 - INFO  - Training [58][  300/  391]   Loss 0.164330   Top1 94.130208   Top5 99.958333   BatchTime 0.106073   LR 0.000010   
2022-11-03 23:26:25,379 - INFO  - Training [58][  320/  391]   Loss 0.165300   Top1 94.089355   Top5 99.953613   BatchTime 0.105756   LR 0.000010   
2022-11-03 23:26:27,389 - INFO  - Training [58][  340/  391]   Loss 0.164640   Top1 94.122243   Top5 99.951746   BatchTime 0.105446   LR 0.000010   
2022-11-03 23:26:29,331 - INFO  - Training [58][  360/  391]   Loss 0.164348   Top1 94.134115   Top5 99.947917   BatchTime 0.104984   LR 0.000010   
2022-11-03 23:26:31,368 - INFO  - Training [58][  380/  391]   Loss 0.164757   Top1 94.111842   Top5 99.950658   BatchTime 0.104817   LR 0.000010   
2022-11-03 23:26:32,666 - INFO  - ==> Top1: 94.124    Top5: 99.952    Loss: 0.165

2022-11-03 23:26:32,666 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:26:35,103 - INFO  - Validation [58][   20/   79]   Loss 0.390119   Top1 88.203125   Top5 99.453125   BatchTime 0.121766   
2022-11-03 23:26:35,714 - INFO  - Validation [58][   40/   79]   Loss 0.384501   Top1 88.632812   Top5 99.414062   BatchTime 0.076161   
2022-11-03 23:26:36,421 - INFO  - Validation [58][   60/   79]   Loss 0.374871   Top1 88.893229   Top5 99.518229   BatchTime 0.062557   
2022-11-03 23:26:37,319 - INFO  - ==> Top1: 89.050    Top5: 99.590    Loss: 0.372

2022-11-03 23:26:37,352 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:26:37,353 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:26:37,353 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:26:37,460 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:26:37,460 - INFO  - >>>>>>>> Epoch  59
2022-11-03 23:26:37,462 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 23:26:41,225 - INFO  - Training [59][   20/  391]   Loss 0.148805   Top1 94.570312   Top5 99.960938   BatchTime 0.188163   LR 0.000010   
2022-11-03 23:26:43,257 - INFO  - Training [59][   40/  391]   Loss 0.159914   Top1 94.238281   Top5 99.921875   BatchTime 0.144877   LR 0.000010   
2022-11-03 23:26:45,257 - INFO  - Training [59][   60/  391]   Loss 0.161609   Top1 94.257812   Top5 99.947917   BatchTime 0.129922   LR 0.000010   
2022-11-03 23:26:47,271 - INFO  - Training [59][   80/  391]   Loss 0.159465   Top1 94.296875   Top5 99.951172   BatchTime 0.122618   LR 0.000010   
2022-11-03 23:26:49,282 - INFO  - Training [59][  100/  391]   Loss 0.160534   Top1 94.265625   Top5 99.937500   BatchTime 0.118199   LR 0.000010   
2022-11-03 23:26:51,291 - INFO  - Training [59][  120/  391]   Loss 0.160682   Top1 94.270833   Top5 99.934896   BatchTime 0.115241   LR 0.000010   
2022-11-03 23:26:53,303 - INFO  - Training [59][  140/  391]   Loss 0.159886   Top1 94.246652   Top5 99.944196   BatchTime 0.113148   LR 0.000010   
2022-11-03 23:26:55,314 - INFO  - Training [59][  160/  391]   Loss 0.161616   Top1 94.184570   Top5 99.941406   BatchTime 0.111576   LR 0.000010   
2022-11-03 23:26:57,352 - INFO  - Training [59][  180/  391]   Loss 0.163975   Top1 94.162326   Top5 99.934896   BatchTime 0.110502   LR 0.000010   
2022-11-03 23:26:59,360 - INFO  - Training [59][  200/  391]   Loss 0.165519   Top1 94.093750   Top5 99.929688   BatchTime 0.109491   LR 0.000010   
2022-11-03 23:27:01,379 - INFO  - Training [59][  220/  391]   Loss 0.164850   Top1 94.122869   Top5 99.928977   BatchTime 0.108714   LR 0.000010   
2022-11-03 23:27:03,396 - INFO  - Training [59][  240/  391]   Loss 0.164911   Top1 94.163411   Top5 99.931641   BatchTime 0.108056   LR 0.000010   
2022-11-03 23:27:05,414 - INFO  - Training [59][  260/  391]   Loss 0.164776   Top1 94.170673   Top5 99.930889   BatchTime 0.107505   LR 0.000010   
2022-11-03 23:27:07,436 - INFO  - Training [59][  280/  391]   Loss 0.164422   Top1 94.202009   Top5 99.930246   BatchTime 0.107049   LR 0.000010   
2022-11-03 23:27:09,470 - INFO  - Training [59][  300/  391]   Loss 0.163991   Top1 94.234375   Top5 99.927083   BatchTime 0.106693   LR 0.000010   
2022-11-03 23:27:11,497 - INFO  - Training [59][  320/  391]   Loss 0.163827   Top1 94.233398   Top5 99.926758   BatchTime 0.106359   LR 0.000010   
2022-11-03 23:27:13,482 - INFO  - Training [59][  340/  391]   Loss 0.165012   Top1 94.191176   Top5 99.928768   BatchTime 0.105941   LR 0.000010   
2022-11-03 23:27:15,436 - INFO  - Training [59][  360/  391]   Loss 0.165343   Top1 94.179688   Top5 99.928385   BatchTime 0.105483   LR 0.000010   
2022-11-03 23:27:17,379 - INFO  - Training [59][  380/  391]   Loss 0.165710   Top1 94.192023   Top5 99.928043   BatchTime 0.105045   LR 0.000010   
2022-11-03 23:27:18,708 - INFO  - ==> Top1: 94.172    Top5: 99.928    Loss: 0.166

2022-11-03 23:27:18,708 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:27:21,199 - INFO  - Validation [59][   20/   79]   Loss 0.388225   Top1 88.125000   Top5 99.570312   BatchTime 0.124461   
2022-11-03 23:27:21,845 - INFO  - Validation [59][   40/   79]   Loss 0.383094   Top1 88.730469   Top5 99.453125   BatchTime 0.078379   
2022-11-03 23:27:22,553 - INFO  - Validation [59][   60/   79]   Loss 0.377255   Top1 88.841146   Top5 99.531250   BatchTime 0.064056   
2022-11-03 23:27:23,478 - INFO  - ==> Top1: 88.930    Top5: 99.620    Loss: 0.374

2022-11-03 23:27:23,511 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.820   Top5: 99.610] Sparsity : 0.849
2022-11-03 23:27:23,512 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.770   Top5: 99.590] Sparsity : 0.850
2022-11-03 23:27:23,512 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.750   Top5: 99.590] Sparsity : 0.851
2022-11-03 23:27:23,629 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_20_epoch60_20221103-224106/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:27:23,630 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 23:27:23,630 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 23:27:26,096 - INFO  - Validation [   20/   79]   Loss 0.388225   Top1 88.125000   Top5 99.570312   BatchTime 0.123245   
2022-11-03 23:27:26,799 - INFO  - Validation [   40/   79]   Loss 0.383094   Top1 88.730469   Top5 99.453125   BatchTime 0.079220   
2022-11-03 23:27:27,668 - INFO  - Validation [   60/   79]   Loss 0.377255   Top1 88.841146   Top5 99.531250   BatchTime 0.067295   
2022-11-03 23:27:28,766 - INFO  - ==> Top1: 88.930    Top5: 99.620    Loss: 0.374

2022-11-03 23:27:28,828 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_20_epoch60_checkpoint.pth.tar

2022-11-03 23:27:28,829 - INFO  - Program completed successfully ... exiting ...
2022-11-03 23:27:28,829 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
