2022-11-03 23:58:03,493 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803.log
2022-11-03 23:58:04,561 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/tb_runs
2022-11-03 23:58:05,678 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-03 23:58:05,729 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = False
2022-11-03 23:58:07,908 - INFO  - Inserted quantizers into the original model
2022-11-03 23:58:09,801 - INFO  - Loaded checkpoint MobileNetv2 model (next epoch 0) from /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_10_epoch60_checkpoint.pth.tar
2022-11-03 23:58:09,802 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 23:58:09,802 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 23:58:09,802 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 23:58:09,802 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:58:13,744 - INFO  - Validation [   20/   40]   Loss 0.394165   Top1 90.351562   Top5 99.648438   BatchTime 0.197034   
2022-11-03 23:58:14,982 - INFO  - Validation [   40/   40]   Loss 0.383492   Top1 90.380000   Top5 99.660000   BatchTime 0.129471   
2022-11-03 23:58:15,152 - INFO  - ==> Top1: 90.380    Top5: 99.660    Loss: 0.383

2022-11-03 23:58:15,191 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-03 23:58:15,191 - INFO  - >>>>>>>> Epoch   0
2022-11-03 23:58:15,192 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:58:19,492 - INFO  - Training [0][   20/  196]   Loss 0.036699   Top1 98.769531   Top5 100.000000   BatchTime 0.214989   LR 0.010000   
2022-11-03 23:58:21,531 - INFO  - Training [0][   40/  196]   Loss 0.040467   Top1 98.603516   Top5 100.000000   BatchTime 0.158481   LR 0.010000   
2022-11-03 23:58:23,548 - INFO  - Training [0][   60/  196]   Loss 0.042308   Top1 98.619792   Top5 99.993490   BatchTime 0.139271   LR 0.010000   
2022-11-03 23:58:25,564 - INFO  - Training [0][   80/  196]   Loss 0.043505   Top1 98.574219   Top5 99.995117   BatchTime 0.129644   LR 0.010000   
2022-11-03 23:58:27,808 - INFO  - Training [0][  100/  196]   Loss 0.044471   Top1 98.550781   Top5 99.996094   BatchTime 0.126161   LR 0.010000   
2022-11-03 23:58:30,322 - INFO  - Training [0][  120/  196]   Loss 0.044117   Top1 98.535156   Top5 99.996745   BatchTime 0.126080   LR 0.010000   
2022-11-03 23:58:32,791 - INFO  - Training [0][  140/  196]   Loss 0.044450   Top1 98.493304   Top5 99.997210   BatchTime 0.125706   LR 0.010000   
2022-11-03 23:58:35,256 - INFO  - Training [0][  160/  196]   Loss 0.046188   Top1 98.413086   Top5 99.995117   BatchTime 0.125401   LR 0.010000   
2022-11-03 23:58:37,720 - INFO  - Training [0][  180/  196]   Loss 0.047974   Top1 98.352865   Top5 99.995660   BatchTime 0.125151   LR 0.010000   
2022-11-03 23:58:40,288 - INFO  - ==> Top1: 98.322    Top5: 99.996    Loss: 0.049

2022-11-03 23:58:40,289 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:58:43,241 - INFO  - Validation [0][   20/   40]   Loss 0.405257   Top1 90.390625   Top5 99.414062   BatchTime 0.147502   
2022-11-03 23:58:44,389 - INFO  - Validation [0][   40/   40]   Loss 0.395530   Top1 90.390000   Top5 99.540000   BatchTime 0.102461   
2022-11-03 23:58:44,656 - INFO  - ==> Top1: 90.390    Top5: 99.540    Loss: 0.396

2022-11-03 23:58:44,698 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-03 23:58:44,698 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-03 23:58:44,776 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-03 23:58:44,837 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-03 23:58:44,838 - INFO  - >>>>>>>> Epoch   1
2022-11-03 23:58:44,839 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:58:49,332 - INFO  - Training [1][   20/  196]   Loss 0.043257   Top1 98.535156   Top5 100.000000   BatchTime 0.224667   LR 0.010000   
2022-11-03 23:58:51,897 - INFO  - Training [1][   40/  196]   Loss 0.047632   Top1 98.359375   Top5 100.000000   BatchTime 0.176444   LR 0.010000   
2022-11-03 23:58:54,365 - INFO  - Training [1][   60/  196]   Loss 0.051511   Top1 98.248698   Top5 100.000000   BatchTime 0.158769   LR 0.010000   
2022-11-03 23:58:56,803 - INFO  - Training [1][   80/  196]   Loss 0.049009   Top1 98.388672   Top5 100.000000   BatchTime 0.149556   LR 0.010000   
2022-11-03 23:58:59,287 - INFO  - Training [1][  100/  196]   Loss 0.047107   Top1 98.457031   Top5 100.000000   BatchTime 0.144483   LR 0.010000   
2022-11-03 23:59:01,756 - INFO  - Training [1][  120/  196]   Loss 0.047382   Top1 98.470052   Top5 100.000000   BatchTime 0.140973   LR 0.010000   
2022-11-03 23:59:04,220 - INFO  - Training [1][  140/  196]   Loss 0.047563   Top1 98.473772   Top5 99.997210   BatchTime 0.138432   LR 0.010000   
2022-11-03 23:59:06,672 - INFO  - Training [1][  160/  196]   Loss 0.047269   Top1 98.481445   Top5 99.997559   BatchTime 0.136454   LR 0.010000   
2022-11-03 23:59:09,118 - INFO  - Training [1][  180/  196]   Loss 0.047654   Top1 98.430990   Top5 99.997830   BatchTime 0.134881   LR 0.010000   
2022-11-03 23:59:11,280 - INFO  - ==> Top1: 98.396    Top5: 99.998    Loss: 0.048

2022-11-03 23:59:11,281 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:59:14,131 - INFO  - Validation [1][   20/   40]   Loss 0.424630   Top1 90.019531   Top5 99.589844   BatchTime 0.142436   
2022-11-03 23:59:14,983 - INFO  - Validation [1][   40/   40]   Loss 0.412254   Top1 90.180000   Top5 99.620000   BatchTime 0.092508   
2022-11-03 23:59:15,260 - INFO  - ==> Top1: 90.180    Top5: 99.620    Loss: 0.412

2022-11-03 23:59:15,292 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-03 23:59:15,293 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-03 23:59:15,293 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 90.180   Top5: 99.620] Sparsity : 0.836
2022-11-03 23:59:15,399 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-03 23:59:15,400 - INFO  - >>>>>>>> Epoch   2
2022-11-03 23:59:15,401 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:59:19,627 - INFO  - Training [2][   20/  196]   Loss 0.043746   Top1 98.457031   Top5 100.000000   BatchTime 0.211293   LR 0.010000   
2022-11-03 23:59:22,103 - INFO  - Training [2][   40/  196]   Loss 0.043902   Top1 98.310547   Top5 100.000000   BatchTime 0.167540   LR 0.010000   
2022-11-03 23:59:24,604 - INFO  - Training [2][   60/  196]   Loss 0.044116   Top1 98.320312   Top5 99.993490   BatchTime 0.153375   LR 0.010000   
2022-11-03 23:59:27,078 - INFO  - Training [2][   80/  196]   Loss 0.046015   Top1 98.261719   Top5 99.995117   BatchTime 0.145961   LR 0.010000   
2022-11-03 23:59:29,561 - INFO  - Training [2][  100/  196]   Loss 0.045999   Top1 98.285156   Top5 99.996094   BatchTime 0.141591   LR 0.010000   
2022-11-03 23:59:32,025 - INFO  - Training [2][  120/  196]   Loss 0.045907   Top1 98.317057   Top5 99.996745   BatchTime 0.138525   LR 0.010000   
2022-11-03 23:59:34,497 - INFO  - Training [2][  140/  196]   Loss 0.047063   Top1 98.284040   Top5 99.997210   BatchTime 0.136396   LR 0.010000   
2022-11-03 23:59:36,953 - INFO  - Training [2][  160/  196]   Loss 0.047715   Top1 98.266602   Top5 99.995117   BatchTime 0.134696   LR 0.010000   
2022-11-03 23:59:39,411 - INFO  - Training [2][  180/  196]   Loss 0.048013   Top1 98.259549   Top5 99.995660   BatchTime 0.133385   LR 0.010000   
2022-11-03 23:59:41,612 - INFO  - ==> Top1: 98.266    Top5: 99.996    Loss: 0.048

2022-11-03 23:59:41,612 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-03 23:59:44,566 - INFO  - Validation [2][   20/   40]   Loss 0.422561   Top1 89.960938   Top5 99.511719   BatchTime 0.147608   
2022-11-03 23:59:45,689 - INFO  - Validation [2][   40/   40]   Loss 0.410054   Top1 90.140000   Top5 99.570000   BatchTime 0.101890   
2022-11-03 23:59:45,974 - INFO  - ==> Top1: 90.140    Top5: 99.570    Loss: 0.410

2022-11-03 23:59:46,021 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-03 23:59:46,022 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-03 23:59:46,022 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 90.180   Top5: 99.620] Sparsity : 0.836
2022-11-03 23:59:46,134 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-03 23:59:46,135 - INFO  - >>>>>>>> Epoch   3
2022-11-03 23:59:46,136 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-03 23:59:50,573 - INFO  - Training [3][   20/  196]   Loss 0.041520   Top1 98.515625   Top5 100.000000   BatchTime 0.221823   LR 0.010000   
2022-11-03 23:59:53,037 - INFO  - Training [3][   40/  196]   Loss 0.044242   Top1 98.457031   Top5 99.990234   BatchTime 0.172519   LR 0.010000   
2022-11-03 23:59:55,504 - INFO  - Training [3][   60/  196]   Loss 0.045110   Top1 98.372396   Top5 99.993490   BatchTime 0.156122   LR 0.010000   
2022-11-03 23:59:57,966 - INFO  - Training [3][   80/  196]   Loss 0.046022   Top1 98.339844   Top5 99.995117   BatchTime 0.147867   LR 0.010000   
2022-11-04 00:00:00,425 - INFO  - Training [3][  100/  196]   Loss 0.046498   Top1 98.347656   Top5 99.996094   BatchTime 0.142886   LR 0.010000   
2022-11-04 00:00:02,907 - INFO  - Training [3][  120/  196]   Loss 0.046493   Top1 98.362630   Top5 99.996745   BatchTime 0.139756   LR 0.010000   
2022-11-04 00:00:05,011 - INFO  - Training [3][  140/  196]   Loss 0.046746   Top1 98.331473   Top5 99.997210   BatchTime 0.134814   LR 0.010000   
2022-11-04 00:00:06,939 - INFO  - Training [3][  160/  196]   Loss 0.046618   Top1 98.342285   Top5 99.997559   BatchTime 0.130015   LR 0.010000   
2022-11-04 00:00:08,953 - INFO  - Training [3][  180/  196]   Loss 0.047538   Top1 98.300781   Top5 99.997830   BatchTime 0.126756   LR 0.010000   
2022-11-04 00:00:10,819 - INFO  - ==> Top1: 98.322    Top5: 99.998    Loss: 0.047

2022-11-04 00:00:10,820 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:00:13,903 - INFO  - Validation [3][   20/   40]   Loss 0.412581   Top1 90.019531   Top5 99.511719   BatchTime 0.154063   
2022-11-04 00:00:15,027 - INFO  - Validation [3][   40/   40]   Loss 0.402157   Top1 90.200000   Top5 99.560000   BatchTime 0.105144   
2022-11-04 00:00:15,302 - INFO  - ==> Top1: 90.200    Top5: 99.560    Loss: 0.402

2022-11-04 00:00:15,336 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:00:15,336 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:00:15,336 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 90.200   Top5: 99.560] Sparsity : 0.836
2022-11-04 00:00:15,433 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:00:15,433 - INFO  - >>>>>>>> Epoch   4
2022-11-04 00:00:15,435 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:00:19,939 - INFO  - Training [4][   20/  196]   Loss 0.047202   Top1 98.300781   Top5 100.000000   BatchTime 0.225228   LR 0.010000   
2022-11-04 00:00:22,406 - INFO  - Training [4][   40/  196]   Loss 0.040255   Top1 98.593750   Top5 100.000000   BatchTime 0.174275   LR 0.010000   
2022-11-04 00:00:24,891 - INFO  - Training [4][   60/  196]   Loss 0.042780   Top1 98.483073   Top5 100.000000   BatchTime 0.157599   LR 0.010000   
2022-11-04 00:00:27,369 - INFO  - Training [4][   80/  196]   Loss 0.045138   Top1 98.388672   Top5 99.995117   BatchTime 0.149182   LR 0.010000   
2022-11-04 00:00:29,847 - INFO  - Training [4][  100/  196]   Loss 0.044662   Top1 98.433594   Top5 99.996094   BatchTime 0.144120   LR 0.010000   
2022-11-04 00:00:32,313 - INFO  - Training [4][  120/  196]   Loss 0.044608   Top1 98.444010   Top5 99.996745   BatchTime 0.140650   LR 0.010000   
2022-11-04 00:00:34,785 - INFO  - Training [4][  140/  196]   Loss 0.045648   Top1 98.384487   Top5 99.997210   BatchTime 0.138217   LR 0.010000   
2022-11-04 00:00:37,250 - INFO  - Training [4][  160/  196]   Loss 0.046711   Top1 98.352051   Top5 99.997559   BatchTime 0.136343   LR 0.010000   
2022-11-04 00:00:39,712 - INFO  - Training [4][  180/  196]   Loss 0.047074   Top1 98.326823   Top5 99.997830   BatchTime 0.134870   LR 0.010000   
2022-11-04 00:00:41,908 - INFO  - ==> Top1: 98.326    Top5: 99.998    Loss: 0.047

2022-11-04 00:00:41,909 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:00:44,889 - INFO  - Validation [4][   20/   40]   Loss 0.406136   Top1 90.625000   Top5 99.511719   BatchTime 0.148956   
2022-11-04 00:00:46,035 - INFO  - Validation [4][   40/   40]   Loss 0.400077   Top1 90.710000   Top5 99.510000   BatchTime 0.103125   
2022-11-04 00:00:46,306 - INFO  - ==> Top1: 90.710    Top5: 99.510    Loss: 0.400

2022-11-04 00:00:46,335 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:00:46,336 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:00:46,336 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:00:46,521 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:00:46,681 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:00:46,682 - INFO  - >>>>>>>> Epoch   5
2022-11-04 00:00:46,683 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:00:51,226 - INFO  - Training [5][   20/  196]   Loss 0.039834   Top1 98.574219   Top5 100.000000   BatchTime 0.227146   LR 0.010000   
2022-11-04 00:00:53,704 - INFO  - Training [5][   40/  196]   Loss 0.040818   Top1 98.603516   Top5 100.000000   BatchTime 0.175526   LR 0.010000   
2022-11-04 00:00:56,174 - INFO  - Training [5][   60/  196]   Loss 0.043380   Top1 98.457031   Top5 100.000000   BatchTime 0.158180   LR 0.010000   
2022-11-04 00:00:58,132 - INFO  - Training [5][   80/  196]   Loss 0.043058   Top1 98.496094   Top5 100.000000   BatchTime 0.143109   LR 0.010000   
2022-11-04 00:01:00,166 - INFO  - Training [5][  100/  196]   Loss 0.043084   Top1 98.503906   Top5 99.996094   BatchTime 0.134832   LR 0.010000   
2022-11-04 00:01:02,217 - INFO  - Training [5][  120/  196]   Loss 0.044085   Top1 98.447266   Top5 99.996745   BatchTime 0.129448   LR 0.010000   
2022-11-04 00:01:04,289 - INFO  - Training [5][  140/  196]   Loss 0.044670   Top1 98.426339   Top5 99.997210   BatchTime 0.125758   LR 0.010000   
2022-11-04 00:01:06,196 - INFO  - Training [5][  160/  196]   Loss 0.044077   Top1 98.444824   Top5 99.997559   BatchTime 0.121954   LR 0.010000   
2022-11-04 00:01:08,667 - INFO  - Training [5][  180/  196]   Loss 0.044698   Top1 98.444010   Top5 99.995660   BatchTime 0.122130   LR 0.010000   
2022-11-04 00:01:10,883 - INFO  - ==> Top1: 98.436    Top5: 99.996    Loss: 0.045

2022-11-04 00:01:10,884 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:01:13,850 - INFO  - Validation [5][   20/   40]   Loss 0.415628   Top1 90.390625   Top5 99.492188   BatchTime 0.148230   
2022-11-04 00:01:14,999 - INFO  - Validation [5][   40/   40]   Loss 0.416535   Top1 90.180000   Top5 99.580000   BatchTime 0.102839   
2022-11-04 00:01:15,283 - INFO  - ==> Top1: 90.180    Top5: 99.580    Loss: 0.417

2022-11-04 00:01:15,329 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:01:15,329 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:01:15,330 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:01:15,420 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:01:15,420 - INFO  - >>>>>>>> Epoch   6
2022-11-04 00:01:15,422 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:01:19,941 - INFO  - Training [6][   20/  196]   Loss 0.042893   Top1 98.515625   Top5 100.000000   BatchTime 0.225934   LR 0.010000   
2022-11-04 00:01:22,423 - INFO  - Training [6][   40/  196]   Loss 0.044085   Top1 98.437500   Top5 100.000000   BatchTime 0.175026   LR 0.010000   
2022-11-04 00:01:24,898 - INFO  - Training [6][   60/  196]   Loss 0.044402   Top1 98.417969   Top5 100.000000   BatchTime 0.157930   LR 0.010000   
2022-11-04 00:01:27,379 - INFO  - Training [6][   80/  196]   Loss 0.041640   Top1 98.525391   Top5 100.000000   BatchTime 0.149468   LR 0.010000   
2022-11-04 00:01:29,883 - INFO  - Training [6][  100/  196]   Loss 0.043594   Top1 98.429688   Top5 100.000000   BatchTime 0.144610   LR 0.010000   
2022-11-04 00:01:32,364 - INFO  - Training [6][  120/  196]   Loss 0.044153   Top1 98.414714   Top5 100.000000   BatchTime 0.141185   LR 0.010000   
2022-11-04 00:01:34,841 - INFO  - Training [6][  140/  196]   Loss 0.044582   Top1 98.404018   Top5 100.000000   BatchTime 0.138705   LR 0.010000   
2022-11-04 00:01:37,310 - INFO  - Training [6][  160/  196]   Loss 0.045351   Top1 98.391113   Top5 100.000000   BatchTime 0.136796   LR 0.010000   
2022-11-04 00:01:39,779 - INFO  - Training [6][  180/  196]   Loss 0.045046   Top1 98.383247   Top5 100.000000   BatchTime 0.135314   LR 0.010000   
2022-11-04 00:01:41,980 - INFO  - ==> Top1: 98.384    Top5: 99.998    Loss: 0.045

2022-11-04 00:01:41,981 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:01:44,942 - INFO  - Validation [6][   20/   40]   Loss 0.423459   Top1 90.078125   Top5 99.589844   BatchTime 0.147973   
2022-11-04 00:01:46,040 - INFO  - Validation [6][   40/   40]   Loss 0.411558   Top1 90.230000   Top5 99.630000   BatchTime 0.101446   
2022-11-04 00:01:46,302 - INFO  - ==> Top1: 90.230    Top5: 99.630    Loss: 0.412

2022-11-04 00:01:46,333 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:01:46,334 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:01:46,334 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:01:46,429 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:01:46,429 - INFO  - >>>>>>>> Epoch   7
2022-11-04 00:01:46,430 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:01:50,395 - INFO  - Training [7][   20/  196]   Loss 0.040320   Top1 98.515625   Top5 100.000000   BatchTime 0.198222   LR 0.010000   
2022-11-04 00:01:52,449 - INFO  - Training [7][   40/  196]   Loss 0.041122   Top1 98.662109   Top5 100.000000   BatchTime 0.150462   LR 0.010000   
2022-11-04 00:01:54,501 - INFO  - Training [7][   60/  196]   Loss 0.041214   Top1 98.606771   Top5 100.000000   BatchTime 0.134504   LR 0.010000   
2022-11-04 00:01:56,436 - INFO  - Training [7][   80/  196]   Loss 0.042479   Top1 98.549805   Top5 99.995117   BatchTime 0.125067   LR 0.010000   
2022-11-04 00:01:58,628 - INFO  - Training [7][  100/  196]   Loss 0.044581   Top1 98.445312   Top5 99.996094   BatchTime 0.121975   LR 0.010000   
2022-11-04 00:02:01,109 - INFO  - Training [7][  120/  196]   Loss 0.045072   Top1 98.430990   Top5 99.996745   BatchTime 0.122321   LR 0.010000   
2022-11-04 00:02:03,599 - INFO  - Training [7][  140/  196]   Loss 0.044911   Top1 98.431920   Top5 99.997210   BatchTime 0.122629   LR 0.010000   
2022-11-04 00:02:06,071 - INFO  - Training [7][  160/  196]   Loss 0.045196   Top1 98.430176   Top5 99.997559   BatchTime 0.122752   LR 0.010000   
2022-11-04 00:02:08,554 - INFO  - Training [7][  180/  196]   Loss 0.045342   Top1 98.411458   Top5 99.997830   BatchTime 0.122904   LR 0.010000   
2022-11-04 00:02:10,748 - INFO  - ==> Top1: 98.386    Top5: 99.998    Loss: 0.046

2022-11-04 00:02:10,749 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:02:13,679 - INFO  - Validation [7][   20/   40]   Loss 0.423513   Top1 89.941406   Top5 99.550781   BatchTime 0.146456   
2022-11-04 00:02:14,820 - INFO  - Validation [7][   40/   40]   Loss 0.413985   Top1 90.010000   Top5 99.590000   BatchTime 0.101745   
2022-11-04 00:02:15,100 - INFO  - ==> Top1: 90.010    Top5: 99.590    Loss: 0.414

2022-11-04 00:02:15,148 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:02:15,149 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:02:15,149 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:02:15,252 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:02:15,252 - INFO  - >>>>>>>> Epoch   8
2022-11-04 00:02:15,254 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:02:19,719 - INFO  - Training [8][   20/  196]   Loss 0.039058   Top1 98.710938   Top5 100.000000   BatchTime 0.223237   LR 0.010000   
2022-11-04 00:02:22,209 - INFO  - Training [8][   40/  196]   Loss 0.041088   Top1 98.613281   Top5 100.000000   BatchTime 0.173877   LR 0.010000   
2022-11-04 00:02:24,691 - INFO  - Training [8][   60/  196]   Loss 0.041796   Top1 98.619792   Top5 100.000000   BatchTime 0.157288   LR 0.010000   
2022-11-04 00:02:27,171 - INFO  - Training [8][   80/  196]   Loss 0.043267   Top1 98.496094   Top5 100.000000   BatchTime 0.148968   LR 0.010000   
2022-11-04 00:02:29,647 - INFO  - Training [8][  100/  196]   Loss 0.042048   Top1 98.523438   Top5 100.000000   BatchTime 0.143929   LR 0.010000   
2022-11-04 00:02:32,115 - INFO  - Training [8][  120/  196]   Loss 0.041575   Top1 98.535156   Top5 100.000000   BatchTime 0.140510   LR 0.010000   
2022-11-04 00:02:34,582 - INFO  - Training [8][  140/  196]   Loss 0.040838   Top1 98.549107   Top5 100.000000   BatchTime 0.138059   LR 0.010000   
2022-11-04 00:02:37,043 - INFO  - Training [8][  160/  196]   Loss 0.040575   Top1 98.579102   Top5 100.000000   BatchTime 0.136179   LR 0.010000   
2022-11-04 00:02:39,502 - INFO  - Training [8][  180/  196]   Loss 0.040685   Top1 98.572049   Top5 100.000000   BatchTime 0.134709   LR 0.010000   
2022-11-04 00:02:41,686 - INFO  - ==> Top1: 98.570    Top5: 100.000    Loss: 0.041

2022-11-04 00:02:41,687 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:02:44,400 - INFO  - Validation [8][   20/   40]   Loss 0.434809   Top1 90.332031   Top5 99.492188   BatchTime 0.135631   
2022-11-04 00:02:45,257 - INFO  - Validation [8][   40/   40]   Loss 0.426610   Top1 90.360000   Top5 99.550000   BatchTime 0.089228   
2022-11-04 00:02:45,528 - INFO  - ==> Top1: 90.360    Top5: 99.550    Loss: 0.427

2022-11-04 00:02:45,559 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:02:45,560 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:02:45,560 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:02:45,660 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:02:45,661 - INFO  - >>>>>>>> Epoch   9
2022-11-04 00:02:45,662 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:02:49,589 - INFO  - Training [9][   20/  196]   Loss 0.042218   Top1 98.398438   Top5 100.000000   BatchTime 0.196324   LR 0.010000   
2022-11-04 00:02:52,078 - INFO  - Training [9][   40/  196]   Loss 0.039455   Top1 98.476562   Top5 100.000000   BatchTime 0.160389   LR 0.010000   
2022-11-04 00:02:54,645 - INFO  - Training [9][   60/  196]   Loss 0.039847   Top1 98.483073   Top5 100.000000   BatchTime 0.149712   LR 0.010000   
2022-11-04 00:02:57,128 - INFO  - Training [9][   80/  196]   Loss 0.039560   Top1 98.505859   Top5 100.000000   BatchTime 0.143312   LR 0.010000   
2022-11-04 00:02:59,628 - INFO  - Training [9][  100/  196]   Loss 0.040085   Top1 98.519531   Top5 100.000000   BatchTime 0.139651   LR 0.010000   
2022-11-04 00:03:02,121 - INFO  - Training [9][  120/  196]   Loss 0.039327   Top1 98.538411   Top5 99.996745   BatchTime 0.137148   LR 0.010000   
2022-11-04 00:03:04,594 - INFO  - Training [9][  140/  196]   Loss 0.039461   Top1 98.515625   Top5 99.997210   BatchTime 0.135223   LR 0.010000   
2022-11-04 00:03:07,056 - INFO  - Training [9][  160/  196]   Loss 0.039541   Top1 98.525391   Top5 99.997559   BatchTime 0.133708   LR 0.010000   
2022-11-04 00:03:09,525 - INFO  - Training [9][  180/  196]   Loss 0.039495   Top1 98.539497   Top5 99.997830   BatchTime 0.132565   LR 0.010000   
2022-11-04 00:03:11,718 - INFO  - ==> Top1: 98.546    Top5: 99.996    Loss: 0.040

2022-11-04 00:03:11,719 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:03:14,692 - INFO  - Validation [9][   20/   40]   Loss 0.432330   Top1 90.214844   Top5 99.492188   BatchTime 0.148586   
2022-11-04 00:03:15,807 - INFO  - Validation [9][   40/   40]   Loss 0.414308   Top1 90.270000   Top5 99.600000   BatchTime 0.102159   
2022-11-04 00:03:16,092 - INFO  - ==> Top1: 90.270    Top5: 99.600    Loss: 0.414

2022-11-04 00:03:16,135 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:03:16,135 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:03:16,135 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 90.380   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:03:16,246 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:03:16,246 - INFO  - >>>>>>>> Epoch  10
2022-11-04 00:03:16,248 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:03:20,750 - INFO  - Training [10][   20/  196]   Loss 0.032440   Top1 98.750000   Top5 100.000000   BatchTime 0.225088   LR 0.010000   
2022-11-04 00:03:23,219 - INFO  - Training [10][   40/  196]   Loss 0.035528   Top1 98.720703   Top5 100.000000   BatchTime 0.174276   LR 0.010000   
2022-11-04 00:03:25,697 - INFO  - Training [10][   60/  196]   Loss 0.037197   Top1 98.691406   Top5 100.000000   BatchTime 0.157487   LR 0.010000   
2022-11-04 00:03:28,174 - INFO  - Training [10][   80/  196]   Loss 0.038163   Top1 98.676758   Top5 100.000000   BatchTime 0.149077   LR 0.010000   
2022-11-04 00:03:30,651 - INFO  - Training [10][  100/  196]   Loss 0.037626   Top1 98.683594   Top5 100.000000   BatchTime 0.144030   LR 0.010000   
2022-11-04 00:03:33,121 - INFO  - Training [10][  120/  196]   Loss 0.037973   Top1 98.688151   Top5 100.000000   BatchTime 0.140602   LR 0.010000   
2022-11-04 00:03:35,488 - INFO  - Training [10][  140/  196]   Loss 0.037998   Top1 98.666295   Top5 100.000000   BatchTime 0.137425   LR 0.010000   
2022-11-04 00:03:37,296 - INFO  - Training [10][  160/  196]   Loss 0.038387   Top1 98.657227   Top5 100.000000   BatchTime 0.131545   LR 0.010000   
2022-11-04 00:03:39,310 - INFO  - Training [10][  180/  196]   Loss 0.038504   Top1 98.645833   Top5 100.000000   BatchTime 0.128118   LR 0.010000   
2022-11-04 00:03:41,156 - INFO  - ==> Top1: 98.638    Top5: 100.000    Loss: 0.039

2022-11-04 00:03:41,157 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:03:44,086 - INFO  - Validation [10][   20/   40]   Loss 0.426188   Top1 90.312500   Top5 99.492188   BatchTime 0.146382   
2022-11-04 00:03:45,222 - INFO  - Validation [10][   40/   40]   Loss 0.415799   Top1 90.400000   Top5 99.550000   BatchTime 0.101594   
2022-11-04 00:03:45,503 - INFO  - ==> Top1: 90.400    Top5: 99.550    Loss: 0.416

2022-11-04 00:03:45,539 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:03:45,540 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
2022-11-04 00:03:45,540 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 90.390   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:03:45,647 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:03:45,647 - INFO  - >>>>>>>> Epoch  11
2022-11-04 00:03:45,649 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:03:50,093 - INFO  - Training [11][   20/  196]   Loss 0.037111   Top1 98.593750   Top5 100.000000   BatchTime 0.222224   LR 0.010000   
2022-11-04 00:03:52,575 - INFO  - Training [11][   40/  196]   Loss 0.036809   Top1 98.740234   Top5 100.000000   BatchTime 0.173166   LR 0.010000   
2022-11-04 00:03:55,052 - INFO  - Training [11][   60/  196]   Loss 0.037754   Top1 98.645833   Top5 100.000000   BatchTime 0.156718   LR 0.010000   
2022-11-04 00:03:57,529 - INFO  - Training [11][   80/  196]   Loss 0.039395   Top1 98.603516   Top5 100.000000   BatchTime 0.148499   LR 0.010000   
2022-11-04 00:04:00,050 - INFO  - Training [11][  100/  196]   Loss 0.040788   Top1 98.539062   Top5 100.000000   BatchTime 0.144014   LR 0.010000   
2022-11-04 00:04:02,538 - INFO  - Training [11][  120/  196]   Loss 0.040040   Top1 98.603516   Top5 100.000000   BatchTime 0.140737   LR 0.010000   
2022-11-04 00:04:05,009 - INFO  - Training [11][  140/  196]   Loss 0.040322   Top1 98.582589   Top5 100.000000   BatchTime 0.138284   LR 0.010000   
2022-11-04 00:04:07,474 - INFO  - Training [11][  160/  196]   Loss 0.039196   Top1 98.620605   Top5 100.000000   BatchTime 0.136404   LR 0.010000   
2022-11-04 00:04:09,944 - INFO  - Training [11][  180/  196]   Loss 0.040128   Top1 98.563368   Top5 100.000000   BatchTime 0.134970   LR 0.010000   
2022-11-04 00:04:12,136 - INFO  - ==> Top1: 98.566    Top5: 100.000    Loss: 0.040

2022-11-04 00:04:12,137 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:04:15,102 - INFO  - Validation [11][   20/   40]   Loss 0.422850   Top1 90.117188   Top5 99.589844   BatchTime 0.148198   
2022-11-04 00:04:16,195 - INFO  - Validation [11][   40/   40]   Loss 0.414019   Top1 90.430000   Top5 99.630000   BatchTime 0.101423   
2022-11-04 00:04:16,485 - INFO  - ==> Top1: 90.430    Top5: 99.630    Loss: 0.414

2022-11-04 00:04:16,521 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:04:16,521 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:04:16,521 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
2022-11-04 00:04:16,624 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:04:16,624 - INFO  - >>>>>>>> Epoch  12
2022-11-04 00:04:16,625 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:04:21,066 - INFO  - Training [12][   20/  196]   Loss 0.039213   Top1 98.671875   Top5 100.000000   BatchTime 0.222000   LR 0.010000   
2022-11-04 00:04:23,532 - INFO  - Training [12][   40/  196]   Loss 0.039908   Top1 98.613281   Top5 100.000000   BatchTime 0.172669   LR 0.010000   
2022-11-04 00:04:26,007 - INFO  - Training [12][   60/  196]   Loss 0.040502   Top1 98.593750   Top5 100.000000   BatchTime 0.156347   LR 0.010000   
2022-11-04 00:04:28,322 - INFO  - Training [12][   80/  196]   Loss 0.040878   Top1 98.525391   Top5 100.000000   BatchTime 0.146201   LR 0.010000   
2022-11-04 00:04:30,171 - INFO  - Training [12][  100/  196]   Loss 0.039676   Top1 98.585938   Top5 100.000000   BatchTime 0.135447   LR 0.010000   
2022-11-04 00:04:32,223 - INFO  - Training [12][  120/  196]   Loss 0.041051   Top1 98.522135   Top5 100.000000   BatchTime 0.129976   LR 0.010000   
2022-11-04 00:04:34,268 - INFO  - Training [12][  140/  196]   Loss 0.041062   Top1 98.521205   Top5 100.000000   BatchTime 0.126011   LR 0.010000   
2022-11-04 00:04:36,143 - INFO  - Training [12][  160/  196]   Loss 0.041569   Top1 98.481445   Top5 100.000000   BatchTime 0.121981   LR 0.010000   
2022-11-04 00:04:38,396 - INFO  - Training [12][  180/  196]   Loss 0.040796   Top1 98.522135   Top5 100.000000   BatchTime 0.120944   LR 0.010000   
2022-11-04 00:04:40,579 - INFO  - ==> Top1: 98.494    Top5: 100.000    Loss: 0.041

2022-11-04 00:04:40,580 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:04:43,551 - INFO  - Validation [12][   20/   40]   Loss 0.428623   Top1 90.332031   Top5 99.648438   BatchTime 0.148488   
2022-11-04 00:04:44,672 - INFO  - Validation [12][   40/   40]   Loss 0.415409   Top1 90.350000   Top5 99.690000   BatchTime 0.102269   
2022-11-04 00:04:44,942 - INFO  - ==> Top1: 90.350    Top5: 99.690    Loss: 0.415

2022-11-04 00:04:44,988 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:04:44,988 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:04:44,988 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
2022-11-04 00:04:45,100 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:04:45,100 - INFO  - >>>>>>>> Epoch  13
2022-11-04 00:04:45,101 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:04:49,588 - INFO  - Training [13][   20/  196]   Loss 0.033332   Top1 98.691406   Top5 99.980469   BatchTime 0.224345   LR 0.010000   
2022-11-04 00:04:52,073 - INFO  - Training [13][   40/  196]   Loss 0.037839   Top1 98.642578   Top5 99.990234   BatchTime 0.174296   LR 0.010000   
2022-11-04 00:04:54,565 - INFO  - Training [13][   60/  196]   Loss 0.038808   Top1 98.580729   Top5 99.993490   BatchTime 0.157734   LR 0.010000   
2022-11-04 00:04:57,045 - INFO  - Training [13][   80/  196]   Loss 0.039166   Top1 98.559570   Top5 99.995117   BatchTime 0.149298   LR 0.010000   
2022-11-04 00:04:59,528 - INFO  - Training [13][  100/  196]   Loss 0.038971   Top1 98.621094   Top5 99.996094   BatchTime 0.144264   LR 0.010000   
2022-11-04 00:05:02,008 - INFO  - Training [13][  120/  196]   Loss 0.039203   Top1 98.606771   Top5 99.996745   BatchTime 0.140883   LR 0.010000   
2022-11-04 00:05:04,612 - INFO  - Training [13][  140/  196]   Loss 0.038807   Top1 98.627232   Top5 99.997210   BatchTime 0.139361   LR 0.010000   
2022-11-04 00:05:07,085 - INFO  - Training [13][  160/  196]   Loss 0.038491   Top1 98.640137   Top5 99.997559   BatchTime 0.137397   LR 0.010000   
2022-11-04 00:05:09,547 - INFO  - Training [13][  180/  196]   Loss 0.038252   Top1 98.669705   Top5 99.997830   BatchTime 0.135806   LR 0.010000   
2022-11-04 00:05:11,745 - INFO  - ==> Top1: 98.642    Top5: 99.998    Loss: 0.039

2022-11-04 00:05:11,746 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:05:14,744 - INFO  - Validation [13][   20/   40]   Loss 0.432988   Top1 90.214844   Top5 99.531250   BatchTime 0.149827   
2022-11-04 00:05:15,873 - INFO  - Validation [13][   40/   40]   Loss 0.425946   Top1 90.280000   Top5 99.590000   BatchTime 0.103134   
2022-11-04 00:05:16,142 - INFO  - ==> Top1: 90.280    Top5: 99.590    Loss: 0.426

2022-11-04 00:05:16,180 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:05:16,181 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:05:16,181 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 90.400   Top5: 99.550] Sparsity : 0.836
2022-11-04 00:05:16,285 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:05:16,286 - INFO  - >>>>>>>> Epoch  14
2022-11-04 00:05:16,287 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:05:20,406 - INFO  - Training [14][   20/  196]   Loss 0.026767   Top1 99.160156   Top5 100.000000   BatchTime 0.205912   LR 0.010000   
2022-11-04 00:05:22,351 - INFO  - Training [14][   40/  196]   Loss 0.032999   Top1 98.876953   Top5 100.000000   BatchTime 0.151588   LR 0.010000   
2022-11-04 00:05:24,408 - INFO  - Training [14][   60/  196]   Loss 0.034225   Top1 98.808594   Top5 100.000000   BatchTime 0.135347   LR 0.010000   
2022-11-04 00:05:26,419 - INFO  - Training [14][   80/  196]   Loss 0.036427   Top1 98.735352   Top5 100.000000   BatchTime 0.126641   LR 0.010000   
2022-11-04 00:05:28,193 - INFO  - Training [14][  100/  196]   Loss 0.035490   Top1 98.769531   Top5 100.000000   BatchTime 0.119052   LR 0.010000   
2022-11-04 00:05:30,607 - INFO  - Training [14][  120/  196]   Loss 0.035285   Top1 98.776042   Top5 100.000000   BatchTime 0.119330   LR 0.010000   
2022-11-04 00:05:33,080 - INFO  - Training [14][  140/  196]   Loss 0.035746   Top1 98.763951   Top5 100.000000   BatchTime 0.119941   LR 0.010000   
2022-11-04 00:05:35,546 - INFO  - Training [14][  160/  196]   Loss 0.035884   Top1 98.764648   Top5 100.000000   BatchTime 0.120362   LR 0.010000   
2022-11-04 00:05:38,015 - INFO  - Training [14][  180/  196]   Loss 0.036777   Top1 98.719618   Top5 100.000000   BatchTime 0.120705   LR 0.010000   
2022-11-04 00:05:40,207 - INFO  - ==> Top1: 98.728    Top5: 99.998    Loss: 0.037

2022-11-04 00:05:40,208 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:05:43,213 - INFO  - Validation [14][   20/   40]   Loss 0.436463   Top1 90.390625   Top5 99.570312   BatchTime 0.150175   
2022-11-04 00:05:44,356 - INFO  - Validation [14][   40/   40]   Loss 0.424772   Top1 90.620000   Top5 99.650000   BatchTime 0.103667   
2022-11-04 00:05:44,635 - INFO  - ==> Top1: 90.620    Top5: 99.650    Loss: 0.425

2022-11-04 00:05:44,674 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:05:44,675 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:05:44,675 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:05:44,780 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:05:44,780 - INFO  - >>>>>>>> Epoch  15
2022-11-04 00:05:44,781 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:05:49,220 - INFO  - Training [15][   20/  196]   Loss 0.038358   Top1 98.535156   Top5 100.000000   BatchTime 0.221946   LR 0.010000   
2022-11-04 00:05:51,704 - INFO  - Training [15][   40/  196]   Loss 0.037470   Top1 98.593750   Top5 100.000000   BatchTime 0.173073   LR 0.010000   
2022-11-04 00:05:54,199 - INFO  - Training [15][   60/  196]   Loss 0.034578   Top1 98.743490   Top5 100.000000   BatchTime 0.156959   LR 0.010000   
2022-11-04 00:05:56,684 - INFO  - Training [15][   80/  196]   Loss 0.036112   Top1 98.696289   Top5 100.000000   BatchTime 0.148782   LR 0.010000   
2022-11-04 00:05:59,164 - INFO  - Training [15][  100/  196]   Loss 0.037031   Top1 98.675781   Top5 100.000000   BatchTime 0.143818   LR 0.010000   
2022-11-04 00:06:01,645 - INFO  - Training [15][  120/  196]   Loss 0.037828   Top1 98.623047   Top5 100.000000   BatchTime 0.140526   LR 0.010000   
2022-11-04 00:06:04,126 - INFO  - Training [15][  140/  196]   Loss 0.037745   Top1 98.643973   Top5 100.000000   BatchTime 0.138169   LR 0.010000   
2022-11-04 00:06:06,588 - INFO  - Training [15][  160/  196]   Loss 0.038270   Top1 98.632812   Top5 100.000000   BatchTime 0.136290   LR 0.010000   
2022-11-04 00:06:09,047 - INFO  - Training [15][  180/  196]   Loss 0.038713   Top1 98.602431   Top5 100.000000   BatchTime 0.134804   LR 0.010000   
2022-11-04 00:06:11,239 - INFO  - ==> Top1: 98.614    Top5: 100.000    Loss: 0.039

2022-11-04 00:06:11,240 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:06:13,877 - INFO  - Validation [15][   20/   40]   Loss 0.425692   Top1 90.253906   Top5 99.648438   BatchTime 0.131750   
2022-11-04 00:06:14,567 - INFO  - Validation [15][   40/   40]   Loss 0.429446   Top1 90.050000   Top5 99.640000   BatchTime 0.083143   
2022-11-04 00:06:14,839 - INFO  - ==> Top1: 90.050    Top5: 99.640    Loss: 0.429

2022-11-04 00:06:14,864 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:06:14,865 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:06:14,865 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:06:14,957 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:06:14,957 - INFO  - >>>>>>>> Epoch  16
2022-11-04 00:06:14,959 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:06:19,000 - INFO  - Training [16][   20/  196]   Loss 0.030476   Top1 98.828125   Top5 100.000000   BatchTime 0.202029   LR 0.010000   
2022-11-04 00:06:21,151 - INFO  - Training [16][   40/  196]   Loss 0.033811   Top1 98.681641   Top5 100.000000   BatchTime 0.154785   LR 0.010000   
2022-11-04 00:06:23,620 - INFO  - Training [16][   60/  196]   Loss 0.035962   Top1 98.671875   Top5 100.000000   BatchTime 0.144354   LR 0.010000   
2022-11-04 00:06:26,111 - INFO  - Training [16][   80/  196]   Loss 0.034920   Top1 98.745117   Top5 100.000000   BatchTime 0.139394   LR 0.010000   
2022-11-04 00:06:28,586 - INFO  - Training [16][  100/  196]   Loss 0.035958   Top1 98.726562   Top5 100.000000   BatchTime 0.136271   LR 0.010000   
2022-11-04 00:06:31,073 - INFO  - Training [16][  120/  196]   Loss 0.036216   Top1 98.704427   Top5 100.000000   BatchTime 0.134282   LR 0.010000   
2022-11-04 00:06:33,501 - INFO  - Training [16][  140/  196]   Loss 0.036578   Top1 98.691406   Top5 100.000000   BatchTime 0.132442   LR 0.010000   
2022-11-04 00:06:35,967 - INFO  - Training [16][  160/  196]   Loss 0.036382   Top1 98.701172   Top5 100.000000   BatchTime 0.131299   LR 0.010000   
2022-11-04 00:06:38,430 - INFO  - Training [16][  180/  196]   Loss 0.036649   Top1 98.695747   Top5 100.000000   BatchTime 0.130390   LR 0.010000   
2022-11-04 00:06:40,630 - INFO  - ==> Top1: 98.694    Top5: 100.000    Loss: 0.036

2022-11-04 00:06:40,630 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:06:43,620 - INFO  - Validation [16][   20/   40]   Loss 0.440802   Top1 90.019531   Top5 99.550781   BatchTime 0.149444   
2022-11-04 00:06:44,777 - INFO  - Validation [16][   40/   40]   Loss 0.430241   Top1 90.380000   Top5 99.580000   BatchTime 0.103631   
2022-11-04 00:06:45,047 - INFO  - ==> Top1: 90.380    Top5: 99.580    Loss: 0.430

2022-11-04 00:06:45,079 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:06:45,080 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:06:45,080 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 90.430   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:06:45,180 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:06:45,180 - INFO  - >>>>>>>> Epoch  17
2022-11-04 00:06:45,182 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:06:49,646 - INFO  - Training [17][   20/  196]   Loss 0.033036   Top1 98.925781   Top5 100.000000   BatchTime 0.223192   LR 0.010000   
2022-11-04 00:06:52,129 - INFO  - Training [17][   40/  196]   Loss 0.032232   Top1 98.886719   Top5 100.000000   BatchTime 0.173673   LR 0.010000   
2022-11-04 00:06:54,619 - INFO  - Training [17][   60/  196]   Loss 0.033475   Top1 98.815104   Top5 100.000000   BatchTime 0.157280   LR 0.010000   
2022-11-04 00:06:57,127 - INFO  - Training [17][   80/  196]   Loss 0.034508   Top1 98.754883   Top5 100.000000   BatchTime 0.149316   LR 0.010000   
2022-11-04 00:06:59,610 - INFO  - Training [17][  100/  196]   Loss 0.034699   Top1 98.750000   Top5 100.000000   BatchTime 0.144282   LR 0.010000   
2022-11-04 00:07:02,082 - INFO  - Training [17][  120/  196]   Loss 0.034016   Top1 98.798828   Top5 100.000000   BatchTime 0.140834   LR 0.010000   
2022-11-04 00:07:04,562 - INFO  - Training [17][  140/  196]   Loss 0.033562   Top1 98.822545   Top5 100.000000   BatchTime 0.138430   LR 0.010000   
2022-11-04 00:07:06,656 - INFO  - Training [17][  160/  196]   Loss 0.032840   Top1 98.847656   Top5 100.000000   BatchTime 0.134214   LR 0.010000   
2022-11-04 00:07:08,557 - INFO  - Training [17][  180/  196]   Loss 0.033157   Top1 98.841146   Top5 100.000000   BatchTime 0.129860   LR 0.010000   
2022-11-04 00:07:10,516 - INFO  - ==> Top1: 98.858    Top5: 100.000    Loss: 0.033

2022-11-04 00:07:10,517 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:07:13,155 - INFO  - Validation [17][   20/   40]   Loss 0.435134   Top1 90.468750   Top5 99.492188   BatchTime 0.131838   
2022-11-04 00:07:14,140 - INFO  - Validation [17][   40/   40]   Loss 0.425159   Top1 90.500000   Top5 99.540000   BatchTime 0.090543   
2022-11-04 00:07:14,427 - INFO  - ==> Top1: 90.500    Top5: 99.540    Loss: 0.425

2022-11-04 00:07:14,470 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:07:14,471 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:07:14,471 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.500   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:07:14,571 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:07:14,571 - INFO  - >>>>>>>> Epoch  18
2022-11-04 00:07:14,573 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:07:19,013 - INFO  - Training [18][   20/  196]   Loss 0.035123   Top1 98.828125   Top5 100.000000   BatchTime 0.221996   LR 0.010000   
2022-11-04 00:07:21,489 - INFO  - Training [18][   40/  196]   Loss 0.032861   Top1 98.955078   Top5 100.000000   BatchTime 0.172910   LR 0.010000   
2022-11-04 00:07:23,974 - INFO  - Training [18][   60/  196]   Loss 0.030344   Top1 99.010417   Top5 100.000000   BatchTime 0.156690   LR 0.010000   
2022-11-04 00:07:26,446 - INFO  - Training [18][   80/  196]   Loss 0.030320   Top1 98.964844   Top5 100.000000   BatchTime 0.148414   LR 0.010000   
2022-11-04 00:07:28,935 - INFO  - Training [18][  100/  196]   Loss 0.031016   Top1 98.910156   Top5 100.000000   BatchTime 0.143617   LR 0.010000   
2022-11-04 00:07:31,412 - INFO  - Training [18][  120/  196]   Loss 0.032425   Top1 98.867188   Top5 100.000000   BatchTime 0.140320   LR 0.010000   
2022-11-04 00:07:33,885 - INFO  - Training [18][  140/  196]   Loss 0.032790   Top1 98.875558   Top5 100.000000   BatchTime 0.137945   LR 0.010000   
2022-11-04 00:07:36,351 - INFO  - Training [18][  160/  196]   Loss 0.032683   Top1 98.869629   Top5 100.000000   BatchTime 0.136112   LR 0.010000   
2022-11-04 00:07:38,819 - INFO  - Training [18][  180/  196]   Loss 0.033050   Top1 98.865017   Top5 100.000000   BatchTime 0.134697   LR 0.010000   
2022-11-04 00:07:41,009 - INFO  - ==> Top1: 98.886    Top5: 100.000    Loss: 0.033

2022-11-04 00:07:41,010 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:07:43,983 - INFO  - Validation [18][   20/   40]   Loss 0.430705   Top1 90.273438   Top5 99.570312   BatchTime 0.148594   
2022-11-04 00:07:45,124 - INFO  - Validation [18][   40/   40]   Loss 0.427353   Top1 90.420000   Top5 99.620000   BatchTime 0.102815   
2022-11-04 00:07:45,385 - INFO  - ==> Top1: 90.420    Top5: 99.620    Loss: 0.427

2022-11-04 00:07:45,427 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:07:45,427 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:07:45,428 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.500   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:07:45,511 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:07:45,512 - INFO  - >>>>>>>> Epoch  19
2022-11-04 00:07:45,512 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:07:50,007 - INFO  - Training [19][   20/  196]   Loss 0.032786   Top1 98.847656   Top5 100.000000   BatchTime 0.224729   LR 0.010000   
2022-11-04 00:07:52,481 - INFO  - Training [19][   40/  196]   Loss 0.031144   Top1 99.003906   Top5 100.000000   BatchTime 0.174215   LR 0.010000   
2022-11-04 00:07:54,947 - INFO  - Training [19][   60/  196]   Loss 0.030661   Top1 98.945312   Top5 100.000000   BatchTime 0.157242   LR 0.010000   
2022-11-04 00:07:57,412 - INFO  - Training [19][   80/  196]   Loss 0.031023   Top1 98.955078   Top5 100.000000   BatchTime 0.148739   LR 0.010000   
2022-11-04 00:07:59,403 - INFO  - Training [19][  100/  196]   Loss 0.029932   Top1 98.984375   Top5 100.000000   BatchTime 0.138905   LR 0.010000   
2022-11-04 00:08:01,443 - INFO  - Training [19][  120/  196]   Loss 0.030694   Top1 98.961589   Top5 100.000000   BatchTime 0.132750   LR 0.010000   
2022-11-04 00:08:03,479 - INFO  - Training [19][  140/  196]   Loss 0.030465   Top1 98.964844   Top5 100.000000   BatchTime 0.128332   LR 0.010000   
2022-11-04 00:08:05,569 - INFO  - Training [19][  160/  196]   Loss 0.030650   Top1 98.945312   Top5 100.000000   BatchTime 0.125350   LR 0.010000   
2022-11-04 00:08:07,280 - INFO  - Training [19][  180/  196]   Loss 0.031353   Top1 98.923611   Top5 100.000000   BatchTime 0.120929   LR 0.010000   
2022-11-04 00:08:09,516 - INFO  - ==> Top1: 98.906    Top5: 100.000    Loss: 0.032

2022-11-04 00:08:09,517 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:08:12,485 - INFO  - Validation [19][   20/   40]   Loss 0.453067   Top1 90.136719   Top5 99.609375   BatchTime 0.148366   
2022-11-04 00:08:13,596 - INFO  - Validation [19][   40/   40]   Loss 0.437638   Top1 90.290000   Top5 99.650000   BatchTime 0.101955   
2022-11-04 00:08:13,882 - INFO  - ==> Top1: 90.290    Top5: 99.650    Loss: 0.438

2022-11-04 00:08:13,912 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:08:13,913 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:08:13,913 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.500   Top5: 99.540] Sparsity : 0.836
2022-11-04 00:08:14,003 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:08:14,003 - INFO  - >>>>>>>> Epoch  20
2022-11-04 00:08:14,005 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:08:18,466 - INFO  - Training [20][   20/  196]   Loss 0.031859   Top1 98.945312   Top5 100.000000   BatchTime 0.223048   LR 0.001000   
2022-11-04 00:08:20,956 - INFO  - Training [20][   40/  196]   Loss 0.035630   Top1 98.828125   Top5 100.000000   BatchTime 0.173786   LR 0.001000   
2022-11-04 00:08:23,433 - INFO  - Training [20][   60/  196]   Loss 0.036671   Top1 98.763021   Top5 100.000000   BatchTime 0.157138   LR 0.001000   
2022-11-04 00:08:25,878 - INFO  - Training [20][   80/  196]   Loss 0.036485   Top1 98.774414   Top5 100.000000   BatchTime 0.148417   LR 0.001000   
2022-11-04 00:08:28,368 - INFO  - Training [20][  100/  196]   Loss 0.033892   Top1 98.875000   Top5 100.000000   BatchTime 0.143631   LR 0.001000   
2022-11-04 00:08:30,849 - INFO  - Training [20][  120/  196]   Loss 0.034445   Top1 98.873698   Top5 100.000000   BatchTime 0.140365   LR 0.001000   
2022-11-04 00:08:33,323 - INFO  - Training [20][  140/  196]   Loss 0.034191   Top1 98.867188   Top5 100.000000   BatchTime 0.137981   LR 0.001000   
2022-11-04 00:08:35,782 - INFO  - Training [20][  160/  196]   Loss 0.034312   Top1 98.872070   Top5 100.000000   BatchTime 0.136102   LR 0.001000   
2022-11-04 00:08:38,251 - INFO  - Training [20][  180/  196]   Loss 0.034106   Top1 98.867188   Top5 100.000000   BatchTime 0.134697   LR 0.001000   
2022-11-04 00:08:40,451 - INFO  - ==> Top1: 98.864    Top5: 100.000    Loss: 0.034

2022-11-04 00:08:40,452 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:08:43,477 - INFO  - Validation [20][   20/   40]   Loss 0.434568   Top1 90.371094   Top5 99.628906   BatchTime 0.151162   
2022-11-04 00:08:44,606 - INFO  - Validation [20][   40/   40]   Loss 0.422013   Top1 90.510000   Top5 99.620000   BatchTime 0.103815   
2022-11-04 00:08:44,860 - INFO  - ==> Top1: 90.510    Top5: 99.620    Loss: 0.422

2022-11-04 00:08:44,891 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:08:44,892 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:08:44,892 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.510   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:08:44,965 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:08:44,965 - INFO  - >>>>>>>> Epoch  21
2022-11-04 00:08:44,966 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:08:49,393 - INFO  - Training [21][   20/  196]   Loss 0.025494   Top1 99.257812   Top5 100.000000   BatchTime 0.221326   LR 0.001000   
2022-11-04 00:08:51,345 - INFO  - Training [21][   40/  196]   Loss 0.027727   Top1 99.062500   Top5 100.000000   BatchTime 0.159468   LR 0.001000   
2022-11-04 00:08:53,364 - INFO  - Training [21][   60/  196]   Loss 0.028431   Top1 98.977865   Top5 100.000000   BatchTime 0.139952   LR 0.001000   
2022-11-04 00:08:55,387 - INFO  - Training [21][   80/  196]   Loss 0.028309   Top1 98.964844   Top5 100.000000   BatchTime 0.130262   LR 0.001000   
2022-11-04 00:08:57,469 - INFO  - Training [21][  100/  196]   Loss 0.027885   Top1 98.980469   Top5 100.000000   BatchTime 0.125019   LR 0.001000   
2022-11-04 00:08:59,363 - INFO  - Training [21][  120/  196]   Loss 0.027511   Top1 99.003906   Top5 100.000000   BatchTime 0.119967   LR 0.001000   
2022-11-04 00:09:01,854 - INFO  - Training [21][  140/  196]   Loss 0.027789   Top1 98.984375   Top5 100.000000   BatchTime 0.120622   LR 0.001000   
2022-11-04 00:09:04,320 - INFO  - Training [21][  160/  196]   Loss 0.027613   Top1 99.006348   Top5 100.000000   BatchTime 0.120958   LR 0.001000   
2022-11-04 00:09:06,787 - INFO  - Training [21][  180/  196]   Loss 0.027383   Top1 99.012587   Top5 100.000000   BatchTime 0.121222   LR 0.001000   
2022-11-04 00:09:08,982 - INFO  - ==> Top1: 99.016    Top5: 100.000    Loss: 0.027

2022-11-04 00:09:08,983 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:09:11,940 - INFO  - Validation [21][   20/   40]   Loss 0.430813   Top1 90.527344   Top5 99.628906   BatchTime 0.147740   
2022-11-04 00:09:13,034 - INFO  - Validation [21][   40/   40]   Loss 0.423175   Top1 90.530000   Top5 99.650000   BatchTime 0.101220   
2022-11-04 00:09:13,297 - INFO  - ==> Top1: 90.530    Top5: 99.650    Loss: 0.423

2022-11-04 00:09:13,332 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:09:13,333 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:09:13,333 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 90.530   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:09:13,427 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:09:13,428 - INFO  - >>>>>>>> Epoch  22
2022-11-04 00:09:13,429 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:09:17,932 - INFO  - Training [22][   20/  196]   Loss 0.024027   Top1 99.277344   Top5 100.000000   BatchTime 0.225154   LR 0.001000   
2022-11-04 00:09:20,423 - INFO  - Training [22][   40/  196]   Loss 0.023991   Top1 99.208984   Top5 100.000000   BatchTime 0.174843   LR 0.001000   
2022-11-04 00:09:22,993 - INFO  - Training [22][   60/  196]   Loss 0.025725   Top1 99.147135   Top5 100.000000   BatchTime 0.159385   LR 0.001000   
2022-11-04 00:09:25,468 - INFO  - Training [22][   80/  196]   Loss 0.026084   Top1 99.116211   Top5 100.000000   BatchTime 0.150475   LR 0.001000   
2022-11-04 00:09:27,940 - INFO  - Training [22][  100/  196]   Loss 0.027392   Top1 99.042969   Top5 100.000000   BatchTime 0.145101   LR 0.001000   
2022-11-04 00:09:30,423 - INFO  - Training [22][  120/  196]   Loss 0.027030   Top1 99.082031   Top5 100.000000   BatchTime 0.141614   LR 0.001000   
2022-11-04 00:09:32,894 - INFO  - Training [22][  140/  196]   Loss 0.027743   Top1 99.059710   Top5 100.000000   BatchTime 0.139033   LR 0.001000   
2022-11-04 00:09:35,366 - INFO  - Training [22][  160/  196]   Loss 0.027559   Top1 99.074707   Top5 100.000000   BatchTime 0.137102   LR 0.001000   
2022-11-04 00:09:37,838 - INFO  - Training [22][  180/  196]   Loss 0.027265   Top1 99.071181   Top5 100.000000   BatchTime 0.135602   LR 0.001000   
2022-11-04 00:09:40,008 - INFO  - ==> Top1: 99.056    Top5: 100.000    Loss: 0.028

2022-11-04 00:09:40,009 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:09:42,904 - INFO  - Validation [22][   20/   40]   Loss 0.438004   Top1 90.644531   Top5 99.609375   BatchTime 0.144633   
2022-11-04 00:09:43,746 - INFO  - Validation [22][   40/   40]   Loss 0.423044   Top1 90.690000   Top5 99.660000   BatchTime 0.093391   
2022-11-04 00:09:44,019 - INFO  - ==> Top1: 90.690    Top5: 99.660    Loss: 0.423

2022-11-04 00:09:44,041 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:09:44,041 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 90.690   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:09:44,042 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 90.620   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:09:44,130 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:09:44,130 - INFO  - >>>>>>>> Epoch  23
2022-11-04 00:09:44,131 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:09:48,252 - INFO  - Training [23][   20/  196]   Loss 0.022296   Top1 99.316406   Top5 100.000000   BatchTime 0.206012   LR 0.001000   
2022-11-04 00:09:50,262 - INFO  - Training [23][   40/  196]   Loss 0.025112   Top1 99.130859   Top5 100.000000   BatchTime 0.153257   LR 0.001000   
2022-11-04 00:09:52,272 - INFO  - Training [23][   60/  196]   Loss 0.024185   Top1 99.179688   Top5 100.000000   BatchTime 0.135669   LR 0.001000   
2022-11-04 00:09:54,752 - INFO  - Training [23][   80/  196]   Loss 0.025129   Top1 99.165039   Top5 100.000000   BatchTime 0.132758   LR 0.001000   
2022-11-04 00:09:57,266 - INFO  - Training [23][  100/  196]   Loss 0.025754   Top1 99.101562   Top5 100.000000   BatchTime 0.131341   LR 0.001000   
2022-11-04 00:09:59,758 - INFO  - Training [23][  120/  196]   Loss 0.025895   Top1 99.121094   Top5 100.000000   BatchTime 0.130214   LR 0.001000   
2022-11-04 00:10:02,240 - INFO  - Training [23][  140/  196]   Loss 0.025973   Top1 99.129464   Top5 100.000000   BatchTime 0.129345   LR 0.001000   
2022-11-04 00:10:04,707 - INFO  - Training [23][  160/  196]   Loss 0.026132   Top1 99.130859   Top5 100.000000   BatchTime 0.128596   LR 0.001000   
2022-11-04 00:10:07,170 - INFO  - Training [23][  180/  196]   Loss 0.026771   Top1 99.105903   Top5 100.000000   BatchTime 0.127991   LR 0.001000   
2022-11-04 00:10:09,356 - INFO  - ==> Top1: 99.098    Top5: 100.000    Loss: 0.027

2022-11-04 00:10:09,357 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:10:12,331 - INFO  - Validation [23][   20/   40]   Loss 0.424975   Top1 90.683594   Top5 99.511719   BatchTime 0.148653   
2022-11-04 00:10:13,436 - INFO  - Validation [23][   40/   40]   Loss 0.417675   Top1 90.880000   Top5 99.590000   BatchTime 0.101951   
2022-11-04 00:10:13,712 - INFO  - ==> Top1: 90.880    Top5: 99.590    Loss: 0.418

2022-11-04 00:10:13,756 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:10:13,757 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:10:13,757 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 90.690   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:10:13,959 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:10:14,124 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:10:14,124 - INFO  - >>>>>>>> Epoch  24
2022-11-04 00:10:14,125 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:10:18,603 - INFO  - Training [24][   20/  196]   Loss 0.023546   Top1 99.296875   Top5 100.000000   BatchTime 0.223852   LR 0.001000   
2022-11-04 00:10:21,103 - INFO  - Training [24][   40/  196]   Loss 0.024920   Top1 99.199219   Top5 100.000000   BatchTime 0.174445   LR 0.001000   
2022-11-04 00:10:23,589 - INFO  - Training [24][   60/  196]   Loss 0.026141   Top1 99.147135   Top5 100.000000   BatchTime 0.157721   LR 0.001000   
2022-11-04 00:10:26,066 - INFO  - Training [24][   80/  196]   Loss 0.025810   Top1 99.140625   Top5 100.000000   BatchTime 0.149255   LR 0.001000   
2022-11-04 00:10:28,552 - INFO  - Training [24][  100/  196]   Loss 0.026283   Top1 99.125000   Top5 100.000000   BatchTime 0.144257   LR 0.001000   
2022-11-04 00:10:31,034 - INFO  - Training [24][  120/  196]   Loss 0.026232   Top1 99.130859   Top5 99.996745   BatchTime 0.140903   LR 0.001000   
2022-11-04 00:10:33,502 - INFO  - Training [24][  140/  196]   Loss 0.026249   Top1 99.121094   Top5 99.994420   BatchTime 0.138398   LR 0.001000   
2022-11-04 00:10:35,956 - INFO  - Training [24][  160/  196]   Loss 0.026110   Top1 99.147949   Top5 99.995117   BatchTime 0.136439   LR 0.001000   
2022-11-04 00:10:38,153 - INFO  - Training [24][  180/  196]   Loss 0.026310   Top1 99.136285   Top5 99.995660   BatchTime 0.133482   LR 0.001000   
2022-11-04 00:10:39,916 - INFO  - ==> Top1: 99.150    Top5: 99.996    Loss: 0.026

2022-11-04 00:10:39,917 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:10:42,653 - INFO  - Validation [24][   20/   40]   Loss 0.432468   Top1 90.644531   Top5 99.550781   BatchTime 0.136731   
2022-11-04 00:10:43,340 - INFO  - Validation [24][   40/   40]   Loss 0.421676   Top1 90.710000   Top5 99.580000   BatchTime 0.085564   
2022-11-04 00:10:43,623 - INFO  - ==> Top1: 90.710    Top5: 99.580    Loss: 0.422

2022-11-04 00:10:43,647 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:10:43,648 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.710   Top5: 99.580] Sparsity : 0.836
2022-11-04 00:10:43,648 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 90.710   Top5: 99.510] Sparsity : 0.836
2022-11-04 00:10:43,744 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:10:43,745 - INFO  - >>>>>>>> Epoch  25
2022-11-04 00:10:43,746 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:10:48,233 - INFO  - Training [25][   20/  196]   Loss 0.028315   Top1 98.984375   Top5 100.000000   BatchTime 0.224303   LR 0.001000   
2022-11-04 00:10:50,715 - INFO  - Training [25][   40/  196]   Loss 0.029280   Top1 99.033203   Top5 100.000000   BatchTime 0.174207   LR 0.001000   
2022-11-04 00:10:53,214 - INFO  - Training [25][   60/  196]   Loss 0.028062   Top1 99.055990   Top5 100.000000   BatchTime 0.157786   LR 0.001000   
2022-11-04 00:10:55,704 - INFO  - Training [25][   80/  196]   Loss 0.028766   Top1 99.013672   Top5 100.000000   BatchTime 0.149471   LR 0.001000   
2022-11-04 00:10:58,191 - INFO  - Training [25][  100/  196]   Loss 0.028324   Top1 99.031250   Top5 100.000000   BatchTime 0.144446   LR 0.001000   
2022-11-04 00:11:00,686 - INFO  - Training [25][  120/  196]   Loss 0.027851   Top1 99.062500   Top5 100.000000   BatchTime 0.141158   LR 0.001000   
2022-11-04 00:11:03,164 - INFO  - Training [25][  140/  196]   Loss 0.027428   Top1 99.076451   Top5 100.000000   BatchTime 0.138693   LR 0.001000   
2022-11-04 00:11:05,625 - INFO  - Training [25][  160/  196]   Loss 0.027279   Top1 99.077148   Top5 100.000000   BatchTime 0.136738   LR 0.001000   
2022-11-04 00:11:08,088 - INFO  - Training [25][  180/  196]   Loss 0.027223   Top1 99.092882   Top5 100.000000   BatchTime 0.135230   LR 0.001000   
2022-11-04 00:11:10,283 - INFO  - ==> Top1: 99.102    Top5: 100.000    Loss: 0.027

2022-11-04 00:11:10,284 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:11:13,264 - INFO  - Validation [25][   20/   40]   Loss 0.429012   Top1 90.839844   Top5 99.570312   BatchTime 0.148978   
2022-11-04 00:11:14,430 - INFO  - Validation [25][   40/   40]   Loss 0.417949   Top1 90.830000   Top5 99.620000   BatchTime 0.103640   
2022-11-04 00:11:14,714 - INFO  - ==> Top1: 90.830    Top5: 99.620    Loss: 0.418

2022-11-04 00:11:14,759 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:11:14,760 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.830   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:11:14,760 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.710   Top5: 99.580] Sparsity : 0.836
2022-11-04 00:11:14,840 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:11:14,840 - INFO  - >>>>>>>> Epoch  26
2022-11-04 00:11:14,842 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:11:19,328 - INFO  - Training [26][   20/  196]   Loss 0.023571   Top1 99.277344   Top5 100.000000   BatchTime 0.224286   LR 0.001000   
2022-11-04 00:11:21,819 - INFO  - Training [26][   40/  196]   Loss 0.022979   Top1 99.287109   Top5 100.000000   BatchTime 0.174414   LR 0.001000   
2022-11-04 00:11:24,436 - INFO  - Training [26][   60/  196]   Loss 0.024033   Top1 99.244792   Top5 100.000000   BatchTime 0.159906   LR 0.001000   
2022-11-04 00:11:26,902 - INFO  - Training [26][   80/  196]   Loss 0.025453   Top1 99.189453   Top5 100.000000   BatchTime 0.150755   LR 0.001000   
2022-11-04 00:11:29,344 - INFO  - Training [26][  100/  196]   Loss 0.025792   Top1 99.167969   Top5 100.000000   BatchTime 0.145023   LR 0.001000   
2022-11-04 00:11:31,183 - INFO  - Training [26][  120/  196]   Loss 0.026210   Top1 99.160156   Top5 100.000000   BatchTime 0.136171   LR 0.001000   
2022-11-04 00:11:33,228 - INFO  - Training [26][  140/  196]   Loss 0.026171   Top1 99.160156   Top5 100.000000   BatchTime 0.131325   LR 0.001000   
2022-11-04 00:11:35,258 - INFO  - Training [26][  160/  196]   Loss 0.025900   Top1 99.152832   Top5 100.000000   BatchTime 0.127598   LR 0.001000   
2022-11-04 00:11:37,167 - INFO  - Training [26][  180/  196]   Loss 0.026018   Top1 99.140625   Top5 100.000000   BatchTime 0.124028   LR 0.001000   
2022-11-04 00:11:39,037 - INFO  - ==> Top1: 99.130    Top5: 100.000    Loss: 0.026

2022-11-04 00:11:39,038 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:11:42,040 - INFO  - Validation [26][   20/   40]   Loss 0.434593   Top1 90.683594   Top5 99.589844   BatchTime 0.149992   
2022-11-04 00:11:43,135 - INFO  - Validation [26][   40/   40]   Loss 0.423876   Top1 90.790000   Top5 99.640000   BatchTime 0.102378   
2022-11-04 00:11:43,404 - INFO  - ==> Top1: 90.790    Top5: 99.640    Loss: 0.424

2022-11-04 00:11:43,440 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:11:43,440 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.830   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:11:43,440 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.790   Top5: 99.640] Sparsity : 0.836
2022-11-04 00:11:43,549 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:11:43,549 - INFO  - >>>>>>>> Epoch  27
2022-11-04 00:11:43,550 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:11:47,971 - INFO  - Training [27][   20/  196]   Loss 0.027646   Top1 99.082031   Top5 100.000000   BatchTime 0.221011   LR 0.001000   
2022-11-04 00:11:50,460 - INFO  - Training [27][   40/  196]   Loss 0.024035   Top1 99.208984   Top5 100.000000   BatchTime 0.172741   LR 0.001000   
2022-11-04 00:11:52,946 - INFO  - Training [27][   60/  196]   Loss 0.025841   Top1 99.114583   Top5 100.000000   BatchTime 0.156583   LR 0.001000   
2022-11-04 00:11:55,425 - INFO  - Training [27][   80/  196]   Loss 0.025438   Top1 99.145508   Top5 100.000000   BatchTime 0.148427   LR 0.001000   
2022-11-04 00:11:57,899 - INFO  - Training [27][  100/  196]   Loss 0.025392   Top1 99.152344   Top5 100.000000   BatchTime 0.143480   LR 0.001000   
2022-11-04 00:12:00,374 - INFO  - Training [27][  120/  196]   Loss 0.025566   Top1 99.134115   Top5 100.000000   BatchTime 0.140196   LR 0.001000   
2022-11-04 00:12:02,845 - INFO  - Training [27][  140/  196]   Loss 0.025043   Top1 99.148996   Top5 100.000000   BatchTime 0.137818   LR 0.001000   
2022-11-04 00:12:05,306 - INFO  - Training [27][  160/  196]   Loss 0.025750   Top1 99.128418   Top5 100.000000   BatchTime 0.135969   LR 0.001000   
2022-11-04 00:12:07,770 - INFO  - Training [27][  180/  196]   Loss 0.025588   Top1 99.142795   Top5 100.000000   BatchTime 0.134548   LR 0.001000   
2022-11-04 00:12:09,978 - INFO  - ==> Top1: 99.122    Top5: 100.000    Loss: 0.026

2022-11-04 00:12:09,978 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:12:12,937 - INFO  - Validation [27][   20/   40]   Loss 0.434353   Top1 90.898438   Top5 99.550781   BatchTime 0.147853   
2022-11-04 00:12:14,084 - INFO  - Validation [27][   40/   40]   Loss 0.423590   Top1 90.910000   Top5 99.620000   BatchTime 0.102594   
2022-11-04 00:12:14,342 - INFO  - ==> Top1: 90.910    Top5: 99.620    Loss: 0.424

2022-11-04 00:12:14,372 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:12:14,373 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:12:14,373 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.830   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:12:14,572 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:12:14,731 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:12:14,731 - INFO  - >>>>>>>> Epoch  28
2022-11-04 00:12:14,732 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:12:19,182 - INFO  - Training [28][   20/  196]   Loss 0.023370   Top1 99.296875   Top5 100.000000   BatchTime 0.222496   LR 0.001000   
2022-11-04 00:12:21,483 - INFO  - Training [28][   40/  196]   Loss 0.022784   Top1 99.316406   Top5 100.000000   BatchTime 0.168778   LR 0.001000   
2022-11-04 00:12:23,402 - INFO  - Training [28][   60/  196]   Loss 0.022711   Top1 99.303385   Top5 100.000000   BatchTime 0.144499   LR 0.001000   
2022-11-04 00:12:25,459 - INFO  - Training [28][   80/  196]   Loss 0.024029   Top1 99.223633   Top5 100.000000   BatchTime 0.134088   LR 0.001000   
2022-11-04 00:12:27,515 - INFO  - Training [28][  100/  196]   Loss 0.025034   Top1 99.187500   Top5 100.000000   BatchTime 0.127827   LR 0.001000   
2022-11-04 00:12:29,346 - INFO  - Training [28][  120/  196]   Loss 0.025368   Top1 99.176432   Top5 100.000000   BatchTime 0.121785   LR 0.001000   
2022-11-04 00:12:31,661 - INFO  - Training [28][  140/  196]   Loss 0.025761   Top1 99.146205   Top5 100.000000   BatchTime 0.120922   LR 0.001000   
2022-11-04 00:12:34,122 - INFO  - Training [28][  160/  196]   Loss 0.025241   Top1 99.160156   Top5 100.000000   BatchTime 0.121185   LR 0.001000   
2022-11-04 00:12:36,593 - INFO  - Training [28][  180/  196]   Loss 0.025824   Top1 99.136285   Top5 100.000000   BatchTime 0.121448   LR 0.001000   
2022-11-04 00:12:38,804 - INFO  - ==> Top1: 99.130    Top5: 100.000    Loss: 0.026

2022-11-04 00:12:38,804 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:12:41,752 - INFO  - Validation [28][   20/   40]   Loss 0.433596   Top1 90.761719   Top5 99.609375   BatchTime 0.147320   
2022-11-04 00:12:42,866 - INFO  - Validation [28][   40/   40]   Loss 0.421149   Top1 90.840000   Top5 99.630000   BatchTime 0.101501   
2022-11-04 00:12:43,117 - INFO  - ==> Top1: 90.840    Top5: 99.630    Loss: 0.421

2022-11-04 00:12:43,155 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:12:43,156 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:12:43,156 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.840   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:12:43,253 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:12:43,253 - INFO  - >>>>>>>> Epoch  29
2022-11-04 00:12:43,255 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:12:47,745 - INFO  - Training [29][   20/  196]   Loss 0.024455   Top1 99.160156   Top5 100.000000   BatchTime 0.224505   LR 0.001000   
2022-11-04 00:12:50,241 - INFO  - Training [29][   40/  196]   Loss 0.024652   Top1 99.072266   Top5 100.000000   BatchTime 0.174664   LR 0.001000   
2022-11-04 00:12:52,733 - INFO  - Training [29][   60/  196]   Loss 0.022792   Top1 99.166667   Top5 100.000000   BatchTime 0.157966   LR 0.001000   
2022-11-04 00:12:55,212 - INFO  - Training [29][   80/  196]   Loss 0.022357   Top1 99.194336   Top5 100.000000   BatchTime 0.149467   LR 0.001000   
2022-11-04 00:12:57,683 - INFO  - Training [29][  100/  196]   Loss 0.023028   Top1 99.179688   Top5 100.000000   BatchTime 0.144279   LR 0.001000   
2022-11-04 00:13:00,166 - INFO  - Training [29][  120/  196]   Loss 0.022641   Top1 99.205729   Top5 100.000000   BatchTime 0.140928   LR 0.001000   
2022-11-04 00:13:02,640 - INFO  - Training [29][  140/  196]   Loss 0.022840   Top1 99.196429   Top5 100.000000   BatchTime 0.138467   LR 0.001000   
2022-11-04 00:13:05,099 - INFO  - Training [29][  160/  196]   Loss 0.022867   Top1 99.191895   Top5 100.000000   BatchTime 0.136527   LR 0.001000   
2022-11-04 00:13:07,557 - INFO  - Training [29][  180/  196]   Loss 0.022928   Top1 99.184028   Top5 100.000000   BatchTime 0.135010   LR 0.001000   
2022-11-04 00:13:09,736 - INFO  - ==> Top1: 99.186    Top5: 100.000    Loss: 0.023

2022-11-04 00:13:09,737 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:13:12,688 - INFO  - Validation [29][   20/   40]   Loss 0.433929   Top1 90.625000   Top5 99.628906   BatchTime 0.147490   
2022-11-04 00:13:13,887 - INFO  - Validation [29][   40/   40]   Loss 0.422932   Top1 90.790000   Top5 99.660000   BatchTime 0.103726   
2022-11-04 00:13:14,187 - INFO  - ==> Top1: 90.790    Top5: 99.660    Loss: 0.423

2022-11-04 00:13:14,210 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:13:14,211 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:13:14,211 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.840   Top5: 99.630] Sparsity : 0.836
2022-11-04 00:13:14,320 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:13:14,320 - INFO  - >>>>>>>> Epoch  30
2022-11-04 00:13:14,321 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:13:18,427 - INFO  - Training [30][   20/  196]   Loss 0.024693   Top1 99.042969   Top5 100.000000   BatchTime 0.205303   LR 0.001000   
2022-11-04 00:13:20,633 - INFO  - Training [30][   40/  196]   Loss 0.022680   Top1 99.238281   Top5 100.000000   BatchTime 0.157792   LR 0.001000   
2022-11-04 00:13:22,384 - INFO  - Training [30][   60/  196]   Loss 0.023471   Top1 99.212240   Top5 100.000000   BatchTime 0.134386   LR 0.001000   
2022-11-04 00:13:24,847 - INFO  - Training [30][   80/  196]   Loss 0.023217   Top1 99.208984   Top5 100.000000   BatchTime 0.131577   LR 0.001000   
2022-11-04 00:13:27,337 - INFO  - Training [30][  100/  196]   Loss 0.024321   Top1 99.171875   Top5 99.996094   BatchTime 0.130158   LR 0.001000   
2022-11-04 00:13:29,821 - INFO  - Training [30][  120/  196]   Loss 0.024581   Top1 99.143880   Top5 99.996745   BatchTime 0.129162   LR 0.001000   
2022-11-04 00:13:32,309 - INFO  - Training [30][  140/  196]   Loss 0.024793   Top1 99.135045   Top5 99.997210   BatchTime 0.128485   LR 0.001000   
2022-11-04 00:13:34,784 - INFO  - Training [30][  160/  196]   Loss 0.024781   Top1 99.130859   Top5 99.997559   BatchTime 0.127891   LR 0.001000   
2022-11-04 00:13:37,259 - INFO  - Training [30][  180/  196]   Loss 0.024848   Top1 99.118924   Top5 99.997830   BatchTime 0.127431   LR 0.001000   
2022-11-04 00:13:39,453 - INFO  - ==> Top1: 99.128    Top5: 99.998    Loss: 0.024

2022-11-04 00:13:39,454 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:13:42,409 - INFO  - Validation [30][   20/   40]   Loss 0.435921   Top1 90.839844   Top5 99.628906   BatchTime 0.147695   
2022-11-04 00:13:43,545 - INFO  - Validation [30][   40/   40]   Loss 0.426439   Top1 90.930000   Top5 99.680000   BatchTime 0.102230   
2022-11-04 00:13:43,816 - INFO  - ==> Top1: 90.930    Top5: 99.680    Loss: 0.426

2022-11-04 00:13:43,858 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:13:43,858 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:13:43,858 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 90.880   Top5: 99.590] Sparsity : 0.836
2022-11-04 00:13:44,021 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:13:44,171 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:13:44,171 - INFO  - >>>>>>>> Epoch  31
2022-11-04 00:13:44,172 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:13:48,651 - INFO  - Training [31][   20/  196]   Loss 0.025723   Top1 99.121094   Top5 100.000000   BatchTime 0.223949   LR 0.001000   
2022-11-04 00:13:51,154 - INFO  - Training [31][   40/  196]   Loss 0.024384   Top1 99.218750   Top5 100.000000   BatchTime 0.174540   LR 0.001000   
2022-11-04 00:13:53,640 - INFO  - Training [31][   60/  196]   Loss 0.023272   Top1 99.277344   Top5 100.000000   BatchTime 0.157803   LR 0.001000   
2022-11-04 00:13:56,113 - INFO  - Training [31][   80/  196]   Loss 0.023765   Top1 99.267578   Top5 100.000000   BatchTime 0.149253   LR 0.001000   
2022-11-04 00:13:58,585 - INFO  - Training [31][  100/  196]   Loss 0.023770   Top1 99.230469   Top5 100.000000   BatchTime 0.144123   LR 0.001000   
2022-11-04 00:14:00,993 - INFO  - Training [31][  120/  196]   Loss 0.024325   Top1 99.208984   Top5 100.000000   BatchTime 0.140169   LR 0.001000   
2022-11-04 00:14:03,478 - INFO  - Training [31][  140/  196]   Loss 0.024426   Top1 99.221540   Top5 100.000000   BatchTime 0.137893   LR 0.001000   
2022-11-04 00:14:05,932 - INFO  - Training [31][  160/  196]   Loss 0.024312   Top1 99.208984   Top5 100.000000   BatchTime 0.135994   LR 0.001000   
2022-11-04 00:14:08,385 - INFO  - Training [31][  180/  196]   Loss 0.024724   Top1 99.197049   Top5 100.000000   BatchTime 0.134513   LR 0.001000   
2022-11-04 00:14:10,082 - INFO  - ==> Top1: 99.194    Top5: 100.000    Loss: 0.025

2022-11-04 00:14:10,083 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:14:12,839 - INFO  - Validation [31][   20/   40]   Loss 0.428663   Top1 91.015625   Top5 99.589844   BatchTime 0.137734   
2022-11-04 00:14:13,724 - INFO  - Validation [31][   40/   40]   Loss 0.421103   Top1 90.970000   Top5 99.660000   BatchTime 0.090999   
2022-11-04 00:14:13,978 - INFO  - ==> Top1: 90.970    Top5: 99.660    Loss: 0.421

2022-11-04 00:14:14,004 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:14:14,005 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:14:14,005 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.910   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:14:14,170 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:14:14,325 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:14:14,325 - INFO  - >>>>>>>> Epoch  32
2022-11-04 00:14:14,326 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:14:18,956 - INFO  - Training [32][   20/  196]   Loss 0.021745   Top1 99.257812   Top5 100.000000   BatchTime 0.231487   LR 0.001000   
2022-11-04 00:14:21,439 - INFO  - Training [32][   40/  196]   Loss 0.021606   Top1 99.306641   Top5 100.000000   BatchTime 0.177807   LR 0.001000   
2022-11-04 00:14:23,932 - INFO  - Training [32][   60/  196]   Loss 0.021542   Top1 99.290365   Top5 100.000000   BatchTime 0.160095   LR 0.001000   
2022-11-04 00:14:26,437 - INFO  - Training [32][   80/  196]   Loss 0.022124   Top1 99.252930   Top5 100.000000   BatchTime 0.151375   LR 0.001000   
2022-11-04 00:14:28,918 - INFO  - Training [32][  100/  196]   Loss 0.022851   Top1 99.214844   Top5 100.000000   BatchTime 0.145916   LR 0.001000   
2022-11-04 00:14:31,407 - INFO  - Training [32][  120/  196]   Loss 0.023436   Top1 99.195964   Top5 100.000000   BatchTime 0.142334   LR 0.001000   
2022-11-04 00:14:33,888 - INFO  - Training [32][  140/  196]   Loss 0.023588   Top1 99.210379   Top5 100.000000   BatchTime 0.139721   LR 0.001000   
2022-11-04 00:14:36,355 - INFO  - Training [32][  160/  196]   Loss 0.023639   Top1 99.206543   Top5 100.000000   BatchTime 0.137674   LR 0.001000   
2022-11-04 00:14:38,819 - INFO  - Training [32][  180/  196]   Loss 0.023419   Top1 99.207899   Top5 100.000000   BatchTime 0.136068   LR 0.001000   
2022-11-04 00:14:41,011 - INFO  - ==> Top1: 99.208    Top5: 100.000    Loss: 0.023

2022-11-04 00:14:41,012 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:14:43,982 - INFO  - Validation [32][   20/   40]   Loss 0.441955   Top1 90.722656   Top5 99.570312   BatchTime 0.148429   
2022-11-04 00:14:45,116 - INFO  - Validation [32][   40/   40]   Loss 0.425704   Top1 90.930000   Top5 99.640000   BatchTime 0.102564   
2022-11-04 00:14:45,388 - INFO  - ==> Top1: 90.930    Top5: 99.640    Loss: 0.426

2022-11-04 00:14:45,417 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:14:45,418 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:14:45,418 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.930   Top5: 99.640] Sparsity : 0.836
2022-11-04 00:14:45,523 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:14:45,523 - INFO  - >>>>>>>> Epoch  33
2022-11-04 00:14:45,524 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:14:49,984 - INFO  - Training [33][   20/  196]   Loss 0.022023   Top1 99.355469   Top5 100.000000   BatchTime 0.222971   LR 0.001000   
2022-11-04 00:14:52,471 - INFO  - Training [33][   40/  196]   Loss 0.020904   Top1 99.394531   Top5 100.000000   BatchTime 0.173656   LR 0.001000   
2022-11-04 00:14:54,932 - INFO  - Training [33][   60/  196]   Loss 0.022407   Top1 99.296875   Top5 100.000000   BatchTime 0.156792   LR 0.001000   
2022-11-04 00:14:57,418 - INFO  - Training [33][   80/  196]   Loss 0.022902   Top1 99.277344   Top5 100.000000   BatchTime 0.148668   LR 0.001000   
2022-11-04 00:14:59,888 - INFO  - Training [33][  100/  196]   Loss 0.023606   Top1 99.234375   Top5 100.000000   BatchTime 0.143632   LR 0.001000   
2022-11-04 00:15:02,044 - INFO  - Training [33][  120/  196]   Loss 0.023512   Top1 99.225260   Top5 100.000000   BatchTime 0.137658   LR 0.001000   
2022-11-04 00:15:03,977 - INFO  - Training [33][  140/  196]   Loss 0.022644   Top1 99.266183   Top5 100.000000   BatchTime 0.131805   LR 0.001000   
2022-11-04 00:15:05,984 - INFO  - Training [33][  160/  196]   Loss 0.022950   Top1 99.245605   Top5 100.000000   BatchTime 0.127868   LR 0.001000   
2022-11-04 00:15:07,983 - INFO  - Training [33][  180/  196]   Loss 0.023299   Top1 99.240451   Top5 100.000000   BatchTime 0.124766   LR 0.001000   
2022-11-04 00:15:09,714 - INFO  - ==> Top1: 99.246    Top5: 100.000    Loss: 0.023

2022-11-04 00:15:09,715 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:15:12,718 - INFO  - Validation [33][   20/   40]   Loss 0.429903   Top1 90.839844   Top5 99.531250   BatchTime 0.150089   
2022-11-04 00:15:13,839 - INFO  - Validation [33][   40/   40]   Loss 0.420455   Top1 90.870000   Top5 99.620000   BatchTime 0.103090   
2022-11-04 00:15:14,095 - INFO  - ==> Top1: 90.870    Top5: 99.620    Loss: 0.420

2022-11-04 00:15:14,141 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:15:14,142 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:15:14,142 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.930   Top5: 99.640] Sparsity : 0.836
2022-11-04 00:15:14,253 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:15:14,254 - INFO  - >>>>>>>> Epoch  34
2022-11-04 00:15:14,255 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:15:18,754 - INFO  - Training [34][   20/  196]   Loss 0.023986   Top1 99.199219   Top5 100.000000   BatchTime 0.224973   LR 0.001000   
2022-11-04 00:15:21,331 - INFO  - Training [34][   40/  196]   Loss 0.022800   Top1 99.248047   Top5 100.000000   BatchTime 0.176902   LR 0.001000   
2022-11-04 00:15:23,811 - INFO  - Training [34][   60/  196]   Loss 0.022920   Top1 99.218750   Top5 100.000000   BatchTime 0.159269   LR 0.001000   
2022-11-04 00:15:26,307 - INFO  - Training [34][   80/  196]   Loss 0.022577   Top1 99.252930   Top5 100.000000   BatchTime 0.150653   LR 0.001000   
2022-11-04 00:15:28,787 - INFO  - Training [34][  100/  196]   Loss 0.022491   Top1 99.253906   Top5 100.000000   BatchTime 0.145319   LR 0.001000   
2022-11-04 00:15:31,269 - INFO  - Training [34][  120/  196]   Loss 0.022016   Top1 99.267578   Top5 100.000000   BatchTime 0.141778   LR 0.001000   
2022-11-04 00:15:33,758 - INFO  - Training [34][  140/  196]   Loss 0.022046   Top1 99.243862   Top5 100.000000   BatchTime 0.139303   LR 0.001000   
2022-11-04 00:15:36,220 - INFO  - Training [34][  160/  196]   Loss 0.022022   Top1 99.255371   Top5 100.000000   BatchTime 0.137281   LR 0.001000   
2022-11-04 00:15:38,687 - INFO  - Training [34][  180/  196]   Loss 0.022072   Top1 99.257812   Top5 100.000000   BatchTime 0.135729   LR 0.001000   
2022-11-04 00:15:40,885 - INFO  - ==> Top1: 99.266    Top5: 100.000    Loss: 0.022

2022-11-04 00:15:40,886 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:15:43,873 - INFO  - Validation [34][   20/   40]   Loss 0.436984   Top1 90.878906   Top5 99.570312   BatchTime 0.149312   
2022-11-04 00:15:45,020 - INFO  - Validation [34][   40/   40]   Loss 0.428904   Top1 90.810000   Top5 99.640000   BatchTime 0.103326   
2022-11-04 00:15:45,282 - INFO  - ==> Top1: 90.810    Top5: 99.640    Loss: 0.429

2022-11-04 00:15:45,315 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:15:45,316 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:15:45,316 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.930   Top5: 99.640] Sparsity : 0.836
2022-11-04 00:15:45,421 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:15:45,421 - INFO  - >>>>>>>> Epoch  35
2022-11-04 00:15:45,422 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:15:49,856 - INFO  - Training [35][   20/  196]   Loss 0.025846   Top1 99.140625   Top5 100.000000   BatchTime 0.221674   LR 0.001000   
2022-11-04 00:15:52,331 - INFO  - Training [35][   40/  196]   Loss 0.023358   Top1 99.238281   Top5 100.000000   BatchTime 0.172720   LR 0.001000   
2022-11-04 00:15:54,505 - INFO  - Training [35][   60/  196]   Loss 0.023943   Top1 99.179688   Top5 100.000000   BatchTime 0.151373   LR 0.001000   
2022-11-04 00:15:56,352 - INFO  - Training [35][   80/  196]   Loss 0.024070   Top1 99.174805   Top5 100.000000   BatchTime 0.136622   LR 0.001000   
2022-11-04 00:15:58,403 - INFO  - Training [35][  100/  196]   Loss 0.024174   Top1 99.171875   Top5 100.000000   BatchTime 0.129800   LR 0.001000   
2022-11-04 00:16:00,439 - INFO  - Training [35][  120/  196]   Loss 0.023821   Top1 99.189453   Top5 100.000000   BatchTime 0.125133   LR 0.001000   
2022-11-04 00:16:02,347 - INFO  - Training [35][  140/  196]   Loss 0.023530   Top1 99.202009   Top5 100.000000   BatchTime 0.120890   LR 0.001000   
2022-11-04 00:16:04,522 - INFO  - Training [35][  160/  196]   Loss 0.023186   Top1 99.216309   Top5 100.000000   BatchTime 0.119369   LR 0.001000   
2022-11-04 00:16:06,990 - INFO  - Training [35][  180/  196]   Loss 0.023067   Top1 99.223090   Top5 100.000000   BatchTime 0.119818   LR 0.001000   
2022-11-04 00:16:09,187 - INFO  - ==> Top1: 99.228    Top5: 100.000    Loss: 0.023

2022-11-04 00:16:09,188 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:16:12,135 - INFO  - Validation [35][   20/   40]   Loss 0.432806   Top1 90.820312   Top5 99.570312   BatchTime 0.147284   
2022-11-04 00:16:13,218 - INFO  - Validation [35][   40/   40]   Loss 0.420817   Top1 91.000000   Top5 99.620000   BatchTime 0.100713   
2022-11-04 00:16:13,488 - INFO  - ==> Top1: 91.000    Top5: 99.620    Loss: 0.421

2022-11-04 00:16:13,530 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:16:13,531 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:16:13,531 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:16:13,733 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:16:13,917 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:16:13,918 - INFO  - >>>>>>>> Epoch  36
2022-11-04 00:16:13,919 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:16:18,408 - INFO  - Training [36][   20/  196]   Loss 0.028170   Top1 99.023438   Top5 100.000000   BatchTime 0.224435   LR 0.001000   
2022-11-04 00:16:20,897 - INFO  - Training [36][   40/  196]   Loss 0.027060   Top1 99.130859   Top5 100.000000   BatchTime 0.174437   LR 0.001000   
2022-11-04 00:16:23,386 - INFO  - Training [36][   60/  196]   Loss 0.026807   Top1 99.101562   Top5 100.000000   BatchTime 0.157779   LR 0.001000   
2022-11-04 00:16:25,866 - INFO  - Training [36][   80/  196]   Loss 0.026088   Top1 99.116211   Top5 100.000000   BatchTime 0.149322   LR 0.001000   
2022-11-04 00:16:28,335 - INFO  - Training [36][  100/  196]   Loss 0.025841   Top1 99.109375   Top5 100.000000   BatchTime 0.144148   LR 0.001000   
2022-11-04 00:16:30,813 - INFO  - Training [36][  120/  196]   Loss 0.025708   Top1 99.111328   Top5 100.000000   BatchTime 0.140779   LR 0.001000   
2022-11-04 00:16:33,290 - INFO  - Training [36][  140/  196]   Loss 0.025354   Top1 99.115513   Top5 100.000000   BatchTime 0.138356   LR 0.001000   
2022-11-04 00:16:35,765 - INFO  - Training [36][  160/  196]   Loss 0.025122   Top1 99.128418   Top5 100.000000   BatchTime 0.136531   LR 0.001000   
2022-11-04 00:16:38,237 - INFO  - Training [36][  180/  196]   Loss 0.024355   Top1 99.160156   Top5 100.000000   BatchTime 0.135097   LR 0.001000   
2022-11-04 00:16:40,429 - INFO  - ==> Top1: 99.156    Top5: 100.000    Loss: 0.024

2022-11-04 00:16:40,430 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:16:43,397 - INFO  - Validation [36][   20/   40]   Loss 0.436465   Top1 90.449219   Top5 99.628906   BatchTime 0.148240   
2022-11-04 00:16:44,526 - INFO  - Validation [36][   40/   40]   Loss 0.427609   Top1 90.720000   Top5 99.670000   BatchTime 0.102336   
2022-11-04 00:16:44,794 - INFO  - ==> Top1: 90.720    Top5: 99.670    Loss: 0.428

2022-11-04 00:16:44,825 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:16:44,825 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:16:44,826 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:16:44,929 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:16:44,929 - INFO  - >>>>>>>> Epoch  37
2022-11-04 00:16:44,930 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:16:48,968 - INFO  - Training [37][   20/  196]   Loss 0.024876   Top1 99.140625   Top5 100.000000   BatchTime 0.201899   LR 0.001000   
2022-11-04 00:16:51,048 - INFO  - Training [37][   40/  196]   Loss 0.025162   Top1 99.208984   Top5 100.000000   BatchTime 0.152935   LR 0.001000   
2022-11-04 00:16:53,127 - INFO  - Training [37][   60/  196]   Loss 0.023951   Top1 99.244792   Top5 100.000000   BatchTime 0.136607   LR 0.001000   
2022-11-04 00:16:54,918 - INFO  - Training [37][   80/  196]   Loss 0.024350   Top1 99.204102   Top5 100.000000   BatchTime 0.124843   LR 0.001000   
2022-11-04 00:16:57,446 - INFO  - Training [37][  100/  196]   Loss 0.024140   Top1 99.191406   Top5 100.000000   BatchTime 0.125157   LR 0.001000   
2022-11-04 00:16:59,928 - INFO  - Training [37][  120/  196]   Loss 0.024646   Top1 99.182943   Top5 100.000000   BatchTime 0.124976   LR 0.001000   
2022-11-04 00:17:02,404 - INFO  - Training [37][  140/  196]   Loss 0.024826   Top1 99.171317   Top5 100.000000   BatchTime 0.124809   LR 0.001000   
2022-11-04 00:17:04,872 - INFO  - Training [37][  160/  196]   Loss 0.024383   Top1 99.179688   Top5 100.000000   BatchTime 0.124632   LR 0.001000   
2022-11-04 00:17:07,331 - INFO  - Training [37][  180/  196]   Loss 0.024060   Top1 99.171007   Top5 100.000000   BatchTime 0.124448   LR 0.001000   
2022-11-04 00:17:09,512 - INFO  - ==> Top1: 99.162    Top5: 100.000    Loss: 0.024

2022-11-04 00:17:09,512 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:17:12,463 - INFO  - Validation [37][   20/   40]   Loss 0.439838   Top1 90.683594   Top5 99.589844   BatchTime 0.147494   
2022-11-04 00:17:13,565 - INFO  - Validation [37][   40/   40]   Loss 0.430386   Top1 90.850000   Top5 99.640000   BatchTime 0.101306   
2022-11-04 00:17:13,847 - INFO  - ==> Top1: 90.850    Top5: 99.640    Loss: 0.430

2022-11-04 00:17:13,875 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:17:13,876 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:17:13,876 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.930   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:17:13,982 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:17:13,982 - INFO  - >>>>>>>> Epoch  38
2022-11-04 00:17:13,983 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:17:18,454 - INFO  - Training [38][   20/  196]   Loss 0.023519   Top1 99.257812   Top5 100.000000   BatchTime 0.223516   LR 0.001000   
2022-11-04 00:17:20,946 - INFO  - Training [38][   40/  196]   Loss 0.023073   Top1 99.218750   Top5 100.000000   BatchTime 0.174057   LR 0.001000   
2022-11-04 00:17:23,442 - INFO  - Training [38][   60/  196]   Loss 0.023359   Top1 99.166667   Top5 100.000000   BatchTime 0.157640   LR 0.001000   
2022-11-04 00:17:26,019 - INFO  - Training [38][   80/  196]   Loss 0.024247   Top1 99.091797   Top5 100.000000   BatchTime 0.150447   LR 0.001000   
2022-11-04 00:17:28,504 - INFO  - Training [38][  100/  196]   Loss 0.023912   Top1 99.136719   Top5 100.000000   BatchTime 0.145205   LR 0.001000   
2022-11-04 00:17:31,005 - INFO  - Training [38][  120/  196]   Loss 0.023098   Top1 99.169922   Top5 100.000000   BatchTime 0.141839   LR 0.001000   
2022-11-04 00:17:33,483 - INFO  - Training [38][  140/  196]   Loss 0.022677   Top1 99.196429   Top5 100.000000   BatchTime 0.139281   LR 0.001000   
2022-11-04 00:17:35,944 - INFO  - Training [38][  160/  196]   Loss 0.022649   Top1 99.208984   Top5 100.000000   BatchTime 0.137249   LR 0.001000   
2022-11-04 00:17:38,407 - INFO  - Training [38][  180/  196]   Loss 0.022752   Top1 99.205729   Top5 100.000000   BatchTime 0.135685   LR 0.001000   
2022-11-04 00:17:40,611 - INFO  - ==> Top1: 99.200    Top5: 100.000    Loss: 0.023

2022-11-04 00:17:40,611 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:17:43,609 - INFO  - Validation [38][   20/   40]   Loss 0.436234   Top1 90.917969   Top5 99.628906   BatchTime 0.149865   
2022-11-04 00:17:44,459 - INFO  - Validation [38][   40/   40]   Loss 0.423642   Top1 91.040000   Top5 99.680000   BatchTime 0.096182   
2022-11-04 00:17:44,723 - INFO  - ==> Top1: 91.040    Top5: 99.680    Loss: 0.424

2022-11-04 00:17:44,756 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:17:44,756 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:17:44,756 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.970   Top5: 99.660] Sparsity : 0.836
2022-11-04 00:17:44,943 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:17:45,109 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:17:45,110 - INFO  - >>>>>>>> Epoch  39
2022-11-04 00:17:45,111 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:17:49,595 - INFO  - Training [39][   20/  196]   Loss 0.021116   Top1 99.238281   Top5 100.000000   BatchTime 0.224174   LR 0.001000   
2022-11-04 00:17:52,039 - INFO  - Training [39][   40/  196]   Loss 0.020821   Top1 99.287109   Top5 100.000000   BatchTime 0.173189   LR 0.001000   
2022-11-04 00:17:54,523 - INFO  - Training [39][   60/  196]   Loss 0.021168   Top1 99.283854   Top5 100.000000   BatchTime 0.156852   LR 0.001000   
2022-11-04 00:17:57,004 - INFO  - Training [39][   80/  196]   Loss 0.021085   Top1 99.316406   Top5 100.000000   BatchTime 0.148661   LR 0.001000   
2022-11-04 00:17:59,485 - INFO  - Training [39][  100/  196]   Loss 0.021435   Top1 99.320312   Top5 100.000000   BatchTime 0.143738   LR 0.001000   
2022-11-04 00:18:01,974 - INFO  - Training [39][  120/  196]   Loss 0.021346   Top1 99.319661   Top5 100.000000   BatchTime 0.140523   LR 0.001000   
2022-11-04 00:18:04,462 - INFO  - Training [39][  140/  196]   Loss 0.021879   Top1 99.305246   Top5 100.000000   BatchTime 0.138213   LR 0.001000   
2022-11-04 00:18:06,935 - INFO  - Training [39][  160/  196]   Loss 0.021794   Top1 99.296875   Top5 100.000000   BatchTime 0.136397   LR 0.001000   
2022-11-04 00:18:09,403 - INFO  - Training [39][  180/  196]   Loss 0.022005   Top1 99.281684   Top5 100.000000   BatchTime 0.134952   LR 0.001000   
2022-11-04 00:18:11,583 - INFO  - ==> Top1: 99.270    Top5: 100.000    Loss: 0.022

2022-11-04 00:18:11,584 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:18:14,605 - INFO  - Validation [39][   20/   40]   Loss 0.440801   Top1 91.269531   Top5 99.550781   BatchTime 0.150980   
2022-11-04 00:18:15,707 - INFO  - Validation [39][   40/   40]   Loss 0.428137   Top1 91.200000   Top5 99.650000   BatchTime 0.103050   
2022-11-04 00:18:15,977 - INFO  - ==> Top1: 91.200    Top5: 99.650    Loss: 0.428

2022-11-04 00:18:16,012 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:18:16,013 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:18:16,013 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:18:16,186 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:18:16,355 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/hard_pruned_model/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_best.pth.tar

2022-11-04 00:18:16,355 - INFO  - >>>>>>>> Epoch  40
2022-11-04 00:18:16,356 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:18:20,867 - INFO  - Training [40][   20/  196]   Loss 0.023547   Top1 99.355469   Top5 100.000000   BatchTime 0.225548   LR 0.000100   
2022-11-04 00:18:23,358 - INFO  - Training [40][   40/  196]   Loss 0.024941   Top1 99.189453   Top5 100.000000   BatchTime 0.175047   LR 0.000100   
2022-11-04 00:18:25,827 - INFO  - Training [40][   60/  196]   Loss 0.024926   Top1 99.205729   Top5 99.993490   BatchTime 0.157846   LR 0.000100   
2022-11-04 00:18:28,318 - INFO  - Training [40][   80/  196]   Loss 0.024802   Top1 99.174805   Top5 99.995117   BatchTime 0.149514   LR 0.000100   
2022-11-04 00:18:30,800 - INFO  - Training [40][  100/  196]   Loss 0.025751   Top1 99.132812   Top5 99.996094   BatchTime 0.144437   LR 0.000100   
2022-11-04 00:18:33,268 - INFO  - Training [40][  120/  196]   Loss 0.024904   Top1 99.160156   Top5 99.996745   BatchTime 0.140928   LR 0.000100   
2022-11-04 00:18:35,097 - INFO  - Training [40][  140/  196]   Loss 0.024906   Top1 99.168527   Top5 99.997210   BatchTime 0.133858   LR 0.000100   
2022-11-04 00:18:37,154 - INFO  - Training [40][  160/  196]   Loss 0.024938   Top1 99.167480   Top5 99.997559   BatchTime 0.129986   LR 0.000100   
2022-11-04 00:18:39,156 - INFO  - Training [40][  180/  196]   Loss 0.024672   Top1 99.184028   Top5 99.997830   BatchTime 0.126663   LR 0.000100   
2022-11-04 00:18:40,982 - INFO  - ==> Top1: 99.198    Top5: 99.998    Loss: 0.024

2022-11-04 00:18:40,982 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:18:44,116 - INFO  - Validation [40][   20/   40]   Loss 0.436330   Top1 90.800781   Top5 99.570312   BatchTime 0.156607   
2022-11-04 00:18:45,243 - INFO  - Validation [40][   40/   40]   Loss 0.426583   Top1 90.990000   Top5 99.660000   BatchTime 0.106475   
2022-11-04 00:18:45,512 - INFO  - ==> Top1: 90.990    Top5: 99.660    Loss: 0.427

2022-11-04 00:18:45,553 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:18:45,554 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:18:45,554 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 91.000   Top5: 99.620] Sparsity : 0.836
2022-11-04 00:18:45,648 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:18:45,648 - INFO  - >>>>>>>> Epoch  41
2022-11-04 00:18:45,649 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:18:50,132 - INFO  - Training [41][   20/  196]   Loss 0.026519   Top1 99.121094   Top5 100.000000   BatchTime 0.224135   LR 0.000100   
2022-11-04 00:18:52,604 - INFO  - Training [41][   40/  196]   Loss 0.026800   Top1 99.072266   Top5 99.990234   BatchTime 0.173867   LR 0.000100   
2022-11-04 00:18:55,092 - INFO  - Training [41][   60/  196]   Loss 0.026682   Top1 99.062500   Top5 99.993490   BatchTime 0.157380   LR 0.000100   
2022-11-04 00:18:57,583 - INFO  - Training [41][   80/  196]   Loss 0.025384   Top1 99.130859   Top5 99.995117   BatchTime 0.149175   LR 0.000100   
2022-11-04 00:19:00,069 - INFO  - Training [41][  100/  196]   Loss 0.024997   Top1 99.160156   Top5 99.996094   BatchTime 0.144195   LR 0.000100   
2022-11-04 00:19:02,539 - INFO  - Training [41][  120/  196]   Loss 0.024651   Top1 99.166667   Top5 99.996745   BatchTime 0.140742   LR 0.000100   
2022-11-04 00:19:05,023 - INFO  - Training [41][  140/  196]   Loss 0.024028   Top1 99.196429   Top5 99.997210   BatchTime 0.138379   LR 0.000100   
2022-11-04 00:19:07,486 - INFO  - Training [41][  160/  196]   Loss 0.023924   Top1 99.187012   Top5 99.997559   BatchTime 0.136481   LR 0.000100   
2022-11-04 00:19:09,955 - INFO  - Training [41][  180/  196]   Loss 0.024045   Top1 99.181858   Top5 99.997830   BatchTime 0.135029   LR 0.000100   
2022-11-04 00:19:12,165 - INFO  - ==> Top1: 99.180    Top5: 99.998    Loss: 0.024

2022-11-04 00:19:12,165 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:19:15,147 - INFO  - Validation [41][   20/   40]   Loss 0.436933   Top1 91.093750   Top5 99.609375   BatchTime 0.148975   
2022-11-04 00:19:16,280 - INFO  - Validation [41][   40/   40]   Loss 0.428555   Top1 91.020000   Top5 99.670000   BatchTime 0.102815   
2022-11-04 00:19:16,562 - INFO  - ==> Top1: 91.020    Top5: 99.670    Loss: 0.429

2022-11-04 00:19:16,601 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:19:16,602 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:19:16,602 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
2022-11-04 00:19:16,706 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:19:16,706 - INFO  - >>>>>>>> Epoch  42
2022-11-04 00:19:16,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:19:21,135 - INFO  - Training [42][   20/  196]   Loss 0.018508   Top1 99.550781   Top5 100.000000   BatchTime 0.221334   LR 0.000100   
2022-11-04 00:19:23,603 - INFO  - Training [42][   40/  196]   Loss 0.020872   Top1 99.326172   Top5 100.000000   BatchTime 0.172370   LR 0.000100   
2022-11-04 00:19:26,077 - INFO  - Training [42][   60/  196]   Loss 0.020623   Top1 99.375000   Top5 100.000000   BatchTime 0.156147   LR 0.000100   
2022-11-04 00:19:27,953 - INFO  - Training [42][   80/  196]   Loss 0.021782   Top1 99.326172   Top5 100.000000   BatchTime 0.140556   LR 0.000100   
2022-11-04 00:19:30,091 - INFO  - Training [42][  100/  196]   Loss 0.022270   Top1 99.300781   Top5 100.000000   BatchTime 0.133825   LR 0.000100   
2022-11-04 00:19:32,094 - INFO  - Training [42][  120/  196]   Loss 0.022388   Top1 99.280599   Top5 100.000000   BatchTime 0.128213   LR 0.000100   
2022-11-04 00:19:34,107 - INFO  - Training [42][  140/  196]   Loss 0.022193   Top1 99.282924   Top5 100.000000   BatchTime 0.124279   LR 0.000100   
2022-11-04 00:19:35,943 - INFO  - Training [42][  160/  196]   Loss 0.022763   Top1 99.257812   Top5 100.000000   BatchTime 0.120217   LR 0.000100   
2022-11-04 00:19:38,418 - INFO  - Training [42][  180/  196]   Loss 0.022163   Top1 99.290365   Top5 100.000000   BatchTime 0.120610   LR 0.000100   
2022-11-04 00:19:40,618 - INFO  - ==> Top1: 99.272    Top5: 100.000    Loss: 0.022

2022-11-04 00:19:40,619 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:19:43,541 - INFO  - Validation [42][   20/   40]   Loss 0.439158   Top1 90.917969   Top5 99.648438   BatchTime 0.146036   
2022-11-04 00:19:44,641 - INFO  - Validation [42][   40/   40]   Loss 0.427523   Top1 90.950000   Top5 99.680000   BatchTime 0.100527   
2022-11-04 00:19:44,912 - INFO  - ==> Top1: 90.950    Top5: 99.680    Loss: 0.428

2022-11-04 00:19:44,957 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:19:44,958 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:19:44,958 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
2022-11-04 00:19:45,064 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:19:45,064 - INFO  - >>>>>>>> Epoch  43
2022-11-04 00:19:45,065 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:19:49,535 - INFO  - Training [43][   20/  196]   Loss 0.023713   Top1 99.316406   Top5 100.000000   BatchTime 0.223473   LR 0.000100   
2022-11-04 00:19:52,023 - INFO  - Training [43][   40/  196]   Loss 0.023672   Top1 99.248047   Top5 100.000000   BatchTime 0.173932   LR 0.000100   
2022-11-04 00:19:54,507 - INFO  - Training [43][   60/  196]   Loss 0.023524   Top1 99.244792   Top5 100.000000   BatchTime 0.157354   LR 0.000100   
2022-11-04 00:19:57,003 - INFO  - Training [43][   80/  196]   Loss 0.023446   Top1 99.262695   Top5 100.000000   BatchTime 0.149212   LR 0.000100   
2022-11-04 00:19:59,488 - INFO  - Training [43][  100/  196]   Loss 0.024187   Top1 99.207031   Top5 100.000000   BatchTime 0.144217   LR 0.000100   
2022-11-04 00:20:01,971 - INFO  - Training [43][  120/  196]   Loss 0.024061   Top1 99.199219   Top5 100.000000   BatchTime 0.140877   LR 0.000100   
2022-11-04 00:20:04,454 - INFO  - Training [43][  140/  196]   Loss 0.023610   Top1 99.227121   Top5 100.000000   BatchTime 0.138488   LR 0.000100   
2022-11-04 00:20:06,920 - INFO  - Training [43][  160/  196]   Loss 0.023463   Top1 99.230957   Top5 100.000000   BatchTime 0.136588   LR 0.000100   
2022-11-04 00:20:09,401 - INFO  - Training [43][  180/  196]   Loss 0.023696   Top1 99.220920   Top5 100.000000   BatchTime 0.135192   LR 0.000100   
2022-11-04 00:20:11,591 - INFO  - ==> Top1: 99.230    Top5: 100.000    Loss: 0.024

2022-11-04 00:20:11,592 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:20:14,594 - INFO  - Validation [43][   20/   40]   Loss 0.431464   Top1 90.781250   Top5 99.570312   BatchTime 0.150021   
2022-11-04 00:20:15,723 - INFO  - Validation [43][   40/   40]   Loss 0.422555   Top1 90.880000   Top5 99.670000   BatchTime 0.103226   
2022-11-04 00:20:15,993 - INFO  - ==> Top1: 90.880    Top5: 99.670    Loss: 0.423

2022-11-04 00:20:16,021 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:20:16,021 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:20:16,021 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
2022-11-04 00:20:16,115 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:20:16,115 - INFO  - >>>>>>>> Epoch  44
2022-11-04 00:20:16,117 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:20:19,972 - INFO  - Training [44][   20/  196]   Loss 0.025345   Top1 99.121094   Top5 100.000000   BatchTime 0.192734   LR 0.000100   
2022-11-04 00:20:22,035 - INFO  - Training [44][   40/  196]   Loss 0.023487   Top1 99.160156   Top5 100.000000   BatchTime 0.147959   LR 0.000100   
2022-11-04 00:20:24,086 - INFO  - Training [44][   60/  196]   Loss 0.024178   Top1 99.160156   Top5 100.000000   BatchTime 0.132812   LR 0.000100   
2022-11-04 00:20:26,111 - INFO  - Training [44][   80/  196]   Loss 0.023629   Top1 99.179688   Top5 100.000000   BatchTime 0.124920   LR 0.000100   
2022-11-04 00:20:28,058 - INFO  - Training [44][  100/  196]   Loss 0.023915   Top1 99.171875   Top5 100.000000   BatchTime 0.119408   LR 0.000100   
2022-11-04 00:20:30,546 - INFO  - Training [44][  120/  196]   Loss 0.023033   Top1 99.231771   Top5 100.000000   BatchTime 0.120240   LR 0.000100   
2022-11-04 00:20:33,027 - INFO  - Training [44][  140/  196]   Loss 0.023869   Top1 99.210379   Top5 100.000000   BatchTime 0.120782   LR 0.000100   
2022-11-04 00:20:35,494 - INFO  - Training [44][  160/  196]   Loss 0.023635   Top1 99.213867   Top5 100.000000   BatchTime 0.121102   LR 0.000100   
2022-11-04 00:20:37,956 - INFO  - Training [44][  180/  196]   Loss 0.023555   Top1 99.220920   Top5 100.000000   BatchTime 0.121324   LR 0.000100   
2022-11-04 00:20:40,163 - INFO  - ==> Top1: 99.232    Top5: 100.000    Loss: 0.023

2022-11-04 00:20:40,164 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:20:43,138 - INFO  - Validation [44][   20/   40]   Loss 0.434922   Top1 90.761719   Top5 99.570312   BatchTime 0.148643   
2022-11-04 00:20:44,258 - INFO  - Validation [44][   40/   40]   Loss 0.424448   Top1 90.920000   Top5 99.650000   BatchTime 0.102306   
2022-11-04 00:20:44,532 - INFO  - ==> Top1: 90.920    Top5: 99.650    Loss: 0.424

2022-11-04 00:20:44,561 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:20:44,562 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:20:44,562 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
2022-11-04 00:20:44,668 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:20:44,668 - INFO  - >>>>>>>> Epoch  45
2022-11-04 00:20:44,670 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:20:49,108 - INFO  - Training [45][   20/  196]   Loss 0.023371   Top1 99.121094   Top5 100.000000   BatchTime 0.221885   LR 0.000100   
2022-11-04 00:20:51,589 - INFO  - Training [45][   40/  196]   Loss 0.023289   Top1 99.150391   Top5 100.000000   BatchTime 0.172971   LR 0.000100   
2022-11-04 00:20:54,069 - INFO  - Training [45][   60/  196]   Loss 0.022548   Top1 99.186198   Top5 100.000000   BatchTime 0.156650   LR 0.000100   
2022-11-04 00:20:56,558 - INFO  - Training [45][   80/  196]   Loss 0.022301   Top1 99.218750   Top5 100.000000   BatchTime 0.148597   LR 0.000100   
2022-11-04 00:20:59,033 - INFO  - Training [45][  100/  196]   Loss 0.022562   Top1 99.222656   Top5 100.000000   BatchTime 0.143634   LR 0.000100   
2022-11-04 00:21:01,532 - INFO  - Training [45][  120/  196]   Loss 0.022375   Top1 99.235026   Top5 100.000000   BatchTime 0.140516   LR 0.000100   
2022-11-04 00:21:04,001 - INFO  - Training [45][  140/  196]   Loss 0.023500   Top1 99.210379   Top5 100.000000   BatchTime 0.138080   LR 0.000100   
2022-11-04 00:21:06,472 - INFO  - Training [45][  160/  196]   Loss 0.023502   Top1 99.221191   Top5 100.000000   BatchTime 0.136259   LR 0.000100   
2022-11-04 00:21:08,932 - INFO  - Training [45][  180/  196]   Loss 0.022949   Top1 99.227431   Top5 100.000000   BatchTime 0.134787   LR 0.000100   
2022-11-04 00:21:11,133 - INFO  - ==> Top1: 99.240    Top5: 100.000    Loss: 0.023

2022-11-04 00:21:11,134 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:21:13,817 - INFO  - Validation [45][   20/   40]   Loss 0.436971   Top1 90.722656   Top5 99.628906   BatchTime 0.134042   
2022-11-04 00:21:14,637 - INFO  - Validation [45][   40/   40]   Loss 0.423851   Top1 90.930000   Top5 99.670000   BatchTime 0.087520   
2022-11-04 00:21:14,912 - INFO  - ==> Top1: 90.930    Top5: 99.670    Loss: 0.424

2022-11-04 00:21:14,942 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:21:14,943 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:21:14,943 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 91.020   Top5: 99.670] Sparsity : 0.836
2022-11-04 00:21:15,050 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:21:15,050 - INFO  - >>>>>>>> Epoch  46
2022-11-04 00:21:15,052 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:21:18,875 - INFO  - Training [46][   20/  196]   Loss 0.020990   Top1 99.375000   Top5 100.000000   BatchTime 0.191179   LR 0.000100   
2022-11-04 00:21:21,384 - INFO  - Training [46][   40/  196]   Loss 0.022584   Top1 99.208984   Top5 100.000000   BatchTime 0.158300   LR 0.000100   
2022-11-04 00:21:23,879 - INFO  - Training [46][   60/  196]   Loss 0.023049   Top1 99.199219   Top5 100.000000   BatchTime 0.147118   LR 0.000100   
2022-11-04 00:21:26,363 - INFO  - Training [46][   80/  196]   Loss 0.022904   Top1 99.189453   Top5 100.000000   BatchTime 0.141391   LR 0.000100   
2022-11-04 00:21:28,855 - INFO  - Training [46][  100/  196]   Loss 0.022882   Top1 99.171875   Top5 100.000000   BatchTime 0.138031   LR 0.000100   
2022-11-04 00:21:31,337 - INFO  - Training [46][  120/  196]   Loss 0.023753   Top1 99.169922   Top5 100.000000   BatchTime 0.135712   LR 0.000100   
2022-11-04 00:21:33,911 - INFO  - Training [46][  140/  196]   Loss 0.023340   Top1 99.204799   Top5 100.000000   BatchTime 0.134706   LR 0.000100   
2022-11-04 00:21:36,378 - INFO  - Training [46][  160/  196]   Loss 0.023830   Top1 99.194336   Top5 100.000000   BatchTime 0.133289   LR 0.000100   
2022-11-04 00:21:38,805 - INFO  - Training [46][  180/  196]   Loss 0.023660   Top1 99.212240   Top5 100.000000   BatchTime 0.131958   LR 0.000100   
2022-11-04 00:21:41,020 - INFO  - ==> Top1: 99.222    Top5: 100.000    Loss: 0.024

2022-11-04 00:21:41,021 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:21:44,044 - INFO  - Validation [46][   20/   40]   Loss 0.437181   Top1 90.839844   Top5 99.609375   BatchTime 0.151085   
2022-11-04 00:21:45,166 - INFO  - Validation [46][   40/   40]   Loss 0.424094   Top1 91.060000   Top5 99.680000   BatchTime 0.103587   
2022-11-04 00:21:45,435 - INFO  - ==> Top1: 91.060    Top5: 99.680    Loss: 0.424

2022-11-04 00:21:45,467 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:21:45,468 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:21:45,468 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:21:45,585 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:21:45,586 - INFO  - >>>>>>>> Epoch  47
2022-11-04 00:21:45,587 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:21:50,073 - INFO  - Training [47][   20/  196]   Loss 0.020342   Top1 99.335938   Top5 100.000000   BatchTime 0.224315   LR 0.000100   
2022-11-04 00:21:52,550 - INFO  - Training [47][   40/  196]   Loss 0.022204   Top1 99.267578   Top5 100.000000   BatchTime 0.174065   LR 0.000100   
2022-11-04 00:21:55,025 - INFO  - Training [47][   60/  196]   Loss 0.022336   Top1 99.264323   Top5 100.000000   BatchTime 0.157295   LR 0.000100   
2022-11-04 00:21:57,517 - INFO  - Training [47][   80/  196]   Loss 0.022734   Top1 99.262695   Top5 100.000000   BatchTime 0.149118   LR 0.000100   
2022-11-04 00:21:59,994 - INFO  - Training [47][  100/  196]   Loss 0.022222   Top1 99.285156   Top5 100.000000   BatchTime 0.144063   LR 0.000100   
2022-11-04 00:22:02,461 - INFO  - Training [47][  120/  196]   Loss 0.021984   Top1 99.316406   Top5 99.996745   BatchTime 0.140612   LR 0.000100   
2022-11-04 00:22:04,912 - INFO  - Training [47][  140/  196]   Loss 0.021960   Top1 99.302455   Top5 99.997210   BatchTime 0.138033   LR 0.000100   
2022-11-04 00:22:06,678 - INFO  - Training [47][  160/  196]   Loss 0.021786   Top1 99.296875   Top5 99.997559   BatchTime 0.131818   LR 0.000100   
2022-11-04 00:22:08,744 - INFO  - Training [47][  180/  196]   Loss 0.022445   Top1 99.266493   Top5 99.997830   BatchTime 0.128649   LR 0.000100   
2022-11-04 00:22:10,586 - INFO  - ==> Top1: 99.270    Top5: 99.998    Loss: 0.022

2022-11-04 00:22:10,587 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:22:13,307 - INFO  - Validation [47][   20/   40]   Loss 0.438073   Top1 90.781250   Top5 99.589844   BatchTime 0.135935   
2022-11-04 00:22:14,445 - INFO  - Validation [47][   40/   40]   Loss 0.424670   Top1 90.920000   Top5 99.690000   BatchTime 0.096429   
2022-11-04 00:22:14,720 - INFO  - ==> Top1: 90.920    Top5: 99.690    Loss: 0.425

2022-11-04 00:22:14,750 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:22:14,752 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:22:14,752 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:22:14,824 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:22:14,824 - INFO  - >>>>>>>> Epoch  48
2022-11-04 00:22:14,826 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:22:19,316 - INFO  - Training [48][   20/  196]   Loss 0.018862   Top1 99.492188   Top5 100.000000   BatchTime 0.224521   LR 0.000100   
2022-11-04 00:22:21,800 - INFO  - Training [48][   40/  196]   Loss 0.020109   Top1 99.365234   Top5 100.000000   BatchTime 0.174354   LR 0.000100   
2022-11-04 00:22:24,272 - INFO  - Training [48][   60/  196]   Loss 0.020478   Top1 99.375000   Top5 100.000000   BatchTime 0.157436   LR 0.000100   
2022-11-04 00:22:26,754 - INFO  - Training [48][   80/  196]   Loss 0.020016   Top1 99.394531   Top5 100.000000   BatchTime 0.149103   LR 0.000100   
2022-11-04 00:22:29,239 - INFO  - Training [48][  100/  196]   Loss 0.020490   Top1 99.371094   Top5 100.000000   BatchTime 0.144135   LR 0.000100   
2022-11-04 00:22:31,723 - INFO  - Training [48][  120/  196]   Loss 0.020031   Top1 99.384766   Top5 100.000000   BatchTime 0.140809   LR 0.000100   
2022-11-04 00:22:34,192 - INFO  - Training [48][  140/  196]   Loss 0.020516   Top1 99.344308   Top5 100.000000   BatchTime 0.138327   LR 0.000100   
2022-11-04 00:22:36,657 - INFO  - Training [48][  160/  196]   Loss 0.020299   Top1 99.360352   Top5 100.000000   BatchTime 0.136440   LR 0.000100   
2022-11-04 00:22:39,118 - INFO  - Training [48][  180/  196]   Loss 0.021147   Top1 99.331597   Top5 100.000000   BatchTime 0.134954   LR 0.000100   
2022-11-04 00:22:41,325 - INFO  - ==> Top1: 99.312    Top5: 100.000    Loss: 0.021

2022-11-04 00:22:41,326 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:22:44,294 - INFO  - Validation [48][   20/   40]   Loss 0.435583   Top1 90.800781   Top5 99.609375   BatchTime 0.148325   
2022-11-04 00:22:45,430 - INFO  - Validation [48][   40/   40]   Loss 0.427517   Top1 90.960000   Top5 99.650000   BatchTime 0.102567   
2022-11-04 00:22:45,712 - INFO  - ==> Top1: 90.960    Top5: 99.650    Loss: 0.428

2022-11-04 00:22:45,742 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:22:45,742 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:22:45,743 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:22:45,850 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:22:45,850 - INFO  - >>>>>>>> Epoch  49
2022-11-04 00:22:45,852 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:22:50,293 - INFO  - Training [49][   20/  196]   Loss 0.022853   Top1 99.355469   Top5 100.000000   BatchTime 0.222054   LR 0.000100   
2022-11-04 00:22:52,762 - INFO  - Training [49][   40/  196]   Loss 0.021660   Top1 99.384766   Top5 100.000000   BatchTime 0.172766   LR 0.000100   
2022-11-04 00:22:55,233 - INFO  - Training [49][   60/  196]   Loss 0.021919   Top1 99.348958   Top5 100.000000   BatchTime 0.156350   LR 0.000100   
2022-11-04 00:22:57,751 - INFO  - Training [49][   80/  196]   Loss 0.022167   Top1 99.350586   Top5 100.000000   BatchTime 0.148733   LR 0.000100   
2022-11-04 00:22:59,576 - INFO  - Training [49][  100/  196]   Loss 0.022653   Top1 99.320312   Top5 100.000000   BatchTime 0.137239   LR 0.000100   
2022-11-04 00:23:01,636 - INFO  - Training [49][  120/  196]   Loss 0.023305   Top1 99.270833   Top5 100.000000   BatchTime 0.131533   LR 0.000100   
2022-11-04 00:23:03,668 - INFO  - Training [49][  140/  196]   Loss 0.023471   Top1 99.266183   Top5 100.000000   BatchTime 0.127259   LR 0.000100   
2022-11-04 00:23:05,599 - INFO  - Training [49][  160/  196]   Loss 0.023155   Top1 99.279785   Top5 100.000000   BatchTime 0.123416   LR 0.000100   
2022-11-04 00:23:07,557 - INFO  - Training [49][  180/  196]   Loss 0.023160   Top1 99.266493   Top5 100.000000   BatchTime 0.120584   LR 0.000100   
2022-11-04 00:23:09,774 - INFO  - ==> Top1: 99.274    Top5: 100.000    Loss: 0.023

2022-11-04 00:23:09,775 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:23:12,741 - INFO  - Validation [49][   20/   40]   Loss 0.431519   Top1 90.937500   Top5 99.589844   BatchTime 0.148182   
2022-11-04 00:23:13,842 - INFO  - Validation [49][   40/   40]   Loss 0.424941   Top1 90.930000   Top5 99.640000   BatchTime 0.101617   
2022-11-04 00:23:14,119 - INFO  - ==> Top1: 90.930    Top5: 99.640    Loss: 0.425

2022-11-04 00:23:14,166 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:23:14,166 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:23:14,167 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 91.040   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:23:14,274 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:23:14,275 - INFO  - >>>>>>>> Epoch  50
2022-11-04 00:23:14,276 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:23:18,773 - INFO  - Training [50][   20/  196]   Loss 0.021150   Top1 99.238281   Top5 100.000000   BatchTime 0.224876   LR 0.000010   
2022-11-04 00:23:21,254 - INFO  - Training [50][   40/  196]   Loss 0.020112   Top1 99.287109   Top5 100.000000   BatchTime 0.174454   LR 0.000010   
2022-11-04 00:23:23,734 - INFO  - Training [50][   60/  196]   Loss 0.020702   Top1 99.283854   Top5 100.000000   BatchTime 0.157636   LR 0.000010   
2022-11-04 00:23:26,220 - INFO  - Training [50][   80/  196]   Loss 0.021444   Top1 99.306641   Top5 100.000000   BatchTime 0.149300   LR 0.000010   
2022-11-04 00:23:28,700 - INFO  - Training [50][  100/  196]   Loss 0.022051   Top1 99.289062   Top5 100.000000   BatchTime 0.144240   LR 0.000010   
2022-11-04 00:23:31,281 - INFO  - Training [50][  120/  196]   Loss 0.021572   Top1 99.306641   Top5 100.000000   BatchTime 0.141705   LR 0.000010   
2022-11-04 00:23:33,752 - INFO  - Training [50][  140/  196]   Loss 0.020923   Top1 99.330357   Top5 100.000000   BatchTime 0.139112   LR 0.000010   
2022-11-04 00:23:36,219 - INFO  - Training [50][  160/  196]   Loss 0.021195   Top1 99.313965   Top5 100.000000   BatchTime 0.137145   LR 0.000010   
2022-11-04 00:23:38,683 - INFO  - Training [50][  180/  196]   Loss 0.021576   Top1 99.294705   Top5 100.000000   BatchTime 0.135593   LR 0.000010   
2022-11-04 00:23:40,893 - INFO  - ==> Top1: 99.264    Top5: 100.000    Loss: 0.022

2022-11-04 00:23:40,894 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:23:43,871 - INFO  - Validation [50][   20/   40]   Loss 0.431533   Top1 90.839844   Top5 99.609375   BatchTime 0.148787   
2022-11-04 00:23:45,007 - INFO  - Validation [50][   40/   40]   Loss 0.421776   Top1 91.070000   Top5 99.650000   BatchTime 0.102791   
2022-11-04 00:23:45,280 - INFO  - ==> Top1: 91.070    Top5: 99.650    Loss: 0.422

2022-11-04 00:23:45,309 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:23:45,310 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:23:45,310 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:23:45,414 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:23:45,415 - INFO  - >>>>>>>> Epoch  51
2022-11-04 00:23:45,416 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:23:49,796 - INFO  - Training [51][   20/  196]   Loss 0.019042   Top1 99.433594   Top5 100.000000   BatchTime 0.218982   LR 0.000010   
2022-11-04 00:23:51,592 - INFO  - Training [51][   40/  196]   Loss 0.022199   Top1 99.238281   Top5 100.000000   BatchTime 0.154389   LR 0.000010   
2022-11-04 00:23:53,624 - INFO  - Training [51][   60/  196]   Loss 0.022967   Top1 99.166667   Top5 100.000000   BatchTime 0.136793   LR 0.000010   
2022-11-04 00:23:55,665 - INFO  - Training [51][   80/  196]   Loss 0.022494   Top1 99.204102   Top5 100.000000   BatchTime 0.128103   LR 0.000010   
2022-11-04 00:23:57,579 - INFO  - Training [51][  100/  196]   Loss 0.021964   Top1 99.214844   Top5 100.000000   BatchTime 0.121624   LR 0.000010   
2022-11-04 00:23:59,661 - INFO  - Training [51][  120/  196]   Loss 0.021987   Top1 99.225260   Top5 100.000000   BatchTime 0.118703   LR 0.000010   
2022-11-04 00:24:02,145 - INFO  - Training [51][  140/  196]   Loss 0.022237   Top1 99.238281   Top5 100.000000   BatchTime 0.119490   LR 0.000010   
2022-11-04 00:24:04,611 - INFO  - Training [51][  160/  196]   Loss 0.022385   Top1 99.228516   Top5 100.000000   BatchTime 0.119966   LR 0.000010   
2022-11-04 00:24:07,084 - INFO  - Training [51][  180/  196]   Loss 0.022470   Top1 99.227431   Top5 100.000000   BatchTime 0.120374   LR 0.000010   
2022-11-04 00:24:09,273 - INFO  - ==> Top1: 99.228    Top5: 100.000    Loss: 0.023

2022-11-04 00:24:09,274 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:24:12,259 - INFO  - Validation [51][   20/   40]   Loss 0.437857   Top1 90.644531   Top5 99.609375   BatchTime 0.149171   
2022-11-04 00:24:13,371 - INFO  - Validation [51][   40/   40]   Loss 0.423992   Top1 90.860000   Top5 99.630000   BatchTime 0.102386   
2022-11-04 00:24:13,643 - INFO  - ==> Top1: 90.860    Top5: 99.630    Loss: 0.424

2022-11-04 00:24:13,681 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:24:13,682 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:24:13,682 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:24:13,744 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:24:13,745 - INFO  - >>>>>>>> Epoch  52
2022-11-04 00:24:13,746 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:24:18,239 - INFO  - Training [52][   20/  196]   Loss 0.022457   Top1 99.335938   Top5 100.000000   BatchTime 0.224617   LR 0.000010   
2022-11-04 00:24:20,733 - INFO  - Training [52][   40/  196]   Loss 0.020436   Top1 99.384766   Top5 100.000000   BatchTime 0.174657   LR 0.000010   
2022-11-04 00:24:23,219 - INFO  - Training [52][   60/  196]   Loss 0.022275   Top1 99.270833   Top5 100.000000   BatchTime 0.157873   LR 0.000010   
2022-11-04 00:24:25,694 - INFO  - Training [52][   80/  196]   Loss 0.022078   Top1 99.277344   Top5 100.000000   BatchTime 0.149343   LR 0.000010   
2022-11-04 00:24:28,182 - INFO  - Training [52][  100/  196]   Loss 0.022710   Top1 99.253906   Top5 100.000000   BatchTime 0.144358   LR 0.000010   
2022-11-04 00:24:30,661 - INFO  - Training [52][  120/  196]   Loss 0.022864   Top1 99.225260   Top5 100.000000   BatchTime 0.140954   LR 0.000010   
2022-11-04 00:24:33,138 - INFO  - Training [52][  140/  196]   Loss 0.022311   Top1 99.266183   Top5 100.000000   BatchTime 0.138513   LR 0.000010   
2022-11-04 00:24:35,607 - INFO  - Training [52][  160/  196]   Loss 0.022253   Top1 99.262695   Top5 100.000000   BatchTime 0.136625   LR 0.000010   
2022-11-04 00:24:38,074 - INFO  - Training [52][  180/  196]   Loss 0.021887   Top1 99.270833   Top5 100.000000   BatchTime 0.135152   LR 0.000010   
2022-11-04 00:24:40,270 - INFO  - ==> Top1: 99.272    Top5: 100.000    Loss: 0.022

2022-11-04 00:24:40,271 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:24:43,179 - INFO  - Validation [52][   20/   40]   Loss 0.433076   Top1 90.957031   Top5 99.589844   BatchTime 0.145294   
2022-11-04 00:24:43,878 - INFO  - Validation [52][   40/   40]   Loss 0.424694   Top1 90.980000   Top5 99.680000   BatchTime 0.090137   
2022-11-04 00:24:44,164 - INFO  - ==> Top1: 90.980    Top5: 99.680    Loss: 0.425

2022-11-04 00:24:44,189 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:24:44,190 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:24:44,190 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:24:44,290 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:24:44,291 - INFO  - >>>>>>>> Epoch  53
2022-11-04 00:24:44,292 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:24:48,413 - INFO  - Training [53][   20/  196]   Loss 0.024151   Top1 99.277344   Top5 100.000000   BatchTime 0.206056   LR 0.000010   
2022-11-04 00:24:50,308 - INFO  - Training [53][   40/  196]   Loss 0.021646   Top1 99.306641   Top5 100.000000   BatchTime 0.150383   LR 0.000010   
2022-11-04 00:24:52,667 - INFO  - Training [53][   60/  196]   Loss 0.022529   Top1 99.257812   Top5 100.000000   BatchTime 0.139570   LR 0.000010   
2022-11-04 00:24:55,139 - INFO  - Training [53][   80/  196]   Loss 0.022804   Top1 99.218750   Top5 100.000000   BatchTime 0.135583   LR 0.000010   
2022-11-04 00:24:57,621 - INFO  - Training [53][  100/  196]   Loss 0.023274   Top1 99.210938   Top5 100.000000   BatchTime 0.133285   LR 0.000010   
2022-11-04 00:25:00,112 - INFO  - Training [53][  120/  196]   Loss 0.023016   Top1 99.222005   Top5 100.000000   BatchTime 0.131828   LR 0.000010   
2022-11-04 00:25:02,591 - INFO  - Training [53][  140/  196]   Loss 0.022717   Top1 99.224330   Top5 100.000000   BatchTime 0.130700   LR 0.000010   
2022-11-04 00:25:05,060 - INFO  - Training [53][  160/  196]   Loss 0.022984   Top1 99.233398   Top5 99.997559   BatchTime 0.129795   LR 0.000010   
2022-11-04 00:25:07,528 - INFO  - Training [53][  180/  196]   Loss 0.022827   Top1 99.240451   Top5 99.997830   BatchTime 0.129086   LR 0.000010   
2022-11-04 00:25:09,743 - INFO  - ==> Top1: 99.232    Top5: 99.998    Loss: 0.023

2022-11-04 00:25:09,744 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:25:12,715 - INFO  - Validation [53][   20/   40]   Loss 0.438885   Top1 90.898438   Top5 99.609375   BatchTime 0.148466   
2022-11-04 00:25:13,851 - INFO  - Validation [53][   40/   40]   Loss 0.428290   Top1 90.950000   Top5 99.640000   BatchTime 0.102638   
2022-11-04 00:25:14,119 - INFO  - ==> Top1: 90.950    Top5: 99.640    Loss: 0.428

2022-11-04 00:25:14,149 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:25:14,149 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:25:14,150 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:25:14,243 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:25:14,243 - INFO  - >>>>>>>> Epoch  54
2022-11-04 00:25:14,245 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:25:18,738 - INFO  - Training [54][   20/  196]   Loss 0.021766   Top1 99.316406   Top5 100.000000   BatchTime 0.224647   LR 0.000010   
2022-11-04 00:25:21,217 - INFO  - Training [54][   40/  196]   Loss 0.021215   Top1 99.316406   Top5 100.000000   BatchTime 0.174307   LR 0.000010   
2022-11-04 00:25:23,688 - INFO  - Training [54][   60/  196]   Loss 0.021791   Top1 99.283854   Top5 100.000000   BatchTime 0.157380   LR 0.000010   
2022-11-04 00:25:26,174 - INFO  - Training [54][   80/  196]   Loss 0.021352   Top1 99.287109   Top5 100.000000   BatchTime 0.149112   LR 0.000010   
2022-11-04 00:25:28,662 - INFO  - Training [54][  100/  196]   Loss 0.021530   Top1 99.277344   Top5 100.000000   BatchTime 0.144174   LR 0.000010   
2022-11-04 00:25:31,130 - INFO  - Training [54][  120/  196]   Loss 0.021761   Top1 99.248047   Top5 100.000000   BatchTime 0.140713   LR 0.000010   
2022-11-04 00:25:33,683 - INFO  - Training [54][  140/  196]   Loss 0.021595   Top1 99.268973   Top5 100.000000   BatchTime 0.138841   LR 0.000010   
2022-11-04 00:25:36,139 - INFO  - Training [54][  160/  196]   Loss 0.021497   Top1 99.270020   Top5 100.000000   BatchTime 0.136835   LR 0.000010   
2022-11-04 00:25:37,953 - INFO  - Training [54][  180/  196]   Loss 0.022055   Top1 99.255642   Top5 100.000000   BatchTime 0.131712   LR 0.000010   
2022-11-04 00:25:39,778 - INFO  - ==> Top1: 99.242    Top5: 100.000    Loss: 0.023

2022-11-04 00:25:39,778 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:25:42,441 - INFO  - Validation [54][   20/   40]   Loss 0.435026   Top1 90.644531   Top5 99.628906   BatchTime 0.133028   
2022-11-04 00:25:43,138 - INFO  - Validation [54][   40/   40]   Loss 0.424341   Top1 90.950000   Top5 99.680000   BatchTime 0.083957   
2022-11-04 00:25:43,436 - INFO  - ==> Top1: 90.950    Top5: 99.680    Loss: 0.424

2022-11-04 00:25:43,477 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:25:43,478 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:25:43,478 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:25:43,631 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:25:43,631 - INFO  - >>>>>>>> Epoch  55
2022-11-04 00:25:43,632 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:25:48,087 - INFO  - Training [55][   20/  196]   Loss 0.020211   Top1 99.375000   Top5 100.000000   BatchTime 0.222724   LR 0.000010   
2022-11-04 00:25:50,565 - INFO  - Training [55][   40/  196]   Loss 0.021986   Top1 99.228516   Top5 100.000000   BatchTime 0.173328   LR 0.000010   
2022-11-04 00:25:53,051 - INFO  - Training [55][   60/  196]   Loss 0.022393   Top1 99.205729   Top5 100.000000   BatchTime 0.156978   LR 0.000010   
2022-11-04 00:25:55,527 - INFO  - Training [55][   80/  196]   Loss 0.023250   Top1 99.208984   Top5 100.000000   BatchTime 0.148686   LR 0.000010   
2022-11-04 00:25:58,011 - INFO  - Training [55][  100/  196]   Loss 0.023136   Top1 99.210938   Top5 100.000000   BatchTime 0.143792   LR 0.000010   
2022-11-04 00:26:00,488 - INFO  - Training [55][  120/  196]   Loss 0.022579   Top1 99.241536   Top5 100.000000   BatchTime 0.140462   LR 0.000010   
2022-11-04 00:26:02,960 - INFO  - Training [55][  140/  196]   Loss 0.022927   Top1 99.235491   Top5 100.000000   BatchTime 0.138052   LR 0.000010   
2022-11-04 00:26:05,427 - INFO  - Training [55][  160/  196]   Loss 0.023443   Top1 99.211426   Top5 100.000000   BatchTime 0.136218   LR 0.000010   
2022-11-04 00:26:07,893 - INFO  - Training [55][  180/  196]   Loss 0.023808   Top1 99.192708   Top5 100.000000   BatchTime 0.134782   LR 0.000010   
2022-11-04 00:26:10,094 - INFO  - ==> Top1: 99.204    Top5: 100.000    Loss: 0.024

2022-11-04 00:26:10,095 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:26:13,048 - INFO  - Validation [55][   20/   40]   Loss 0.438399   Top1 90.703125   Top5 99.609375   BatchTime 0.147530   
2022-11-04 00:26:14,152 - INFO  - Validation [55][   40/   40]   Loss 0.424771   Top1 90.970000   Top5 99.680000   BatchTime 0.101362   
2022-11-04 00:26:14,432 - INFO  - ==> Top1: 90.970    Top5: 99.680    Loss: 0.425

2022-11-04 00:26:14,470 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:26:14,471 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:26:14,471 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:26:14,578 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:26:14,579 - INFO  - >>>>>>>> Epoch  56
2022-11-04 00:26:14,581 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:26:19,060 - INFO  - Training [56][   20/  196]   Loss 0.019914   Top1 99.453125   Top5 100.000000   BatchTime 0.223960   LR 0.000010   
2022-11-04 00:26:21,532 - INFO  - Training [56][   40/  196]   Loss 0.022341   Top1 99.287109   Top5 100.000000   BatchTime 0.173791   LR 0.000010   
2022-11-04 00:26:24,005 - INFO  - Training [56][   60/  196]   Loss 0.021181   Top1 99.342448   Top5 100.000000   BatchTime 0.157069   LR 0.000010   
2022-11-04 00:26:26,484 - INFO  - Training [56][   80/  196]   Loss 0.022147   Top1 99.291992   Top5 100.000000   BatchTime 0.148785   LR 0.000010   
2022-11-04 00:26:28,888 - INFO  - Training [56][  100/  196]   Loss 0.022092   Top1 99.261719   Top5 100.000000   BatchTime 0.143075   LR 0.000010   
2022-11-04 00:26:30,744 - INFO  - Training [56][  120/  196]   Loss 0.022174   Top1 99.254557   Top5 100.000000   BatchTime 0.134695   LR 0.000010   
2022-11-04 00:26:32,785 - INFO  - Training [56][  140/  196]   Loss 0.022595   Top1 99.229911   Top5 100.000000   BatchTime 0.130024   LR 0.000010   
2022-11-04 00:26:34,787 - INFO  - Training [56][  160/  196]   Loss 0.022406   Top1 99.235840   Top5 100.000000   BatchTime 0.126286   LR 0.000010   
2022-11-04 00:26:36,647 - INFO  - Training [56][  180/  196]   Loss 0.022202   Top1 99.240451   Top5 100.000000   BatchTime 0.122588   LR 0.000010   
2022-11-04 00:26:38,523 - INFO  - ==> Top1: 99.244    Top5: 100.000    Loss: 0.022

2022-11-04 00:26:38,524 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:26:41,475 - INFO  - Validation [56][   20/   40]   Loss 0.432600   Top1 90.859375   Top5 99.628906   BatchTime 0.147475   
2022-11-04 00:26:42,603 - INFO  - Validation [56][   40/   40]   Loss 0.422994   Top1 90.930000   Top5 99.690000   BatchTime 0.101950   
2022-11-04 00:26:42,881 - INFO  - ==> Top1: 90.930    Top5: 99.690    Loss: 0.423

2022-11-04 00:26:42,929 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:26:42,930 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:26:42,930 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:26:43,036 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:26:43,036 - INFO  - >>>>>>>> Epoch  57
2022-11-04 00:26:43,038 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:26:47,538 - INFO  - Training [57][   20/  196]   Loss 0.018543   Top1 99.296875   Top5 100.000000   BatchTime 0.225027   LR 0.000010   
2022-11-04 00:26:50,023 - INFO  - Training [57][   40/  196]   Loss 0.018299   Top1 99.355469   Top5 100.000000   BatchTime 0.174619   LR 0.000010   
2022-11-04 00:26:52,527 - INFO  - Training [57][   60/  196]   Loss 0.018867   Top1 99.348958   Top5 100.000000   BatchTime 0.158151   LR 0.000010   
2022-11-04 00:26:55,011 - INFO  - Training [57][   80/  196]   Loss 0.020129   Top1 99.321289   Top5 100.000000   BatchTime 0.149664   LR 0.000010   
2022-11-04 00:26:57,484 - INFO  - Training [57][  100/  196]   Loss 0.021068   Top1 99.253906   Top5 100.000000   BatchTime 0.144460   LR 0.000010   
2022-11-04 00:26:59,966 - INFO  - Training [57][  120/  196]   Loss 0.020760   Top1 99.277344   Top5 100.000000   BatchTime 0.141062   LR 0.000010   
2022-11-04 00:27:02,434 - INFO  - Training [57][  140/  196]   Loss 0.020899   Top1 99.296875   Top5 100.000000   BatchTime 0.138542   LR 0.000010   
2022-11-04 00:27:04,908 - INFO  - Training [57][  160/  196]   Loss 0.021161   Top1 99.287109   Top5 100.000000   BatchTime 0.136684   LR 0.000010   
2022-11-04 00:27:07,378 - INFO  - Training [57][  180/  196]   Loss 0.021200   Top1 99.283854   Top5 100.000000   BatchTime 0.135222   LR 0.000010   
2022-11-04 00:27:09,579 - INFO  - ==> Top1: 99.274    Top5: 100.000    Loss: 0.021

2022-11-04 00:27:09,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:27:12,544 - INFO  - Validation [57][   20/   40]   Loss 0.433744   Top1 90.878906   Top5 99.531250   BatchTime 0.148135   
2022-11-04 00:27:13,697 - INFO  - Validation [57][   40/   40]   Loss 0.422811   Top1 90.840000   Top5 99.630000   BatchTime 0.102896   
2022-11-04 00:27:13,960 - INFO  - ==> Top1: 90.840    Top5: 99.630    Loss: 0.423

2022-11-04 00:27:14,006 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:27:14,007 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:27:14,007 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:27:14,099 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:27:14,099 - INFO  - >>>>>>>> Epoch  58
2022-11-04 00:27:14,100 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:27:18,545 - INFO  - Training [58][   20/  196]   Loss 0.020418   Top1 99.414062   Top5 100.000000   BatchTime 0.222240   LR 0.000010   
2022-11-04 00:27:20,937 - INFO  - Training [58][   40/  196]   Loss 0.022134   Top1 99.257812   Top5 100.000000   BatchTime 0.170900   LR 0.000010   
2022-11-04 00:27:22,784 - INFO  - Training [58][   60/  196]   Loss 0.023083   Top1 99.212240   Top5 100.000000   BatchTime 0.144726   LR 0.000010   
2022-11-04 00:27:24,828 - INFO  - Training [58][   80/  196]   Loss 0.022514   Top1 99.218750   Top5 100.000000   BatchTime 0.134085   LR 0.000010   
2022-11-04 00:27:26,903 - INFO  - Training [58][  100/  196]   Loss 0.022571   Top1 99.218750   Top5 99.996094   BatchTime 0.128020   LR 0.000010   
2022-11-04 00:27:28,823 - INFO  - Training [58][  120/  196]   Loss 0.022289   Top1 99.235026   Top5 99.996745   BatchTime 0.122687   LR 0.000010   
2022-11-04 00:27:31,144 - INFO  - Training [58][  140/  196]   Loss 0.022702   Top1 99.232701   Top5 99.997210   BatchTime 0.121736   LR 0.000010   
2022-11-04 00:27:33,606 - INFO  - Training [58][  160/  196]   Loss 0.022827   Top1 99.218750   Top5 99.997559   BatchTime 0.121905   LR 0.000010   
2022-11-04 00:27:36,073 - INFO  - Training [58][  180/  196]   Loss 0.022679   Top1 99.227431   Top5 99.997830   BatchTime 0.122064   LR 0.000010   
2022-11-04 00:27:38,417 - INFO  - ==> Top1: 99.232    Top5: 99.998    Loss: 0.023

2022-11-04 00:27:38,418 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:27:41,410 - INFO  - Validation [58][   20/   40]   Loss 0.435743   Top1 90.585938   Top5 99.628906   BatchTime 0.149554   
2022-11-04 00:27:42,535 - INFO  - Validation [58][   40/   40]   Loss 0.426465   Top1 90.740000   Top5 99.650000   BatchTime 0.102892   
2022-11-04 00:27:42,820 - INFO  - ==> Top1: 90.740    Top5: 99.650    Loss: 0.426

2022-11-04 00:27:42,854 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:27:42,855 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:27:42,855 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:27:42,960 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:27:42,960 - INFO  - >>>>>>>> Epoch  59
2022-11-04 00:27:42,962 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-04 00:27:47,483 - INFO  - Training [59][   20/  196]   Loss 0.019834   Top1 99.414062   Top5 100.000000   BatchTime 0.226064   LR 0.000010   
2022-11-04 00:27:49,971 - INFO  - Training [59][   40/  196]   Loss 0.020152   Top1 99.384766   Top5 100.000000   BatchTime 0.175210   LR 0.000010   
2022-11-04 00:27:52,452 - INFO  - Training [59][   60/  196]   Loss 0.022005   Top1 99.348958   Top5 99.993490   BatchTime 0.158168   LR 0.000010   
2022-11-04 00:27:54,939 - INFO  - Training [59][   80/  196]   Loss 0.022069   Top1 99.375000   Top5 99.995117   BatchTime 0.149707   LR 0.000010   
2022-11-04 00:27:57,454 - INFO  - Training [59][  100/  196]   Loss 0.022791   Top1 99.316406   Top5 99.996094   BatchTime 0.144913   LR 0.000010   
2022-11-04 00:27:59,956 - INFO  - Training [59][  120/  196]   Loss 0.022697   Top1 99.313151   Top5 99.996745   BatchTime 0.141613   LR 0.000010   
2022-11-04 00:28:02,435 - INFO  - Training [59][  140/  196]   Loss 0.022465   Top1 99.327567   Top5 99.997210   BatchTime 0.139086   LR 0.000010   
2022-11-04 00:28:04,906 - INFO  - Training [59][  160/  196]   Loss 0.022981   Top1 99.299316   Top5 99.997559   BatchTime 0.137148   LR 0.000010   
2022-11-04 00:28:07,390 - INFO  - Training [59][  180/  196]   Loss 0.022991   Top1 99.288194   Top5 99.997830   BatchTime 0.135707   LR 0.000010   
2022-11-04 00:28:09,548 - INFO  - ==> Top1: 99.286    Top5: 99.998    Loss: 0.023

2022-11-04 00:28:09,549 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:28:12,526 - INFO  - Validation [59][   20/   40]   Loss 0.432156   Top1 90.898438   Top5 99.589844   BatchTime 0.148815   
2022-11-04 00:28:13,470 - INFO  - Validation [59][   40/   40]   Loss 0.423042   Top1 90.880000   Top5 99.650000   BatchTime 0.098007   
2022-11-04 00:28:13,748 - INFO  - ==> Top1: 90.880    Top5: 99.650    Loss: 0.423

2022-11-04 00:28:13,770 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 91.200   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:28:13,771 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 91.070   Top5: 99.650] Sparsity : 0.836
2022-11-04 00:28:13,771 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.060   Top5: 99.680] Sparsity : 0.836
2022-11-04 00:28:13,874 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_20221103-235803/MobileNetv2_cifar10_a8w8_hard_pruning_10_epoch60_checkpoint.pth.tar

2022-11-04 00:28:13,875 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-04 00:28:13,875 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-04 00:28:16,647 - INFO  - Validation [   20/   40]   Loss 0.432156   Top1 90.898438   Top5 99.589844   BatchTime 0.138520   
2022-11-04 00:28:17,497 - INFO  - Validation [   40/   40]   Loss 0.423042   Top1 90.880000   Top5 99.650000   BatchTime 0.090507   
2022-11-04 00:28:17,788 - INFO  - ==> Top1: 90.880    Top5: 99.650    Loss: 0.423

2022-11-04 00:28:17,820 - INFO  - Program completed successfully ... exiting ...
2022-11-04 00:28:17,820 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
