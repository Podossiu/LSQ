2022-11-03 21:39:52,680 - INFO  - Log file for this run: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952.log
2022-11-03 21:39:53,721 - INFO  - TensorBoard data directory: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/tb_runs
2022-11-03 21:39:54,826 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (391)
        Validation Set = 10000 (79)
              Test Set = 10000 (79)
2022-11-03 21:39:56,607 - INFO  - Created `MobileNetv2` model for `cifar10` dataset
          Use pre-trained model = True
2022-11-03 21:39:58,841 - INFO  - Inserted quantizers into the original model
2022-11-03 21:39:59,120 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 4e-05
           )
2022-11-03 21:39:59,120 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-11-03 21:39:59,120 - INFO  - >>>>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-03 21:39:59,120 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:40:02,802 - INFO  - Validation [   20/   79]   Loss 2.545371   Top1 10.429688   Top5 49.101562   BatchTime 0.184069   
2022-11-03 21:40:03,692 - INFO  - Validation [   40/   79]   Loss 2.549466   Top1 10.175781   Top5 49.941406   BatchTime 0.114272   
2022-11-03 21:40:04,585 - INFO  - Validation [   60/   79]   Loss 2.541519   Top1 10.117188   Top5 50.377604   BatchTime 0.091064   
2022-11-03 21:40:05,739 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.546

2022-11-03 21:40:05,774 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 21:40:05,774 - INFO  - >>>>>>>> Epoch   0
2022-11-03 21:40:05,775 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:40:09,903 - INFO  - Training [0][   20/  391]   Loss 1.620116   Top1 67.656250   Top5 96.757812   BatchTime 0.206379   LR 0.010000   
2022-11-03 21:40:11,940 - INFO  - Training [0][   40/  391]   Loss 1.341391   Top1 69.199219   Top5 97.207031   BatchTime 0.154121   LR 0.010000   
2022-11-03 21:40:13,964 - INFO  - Training [0][   60/  391]   Loss 1.171755   Top1 70.260417   Top5 97.552083   BatchTime 0.136468   LR 0.010000   
2022-11-03 21:40:15,958 - INFO  - Training [0][   80/  391]   Loss 1.050288   Top1 71.992188   Top5 97.900391   BatchTime 0.127277   LR 0.010000   
2022-11-03 21:40:17,958 - INFO  - Training [0][  100/  391]   Loss 0.955926   Top1 73.640625   Top5 98.117188   BatchTime 0.121821   LR 0.010000   
2022-11-03 21:40:20,055 - INFO  - Training [0][  120/  391]   Loss 0.882038   Top1 75.084635   Top5 98.326823   BatchTime 0.118992   LR 0.010000   
2022-11-03 21:40:21,578 - INFO  - Training [0][  140/  391]   Loss 0.826354   Top1 76.104911   Top5 98.476562   BatchTime 0.112873   LR 0.010000   
2022-11-03 21:40:23,297 - INFO  - Training [0][  160/  391]   Loss 0.783205   Top1 77.026367   Top5 98.613281   BatchTime 0.109510   LR 0.010000   
2022-11-03 21:40:24,921 - INFO  - Training [0][  180/  391]   Loss 0.742411   Top1 77.947049   Top5 98.728299   BatchTime 0.106363   LR 0.010000   
2022-11-03 21:40:26,663 - INFO  - Training [0][  200/  391]   Loss 0.715892   Top1 78.484375   Top5 98.808594   BatchTime 0.104436   LR 0.010000   
2022-11-03 21:40:28,522 - INFO  - Training [0][  220/  391]   Loss 0.689337   Top1 79.094460   Top5 98.884943   BatchTime 0.103393   LR 0.010000   
2022-11-03 21:40:30,538 - INFO  - Training [0][  240/  391]   Loss 0.666872   Top1 79.632161   Top5 98.922526   BatchTime 0.103176   LR 0.010000   
2022-11-03 21:40:32,542 - INFO  - Training [0][  260/  391]   Loss 0.646147   Top1 80.102163   Top5 98.972356   BatchTime 0.102946   LR 0.010000   
2022-11-03 21:40:34,547 - INFO  - Training [0][  280/  391]   Loss 0.628827   Top1 80.516183   Top5 99.017857   BatchTime 0.102753   LR 0.010000   
2022-11-03 21:40:36,562 - INFO  - Training [0][  300/  391]   Loss 0.614083   Top1 80.880208   Top5 99.046875   BatchTime 0.102619   LR 0.010000   
2022-11-03 21:40:38,594 - INFO  - Training [0][  320/  391]   Loss 0.598902   Top1 81.208496   Top5 99.084473   BatchTime 0.102557   LR 0.010000   
2022-11-03 21:40:40,584 - INFO  - Training [0][  340/  391]   Loss 0.585690   Top1 81.546415   Top5 99.124540   BatchTime 0.102375   LR 0.010000   
2022-11-03 21:40:42,579 - INFO  - Training [0][  360/  391]   Loss 0.571510   Top1 81.935764   Top5 99.162326   BatchTime 0.102230   LR 0.010000   
2022-11-03 21:40:44,700 - INFO  - Training [0][  380/  391]   Loss 0.561064   Top1 82.208059   Top5 99.183799   BatchTime 0.102432   LR 0.010000   
2022-11-03 21:40:46,366 - INFO  - ==> Top1: 82.352    Top5: 99.192    Loss: 0.556

2022-11-03 21:40:46,367 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:40:49,020 - INFO  - Validation [0][   20/   79]   Loss 0.461781   Top1 84.414062   Top5 99.492188   BatchTime 0.132597   
2022-11-03 21:40:49,881 - INFO  - Validation [0][   40/   79]   Loss 0.461809   Top1 84.472656   Top5 99.257812   BatchTime 0.087814   
2022-11-03 21:40:50,787 - INFO  - Validation [0][   60/   79]   Loss 0.461702   Top1 84.661458   Top5 99.192708   BatchTime 0.073651   
2022-11-03 21:40:51,880 - INFO  - ==> Top1: 84.710    Top5: 99.210    Loss: 0.457

2022-11-03 21:40:51,910 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.710   Top5: 99.210] Sparsity : 0.556
2022-11-03 21:40:51,910 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 21:40:51,974 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:40:51,975 - INFO  - >>>>>>>> Epoch   1
2022-11-03 21:40:51,975 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:40:55,780 - INFO  - Training [1][   20/  391]   Loss 0.315728   Top1 89.101562   Top5 99.726562   BatchTime 0.190239   LR 0.010000   
2022-11-03 21:40:57,814 - INFO  - Training [1][   40/  391]   Loss 0.312323   Top1 89.082031   Top5 99.589844   BatchTime 0.145966   LR 0.010000   
2022-11-03 21:40:59,817 - INFO  - Training [1][   60/  391]   Loss 0.314719   Top1 88.893229   Top5 99.700521   BatchTime 0.130683   LR 0.010000   
2022-11-03 21:41:01,795 - INFO  - Training [1][   80/  391]   Loss 0.315109   Top1 88.925781   Top5 99.736328   BatchTime 0.122739   LR 0.010000   
2022-11-03 21:41:03,766 - INFO  - Training [1][  100/  391]   Loss 0.310114   Top1 89.070312   Top5 99.757812   BatchTime 0.117905   LR 0.010000   
2022-11-03 21:41:05,754 - INFO  - Training [1][  120/  391]   Loss 0.307907   Top1 89.134115   Top5 99.752604   BatchTime 0.114822   LR 0.010000   
2022-11-03 21:41:07,272 - INFO  - Training [1][  140/  391]   Loss 0.301855   Top1 89.280134   Top5 99.771205   BatchTime 0.109257   LR 0.010000   
2022-11-03 21:41:09,020 - INFO  - Training [1][  160/  391]   Loss 0.299497   Top1 89.428711   Top5 99.780273   BatchTime 0.106527   LR 0.010000   
2022-11-03 21:41:10,666 - INFO  - Training [1][  180/  391]   Loss 0.297398   Top1 89.461806   Top5 99.791667   BatchTime 0.103834   LR 0.010000   
2022-11-03 21:41:12,344 - INFO  - Training [1][  200/  391]   Loss 0.296842   Top1 89.492188   Top5 99.792969   BatchTime 0.101841   LR 0.010000   
2022-11-03 21:41:14,158 - INFO  - Training [1][  220/  391]   Loss 0.296862   Top1 89.534801   Top5 99.783381   BatchTime 0.100827   LR 0.010000   
2022-11-03 21:41:16,158 - INFO  - Training [1][  240/  391]   Loss 0.295266   Top1 89.622396   Top5 99.785156   BatchTime 0.100759   LR 0.010000   
2022-11-03 21:41:18,158 - INFO  - Training [1][  260/  391]   Loss 0.293571   Top1 89.672476   Top5 99.789663   BatchTime 0.100701   LR 0.010000   
2022-11-03 21:41:20,148 - INFO  - Training [1][  280/  391]   Loss 0.291404   Top1 89.773996   Top5 99.790737   BatchTime 0.100614   LR 0.010000   
2022-11-03 21:41:22,154 - INFO  - Training [1][  300/  391]   Loss 0.288129   Top1 89.872396   Top5 99.794271   BatchTime 0.100594   LR 0.010000   
2022-11-03 21:41:24,169 - INFO  - Training [1][  320/  391]   Loss 0.285465   Top1 89.970703   Top5 99.797363   BatchTime 0.100602   LR 0.010000   
2022-11-03 21:41:26,162 - INFO  - Training [1][  340/  391]   Loss 0.283260   Top1 90.039062   Top5 99.806985   BatchTime 0.100548   LR 0.010000   
2022-11-03 21:41:28,133 - INFO  - Training [1][  360/  391]   Loss 0.281494   Top1 90.101997   Top5 99.813368   BatchTime 0.100434   LR 0.010000   
2022-11-03 21:41:30,116 - INFO  - Training [1][  380/  391]   Loss 0.280360   Top1 90.156250   Top5 99.814967   BatchTime 0.100367   LR 0.010000   
2022-11-03 21:41:31,446 - INFO  - ==> Top1: 90.224    Top5: 99.820    Loss: 0.279

2022-11-03 21:41:31,446 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:41:34,077 - INFO  - Validation [1][   20/   79]   Loss 0.430041   Top1 86.210938   Top5 99.570312   BatchTime 0.131488   
2022-11-03 21:41:34,972 - INFO  - Validation [1][   40/   79]   Loss 0.437866   Top1 86.328125   Top5 99.433594   BatchTime 0.088117   
2022-11-03 21:41:35,861 - INFO  - Validation [1][   60/   79]   Loss 0.430177   Top1 86.510417   Top5 99.453125   BatchTime 0.073552   
2022-11-03 21:41:36,985 - INFO  - ==> Top1: 86.590    Top5: 99.500    Loss: 0.425

2022-11-03 21:41:37,017 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.590   Top5: 99.500] Sparsity : 0.587
2022-11-03 21:41:37,018 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.710   Top5: 99.210] Sparsity : 0.556
2022-11-03 21:41:37,018 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 10.000   Top5: 50.000] Sparsity : 0.062
2022-11-03 21:41:37,207 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:41:37,207 - INFO  - >>>>>>>> Epoch   2
2022-11-03 21:41:37,208 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:41:41,002 - INFO  - Training [2][   20/  391]   Loss 0.204896   Top1 92.890625   Top5 99.843750   BatchTime 0.189701   LR 0.010000   
2022-11-03 21:41:43,040 - INFO  - Training [2][   40/  391]   Loss 0.210663   Top1 92.480469   Top5 99.882812   BatchTime 0.145798   LR 0.010000   
2022-11-03 21:41:45,026 - INFO  - Training [2][   60/  391]   Loss 0.210829   Top1 92.447917   Top5 99.908854   BatchTime 0.130304   LR 0.010000   
2022-11-03 21:41:47,027 - INFO  - Training [2][   80/  391]   Loss 0.211054   Top1 92.548828   Top5 99.892578   BatchTime 0.122728   LR 0.010000   
2022-11-03 21:41:48,996 - INFO  - Training [2][  100/  391]   Loss 0.212742   Top1 92.500000   Top5 99.906250   BatchTime 0.117878   LR 0.010000   
2022-11-03 21:41:50,996 - INFO  - Training [2][  120/  391]   Loss 0.212680   Top1 92.565104   Top5 99.921875   BatchTime 0.114899   LR 0.010000   
2022-11-03 21:41:52,525 - INFO  - Training [2][  140/  391]   Loss 0.210729   Top1 92.656250   Top5 99.905134   BatchTime 0.109406   LR 0.010000   
2022-11-03 21:41:54,218 - INFO  - Training [2][  160/  391]   Loss 0.210712   Top1 92.700195   Top5 99.902344   BatchTime 0.106309   LR 0.010000   
2022-11-03 21:41:55,847 - INFO  - Training [2][  180/  391]   Loss 0.210591   Top1 92.677951   Top5 99.904514   BatchTime 0.103547   LR 0.010000   
2022-11-03 21:41:57,553 - INFO  - Training [2][  200/  391]   Loss 0.208579   Top1 92.761719   Top5 99.902344   BatchTime 0.101723   LR 0.010000   
2022-11-03 21:41:59,341 - INFO  - Training [2][  220/  391]   Loss 0.209844   Top1 92.723722   Top5 99.893466   BatchTime 0.100601   LR 0.010000   
2022-11-03 21:42:01,353 - INFO  - Training [2][  240/  391]   Loss 0.209197   Top1 92.747396   Top5 99.902344   BatchTime 0.100602   LR 0.010000   
2022-11-03 21:42:03,358 - INFO  - Training [2][  260/  391]   Loss 0.208990   Top1 92.746394   Top5 99.903846   BatchTime 0.100576   LR 0.010000   
2022-11-03 21:42:05,363 - INFO  - Training [2][  280/  391]   Loss 0.208830   Top1 92.745536   Top5 99.905134   BatchTime 0.100552   LR 0.010000   
2022-11-03 21:42:07,376 - INFO  - Training [2][  300/  391]   Loss 0.208929   Top1 92.791667   Top5 99.898438   BatchTime 0.100557   LR 0.010000   
2022-11-03 21:42:09,374 - INFO  - Training [2][  320/  391]   Loss 0.206933   Top1 92.841797   Top5 99.899902   BatchTime 0.100517   LR 0.010000   
2022-11-03 21:42:11,346 - INFO  - Training [2][  340/  391]   Loss 0.205588   Top1 92.890625   Top5 99.901195   BatchTime 0.100402   LR 0.010000   
2022-11-03 21:42:13,315 - INFO  - Training [2][  360/  391]   Loss 0.203773   Top1 92.940538   Top5 99.898003   BatchTime 0.100295   LR 0.010000   
2022-11-03 21:42:15,295 - INFO  - Training [2][  380/  391]   Loss 0.202421   Top1 93.005757   Top5 99.903372   BatchTime 0.100226   LR 0.010000   
2022-11-03 21:42:16,622 - INFO  - ==> Top1: 93.012    Top5: 99.904    Loss: 0.202

2022-11-03 21:42:16,623 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:42:19,259 - INFO  - Validation [2][   20/   79]   Loss 0.404757   Top1 87.773438   Top5 99.453125   BatchTime 0.131739   
2022-11-03 21:42:20,167 - INFO  - Validation [2][   40/   79]   Loss 0.410888   Top1 87.636719   Top5 99.472656   BatchTime 0.088563   
2022-11-03 21:42:21,039 - INFO  - Validation [2][   60/   79]   Loss 0.397854   Top1 87.994792   Top5 99.492188   BatchTime 0.073580   
2022-11-03 21:42:22,140 - INFO  - ==> Top1: 87.960    Top5: 99.560    Loss: 0.397

2022-11-03 21:42:22,186 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.960   Top5: 99.560] Sparsity : 0.599
2022-11-03 21:42:22,187 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.590   Top5: 99.500] Sparsity : 0.587
2022-11-03 21:42:22,187 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 84.710   Top5: 99.210] Sparsity : 0.556
2022-11-03 21:42:22,357 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:42:22,357 - INFO  - >>>>>>>> Epoch   3
2022-11-03 21:42:22,358 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:42:26,305 - INFO  - Training [3][   20/  391]   Loss 0.160537   Top1 94.140625   Top5 99.960938   BatchTime 0.197338   LR 0.010000   
2022-11-03 21:42:28,356 - INFO  - Training [3][   40/  391]   Loss 0.157223   Top1 94.140625   Top5 99.960938   BatchTime 0.149949   LR 0.010000   
2022-11-03 21:42:30,369 - INFO  - Training [3][   60/  391]   Loss 0.156365   Top1 94.192708   Top5 99.960938   BatchTime 0.133513   LR 0.010000   
2022-11-03 21:42:32,358 - INFO  - Training [3][   80/  391]   Loss 0.156745   Top1 94.218750   Top5 99.960938   BatchTime 0.125002   LR 0.010000   
2022-11-03 21:42:34,335 - INFO  - Training [3][  100/  391]   Loss 0.159821   Top1 94.164062   Top5 99.937500   BatchTime 0.119771   LR 0.010000   
2022-11-03 21:42:36,434 - INFO  - Training [3][  120/  391]   Loss 0.160639   Top1 94.173177   Top5 99.941406   BatchTime 0.117299   LR 0.010000   
2022-11-03 21:42:38,028 - INFO  - Training [3][  140/  391]   Loss 0.159576   Top1 94.168527   Top5 99.944196   BatchTime 0.111928   LR 0.010000   
2022-11-03 21:42:39,748 - INFO  - Training [3][  160/  391]   Loss 0.161951   Top1 94.165039   Top5 99.941406   BatchTime 0.108686   LR 0.010000   
2022-11-03 21:42:41,461 - INFO  - Training [3][  180/  391]   Loss 0.162225   Top1 94.188368   Top5 99.943576   BatchTime 0.106127   LR 0.010000   
2022-11-03 21:42:43,189 - INFO  - Training [3][  200/  391]   Loss 0.161925   Top1 94.203125   Top5 99.945312   BatchTime 0.104154   LR 0.010000   
2022-11-03 21:42:45,013 - INFO  - Training [3][  220/  391]   Loss 0.162869   Top1 94.176136   Top5 99.950284   BatchTime 0.102975   LR 0.010000   
2022-11-03 21:42:47,025 - INFO  - Training [3][  240/  391]   Loss 0.162702   Top1 94.156901   Top5 99.951172   BatchTime 0.102777   LR 0.010000   
2022-11-03 21:42:49,062 - INFO  - Training [3][  260/  391]   Loss 0.164054   Top1 94.104567   Top5 99.948918   BatchTime 0.102705   LR 0.010000   
2022-11-03 21:42:51,051 - INFO  - Training [3][  280/  391]   Loss 0.164942   Top1 94.101562   Top5 99.946987   BatchTime 0.102474   LR 0.010000   
2022-11-03 21:42:53,047 - INFO  - Training [3][  300/  391]   Loss 0.164933   Top1 94.109375   Top5 99.947917   BatchTime 0.102295   LR 0.010000   
2022-11-03 21:42:55,052 - INFO  - Training [3][  320/  391]   Loss 0.164614   Top1 94.128418   Top5 99.948730   BatchTime 0.102166   LR 0.010000   
2022-11-03 21:42:57,055 - INFO  - Training [3][  340/  391]   Loss 0.165133   Top1 94.103860   Top5 99.944853   BatchTime 0.102047   LR 0.010000   
2022-11-03 21:42:59,025 - INFO  - Training [3][  360/  391]   Loss 0.164938   Top1 94.110243   Top5 99.947917   BatchTime 0.101850   LR 0.010000   
2022-11-03 21:43:01,004 - INFO  - Training [3][  380/  391]   Loss 0.163812   Top1 94.159128   Top5 99.950658   BatchTime 0.101697   LR 0.010000   
2022-11-03 21:43:02,342 - INFO  - ==> Top1: 94.192    Top5: 99.950    Loss: 0.164

2022-11-03 21:43:02,343 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:43:05,023 - INFO  - Validation [3][   20/   79]   Loss 0.410078   Top1 87.421875   Top5 99.492188   BatchTime 0.133920   
2022-11-03 21:43:05,911 - INFO  - Validation [3][   40/   79]   Loss 0.403555   Top1 88.046875   Top5 99.453125   BatchTime 0.089173   
2022-11-03 21:43:06,806 - INFO  - Validation [3][   60/   79]   Loss 0.396281   Top1 88.281250   Top5 99.466146   BatchTime 0.074364   
2022-11-03 21:43:07,936 - INFO  - ==> Top1: 88.330    Top5: 99.490    Loss: 0.393

2022-11-03 21:43:07,974 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 88.330   Top5: 99.490] Sparsity : 0.623
2022-11-03 21:43:07,975 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.960   Top5: 99.560] Sparsity : 0.599
2022-11-03 21:43:07,975 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.590   Top5: 99.500] Sparsity : 0.587
2022-11-03 21:43:08,156 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:43:08,157 - INFO  - >>>>>>>> Epoch   4
2022-11-03 21:43:08,158 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:43:11,989 - INFO  - Training [4][   20/  391]   Loss 0.141287   Top1 94.687500   Top5 100.000000   BatchTime 0.191522   LR 0.010000   
2022-11-03 21:43:14,005 - INFO  - Training [4][   40/  391]   Loss 0.146788   Top1 94.746094   Top5 100.000000   BatchTime 0.146165   LR 0.010000   
2022-11-03 21:43:16,015 - INFO  - Training [4][   60/  391]   Loss 0.143285   Top1 94.921875   Top5 100.000000   BatchTime 0.130936   LR 0.010000   
2022-11-03 21:43:18,001 - INFO  - Training [4][   80/  391]   Loss 0.139712   Top1 94.970703   Top5 99.990234   BatchTime 0.123037   LR 0.010000   
2022-11-03 21:43:19,996 - INFO  - Training [4][  100/  391]   Loss 0.144026   Top1 94.843750   Top5 99.976562   BatchTime 0.118373   LR 0.010000   
2022-11-03 21:43:22,091 - INFO  - Training [4][  120/  391]   Loss 0.143390   Top1 94.908854   Top5 99.973958   BatchTime 0.116101   LR 0.010000   
2022-11-03 21:43:23,605 - INFO  - Training [4][  140/  391]   Loss 0.144684   Top1 94.866071   Top5 99.972098   BatchTime 0.110330   LR 0.010000   
2022-11-03 21:43:25,360 - INFO  - Training [4][  160/  391]   Loss 0.144451   Top1 94.877930   Top5 99.970703   BatchTime 0.107509   LR 0.010000   
2022-11-03 21:43:27,060 - INFO  - Training [4][  180/  391]   Loss 0.145051   Top1 94.865451   Top5 99.973958   BatchTime 0.105010   LR 0.010000   
2022-11-03 21:43:28,782 - INFO  - Training [4][  200/  391]   Loss 0.144969   Top1 94.871094   Top5 99.976562   BatchTime 0.103117   LR 0.010000   
2022-11-03 21:43:30,555 - INFO  - Training [4][  220/  391]   Loss 0.143766   Top1 94.914773   Top5 99.975142   BatchTime 0.101801   LR 0.010000   
2022-11-03 21:43:32,551 - INFO  - Training [4][  240/  391]   Loss 0.143255   Top1 94.928385   Top5 99.973958   BatchTime 0.101634   LR 0.010000   
2022-11-03 21:43:34,557 - INFO  - Training [4][  260/  391]   Loss 0.142877   Top1 94.945913   Top5 99.975962   BatchTime 0.101530   LR 0.010000   
2022-11-03 21:43:36,558 - INFO  - Training [4][  280/  391]   Loss 0.142614   Top1 94.927455   Top5 99.972098   BatchTime 0.101424   LR 0.010000   
2022-11-03 21:43:38,561 - INFO  - Training [4][  300/  391]   Loss 0.142233   Top1 94.924479   Top5 99.971354   BatchTime 0.101341   LR 0.010000   
2022-11-03 21:43:40,550 - INFO  - Training [4][  320/  391]   Loss 0.141432   Top1 94.936523   Top5 99.973145   BatchTime 0.101221   LR 0.010000   
2022-11-03 21:43:42,534 - INFO  - Training [4][  340/  391]   Loss 0.140592   Top1 94.956342   Top5 99.972426   BatchTime 0.101102   LR 0.010000   
2022-11-03 21:43:44,504 - INFO  - Training [4][  360/  391]   Loss 0.141274   Top1 94.939236   Top5 99.971788   BatchTime 0.100957   LR 0.010000   
2022-11-03 21:43:46,399 - INFO  - Training [4][  380/  391]   Loss 0.141651   Top1 94.938322   Top5 99.971217   BatchTime 0.100631   LR 0.010000   
2022-11-03 21:43:47,729 - INFO  - ==> Top1: 94.938    Top5: 99.972    Loss: 0.142

2022-11-03 21:43:47,730 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:43:50,356 - INFO  - Validation [4][   20/   79]   Loss 0.404349   Top1 88.242188   Top5 99.414062   BatchTime 0.131245   
2022-11-03 21:43:51,250 - INFO  - Validation [4][   40/   79]   Loss 0.407602   Top1 88.261719   Top5 99.355469   BatchTime 0.087960   
2022-11-03 21:43:52,149 - INFO  - Validation [4][   60/   79]   Loss 0.390006   Top1 88.606771   Top5 99.427083   BatchTime 0.073619   
2022-11-03 21:43:53,223 - INFO  - ==> Top1: 88.570    Top5: 99.500    Loss: 0.385

2022-11-03 21:43:53,253 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.570   Top5: 99.500] Sparsity : 0.655
2022-11-03 21:43:53,253 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 88.330   Top5: 99.490] Sparsity : 0.623
2022-11-03 21:43:53,253 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.960   Top5: 99.560] Sparsity : 0.599
2022-11-03 21:43:53,447 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:43:53,448 - INFO  - >>>>>>>> Epoch   5
2022-11-03 21:43:53,449 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:43:57,281 - INFO  - Training [5][   20/  391]   Loss 0.140237   Top1 95.234375   Top5 99.960938   BatchTime 0.191590   LR 0.010000   
2022-11-03 21:43:59,281 - INFO  - Training [5][   40/  391]   Loss 0.127799   Top1 95.429688   Top5 99.980469   BatchTime 0.145803   LR 0.010000   
2022-11-03 21:44:01,412 - INFO  - Training [5][   60/  391]   Loss 0.129978   Top1 95.494792   Top5 99.973958   BatchTime 0.132716   LR 0.010000   
2022-11-03 21:44:03,381 - INFO  - Training [5][   80/  391]   Loss 0.128825   Top1 95.468750   Top5 99.970703   BatchTime 0.124148   LR 0.010000   
2022-11-03 21:44:05,360 - INFO  - Training [5][  100/  391]   Loss 0.125827   Top1 95.609375   Top5 99.968750   BatchTime 0.119117   LR 0.010000   
2022-11-03 21:44:07,325 - INFO  - Training [5][  120/  391]   Loss 0.127451   Top1 95.572917   Top5 99.973958   BatchTime 0.115639   LR 0.010000   
2022-11-03 21:44:09,014 - INFO  - Training [5][  140/  391]   Loss 0.126742   Top1 95.619420   Top5 99.977679   BatchTime 0.111181   LR 0.010000   
2022-11-03 21:44:10,737 - INFO  - Training [5][  160/  391]   Loss 0.127463   Top1 95.556641   Top5 99.975586   BatchTime 0.108052   LR 0.010000   
2022-11-03 21:44:12,371 - INFO  - Training [5][  180/  391]   Loss 0.127669   Top1 95.542535   Top5 99.978299   BatchTime 0.105125   LR 0.010000   
2022-11-03 21:44:14,053 - INFO  - Training [5][  200/  391]   Loss 0.128914   Top1 95.558594   Top5 99.972656   BatchTime 0.103018   LR 0.010000   
2022-11-03 21:44:15,744 - INFO  - Training [5][  220/  391]   Loss 0.132456   Top1 95.404830   Top5 99.975142   BatchTime 0.101340   LR 0.010000   
2022-11-03 21:44:17,755 - INFO  - Training [5][  240/  391]   Loss 0.133493   Top1 95.393880   Top5 99.973958   BatchTime 0.101275   LR 0.010000   
2022-11-03 21:44:19,766 - INFO  - Training [5][  260/  391]   Loss 0.133973   Top1 95.366587   Top5 99.972957   BatchTime 0.101218   LR 0.010000   
2022-11-03 21:44:21,790 - INFO  - Training [5][  280/  391]   Loss 0.134720   Top1 95.329241   Top5 99.972098   BatchTime 0.101219   LR 0.010000   
2022-11-03 21:44:23,787 - INFO  - Training [5][  300/  391]   Loss 0.135993   Top1 95.268229   Top5 99.968750   BatchTime 0.101125   LR 0.010000   
2022-11-03 21:44:25,796 - INFO  - Training [5][  320/  391]   Loss 0.136221   Top1 95.251465   Top5 99.968262   BatchTime 0.101084   LR 0.010000   
2022-11-03 21:44:27,792 - INFO  - Training [5][  340/  391]   Loss 0.137470   Top1 95.202206   Top5 99.967831   BatchTime 0.101007   LR 0.010000   
2022-11-03 21:44:29,774 - INFO  - Training [5][  360/  391]   Loss 0.137232   Top1 95.199653   Top5 99.967448   BatchTime 0.100901   LR 0.010000   
2022-11-03 21:44:31,764 - INFO  - Training [5][  380/  391]   Loss 0.138025   Top1 95.189145   Top5 99.967105   BatchTime 0.100828   LR 0.010000   
2022-11-03 21:44:33,120 - INFO  - ==> Top1: 95.148    Top5: 99.968    Loss: 0.139

2022-11-03 21:44:33,121 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:44:35,793 - INFO  - Validation [5][   20/   79]   Loss 0.390006   Top1 88.632812   Top5 99.257812   BatchTime 0.133512   
2022-11-03 21:44:36,689 - INFO  - Validation [5][   40/   79]   Loss 0.393322   Top1 88.925781   Top5 99.277344   BatchTime 0.089175   
2022-11-03 21:44:37,601 - INFO  - Validation [5][   60/   79]   Loss 0.384100   Top1 89.088542   Top5 99.401042   BatchTime 0.074642   
2022-11-03 21:44:38,710 - INFO  - ==> Top1: 89.020    Top5: 99.470    Loss: 0.379

2022-11-03 21:44:38,750 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.020   Top5: 99.470] Sparsity : 0.697
2022-11-03 21:44:38,751 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.570   Top5: 99.500] Sparsity : 0.655
2022-11-03 21:44:38,751 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 88.330   Top5: 99.490] Sparsity : 0.623
2022-11-03 21:44:38,919 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:44:38,919 - INFO  - >>>>>>>> Epoch   6
2022-11-03 21:44:38,921 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:44:42,706 - INFO  - Training [6][   20/  391]   Loss 0.138054   Top1 95.000000   Top5 100.000000   BatchTime 0.189245   LR 0.010000   
2022-11-03 21:44:44,737 - INFO  - Training [6][   40/  391]   Loss 0.129216   Top1 95.351562   Top5 99.960938   BatchTime 0.145413   LR 0.010000   
2022-11-03 21:44:46,739 - INFO  - Training [6][   60/  391]   Loss 0.129218   Top1 95.273438   Top5 99.960938   BatchTime 0.130307   LR 0.010000   
2022-11-03 21:44:48,734 - INFO  - Training [6][   80/  391]   Loss 0.128827   Top1 95.273438   Top5 99.970703   BatchTime 0.122665   LR 0.010000   
2022-11-03 21:44:50,720 - INFO  - Training [6][  100/  391]   Loss 0.131311   Top1 95.226562   Top5 99.968750   BatchTime 0.117994   LR 0.010000   
2022-11-03 21:44:52,677 - INFO  - Training [6][  120/  391]   Loss 0.131805   Top1 95.195312   Top5 99.973958   BatchTime 0.114631   LR 0.010000   
2022-11-03 21:44:54,322 - INFO  - Training [6][  140/  391]   Loss 0.132005   Top1 95.206473   Top5 99.972098   BatchTime 0.110005   LR 0.010000   
2022-11-03 21:44:56,037 - INFO  - Training [6][  160/  391]   Loss 0.128880   Top1 95.356445   Top5 99.975586   BatchTime 0.106974   LR 0.010000   
2022-11-03 21:44:57,684 - INFO  - Training [6][  180/  391]   Loss 0.129481   Top1 95.308160   Top5 99.978299   BatchTime 0.104240   LR 0.010000   
2022-11-03 21:44:59,393 - INFO  - Training [6][  200/  391]   Loss 0.129601   Top1 95.332031   Top5 99.972656   BatchTime 0.102360   LR 0.010000   
2022-11-03 21:45:01,176 - INFO  - Training [6][  220/  391]   Loss 0.128070   Top1 95.379972   Top5 99.975142   BatchTime 0.101156   LR 0.010000   
2022-11-03 21:45:03,188 - INFO  - Training [6][  240/  391]   Loss 0.128106   Top1 95.387370   Top5 99.977214   BatchTime 0.101110   LR 0.010000   
2022-11-03 21:45:05,196 - INFO  - Training [6][  260/  391]   Loss 0.127375   Top1 95.399639   Top5 99.978966   BatchTime 0.101055   LR 0.010000   
2022-11-03 21:45:07,196 - INFO  - Training [6][  280/  391]   Loss 0.127028   Top1 95.454799   Top5 99.972098   BatchTime 0.100981   LR 0.010000   
2022-11-03 21:45:09,194 - INFO  - Training [6][  300/  391]   Loss 0.127209   Top1 95.468750   Top5 99.971354   BatchTime 0.100908   LR 0.010000   
2022-11-03 21:45:11,197 - INFO  - Training [6][  320/  391]   Loss 0.127746   Top1 95.468750   Top5 99.970703   BatchTime 0.100862   LR 0.010000   
2022-11-03 21:45:13,184 - INFO  - Training [6][  340/  391]   Loss 0.128727   Top1 95.459559   Top5 99.972426   BatchTime 0.100773   LR 0.010000   
2022-11-03 21:45:15,154 - INFO  - Training [6][  360/  391]   Loss 0.128973   Top1 95.453559   Top5 99.971788   BatchTime 0.100646   LR 0.010000   
2022-11-03 21:45:17,116 - INFO  - Training [6][  380/  391]   Loss 0.128690   Top1 95.448191   Top5 99.973273   BatchTime 0.100512   LR 0.010000   
2022-11-03 21:45:18,440 - INFO  - ==> Top1: 95.464    Top5: 99.974    Loss: 0.128

2022-11-03 21:45:18,441 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:45:21,035 - INFO  - Validation [6][   20/   79]   Loss 0.380533   Top1 88.906250   Top5 99.335938   BatchTime 0.129582   
2022-11-03 21:45:21,892 - INFO  - Validation [6][   40/   79]   Loss 0.394915   Top1 89.179688   Top5 99.277344   BatchTime 0.086219   
2022-11-03 21:45:22,772 - INFO  - Validation [6][   60/   79]   Loss 0.386726   Top1 89.309896   Top5 99.440104   BatchTime 0.072146   
2022-11-03 21:45:23,878 - INFO  - ==> Top1: 89.380    Top5: 99.510    Loss: 0.380

2022-11-03 21:45:23,918 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.380   Top5: 99.510] Sparsity : 0.701
2022-11-03 21:45:23,919 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.020   Top5: 99.470] Sparsity : 0.697
2022-11-03 21:45:23,919 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.570   Top5: 99.500] Sparsity : 0.655
2022-11-03 21:45:24,108 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:45:24,108 - INFO  - >>>>>>>> Epoch   7
2022-11-03 21:45:24,110 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:45:27,899 - INFO  - Training [7][   20/  391]   Loss 0.115644   Top1 96.132812   Top5 99.960938   BatchTime 0.189441   LR 0.010000   
2022-11-03 21:45:29,901 - INFO  - Training [7][   40/  391]   Loss 0.114913   Top1 95.976562   Top5 99.980469   BatchTime 0.144768   LR 0.010000   
2022-11-03 21:45:31,883 - INFO  - Training [7][   60/  391]   Loss 0.116105   Top1 95.794271   Top5 99.973958   BatchTime 0.129541   LR 0.010000   
2022-11-03 21:45:33,852 - INFO  - Training [7][   80/  391]   Loss 0.113978   Top1 95.849609   Top5 99.980469   BatchTime 0.121770   LR 0.010000   
2022-11-03 21:45:35,919 - INFO  - Training [7][  100/  391]   Loss 0.115877   Top1 95.867188   Top5 99.968750   BatchTime 0.118091   LR 0.010000   
2022-11-03 21:45:37,880 - INFO  - Training [7][  120/  391]   Loss 0.115604   Top1 95.852865   Top5 99.967448   BatchTime 0.114746   LR 0.010000   
2022-11-03 21:45:39,531 - INFO  - Training [7][  140/  391]   Loss 0.117384   Top1 95.814732   Top5 99.972098   BatchTime 0.110150   LR 0.010000   
2022-11-03 21:45:41,197 - INFO  - Training [7][  160/  391]   Loss 0.115296   Top1 95.888672   Top5 99.975586   BatchTime 0.106792   LR 0.010000   
2022-11-03 21:45:42,838 - INFO  - Training [7][  180/  391]   Loss 0.114648   Top1 95.924479   Top5 99.978299   BatchTime 0.104044   LR 0.010000   
2022-11-03 21:45:44,541 - INFO  - Training [7][  200/  391]   Loss 0.115852   Top1 95.886719   Top5 99.976562   BatchTime 0.102154   LR 0.010000   
2022-11-03 21:45:46,188 - INFO  - Training [7][  220/  391]   Loss 0.115758   Top1 95.926847   Top5 99.975142   BatchTime 0.100351   LR 0.010000   
2022-11-03 21:45:48,199 - INFO  - Training [7][  240/  391]   Loss 0.116842   Top1 95.885417   Top5 99.977214   BatchTime 0.100369   LR 0.010000   
2022-11-03 21:45:50,214 - INFO  - Training [7][  260/  391]   Loss 0.117395   Top1 95.877404   Top5 99.969952   BatchTime 0.100400   LR 0.010000   
2022-11-03 21:45:52,214 - INFO  - Training [7][  280/  391]   Loss 0.118202   Top1 95.851004   Top5 99.972098   BatchTime 0.100371   LR 0.010000   
2022-11-03 21:45:54,210 - INFO  - Training [7][  300/  391]   Loss 0.118955   Top1 95.799479   Top5 99.966146   BatchTime 0.100333   LR 0.010000   
2022-11-03 21:45:56,213 - INFO  - Training [7][  320/  391]   Loss 0.119022   Top1 95.773926   Top5 99.968262   BatchTime 0.100320   LR 0.010000   
2022-11-03 21:45:58,184 - INFO  - Training [7][  340/  391]   Loss 0.118548   Top1 95.790441   Top5 99.967831   BatchTime 0.100215   LR 0.010000   
2022-11-03 21:46:00,143 - INFO  - Training [7][  360/  391]   Loss 0.116832   Top1 95.850694   Top5 99.969618   BatchTime 0.100090   LR 0.010000   
2022-11-03 21:46:02,100 - INFO  - Training [7][  380/  391]   Loss 0.116712   Top1 95.863487   Top5 99.969161   BatchTime 0.099972   LR 0.010000   
2022-11-03 21:46:03,428 - INFO  - ==> Top1: 95.872    Top5: 99.970    Loss: 0.116

2022-11-03 21:46:03,429 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:46:06,047 - INFO  - Validation [7][   20/   79]   Loss 0.397490   Top1 88.085938   Top5 99.375000   BatchTime 0.130796   
2022-11-03 21:46:06,919 - INFO  - Validation [7][   40/   79]   Loss 0.393179   Top1 88.671875   Top5 99.414062   BatchTime 0.087202   
2022-11-03 21:46:07,829 - INFO  - Validation [7][   60/   79]   Loss 0.381528   Top1 89.257812   Top5 99.505208   BatchTime 0.073295   
2022-11-03 21:46:08,948 - INFO  - ==> Top1: 89.400    Top5: 99.600    Loss: 0.373

2022-11-03 21:46:08,995 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.400   Top5: 99.600] Sparsity : 0.705
2022-11-03 21:46:08,996 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 89.380   Top5: 99.510] Sparsity : 0.701
2022-11-03 21:46:08,996 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.020   Top5: 99.470] Sparsity : 0.697
2022-11-03 21:46:09,173 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:46:09,174 - INFO  - >>>>>>>> Epoch   8
2022-11-03 21:46:09,175 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:46:12,952 - INFO  - Training [8][   20/  391]   Loss 0.082686   Top1 96.914062   Top5 100.000000   BatchTime 0.188811   LR 0.010000   
2022-11-03 21:46:14,959 - INFO  - Training [8][   40/  391]   Loss 0.094957   Top1 96.523438   Top5 100.000000   BatchTime 0.144582   LR 0.010000   
2022-11-03 21:46:16,984 - INFO  - Training [8][   60/  391]   Loss 0.092684   Top1 96.562500   Top5 100.000000   BatchTime 0.130142   LR 0.010000   
2022-11-03 21:46:18,999 - INFO  - Training [8][   80/  391]   Loss 0.092900   Top1 96.601562   Top5 100.000000   BatchTime 0.122795   LR 0.010000   
2022-11-03 21:46:20,988 - INFO  - Training [8][  100/  391]   Loss 0.092122   Top1 96.734375   Top5 100.000000   BatchTime 0.118124   LR 0.010000   
2022-11-03 21:46:22,984 - INFO  - Training [8][  120/  391]   Loss 0.095097   Top1 96.679688   Top5 100.000000   BatchTime 0.115067   LR 0.010000   
2022-11-03 21:46:24,776 - INFO  - Training [8][  140/  391]   Loss 0.095939   Top1 96.635045   Top5 100.000000   BatchTime 0.111432   LR 0.010000   
2022-11-03 21:46:26,503 - INFO  - Training [8][  160/  391]   Loss 0.098242   Top1 96.542969   Top5 99.995117   BatchTime 0.108296   LR 0.010000   
2022-11-03 21:46:28,179 - INFO  - Training [8][  180/  391]   Loss 0.098833   Top1 96.506076   Top5 99.991319   BatchTime 0.105571   LR 0.010000   
2022-11-03 21:46:29,889 - INFO  - Training [8][  200/  391]   Loss 0.099079   Top1 96.496094   Top5 99.988281   BatchTime 0.103564   LR 0.010000   
2022-11-03 21:46:31,519 - INFO  - Training [8][  220/  391]   Loss 0.100317   Top1 96.452415   Top5 99.985795   BatchTime 0.101561   LR 0.010000   
2022-11-03 21:46:33,563 - INFO  - Training [8][  240/  391]   Loss 0.099538   Top1 96.481120   Top5 99.980469   BatchTime 0.101611   LR 0.010000   
2022-11-03 21:46:35,565 - INFO  - Training [8][  260/  391]   Loss 0.099513   Top1 96.484375   Top5 99.978966   BatchTime 0.101494   LR 0.010000   
2022-11-03 21:46:37,572 - INFO  - Training [8][  280/  391]   Loss 0.100447   Top1 96.459263   Top5 99.974888   BatchTime 0.101415   LR 0.010000   
2022-11-03 21:46:39,574 - INFO  - Training [8][  300/  391]   Loss 0.101231   Top1 96.427083   Top5 99.973958   BatchTime 0.101325   LR 0.010000   
2022-11-03 21:46:41,575 - INFO  - Training [8][  320/  391]   Loss 0.102045   Top1 96.396484   Top5 99.975586   BatchTime 0.101247   LR 0.010000   
2022-11-03 21:46:43,573 - INFO  - Training [8][  340/  391]   Loss 0.101490   Top1 96.426930   Top5 99.977022   BatchTime 0.101166   LR 0.010000   
2022-11-03 21:46:45,546 - INFO  - Training [8][  360/  391]   Loss 0.102466   Top1 96.395399   Top5 99.976128   BatchTime 0.101027   LR 0.010000   
2022-11-03 21:46:47,517 - INFO  - Training [8][  380/  391]   Loss 0.103370   Top1 96.365132   Top5 99.977385   BatchTime 0.100896   LR 0.010000   
2022-11-03 21:46:48,850 - INFO  - ==> Top1: 96.368    Top5: 99.978    Loss: 0.103

2022-11-03 21:46:48,851 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:46:51,482 - INFO  - Validation [8][   20/   79]   Loss 0.377858   Top1 89.531250   Top5 99.531250   BatchTime 0.131468   
2022-11-03 21:46:52,340 - INFO  - Validation [8][   40/   79]   Loss 0.390174   Top1 89.589844   Top5 99.433594   BatchTime 0.087191   
2022-11-03 21:46:53,237 - INFO  - Validation [8][   60/   79]   Loss 0.382317   Top1 89.661458   Top5 99.492188   BatchTime 0.073076   
2022-11-03 21:46:54,341 - INFO  - ==> Top1: 89.550    Top5: 99.510    Loss: 0.382

2022-11-03 21:46:54,391 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:46:54,392 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.400   Top5: 99.600] Sparsity : 0.705
2022-11-03 21:46:54,392 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 89.380   Top5: 99.510] Sparsity : 0.701
2022-11-03 21:46:54,560 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:46:54,560 - INFO  - >>>>>>>> Epoch   9
2022-11-03 21:46:54,561 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:46:58,350 - INFO  - Training [9][   20/  391]   Loss 0.095364   Top1 96.679688   Top5 100.000000   BatchTime 0.189405   LR 0.010000   
2022-11-03 21:47:00,346 - INFO  - Training [9][   40/  391]   Loss 0.100176   Top1 96.660156   Top5 99.980469   BatchTime 0.144619   LR 0.010000   
2022-11-03 21:47:02,350 - INFO  - Training [9][   60/  391]   Loss 0.094996   Top1 96.757812   Top5 99.986979   BatchTime 0.129801   LR 0.010000   
2022-11-03 21:47:04,330 - INFO  - Training [9][   80/  391]   Loss 0.095291   Top1 96.738281   Top5 99.990234   BatchTime 0.122107   LR 0.010000   
2022-11-03 21:47:06,296 - INFO  - Training [9][  100/  391]   Loss 0.095345   Top1 96.750000   Top5 99.984375   BatchTime 0.117340   LR 0.010000   
2022-11-03 21:47:08,281 - INFO  - Training [9][  120/  391]   Loss 0.096767   Top1 96.686198   Top5 99.980469   BatchTime 0.114325   LR 0.010000   
2022-11-03 21:47:10,110 - INFO  - Training [9][  140/  391]   Loss 0.095994   Top1 96.713170   Top5 99.983259   BatchTime 0.111058   LR 0.010000   
2022-11-03 21:47:11,920 - INFO  - Training [9][  160/  391]   Loss 0.094496   Top1 96.728516   Top5 99.980469   BatchTime 0.108486   LR 0.010000   
2022-11-03 21:47:13,571 - INFO  - Training [9][  180/  391]   Loss 0.093236   Top1 96.744792   Top5 99.982639   BatchTime 0.105606   LR 0.010000   
2022-11-03 21:47:15,295 - INFO  - Training [9][  200/  391]   Loss 0.092135   Top1 96.792969   Top5 99.984375   BatchTime 0.103666   LR 0.010000   
2022-11-03 21:47:16,830 - INFO  - Training [9][  220/  391]   Loss 0.091771   Top1 96.786222   Top5 99.985795   BatchTime 0.101217   LR 0.010000   
2022-11-03 21:47:18,910 - INFO  - Training [9][  240/  391]   Loss 0.091934   Top1 96.806641   Top5 99.986979   BatchTime 0.101451   LR 0.010000   
2022-11-03 21:47:20,911 - INFO  - Training [9][  260/  391]   Loss 0.092946   Top1 96.751803   Top5 99.987981   BatchTime 0.101343   LR 0.010000   
2022-11-03 21:47:22,920 - INFO  - Training [9][  280/  391]   Loss 0.093926   Top1 96.699219   Top5 99.988839   BatchTime 0.101280   LR 0.010000   
2022-11-03 21:47:24,919 - INFO  - Training [9][  300/  391]   Loss 0.094554   Top1 96.661458   Top5 99.989583   BatchTime 0.101189   LR 0.010000   
2022-11-03 21:47:26,916 - INFO  - Training [9][  320/  391]   Loss 0.095925   Top1 96.611328   Top5 99.987793   BatchTime 0.101105   LR 0.010000   
2022-11-03 21:47:28,900 - INFO  - Training [9][  340/  391]   Loss 0.096713   Top1 96.583180   Top5 99.988511   BatchTime 0.100993   LR 0.010000   
2022-11-03 21:47:30,878 - INFO  - Training [9][  360/  391]   Loss 0.097283   Top1 96.558160   Top5 99.984809   BatchTime 0.100878   LR 0.010000   
2022-11-03 21:47:32,846 - INFO  - Training [9][  380/  391]   Loss 0.098455   Top1 96.513158   Top5 99.983553   BatchTime 0.100747   LR 0.010000   
2022-11-03 21:47:34,181 - INFO  - ==> Top1: 96.496    Top5: 99.982    Loss: 0.099

2022-11-03 21:47:34,182 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:47:36,826 - INFO  - Validation [9][   20/   79]   Loss 0.412778   Top1 88.671875   Top5 99.453125   BatchTime 0.132140   
2022-11-03 21:47:37,773 - INFO  - Validation [9][   40/   79]   Loss 0.413050   Top1 88.925781   Top5 99.375000   BatchTime 0.089738   
2022-11-03 21:47:38,671 - INFO  - Validation [9][   60/   79]   Loss 0.400030   Top1 89.036458   Top5 99.440104   BatchTime 0.074790   
2022-11-03 21:47:39,787 - INFO  - ==> Top1: 88.910    Top5: 99.480    Loss: 0.396

2022-11-03 21:47:39,833 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:47:39,834 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.400   Top5: 99.600] Sparsity : 0.705
2022-11-03 21:47:39,834 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 89.380   Top5: 99.510] Sparsity : 0.701
2022-11-03 21:47:39,931 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:47:39,932 - INFO  - >>>>>>>> Epoch  10
2022-11-03 21:47:39,932 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:47:43,721 - INFO  - Training [10][   20/  391]   Loss 0.100998   Top1 96.562500   Top5 99.921875   BatchTime 0.189412   LR 0.010000   
2022-11-03 21:47:45,742 - INFO  - Training [10][   40/  391]   Loss 0.094618   Top1 96.796875   Top5 99.960938   BatchTime 0.145237   LR 0.010000   
2022-11-03 21:47:47,763 - INFO  - Training [10][   60/  391]   Loss 0.094987   Top1 96.835938   Top5 99.973958   BatchTime 0.130506   LR 0.010000   
2022-11-03 21:47:49,771 - INFO  - Training [10][   80/  391]   Loss 0.093505   Top1 96.767578   Top5 99.980469   BatchTime 0.122981   LR 0.010000   
2022-11-03 21:47:51,735 - INFO  - Training [10][  100/  391]   Loss 0.093795   Top1 96.703125   Top5 99.984375   BatchTime 0.118028   LR 0.010000   
2022-11-03 21:47:53,722 - INFO  - Training [10][  120/  391]   Loss 0.095170   Top1 96.608073   Top5 99.986979   BatchTime 0.114914   LR 0.010000   
2022-11-03 21:47:55,495 - INFO  - Training [10][  140/  391]   Loss 0.095703   Top1 96.607143   Top5 99.988839   BatchTime 0.111158   LR 0.010000   
2022-11-03 21:47:57,149 - INFO  - Training [10][  160/  391]   Loss 0.096435   Top1 96.606445   Top5 99.990234   BatchTime 0.107600   LR 0.010000   
2022-11-03 21:47:58,759 - INFO  - Training [10][  180/  391]   Loss 0.095731   Top1 96.649306   Top5 99.982639   BatchTime 0.104587   LR 0.010000   
2022-11-03 21:48:00,476 - INFO  - Training [10][  200/  391]   Loss 0.096174   Top1 96.667969   Top5 99.976562   BatchTime 0.102714   LR 0.010000   
2022-11-03 21:48:01,922 - INFO  - Training [10][  220/  391]   Loss 0.097716   Top1 96.605114   Top5 99.978693   BatchTime 0.099949   LR 0.010000   
2022-11-03 21:48:03,952 - INFO  - Training [10][  240/  391]   Loss 0.098331   Top1 96.582031   Top5 99.973958   BatchTime 0.100080   LR 0.010000   
2022-11-03 21:48:05,953 - INFO  - Training [10][  260/  391]   Loss 0.098083   Top1 96.592548   Top5 99.975962   BatchTime 0.100078   LR 0.010000   
2022-11-03 21:48:07,987 - INFO  - Training [10][  280/  391]   Loss 0.099573   Top1 96.534598   Top5 99.974888   BatchTime 0.100192   LR 0.010000   
2022-11-03 21:48:09,974 - INFO  - Training [10][  300/  391]   Loss 0.100803   Top1 96.497396   Top5 99.976562   BatchTime 0.100137   LR 0.010000   
2022-11-03 21:48:11,986 - INFO  - Training [10][  320/  391]   Loss 0.101179   Top1 96.464844   Top5 99.978027   BatchTime 0.100164   LR 0.010000   
2022-11-03 21:48:13,961 - INFO  - Training [10][  340/  391]   Loss 0.101877   Top1 96.456801   Top5 99.974724   BatchTime 0.100083   LR 0.010000   
2022-11-03 21:48:15,931 - INFO  - Training [10][  360/  391]   Loss 0.102310   Top1 96.430122   Top5 99.976128   BatchTime 0.099994   LR 0.010000   
2022-11-03 21:48:17,897 - INFO  - Training [10][  380/  391]   Loss 0.102658   Top1 96.418586   Top5 99.975329   BatchTime 0.099904   LR 0.010000   
2022-11-03 21:48:19,232 - INFO  - ==> Top1: 96.420    Top5: 99.976    Loss: 0.103

2022-11-03 21:48:19,233 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:48:21,886 - INFO  - Validation [10][   20/   79]   Loss 0.366698   Top1 89.609375   Top5 99.453125   BatchTime 0.132513   
2022-11-03 21:48:22,755 - INFO  - Validation [10][   40/   79]   Loss 0.385431   Top1 89.628906   Top5 99.414062   BatchTime 0.087995   
2022-11-03 21:48:23,625 - INFO  - Validation [10][   60/   79]   Loss 0.377768   Top1 89.765625   Top5 99.479167   BatchTime 0.073168   
2022-11-03 21:48:24,766 - INFO  - ==> Top1: 89.780    Top5: 99.510    Loss: 0.376

2022-11-03 21:48:24,807 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:48:24,808 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:48:24,808 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.400   Top5: 99.600] Sparsity : 0.705
2022-11-03 21:48:24,991 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:48:24,992 - INFO  - >>>>>>>> Epoch  11
2022-11-03 21:48:24,993 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:48:28,872 - INFO  - Training [11][   20/  391]   Loss 0.083430   Top1 97.148438   Top5 99.960938   BatchTime 0.193938   LR 0.010000   
2022-11-03 21:48:30,912 - INFO  - Training [11][   40/  391]   Loss 0.091130   Top1 96.855469   Top5 99.980469   BatchTime 0.147969   LR 0.010000   
2022-11-03 21:48:32,904 - INFO  - Training [11][   60/  391]   Loss 0.093090   Top1 96.614583   Top5 99.986979   BatchTime 0.131849   LR 0.010000   
2022-11-03 21:48:34,832 - INFO  - Training [11][   80/  391]   Loss 0.092497   Top1 96.689453   Top5 99.990234   BatchTime 0.122986   LR 0.010000   
2022-11-03 21:48:36,811 - INFO  - Training [11][  100/  391]   Loss 0.092807   Top1 96.664062   Top5 99.984375   BatchTime 0.118175   LR 0.010000   
2022-11-03 21:48:38,780 - INFO  - Training [11][  120/  391]   Loss 0.093127   Top1 96.634115   Top5 99.986979   BatchTime 0.114886   LR 0.010000   
2022-11-03 21:48:40,668 - INFO  - Training [11][  140/  391]   Loss 0.093342   Top1 96.601562   Top5 99.988839   BatchTime 0.111958   LR 0.010000   
2022-11-03 21:48:42,250 - INFO  - Training [11][  160/  391]   Loss 0.093278   Top1 96.611328   Top5 99.990234   BatchTime 0.107850   LR 0.010000   
2022-11-03 21:48:43,897 - INFO  - Training [11][  180/  391]   Loss 0.093727   Top1 96.627604   Top5 99.991319   BatchTime 0.105018   LR 0.010000   
2022-11-03 21:48:45,511 - INFO  - Training [11][  200/  391]   Loss 0.093897   Top1 96.609375   Top5 99.992188   BatchTime 0.102585   LR 0.010000   
2022-11-03 21:48:47,251 - INFO  - Training [11][  220/  391]   Loss 0.094555   Top1 96.598011   Top5 99.989347   BatchTime 0.101167   LR 0.010000   
2022-11-03 21:48:49,230 - INFO  - Training [11][  240/  391]   Loss 0.094311   Top1 96.614583   Top5 99.990234   BatchTime 0.100983   LR 0.010000   
2022-11-03 21:48:51,216 - INFO  - Training [11][  260/  391]   Loss 0.093932   Top1 96.622596   Top5 99.990986   BatchTime 0.100853   LR 0.010000   
2022-11-03 21:48:53,229 - INFO  - Training [11][  280/  391]   Loss 0.094283   Top1 96.598772   Top5 99.991629   BatchTime 0.100838   LR 0.010000   
2022-11-03 21:48:55,232 - INFO  - Training [11][  300/  391]   Loss 0.094568   Top1 96.601562   Top5 99.992188   BatchTime 0.100793   LR 0.010000   
2022-11-03 21:48:57,241 - INFO  - Training [11][  320/  391]   Loss 0.094773   Top1 96.567383   Top5 99.990234   BatchTime 0.100773   LR 0.010000   
2022-11-03 21:48:59,220 - INFO  - Training [11][  340/  391]   Loss 0.095838   Top1 96.560202   Top5 99.986213   BatchTime 0.100665   LR 0.010000   
2022-11-03 21:49:01,207 - INFO  - Training [11][  360/  391]   Loss 0.096035   Top1 96.575521   Top5 99.986979   BatchTime 0.100592   LR 0.010000   
2022-11-03 21:49:03,168 - INFO  - Training [11][  380/  391]   Loss 0.096569   Top1 96.566612   Top5 99.985609   BatchTime 0.100459   LR 0.010000   
2022-11-03 21:49:04,495 - INFO  - ==> Top1: 96.570    Top5: 99.986    Loss: 0.097

2022-11-03 21:49:04,496 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:49:07,141 - INFO  - Validation [11][   20/   79]   Loss 0.368521   Top1 89.453125   Top5 99.453125   BatchTime 0.132188   
2022-11-03 21:49:08,017 - INFO  - Validation [11][   40/   79]   Loss 0.384323   Top1 89.433594   Top5 99.472656   BatchTime 0.087981   
2022-11-03 21:49:08,915 - INFO  - Validation [11][   60/   79]   Loss 0.377034   Top1 89.713542   Top5 99.544271   BatchTime 0.073624   
2022-11-03 21:49:10,044 - INFO  - ==> Top1: 89.490    Top5: 99.590    Loss: 0.381

2022-11-03 21:49:10,085 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:49:10,085 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:49:10,085 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 89.490   Top5: 99.590] Sparsity : 0.746
2022-11-03 21:49:10,195 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:49:10,195 - INFO  - >>>>>>>> Epoch  12
2022-11-03 21:49:10,197 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:49:14,002 - INFO  - Training [12][   20/  391]   Loss 0.088237   Top1 97.187500   Top5 100.000000   BatchTime 0.190235   LR 0.010000   
2022-11-03 21:49:15,996 - INFO  - Training [12][   40/  391]   Loss 0.085883   Top1 97.109375   Top5 99.980469   BatchTime 0.144968   LR 0.010000   
2022-11-03 21:49:17,999 - INFO  - Training [12][   60/  391]   Loss 0.085897   Top1 97.057292   Top5 99.986979   BatchTime 0.130027   LR 0.010000   
2022-11-03 21:49:20,001 - INFO  - Training [12][   80/  391]   Loss 0.084956   Top1 97.089844   Top5 99.990234   BatchTime 0.122553   LR 0.010000   
2022-11-03 21:49:21,990 - INFO  - Training [12][  100/  391]   Loss 0.086443   Top1 97.039062   Top5 99.992188   BatchTime 0.117927   LR 0.010000   
2022-11-03 21:49:23,968 - INFO  - Training [12][  120/  391]   Loss 0.086240   Top1 97.044271   Top5 99.993490   BatchTime 0.114761   LR 0.010000   
2022-11-03 21:49:25,847 - INFO  - Training [12][  140/  391]   Loss 0.087502   Top1 96.986607   Top5 99.994420   BatchTime 0.111786   LR 0.010000   
2022-11-03 21:49:27,422 - INFO  - Training [12][  160/  391]   Loss 0.087082   Top1 97.006836   Top5 99.995117   BatchTime 0.107652   LR 0.010000   
2022-11-03 21:49:29,108 - INFO  - Training [12][  180/  391]   Loss 0.086340   Top1 97.018229   Top5 99.991319   BatchTime 0.105059   LR 0.010000   
2022-11-03 21:49:30,907 - INFO  - Training [12][  200/  391]   Loss 0.086357   Top1 97.011719   Top5 99.992188   BatchTime 0.103545   LR 0.010000   
2022-11-03 21:49:32,445 - INFO  - Training [12][  220/  391]   Loss 0.088019   Top1 96.949574   Top5 99.992898   BatchTime 0.101123   LR 0.010000   
2022-11-03 21:49:34,418 - INFO  - Training [12][  240/  391]   Loss 0.088691   Top1 96.917318   Top5 99.993490   BatchTime 0.100919   LR 0.010000   
2022-11-03 21:49:36,419 - INFO  - Training [12][  260/  391]   Loss 0.089801   Top1 96.859976   Top5 99.993990   BatchTime 0.100853   LR 0.010000   
2022-11-03 21:49:38,407 - INFO  - Training [12][  280/  391]   Loss 0.090917   Top1 96.810826   Top5 99.994420   BatchTime 0.100747   LR 0.010000   
2022-11-03 21:49:40,406 - INFO  - Training [12][  300/  391]   Loss 0.090584   Top1 96.802083   Top5 99.994792   BatchTime 0.100693   LR 0.010000   
2022-11-03 21:49:42,388 - INFO  - Training [12][  320/  391]   Loss 0.090086   Top1 96.801758   Top5 99.995117   BatchTime 0.100595   LR 0.010000   
2022-11-03 21:49:44,372 - INFO  - Training [12][  340/  391]   Loss 0.089753   Top1 96.812960   Top5 99.995404   BatchTime 0.100513   LR 0.010000   
2022-11-03 21:49:46,353 - INFO  - Training [12][  360/  391]   Loss 0.089624   Top1 96.818576   Top5 99.995660   BatchTime 0.100431   LR 0.010000   
2022-11-03 21:49:48,325 - INFO  - Training [12][  380/  391]   Loss 0.089509   Top1 96.837993   Top5 99.993832   BatchTime 0.100335   LR 0.010000   
2022-11-03 21:49:49,637 - INFO  - ==> Top1: 96.848    Top5: 99.994    Loss: 0.089

2022-11-03 21:49:49,638 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:49:52,305 - INFO  - Validation [12][   20/   79]   Loss 0.387964   Top1 89.257812   Top5 99.648438   BatchTime 0.133249   
2022-11-03 21:49:53,197 - INFO  - Validation [12][   40/   79]   Loss 0.404258   Top1 89.101562   Top5 99.589844   BatchTime 0.088917   
2022-11-03 21:49:54,062 - INFO  - Validation [12][   60/   79]   Loss 0.391953   Top1 89.544271   Top5 99.596354   BatchTime 0.073697   
2022-11-03 21:49:55,166 - INFO  - ==> Top1: 89.500    Top5: 99.590    Loss: 0.389

2022-11-03 21:49:55,192 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:49:55,193 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:49:55,193 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.500   Top5: 99.590] Sparsity : 0.754
2022-11-03 21:49:55,306 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:49:55,306 - INFO  - >>>>>>>> Epoch  13
2022-11-03 21:49:55,307 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:49:59,130 - INFO  - Training [13][   20/  391]   Loss 0.079768   Top1 97.539062   Top5 99.960938   BatchTime 0.191152   LR 0.010000   
2022-11-03 21:50:01,119 - INFO  - Training [13][   40/  391]   Loss 0.075303   Top1 97.402344   Top5 99.980469   BatchTime 0.145284   LR 0.010000   
2022-11-03 21:50:03,107 - INFO  - Training [13][   60/  391]   Loss 0.075557   Top1 97.447917   Top5 99.986979   BatchTime 0.130001   LR 0.010000   
2022-11-03 21:50:05,104 - INFO  - Training [13][   80/  391]   Loss 0.079805   Top1 97.207031   Top5 99.990234   BatchTime 0.122461   LR 0.010000   
2022-11-03 21:50:07,080 - INFO  - Training [13][  100/  391]   Loss 0.080472   Top1 97.203125   Top5 99.992188   BatchTime 0.117730   LR 0.010000   
2022-11-03 21:50:09,052 - INFO  - Training [13][  120/  391]   Loss 0.081835   Top1 97.161458   Top5 99.993490   BatchTime 0.114542   LR 0.010000   
2022-11-03 21:50:10,964 - INFO  - Training [13][  140/  391]   Loss 0.080506   Top1 97.198661   Top5 99.994420   BatchTime 0.111836   LR 0.010000   
2022-11-03 21:50:12,503 - INFO  - Training [13][  160/  391]   Loss 0.081267   Top1 97.143555   Top5 99.990234   BatchTime 0.107473   LR 0.010000   
2022-11-03 21:50:14,179 - INFO  - Training [13][  180/  391]   Loss 0.081510   Top1 97.113715   Top5 99.991319   BatchTime 0.104841   LR 0.010000   
2022-11-03 21:50:15,791 - INFO  - Training [13][  200/  391]   Loss 0.081871   Top1 97.101562   Top5 99.992188   BatchTime 0.102419   LR 0.010000   
2022-11-03 21:50:17,448 - INFO  - Training [13][  220/  391]   Loss 0.082672   Top1 97.098722   Top5 99.992898   BatchTime 0.100637   LR 0.010000   
2022-11-03 21:50:19,279 - INFO  - Training [13][  240/  391]   Loss 0.083103   Top1 97.089844   Top5 99.990234   BatchTime 0.099879   LR 0.010000   
2022-11-03 21:50:21,277 - INFO  - Training [13][  260/  391]   Loss 0.083654   Top1 97.070312   Top5 99.990986   BatchTime 0.099882   LR 0.010000   
2022-11-03 21:50:23,403 - INFO  - Training [13][  280/  391]   Loss 0.084334   Top1 97.047991   Top5 99.991629   BatchTime 0.100340   LR 0.010000   
2022-11-03 21:50:25,405 - INFO  - Training [13][  300/  391]   Loss 0.085311   Top1 97.007812   Top5 99.992188   BatchTime 0.100325   LR 0.010000   
2022-11-03 21:50:27,428 - INFO  - Training [13][  320/  391]   Loss 0.086118   Top1 96.982422   Top5 99.992676   BatchTime 0.100377   LR 0.010000   
2022-11-03 21:50:29,399 - INFO  - Training [13][  340/  391]   Loss 0.087132   Top1 96.941636   Top5 99.990809   BatchTime 0.100269   LR 0.010000   
2022-11-03 21:50:31,368 - INFO  - Training [13][  360/  391]   Loss 0.087641   Top1 96.907552   Top5 99.991319   BatchTime 0.100168   LR 0.010000   
2022-11-03 21:50:33,359 - INFO  - Training [13][  380/  391]   Loss 0.088295   Top1 96.887336   Top5 99.991776   BatchTime 0.100133   LR 0.010000   
2022-11-03 21:50:34,684 - INFO  - ==> Top1: 96.862    Top5: 99.992    Loss: 0.089

2022-11-03 21:50:34,685 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:50:37,329 - INFO  - Validation [13][   20/   79]   Loss 0.400790   Top1 89.726562   Top5 99.570312   BatchTime 0.132183   
2022-11-03 21:50:38,232 - INFO  - Validation [13][   40/   79]   Loss 0.412812   Top1 89.238281   Top5 99.453125   BatchTime 0.088657   
2022-11-03 21:50:39,111 - INFO  - Validation [13][   60/   79]   Loss 0.402346   Top1 89.427083   Top5 99.531250   BatchTime 0.073758   
2022-11-03 21:50:40,204 - INFO  - ==> Top1: 89.370    Top5: 99.550    Loss: 0.399

2022-11-03 21:50:40,244 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:50:40,245 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:50:40,245 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.500   Top5: 99.590] Sparsity : 0.754
2022-11-03 21:50:40,330 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:50:40,330 - INFO  - >>>>>>>> Epoch  14
2022-11-03 21:50:40,331 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:50:44,136 - INFO  - Training [14][   20/  391]   Loss 0.086890   Top1 96.914062   Top5 100.000000   BatchTime 0.190272   LR 0.010000   
2022-11-03 21:50:46,128 - INFO  - Training [14][   40/  391]   Loss 0.084846   Top1 96.933594   Top5 100.000000   BatchTime 0.144934   LR 0.010000   
2022-11-03 21:50:48,116 - INFO  - Training [14][   60/  391]   Loss 0.090922   Top1 96.809896   Top5 99.973958   BatchTime 0.129756   LR 0.010000   
2022-11-03 21:50:50,121 - INFO  - Training [14][   80/  391]   Loss 0.092807   Top1 96.630859   Top5 99.980469   BatchTime 0.122378   LR 0.010000   
2022-11-03 21:50:52,103 - INFO  - Training [14][  100/  391]   Loss 0.094144   Top1 96.593750   Top5 99.984375   BatchTime 0.117720   LR 0.010000   
2022-11-03 21:50:54,071 - INFO  - Training [14][  120/  391]   Loss 0.095353   Top1 96.555990   Top5 99.980469   BatchTime 0.114501   LR 0.010000   
2022-11-03 21:50:56,142 - INFO  - Training [14][  140/  391]   Loss 0.096162   Top1 96.512277   Top5 99.977679   BatchTime 0.112937   LR 0.010000   
2022-11-03 21:50:57,597 - INFO  - Training [14][  160/  391]   Loss 0.097518   Top1 96.450195   Top5 99.980469   BatchTime 0.107913   LR 0.010000   
2022-11-03 21:50:59,322 - INFO  - Training [14][  180/  391]   Loss 0.099360   Top1 96.406250   Top5 99.978299   BatchTime 0.105503   LR 0.010000   
2022-11-03 21:51:00,977 - INFO  - Training [14][  200/  391]   Loss 0.100714   Top1 96.355469   Top5 99.980469   BatchTime 0.103228   LR 0.010000   
2022-11-03 21:51:02,696 - INFO  - Training [14][  220/  391]   Loss 0.101197   Top1 96.331676   Top5 99.978693   BatchTime 0.101659   LR 0.010000   
2022-11-03 21:51:04,549 - INFO  - Training [14][  240/  391]   Loss 0.102270   Top1 96.285807   Top5 99.977214   BatchTime 0.100906   LR 0.010000   
2022-11-03 21:51:06,551 - INFO  - Training [14][  260/  391]   Loss 0.103633   Top1 96.253005   Top5 99.975962   BatchTime 0.100844   LR 0.010000   
2022-11-03 21:51:08,543 - INFO  - Training [14][  280/  391]   Loss 0.104093   Top1 96.238839   Top5 99.974888   BatchTime 0.100756   LR 0.010000   
2022-11-03 21:51:10,551 - INFO  - Training [14][  300/  391]   Loss 0.104947   Top1 96.216146   Top5 99.976562   BatchTime 0.100732   LR 0.010000   
2022-11-03 21:51:12,543 - INFO  - Training [14][  320/  391]   Loss 0.106043   Top1 96.186523   Top5 99.975586   BatchTime 0.100662   LR 0.010000   
2022-11-03 21:51:14,536 - INFO  - Training [14][  340/  391]   Loss 0.107838   Top1 96.139706   Top5 99.977022   BatchTime 0.100600   LR 0.010000   
2022-11-03 21:51:16,508 - INFO  - Training [14][  360/  391]   Loss 0.109736   Top1 96.098090   Top5 99.967448   BatchTime 0.100489   LR 0.010000   
2022-11-03 21:51:18,475 - INFO  - Training [14][  380/  391]   Loss 0.110509   Top1 96.081414   Top5 99.967105   BatchTime 0.100376   LR 0.010000   
2022-11-03 21:51:19,797 - INFO  - ==> Top1: 96.058    Top5: 99.968    Loss: 0.111

2022-11-03 21:51:19,797 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:51:22,459 - INFO  - Validation [14][   20/   79]   Loss 0.381259   Top1 89.453125   Top5 99.453125   BatchTime 0.133046   
2022-11-03 21:51:23,333 - INFO  - Validation [14][   40/   79]   Loss 0.398806   Top1 88.886719   Top5 99.355469   BatchTime 0.088361   
2022-11-03 21:51:24,231 - INFO  - Validation [14][   60/   79]   Loss 0.391122   Top1 89.309896   Top5 99.335938   BatchTime 0.073870   
2022-11-03 21:51:25,356 - INFO  - ==> Top1: 89.400    Top5: 99.390    Loss: 0.382

2022-11-03 21:51:25,399 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:51:25,400 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:51:25,400 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.500   Top5: 99.590] Sparsity : 0.754
2022-11-03 21:51:25,513 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:51:25,513 - INFO  - >>>>>>>> Epoch  15
2022-11-03 21:51:25,515 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:51:29,312 - INFO  - Training [15][   20/  391]   Loss 0.114268   Top1 96.132812   Top5 100.000000   BatchTime 0.189865   LR 0.010000   
2022-11-03 21:51:31,339 - INFO  - Training [15][   40/  391]   Loss 0.114145   Top1 96.171875   Top5 100.000000   BatchTime 0.145598   LR 0.010000   
2022-11-03 21:51:33,335 - INFO  - Training [15][   60/  391]   Loss 0.116030   Top1 96.002604   Top5 99.986979   BatchTime 0.130327   LR 0.010000   
2022-11-03 21:51:35,314 - INFO  - Training [15][   80/  391]   Loss 0.120633   Top1 95.712891   Top5 99.980469   BatchTime 0.122492   LR 0.010000   
2022-11-03 21:51:37,301 - INFO  - Training [15][  100/  391]   Loss 0.118848   Top1 95.773438   Top5 99.976562   BatchTime 0.117859   LR 0.010000   
2022-11-03 21:51:39,295 - INFO  - Training [15][  120/  391]   Loss 0.116512   Top1 95.911458   Top5 99.980469   BatchTime 0.114834   LR 0.010000   
2022-11-03 21:51:41,391 - INFO  - Training [15][  140/  391]   Loss 0.117917   Top1 95.926339   Top5 99.983259   BatchTime 0.113396   LR 0.010000   
2022-11-03 21:51:42,949 - INFO  - Training [15][  160/  391]   Loss 0.117403   Top1 95.903320   Top5 99.975586   BatchTime 0.108961   LR 0.010000   
2022-11-03 21:51:44,665 - INFO  - Training [15][  180/  391]   Loss 0.118876   Top1 95.881076   Top5 99.978299   BatchTime 0.106389   LR 0.010000   
2022-11-03 21:51:46,352 - INFO  - Training [15][  200/  391]   Loss 0.118087   Top1 95.886719   Top5 99.976562   BatchTime 0.104185   LR 0.010000   
2022-11-03 21:51:48,058 - INFO  - Training [15][  220/  391]   Loss 0.122074   Top1 95.770597   Top5 99.971591   BatchTime 0.102464   LR 0.010000   
2022-11-03 21:51:49,987 - INFO  - Training [15][  240/  391]   Loss 0.121902   Top1 95.735677   Top5 99.970703   BatchTime 0.101964   LR 0.010000   
2022-11-03 21:51:51,985 - INFO  - Training [15][  260/  391]   Loss 0.121450   Top1 95.757212   Top5 99.969952   BatchTime 0.101807   LR 0.010000   
2022-11-03 21:51:53,959 - INFO  - Training [15][  280/  391]   Loss 0.123148   Top1 95.697545   Top5 99.969308   BatchTime 0.101582   LR 0.010000   
2022-11-03 21:51:55,963 - INFO  - Training [15][  300/  391]   Loss 0.122446   Top1 95.700521   Top5 99.968750   BatchTime 0.101490   LR 0.010000   
2022-11-03 21:51:57,974 - INFO  - Training [15][  320/  391]   Loss 0.122608   Top1 95.700684   Top5 99.965820   BatchTime 0.101432   LR 0.010000   
2022-11-03 21:52:00,111 - INFO  - Training [15][  340/  391]   Loss 0.122096   Top1 95.730699   Top5 99.967831   BatchTime 0.101752   LR 0.010000   
2022-11-03 21:52:02,089 - INFO  - Training [15][  360/  391]   Loss 0.123123   Top1 95.698785   Top5 99.967448   BatchTime 0.101592   LR 0.010000   
2022-11-03 21:52:04,062 - INFO  - Training [15][  380/  391]   Loss 0.123439   Top1 95.686678   Top5 99.969161   BatchTime 0.101437   LR 0.010000   
2022-11-03 21:52:05,379 - INFO  - ==> Top1: 95.678    Top5: 99.970    Loss: 0.124

2022-11-03 21:52:05,380 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:52:08,026 - INFO  - Validation [15][   20/   79]   Loss 0.399354   Top1 88.906250   Top5 99.453125   BatchTime 0.132270   
2022-11-03 21:52:08,932 - INFO  - Validation [15][   40/   79]   Loss 0.408913   Top1 88.867188   Top5 99.394531   BatchTime 0.088782   
2022-11-03 21:52:09,815 - INFO  - Validation [15][   60/   79]   Loss 0.396604   Top1 89.205729   Top5 99.453125   BatchTime 0.073898   
2022-11-03 21:52:10,899 - INFO  - ==> Top1: 89.210    Top5: 99.500    Loss: 0.388

2022-11-03 21:52:10,940 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:52:10,941 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:52:10,941 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 89.500   Top5: 99.590] Sparsity : 0.754
2022-11-03 21:52:11,057 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:52:11,058 - INFO  - >>>>>>>> Epoch  16
2022-11-03 21:52:11,059 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:52:14,815 - INFO  - Training [16][   20/  391]   Loss 0.113341   Top1 95.937500   Top5 100.000000   BatchTime 0.187781   LR 0.010000   
2022-11-03 21:52:16,831 - INFO  - Training [16][   40/  391]   Loss 0.104157   Top1 96.230469   Top5 100.000000   BatchTime 0.144299   LR 0.010000   
2022-11-03 21:52:18,866 - INFO  - Training [16][   60/  391]   Loss 0.105653   Top1 96.289062   Top5 99.986979   BatchTime 0.130108   LR 0.010000   
2022-11-03 21:52:20,870 - INFO  - Training [16][   80/  391]   Loss 0.108691   Top1 96.181641   Top5 99.990234   BatchTime 0.122634   LR 0.010000   
2022-11-03 21:52:22,852 - INFO  - Training [16][  100/  391]   Loss 0.107815   Top1 96.187500   Top5 99.984375   BatchTime 0.117922   LR 0.010000   
2022-11-03 21:52:24,820 - INFO  - Training [16][  120/  391]   Loss 0.108908   Top1 96.184896   Top5 99.980469   BatchTime 0.114669   LR 0.010000   
2022-11-03 21:52:26,868 - INFO  - Training [16][  140/  391]   Loss 0.109905   Top1 96.155134   Top5 99.983259   BatchTime 0.112920   LR 0.010000   
2022-11-03 21:52:28,410 - INFO  - Training [16][  160/  391]   Loss 0.109254   Top1 96.201172   Top5 99.980469   BatchTime 0.108442   LR 0.010000   
2022-11-03 21:52:30,190 - INFO  - Training [16][  180/  391]   Loss 0.111188   Top1 96.106771   Top5 99.978299   BatchTime 0.106278   LR 0.010000   
2022-11-03 21:52:31,828 - INFO  - Training [16][  200/  391]   Loss 0.112070   Top1 96.039062   Top5 99.980469   BatchTime 0.103842   LR 0.010000   
2022-11-03 21:52:33,460 - INFO  - Training [16][  220/  391]   Loss 0.112171   Top1 96.044034   Top5 99.982244   BatchTime 0.101818   LR 0.010000   
2022-11-03 21:52:35,287 - INFO  - Training [16][  240/  391]   Loss 0.111808   Top1 96.067708   Top5 99.983724   BatchTime 0.100947   LR 0.010000   
2022-11-03 21:52:37,295 - INFO  - Training [16][  260/  391]   Loss 0.111194   Top1 96.114784   Top5 99.984976   BatchTime 0.100905   LR 0.010000   
2022-11-03 21:52:39,318 - INFO  - Training [16][  280/  391]   Loss 0.111747   Top1 96.079799   Top5 99.986049   BatchTime 0.100921   LR 0.010000   
2022-11-03 21:52:41,327 - INFO  - Training [16][  300/  391]   Loss 0.112729   Top1 96.046875   Top5 99.986979   BatchTime 0.100892   LR 0.010000   
2022-11-03 21:52:43,348 - INFO  - Training [16][  320/  391]   Loss 0.113442   Top1 95.998535   Top5 99.985352   BatchTime 0.100900   LR 0.010000   
2022-11-03 21:52:45,315 - INFO  - Training [16][  340/  391]   Loss 0.113306   Top1 96.013327   Top5 99.983915   BatchTime 0.100749   LR 0.010000   
2022-11-03 21:52:47,302 - INFO  - Training [16][  360/  391]   Loss 0.113381   Top1 96.009115   Top5 99.984809   BatchTime 0.100672   LR 0.010000   
2022-11-03 21:52:49,253 - INFO  - Training [16][  380/  391]   Loss 0.112429   Top1 96.064967   Top5 99.985609   BatchTime 0.100507   LR 0.010000   
2022-11-03 21:52:50,576 - INFO  - ==> Top1: 96.066    Top5: 99.986    Loss: 0.112

2022-11-03 21:52:50,577 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:52:53,225 - INFO  - Validation [16][   20/   79]   Loss 0.392883   Top1 89.531250   Top5 99.414062   BatchTime 0.132321   
2022-11-03 21:52:54,101 - INFO  - Validation [16][   40/   79]   Loss 0.393748   Top1 89.628906   Top5 99.375000   BatchTime 0.088065   
2022-11-03 21:52:54,997 - INFO  - Validation [16][   60/   79]   Loss 0.386289   Top1 89.739583   Top5 99.427083   BatchTime 0.073644   
2022-11-03 21:52:56,128 - INFO  - ==> Top1: 89.720    Top5: 99.490    Loss: 0.384

2022-11-03 21:52:56,161 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:52:56,162 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 89.720   Top5: 99.490] Sparsity : 0.800
2022-11-03 21:52:56,162 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:52:56,248 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:52:56,248 - INFO  - >>>>>>>> Epoch  17
2022-11-03 21:52:56,250 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:53:00,080 - INFO  - Training [17][   20/  391]   Loss 0.096536   Top1 96.796875   Top5 100.000000   BatchTime 0.191531   LR 0.010000   
2022-11-03 21:53:02,089 - INFO  - Training [17][   40/  391]   Loss 0.108922   Top1 96.250000   Top5 99.980469   BatchTime 0.145979   LR 0.010000   
2022-11-03 21:53:04,103 - INFO  - Training [17][   60/  391]   Loss 0.104317   Top1 96.380208   Top5 99.986979   BatchTime 0.130888   LR 0.010000   
2022-11-03 21:53:06,089 - INFO  - Training [17][   80/  391]   Loss 0.102472   Top1 96.367188   Top5 99.990234   BatchTime 0.122987   LR 0.010000   
2022-11-03 21:53:08,059 - INFO  - Training [17][  100/  391]   Loss 0.100342   Top1 96.453125   Top5 99.992188   BatchTime 0.118097   LR 0.010000   
2022-11-03 21:53:10,030 - INFO  - Training [17][  120/  391]   Loss 0.103031   Top1 96.341146   Top5 99.993490   BatchTime 0.114835   LR 0.010000   
2022-11-03 21:53:12,009 - INFO  - Training [17][  140/  391]   Loss 0.102725   Top1 96.395089   Top5 99.994420   BatchTime 0.112567   LR 0.010000   
2022-11-03 21:53:13,665 - INFO  - Training [17][  160/  391]   Loss 0.104866   Top1 96.328125   Top5 99.990234   BatchTime 0.108841   LR 0.010000   
2022-11-03 21:53:15,361 - INFO  - Training [17][  180/  391]   Loss 0.104524   Top1 96.358507   Top5 99.986979   BatchTime 0.106172   LR 0.010000   
2022-11-03 21:53:16,976 - INFO  - Training [17][  200/  391]   Loss 0.105560   Top1 96.304688   Top5 99.980469   BatchTime 0.103631   LR 0.010000   
2022-11-03 21:53:18,655 - INFO  - Training [17][  220/  391]   Loss 0.106018   Top1 96.299716   Top5 99.982244   BatchTime 0.101842   LR 0.010000   
2022-11-03 21:53:20,415 - INFO  - Training [17][  240/  391]   Loss 0.106074   Top1 96.295573   Top5 99.980469   BatchTime 0.100687   LR 0.010000   
2022-11-03 21:53:22,417 - INFO  - Training [17][  260/  391]   Loss 0.107066   Top1 96.246995   Top5 99.981971   BatchTime 0.100640   LR 0.010000   
2022-11-03 21:53:24,417 - INFO  - Training [17][  280/  391]   Loss 0.107197   Top1 96.244420   Top5 99.977679   BatchTime 0.100595   LR 0.010000   
2022-11-03 21:53:26,431 - INFO  - Training [17][  300/  391]   Loss 0.106909   Top1 96.250000   Top5 99.979167   BatchTime 0.100603   LR 0.010000   
2022-11-03 21:53:28,443 - INFO  - Training [17][  320/  391]   Loss 0.107161   Top1 96.259766   Top5 99.980469   BatchTime 0.100603   LR 0.010000   
2022-11-03 21:53:30,405 - INFO  - Training [17][  340/  391]   Loss 0.107263   Top1 96.268382   Top5 99.977022   BatchTime 0.100456   LR 0.010000   
2022-11-03 21:53:32,380 - INFO  - Training [17][  360/  391]   Loss 0.107154   Top1 96.273872   Top5 99.976128   BatchTime 0.100360   LR 0.010000   
2022-11-03 21:53:34,353 - INFO  - Training [17][  380/  391]   Loss 0.106765   Top1 96.278783   Top5 99.975329   BatchTime 0.100270   LR 0.010000   
2022-11-03 21:53:35,674 - INFO  - ==> Top1: 96.282    Top5: 99.974    Loss: 0.107

2022-11-03 21:53:35,675 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:53:38,426 - INFO  - Validation [17][   20/   79]   Loss 0.380845   Top1 88.867188   Top5 99.648438   BatchTime 0.137466   
2022-11-03 21:53:39,333 - INFO  - Validation [17][   40/   79]   Loss 0.382799   Top1 89.042969   Top5 99.492188   BatchTime 0.091407   
2022-11-03 21:53:40,247 - INFO  - Validation [17][   60/   79]   Loss 0.374829   Top1 89.322917   Top5 99.492188   BatchTime 0.076168   
2022-11-03 21:53:41,371 - INFO  - ==> Top1: 89.340    Top5: 99.500    Loss: 0.373

2022-11-03 21:53:41,409 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:53:41,410 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 89.720   Top5: 99.490] Sparsity : 0.800
2022-11-03 21:53:41,410 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.550   Top5: 99.510] Sparsity : 0.711
2022-11-03 21:53:41,520 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:53:41,520 - INFO  - >>>>>>>> Epoch  18
2022-11-03 21:53:41,521 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:53:45,347 - INFO  - Training [18][   20/  391]   Loss 0.092255   Top1 96.562500   Top5 99.960938   BatchTime 0.191276   LR 0.010000   
2022-11-03 21:53:47,351 - INFO  - Training [18][   40/  391]   Loss 0.099469   Top1 96.132812   Top5 99.980469   BatchTime 0.145756   LR 0.010000   
2022-11-03 21:53:49,335 - INFO  - Training [18][   60/  391]   Loss 0.093968   Top1 96.432292   Top5 99.986979   BatchTime 0.130225   LR 0.010000   
2022-11-03 21:53:51,337 - INFO  - Training [18][   80/  391]   Loss 0.093661   Top1 96.425781   Top5 99.990234   BatchTime 0.122693   LR 0.010000   
2022-11-03 21:53:53,320 - INFO  - Training [18][  100/  391]   Loss 0.093254   Top1 96.468750   Top5 99.992188   BatchTime 0.117986   LR 0.010000   
2022-11-03 21:53:55,289 - INFO  - Training [18][  120/  391]   Loss 0.094245   Top1 96.451823   Top5 99.993490   BatchTime 0.114730   LR 0.010000   
2022-11-03 21:53:57,255 - INFO  - Training [18][  140/  391]   Loss 0.095024   Top1 96.456473   Top5 99.988839   BatchTime 0.112385   LR 0.010000   
2022-11-03 21:53:58,921 - INFO  - Training [18][  160/  391]   Loss 0.096384   Top1 96.406250   Top5 99.985352   BatchTime 0.108751   LR 0.010000   
2022-11-03 21:54:00,663 - INFO  - Training [18][  180/  391]   Loss 0.095830   Top1 96.445312   Top5 99.986979   BatchTime 0.106344   LR 0.010000   
2022-11-03 21:54:02,331 - INFO  - Training [18][  200/  391]   Loss 0.095873   Top1 96.460938   Top5 99.984375   BatchTime 0.104046   LR 0.010000   
2022-11-03 21:54:04,008 - INFO  - Training [18][  220/  391]   Loss 0.099017   Top1 96.388494   Top5 99.985795   BatchTime 0.102210   LR 0.010000   
2022-11-03 21:54:05,722 - INFO  - Training [18][  240/  391]   Loss 0.101360   Top1 96.305339   Top5 99.980469   BatchTime 0.100836   LR 0.010000   
2022-11-03 21:54:07,737 - INFO  - Training [18][  260/  391]   Loss 0.101396   Top1 96.346154   Top5 99.981971   BatchTime 0.100828   LR 0.010000   
2022-11-03 21:54:09,731 - INFO  - Training [18][  280/  391]   Loss 0.102240   Top1 96.333705   Top5 99.980469   BatchTime 0.100747   LR 0.010000   
2022-11-03 21:54:11,755 - INFO  - Training [18][  300/  391]   Loss 0.102041   Top1 96.330729   Top5 99.979167   BatchTime 0.100778   LR 0.010000   
2022-11-03 21:54:13,786 - INFO  - Training [18][  320/  391]   Loss 0.101949   Top1 96.350098   Top5 99.978027   BatchTime 0.100827   LR 0.010000   
2022-11-03 21:54:15,772 - INFO  - Training [18][  340/  391]   Loss 0.102122   Top1 96.351103   Top5 99.979320   BatchTime 0.100735   LR 0.010000   
2022-11-03 21:54:17,747 - INFO  - Training [18][  360/  391]   Loss 0.102641   Top1 96.334635   Top5 99.973958   BatchTime 0.100625   LR 0.010000   
2022-11-03 21:54:19,745 - INFO  - Training [18][  380/  391]   Loss 0.102284   Top1 96.352796   Top5 99.973273   BatchTime 0.100586   LR 0.010000   
2022-11-03 21:54:21,068 - INFO  - ==> Top1: 96.370    Top5: 99.972    Loss: 0.102

2022-11-03 21:54:21,069 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:54:23,749 - INFO  - Validation [18][   20/   79]   Loss 0.390678   Top1 89.492188   Top5 99.531250   BatchTime 0.133924   
2022-11-03 21:54:24,664 - INFO  - Validation [18][   40/   79]   Loss 0.399261   Top1 89.296875   Top5 99.472656   BatchTime 0.089837   
2022-11-03 21:54:25,561 - INFO  - Validation [18][   60/   79]   Loss 0.385585   Top1 89.726562   Top5 99.492188   BatchTime 0.074834   
2022-11-03 21:54:26,660 - INFO  - ==> Top1: 89.760    Top5: 99.530    Loss: 0.383

2022-11-03 21:54:26,705 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:54:26,706 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.760   Top5: 99.530] Sparsity : 0.808
2022-11-03 21:54:26,706 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.720   Top5: 99.490] Sparsity : 0.800
2022-11-03 21:54:26,796 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:54:26,797 - INFO  - >>>>>>>> Epoch  19
2022-11-03 21:54:26,798 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:54:30,599 - INFO  - Training [19][   20/  391]   Loss 0.115479   Top1 95.820312   Top5 100.000000   BatchTime 0.190076   LR 0.010000   
2022-11-03 21:54:32,591 - INFO  - Training [19][   40/  391]   Loss 0.103809   Top1 96.328125   Top5 100.000000   BatchTime 0.144826   LR 0.010000   
2022-11-03 21:54:34,594 - INFO  - Training [19][   60/  391]   Loss 0.099848   Top1 96.445312   Top5 100.000000   BatchTime 0.129930   LR 0.010000   
2022-11-03 21:54:36,618 - INFO  - Training [19][   80/  391]   Loss 0.096512   Top1 96.630859   Top5 100.000000   BatchTime 0.122749   LR 0.010000   
2022-11-03 21:54:38,595 - INFO  - Training [19][  100/  391]   Loss 0.096979   Top1 96.640625   Top5 100.000000   BatchTime 0.117973   LR 0.010000   
2022-11-03 21:54:40,571 - INFO  - Training [19][  120/  391]   Loss 0.097366   Top1 96.575521   Top5 100.000000   BatchTime 0.114777   LR 0.010000   
2022-11-03 21:54:42,534 - INFO  - Training [19][  140/  391]   Loss 0.097015   Top1 96.556920   Top5 100.000000   BatchTime 0.112403   LR 0.010000   
2022-11-03 21:54:44,213 - INFO  - Training [19][  160/  391]   Loss 0.099001   Top1 96.464844   Top5 100.000000   BatchTime 0.108843   LR 0.010000   
2022-11-03 21:54:45,881 - INFO  - Training [19][  180/  391]   Loss 0.098636   Top1 96.467014   Top5 100.000000   BatchTime 0.106014   LR 0.010000   
2022-11-03 21:54:47,499 - INFO  - Training [19][  200/  391]   Loss 0.099470   Top1 96.480469   Top5 100.000000   BatchTime 0.103506   LR 0.010000   
2022-11-03 21:54:49,211 - INFO  - Training [19][  220/  391]   Loss 0.099939   Top1 96.463068   Top5 100.000000   BatchTime 0.101876   LR 0.010000   
2022-11-03 21:54:50,833 - INFO  - Training [19][  240/  391]   Loss 0.101392   Top1 96.432292   Top5 99.996745   BatchTime 0.100144   LR 0.010000   
2022-11-03 21:54:52,498 - INFO  - Training [19][  260/  391]   Loss 0.102301   Top1 96.400240   Top5 99.996995   BatchTime 0.098846   LR 0.010000   
2022-11-03 21:54:54,208 - INFO  - Training [19][  280/  391]   Loss 0.102042   Top1 96.403460   Top5 99.997210   BatchTime 0.097893   LR 0.010000   
2022-11-03 21:54:55,708 - INFO  - Training [19][  300/  391]   Loss 0.103497   Top1 96.333333   Top5 99.997396   BatchTime 0.096364   LR 0.010000   
2022-11-03 21:54:57,195 - INFO  - Training [19][  320/  391]   Loss 0.104340   Top1 96.291504   Top5 99.997559   BatchTime 0.094990   LR 0.010000   
2022-11-03 21:54:58,654 - INFO  - Training [19][  340/  391]   Loss 0.105638   Top1 96.266085   Top5 99.997702   BatchTime 0.093693   LR 0.010000   
2022-11-03 21:55:00,057 - INFO  - Training [19][  360/  391]   Loss 0.106566   Top1 96.230469   Top5 99.997830   BatchTime 0.092385   LR 0.010000   
2022-11-03 21:55:01,499 - INFO  - Training [19][  380/  391]   Loss 0.106324   Top1 96.235609   Top5 99.993832   BatchTime 0.091317   LR 0.010000   
2022-11-03 21:55:02,573 - INFO  - ==> Top1: 96.228    Top5: 99.994    Loss: 0.107

2022-11-03 21:55:02,574 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:55:04,892 - INFO  - Validation [19][   20/   79]   Loss 0.397221   Top1 88.906250   Top5 99.570312   BatchTime 0.115806   
2022-11-03 21:55:05,425 - INFO  - Validation [19][   40/   79]   Loss 0.402566   Top1 88.847656   Top5 99.492188   BatchTime 0.071220   
2022-11-03 21:55:05,954 - INFO  - Validation [19][   60/   79]   Loss 0.391880   Top1 89.414062   Top5 99.570312   BatchTime 0.056295   
2022-11-03 21:55:06,686 - INFO  - ==> Top1: 89.490    Top5: 99.610    Loss: 0.386

2022-11-03 21:55:06,714 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:55:06,715 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.760   Top5: 99.530] Sparsity : 0.808
2022-11-03 21:55:06,715 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.720   Top5: 99.490] Sparsity : 0.800
2022-11-03 21:55:06,829 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:55:06,829 - INFO  - >>>>>>>> Epoch  20
2022-11-03 21:55:06,830 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:55:10,391 - INFO  - Training [20][   20/  391]   Loss 0.106375   Top1 96.093750   Top5 100.000000   BatchTime 0.178039   LR 0.010000   
2022-11-03 21:55:12,126 - INFO  - Training [20][   40/  391]   Loss 0.100672   Top1 96.425781   Top5 100.000000   BatchTime 0.132373   LR 0.010000   
2022-11-03 21:55:13,678 - INFO  - Training [20][   60/  391]   Loss 0.099400   Top1 96.341146   Top5 100.000000   BatchTime 0.114122   LR 0.010000   
2022-11-03 21:55:15,346 - INFO  - Training [20][   80/  391]   Loss 0.103944   Top1 96.220703   Top5 100.000000   BatchTime 0.106436   LR 0.010000   
2022-11-03 21:55:17,026 - INFO  - Training [20][  100/  391]   Loss 0.106412   Top1 96.140625   Top5 100.000000   BatchTime 0.101956   LR 0.010000   
2022-11-03 21:55:18,609 - INFO  - Training [20][  120/  391]   Loss 0.108642   Top1 96.061198   Top5 100.000000   BatchTime 0.098154   LR 0.010000   
2022-11-03 21:55:20,580 - INFO  - Training [20][  140/  391]   Loss 0.109934   Top1 96.032366   Top5 100.000000   BatchTime 0.098206   LR 0.010000   
2022-11-03 21:55:22,588 - INFO  - Training [20][  160/  391]   Loss 0.111855   Top1 95.952148   Top5 99.995117   BatchTime 0.098481   LR 0.010000   
2022-11-03 21:55:24,591 - INFO  - Training [20][  180/  391]   Loss 0.111321   Top1 96.019965   Top5 99.995660   BatchTime 0.098667   LR 0.010000   
2022-11-03 21:55:26,588 - INFO  - Training [20][  200/  391]   Loss 0.111599   Top1 96.015625   Top5 99.996094   BatchTime 0.098787   LR 0.010000   
2022-11-03 21:55:28,598 - INFO  - Training [20][  220/  391]   Loss 0.112458   Top1 95.990767   Top5 99.992898   BatchTime 0.098940   LR 0.010000   
2022-11-03 21:55:30,624 - INFO  - Training [20][  240/  391]   Loss 0.112450   Top1 95.986328   Top5 99.993490   BatchTime 0.099136   LR 0.010000   
2022-11-03 21:55:32,638 - INFO  - Training [20][  260/  391]   Loss 0.113656   Top1 95.979567   Top5 99.987981   BatchTime 0.099256   LR 0.010000   
2022-11-03 21:55:34,656 - INFO  - Training [20][  280/  391]   Loss 0.114540   Top1 95.943080   Top5 99.988839   BatchTime 0.099373   LR 0.010000   
2022-11-03 21:55:36,679 - INFO  - Training [20][  300/  391]   Loss 0.113838   Top1 95.950521   Top5 99.989583   BatchTime 0.099491   LR 0.010000   
2022-11-03 21:55:38,678 - INFO  - Training [20][  320/  391]   Loss 0.113885   Top1 95.930176   Top5 99.987793   BatchTime 0.099522   LR 0.010000   
2022-11-03 21:55:40,674 - INFO  - Training [20][  340/  391]   Loss 0.114077   Top1 95.942096   Top5 99.988511   BatchTime 0.099536   LR 0.010000   
2022-11-03 21:55:42,642 - INFO  - Training [20][  360/  391]   Loss 0.114869   Top1 95.896267   Top5 99.989149   BatchTime 0.099475   LR 0.010000   
2022-11-03 21:55:44,628 - INFO  - Training [20][  380/  391]   Loss 0.115017   Top1 95.859375   Top5 99.989720   BatchTime 0.099463   LR 0.010000   
2022-11-03 21:55:45,949 - INFO  - ==> Top1: 95.858    Top5: 99.990    Loss: 0.115

2022-11-03 21:55:45,950 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:55:48,636 - INFO  - Validation [20][   20/   79]   Loss 0.367598   Top1 89.062500   Top5 99.726562   BatchTime 0.134173   
2022-11-03 21:55:49,512 - INFO  - Validation [20][   40/   79]   Loss 0.379967   Top1 89.023438   Top5 99.609375   BatchTime 0.088990   
2022-11-03 21:55:50,420 - INFO  - Validation [20][   60/   79]   Loss 0.381012   Top1 89.127604   Top5 99.609375   BatchTime 0.074461   
2022-11-03 21:55:51,508 - INFO  - ==> Top1: 89.260    Top5: 99.540    Loss: 0.380

2022-11-03 21:55:51,543 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:55:51,543 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.760   Top5: 99.530] Sparsity : 0.808
2022-11-03 21:55:51,544 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.720   Top5: 99.490] Sparsity : 0.800
2022-11-03 21:55:51,655 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:55:51,656 - INFO  - >>>>>>>> Epoch  21
2022-11-03 21:55:51,657 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:55:55,371 - INFO  - Training [21][   20/  391]   Loss 0.096877   Top1 96.523438   Top5 100.000000   BatchTime 0.185685   LR 0.010000   
2022-11-03 21:55:57,290 - INFO  - Training [21][   40/  391]   Loss 0.095582   Top1 96.699219   Top5 99.960938   BatchTime 0.140812   LR 0.010000   
2022-11-03 21:55:58,910 - INFO  - Training [21][   60/  391]   Loss 0.096636   Top1 96.666667   Top5 99.973958   BatchTime 0.120881   LR 0.010000   
2022-11-03 21:56:00,619 - INFO  - Training [21][   80/  391]   Loss 0.100054   Top1 96.464844   Top5 99.980469   BatchTime 0.112018   LR 0.010000   
2022-11-03 21:56:02,259 - INFO  - Training [21][  100/  391]   Loss 0.097238   Top1 96.585938   Top5 99.984375   BatchTime 0.106016   LR 0.010000   
2022-11-03 21:56:03,940 - INFO  - Training [21][  120/  391]   Loss 0.098130   Top1 96.523438   Top5 99.986979   BatchTime 0.102355   LR 0.010000   
2022-11-03 21:56:05,755 - INFO  - Training [21][  140/  391]   Loss 0.097750   Top1 96.478795   Top5 99.988839   BatchTime 0.100692   LR 0.010000   
2022-11-03 21:56:07,757 - INFO  - Training [21][  160/  391]   Loss 0.099642   Top1 96.435547   Top5 99.990234   BatchTime 0.100617   LR 0.010000   
2022-11-03 21:56:09,771 - INFO  - Training [21][  180/  391]   Loss 0.100406   Top1 96.410590   Top5 99.986979   BatchTime 0.100627   LR 0.010000   
2022-11-03 21:56:11,788 - INFO  - Training [21][  200/  391]   Loss 0.100281   Top1 96.449219   Top5 99.980469   BatchTime 0.100650   LR 0.010000   
2022-11-03 21:56:13,812 - INFO  - Training [21][  220/  391]   Loss 0.101785   Top1 96.445312   Top5 99.978693   BatchTime 0.100700   LR 0.010000   
2022-11-03 21:56:15,814 - INFO  - Training [21][  240/  391]   Loss 0.100467   Top1 96.503906   Top5 99.980469   BatchTime 0.100648   LR 0.010000   
2022-11-03 21:56:17,817 - INFO  - Training [21][  260/  391]   Loss 0.100428   Top1 96.523438   Top5 99.981971   BatchTime 0.100610   LR 0.010000   
2022-11-03 21:56:19,830 - INFO  - Training [21][  280/  391]   Loss 0.100843   Top1 96.515067   Top5 99.983259   BatchTime 0.100613   LR 0.010000   
2022-11-03 21:56:21,816 - INFO  - Training [21][  300/  391]   Loss 0.100726   Top1 96.528646   Top5 99.981771   BatchTime 0.100526   LR 0.010000   
2022-11-03 21:56:23,845 - INFO  - Training [21][  320/  391]   Loss 0.100561   Top1 96.518555   Top5 99.978027   BatchTime 0.100582   LR 0.010000   
2022-11-03 21:56:25,846 - INFO  - Training [21][  340/  391]   Loss 0.100726   Top1 96.534926   Top5 99.979320   BatchTime 0.100553   LR 0.010000   
2022-11-03 21:56:27,822 - INFO  - Training [21][  360/  391]   Loss 0.101410   Top1 96.499566   Top5 99.980469   BatchTime 0.100455   LR 0.010000   
2022-11-03 21:56:29,794 - INFO  - Training [21][  380/  391]   Loss 0.102622   Top1 96.443257   Top5 99.975329   BatchTime 0.100357   LR 0.010000   
2022-11-03 21:56:31,115 - INFO  - ==> Top1: 96.446    Top5: 99.972    Loss: 0.103

2022-11-03 21:56:31,116 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:56:33,783 - INFO  - Validation [21][   20/   79]   Loss 0.385531   Top1 89.492188   Top5 99.609375   BatchTime 0.133290   
2022-11-03 21:56:34,690 - INFO  - Validation [21][   40/   79]   Loss 0.397047   Top1 89.394531   Top5 99.492188   BatchTime 0.089313   
2022-11-03 21:56:35,571 - INFO  - Validation [21][   60/   79]   Loss 0.386716   Top1 89.661458   Top5 99.518229   BatchTime 0.074228   
2022-11-03 21:56:36,670 - INFO  - ==> Top1: 89.560    Top5: 99.510    Loss: 0.386

2022-11-03 21:56:36,706 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:56:36,707 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 89.760   Top5: 99.530] Sparsity : 0.808
2022-11-03 21:56:36,707 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 89.720   Top5: 99.490] Sparsity : 0.800
2022-11-03 21:56:36,801 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:56:36,802 - INFO  - >>>>>>>> Epoch  22
2022-11-03 21:56:36,802 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:56:40,571 - INFO  - Training [22][   20/  391]   Loss 0.085853   Top1 96.992188   Top5 100.000000   BatchTime 0.188437   LR 0.010000   
2022-11-03 21:56:42,552 - INFO  - Training [22][   40/  391]   Loss 0.088214   Top1 96.855469   Top5 100.000000   BatchTime 0.143743   LR 0.010000   
2022-11-03 21:56:44,220 - INFO  - Training [22][   60/  391]   Loss 0.088352   Top1 96.901042   Top5 99.986979   BatchTime 0.123619   LR 0.010000   
2022-11-03 21:56:46,047 - INFO  - Training [22][   80/  391]   Loss 0.094250   Top1 96.708984   Top5 99.960938   BatchTime 0.115558   LR 0.010000   
2022-11-03 21:56:47,689 - INFO  - Training [22][  100/  391]   Loss 0.096489   Top1 96.625000   Top5 99.960938   BatchTime 0.108867   LR 0.010000   
2022-11-03 21:56:49,396 - INFO  - Training [22][  120/  391]   Loss 0.099348   Top1 96.523438   Top5 99.967448   BatchTime 0.104939   LR 0.010000   
2022-11-03 21:56:51,249 - INFO  - Training [22][  140/  391]   Loss 0.100470   Top1 96.512277   Top5 99.966518   BatchTime 0.103186   LR 0.010000   
2022-11-03 21:56:53,267 - INFO  - Training [22][  160/  391]   Loss 0.100991   Top1 96.469727   Top5 99.970703   BatchTime 0.102899   LR 0.010000   
2022-11-03 21:56:55,295 - INFO  - Training [22][  180/  391]   Loss 0.101232   Top1 96.423611   Top5 99.969618   BatchTime 0.102736   LR 0.010000   
2022-11-03 21:56:57,302 - INFO  - Training [22][  200/  391]   Loss 0.100441   Top1 96.476562   Top5 99.968750   BatchTime 0.102495   LR 0.010000   
2022-11-03 21:56:59,340 - INFO  - Training [22][  220/  391]   Loss 0.099968   Top1 96.459517   Top5 99.971591   BatchTime 0.102438   LR 0.010000   
2022-11-03 21:57:01,340 - INFO  - Training [22][  240/  391]   Loss 0.099205   Top1 96.503906   Top5 99.973958   BatchTime 0.102236   LR 0.010000   
2022-11-03 21:57:03,344 - INFO  - Training [22][  260/  391]   Loss 0.099268   Top1 96.502404   Top5 99.975962   BatchTime 0.102079   LR 0.010000   
2022-11-03 21:57:05,342 - INFO  - Training [22][  280/  391]   Loss 0.098997   Top1 96.520647   Top5 99.972098   BatchTime 0.101924   LR 0.010000   
2022-11-03 21:57:07,341 - INFO  - Training [22][  300/  391]   Loss 0.099083   Top1 96.507812   Top5 99.973958   BatchTime 0.101794   LR 0.010000   
2022-11-03 21:57:09,353 - INFO  - Training [22][  320/  391]   Loss 0.099070   Top1 96.508789   Top5 99.975586   BatchTime 0.101718   LR 0.010000   
2022-11-03 21:57:11,343 - INFO  - Training [22][  340/  391]   Loss 0.099235   Top1 96.516544   Top5 99.977022   BatchTime 0.101587   LR 0.010000   
2022-11-03 21:57:13,322 - INFO  - Training [22][  360/  391]   Loss 0.099415   Top1 96.503906   Top5 99.973958   BatchTime 0.101441   LR 0.010000   
2022-11-03 21:57:15,296 - INFO  - Training [22][  380/  391]   Loss 0.101175   Top1 96.457648   Top5 99.973273   BatchTime 0.101297   LR 0.010000   
2022-11-03 21:57:16,602 - INFO  - ==> Top1: 96.464    Top5: 99.974    Loss: 0.101

2022-11-03 21:57:16,603 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:57:19,266 - INFO  - Validation [22][   20/   79]   Loss 0.389854   Top1 89.335938   Top5 99.648438   BatchTime 0.133050   
2022-11-03 21:57:20,159 - INFO  - Validation [22][   40/   79]   Loss 0.390170   Top1 89.667969   Top5 99.570312   BatchTime 0.088859   
2022-11-03 21:57:21,056 - INFO  - Validation [22][   60/   79]   Loss 0.383396   Top1 90.000000   Top5 99.570312   BatchTime 0.074189   
2022-11-03 21:57:22,130 - INFO  - ==> Top1: 89.760    Top5: 99.580    Loss: 0.385

2022-11-03 21:57:22,172 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:57:22,173 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.760   Top5: 99.580] Sparsity : 0.815
2022-11-03 21:57:22,173 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 89.760   Top5: 99.530] Sparsity : 0.808
2022-11-03 21:57:22,292 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:57:22,292 - INFO  - >>>>>>>> Epoch  23
2022-11-03 21:57:22,293 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:57:26,058 - INFO  - Training [23][   20/  391]   Loss 0.102035   Top1 96.796875   Top5 100.000000   BatchTime 0.188236   LR 0.010000   
2022-11-03 21:57:28,121 - INFO  - Training [23][   40/  391]   Loss 0.096582   Top1 96.621094   Top5 99.960938   BatchTime 0.145689   LR 0.010000   
2022-11-03 21:57:29,666 - INFO  - Training [23][   60/  391]   Loss 0.097073   Top1 96.510417   Top5 99.973958   BatchTime 0.122874   LR 0.010000   
2022-11-03 21:57:31,397 - INFO  - Training [23][   80/  391]   Loss 0.093619   Top1 96.669922   Top5 99.980469   BatchTime 0.113802   LR 0.010000   
2022-11-03 21:57:33,091 - INFO  - Training [23][  100/  391]   Loss 0.093011   Top1 96.726562   Top5 99.976562   BatchTime 0.107972   LR 0.010000   
2022-11-03 21:57:34,796 - INFO  - Training [23][  120/  391]   Loss 0.093396   Top1 96.679688   Top5 99.980469   BatchTime 0.104188   LR 0.010000   
2022-11-03 21:57:36,663 - INFO  - Training [23][  140/  391]   Loss 0.095260   Top1 96.657366   Top5 99.972098   BatchTime 0.102640   LR 0.010000   
2022-11-03 21:57:38,662 - INFO  - Training [23][  160/  391]   Loss 0.094968   Top1 96.718750   Top5 99.975586   BatchTime 0.102306   LR 0.010000   
2022-11-03 21:57:40,648 - INFO  - Training [23][  180/  391]   Loss 0.093858   Top1 96.762153   Top5 99.978299   BatchTime 0.101967   LR 0.010000   
2022-11-03 21:57:42,660 - INFO  - Training [23][  200/  391]   Loss 0.095444   Top1 96.714844   Top5 99.980469   BatchTime 0.101833   LR 0.010000   
2022-11-03 21:57:44,660 - INFO  - Training [23][  220/  391]   Loss 0.095400   Top1 96.697443   Top5 99.982244   BatchTime 0.101665   LR 0.010000   
2022-11-03 21:57:46,673 - INFO  - Training [23][  240/  391]   Loss 0.095718   Top1 96.669922   Top5 99.983724   BatchTime 0.101579   LR 0.010000   
2022-11-03 21:57:48,666 - INFO  - Training [23][  260/  391]   Loss 0.095809   Top1 96.667668   Top5 99.984976   BatchTime 0.101432   LR 0.010000   
2022-11-03 21:57:50,654 - INFO  - Training [23][  280/  391]   Loss 0.096173   Top1 96.668527   Top5 99.986049   BatchTime 0.101285   LR 0.010000   
2022-11-03 21:57:52,664 - INFO  - Training [23][  300/  391]   Loss 0.096591   Top1 96.658854   Top5 99.986979   BatchTime 0.101236   LR 0.010000   
2022-11-03 21:57:54,670 - INFO  - Training [23][  320/  391]   Loss 0.096691   Top1 96.633301   Top5 99.987793   BatchTime 0.101175   LR 0.010000   
2022-11-03 21:57:56,650 - INFO  - Training [23][  340/  391]   Loss 0.096225   Top1 96.656710   Top5 99.986213   BatchTime 0.101048   LR 0.010000   
2022-11-03 21:57:58,640 - INFO  - Training [23][  360/  391]   Loss 0.096821   Top1 96.629774   Top5 99.986979   BatchTime 0.100962   LR 0.010000   
2022-11-03 21:58:00,628 - INFO  - Training [23][  380/  391]   Loss 0.096748   Top1 96.642681   Top5 99.987664   BatchTime 0.100879   LR 0.010000   
2022-11-03 21:58:01,955 - INFO  - ==> Top1: 96.648    Top5: 99.986    Loss: 0.097

2022-11-03 21:58:01,956 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:58:04,599 - INFO  - Validation [23][   20/   79]   Loss 0.394151   Top1 89.453125   Top5 99.570312   BatchTime 0.132061   
2022-11-03 21:58:05,535 - INFO  - Validation [23][   40/   79]   Loss 0.406310   Top1 89.589844   Top5 99.492188   BatchTime 0.089427   
2022-11-03 21:58:06,431 - INFO  - Validation [23][   60/   79]   Loss 0.399714   Top1 89.661458   Top5 99.570312   BatchTime 0.074562   
2022-11-03 21:58:07,509 - INFO  - ==> Top1: 89.500    Top5: 99.560    Loss: 0.400

2022-11-03 21:58:07,540 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:58:07,541 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.760   Top5: 99.580] Sparsity : 0.815
2022-11-03 21:58:07,541 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 89.760   Top5: 99.530] Sparsity : 0.808
2022-11-03 21:58:07,640 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:58:07,640 - INFO  - >>>>>>>> Epoch  24
2022-11-03 21:58:07,642 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:58:11,442 - INFO  - Training [24][   20/  391]   Loss 0.086498   Top1 96.640625   Top5 100.000000   BatchTime 0.189986   LR 0.010000   
2022-11-03 21:58:13,467 - INFO  - Training [24][   40/  391]   Loss 0.088581   Top1 96.699219   Top5 99.980469   BatchTime 0.145620   LR 0.010000   
2022-11-03 21:58:14,995 - INFO  - Training [24][   60/  391]   Loss 0.089943   Top1 96.627604   Top5 99.986979   BatchTime 0.122541   LR 0.010000   
2022-11-03 21:58:16,729 - INFO  - Training [24][   80/  391]   Loss 0.088257   Top1 96.699219   Top5 99.990234   BatchTime 0.113579   LR 0.010000   
2022-11-03 21:58:18,414 - INFO  - Training [24][  100/  391]   Loss 0.088543   Top1 96.734375   Top5 99.992188   BatchTime 0.107721   LR 0.010000   
2022-11-03 21:58:20,108 - INFO  - Training [24][  120/  391]   Loss 0.088286   Top1 96.705729   Top5 99.993490   BatchTime 0.103882   LR 0.010000   
2022-11-03 21:58:22,015 - INFO  - Training [24][  140/  391]   Loss 0.087509   Top1 96.813616   Top5 99.994420   BatchTime 0.102664   LR 0.010000   
2022-11-03 21:58:24,024 - INFO  - Training [24][  160/  391]   Loss 0.087787   Top1 96.811523   Top5 99.995117   BatchTime 0.102381   LR 0.010000   
2022-11-03 21:58:26,030 - INFO  - Training [24][  180/  391]   Loss 0.089180   Top1 96.809896   Top5 99.991319   BatchTime 0.102150   LR 0.010000   
2022-11-03 21:58:28,044 - INFO  - Training [24][  200/  391]   Loss 0.091580   Top1 96.738281   Top5 99.988281   BatchTime 0.102006   LR 0.010000   
2022-11-03 21:58:30,060 - INFO  - Training [24][  220/  391]   Loss 0.091069   Top1 96.779119   Top5 99.989347   BatchTime 0.101899   LR 0.010000   
2022-11-03 21:58:32,072 - INFO  - Training [24][  240/  391]   Loss 0.091350   Top1 96.787109   Top5 99.986979   BatchTime 0.101788   LR 0.010000   
2022-11-03 21:58:34,064 - INFO  - Training [24][  260/  391]   Loss 0.089977   Top1 96.844952   Top5 99.987981   BatchTime 0.101621   LR 0.010000   
2022-11-03 21:58:36,075 - INFO  - Training [24][  280/  391]   Loss 0.089095   Top1 96.900112   Top5 99.988839   BatchTime 0.101542   LR 0.010000   
2022-11-03 21:58:38,094 - INFO  - Training [24][  300/  391]   Loss 0.090002   Top1 96.888021   Top5 99.989583   BatchTime 0.101505   LR 0.010000   
2022-11-03 21:58:40,118 - INFO  - Training [24][  320/  391]   Loss 0.090404   Top1 96.862793   Top5 99.990234   BatchTime 0.101483   LR 0.010000   
2022-11-03 21:58:42,104 - INFO  - Training [24][  340/  391]   Loss 0.090390   Top1 96.847426   Top5 99.990809   BatchTime 0.101356   LR 0.010000   
2022-11-03 21:58:44,079 - INFO  - Training [24][  360/  391]   Loss 0.090572   Top1 96.829427   Top5 99.991319   BatchTime 0.101211   LR 0.010000   
2022-11-03 21:58:46,052 - INFO  - Training [24][  380/  391]   Loss 0.090655   Top1 96.835938   Top5 99.989720   BatchTime 0.101075   LR 0.010000   
2022-11-03 21:58:47,397 - INFO  - ==> Top1: 96.830    Top5: 99.990    Loss: 0.091

2022-11-03 21:58:47,398 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:58:50,076 - INFO  - Validation [24][   20/   79]   Loss 0.381264   Top1 90.039062   Top5 99.648438   BatchTime 0.133819   
2022-11-03 21:58:50,971 - INFO  - Validation [24][   40/   79]   Loss 0.382291   Top1 90.195312   Top5 99.648438   BatchTime 0.089275   
2022-11-03 21:58:51,867 - INFO  - Validation [24][   60/   79]   Loss 0.380629   Top1 90.221354   Top5 99.661458   BatchTime 0.074461   
2022-11-03 21:58:52,970 - INFO  - ==> Top1: 90.020    Top5: 99.680    Loss: 0.381

2022-11-03 21:58:53,010 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 21:58:53,011 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:58:53,011 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 89.760   Top5: 99.580] Sparsity : 0.815
2022-11-03 21:58:53,172 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 21:58:53,172 - INFO  - >>>>>>>> Epoch  25
2022-11-03 21:58:53,173 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:58:57,007 - INFO  - Training [25][   20/  391]   Loss 0.097370   Top1 96.601562   Top5 99.960938   BatchTime 0.191707   LR 0.010000   
2022-11-03 21:58:59,015 - INFO  - Training [25][   40/  391]   Loss 0.093551   Top1 96.699219   Top5 99.980469   BatchTime 0.146053   LR 0.010000   
2022-11-03 21:59:00,664 - INFO  - Training [25][   60/  391]   Loss 0.089583   Top1 96.757812   Top5 99.986979   BatchTime 0.124837   LR 0.010000   
2022-11-03 21:59:02,320 - INFO  - Training [25][   80/  391]   Loss 0.089671   Top1 96.718750   Top5 99.980469   BatchTime 0.114329   LR 0.010000   
2022-11-03 21:59:03,938 - INFO  - Training [25][  100/  391]   Loss 0.092417   Top1 96.601562   Top5 99.984375   BatchTime 0.107646   LR 0.010000   
2022-11-03 21:59:05,606 - INFO  - Training [25][  120/  391]   Loss 0.091217   Top1 96.634115   Top5 99.986979   BatchTime 0.103602   LR 0.010000   
2022-11-03 21:59:07,413 - INFO  - Training [25][  140/  391]   Loss 0.091142   Top1 96.618304   Top5 99.988839   BatchTime 0.101711   LR 0.010000   
2022-11-03 21:59:09,416 - INFO  - Training [25][  160/  391]   Loss 0.092281   Top1 96.538086   Top5 99.985352   BatchTime 0.101517   LR 0.010000   
2022-11-03 21:59:11,436 - INFO  - Training [25][  180/  391]   Loss 0.092117   Top1 96.540799   Top5 99.982639   BatchTime 0.101456   LR 0.010000   
2022-11-03 21:59:13,453 - INFO  - Training [25][  200/  391]   Loss 0.091621   Top1 96.589844   Top5 99.980469   BatchTime 0.101394   LR 0.010000   
2022-11-03 21:59:15,464 - INFO  - Training [25][  220/  391]   Loss 0.092480   Top1 96.598011   Top5 99.978693   BatchTime 0.101319   LR 0.010000   
2022-11-03 21:59:17,467 - INFO  - Training [25][  240/  391]   Loss 0.090877   Top1 96.679688   Top5 99.977214   BatchTime 0.101220   LR 0.010000   
2022-11-03 21:59:19,458 - INFO  - Training [25][  260/  391]   Loss 0.090184   Top1 96.736779   Top5 99.978966   BatchTime 0.101094   LR 0.010000   
2022-11-03 21:59:21,463 - INFO  - Training [25][  280/  391]   Loss 0.090244   Top1 96.715960   Top5 99.980469   BatchTime 0.101033   LR 0.010000   
2022-11-03 21:59:23,481 - INFO  - Training [25][  300/  391]   Loss 0.090836   Top1 96.674479   Top5 99.981771   BatchTime 0.101024   LR 0.010000   
2022-11-03 21:59:25,494 - INFO  - Training [25][  320/  391]   Loss 0.091186   Top1 96.655273   Top5 99.980469   BatchTime 0.101001   LR 0.010000   
2022-11-03 21:59:27,465 - INFO  - Training [25][  340/  391]   Loss 0.090897   Top1 96.663603   Top5 99.981618   BatchTime 0.100857   LR 0.010000   
2022-11-03 21:59:29,449 - INFO  - Training [25][  360/  391]   Loss 0.091559   Top1 96.638455   Top5 99.982639   BatchTime 0.100763   LR 0.010000   
2022-11-03 21:59:31,418 - INFO  - Training [25][  380/  391]   Loss 0.091723   Top1 96.634457   Top5 99.981497   BatchTime 0.100642   LR 0.010000   
2022-11-03 21:59:32,769 - INFO  - ==> Top1: 96.650    Top5: 99.982    Loss: 0.092

2022-11-03 21:59:32,770 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 21:59:35,456 - INFO  - Validation [25][   20/   79]   Loss 0.378791   Top1 90.312500   Top5 99.570312   BatchTime 0.134196   
2022-11-03 21:59:36,351 - INFO  - Validation [25][   40/   79]   Loss 0.385017   Top1 90.039062   Top5 99.492188   BatchTime 0.089498   
2022-11-03 21:59:37,222 - INFO  - Validation [25][   60/   79]   Loss 0.385281   Top1 90.078125   Top5 99.531250   BatchTime 0.074180   
2022-11-03 21:59:38,287 - INFO  - ==> Top1: 89.940    Top5: 99.570    Loss: 0.383

2022-11-03 21:59:38,331 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 21:59:38,332 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.570] Sparsity : 0.818
2022-11-03 21:59:38,332 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 21:59:38,433 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 21:59:38,433 - INFO  - >>>>>>>> Epoch  26
2022-11-03 21:59:38,434 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 21:59:42,202 - INFO  - Training [26][   20/  391]   Loss 0.095938   Top1 96.796875   Top5 100.000000   BatchTime 0.188392   LR 0.010000   
2022-11-03 21:59:44,191 - INFO  - Training [26][   40/  391]   Loss 0.086972   Top1 96.992188   Top5 100.000000   BatchTime 0.143905   LR 0.010000   
2022-11-03 21:59:45,881 - INFO  - Training [26][   60/  391]   Loss 0.085905   Top1 97.096354   Top5 100.000000   BatchTime 0.124109   LR 0.010000   
2022-11-03 21:59:47,660 - INFO  - Training [26][   80/  391]   Loss 0.084662   Top1 97.138672   Top5 100.000000   BatchTime 0.115321   LR 0.010000   
2022-11-03 21:59:49,388 - INFO  - Training [26][  100/  391]   Loss 0.082706   Top1 97.203125   Top5 100.000000   BatchTime 0.109534   LR 0.010000   
2022-11-03 21:59:51,101 - INFO  - Training [26][  120/  391]   Loss 0.082126   Top1 97.239583   Top5 100.000000   BatchTime 0.105551   LR 0.010000   
2022-11-03 21:59:52,910 - INFO  - Training [26][  140/  391]   Loss 0.081835   Top1 97.237723   Top5 100.000000   BatchTime 0.103395   LR 0.010000   
2022-11-03 21:59:54,945 - INFO  - Training [26][  160/  391]   Loss 0.082630   Top1 97.187500   Top5 100.000000   BatchTime 0.103188   LR 0.010000   
2022-11-03 21:59:56,948 - INFO  - Training [26][  180/  391]   Loss 0.084516   Top1 97.118056   Top5 100.000000   BatchTime 0.102851   LR 0.010000   
2022-11-03 21:59:58,955 - INFO  - Training [26][  200/  391]   Loss 0.083786   Top1 97.144531   Top5 100.000000   BatchTime 0.102602   LR 0.010000   
2022-11-03 22:00:01,096 - INFO  - Training [26][  220/  391]   Loss 0.083952   Top1 97.109375   Top5 99.996449   BatchTime 0.103006   LR 0.010000   
2022-11-03 22:00:03,131 - INFO  - Training [26][  240/  391]   Loss 0.083120   Top1 97.141927   Top5 99.996745   BatchTime 0.102899   LR 0.010000   
2022-11-03 22:00:05,135 - INFO  - Training [26][  260/  391]   Loss 0.084058   Top1 97.106370   Top5 99.993990   BatchTime 0.102690   LR 0.010000   
2022-11-03 22:00:07,141 - INFO  - Training [26][  280/  391]   Loss 0.084309   Top1 97.087054   Top5 99.994420   BatchTime 0.102519   LR 0.010000   
2022-11-03 22:00:09,140 - INFO  - Training [26][  300/  391]   Loss 0.084329   Top1 97.101562   Top5 99.994792   BatchTime 0.102350   LR 0.010000   
2022-11-03 22:00:11,169 - INFO  - Training [26][  320/  391]   Loss 0.085349   Top1 97.060547   Top5 99.992676   BatchTime 0.102293   LR 0.010000   
2022-11-03 22:00:13,161 - INFO  - Training [26][  340/  391]   Loss 0.085195   Top1 97.068015   Top5 99.990809   BatchTime 0.102134   LR 0.010000   
2022-11-03 22:00:15,138 - INFO  - Training [26][  360/  391]   Loss 0.085955   Top1 97.044271   Top5 99.991319   BatchTime 0.101953   LR 0.010000   
2022-11-03 22:00:17,121 - INFO  - Training [26][  380/  391]   Loss 0.086238   Top1 97.035362   Top5 99.989720   BatchTime 0.101804   LR 0.010000   
2022-11-03 22:00:18,479 - INFO  - ==> Top1: 97.002    Top5: 99.990    Loss: 0.087

2022-11-03 22:00:18,480 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:00:21,156 - INFO  - Validation [26][   20/   79]   Loss 0.415648   Top1 89.101562   Top5 99.531250   BatchTime 0.133766   
2022-11-03 22:00:22,052 - INFO  - Validation [26][   40/   79]   Loss 0.411482   Top1 89.453125   Top5 99.589844   BatchTime 0.089278   
2022-11-03 22:00:22,943 - INFO  - Validation [26][   60/   79]   Loss 0.399171   Top1 89.726562   Top5 99.596354   BatchTime 0.074370   
2022-11-03 22:00:24,024 - INFO  - ==> Top1: 89.700    Top5: 99.620    Loss: 0.396

2022-11-03 22:00:24,053 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 22:00:24,054 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.570] Sparsity : 0.818
2022-11-03 22:00:24,054 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 22:00:24,164 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:00:24,164 - INFO  - >>>>>>>> Epoch  27
2022-11-03 22:00:24,166 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:00:27,960 - INFO  - Training [27][   20/  391]   Loss 0.077896   Top1 97.187500   Top5 100.000000   BatchTime 0.189696   LR 0.010000   
2022-11-03 22:00:30,010 - INFO  - Training [27][   40/  391]   Loss 0.082306   Top1 97.167969   Top5 100.000000   BatchTime 0.146114   LR 0.010000   
2022-11-03 22:00:31,521 - INFO  - Training [27][   60/  391]   Loss 0.082933   Top1 97.161458   Top5 100.000000   BatchTime 0.122594   LR 0.010000   
2022-11-03 22:00:33,312 - INFO  - Training [27][   80/  391]   Loss 0.078216   Top1 97.226562   Top5 100.000000   BatchTime 0.114331   LR 0.010000   
2022-11-03 22:00:34,985 - INFO  - Training [27][  100/  391]   Loss 0.079057   Top1 97.250000   Top5 99.992188   BatchTime 0.108193   LR 0.010000   
2022-11-03 22:00:36,664 - INFO  - Training [27][  120/  391]   Loss 0.080183   Top1 97.259115   Top5 99.993490   BatchTime 0.104150   LR 0.010000   
2022-11-03 22:00:38,570 - INFO  - Training [27][  140/  391]   Loss 0.081767   Top1 97.232143   Top5 99.994420   BatchTime 0.102886   LR 0.010000   
2022-11-03 22:00:40,607 - INFO  - Training [27][  160/  391]   Loss 0.082054   Top1 97.197266   Top5 99.995117   BatchTime 0.102755   LR 0.010000   
2022-11-03 22:00:42,644 - INFO  - Training [27][  180/  391]   Loss 0.084004   Top1 97.122396   Top5 99.995660   BatchTime 0.102657   LR 0.010000   
2022-11-03 22:00:44,575 - INFO  - Training [27][  200/  391]   Loss 0.085262   Top1 97.046875   Top5 99.992188   BatchTime 0.102043   LR 0.010000   
2022-11-03 22:00:46,574 - INFO  - Training [27][  220/  391]   Loss 0.085928   Top1 97.006392   Top5 99.989347   BatchTime 0.101855   LR 0.010000   
2022-11-03 22:00:48,569 - INFO  - Training [27][  240/  391]   Loss 0.085906   Top1 97.014974   Top5 99.990234   BatchTime 0.101679   LR 0.010000   
2022-11-03 22:00:50,572 - INFO  - Training [27][  260/  391]   Loss 0.086359   Top1 97.010216   Top5 99.990986   BatchTime 0.101561   LR 0.010000   
2022-11-03 22:00:52,596 - INFO  - Training [27][  280/  391]   Loss 0.086285   Top1 97.014509   Top5 99.988839   BatchTime 0.101534   LR 0.010000   
2022-11-03 22:00:54,605 - INFO  - Training [27][  300/  391]   Loss 0.086953   Top1 96.997396   Top5 99.984375   BatchTime 0.101463   LR 0.010000   
2022-11-03 22:00:56,604 - INFO  - Training [27][  320/  391]   Loss 0.086658   Top1 97.006836   Top5 99.985352   BatchTime 0.101366   LR 0.010000   
2022-11-03 22:00:58,577 - INFO  - Training [27][  340/  391]   Loss 0.086089   Top1 97.024357   Top5 99.983915   BatchTime 0.101209   LR 0.010000   
2022-11-03 22:01:00,548 - INFO  - Training [27][  360/  391]   Loss 0.086426   Top1 97.005208   Top5 99.982639   BatchTime 0.101061   LR 0.010000   
2022-11-03 22:01:02,525 - INFO  - Training [27][  380/  391]   Loss 0.086150   Top1 96.996299   Top5 99.983553   BatchTime 0.100944   LR 0.010000   
2022-11-03 22:01:03,855 - INFO  - ==> Top1: 96.980    Top5: 99.982    Loss: 0.086

2022-11-03 22:01:03,856 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:01:06,561 - INFO  - Validation [27][   20/   79]   Loss 0.407102   Top1 88.945312   Top5 99.453125   BatchTime 0.135156   
2022-11-03 22:01:07,455 - INFO  - Validation [27][   40/   79]   Loss 0.418538   Top1 89.023438   Top5 99.511719   BatchTime 0.089935   
2022-11-03 22:01:08,325 - INFO  - Validation [27][   60/   79]   Loss 0.408408   Top1 89.492188   Top5 99.518229   BatchTime 0.074449   
2022-11-03 22:01:09,405 - INFO  - ==> Top1: 89.470    Top5: 99.570    Loss: 0.405

2022-11-03 22:01:09,436 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 22:01:09,437 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.570] Sparsity : 0.818
2022-11-03 22:01:09,437 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 89.780   Top5: 99.510] Sparsity : 0.743
2022-11-03 22:01:09,596 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:01:09,596 - INFO  - >>>>>>>> Epoch  28
2022-11-03 22:01:09,598 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:01:13,399 - INFO  - Training [28][   20/  391]   Loss 0.086129   Top1 97.304688   Top5 100.000000   BatchTime 0.190064   LR 0.010000   
2022-11-03 22:01:15,434 - INFO  - Training [28][   40/  391]   Loss 0.081870   Top1 97.167969   Top5 100.000000   BatchTime 0.145907   LR 0.010000   
2022-11-03 22:01:16,963 - INFO  - Training [28][   60/  391]   Loss 0.085359   Top1 97.057292   Top5 100.000000   BatchTime 0.122748   LR 0.010000   
2022-11-03 22:01:18,726 - INFO  - Training [28][   80/  391]   Loss 0.083367   Top1 97.187500   Top5 100.000000   BatchTime 0.114104   LR 0.010000   
2022-11-03 22:01:20,414 - INFO  - Training [28][  100/  391]   Loss 0.082922   Top1 97.179688   Top5 100.000000   BatchTime 0.108156   LR 0.010000   
2022-11-03 22:01:22,047 - INFO  - Training [28][  120/  391]   Loss 0.084378   Top1 97.109375   Top5 100.000000   BatchTime 0.103743   LR 0.010000   
2022-11-03 22:01:23,959 - INFO  - Training [28][  140/  391]   Loss 0.083271   Top1 97.114955   Top5 100.000000   BatchTime 0.102580   LR 0.010000   
2022-11-03 22:01:25,963 - INFO  - Training [28][  160/  391]   Loss 0.083186   Top1 97.055664   Top5 100.000000   BatchTime 0.102281   LR 0.010000   
2022-11-03 22:01:27,976 - INFO  - Training [28][  180/  391]   Loss 0.083267   Top1 97.044271   Top5 100.000000   BatchTime 0.102098   LR 0.010000   
2022-11-03 22:01:29,999 - INFO  - Training [28][  200/  391]   Loss 0.083602   Top1 97.042969   Top5 100.000000   BatchTime 0.102004   LR 0.010000   
2022-11-03 22:01:32,022 - INFO  - Training [28][  220/  391]   Loss 0.083511   Top1 97.056108   Top5 100.000000   BatchTime 0.101924   LR 0.010000   
2022-11-03 22:01:34,022 - INFO  - Training [28][  240/  391]   Loss 0.083120   Top1 97.080078   Top5 100.000000   BatchTime 0.101765   LR 0.010000   
2022-11-03 22:01:36,033 - INFO  - Training [28][  260/  391]   Loss 0.083118   Top1 97.049279   Top5 100.000000   BatchTime 0.101672   LR 0.010000   
2022-11-03 22:01:38,144 - INFO  - Training [28][  280/  391]   Loss 0.083621   Top1 97.025670   Top5 100.000000   BatchTime 0.101947   LR 0.010000   
2022-11-03 22:01:40,144 - INFO  - Training [28][  300/  391]   Loss 0.083259   Top1 97.065104   Top5 100.000000   BatchTime 0.101818   LR 0.010000   
2022-11-03 22:01:42,148 - INFO  - Training [28][  320/  391]   Loss 0.084225   Top1 97.045898   Top5 100.000000   BatchTime 0.101717   LR 0.010000   
2022-11-03 22:01:44,154 - INFO  - Training [28][  340/  391]   Loss 0.084091   Top1 97.051930   Top5 99.997702   BatchTime 0.101633   LR 0.010000   
2022-11-03 22:01:46,122 - INFO  - Training [28][  360/  391]   Loss 0.083746   Top1 97.070312   Top5 99.997830   BatchTime 0.101453   LR 0.010000   
2022-11-03 22:01:48,102 - INFO  - Training [28][  380/  391]   Loss 0.083957   Top1 97.062089   Top5 99.997944   BatchTime 0.101324   LR 0.010000   
2022-11-03 22:01:49,425 - INFO  - ==> Top1: 97.072    Top5: 99.998    Loss: 0.084

2022-11-03 22:01:49,425 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:01:52,120 - INFO  - Validation [28][   20/   79]   Loss 0.403534   Top1 89.257812   Top5 99.570312   BatchTime 0.134678   
2022-11-03 22:01:53,015 - INFO  - Validation [28][   40/   79]   Loss 0.410421   Top1 89.414062   Top5 99.589844   BatchTime 0.089705   
2022-11-03 22:01:53,894 - INFO  - Validation [28][   60/   79]   Loss 0.395297   Top1 89.713542   Top5 99.596354   BatchTime 0.074459   
2022-11-03 22:01:54,994 - INFO  - ==> Top1: 89.830    Top5: 99.640    Loss: 0.386

2022-11-03 22:01:55,024 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 22:01:55,024 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.570] Sparsity : 0.818
2022-11-03 22:01:55,025 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 89.830   Top5: 99.640] Sparsity : 0.820
2022-11-03 22:01:55,144 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:01:55,144 - INFO  - >>>>>>>> Epoch  29
2022-11-03 22:01:55,146 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:01:58,952 - INFO  - Training [29][   20/  391]   Loss 0.070367   Top1 97.226562   Top5 100.000000   BatchTime 0.190289   LR 0.010000   
2022-11-03 22:02:00,956 - INFO  - Training [29][   40/  391]   Loss 0.073162   Top1 97.285156   Top5 100.000000   BatchTime 0.145261   LR 0.010000   
2022-11-03 22:02:02,428 - INFO  - Training [29][   60/  391]   Loss 0.074243   Top1 97.213542   Top5 100.000000   BatchTime 0.121362   LR 0.010000   
2022-11-03 22:02:04,206 - INFO  - Training [29][   80/  391]   Loss 0.075055   Top1 97.216797   Top5 100.000000   BatchTime 0.113246   LR 0.010000   
2022-11-03 22:02:05,873 - INFO  - Training [29][  100/  391]   Loss 0.077312   Top1 97.156250   Top5 100.000000   BatchTime 0.107272   LR 0.010000   
2022-11-03 22:02:07,579 - INFO  - Training [29][  120/  391]   Loss 0.076247   Top1 97.213542   Top5 100.000000   BatchTime 0.103611   LR 0.010000   
2022-11-03 22:02:09,475 - INFO  - Training [29][  140/  391]   Loss 0.075975   Top1 97.198661   Top5 100.000000   BatchTime 0.102350   LR 0.010000   
2022-11-03 22:02:11,504 - INFO  - Training [29][  160/  391]   Loss 0.077021   Top1 97.158203   Top5 99.990234   BatchTime 0.102237   LR 0.010000   
2022-11-03 22:02:13,521 - INFO  - Training [29][  180/  391]   Loss 0.077399   Top1 97.196181   Top5 99.991319   BatchTime 0.102084   LR 0.010000   
2022-11-03 22:02:15,535 - INFO  - Training [29][  200/  391]   Loss 0.077837   Top1 97.203125   Top5 99.992188   BatchTime 0.101945   LR 0.010000   
2022-11-03 22:02:17,543 - INFO  - Training [29][  220/  391]   Loss 0.077817   Top1 97.230114   Top5 99.992898   BatchTime 0.101801   LR 0.010000   
2022-11-03 22:02:19,572 - INFO  - Training [29][  240/  391]   Loss 0.077220   Top1 97.242839   Top5 99.993490   BatchTime 0.101774   LR 0.010000   
2022-11-03 22:02:21,578 - INFO  - Training [29][  260/  391]   Loss 0.077761   Top1 97.223558   Top5 99.993990   BatchTime 0.101661   LR 0.010000   
2022-11-03 22:02:23,570 - INFO  - Training [29][  280/  391]   Loss 0.077903   Top1 97.248884   Top5 99.991629   BatchTime 0.101513   LR 0.010000   
2022-11-03 22:02:25,583 - INFO  - Training [29][  300/  391]   Loss 0.077363   Top1 97.265625   Top5 99.992188   BatchTime 0.101456   LR 0.010000   
2022-11-03 22:02:27,577 - INFO  - Training [29][  320/  391]   Loss 0.078187   Top1 97.253418   Top5 99.992676   BatchTime 0.101344   LR 0.010000   
2022-11-03 22:02:29,553 - INFO  - Training [29][  340/  391]   Loss 0.077763   Top1 97.261029   Top5 99.993107   BatchTime 0.101195   LR 0.010000   
2022-11-03 22:02:31,523 - INFO  - Training [29][  360/  391]   Loss 0.077960   Top1 97.265625   Top5 99.993490   BatchTime 0.101046   LR 0.010000   
2022-11-03 22:02:33,491 - INFO  - Training [29][  380/  391]   Loss 0.078747   Top1 97.230674   Top5 99.993832   BatchTime 0.100907   LR 0.010000   
2022-11-03 22:02:34,833 - INFO  - ==> Top1: 97.218    Top5: 99.994    Loss: 0.079

2022-11-03 22:02:34,834 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:02:37,511 - INFO  - Validation [29][   20/   79]   Loss 0.421490   Top1 89.609375   Top5 99.492188   BatchTime 0.133825   
2022-11-03 22:02:38,404 - INFO  - Validation [29][   40/   79]   Loss 0.426566   Top1 89.238281   Top5 99.492188   BatchTime 0.089221   
2022-11-03 22:02:39,300 - INFO  - Validation [29][   60/   79]   Loss 0.412661   Top1 89.752604   Top5 99.466146   BatchTime 0.074426   
2022-11-03 22:02:40,385 - INFO  - ==> Top1: 89.730    Top5: 99.500    Loss: 0.409

2022-11-03 22:02:40,420 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 22:02:40,421 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.570] Sparsity : 0.818
2022-11-03 22:02:40,421 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 89.830   Top5: 99.640] Sparsity : 0.820
2022-11-03 22:02:40,528 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:02:40,528 - INFO  - >>>>>>>> Epoch  30
2022-11-03 22:02:40,529 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:02:44,325 - INFO  - Training [30][   20/  391]   Loss 0.074519   Top1 97.656250   Top5 100.000000   BatchTime 0.189807   LR 0.001000   
2022-11-03 22:02:46,340 - INFO  - Training [30][   40/  391]   Loss 0.073068   Top1 97.578125   Top5 100.000000   BatchTime 0.145268   LR 0.001000   
2022-11-03 22:02:47,846 - INFO  - Training [30][   60/  391]   Loss 0.072761   Top1 97.552083   Top5 100.000000   BatchTime 0.121947   LR 0.001000   
2022-11-03 22:02:49,608 - INFO  - Training [30][   80/  391]   Loss 0.072269   Top1 97.578125   Top5 100.000000   BatchTime 0.113486   LR 0.001000   
2022-11-03 22:02:51,241 - INFO  - Training [30][  100/  391]   Loss 0.072915   Top1 97.562500   Top5 100.000000   BatchTime 0.107122   LR 0.001000   
2022-11-03 22:02:52,879 - INFO  - Training [30][  120/  391]   Loss 0.071401   Top1 97.558594   Top5 100.000000   BatchTime 0.102917   LR 0.001000   
2022-11-03 22:02:54,774 - INFO  - Training [30][  140/  391]   Loss 0.070393   Top1 97.633929   Top5 100.000000   BatchTime 0.101745   LR 0.001000   
2022-11-03 22:02:56,770 - INFO  - Training [30][  160/  391]   Loss 0.069146   Top1 97.695312   Top5 100.000000   BatchTime 0.101506   LR 0.001000   
2022-11-03 22:02:58,795 - INFO  - Training [30][  180/  391]   Loss 0.068457   Top1 97.708333   Top5 99.995660   BatchTime 0.101476   LR 0.001000   
2022-11-03 22:03:00,798 - INFO  - Training [30][  200/  391]   Loss 0.069351   Top1 97.695312   Top5 99.996094   BatchTime 0.101345   LR 0.001000   
2022-11-03 22:03:02,801 - INFO  - Training [30][  220/  391]   Loss 0.069020   Top1 97.720170   Top5 99.996449   BatchTime 0.101236   LR 0.001000   
2022-11-03 22:03:04,806 - INFO  - Training [30][  240/  391]   Loss 0.068134   Top1 97.718099   Top5 99.996745   BatchTime 0.101150   LR 0.001000   
2022-11-03 22:03:06,833 - INFO  - Training [30][  260/  391]   Loss 0.068368   Top1 97.695312   Top5 99.990986   BatchTime 0.101167   LR 0.001000   
2022-11-03 22:03:08,847 - INFO  - Training [30][  280/  391]   Loss 0.067890   Top1 97.686942   Top5 99.991629   BatchTime 0.101132   LR 0.001000   
2022-11-03 22:03:10,852 - INFO  - Training [30][  300/  391]   Loss 0.066951   Top1 97.723958   Top5 99.992188   BatchTime 0.101074   LR 0.001000   
2022-11-03 22:03:12,875 - INFO  - Training [30][  320/  391]   Loss 0.066786   Top1 97.731934   Top5 99.992676   BatchTime 0.101078   LR 0.001000   
2022-11-03 22:03:15,001 - INFO  - Training [30][  340/  391]   Loss 0.066763   Top1 97.741268   Top5 99.993107   BatchTime 0.101386   LR 0.001000   
2022-11-03 22:03:16,988 - INFO  - Training [30][  360/  391]   Loss 0.066717   Top1 97.738715   Top5 99.993490   BatchTime 0.101272   LR 0.001000   
2022-11-03 22:03:18,961 - INFO  - Training [30][  380/  391]   Loss 0.066438   Top1 97.740543   Top5 99.993832   BatchTime 0.101134   LR 0.001000   
2022-11-03 22:03:20,301 - INFO  - ==> Top1: 97.740    Top5: 99.994    Loss: 0.066

2022-11-03 22:03:20,302 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:03:23,006 - INFO  - Validation [30][   20/   79]   Loss 0.376278   Top1 90.117188   Top5 99.570312   BatchTime 0.135115   
2022-11-03 22:03:23,901 - INFO  - Validation [30][   40/   79]   Loss 0.395801   Top1 89.687500   Top5 99.550781   BatchTime 0.089937   
2022-11-03 22:03:24,773 - INFO  - Validation [30][   60/   79]   Loss 0.381844   Top1 90.260417   Top5 99.596354   BatchTime 0.074489   
2022-11-03 22:03:25,851 - INFO  - ==> Top1: 90.190    Top5: 99.620    Loss: 0.378

2022-11-03 22:03:25,892 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 90.190   Top5: 99.620] Sparsity : 0.821
2022-11-03 22:03:25,893 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 22:03:25,893 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.940   Top5: 99.570] Sparsity : 0.818
2022-11-03 22:03:26,079 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:03:26,080 - INFO  - >>>>>>>> Epoch  31
2022-11-03 22:03:26,081 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:03:29,858 - INFO  - Training [31][   20/  391]   Loss 0.060758   Top1 97.851562   Top5 100.000000   BatchTime 0.188850   LR 0.001000   
2022-11-03 22:03:31,773 - INFO  - Training [31][   40/  391]   Loss 0.062588   Top1 97.871094   Top5 100.000000   BatchTime 0.142299   LR 0.001000   
2022-11-03 22:03:33,432 - INFO  - Training [31][   60/  391]   Loss 0.061788   Top1 97.851562   Top5 100.000000   BatchTime 0.122516   LR 0.001000   
2022-11-03 22:03:35,129 - INFO  - Training [31][   80/  391]   Loss 0.060145   Top1 97.929688   Top5 100.000000   BatchTime 0.113094   LR 0.001000   
2022-11-03 22:03:36,921 - INFO  - Training [31][  100/  391]   Loss 0.061158   Top1 97.890625   Top5 100.000000   BatchTime 0.108400   LR 0.001000   
2022-11-03 22:03:38,431 - INFO  - Training [31][  120/  391]   Loss 0.059291   Top1 97.962240   Top5 100.000000   BatchTime 0.102916   LR 0.001000   
2022-11-03 22:03:40,446 - INFO  - Training [31][  140/  391]   Loss 0.058083   Top1 97.991071   Top5 99.994420   BatchTime 0.102604   LR 0.001000   
2022-11-03 22:03:42,486 - INFO  - Training [31][  160/  391]   Loss 0.058583   Top1 97.978516   Top5 99.995117   BatchTime 0.102526   LR 0.001000   
2022-11-03 22:03:44,492 - INFO  - Training [31][  180/  391]   Loss 0.058966   Top1 97.977431   Top5 99.995660   BatchTime 0.102279   LR 0.001000   
2022-11-03 22:03:46,509 - INFO  - Training [31][  200/  391]   Loss 0.058442   Top1 98.007812   Top5 99.996094   BatchTime 0.102139   LR 0.001000   
2022-11-03 22:03:48,507 - INFO  - Training [31][  220/  391]   Loss 0.057801   Top1 98.022017   Top5 99.996449   BatchTime 0.101933   LR 0.001000   
2022-11-03 22:03:50,493 - INFO  - Training [31][  240/  391]   Loss 0.057822   Top1 98.033854   Top5 99.996745   BatchTime 0.101716   LR 0.001000   
2022-11-03 22:03:52,481 - INFO  - Training [31][  260/  391]   Loss 0.057623   Top1 98.031851   Top5 99.996995   BatchTime 0.101537   LR 0.001000   
2022-11-03 22:03:54,487 - INFO  - Training [31][  280/  391]   Loss 0.057684   Top1 98.013393   Top5 99.997210   BatchTime 0.101448   LR 0.001000   
2022-11-03 22:03:56,480 - INFO  - Training [31][  300/  391]   Loss 0.058459   Top1 97.973958   Top5 99.997396   BatchTime 0.101326   LR 0.001000   
2022-11-03 22:03:58,475 - INFO  - Training [31][  320/  391]   Loss 0.058053   Top1 97.993164   Top5 99.997559   BatchTime 0.101230   LR 0.001000   
2022-11-03 22:04:00,463 - INFO  - Training [31][  340/  391]   Loss 0.057950   Top1 97.996324   Top5 99.997702   BatchTime 0.101121   LR 0.001000   
2022-11-03 22:04:02,428 - INFO  - Training [31][  360/  391]   Loss 0.058132   Top1 97.996962   Top5 99.997830   BatchTime 0.100961   LR 0.001000   
2022-11-03 22:04:04,417 - INFO  - Training [31][  380/  391]   Loss 0.058332   Top1 97.985197   Top5 99.997944   BatchTime 0.100882   LR 0.001000   
2022-11-03 22:04:05,727 - INFO  - ==> Top1: 98.002    Top5: 99.998    Loss: 0.058

2022-11-03 22:04:05,728 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:04:08,423 - INFO  - Validation [31][   20/   79]   Loss 0.380727   Top1 90.390625   Top5 99.492188   BatchTime 0.134644   
2022-11-03 22:04:09,327 - INFO  - Validation [31][   40/   79]   Loss 0.398054   Top1 90.097656   Top5 99.531250   BatchTime 0.089916   
2022-11-03 22:04:10,224 - INFO  - Validation [31][   60/   79]   Loss 0.384429   Top1 90.507812   Top5 99.570312   BatchTime 0.074897   
2022-11-03 22:04:11,353 - INFO  - ==> Top1: 90.430    Top5: 99.590    Loss: 0.378

2022-11-03 22:04:11,380 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.430   Top5: 99.590] Sparsity : 0.821
2022-11-03 22:04:11,380 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 90.190   Top5: 99.620] Sparsity : 0.821
2022-11-03 22:04:11,381 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.020   Top5: 99.680] Sparsity : 0.817
2022-11-03 22:04:11,564 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:04:11,565 - INFO  - >>>>>>>> Epoch  32
2022-11-03 22:04:11,566 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:04:15,359 - INFO  - Training [32][   20/  391]   Loss 0.067546   Top1 97.851562   Top5 100.000000   BatchTime 0.189665   LR 0.001000   
2022-11-03 22:04:17,146 - INFO  - Training [32][   40/  391]   Loss 0.062556   Top1 98.046875   Top5 100.000000   BatchTime 0.139519   LR 0.001000   
2022-11-03 22:04:18,828 - INFO  - Training [32][   60/  391]   Loss 0.059221   Top1 98.072917   Top5 100.000000   BatchTime 0.121042   LR 0.001000   
2022-11-03 22:04:20,505 - INFO  - Training [32][   80/  391]   Loss 0.059205   Top1 97.998047   Top5 100.000000   BatchTime 0.111743   LR 0.001000   
2022-11-03 22:04:22,326 - INFO  - Training [32][  100/  391]   Loss 0.060453   Top1 97.921875   Top5 99.992188   BatchTime 0.107602   LR 0.001000   
2022-11-03 22:04:23,957 - INFO  - Training [32][  120/  391]   Loss 0.059201   Top1 97.936198   Top5 99.986979   BatchTime 0.103256   LR 0.001000   
2022-11-03 22:04:25,988 - INFO  - Training [32][  140/  391]   Loss 0.057950   Top1 97.985491   Top5 99.988839   BatchTime 0.103015   LR 0.001000   
2022-11-03 22:04:28,003 - INFO  - Training [32][  160/  391]   Loss 0.057598   Top1 98.012695   Top5 99.990234   BatchTime 0.102729   LR 0.001000   
2022-11-03 22:04:30,015 - INFO  - Training [32][  180/  391]   Loss 0.056374   Top1 98.077257   Top5 99.986979   BatchTime 0.102496   LR 0.001000   
2022-11-03 22:04:32,022 - INFO  - Training [32][  200/  391]   Loss 0.056558   Top1 98.093750   Top5 99.988281   BatchTime 0.102279   LR 0.001000   
2022-11-03 22:04:34,034 - INFO  - Training [32][  220/  391]   Loss 0.057168   Top1 98.061080   Top5 99.985795   BatchTime 0.102125   LR 0.001000   
2022-11-03 22:04:36,035 - INFO  - Training [32][  240/  391]   Loss 0.056413   Top1 98.063151   Top5 99.986979   BatchTime 0.101955   LR 0.001000   
2022-11-03 22:04:38,044 - INFO  - Training [32][  260/  391]   Loss 0.056572   Top1 98.073918   Top5 99.987981   BatchTime 0.101837   LR 0.001000   
2022-11-03 22:04:40,048 - INFO  - Training [32][  280/  391]   Loss 0.056320   Top1 98.088728   Top5 99.986049   BatchTime 0.101719   LR 0.001000   
2022-11-03 22:04:42,054 - INFO  - Training [32][  300/  391]   Loss 0.055860   Top1 98.101562   Top5 99.986979   BatchTime 0.101625   LR 0.001000   
2022-11-03 22:04:44,057 - INFO  - Training [32][  320/  391]   Loss 0.055478   Top1 98.117676   Top5 99.987793   BatchTime 0.101533   LR 0.001000   
2022-11-03 22:04:46,044 - INFO  - Training [32][  340/  391]   Loss 0.055683   Top1 98.108915   Top5 99.988511   BatchTime 0.101404   LR 0.001000   
2022-11-03 22:04:47,991 - INFO  - Training [32][  360/  391]   Loss 0.055835   Top1 98.109809   Top5 99.986979   BatchTime 0.101180   LR 0.001000   
2022-11-03 22:04:49,968 - INFO  - Training [32][  380/  391]   Loss 0.055867   Top1 98.100329   Top5 99.987664   BatchTime 0.101055   LR 0.001000   
2022-11-03 22:04:51,312 - INFO  - ==> Top1: 98.110    Top5: 99.988    Loss: 0.056

2022-11-03 22:04:51,313 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:04:53,986 - INFO  - Validation [32][   20/   79]   Loss 0.375197   Top1 90.507812   Top5 99.687500   BatchTime 0.133555   
2022-11-03 22:04:54,879 - INFO  - Validation [32][   40/   79]   Loss 0.400934   Top1 89.902344   Top5 99.628906   BatchTime 0.089111   
2022-11-03 22:04:55,789 - INFO  - Validation [32][   60/   79]   Loss 0.385591   Top1 90.390625   Top5 99.687500   BatchTime 0.074565   
2022-11-03 22:04:56,917 - INFO  - ==> Top1: 90.300    Top5: 99.710    Loss: 0.380

2022-11-03 22:04:56,963 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 90.430   Top5: 99.590] Sparsity : 0.821
2022-11-03 22:04:56,963 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 90.300   Top5: 99.710] Sparsity : 0.821
2022-11-03 22:04:56,963 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 90.190   Top5: 99.620] Sparsity : 0.821
2022-11-03 22:04:57,156 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:04:57,156 - INFO  - >>>>>>>> Epoch  33
2022-11-03 22:04:57,157 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:05:00,959 - INFO  - Training [33][   20/  391]   Loss 0.052934   Top1 98.242188   Top5 100.000000   BatchTime 0.190045   LR 0.001000   
2022-11-03 22:05:02,688 - INFO  - Training [33][   40/  391]   Loss 0.052651   Top1 98.222656   Top5 100.000000   BatchTime 0.138264   LR 0.001000   
2022-11-03 22:05:04,395 - INFO  - Training [33][   60/  391]   Loss 0.048437   Top1 98.359375   Top5 100.000000   BatchTime 0.120620   LR 0.001000   
2022-11-03 22:05:06,012 - INFO  - Training [33][   80/  391]   Loss 0.048997   Top1 98.349609   Top5 100.000000   BatchTime 0.110672   LR 0.001000   
2022-11-03 22:05:07,751 - INFO  - Training [33][  100/  391]   Loss 0.049848   Top1 98.296875   Top5 100.000000   BatchTime 0.105933   LR 0.001000   
2022-11-03 22:05:09,443 - INFO  - Training [33][  120/  391]   Loss 0.050989   Top1 98.235677   Top5 100.000000   BatchTime 0.102377   LR 0.001000   
2022-11-03 22:05:11,440 - INFO  - Training [33][  140/  391]   Loss 0.051565   Top1 98.208705   Top5 100.000000   BatchTime 0.102016   LR 0.001000   
2022-11-03 22:05:13,448 - INFO  - Training [33][  160/  391]   Loss 0.052926   Top1 98.183594   Top5 100.000000   BatchTime 0.101814   LR 0.001000   
2022-11-03 22:05:15,440 - INFO  - Training [33][  180/  391]   Loss 0.053580   Top1 98.155382   Top5 100.000000   BatchTime 0.101569   LR 0.001000   
2022-11-03 22:05:17,468 - INFO  - Training [33][  200/  391]   Loss 0.053407   Top1 98.164062   Top5 100.000000   BatchTime 0.101549   LR 0.001000   
2022-11-03 22:05:19,492 - INFO  - Training [33][  220/  391]   Loss 0.052719   Top1 98.203125   Top5 100.000000   BatchTime 0.101519   LR 0.001000   
2022-11-03 22:05:21,508 - INFO  - Training [33][  240/  391]   Loss 0.052454   Top1 98.219401   Top5 100.000000   BatchTime 0.101458   LR 0.001000   
2022-11-03 22:05:23,502 - INFO  - Training [33][  260/  391]   Loss 0.052125   Top1 98.227163   Top5 100.000000   BatchTime 0.101324   LR 0.001000   
2022-11-03 22:05:25,522 - INFO  - Training [33][  280/  391]   Loss 0.052995   Top1 98.189174   Top5 100.000000   BatchTime 0.101300   LR 0.001000   
2022-11-03 22:05:27,517 - INFO  - Training [33][  300/  391]   Loss 0.052915   Top1 98.190104   Top5 100.000000   BatchTime 0.101197   LR 0.001000   
2022-11-03 22:05:29,529 - INFO  - Training [33][  320/  391]   Loss 0.052835   Top1 98.200684   Top5 100.000000   BatchTime 0.101159   LR 0.001000   
2022-11-03 22:05:31,508 - INFO  - Training [33][  340/  391]   Loss 0.053410   Top1 98.175551   Top5 99.997702   BatchTime 0.101028   LR 0.001000   
2022-11-03 22:05:33,486 - INFO  - Training [33][  360/  391]   Loss 0.053423   Top1 98.166233   Top5 99.997830   BatchTime 0.100910   LR 0.001000   
2022-11-03 22:05:35,478 - INFO  - Training [33][  380/  391]   Loss 0.053783   Top1 98.168174   Top5 99.995888   BatchTime 0.100840   LR 0.001000   
2022-11-03 22:05:36,781 - INFO  - ==> Top1: 98.166    Top5: 99.996    Loss: 0.054

2022-11-03 22:05:36,781 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:05:39,433 - INFO  - Validation [33][   20/   79]   Loss 0.370926   Top1 90.429688   Top5 99.453125   BatchTime 0.132532   
2022-11-03 22:05:40,295 - INFO  - Validation [33][   40/   79]   Loss 0.389367   Top1 90.156250   Top5 99.492188   BatchTime 0.087818   
2022-11-03 22:05:41,186 - INFO  - Validation [33][   60/   79]   Loss 0.378339   Top1 90.546875   Top5 99.557292   BatchTime 0.073397   
2022-11-03 22:05:42,275 - INFO  - ==> Top1: 90.510    Top5: 99.610    Loss: 0.373

2022-11-03 22:05:42,306 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 90.510   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:05:42,307 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 90.430   Top5: 99.590] Sparsity : 0.821
2022-11-03 22:05:42,307 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 90.300   Top5: 99.710] Sparsity : 0.821
2022-11-03 22:05:42,472 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:05:42,472 - INFO  - >>>>>>>> Epoch  34
2022-11-03 22:05:42,474 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:05:46,248 - INFO  - Training [34][   20/  391]   Loss 0.054986   Top1 98.125000   Top5 100.000000   BatchTime 0.188711   LR 0.001000   
2022-11-03 22:05:48,027 - INFO  - Training [34][   40/  391]   Loss 0.055030   Top1 98.007812   Top5 100.000000   BatchTime 0.138829   LR 0.001000   
2022-11-03 22:05:49,724 - INFO  - Training [34][   60/  391]   Loss 0.053186   Top1 98.190104   Top5 100.000000   BatchTime 0.120842   LR 0.001000   
2022-11-03 22:05:51,401 - INFO  - Training [34][   80/  391]   Loss 0.052796   Top1 98.144531   Top5 100.000000   BatchTime 0.111587   LR 0.001000   
2022-11-03 22:05:53,183 - INFO  - Training [34][  100/  391]   Loss 0.050181   Top1 98.226562   Top5 100.000000   BatchTime 0.107093   LR 0.001000   
2022-11-03 22:05:54,931 - INFO  - Training [34][  120/  391]   Loss 0.049739   Top1 98.268229   Top5 100.000000   BatchTime 0.103807   LR 0.001000   
2022-11-03 22:05:56,961 - INFO  - Training [34][  140/  391]   Loss 0.050340   Top1 98.231027   Top5 100.000000   BatchTime 0.103476   LR 0.001000   
2022-11-03 22:05:58,973 - INFO  - Training [34][  160/  391]   Loss 0.050389   Top1 98.212891   Top5 100.000000   BatchTime 0.103116   LR 0.001000   
2022-11-03 22:06:00,977 - INFO  - Training [34][  180/  391]   Loss 0.049615   Top1 98.220486   Top5 100.000000   BatchTime 0.102791   LR 0.001000   
2022-11-03 22:06:03,006 - INFO  - Training [34][  200/  391]   Loss 0.050696   Top1 98.191406   Top5 100.000000   BatchTime 0.102658   LR 0.001000   
2022-11-03 22:06:05,024 - INFO  - Training [34][  220/  391]   Loss 0.050573   Top1 98.203125   Top5 100.000000   BatchTime 0.102497   LR 0.001000   
2022-11-03 22:06:07,053 - INFO  - Training [34][  240/  391]   Loss 0.050224   Top1 98.212891   Top5 100.000000   BatchTime 0.102410   LR 0.001000   
2022-11-03 22:06:09,055 - INFO  - Training [34][  260/  391]   Loss 0.050742   Top1 98.191106   Top5 99.996995   BatchTime 0.102233   LR 0.001000   
2022-11-03 22:06:11,052 - INFO  - Training [34][  280/  391]   Loss 0.051126   Top1 98.175223   Top5 99.997210   BatchTime 0.102064   LR 0.001000   
2022-11-03 22:06:13,048 - INFO  - Training [34][  300/  391]   Loss 0.051326   Top1 98.190104   Top5 99.997396   BatchTime 0.101911   LR 0.001000   
2022-11-03 22:06:15,061 - INFO  - Training [34][  320/  391]   Loss 0.052147   Top1 98.171387   Top5 99.997559   BatchTime 0.101834   LR 0.001000   
2022-11-03 22:06:17,037 - INFO  - Training [34][  340/  391]   Loss 0.051974   Top1 98.182445   Top5 99.997702   BatchTime 0.101655   LR 0.001000   
2022-11-03 22:06:19,008 - INFO  - Training [34][  360/  391]   Loss 0.051677   Top1 98.194444   Top5 99.997830   BatchTime 0.101481   LR 0.001000   
2022-11-03 22:06:20,994 - INFO  - Training [34][  380/  391]   Loss 0.051401   Top1 98.196957   Top5 99.997944   BatchTime 0.101366   LR 0.001000   
2022-11-03 22:06:22,332 - INFO  - ==> Top1: 98.194    Top5: 99.998    Loss: 0.051

2022-11-03 22:06:22,333 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:06:24,989 - INFO  - Validation [34][   20/   79]   Loss 0.371901   Top1 90.039062   Top5 99.648438   BatchTime 0.132767   
2022-11-03 22:06:25,851 - INFO  - Validation [34][   40/   79]   Loss 0.392119   Top1 90.078125   Top5 99.550781   BatchTime 0.087916   
2022-11-03 22:06:26,741 - INFO  - Validation [34][   60/   79]   Loss 0.380825   Top1 90.520833   Top5 99.622396   BatchTime 0.073450   
2022-11-03 22:06:27,857 - INFO  - ==> Top1: 90.580    Top5: 99.630    Loss: 0.375

2022-11-03 22:06:27,889 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:06:27,890 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.510   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:06:27,890 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.430   Top5: 99.590] Sparsity : 0.821
2022-11-03 22:06:28,074 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:06:28,074 - INFO  - >>>>>>>> Epoch  35
2022-11-03 22:06:28,075 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:06:31,867 - INFO  - Training [35][   20/  391]   Loss 0.042687   Top1 98.476562   Top5 100.000000   BatchTime 0.189567   LR 0.001000   
2022-11-03 22:06:33,692 - INFO  - Training [35][   40/  391]   Loss 0.044447   Top1 98.437500   Top5 100.000000   BatchTime 0.140416   LR 0.001000   
2022-11-03 22:06:35,400 - INFO  - Training [35][   60/  391]   Loss 0.043256   Top1 98.515625   Top5 100.000000   BatchTime 0.122079   LR 0.001000   
2022-11-03 22:06:37,065 - INFO  - Training [35][   80/  391]   Loss 0.044602   Top1 98.398438   Top5 100.000000   BatchTime 0.112363   LR 0.001000   
2022-11-03 22:06:38,736 - INFO  - Training [35][  100/  391]   Loss 0.045831   Top1 98.406250   Top5 100.000000   BatchTime 0.106607   LR 0.001000   
2022-11-03 22:06:40,551 - INFO  - Training [35][  120/  391]   Loss 0.047511   Top1 98.326823   Top5 100.000000   BatchTime 0.103958   LR 0.001000   
2022-11-03 22:06:42,583 - INFO  - Training [35][  140/  391]   Loss 0.047381   Top1 98.348214   Top5 100.000000   BatchTime 0.103623   LR 0.001000   
2022-11-03 22:06:44,605 - INFO  - Training [35][  160/  391]   Loss 0.046419   Top1 98.393555   Top5 100.000000   BatchTime 0.103310   LR 0.001000   
2022-11-03 22:06:46,613 - INFO  - Training [35][  180/  391]   Loss 0.046950   Top1 98.372396   Top5 100.000000   BatchTime 0.102983   LR 0.001000   
2022-11-03 22:06:48,607 - INFO  - Training [35][  200/  391]   Loss 0.046469   Top1 98.410156   Top5 100.000000   BatchTime 0.102657   LR 0.001000   
2022-11-03 22:06:50,625 - INFO  - Training [35][  220/  391]   Loss 0.046414   Top1 98.412642   Top5 100.000000   BatchTime 0.102498   LR 0.001000   
2022-11-03 22:06:52,648 - INFO  - Training [35][  240/  391]   Loss 0.046596   Top1 98.421224   Top5 100.000000   BatchTime 0.102385   LR 0.001000   
2022-11-03 22:06:54,656 - INFO  - Training [35][  260/  391]   Loss 0.046353   Top1 98.416466   Top5 100.000000   BatchTime 0.102231   LR 0.001000   
2022-11-03 22:06:56,665 - INFO  - Training [35][  280/  391]   Loss 0.046739   Top1 98.387277   Top5 100.000000   BatchTime 0.102104   LR 0.001000   
2022-11-03 22:06:58,662 - INFO  - Training [35][  300/  391]   Loss 0.046818   Top1 98.380208   Top5 100.000000   BatchTime 0.101952   LR 0.001000   
2022-11-03 22:07:00,679 - INFO  - Training [35][  320/  391]   Loss 0.047198   Top1 98.354492   Top5 100.000000   BatchTime 0.101884   LR 0.001000   
2022-11-03 22:07:02,681 - INFO  - Training [35][  340/  391]   Loss 0.047088   Top1 98.354779   Top5 100.000000   BatchTime 0.101778   LR 0.001000   
2022-11-03 22:07:04,673 - INFO  - Training [35][  360/  391]   Loss 0.047463   Top1 98.342014   Top5 100.000000   BatchTime 0.101659   LR 0.001000   
2022-11-03 22:07:06,666 - INFO  - Training [35][  380/  391]   Loss 0.047515   Top1 98.340872   Top5 100.000000   BatchTime 0.101553   LR 0.001000   
2022-11-03 22:07:08,008 - INFO  - ==> Top1: 98.334    Top5: 100.000    Loss: 0.048

2022-11-03 22:07:08,009 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:07:10,701 - INFO  - Validation [35][   20/   79]   Loss 0.376769   Top1 89.726562   Top5 99.570312   BatchTime 0.134504   
2022-11-03 22:07:11,584 - INFO  - Validation [35][   40/   79]   Loss 0.395966   Top1 89.707031   Top5 99.531250   BatchTime 0.089341   
2022-11-03 22:07:12,407 - INFO  - Validation [35][   60/   79]   Loss 0.383606   Top1 90.338542   Top5 99.609375   BatchTime 0.073273   
2022-11-03 22:07:13,502 - INFO  - ==> Top1: 90.340    Top5: 99.630    Loss: 0.378

2022-11-03 22:07:13,545 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:07:13,546 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.510   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:07:13,546 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 90.430   Top5: 99.590] Sparsity : 0.821
2022-11-03 22:07:13,648 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:07:13,648 - INFO  - >>>>>>>> Epoch  36
2022-11-03 22:07:13,650 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:07:17,413 - INFO  - Training [36][   20/  391]   Loss 0.052581   Top1 98.085938   Top5 100.000000   BatchTime 0.188172   LR 0.001000   
2022-11-03 22:07:19,154 - INFO  - Training [36][   40/  391]   Loss 0.047445   Top1 98.261719   Top5 100.000000   BatchTime 0.137612   LR 0.001000   
2022-11-03 22:07:20,874 - INFO  - Training [36][   60/  391]   Loss 0.044615   Top1 98.476562   Top5 100.000000   BatchTime 0.120403   LR 0.001000   
2022-11-03 22:07:22,519 - INFO  - Training [36][   80/  391]   Loss 0.045223   Top1 98.496094   Top5 100.000000   BatchTime 0.110861   LR 0.001000   
2022-11-03 22:07:24,263 - INFO  - Training [36][  100/  391]   Loss 0.044960   Top1 98.492188   Top5 100.000000   BatchTime 0.106131   LR 0.001000   
2022-11-03 22:07:26,095 - INFO  - Training [36][  120/  391]   Loss 0.045083   Top1 98.483073   Top5 100.000000   BatchTime 0.103708   LR 0.001000   
2022-11-03 22:07:28,112 - INFO  - Training [36][  140/  391]   Loss 0.046457   Top1 98.392857   Top5 100.000000   BatchTime 0.103298   LR 0.001000   
2022-11-03 22:07:30,117 - INFO  - Training [36][  160/  391]   Loss 0.046078   Top1 98.422852   Top5 100.000000   BatchTime 0.102921   LR 0.001000   
2022-11-03 22:07:32,132 - INFO  - Training [36][  180/  391]   Loss 0.046291   Top1 98.433160   Top5 100.000000   BatchTime 0.102679   LR 0.001000   
2022-11-03 22:07:34,144 - INFO  - Training [36][  200/  391]   Loss 0.046952   Top1 98.406250   Top5 100.000000   BatchTime 0.102468   LR 0.001000   
2022-11-03 22:07:36,163 - INFO  - Training [36][  220/  391]   Loss 0.046816   Top1 98.405540   Top5 100.000000   BatchTime 0.102330   LR 0.001000   
2022-11-03 22:07:38,187 - INFO  - Training [36][  240/  391]   Loss 0.046844   Top1 98.398438   Top5 100.000000   BatchTime 0.102236   LR 0.001000   
2022-11-03 22:07:40,203 - INFO  - Training [36][  260/  391]   Loss 0.047263   Top1 98.380409   Top5 100.000000   BatchTime 0.102126   LR 0.001000   
2022-11-03 22:07:42,227 - INFO  - Training [36][  280/  391]   Loss 0.047248   Top1 98.378906   Top5 100.000000   BatchTime 0.102060   LR 0.001000   
2022-11-03 22:07:44,247 - INFO  - Training [36][  300/  391]   Loss 0.047364   Top1 98.364583   Top5 100.000000   BatchTime 0.101989   LR 0.001000   
2022-11-03 22:07:46,292 - INFO  - Training [36][  320/  391]   Loss 0.047227   Top1 98.369141   Top5 100.000000   BatchTime 0.102006   LR 0.001000   
2022-11-03 22:07:48,286 - INFO  - Training [36][  340/  391]   Loss 0.047179   Top1 98.370864   Top5 100.000000   BatchTime 0.101870   LR 0.001000   
2022-11-03 22:07:50,256 - INFO  - Training [36][  360/  391]   Loss 0.047097   Top1 98.372396   Top5 100.000000   BatchTime 0.101683   LR 0.001000   
2022-11-03 22:07:52,223 - INFO  - Training [36][  380/  391]   Loss 0.047219   Top1 98.371711   Top5 100.000000   BatchTime 0.101507   LR 0.001000   
2022-11-03 22:07:53,564 - INFO  - ==> Top1: 98.378    Top5: 100.000    Loss: 0.047

2022-11-03 22:07:53,565 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:07:56,243 - INFO  - Validation [36][   20/   79]   Loss 0.383145   Top1 90.390625   Top5 99.492188   BatchTime 0.133816   
2022-11-03 22:07:57,131 - INFO  - Validation [36][   40/   79]   Loss 0.401300   Top1 90.273438   Top5 99.550781   BatchTime 0.089112   
2022-11-03 22:07:57,999 - INFO  - Validation [36][   60/   79]   Loss 0.392794   Top1 90.507812   Top5 99.570312   BatchTime 0.073871   
2022-11-03 22:07:59,086 - INFO  - ==> Top1: 90.480    Top5: 99.600    Loss: 0.387

2022-11-03 22:07:59,126 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:07:59,126 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 90.510   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:07:59,126 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 90.480   Top5: 99.600] Sparsity : 0.821
2022-11-03 22:07:59,223 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:07:59,223 - INFO  - >>>>>>>> Epoch  37
2022-11-03 22:07:59,224 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:08:03,029 - INFO  - Training [37][   20/  391]   Loss 0.051508   Top1 98.320312   Top5 100.000000   BatchTime 0.190219   LR 0.001000   
2022-11-03 22:08:04,637 - INFO  - Training [37][   40/  391]   Loss 0.048971   Top1 98.398438   Top5 99.980469   BatchTime 0.135307   LR 0.001000   
2022-11-03 22:08:06,365 - INFO  - Training [37][   60/  391]   Loss 0.048286   Top1 98.333333   Top5 99.986979   BatchTime 0.119002   LR 0.001000   
2022-11-03 22:08:08,039 - INFO  - Training [37][   80/  391]   Loss 0.047068   Top1 98.427734   Top5 99.990234   BatchTime 0.110179   LR 0.001000   
2022-11-03 22:08:09,875 - INFO  - Training [37][  100/  391]   Loss 0.046465   Top1 98.437500   Top5 99.992188   BatchTime 0.106504   LR 0.001000   
2022-11-03 22:08:11,699 - INFO  - Training [37][  120/  391]   Loss 0.046849   Top1 98.430990   Top5 99.993490   BatchTime 0.103954   LR 0.001000   
2022-11-03 22:08:13,725 - INFO  - Training [37][  140/  391]   Loss 0.046412   Top1 98.470982   Top5 99.994420   BatchTime 0.103570   LR 0.001000   
2022-11-03 22:08:15,745 - INFO  - Training [37][  160/  391]   Loss 0.047122   Top1 98.447266   Top5 99.995117   BatchTime 0.103250   LR 0.001000   
2022-11-03 22:08:17,764 - INFO  - Training [37][  180/  391]   Loss 0.047464   Top1 98.433160   Top5 99.995660   BatchTime 0.102996   LR 0.001000   
2022-11-03 22:08:19,776 - INFO  - Training [37][  200/  391]   Loss 0.047101   Top1 98.441406   Top5 99.996094   BatchTime 0.102755   LR 0.001000   
2022-11-03 22:08:21,795 - INFO  - Training [37][  220/  391]   Loss 0.046961   Top1 98.448153   Top5 99.996449   BatchTime 0.102590   LR 0.001000   
2022-11-03 22:08:23,817 - INFO  - Training [37][  240/  391]   Loss 0.047796   Top1 98.414714   Top5 99.996745   BatchTime 0.102467   LR 0.001000   
2022-11-03 22:08:25,829 - INFO  - Training [37][  260/  391]   Loss 0.048358   Top1 98.389423   Top5 99.993990   BatchTime 0.102320   LR 0.001000   
2022-11-03 22:08:27,844 - INFO  - Training [37][  280/  391]   Loss 0.048413   Top1 98.384487   Top5 99.994420   BatchTime 0.102211   LR 0.001000   
2022-11-03 22:08:29,845 - INFO  - Training [37][  300/  391]   Loss 0.048812   Top1 98.367188   Top5 99.994792   BatchTime 0.102067   LR 0.001000   
2022-11-03 22:08:31,853 - INFO  - Training [37][  320/  391]   Loss 0.048885   Top1 98.376465   Top5 99.992676   BatchTime 0.101962   LR 0.001000   
2022-11-03 22:08:33,834 - INFO  - Training [37][  340/  391]   Loss 0.048758   Top1 98.370864   Top5 99.993107   BatchTime 0.101789   LR 0.001000   
2022-11-03 22:08:35,811 - INFO  - Training [37][  360/  391]   Loss 0.048348   Top1 98.383247   Top5 99.993490   BatchTime 0.101628   LR 0.001000   
2022-11-03 22:08:37,778 - INFO  - Training [37][  380/  391]   Loss 0.048616   Top1 98.367599   Top5 99.993832   BatchTime 0.101453   LR 0.001000   
2022-11-03 22:08:39,103 - INFO  - ==> Top1: 98.372    Top5: 99.994    Loss: 0.049

2022-11-03 22:08:39,104 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:08:41,765 - INFO  - Validation [37][   20/   79]   Loss 0.380302   Top1 90.351562   Top5 99.570312   BatchTime 0.132966   
2022-11-03 22:08:42,665 - INFO  - Validation [37][   40/   79]   Loss 0.395408   Top1 90.195312   Top5 99.570312   BatchTime 0.088994   
2022-11-03 22:08:43,561 - INFO  - Validation [37][   60/   79]   Loss 0.384626   Top1 90.755208   Top5 99.596354   BatchTime 0.074257   
2022-11-03 22:08:44,665 - INFO  - ==> Top1: 90.720    Top5: 99.610    Loss: 0.379

2022-11-03 22:08:44,711 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:08:44,711 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:08:44,711 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 90.510   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:08:44,888 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:08:44,888 - INFO  - >>>>>>>> Epoch  38
2022-11-03 22:08:44,889 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:08:48,771 - INFO  - Training [38][   20/  391]   Loss 0.037211   Top1 98.945312   Top5 100.000000   BatchTime 0.194049   LR 0.001000   
2022-11-03 22:08:50,300 - INFO  - Training [38][   40/  391]   Loss 0.040877   Top1 98.691406   Top5 100.000000   BatchTime 0.135260   LR 0.001000   
2022-11-03 22:08:52,007 - INFO  - Training [38][   60/  391]   Loss 0.040658   Top1 98.671875   Top5 100.000000   BatchTime 0.118623   LR 0.001000   
2022-11-03 22:08:53,653 - INFO  - Training [38][   80/  391]   Loss 0.042698   Top1 98.613281   Top5 100.000000   BatchTime 0.109546   LR 0.001000   
2022-11-03 22:08:55,304 - INFO  - Training [38][  100/  391]   Loss 0.043555   Top1 98.593750   Top5 100.000000   BatchTime 0.104139   LR 0.001000   
2022-11-03 22:08:57,045 - INFO  - Training [38][  120/  391]   Loss 0.043946   Top1 98.561198   Top5 100.000000   BatchTime 0.101294   LR 0.001000   
2022-11-03 22:08:59,059 - INFO  - Training [38][  140/  391]   Loss 0.045682   Top1 98.482143   Top5 100.000000   BatchTime 0.101209   LR 0.001000   
2022-11-03 22:09:01,078 - INFO  - Training [38][  160/  391]   Loss 0.046083   Top1 98.466797   Top5 100.000000   BatchTime 0.101172   LR 0.001000   
2022-11-03 22:09:03,090 - INFO  - Training [38][  180/  391]   Loss 0.045361   Top1 98.506944   Top5 100.000000   BatchTime 0.101109   LR 0.001000   
2022-11-03 22:09:05,091 - INFO  - Training [38][  200/  391]   Loss 0.045139   Top1 98.523438   Top5 100.000000   BatchTime 0.101006   LR 0.001000   
2022-11-03 22:09:07,101 - INFO  - Training [38][  220/  391]   Loss 0.045049   Top1 98.533381   Top5 100.000000   BatchTime 0.100957   LR 0.001000   
2022-11-03 22:09:09,098 - INFO  - Training [38][  240/  391]   Loss 0.044367   Top1 98.567708   Top5 100.000000   BatchTime 0.100865   LR 0.001000   
2022-11-03 22:09:11,104 - INFO  - Training [38][  260/  391]   Loss 0.044356   Top1 98.551683   Top5 100.000000   BatchTime 0.100823   LR 0.001000   
2022-11-03 22:09:13,105 - INFO  - Training [38][  280/  391]   Loss 0.044366   Top1 98.535156   Top5 100.000000   BatchTime 0.100767   LR 0.001000   
2022-11-03 22:09:15,116 - INFO  - Training [38][  300/  391]   Loss 0.044710   Top1 98.492188   Top5 100.000000   BatchTime 0.100752   LR 0.001000   
2022-11-03 22:09:17,143 - INFO  - Training [38][  320/  391]   Loss 0.044852   Top1 98.481445   Top5 99.997559   BatchTime 0.100789   LR 0.001000   
2022-11-03 22:09:19,133 - INFO  - Training [38][  340/  391]   Loss 0.045148   Top1 98.455882   Top5 99.997702   BatchTime 0.100714   LR 0.001000   
2022-11-03 22:09:21,113 - INFO  - Training [38][  360/  391]   Loss 0.045030   Top1 98.452691   Top5 99.997830   BatchTime 0.100618   LR 0.001000   
2022-11-03 22:09:23,099 - INFO  - Training [38][  380/  391]   Loss 0.045595   Top1 98.443668   Top5 99.997944   BatchTime 0.100548   LR 0.001000   
2022-11-03 22:09:24,427 - INFO  - ==> Top1: 98.446    Top5: 99.998    Loss: 0.045

2022-11-03 22:09:24,428 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:09:27,101 - INFO  - Validation [38][   20/   79]   Loss 0.377933   Top1 90.585938   Top5 99.648438   BatchTime 0.133586   
2022-11-03 22:09:28,019 - INFO  - Validation [38][   40/   79]   Loss 0.396458   Top1 90.292969   Top5 99.589844   BatchTime 0.089724   
2022-11-03 22:09:28,937 - INFO  - Validation [38][   60/   79]   Loss 0.384799   Top1 90.664062   Top5 99.622396   BatchTime 0.075125   
2022-11-03 22:09:30,054 - INFO  - ==> Top1: 90.590    Top5: 99.630    Loss: 0.381

2022-11-03 22:09:30,095 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:09:30,096 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.590   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:09:30,096 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:09:30,200 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:09:30,200 - INFO  - >>>>>>>> Epoch  39
2022-11-03 22:09:30,201 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:09:34,102 - INFO  - Training [39][   20/  391]   Loss 0.042844   Top1 98.671875   Top5 99.960938   BatchTime 0.195019   LR 0.001000   
2022-11-03 22:09:35,670 - INFO  - Training [39][   40/  391]   Loss 0.046754   Top1 98.476562   Top5 99.980469   BatchTime 0.136723   LR 0.001000   
2022-11-03 22:09:37,431 - INFO  - Training [39][   60/  391]   Loss 0.044872   Top1 98.528646   Top5 99.986979   BatchTime 0.120497   LR 0.001000   
2022-11-03 22:09:39,033 - INFO  - Training [39][   80/  391]   Loss 0.046072   Top1 98.486328   Top5 99.990234   BatchTime 0.110393   LR 0.001000   
2022-11-03 22:09:40,700 - INFO  - Training [39][  100/  391]   Loss 0.047140   Top1 98.421875   Top5 99.992188   BatchTime 0.104988   LR 0.001000   
2022-11-03 22:09:42,515 - INFO  - Training [39][  120/  391]   Loss 0.047319   Top1 98.411458   Top5 99.993490   BatchTime 0.102614   LR 0.001000   
2022-11-03 22:09:44,654 - INFO  - Training [39][  140/  391]   Loss 0.047252   Top1 98.398438   Top5 99.994420   BatchTime 0.103233   LR 0.001000   
2022-11-03 22:09:46,679 - INFO  - Training [39][  160/  391]   Loss 0.046468   Top1 98.432617   Top5 99.995117   BatchTime 0.102985   LR 0.001000   
2022-11-03 22:09:48,705 - INFO  - Training [39][  180/  391]   Loss 0.046580   Top1 98.402778   Top5 99.995660   BatchTime 0.102798   LR 0.001000   
2022-11-03 22:09:50,701 - INFO  - Training [39][  200/  391]   Loss 0.045842   Top1 98.421875   Top5 99.996094   BatchTime 0.102497   LR 0.001000   
2022-11-03 22:09:52,698 - INFO  - Training [39][  220/  391]   Loss 0.046431   Top1 98.380682   Top5 99.996449   BatchTime 0.102256   LR 0.001000   
2022-11-03 22:09:54,698 - INFO  - Training [39][  240/  391]   Loss 0.046779   Top1 98.382161   Top5 99.996745   BatchTime 0.102066   LR 0.001000   
2022-11-03 22:09:56,694 - INFO  - Training [39][  260/  391]   Loss 0.047705   Top1 98.359375   Top5 99.996995   BatchTime 0.101891   LR 0.001000   
2022-11-03 22:09:58,690 - INFO  - Training [39][  280/  391]   Loss 0.048226   Top1 98.342634   Top5 99.997210   BatchTime 0.101744   LR 0.001000   
2022-11-03 22:10:00,692 - INFO  - Training [39][  300/  391]   Loss 0.047801   Top1 98.372396   Top5 99.997396   BatchTime 0.101634   LR 0.001000   
2022-11-03 22:10:02,679 - INFO  - Training [39][  320/  391]   Loss 0.047503   Top1 98.395996   Top5 99.997559   BatchTime 0.101489   LR 0.001000   
2022-11-03 22:10:04,667 - INFO  - Training [39][  340/  391]   Loss 0.047546   Top1 98.400735   Top5 99.997702   BatchTime 0.101366   LR 0.001000   
2022-11-03 22:10:06,617 - INFO  - Training [39][  360/  391]   Loss 0.047667   Top1 98.385417   Top5 99.997830   BatchTime 0.101153   LR 0.001000   
2022-11-03 22:10:08,608 - INFO  - Training [39][  380/  391]   Loss 0.047497   Top1 98.377878   Top5 99.995888   BatchTime 0.101067   LR 0.001000   
2022-11-03 22:10:09,954 - INFO  - ==> Top1: 98.390    Top5: 99.996    Loss: 0.047

2022-11-03 22:10:09,955 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:10:12,646 - INFO  - Validation [39][   20/   79]   Loss 0.382152   Top1 90.390625   Top5 99.531250   BatchTime 0.134461   
2022-11-03 22:10:13,536 - INFO  - Validation [39][   40/   79]   Loss 0.395575   Top1 90.234375   Top5 99.511719   BatchTime 0.089497   
2022-11-03 22:10:14,428 - INFO  - Validation [39][   60/   79]   Loss 0.384808   Top1 90.416667   Top5 99.557292   BatchTime 0.074519   
2022-11-03 22:10:15,534 - INFO  - ==> Top1: 90.470    Top5: 99.590    Loss: 0.380

2022-11-03 22:10:15,566 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:10:15,567 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.590   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:10:15,567 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:10:15,663 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:10:15,663 - INFO  - >>>>>>>> Epoch  40
2022-11-03 22:10:15,664 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:10:19,419 - INFO  - Training [40][   20/  391]   Loss 0.046158   Top1 98.398438   Top5 100.000000   BatchTime 0.187711   LR 0.001000   
2022-11-03 22:10:20,989 - INFO  - Training [40][   40/  391]   Loss 0.044314   Top1 98.496094   Top5 100.000000   BatchTime 0.133096   LR 0.001000   
2022-11-03 22:10:22,689 - INFO  - Training [40][   60/  391]   Loss 0.045406   Top1 98.541667   Top5 100.000000   BatchTime 0.117074   LR 0.001000   
2022-11-03 22:10:24,334 - INFO  - Training [40][   80/  391]   Loss 0.048137   Top1 98.417969   Top5 100.000000   BatchTime 0.108359   LR 0.001000   
2022-11-03 22:10:25,959 - INFO  - Training [40][  100/  391]   Loss 0.049599   Top1 98.398438   Top5 100.000000   BatchTime 0.102940   LR 0.001000   
2022-11-03 22:10:27,714 - INFO  - Training [40][  120/  391]   Loss 0.047165   Top1 98.476562   Top5 100.000000   BatchTime 0.100405   LR 0.001000   
2022-11-03 22:10:29,702 - INFO  - Training [40][  140/  391]   Loss 0.046009   Top1 98.515625   Top5 100.000000   BatchTime 0.100267   LR 0.001000   
2022-11-03 22:10:31,682 - INFO  - Training [40][  160/  391]   Loss 0.046313   Top1 98.505859   Top5 100.000000   BatchTime 0.100104   LR 0.001000   
2022-11-03 22:10:33,682 - INFO  - Training [40][  180/  391]   Loss 0.046152   Top1 98.493924   Top5 99.995660   BatchTime 0.100095   LR 0.001000   
2022-11-03 22:10:35,685 - INFO  - Training [40][  200/  391]   Loss 0.046084   Top1 98.496094   Top5 99.992188   BatchTime 0.100098   LR 0.001000   
2022-11-03 22:10:37,681 - INFO  - Training [40][  220/  391]   Loss 0.045959   Top1 98.480114   Top5 99.992898   BatchTime 0.100072   LR 0.001000   
2022-11-03 22:10:39,689 - INFO  - Training [40][  240/  391]   Loss 0.046035   Top1 98.466797   Top5 99.993490   BatchTime 0.100099   LR 0.001000   
2022-11-03 22:10:41,684 - INFO  - Training [40][  260/  391]   Loss 0.046088   Top1 98.479567   Top5 99.993990   BatchTime 0.100070   LR 0.001000   
2022-11-03 22:10:43,685 - INFO  - Training [40][  280/  391]   Loss 0.046130   Top1 98.479353   Top5 99.994420   BatchTime 0.100071   LR 0.001000   
2022-11-03 22:10:45,681 - INFO  - Training [40][  300/  391]   Loss 0.046329   Top1 98.468750   Top5 99.992188   BatchTime 0.100051   LR 0.001000   
2022-11-03 22:10:47,676 - INFO  - Training [40][  320/  391]   Loss 0.046514   Top1 98.459473   Top5 99.992676   BatchTime 0.100033   LR 0.001000   
2022-11-03 22:10:49,663 - INFO  - Training [40][  340/  391]   Loss 0.046366   Top1 98.455882   Top5 99.993107   BatchTime 0.099993   LR 0.001000   
2022-11-03 22:10:51,630 - INFO  - Training [40][  360/  391]   Loss 0.046518   Top1 98.446181   Top5 99.993490   BatchTime 0.099902   LR 0.001000   
2022-11-03 22:10:53,608 - INFO  - Training [40][  380/  391]   Loss 0.046223   Top1 98.451891   Top5 99.993832   BatchTime 0.099849   LR 0.001000   
2022-11-03 22:10:54,922 - INFO  - ==> Top1: 98.460    Top5: 99.994    Loss: 0.046

2022-11-03 22:10:54,923 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:10:57,606 - INFO  - Validation [40][   20/   79]   Loss 0.383890   Top1 90.156250   Top5 99.531250   BatchTime 0.134084   
2022-11-03 22:10:58,496 - INFO  - Validation [40][   40/   79]   Loss 0.396805   Top1 90.195312   Top5 99.531250   BatchTime 0.089279   
2022-11-03 22:10:59,395 - INFO  - Validation [40][   60/   79]   Loss 0.388636   Top1 90.481771   Top5 99.570312   BatchTime 0.074507   
2022-11-03 22:11:00,516 - INFO  - ==> Top1: 90.530    Top5: 99.600    Loss: 0.383

2022-11-03 22:11:00,563 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:11:00,564 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 90.590   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:11:00,564 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 90.580   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:11:00,663 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:11:00,663 - INFO  - >>>>>>>> Epoch  41
2022-11-03 22:11:00,665 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:11:04,496 - INFO  - Training [41][   20/  391]   Loss 0.044370   Top1 98.437500   Top5 100.000000   BatchTime 0.191569   LR 0.001000   
2022-11-03 22:11:05,995 - INFO  - Training [41][   40/  391]   Loss 0.043573   Top1 98.457031   Top5 100.000000   BatchTime 0.133243   LR 0.001000   
2022-11-03 22:11:07,741 - INFO  - Training [41][   60/  391]   Loss 0.046736   Top1 98.307292   Top5 100.000000   BatchTime 0.117930   LR 0.001000   
2022-11-03 22:11:09,379 - INFO  - Training [41][   80/  391]   Loss 0.045691   Top1 98.339844   Top5 100.000000   BatchTime 0.108922   LR 0.001000   
2022-11-03 22:11:11,046 - INFO  - Training [41][  100/  391]   Loss 0.048667   Top1 98.171875   Top5 100.000000   BatchTime 0.103810   LR 0.001000   
2022-11-03 22:11:12,820 - INFO  - Training [41][  120/  391]   Loss 0.047878   Top1 98.248698   Top5 100.000000   BatchTime 0.101291   LR 0.001000   
2022-11-03 22:11:14,841 - INFO  - Training [41][  140/  391]   Loss 0.046775   Top1 98.292411   Top5 100.000000   BatchTime 0.101258   LR 0.001000   
2022-11-03 22:11:16,863 - INFO  - Training [41][  160/  391]   Loss 0.046656   Top1 98.300781   Top5 100.000000   BatchTime 0.101237   LR 0.001000   
2022-11-03 22:11:18,880 - INFO  - Training [41][  180/  391]   Loss 0.046698   Top1 98.333333   Top5 100.000000   BatchTime 0.101192   LR 0.001000   
2022-11-03 22:11:21,000 - INFO  - Training [41][  200/  391]   Loss 0.046441   Top1 98.351562   Top5 100.000000   BatchTime 0.101675   LR 0.001000   
2022-11-03 22:11:22,988 - INFO  - Training [41][  220/  391]   Loss 0.047879   Top1 98.309659   Top5 100.000000   BatchTime 0.101465   LR 0.001000   
2022-11-03 22:11:25,001 - INFO  - Training [41][  240/  391]   Loss 0.047781   Top1 98.317057   Top5 100.000000   BatchTime 0.101398   LR 0.001000   
2022-11-03 22:11:27,021 - INFO  - Training [41][  260/  391]   Loss 0.047122   Top1 98.338341   Top5 100.000000   BatchTime 0.101369   LR 0.001000   
2022-11-03 22:11:29,012 - INFO  - Training [41][  280/  391]   Loss 0.046343   Top1 98.378906   Top5 100.000000   BatchTime 0.101238   LR 0.001000   
2022-11-03 22:11:31,045 - INFO  - Training [41][  300/  391]   Loss 0.045955   Top1 98.395833   Top5 100.000000   BatchTime 0.101263   LR 0.001000   
2022-11-03 22:11:33,078 - INFO  - Training [41][  320/  391]   Loss 0.045749   Top1 98.413086   Top5 100.000000   BatchTime 0.101288   LR 0.001000   
2022-11-03 22:11:35,060 - INFO  - Training [41][  340/  391]   Loss 0.045207   Top1 98.442096   Top5 100.000000   BatchTime 0.101161   LR 0.001000   
2022-11-03 22:11:37,049 - INFO  - Training [41][  360/  391]   Loss 0.045038   Top1 98.452691   Top5 100.000000   BatchTime 0.101064   LR 0.001000   
2022-11-03 22:11:39,028 - INFO  - Training [41][  380/  391]   Loss 0.044959   Top1 98.449836   Top5 100.000000   BatchTime 0.100952   LR 0.001000   
2022-11-03 22:11:40,351 - INFO  - ==> Top1: 98.452    Top5: 100.000    Loss: 0.045

2022-11-03 22:11:40,352 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:11:43,059 - INFO  - Validation [41][   20/   79]   Loss 0.384028   Top1 90.546875   Top5 99.765625   BatchTime 0.135254   
2022-11-03 22:11:43,921 - INFO  - Validation [41][   40/   79]   Loss 0.398743   Top1 90.488281   Top5 99.648438   BatchTime 0.089173   
2022-11-03 22:11:44,816 - INFO  - Validation [41][   60/   79]   Loss 0.386798   Top1 90.885417   Top5 99.674479   BatchTime 0.074377   
2022-11-03 22:11:45,934 - INFO  - ==> Top1: 90.800    Top5: 99.690    Loss: 0.380

2022-11-03 22:11:45,966 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:11:45,967 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:11:45,967 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 90.590   Top5: 99.630] Sparsity : 0.821
2022-11-03 22:11:46,163 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:11:46,164 - INFO  - >>>>>>>> Epoch  42
2022-11-03 22:11:46,165 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:11:50,027 - INFO  - Training [42][   20/  391]   Loss 0.041442   Top1 98.476562   Top5 100.000000   BatchTime 0.193120   LR 0.001000   
2022-11-03 22:11:51,602 - INFO  - Training [42][   40/  391]   Loss 0.037128   Top1 98.769531   Top5 100.000000   BatchTime 0.135921   LR 0.001000   
2022-11-03 22:11:53,372 - INFO  - Training [42][   60/  391]   Loss 0.042449   Top1 98.554688   Top5 100.000000   BatchTime 0.120123   LR 0.001000   
2022-11-03 22:11:55,024 - INFO  - Training [42][   80/  391]   Loss 0.043862   Top1 98.457031   Top5 100.000000   BatchTime 0.110735   LR 0.001000   
2022-11-03 22:11:56,759 - INFO  - Training [42][  100/  391]   Loss 0.043605   Top1 98.515625   Top5 100.000000   BatchTime 0.105940   LR 0.001000   
2022-11-03 22:11:58,623 - INFO  - Training [42][  120/  391]   Loss 0.043384   Top1 98.515625   Top5 100.000000   BatchTime 0.103815   LR 0.001000   
2022-11-03 22:12:00,606 - INFO  - Training [42][  140/  391]   Loss 0.042360   Top1 98.532366   Top5 100.000000   BatchTime 0.103150   LR 0.001000   
2022-11-03 22:12:02,605 - INFO  - Training [42][  160/  391]   Loss 0.043026   Top1 98.515625   Top5 100.000000   BatchTime 0.102748   LR 0.001000   
2022-11-03 22:12:04,612 - INFO  - Training [42][  180/  391]   Loss 0.043110   Top1 98.532986   Top5 100.000000   BatchTime 0.102480   LR 0.001000   
2022-11-03 22:12:06,608 - INFO  - Training [42][  200/  391]   Loss 0.043682   Top1 98.507812   Top5 100.000000   BatchTime 0.102215   LR 0.001000   
2022-11-03 22:12:08,608 - INFO  - Training [42][  220/  391]   Loss 0.043492   Top1 98.483665   Top5 100.000000   BatchTime 0.102013   LR 0.001000   
2022-11-03 22:12:10,602 - INFO  - Training [42][  240/  391]   Loss 0.043629   Top1 98.470052   Top5 100.000000   BatchTime 0.101820   LR 0.001000   
2022-11-03 22:12:12,615 - INFO  - Training [42][  260/  391]   Loss 0.043565   Top1 98.491587   Top5 100.000000   BatchTime 0.101730   LR 0.001000   
2022-11-03 22:12:14,615 - INFO  - Training [42][  280/  391]   Loss 0.043058   Top1 98.504464   Top5 100.000000   BatchTime 0.101606   LR 0.001000   
2022-11-03 22:12:16,620 - INFO  - Training [42][  300/  391]   Loss 0.043986   Top1 98.466146   Top5 100.000000   BatchTime 0.101516   LR 0.001000   
2022-11-03 22:12:18,639 - INFO  - Training [42][  320/  391]   Loss 0.044029   Top1 98.461914   Top5 100.000000   BatchTime 0.101479   LR 0.001000   
2022-11-03 22:12:20,623 - INFO  - Training [42][  340/  391]   Loss 0.043590   Top1 98.488051   Top5 100.000000   BatchTime 0.101345   LR 0.001000   
2022-11-03 22:12:22,589 - INFO  - Training [42][  360/  391]   Loss 0.043658   Top1 98.476562   Top5 100.000000   BatchTime 0.101176   LR 0.001000   
2022-11-03 22:12:24,589 - INFO  - Training [42][  380/  391]   Loss 0.043850   Top1 98.482730   Top5 100.000000   BatchTime 0.101113   LR 0.001000   
2022-11-03 22:12:25,940 - INFO  - ==> Top1: 98.470    Top5: 100.000    Loss: 0.044

2022-11-03 22:12:25,941 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:12:28,599 - INFO  - Validation [42][   20/   79]   Loss 0.385991   Top1 90.429688   Top5 99.570312   BatchTime 0.132805   
2022-11-03 22:12:29,493 - INFO  - Validation [42][   40/   79]   Loss 0.396966   Top1 90.449219   Top5 99.511719   BatchTime 0.088757   
2022-11-03 22:12:30,397 - INFO  - Validation [42][   60/   79]   Loss 0.383798   Top1 90.833333   Top5 99.596354   BatchTime 0.074246   
2022-11-03 22:12:31,507 - INFO  - ==> Top1: 90.680    Top5: 99.610    Loss: 0.378

2022-11-03 22:12:31,545 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:12:31,546 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:12:31,546 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.680   Top5: 99.610] Sparsity : 0.822
2022-11-03 22:12:31,653 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:12:31,654 - INFO  - >>>>>>>> Epoch  43
2022-11-03 22:12:31,655 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:12:35,423 - INFO  - Training [43][   20/  391]   Loss 0.052582   Top1 98.164062   Top5 100.000000   BatchTime 0.188398   LR 0.001000   
2022-11-03 22:12:36,995 - INFO  - Training [43][   40/  391]   Loss 0.047030   Top1 98.320312   Top5 100.000000   BatchTime 0.133495   LR 0.001000   
2022-11-03 22:12:38,657 - INFO  - Training [43][   60/  391]   Loss 0.046017   Top1 98.424479   Top5 100.000000   BatchTime 0.116699   LR 0.001000   
2022-11-03 22:12:40,304 - INFO  - Training [43][   80/  391]   Loss 0.044977   Top1 98.476562   Top5 100.000000   BatchTime 0.108108   LR 0.001000   
2022-11-03 22:12:41,959 - INFO  - Training [43][  100/  391]   Loss 0.046036   Top1 98.421875   Top5 100.000000   BatchTime 0.103037   LR 0.001000   
2022-11-03 22:12:43,853 - INFO  - Training [43][  120/  391]   Loss 0.045415   Top1 98.437500   Top5 100.000000   BatchTime 0.101642   LR 0.001000   
2022-11-03 22:12:45,863 - INFO  - Training [43][  140/  391]   Loss 0.044535   Top1 98.465402   Top5 100.000000   BatchTime 0.101485   LR 0.001000   
2022-11-03 22:12:47,873 - INFO  - Training [43][  160/  391]   Loss 0.044193   Top1 98.461914   Top5 100.000000   BatchTime 0.101362   LR 0.001000   
2022-11-03 22:12:49,887 - INFO  - Training [43][  180/  391]   Loss 0.043468   Top1 98.498264   Top5 100.000000   BatchTime 0.101284   LR 0.001000   
2022-11-03 22:12:51,888 - INFO  - Training [43][  200/  391]   Loss 0.043739   Top1 98.453125   Top5 100.000000   BatchTime 0.101160   LR 0.001000   
2022-11-03 22:12:53,894 - INFO  - Training [43][  220/  391]   Loss 0.043415   Top1 98.465909   Top5 100.000000   BatchTime 0.101085   LR 0.001000   
2022-11-03 22:12:55,984 - INFO  - Training [43][  240/  391]   Loss 0.044077   Top1 98.470052   Top5 100.000000   BatchTime 0.101368   LR 0.001000   
2022-11-03 22:12:57,983 - INFO  - Training [43][  260/  391]   Loss 0.044201   Top1 98.479567   Top5 100.000000   BatchTime 0.101258   LR 0.001000   
2022-11-03 22:12:59,983 - INFO  - Training [43][  280/  391]   Loss 0.044052   Top1 98.504464   Top5 100.000000   BatchTime 0.101168   LR 0.001000   
2022-11-03 22:13:01,992 - INFO  - Training [43][  300/  391]   Loss 0.043839   Top1 98.510417   Top5 99.997396   BatchTime 0.101119   LR 0.001000   
2022-11-03 22:13:03,978 - INFO  - Training [43][  320/  391]   Loss 0.044202   Top1 98.513184   Top5 99.997559   BatchTime 0.101007   LR 0.001000   
2022-11-03 22:13:05,959 - INFO  - Training [43][  340/  391]   Loss 0.044040   Top1 98.517923   Top5 99.997702   BatchTime 0.100890   LR 0.001000   
2022-11-03 22:13:07,919 - INFO  - Training [43][  360/  391]   Loss 0.044070   Top1 98.522135   Top5 99.997830   BatchTime 0.100731   LR 0.001000   
2022-11-03 22:13:09,894 - INFO  - Training [43][  380/  391]   Loss 0.044002   Top1 98.519737   Top5 99.997944   BatchTime 0.100626   LR 0.001000   
2022-11-03 22:13:11,225 - INFO  - ==> Top1: 98.506    Top5: 99.998    Loss: 0.044

2022-11-03 22:13:11,226 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:13:13,879 - INFO  - Validation [43][   20/   79]   Loss 0.390187   Top1 90.234375   Top5 99.687500   BatchTime 0.132578   
2022-11-03 22:13:14,754 - INFO  - Validation [43][   40/   79]   Loss 0.399368   Top1 90.488281   Top5 99.609375   BatchTime 0.088154   
2022-11-03 22:13:15,673 - INFO  - Validation [43][   60/   79]   Loss 0.390454   Top1 90.859375   Top5 99.635417   BatchTime 0.074093   
2022-11-03 22:13:16,797 - INFO  - ==> Top1: 90.830    Top5: 99.650    Loss: 0.387

2022-11-03 22:13:16,826 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:13:16,827 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:13:16,827 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:13:17,012 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:13:17,013 - INFO  - >>>>>>>> Epoch  44
2022-11-03 22:13:17,013 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:13:20,792 - INFO  - Training [44][   20/  391]   Loss 0.042850   Top1 98.632812   Top5 100.000000   BatchTime 0.188927   LR 0.001000   
2022-11-03 22:13:22,396 - INFO  - Training [44][   40/  391]   Loss 0.043139   Top1 98.535156   Top5 100.000000   BatchTime 0.134548   LR 0.001000   
2022-11-03 22:13:24,074 - INFO  - Training [44][   60/  391]   Loss 0.045458   Top1 98.476562   Top5 100.000000   BatchTime 0.117668   LR 0.001000   
2022-11-03 22:13:25,841 - INFO  - Training [44][   80/  391]   Loss 0.046163   Top1 98.515625   Top5 100.000000   BatchTime 0.110336   LR 0.001000   
2022-11-03 22:13:27,374 - INFO  - Training [44][  100/  391]   Loss 0.045823   Top1 98.515625   Top5 100.000000   BatchTime 0.103603   LR 0.001000   
2022-11-03 22:13:29,359 - INFO  - Training [44][  120/  391]   Loss 0.045828   Top1 98.502604   Top5 100.000000   BatchTime 0.102875   LR 0.001000   
2022-11-03 22:13:31,372 - INFO  - Training [44][  140/  391]   Loss 0.044541   Top1 98.588170   Top5 100.000000   BatchTime 0.102560   LR 0.001000   
2022-11-03 22:13:33,373 - INFO  - Training [44][  160/  391]   Loss 0.044328   Top1 98.583984   Top5 100.000000   BatchTime 0.102245   LR 0.001000   
2022-11-03 22:13:35,389 - INFO  - Training [44][  180/  391]   Loss 0.044850   Top1 98.541667   Top5 100.000000   BatchTime 0.102081   LR 0.001000   
2022-11-03 22:13:37,370 - INFO  - Training [44][  200/  391]   Loss 0.044503   Top1 98.542969   Top5 99.996094   BatchTime 0.101782   LR 0.001000   
2022-11-03 22:13:39,367 - INFO  - Training [44][  220/  391]   Loss 0.044034   Top1 98.568892   Top5 99.996449   BatchTime 0.101605   LR 0.001000   
2022-11-03 22:13:41,363 - INFO  - Training [44][  240/  391]   Loss 0.043490   Top1 98.574219   Top5 99.996745   BatchTime 0.101453   LR 0.001000   
2022-11-03 22:13:43,364 - INFO  - Training [44][  260/  391]   Loss 0.043287   Top1 98.554688   Top5 99.996995   BatchTime 0.101346   LR 0.001000   
2022-11-03 22:13:45,373 - INFO  - Training [44][  280/  391]   Loss 0.043299   Top1 98.546317   Top5 99.997210   BatchTime 0.101282   LR 0.001000   
2022-11-03 22:13:47,359 - INFO  - Training [44][  300/  391]   Loss 0.042913   Top1 98.552083   Top5 99.997396   BatchTime 0.101149   LR 0.001000   
2022-11-03 22:13:49,351 - INFO  - Training [44][  320/  391]   Loss 0.043007   Top1 98.549805   Top5 99.997559   BatchTime 0.101052   LR 0.001000   
2022-11-03 22:13:51,339 - INFO  - Training [44][  340/  391]   Loss 0.043363   Top1 98.536305   Top5 99.997702   BatchTime 0.100954   LR 0.001000   
2022-11-03 22:13:53,329 - INFO  - Training [44][  360/  391]   Loss 0.043319   Top1 98.546007   Top5 99.997830   BatchTime 0.100875   LR 0.001000   
2022-11-03 22:13:55,301 - INFO  - Training [44][  380/  391]   Loss 0.043541   Top1 98.536184   Top5 99.997944   BatchTime 0.100754   LR 0.001000   
2022-11-03 22:13:56,632 - INFO  - ==> Top1: 98.534    Top5: 99.998    Loss: 0.043

2022-11-03 22:13:56,633 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:13:59,339 - INFO  - Validation [44][   20/   79]   Loss 0.393709   Top1 90.585938   Top5 99.531250   BatchTime 0.135239   
2022-11-03 22:14:00,249 - INFO  - Validation [44][   40/   79]   Loss 0.400284   Top1 90.488281   Top5 99.550781   BatchTime 0.090376   
2022-11-03 22:14:01,142 - INFO  - Validation [44][   60/   79]   Loss 0.390644   Top1 90.729167   Top5 99.583333   BatchTime 0.075124   
2022-11-03 22:14:02,249 - INFO  - ==> Top1: 90.640    Top5: 99.620    Loss: 0.389

2022-11-03 22:14:02,284 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:14:02,284 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:14:02,284 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:14:02,379 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:14:02,379 - INFO  - >>>>>>>> Epoch  45
2022-11-03 22:14:02,381 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:14:06,051 - INFO  - Training [45][   20/  391]   Loss 0.041161   Top1 98.593750   Top5 99.960938   BatchTime 0.183510   LR 0.001000   
2022-11-03 22:14:07,721 - INFO  - Training [45][   40/  391]   Loss 0.043071   Top1 98.515625   Top5 99.980469   BatchTime 0.133503   LR 0.001000   
2022-11-03 22:14:09,378 - INFO  - Training [45][   60/  391]   Loss 0.039501   Top1 98.593750   Top5 99.986979   BatchTime 0.116625   LR 0.001000   
2022-11-03 22:14:11,182 - INFO  - Training [45][   80/  391]   Loss 0.039808   Top1 98.583984   Top5 99.990234   BatchTime 0.110010   LR 0.001000   
2022-11-03 22:14:12,823 - INFO  - Training [45][  100/  391]   Loss 0.041293   Top1 98.554688   Top5 99.992188   BatchTime 0.104416   LR 0.001000   
2022-11-03 22:14:14,859 - INFO  - Training [45][  120/  391]   Loss 0.040002   Top1 98.626302   Top5 99.993490   BatchTime 0.103980   LR 0.001000   
2022-11-03 22:14:16,897 - INFO  - Training [45][  140/  391]   Loss 0.041078   Top1 98.532366   Top5 99.994420   BatchTime 0.103687   LR 0.001000   
2022-11-03 22:14:18,896 - INFO  - Training [45][  160/  391]   Loss 0.041219   Top1 98.520508   Top5 99.995117   BatchTime 0.103215   LR 0.001000   
2022-11-03 22:14:20,903 - INFO  - Training [45][  180/  391]   Loss 0.041248   Top1 98.559028   Top5 99.995660   BatchTime 0.102901   LR 0.001000   
2022-11-03 22:14:22,915 - INFO  - Training [45][  200/  391]   Loss 0.041930   Top1 98.527344   Top5 99.996094   BatchTime 0.102666   LR 0.001000   
2022-11-03 22:14:24,905 - INFO  - Training [45][  220/  391]   Loss 0.041586   Top1 98.544034   Top5 99.996449   BatchTime 0.102379   LR 0.001000   
2022-11-03 22:14:26,918 - INFO  - Training [45][  240/  391]   Loss 0.041895   Top1 98.561198   Top5 99.996745   BatchTime 0.102234   LR 0.001000   
2022-11-03 22:14:28,949 - INFO  - Training [45][  260/  391]   Loss 0.042194   Top1 98.539663   Top5 99.996995   BatchTime 0.102182   LR 0.001000   
2022-11-03 22:14:30,966 - INFO  - Training [45][  280/  391]   Loss 0.042389   Top1 98.529576   Top5 99.997210   BatchTime 0.102087   LR 0.001000   
2022-11-03 22:14:32,985 - INFO  - Training [45][  300/  391]   Loss 0.042587   Top1 98.505208   Top5 99.997396   BatchTime 0.102012   LR 0.001000   
2022-11-03 22:14:35,144 - INFO  - Training [45][  320/  391]   Loss 0.042895   Top1 98.500977   Top5 99.997559   BatchTime 0.102383   LR 0.001000   
2022-11-03 22:14:37,134 - INFO  - Training [45][  340/  391]   Loss 0.042539   Top1 98.522518   Top5 99.997702   BatchTime 0.102213   LR 0.001000   
2022-11-03 22:14:39,109 - INFO  - Training [45][  360/  391]   Loss 0.042987   Top1 98.519965   Top5 99.997830   BatchTime 0.102021   LR 0.001000   
2022-11-03 22:14:41,085 - INFO  - Training [45][  380/  391]   Loss 0.043126   Top1 98.517681   Top5 99.997944   BatchTime 0.101850   LR 0.001000   
2022-11-03 22:14:42,429 - INFO  - ==> Top1: 98.512    Top5: 99.998    Loss: 0.043

2022-11-03 22:14:42,430 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:14:45,101 - INFO  - Validation [45][   20/   79]   Loss 0.396994   Top1 90.078125   Top5 99.648438   BatchTime 0.133520   
2022-11-03 22:14:45,991 - INFO  - Validation [45][   40/   79]   Loss 0.404725   Top1 90.234375   Top5 99.550781   BatchTime 0.088999   
2022-11-03 22:14:46,887 - INFO  - Validation [45][   60/   79]   Loss 0.397105   Top1 90.468750   Top5 99.557292   BatchTime 0.074264   
2022-11-03 22:14:47,991 - INFO  - ==> Top1: 90.370    Top5: 99.610    Loss: 0.392

2022-11-03 22:14:48,032 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:14:48,033 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:14:48,033 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:14:48,129 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:14:48,129 - INFO  - >>>>>>>> Epoch  46
2022-11-03 22:14:48,131 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:14:51,731 - INFO  - Training [46][   20/  391]   Loss 0.032780   Top1 98.867188   Top5 100.000000   BatchTime 0.180001   LR 0.001000   
2022-11-03 22:14:53,380 - INFO  - Training [46][   40/  391]   Loss 0.040812   Top1 98.496094   Top5 100.000000   BatchTime 0.131213   LR 0.001000   
2022-11-03 22:14:55,024 - INFO  - Training [46][   60/  391]   Loss 0.042692   Top1 98.528646   Top5 99.960938   BatchTime 0.114889   LR 0.001000   
2022-11-03 22:14:56,778 - INFO  - Training [46][   80/  391]   Loss 0.043550   Top1 98.447266   Top5 99.970703   BatchTime 0.108084   LR 0.001000   
2022-11-03 22:14:58,494 - INFO  - Training [46][  100/  391]   Loss 0.043578   Top1 98.492188   Top5 99.976562   BatchTime 0.103625   LR 0.001000   
2022-11-03 22:15:00,502 - INFO  - Training [46][  120/  391]   Loss 0.041736   Top1 98.587240   Top5 99.980469   BatchTime 0.103094   LR 0.001000   
2022-11-03 22:15:02,509 - INFO  - Training [46][  140/  391]   Loss 0.041550   Top1 98.577009   Top5 99.983259   BatchTime 0.102701   LR 0.001000   
2022-11-03 22:15:04,522 - INFO  - Training [46][  160/  391]   Loss 0.041455   Top1 98.583984   Top5 99.985352   BatchTime 0.102441   LR 0.001000   
2022-11-03 22:15:06,522 - INFO  - Training [46][  180/  391]   Loss 0.042075   Top1 98.537326   Top5 99.986979   BatchTime 0.102171   LR 0.001000   
2022-11-03 22:15:08,531 - INFO  - Training [46][  200/  391]   Loss 0.041371   Top1 98.574219   Top5 99.988281   BatchTime 0.101996   LR 0.001000   
2022-11-03 22:15:10,545 - INFO  - Training [46][  220/  391]   Loss 0.042110   Top1 98.554688   Top5 99.989347   BatchTime 0.101878   LR 0.001000   
2022-11-03 22:15:12,544 - INFO  - Training [46][  240/  391]   Loss 0.041502   Top1 98.557943   Top5 99.990234   BatchTime 0.101717   LR 0.001000   
2022-11-03 22:15:14,482 - INFO  - Training [46][  260/  391]   Loss 0.041134   Top1 98.560697   Top5 99.990986   BatchTime 0.101346   LR 0.001000   
2022-11-03 22:15:16,480 - INFO  - Training [46][  280/  391]   Loss 0.040490   Top1 98.585379   Top5 99.991629   BatchTime 0.101245   LR 0.001000   
2022-11-03 22:15:18,494 - INFO  - Training [46][  300/  391]   Loss 0.041453   Top1 98.546875   Top5 99.992188   BatchTime 0.101209   LR 0.001000   
2022-11-03 22:15:20,495 - INFO  - Training [46][  320/  391]   Loss 0.041958   Top1 98.527832   Top5 99.992676   BatchTime 0.101136   LR 0.001000   
2022-11-03 22:15:22,459 - INFO  - Training [46][  340/  391]   Loss 0.042126   Top1 98.520221   Top5 99.993107   BatchTime 0.100962   LR 0.001000   
2022-11-03 22:15:24,450 - INFO  - Training [46][  360/  391]   Loss 0.042074   Top1 98.517795   Top5 99.993490   BatchTime 0.100883   LR 0.001000   
2022-11-03 22:15:26,410 - INFO  - Training [46][  380/  391]   Loss 0.042634   Top1 98.499178   Top5 99.993832   BatchTime 0.100732   LR 0.001000   
2022-11-03 22:15:27,736 - INFO  - ==> Top1: 98.514    Top5: 99.994    Loss: 0.042

2022-11-03 22:15:27,737 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:15:30,413 - INFO  - Validation [46][   20/   79]   Loss 0.387900   Top1 90.234375   Top5 99.609375   BatchTime 0.133716   
2022-11-03 22:15:31,311 - INFO  - Validation [46][   40/   79]   Loss 0.401630   Top1 90.351562   Top5 99.531250   BatchTime 0.089321   
2022-11-03 22:15:32,230 - INFO  - Validation [46][   60/   79]   Loss 0.391622   Top1 90.677083   Top5 99.544271   BatchTime 0.074859   
2022-11-03 22:15:33,337 - INFO  - ==> Top1: 90.530    Top5: 99.580    Loss: 0.386

2022-11-03 22:15:33,372 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:15:33,373 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:15:33,373 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:15:33,475 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:15:33,475 - INFO  - >>>>>>>> Epoch  47
2022-11-03 22:15:33,477 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:15:37,060 - INFO  - Training [47][   20/  391]   Loss 0.033227   Top1 98.867188   Top5 100.000000   BatchTime 0.179128   LR 0.001000   
2022-11-03 22:15:38,793 - INFO  - Training [47][   40/  391]   Loss 0.035573   Top1 98.750000   Top5 100.000000   BatchTime 0.132906   LR 0.001000   
2022-11-03 22:15:40,453 - INFO  - Training [47][   60/  391]   Loss 0.036932   Top1 98.658854   Top5 100.000000   BatchTime 0.116261   LR 0.001000   
2022-11-03 22:15:42,161 - INFO  - Training [47][   80/  391]   Loss 0.039433   Top1 98.583984   Top5 100.000000   BatchTime 0.108540   LR 0.001000   
2022-11-03 22:15:43,855 - INFO  - Training [47][  100/  391]   Loss 0.039648   Top1 98.554688   Top5 100.000000   BatchTime 0.103779   LR 0.001000   
2022-11-03 22:15:45,873 - INFO  - Training [47][  120/  391]   Loss 0.040563   Top1 98.535156   Top5 100.000000   BatchTime 0.103299   LR 0.001000   
2022-11-03 22:15:47,896 - INFO  - Training [47][  140/  391]   Loss 0.040985   Top1 98.532366   Top5 100.000000   BatchTime 0.102987   LR 0.001000   
2022-11-03 22:15:49,910 - INFO  - Training [47][  160/  391]   Loss 0.041097   Top1 98.544922   Top5 100.000000   BatchTime 0.102701   LR 0.001000   
2022-11-03 22:15:51,932 - INFO  - Training [47][  180/  391]   Loss 0.039708   Top1 98.611111   Top5 100.000000   BatchTime 0.102523   LR 0.001000   
2022-11-03 22:15:53,942 - INFO  - Training [47][  200/  391]   Loss 0.040295   Top1 98.566406   Top5 100.000000   BatchTime 0.102321   LR 0.001000   
2022-11-03 22:15:55,956 - INFO  - Training [47][  220/  391]   Loss 0.040375   Top1 98.590199   Top5 100.000000   BatchTime 0.102175   LR 0.001000   
2022-11-03 22:15:57,982 - INFO  - Training [47][  240/  391]   Loss 0.040085   Top1 98.610026   Top5 100.000000   BatchTime 0.102103   LR 0.001000   
2022-11-03 22:15:59,986 - INFO  - Training [47][  260/  391]   Loss 0.040667   Top1 98.593750   Top5 100.000000   BatchTime 0.101954   LR 0.001000   
2022-11-03 22:16:01,985 - INFO  - Training [47][  280/  391]   Loss 0.040659   Top1 98.582589   Top5 100.000000   BatchTime 0.101812   LR 0.001000   
2022-11-03 22:16:03,990 - INFO  - Training [47][  300/  391]   Loss 0.040798   Top1 98.580729   Top5 100.000000   BatchTime 0.101708   LR 0.001000   
2022-11-03 22:16:05,988 - INFO  - Training [47][  320/  391]   Loss 0.040824   Top1 98.579102   Top5 100.000000   BatchTime 0.101595   LR 0.001000   
2022-11-03 22:16:07,985 - INFO  - Training [47][  340/  391]   Loss 0.040840   Top1 98.573070   Top5 100.000000   BatchTime 0.101492   LR 0.001000   
2022-11-03 22:16:09,967 - INFO  - Training [47][  360/  391]   Loss 0.041038   Top1 98.546007   Top5 100.000000   BatchTime 0.101358   LR 0.001000   
2022-11-03 22:16:12,021 - INFO  - Training [47][  380/  391]   Loss 0.041305   Top1 98.550576   Top5 99.997944   BatchTime 0.101428   LR 0.001000   
2022-11-03 22:16:13,356 - INFO  - ==> Top1: 98.546    Top5: 99.998    Loss: 0.042

2022-11-03 22:16:13,356 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:16:16,030 - INFO  - Validation [47][   20/   79]   Loss 0.394916   Top1 90.234375   Top5 99.570312   BatchTime 0.133607   
2022-11-03 22:16:16,939 - INFO  - Validation [47][   40/   79]   Loss 0.408562   Top1 90.234375   Top5 99.550781   BatchTime 0.089538   
2022-11-03 22:16:17,845 - INFO  - Validation [47][   60/   79]   Loss 0.395106   Top1 90.455729   Top5 99.583333   BatchTime 0.074792   
2022-11-03 22:16:18,923 - INFO  - ==> Top1: 90.480    Top5: 99.600    Loss: 0.391

2022-11-03 22:16:18,965 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:16:18,965 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:16:18,965 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:16:19,052 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:16:19,053 - INFO  - >>>>>>>> Epoch  48
2022-11-03 22:16:19,053 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:16:22,495 - INFO  - Training [48][   20/  391]   Loss 0.037295   Top1 98.906250   Top5 100.000000   BatchTime 0.172072   LR 0.001000   
2022-11-03 22:16:24,239 - INFO  - Training [48][   40/  391]   Loss 0.038275   Top1 98.808594   Top5 100.000000   BatchTime 0.129627   LR 0.001000   
2022-11-03 22:16:25,908 - INFO  - Training [48][   60/  391]   Loss 0.038119   Top1 98.815104   Top5 99.986979   BatchTime 0.114243   LR 0.001000   
2022-11-03 22:16:27,643 - INFO  - Training [48][   80/  391]   Loss 0.039648   Top1 98.740234   Top5 99.990234   BatchTime 0.107362   LR 0.001000   
2022-11-03 22:16:29,510 - INFO  - Training [48][  100/  391]   Loss 0.039470   Top1 98.750000   Top5 99.992188   BatchTime 0.104563   LR 0.001000   
2022-11-03 22:16:31,505 - INFO  - Training [48][  120/  391]   Loss 0.040675   Top1 98.652344   Top5 99.993490   BatchTime 0.103759   LR 0.001000   
2022-11-03 22:16:33,512 - INFO  - Training [48][  140/  391]   Loss 0.041142   Top1 98.638393   Top5 99.994420   BatchTime 0.103272   LR 0.001000   
2022-11-03 22:16:35,533 - INFO  - Training [48][  160/  391]   Loss 0.040672   Top1 98.662109   Top5 99.995117   BatchTime 0.102994   LR 0.001000   
2022-11-03 22:16:37,537 - INFO  - Training [48][  180/  391]   Loss 0.039973   Top1 98.684896   Top5 99.995660   BatchTime 0.102684   LR 0.001000   
2022-11-03 22:16:39,569 - INFO  - Training [48][  200/  391]   Loss 0.040133   Top1 98.667969   Top5 99.996094   BatchTime 0.102575   LR 0.001000   
2022-11-03 22:16:41,568 - INFO  - Training [48][  220/  391]   Loss 0.039855   Top1 98.671875   Top5 99.996449   BatchTime 0.102336   LR 0.001000   
2022-11-03 22:16:43,597 - INFO  - Training [48][  240/  391]   Loss 0.039364   Top1 98.697917   Top5 99.996745   BatchTime 0.102262   LR 0.001000   
2022-11-03 22:16:45,611 - INFO  - Training [48][  260/  391]   Loss 0.039337   Top1 98.704928   Top5 99.996995   BatchTime 0.102142   LR 0.001000   
2022-11-03 22:16:47,610 - INFO  - Training [48][  280/  391]   Loss 0.039279   Top1 98.696987   Top5 99.997210   BatchTime 0.101985   LR 0.001000   
2022-11-03 22:16:49,553 - INFO  - Training [48][  300/  391]   Loss 0.039200   Top1 98.690104   Top5 99.997396   BatchTime 0.101663   LR 0.001000   
2022-11-03 22:16:51,557 - INFO  - Training [48][  320/  391]   Loss 0.039254   Top1 98.701172   Top5 99.995117   BatchTime 0.101570   LR 0.001000   
2022-11-03 22:16:53,545 - INFO  - Training [48][  340/  391]   Loss 0.039121   Top1 98.710938   Top5 99.995404   BatchTime 0.101443   LR 0.001000   
2022-11-03 22:16:55,516 - INFO  - Training [48][  360/  391]   Loss 0.039422   Top1 98.713108   Top5 99.995660   BatchTime 0.101284   LR 0.001000   
2022-11-03 22:16:57,485 - INFO  - Training [48][  380/  391]   Loss 0.039625   Top1 98.690378   Top5 99.995888   BatchTime 0.101134   LR 0.001000   
2022-11-03 22:16:58,802 - INFO  - ==> Top1: 98.678    Top5: 99.996    Loss: 0.040

2022-11-03 22:16:58,803 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:17:01,480 - INFO  - Validation [48][   20/   79]   Loss 0.398170   Top1 89.921875   Top5 99.492188   BatchTime 0.133806   
2022-11-03 22:17:02,379 - INFO  - Validation [48][   40/   79]   Loss 0.406131   Top1 90.039062   Top5 99.511719   BatchTime 0.089372   
2022-11-03 22:17:03,262 - INFO  - Validation [48][   60/   79]   Loss 0.397509   Top1 90.481771   Top5 99.544271   BatchTime 0.074289   
2022-11-03 22:17:04,372 - INFO  - ==> Top1: 90.520    Top5: 99.600    Loss: 0.394

2022-11-03 22:17:04,416 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:17:04,417 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:17:04,417 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:17:04,564 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:17:04,564 - INFO  - >>>>>>>> Epoch  49
2022-11-03 22:17:04,565 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:17:08,032 - INFO  - Training [49][   20/  391]   Loss 0.046132   Top1 98.554688   Top5 100.000000   BatchTime 0.173300   LR 0.001000   
2022-11-03 22:17:09,742 - INFO  - Training [49][   40/  391]   Loss 0.043417   Top1 98.769531   Top5 100.000000   BatchTime 0.129405   LR 0.001000   
2022-11-03 22:17:11,386 - INFO  - Training [49][   60/  391]   Loss 0.044346   Top1 98.619792   Top5 100.000000   BatchTime 0.113667   LR 0.001000   
2022-11-03 22:17:13,077 - INFO  - Training [49][   80/  391]   Loss 0.043731   Top1 98.632812   Top5 100.000000   BatchTime 0.106385   LR 0.001000   
2022-11-03 22:17:14,836 - INFO  - Training [49][  100/  391]   Loss 0.042881   Top1 98.648438   Top5 100.000000   BatchTime 0.102700   LR 0.001000   
2022-11-03 22:17:16,855 - INFO  - Training [49][  120/  391]   Loss 0.044017   Top1 98.574219   Top5 100.000000   BatchTime 0.102410   LR 0.001000   
2022-11-03 22:17:18,870 - INFO  - Training [49][  140/  391]   Loss 0.043677   Top1 98.593750   Top5 100.000000   BatchTime 0.102173   LR 0.001000   
2022-11-03 22:17:20,885 - INFO  - Training [49][  160/  391]   Loss 0.044274   Top1 98.588867   Top5 100.000000   BatchTime 0.101996   LR 0.001000   
2022-11-03 22:17:22,895 - INFO  - Training [49][  180/  391]   Loss 0.043594   Top1 98.589410   Top5 100.000000   BatchTime 0.101827   LR 0.001000   
2022-11-03 22:17:24,916 - INFO  - Training [49][  200/  391]   Loss 0.043671   Top1 98.574219   Top5 100.000000   BatchTime 0.101750   LR 0.001000   
2022-11-03 22:17:26,920 - INFO  - Training [49][  220/  391]   Loss 0.044182   Top1 98.544034   Top5 100.000000   BatchTime 0.101608   LR 0.001000   
2022-11-03 22:17:28,910 - INFO  - Training [49][  240/  391]   Loss 0.043746   Top1 98.561198   Top5 100.000000   BatchTime 0.101434   LR 0.001000   
2022-11-03 22:17:30,907 - INFO  - Training [49][  260/  391]   Loss 0.043466   Top1 98.554688   Top5 100.000000   BatchTime 0.101311   LR 0.001000   
2022-11-03 22:17:32,916 - INFO  - Training [49][  280/  391]   Loss 0.043422   Top1 98.540737   Top5 100.000000   BatchTime 0.101248   LR 0.001000   
2022-11-03 22:17:34,913 - INFO  - Training [49][  300/  391]   Loss 0.042604   Top1 98.565104   Top5 100.000000   BatchTime 0.101157   LR 0.001000   
2022-11-03 22:17:36,936 - INFO  - Training [49][  320/  391]   Loss 0.042294   Top1 98.581543   Top5 100.000000   BatchTime 0.101155   LR 0.001000   
2022-11-03 22:17:38,913 - INFO  - Training [49][  340/  391]   Loss 0.042443   Top1 98.568474   Top5 100.000000   BatchTime 0.101018   LR 0.001000   
2022-11-03 22:17:40,901 - INFO  - Training [49][  360/  391]   Loss 0.042427   Top1 98.569878   Top5 100.000000   BatchTime 0.100929   LR 0.001000   
2022-11-03 22:17:42,904 - INFO  - Training [49][  380/  391]   Loss 0.042412   Top1 98.556743   Top5 100.000000   BatchTime 0.100887   LR 0.001000   
2022-11-03 22:17:44,215 - INFO  - ==> Top1: 98.566    Top5: 100.000    Loss: 0.042

2022-11-03 22:17:44,216 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:17:46,881 - INFO  - Validation [49][   20/   79]   Loss 0.399692   Top1 90.195312   Top5 99.570312   BatchTime 0.133206   
2022-11-03 22:17:47,776 - INFO  - Validation [49][   40/   79]   Loss 0.405962   Top1 90.156250   Top5 99.550781   BatchTime 0.088958   
2022-11-03 22:17:48,660 - INFO  - Validation [49][   60/   79]   Loss 0.395201   Top1 90.559896   Top5 99.583333   BatchTime 0.074044   
2022-11-03 22:17:49,771 - INFO  - ==> Top1: 90.500    Top5: 99.600    Loss: 0.391

2022-11-03 22:17:49,817 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:17:49,817 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:17:49,817 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:17:49,917 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:17:49,917 - INFO  - >>>>>>>> Epoch  50
2022-11-03 22:17:49,918 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:17:53,578 - INFO  - Training [50][   20/  391]   Loss 0.039625   Top1 98.320312   Top5 100.000000   BatchTime 0.183019   LR 0.001000   
2022-11-03 22:17:55,313 - INFO  - Training [50][   40/  391]   Loss 0.037966   Top1 98.613281   Top5 100.000000   BatchTime 0.134881   LR 0.001000   
2022-11-03 22:17:56,973 - INFO  - Training [50][   60/  391]   Loss 0.037931   Top1 98.684896   Top5 100.000000   BatchTime 0.117588   LR 0.001000   
2022-11-03 22:17:58,661 - INFO  - Training [50][   80/  391]   Loss 0.040071   Top1 98.583984   Top5 100.000000   BatchTime 0.109285   LR 0.001000   
2022-11-03 22:18:00,518 - INFO  - Training [50][  100/  391]   Loss 0.039014   Top1 98.648438   Top5 100.000000   BatchTime 0.105995   LR 0.001000   
2022-11-03 22:18:02,526 - INFO  - Training [50][  120/  391]   Loss 0.039683   Top1 98.606771   Top5 100.000000   BatchTime 0.105064   LR 0.001000   
2022-11-03 22:18:04,553 - INFO  - Training [50][  140/  391]   Loss 0.041560   Top1 98.515625   Top5 100.000000   BatchTime 0.104534   LR 0.001000   
2022-11-03 22:18:06,559 - INFO  - Training [50][  160/  391]   Loss 0.041943   Top1 98.486328   Top5 100.000000   BatchTime 0.104007   LR 0.001000   
2022-11-03 22:18:08,577 - INFO  - Training [50][  180/  391]   Loss 0.041608   Top1 98.502604   Top5 100.000000   BatchTime 0.103659   LR 0.001000   
2022-11-03 22:18:10,601 - INFO  - Training [50][  200/  391]   Loss 0.041766   Top1 98.496094   Top5 100.000000   BatchTime 0.103413   LR 0.001000   
2022-11-03 22:18:12,609 - INFO  - Training [50][  220/  391]   Loss 0.041467   Top1 98.490767   Top5 100.000000   BatchTime 0.103140   LR 0.001000   
2022-11-03 22:18:14,625 - INFO  - Training [50][  240/  391]   Loss 0.041604   Top1 98.496094   Top5 100.000000   BatchTime 0.102945   LR 0.001000   
2022-11-03 22:18:16,644 - INFO  - Training [50][  260/  391]   Loss 0.042408   Top1 98.479567   Top5 100.000000   BatchTime 0.102789   LR 0.001000   
2022-11-03 22:18:18,663 - INFO  - Training [50][  280/  391]   Loss 0.041908   Top1 98.507254   Top5 100.000000   BatchTime 0.102659   LR 0.001000   
2022-11-03 22:18:20,678 - INFO  - Training [50][  300/  391]   Loss 0.041789   Top1 98.502604   Top5 100.000000   BatchTime 0.102532   LR 0.001000   
2022-11-03 22:18:22,688 - INFO  - Training [50][  320/  391]   Loss 0.041810   Top1 98.508301   Top5 100.000000   BatchTime 0.102405   LR 0.001000   
2022-11-03 22:18:24,636 - INFO  - Training [50][  340/  391]   Loss 0.041575   Top1 98.524816   Top5 100.000000   BatchTime 0.102110   LR 0.001000   
2022-11-03 22:18:26,627 - INFO  - Training [50][  360/  391]   Loss 0.041086   Top1 98.530816   Top5 100.000000   BatchTime 0.101968   LR 0.001000   
2022-11-03 22:18:28,611 - INFO  - Training [50][  380/  391]   Loss 0.040977   Top1 98.519737   Top5 100.000000   BatchTime 0.101820   LR 0.001000   
2022-11-03 22:18:29,939 - INFO  - ==> Top1: 98.506    Top5: 100.000    Loss: 0.041

2022-11-03 22:18:29,940 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:18:32,592 - INFO  - Validation [50][   20/   79]   Loss 0.400595   Top1 90.195312   Top5 99.648438   BatchTime 0.132500   
2022-11-03 22:18:33,484 - INFO  - Validation [50][   40/   79]   Loss 0.408433   Top1 90.156250   Top5 99.550781   BatchTime 0.088570   
2022-11-03 22:18:34,397 - INFO  - Validation [50][   60/   79]   Loss 0.398246   Top1 90.507812   Top5 99.583333   BatchTime 0.074253   
2022-11-03 22:18:35,516 - INFO  - ==> Top1: 90.500    Top5: 99.620    Loss: 0.393

2022-11-03 22:18:35,554 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:18:35,555 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:18:35,555 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:18:35,646 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:18:35,646 - INFO  - >>>>>>>> Epoch  51
2022-11-03 22:18:35,648 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:18:39,156 - INFO  - Training [51][   20/  391]   Loss 0.035007   Top1 98.632812   Top5 100.000000   BatchTime 0.175413   LR 0.001000   
2022-11-03 22:18:40,895 - INFO  - Training [51][   40/  391]   Loss 0.039288   Top1 98.671875   Top5 100.000000   BatchTime 0.131175   LR 0.001000   
2022-11-03 22:18:42,556 - INFO  - Training [51][   60/  391]   Loss 0.038840   Top1 98.645833   Top5 100.000000   BatchTime 0.115136   LR 0.001000   
2022-11-03 22:18:44,289 - INFO  - Training [51][   80/  391]   Loss 0.037892   Top1 98.662109   Top5 100.000000   BatchTime 0.108012   LR 0.001000   
2022-11-03 22:18:46,193 - INFO  - Training [51][  100/  391]   Loss 0.038844   Top1 98.640625   Top5 100.000000   BatchTime 0.105453   LR 0.001000   
2022-11-03 22:18:48,201 - INFO  - Training [51][  120/  391]   Loss 0.039463   Top1 98.619792   Top5 100.000000   BatchTime 0.104610   LR 0.001000   
2022-11-03 22:18:50,212 - INFO  - Training [51][  140/  391]   Loss 0.039012   Top1 98.616071   Top5 100.000000   BatchTime 0.104025   LR 0.001000   
2022-11-03 22:18:52,222 - INFO  - Training [51][  160/  391]   Loss 0.038526   Top1 98.632812   Top5 100.000000   BatchTime 0.103584   LR 0.001000   
2022-11-03 22:18:54,234 - INFO  - Training [51][  180/  391]   Loss 0.039050   Top1 98.632812   Top5 100.000000   BatchTime 0.103255   LR 0.001000   
2022-11-03 22:18:56,259 - INFO  - Training [51][  200/  391]   Loss 0.038884   Top1 98.656250   Top5 100.000000   BatchTime 0.103055   LR 0.001000   
2022-11-03 22:18:58,292 - INFO  - Training [51][  220/  391]   Loss 0.039335   Top1 98.636364   Top5 100.000000   BatchTime 0.102927   LR 0.001000   
2022-11-03 22:19:00,325 - INFO  - Training [51][  240/  391]   Loss 0.039092   Top1 98.645833   Top5 100.000000   BatchTime 0.102820   LR 0.001000   
2022-11-03 22:19:02,344 - INFO  - Training [51][  260/  391]   Loss 0.038989   Top1 98.653846   Top5 100.000000   BatchTime 0.102674   LR 0.001000   
2022-11-03 22:19:04,358 - INFO  - Training [51][  280/  391]   Loss 0.039481   Top1 98.638393   Top5 100.000000   BatchTime 0.102533   LR 0.001000   
2022-11-03 22:19:06,360 - INFO  - Training [51][  300/  391]   Loss 0.039744   Top1 98.627604   Top5 100.000000   BatchTime 0.102373   LR 0.001000   
2022-11-03 22:19:08,369 - INFO  - Training [51][  320/  391]   Loss 0.040071   Top1 98.613281   Top5 100.000000   BatchTime 0.102251   LR 0.001000   
2022-11-03 22:19:10,361 - INFO  - Training [51][  340/  391]   Loss 0.039586   Top1 98.642004   Top5 99.997702   BatchTime 0.102095   LR 0.001000   
2022-11-03 22:19:12,336 - INFO  - Training [51][  360/  391]   Loss 0.039729   Top1 98.639323   Top5 99.997830   BatchTime 0.101909   LR 0.001000   
2022-11-03 22:19:14,308 - INFO  - Training [51][  380/  391]   Loss 0.039951   Top1 98.630757   Top5 99.997944   BatchTime 0.101735   LR 0.001000   
2022-11-03 22:19:15,637 - INFO  - ==> Top1: 98.640    Top5: 99.998    Loss: 0.040

2022-11-03 22:19:15,637 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:19:18,277 - INFO  - Validation [51][   20/   79]   Loss 0.395747   Top1 90.156250   Top5 99.648438   BatchTime 0.131945   
2022-11-03 22:19:19,157 - INFO  - Validation [51][   40/   79]   Loss 0.410464   Top1 90.156250   Top5 99.511719   BatchTime 0.087963   
2022-11-03 22:19:20,047 - INFO  - Validation [51][   60/   79]   Loss 0.400490   Top1 90.533854   Top5 99.557292   BatchTime 0.073474   
2022-11-03 22:19:21,123 - INFO  - ==> Top1: 90.500    Top5: 99.590    Loss: 0.396

2022-11-03 22:19:21,154 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:19:21,155 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:19:21,155 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:19:21,253 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:19:21,253 - INFO  - >>>>>>>> Epoch  52
2022-11-03 22:19:21,255 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:19:24,707 - INFO  - Training [52][   20/  391]   Loss 0.040429   Top1 98.554688   Top5 100.000000   BatchTime 0.172592   LR 0.001000   
2022-11-03 22:19:26,559 - INFO  - Training [52][   40/  391]   Loss 0.043115   Top1 98.574219   Top5 100.000000   BatchTime 0.132610   LR 0.001000   
2022-11-03 22:19:28,227 - INFO  - Training [52][   60/  391]   Loss 0.045385   Top1 98.476562   Top5 99.986979   BatchTime 0.116206   LR 0.001000   
2022-11-03 22:19:29,902 - INFO  - Training [52][   80/  391]   Loss 0.043417   Top1 98.574219   Top5 99.990234   BatchTime 0.108083   LR 0.001000   
2022-11-03 22:19:31,841 - INFO  - Training [52][  100/  391]   Loss 0.043568   Top1 98.570312   Top5 99.992188   BatchTime 0.105855   LR 0.001000   
2022-11-03 22:19:33,853 - INFO  - Training [52][  120/  391]   Loss 0.042440   Top1 98.587240   Top5 99.993490   BatchTime 0.104978   LR 0.001000   
2022-11-03 22:19:35,863 - INFO  - Training [52][  140/  391]   Loss 0.041565   Top1 98.643973   Top5 99.994420   BatchTime 0.104343   LR 0.001000   
2022-11-03 22:19:37,872 - INFO  - Training [52][  160/  391]   Loss 0.041076   Top1 98.657227   Top5 99.995117   BatchTime 0.103854   LR 0.001000   
2022-11-03 22:19:39,875 - INFO  - Training [52][  180/  391]   Loss 0.039986   Top1 98.693576   Top5 99.995660   BatchTime 0.103442   LR 0.001000   
2022-11-03 22:19:41,886 - INFO  - Training [52][  200/  391]   Loss 0.039890   Top1 98.679688   Top5 99.996094   BatchTime 0.103152   LR 0.001000   
2022-11-03 22:19:43,923 - INFO  - Training [52][  220/  391]   Loss 0.040464   Top1 98.657670   Top5 99.996449   BatchTime 0.103035   LR 0.001000   
2022-11-03 22:19:45,949 - INFO  - Training [52][  240/  391]   Loss 0.040397   Top1 98.678385   Top5 99.996745   BatchTime 0.102889   LR 0.001000   
2022-11-03 22:19:47,971 - INFO  - Training [52][  260/  391]   Loss 0.040422   Top1 98.665865   Top5 99.996995   BatchTime 0.102750   LR 0.001000   
2022-11-03 22:19:49,996 - INFO  - Training [52][  280/  391]   Loss 0.039594   Top1 98.691406   Top5 99.997210   BatchTime 0.102645   LR 0.001000   
2022-11-03 22:19:52,000 - INFO  - Training [52][  300/  391]   Loss 0.040028   Top1 98.669271   Top5 99.997396   BatchTime 0.102482   LR 0.001000   
2022-11-03 22:19:53,994 - INFO  - Training [52][  320/  391]   Loss 0.040458   Top1 98.642578   Top5 99.997559   BatchTime 0.102308   LR 0.001000   
2022-11-03 22:19:56,014 - INFO  - Training [52][  340/  391]   Loss 0.040611   Top1 98.623621   Top5 99.997702   BatchTime 0.102230   LR 0.001000   
2022-11-03 22:19:57,998 - INFO  - Training [52][  360/  391]   Loss 0.039960   Top1 98.645833   Top5 99.997830   BatchTime 0.102063   LR 0.001000   
2022-11-03 22:19:59,982 - INFO  - Training [52][  380/  391]   Loss 0.039933   Top1 98.641036   Top5 99.997944   BatchTime 0.101912   LR 0.001000   
2022-11-03 22:20:01,322 - INFO  - ==> Top1: 98.644    Top5: 99.998    Loss: 0.040

2022-11-03 22:20:01,322 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:20:03,996 - INFO  - Validation [52][   20/   79]   Loss 0.396987   Top1 90.507812   Top5 99.687500   BatchTime 0.133633   
2022-11-03 22:20:04,893 - INFO  - Validation [52][   40/   79]   Loss 0.409146   Top1 90.351562   Top5 99.667969   BatchTime 0.089243   
2022-11-03 22:20:05,795 - INFO  - Validation [52][   60/   79]   Loss 0.395911   Top1 90.703125   Top5 99.661458   BatchTime 0.074530   
2022-11-03 22:20:06,906 - INFO  - ==> Top1: 90.640    Top5: 99.650    Loss: 0.392

2022-11-03 22:20:06,939 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:20:06,940 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:20:06,940 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:20:07,046 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:20:07,046 - INFO  - >>>>>>>> Epoch  53
2022-11-03 22:20:07,048 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:20:10,578 - INFO  - Training [53][   20/  391]   Loss 0.042744   Top1 98.671875   Top5 100.000000   BatchTime 0.176488   LR 0.001000   
2022-11-03 22:20:12,249 - INFO  - Training [53][   40/  391]   Loss 0.040656   Top1 98.652344   Top5 100.000000   BatchTime 0.130033   LR 0.001000   
2022-11-03 22:20:13,931 - INFO  - Training [53][   60/  391]   Loss 0.040866   Top1 98.645833   Top5 99.986979   BatchTime 0.114719   LR 0.001000   
2022-11-03 22:20:15,582 - INFO  - Training [53][   80/  391]   Loss 0.040128   Top1 98.681641   Top5 99.990234   BatchTime 0.106670   LR 0.001000   
2022-11-03 22:20:17,553 - INFO  - Training [53][  100/  391]   Loss 0.040038   Top1 98.640625   Top5 99.992188   BatchTime 0.105048   LR 0.001000   
2022-11-03 22:20:19,562 - INFO  - Training [53][  120/  391]   Loss 0.040190   Top1 98.632812   Top5 99.993490   BatchTime 0.104281   LR 0.001000   
2022-11-03 22:20:21,570 - INFO  - Training [53][  140/  391]   Loss 0.040076   Top1 98.649554   Top5 99.994420   BatchTime 0.103731   LR 0.001000   
2022-11-03 22:20:23,588 - INFO  - Training [53][  160/  391]   Loss 0.041365   Top1 98.627930   Top5 99.995117   BatchTime 0.103375   LR 0.001000   
2022-11-03 22:20:25,609 - INFO  - Training [53][  180/  391]   Loss 0.041186   Top1 98.641493   Top5 99.995660   BatchTime 0.103115   LR 0.001000   
2022-11-03 22:20:27,650 - INFO  - Training [53][  200/  391]   Loss 0.040984   Top1 98.648438   Top5 99.996094   BatchTime 0.103006   LR 0.001000   
2022-11-03 22:20:29,670 - INFO  - Training [53][  220/  391]   Loss 0.040567   Top1 98.668324   Top5 99.996449   BatchTime 0.102827   LR 0.001000   
2022-11-03 22:20:31,686 - INFO  - Training [53][  240/  391]   Loss 0.040218   Top1 98.668620   Top5 99.996745   BatchTime 0.102656   LR 0.001000   
2022-11-03 22:20:33,696 - INFO  - Training [53][  260/  391]   Loss 0.040229   Top1 98.674880   Top5 99.996995   BatchTime 0.102492   LR 0.001000   
2022-11-03 22:20:35,701 - INFO  - Training [53][  280/  391]   Loss 0.039521   Top1 98.708147   Top5 99.997210   BatchTime 0.102330   LR 0.001000   
2022-11-03 22:20:37,729 - INFO  - Training [53][  300/  391]   Loss 0.039792   Top1 98.705729   Top5 99.997396   BatchTime 0.102269   LR 0.001000   
2022-11-03 22:20:39,729 - INFO  - Training [53][  320/  391]   Loss 0.039408   Top1 98.713379   Top5 99.997559   BatchTime 0.102127   LR 0.001000   
2022-11-03 22:20:41,733 - INFO  - Training [53][  340/  391]   Loss 0.039173   Top1 98.713235   Top5 99.997702   BatchTime 0.102014   LR 0.001000   
2022-11-03 22:20:43,727 - INFO  - Training [53][  360/  391]   Loss 0.038888   Top1 98.726128   Top5 99.997830   BatchTime 0.101884   LR 0.001000   
2022-11-03 22:20:45,711 - INFO  - Training [53][  380/  391]   Loss 0.039034   Top1 98.702714   Top5 99.997944   BatchTime 0.101744   LR 0.001000   
2022-11-03 22:20:47,045 - INFO  - ==> Top1: 98.692    Top5: 99.996    Loss: 0.039

2022-11-03 22:20:47,046 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:20:49,722 - INFO  - Validation [53][   20/   79]   Loss 0.401075   Top1 90.117188   Top5 99.609375   BatchTime 0.133739   
2022-11-03 22:20:50,610 - INFO  - Validation [53][   40/   79]   Loss 0.413380   Top1 89.980469   Top5 99.589844   BatchTime 0.089075   
2022-11-03 22:20:51,486 - INFO  - Validation [53][   60/   79]   Loss 0.402501   Top1 90.377604   Top5 99.635417   BatchTime 0.073991   
2022-11-03 22:20:52,579 - INFO  - ==> Top1: 90.390    Top5: 99.640    Loss: 0.397

2022-11-03 22:20:52,606 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:20:52,607 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:20:52,607 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:20:52,714 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:20:52,714 - INFO  - >>>>>>>> Epoch  54
2022-11-03 22:20:52,716 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:20:56,317 - INFO  - Training [54][   20/  391]   Loss 0.041399   Top1 98.515625   Top5 100.000000   BatchTime 0.180071   LR 0.001000   
2022-11-03 22:20:57,970 - INFO  - Training [54][   40/  391]   Loss 0.040272   Top1 98.574219   Top5 100.000000   BatchTime 0.131367   LR 0.001000   
2022-11-03 22:20:59,633 - INFO  - Training [54][   60/  391]   Loss 0.039565   Top1 98.671875   Top5 100.000000   BatchTime 0.115280   LR 0.001000   
2022-11-03 22:21:01,243 - INFO  - Training [54][   80/  391]   Loss 0.040522   Top1 98.603516   Top5 100.000000   BatchTime 0.106588   LR 0.001000   
2022-11-03 22:21:03,316 - INFO  - Training [54][  100/  391]   Loss 0.040889   Top1 98.578125   Top5 100.000000   BatchTime 0.106003   LR 0.001000   
2022-11-03 22:21:05,317 - INFO  - Training [54][  120/  391]   Loss 0.039939   Top1 98.613281   Top5 100.000000   BatchTime 0.105006   LR 0.001000   
2022-11-03 22:21:07,316 - INFO  - Training [54][  140/  391]   Loss 0.039890   Top1 98.621652   Top5 100.000000   BatchTime 0.104284   LR 0.001000   
2022-11-03 22:21:09,325 - INFO  - Training [54][  160/  391]   Loss 0.039269   Top1 98.623047   Top5 100.000000   BatchTime 0.103804   LR 0.001000   
2022-11-03 22:21:11,334 - INFO  - Training [54][  180/  391]   Loss 0.039857   Top1 98.598090   Top5 100.000000   BatchTime 0.103432   LR 0.001000   
2022-11-03 22:21:13,359 - INFO  - Training [54][  200/  391]   Loss 0.040043   Top1 98.574219   Top5 100.000000   BatchTime 0.103212   LR 0.001000   
2022-11-03 22:21:15,389 - INFO  - Training [54][  220/  391]   Loss 0.039538   Top1 98.590199   Top5 100.000000   BatchTime 0.103058   LR 0.001000   
2022-11-03 22:21:17,425 - INFO  - Training [54][  240/  391]   Loss 0.039669   Top1 98.597005   Top5 100.000000   BatchTime 0.102953   LR 0.001000   
2022-11-03 22:21:19,414 - INFO  - Training [54][  260/  391]   Loss 0.039335   Top1 98.608774   Top5 100.000000   BatchTime 0.102682   LR 0.001000   
2022-11-03 22:21:21,413 - INFO  - Training [54][  280/  391]   Loss 0.039418   Top1 98.607701   Top5 100.000000   BatchTime 0.102490   LR 0.001000   
2022-11-03 22:21:23,416 - INFO  - Training [54][  300/  391]   Loss 0.039732   Top1 98.609375   Top5 99.997396   BatchTime 0.102332   LR 0.001000   
2022-11-03 22:21:25,421 - INFO  - Training [54][  320/  391]   Loss 0.039568   Top1 98.630371   Top5 99.997559   BatchTime 0.102201   LR 0.001000   
2022-11-03 22:21:27,411 - INFO  - Training [54][  340/  391]   Loss 0.039569   Top1 98.635110   Top5 99.997702   BatchTime 0.102041   LR 0.001000   
2022-11-03 22:21:29,390 - INFO  - Training [54][  360/  391]   Loss 0.039848   Top1 98.621962   Top5 99.995660   BatchTime 0.101871   LR 0.001000   
2022-11-03 22:21:31,367 - INFO  - Training [54][  380/  391]   Loss 0.039965   Top1 98.612253   Top5 99.995888   BatchTime 0.101712   LR 0.001000   
2022-11-03 22:21:32,704 - INFO  - ==> Top1: 98.614    Top5: 99.996    Loss: 0.040

2022-11-03 22:21:32,705 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:21:35,380 - INFO  - Validation [54][   20/   79]   Loss 0.398045   Top1 90.312500   Top5 99.648438   BatchTime 0.133715   
2022-11-03 22:21:36,269 - INFO  - Validation [54][   40/   79]   Loss 0.415390   Top1 90.156250   Top5 99.609375   BatchTime 0.089064   
2022-11-03 22:21:37,088 - INFO  - Validation [54][   60/   79]   Loss 0.404544   Top1 90.481771   Top5 99.635417   BatchTime 0.073028   
2022-11-03 22:21:38,181 - INFO  - ==> Top1: 90.460    Top5: 99.670    Loss: 0.397

2022-11-03 22:21:38,226 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:21:38,226 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:21:38,227 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:21:38,327 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:21:38,327 - INFO  - >>>>>>>> Epoch  55
2022-11-03 22:21:38,328 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:21:41,937 - INFO  - Training [55][   20/  391]   Loss 0.042359   Top1 98.359375   Top5 100.000000   BatchTime 0.180449   LR 0.001000   
2022-11-03 22:21:43,630 - INFO  - Training [55][   40/  391]   Loss 0.040330   Top1 98.574219   Top5 100.000000   BatchTime 0.132547   LR 0.001000   
2022-11-03 22:21:45,335 - INFO  - Training [55][   60/  391]   Loss 0.039745   Top1 98.632812   Top5 100.000000   BatchTime 0.116787   LR 0.001000   
2022-11-03 22:21:46,894 - INFO  - Training [55][   80/  391]   Loss 0.041036   Top1 98.603516   Top5 100.000000   BatchTime 0.107080   LR 0.001000   
2022-11-03 22:21:48,908 - INFO  - Training [55][  100/  391]   Loss 0.040808   Top1 98.601562   Top5 100.000000   BatchTime 0.105794   LR 0.001000   
2022-11-03 22:21:50,913 - INFO  - Training [55][  120/  391]   Loss 0.039963   Top1 98.613281   Top5 100.000000   BatchTime 0.104875   LR 0.001000   
2022-11-03 22:21:52,932 - INFO  - Training [55][  140/  391]   Loss 0.040208   Top1 98.604911   Top5 100.000000   BatchTime 0.104311   LR 0.001000   
2022-11-03 22:21:54,925 - INFO  - Training [55][  160/  391]   Loss 0.039649   Top1 98.647461   Top5 100.000000   BatchTime 0.103727   LR 0.001000   
2022-11-03 22:21:56,973 - INFO  - Training [55][  180/  391]   Loss 0.039302   Top1 98.650174   Top5 100.000000   BatchTime 0.103583   LR 0.001000   
2022-11-03 22:21:58,988 - INFO  - Training [55][  200/  391]   Loss 0.038739   Top1 98.671875   Top5 100.000000   BatchTime 0.103297   LR 0.001000   
2022-11-03 22:22:01,025 - INFO  - Training [55][  220/  391]   Loss 0.039014   Top1 98.682528   Top5 100.000000   BatchTime 0.103166   LR 0.001000   
2022-11-03 22:22:03,048 - INFO  - Training [55][  240/  391]   Loss 0.039204   Top1 98.668620   Top5 100.000000   BatchTime 0.102996   LR 0.001000   
2022-11-03 22:22:05,036 - INFO  - Training [55][  260/  391]   Loss 0.039685   Top1 98.662861   Top5 100.000000   BatchTime 0.102720   LR 0.001000   
2022-11-03 22:22:07,054 - INFO  - Training [55][  280/  391]   Loss 0.039451   Top1 98.677455   Top5 100.000000   BatchTime 0.102592   LR 0.001000   
2022-11-03 22:22:09,049 - INFO  - Training [55][  300/  391]   Loss 0.039480   Top1 98.674479   Top5 100.000000   BatchTime 0.102402   LR 0.001000   
2022-11-03 22:22:11,052 - INFO  - Training [55][  320/  391]   Loss 0.039351   Top1 98.676758   Top5 100.000000   BatchTime 0.102259   LR 0.001000   
2022-11-03 22:22:13,037 - INFO  - Training [55][  340/  391]   Loss 0.039007   Top1 98.690257   Top5 100.000000   BatchTime 0.102083   LR 0.001000   
2022-11-03 22:22:15,014 - INFO  - Training [55][  360/  391]   Loss 0.039250   Top1 98.665365   Top5 100.000000   BatchTime 0.101903   LR 0.001000   
2022-11-03 22:22:16,993 - INFO  - Training [55][  380/  391]   Loss 0.039258   Top1 98.653372   Top5 100.000000   BatchTime 0.101747   LR 0.001000   
2022-11-03 22:22:18,335 - INFO  - ==> Top1: 98.656    Top5: 100.000    Loss: 0.039

2022-11-03 22:22:18,336 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:22:20,978 - INFO  - Validation [55][   20/   79]   Loss 0.405674   Top1 90.117188   Top5 99.648438   BatchTime 0.132017   
2022-11-03 22:22:21,862 - INFO  - Validation [55][   40/   79]   Loss 0.418839   Top1 90.273438   Top5 99.589844   BatchTime 0.088119   
2022-11-03 22:22:22,758 - INFO  - Validation [55][   60/   79]   Loss 0.405607   Top1 90.598958   Top5 99.609375   BatchTime 0.073672   
2022-11-03 22:22:23,897 - INFO  - ==> Top1: 90.550    Top5: 99.620    Loss: 0.399

2022-11-03 22:22:23,926 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:22:23,927 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:22:23,927 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:22:24,023 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:22:24,023 - INFO  - >>>>>>>> Epoch  56
2022-11-03 22:22:24,024 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:22:27,743 - INFO  - Training [56][   20/  391]   Loss 0.041502   Top1 98.554688   Top5 100.000000   BatchTime 0.185951   LR 0.001000   
2022-11-03 22:22:29,390 - INFO  - Training [56][   40/  391]   Loss 0.042670   Top1 98.476562   Top5 100.000000   BatchTime 0.134157   LR 0.001000   
2022-11-03 22:22:31,183 - INFO  - Training [56][   60/  391]   Loss 0.039679   Top1 98.606771   Top5 100.000000   BatchTime 0.119320   LR 0.001000   
2022-11-03 22:22:32,652 - INFO  - Training [56][   80/  391]   Loss 0.039931   Top1 98.574219   Top5 100.000000   BatchTime 0.107854   LR 0.001000   
2022-11-03 22:22:34,772 - INFO  - Training [56][  100/  391]   Loss 0.039121   Top1 98.601562   Top5 100.000000   BatchTime 0.107476   LR 0.001000   
2022-11-03 22:22:36,796 - INFO  - Training [56][  120/  391]   Loss 0.038251   Top1 98.645833   Top5 100.000000   BatchTime 0.106428   LR 0.001000   
2022-11-03 22:22:38,819 - INFO  - Training [56][  140/  391]   Loss 0.038209   Top1 98.666295   Top5 100.000000   BatchTime 0.105675   LR 0.001000   
2022-11-03 22:22:40,848 - INFO  - Training [56][  160/  391]   Loss 0.038534   Top1 98.652344   Top5 100.000000   BatchTime 0.105150   LR 0.001000   
2022-11-03 22:22:42,953 - INFO  - Training [56][  180/  391]   Loss 0.038202   Top1 98.684896   Top5 100.000000   BatchTime 0.105157   LR 0.001000   
2022-11-03 22:22:44,957 - INFO  - Training [56][  200/  391]   Loss 0.037685   Top1 98.695312   Top5 100.000000   BatchTime 0.104663   LR 0.001000   
2022-11-03 22:22:46,958 - INFO  - Training [56][  220/  391]   Loss 0.037692   Top1 98.700284   Top5 100.000000   BatchTime 0.104243   LR 0.001000   
2022-11-03 22:22:48,956 - INFO  - Training [56][  240/  391]   Loss 0.037451   Top1 98.717448   Top5 100.000000   BatchTime 0.103880   LR 0.001000   
2022-11-03 22:22:50,964 - INFO  - Training [56][  260/  391]   Loss 0.037825   Top1 98.695913   Top5 100.000000   BatchTime 0.103613   LR 0.001000   
2022-11-03 22:22:52,971 - INFO  - Training [56][  280/  391]   Loss 0.038365   Top1 98.671875   Top5 100.000000   BatchTime 0.103378   LR 0.001000   
2022-11-03 22:22:54,976 - INFO  - Training [56][  300/  391]   Loss 0.038152   Top1 98.677083   Top5 100.000000   BatchTime 0.103172   LR 0.001000   
2022-11-03 22:22:56,979 - INFO  - Training [56][  320/  391]   Loss 0.038030   Top1 98.657227   Top5 100.000000   BatchTime 0.102983   LR 0.001000   
2022-11-03 22:22:58,943 - INFO  - Training [56][  340/  391]   Loss 0.038072   Top1 98.664982   Top5 100.000000   BatchTime 0.102701   LR 0.001000   
2022-11-03 22:23:00,920 - INFO  - Training [56][  360/  391]   Loss 0.038354   Top1 98.676215   Top5 100.000000   BatchTime 0.102486   LR 0.001000   
2022-11-03 22:23:02,900 - INFO  - Training [56][  380/  391]   Loss 0.038184   Top1 98.669819   Top5 100.000000   BatchTime 0.102302   LR 0.001000   
2022-11-03 22:23:04,256 - INFO  - ==> Top1: 98.646    Top5: 100.000    Loss: 0.038

2022-11-03 22:23:04,257 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:23:06,918 - INFO  - Validation [56][   20/   79]   Loss 0.405717   Top1 90.078125   Top5 99.531250   BatchTime 0.132991   
2022-11-03 22:23:07,824 - INFO  - Validation [56][   40/   79]   Loss 0.413186   Top1 90.312500   Top5 99.492188   BatchTime 0.089129   
2022-11-03 22:23:08,735 - INFO  - Validation [56][   60/   79]   Loss 0.404436   Top1 90.598958   Top5 99.531250   BatchTime 0.074599   
2022-11-03 22:23:09,850 - INFO  - ==> Top1: 90.560    Top5: 99.560    Loss: 0.399

2022-11-03 22:23:09,883 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:23:09,884 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:23:09,884 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:23:09,976 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:23:09,977 - INFO  - >>>>>>>> Epoch  57
2022-11-03 22:23:09,978 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:23:13,638 - INFO  - Training [57][   20/  391]   Loss 0.046327   Top1 98.281250   Top5 100.000000   BatchTime 0.182976   LR 0.001000   
2022-11-03 22:23:15,297 - INFO  - Training [57][   40/  391]   Loss 0.040361   Top1 98.593750   Top5 100.000000   BatchTime 0.132970   LR 0.001000   
2022-11-03 22:23:17,040 - INFO  - Training [57][   60/  391]   Loss 0.038112   Top1 98.710938   Top5 100.000000   BatchTime 0.117704   LR 0.001000   
2022-11-03 22:23:18,727 - INFO  - Training [57][   80/  391]   Loss 0.037176   Top1 98.759766   Top5 100.000000   BatchTime 0.109360   LR 0.001000   
2022-11-03 22:23:20,724 - INFO  - Training [57][  100/  391]   Loss 0.037096   Top1 98.742188   Top5 100.000000   BatchTime 0.107454   LR 0.001000   
2022-11-03 22:23:22,742 - INFO  - Training [57][  120/  391]   Loss 0.036565   Top1 98.776042   Top5 100.000000   BatchTime 0.106364   LR 0.001000   
2022-11-03 22:23:24,753 - INFO  - Training [57][  140/  391]   Loss 0.037242   Top1 98.755580   Top5 100.000000   BatchTime 0.105531   LR 0.001000   
2022-11-03 22:23:26,771 - INFO  - Training [57][  160/  391]   Loss 0.037884   Top1 98.730469   Top5 100.000000   BatchTime 0.104956   LR 0.001000   
2022-11-03 22:23:28,790 - INFO  - Training [57][  180/  391]   Loss 0.037239   Top1 98.750000   Top5 100.000000   BatchTime 0.104507   LR 0.001000   
2022-11-03 22:23:30,796 - INFO  - Training [57][  200/  391]   Loss 0.037909   Top1 98.726562   Top5 100.000000   BatchTime 0.104088   LR 0.001000   
2022-11-03 22:23:32,812 - INFO  - Training [57][  220/  391]   Loss 0.038125   Top1 98.718040   Top5 100.000000   BatchTime 0.103787   LR 0.001000   
2022-11-03 22:23:34,833 - INFO  - Training [57][  240/  391]   Loss 0.038599   Top1 98.707682   Top5 100.000000   BatchTime 0.103561   LR 0.001000   
2022-11-03 22:23:36,842 - INFO  - Training [57][  260/  391]   Loss 0.038086   Top1 98.719952   Top5 100.000000   BatchTime 0.103319   LR 0.001000   
2022-11-03 22:23:38,844 - INFO  - Training [57][  280/  391]   Loss 0.037867   Top1 98.738839   Top5 100.000000   BatchTime 0.103090   LR 0.001000   
2022-11-03 22:23:40,854 - INFO  - Training [57][  300/  391]   Loss 0.037893   Top1 98.726562   Top5 100.000000   BatchTime 0.102919   LR 0.001000   
2022-11-03 22:23:42,863 - INFO  - Training [57][  320/  391]   Loss 0.037719   Top1 98.725586   Top5 100.000000   BatchTime 0.102763   LR 0.001000   
2022-11-03 22:23:44,864 - INFO  - Training [57][  340/  391]   Loss 0.037833   Top1 98.715533   Top5 100.000000   BatchTime 0.102605   LR 0.001000   
2022-11-03 22:23:46,842 - INFO  - Training [57][  360/  391]   Loss 0.038202   Top1 98.695747   Top5 100.000000   BatchTime 0.102399   LR 0.001000   
2022-11-03 22:23:48,826 - INFO  - Training [57][  380/  391]   Loss 0.038052   Top1 98.712993   Top5 100.000000   BatchTime 0.102230   LR 0.001000   
2022-11-03 22:23:50,152 - INFO  - ==> Top1: 98.718    Top5: 100.000    Loss: 0.038

2022-11-03 22:23:50,153 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:23:52,839 - INFO  - Validation [57][   20/   79]   Loss 0.407729   Top1 90.273438   Top5 99.453125   BatchTime 0.134211   
2022-11-03 22:23:53,760 - INFO  - Validation [57][   40/   79]   Loss 0.416344   Top1 90.273438   Top5 99.492188   BatchTime 0.090140   
2022-11-03 22:23:54,641 - INFO  - Validation [57][   60/   79]   Loss 0.405776   Top1 90.572917   Top5 99.544271   BatchTime 0.074763   
2022-11-03 22:23:55,728 - INFO  - ==> Top1: 90.460    Top5: 99.580    Loss: 0.403

2022-11-03 22:23:55,761 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:23:55,762 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:23:55,762 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:23:55,850 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:23:55,851 - INFO  - >>>>>>>> Epoch  58
2022-11-03 22:23:55,852 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:23:59,565 - INFO  - Training [58][   20/  391]   Loss 0.032435   Top1 98.984375   Top5 100.000000   BatchTime 0.185634   LR 0.001000   
2022-11-03 22:24:01,250 - INFO  - Training [58][   40/  391]   Loss 0.036714   Top1 98.828125   Top5 100.000000   BatchTime 0.134934   LR 0.001000   
2022-11-03 22:24:02,974 - INFO  - Training [58][   60/  391]   Loss 0.038100   Top1 98.750000   Top5 100.000000   BatchTime 0.118688   LR 0.001000   
2022-11-03 22:24:04,567 - INFO  - Training [58][   80/  391]   Loss 0.036530   Top1 98.818359   Top5 100.000000   BatchTime 0.108928   LR 0.001000   
2022-11-03 22:24:06,584 - INFO  - Training [58][  100/  391]   Loss 0.035643   Top1 98.835938   Top5 100.000000   BatchTime 0.107312   LR 0.001000   
2022-11-03 22:24:08,601 - INFO  - Training [58][  120/  391]   Loss 0.036391   Top1 98.802083   Top5 100.000000   BatchTime 0.106234   LR 0.001000   
2022-11-03 22:24:10,615 - INFO  - Training [58][  140/  391]   Loss 0.036895   Top1 98.783482   Top5 100.000000   BatchTime 0.105446   LR 0.001000   
2022-11-03 22:24:12,615 - INFO  - Training [58][  160/  391]   Loss 0.036808   Top1 98.774414   Top5 100.000000   BatchTime 0.104763   LR 0.001000   
2022-11-03 22:24:14,632 - INFO  - Training [58][  180/  391]   Loss 0.036192   Top1 98.802083   Top5 100.000000   BatchTime 0.104328   LR 0.001000   
2022-11-03 22:24:16,643 - INFO  - Training [58][  200/  391]   Loss 0.036245   Top1 98.785156   Top5 100.000000   BatchTime 0.103950   LR 0.001000   
2022-11-03 22:24:18,645 - INFO  - Training [58][  220/  391]   Loss 0.035695   Top1 98.799716   Top5 100.000000   BatchTime 0.103602   LR 0.001000   
2022-11-03 22:24:20,666 - INFO  - Training [58][  240/  391]   Loss 0.035676   Top1 98.802083   Top5 100.000000   BatchTime 0.103387   LR 0.001000   
2022-11-03 22:24:22,775 - INFO  - Training [58][  260/  391]   Loss 0.035653   Top1 98.819111   Top5 100.000000   BatchTime 0.103548   LR 0.001000   
2022-11-03 22:24:24,774 - INFO  - Training [58][  280/  391]   Loss 0.036477   Top1 98.783482   Top5 100.000000   BatchTime 0.103289   LR 0.001000   
2022-11-03 22:24:26,783 - INFO  - Training [58][  300/  391]   Loss 0.036585   Top1 98.776042   Top5 100.000000   BatchTime 0.103101   LR 0.001000   
2022-11-03 22:24:28,782 - INFO  - Training [58][  320/  391]   Loss 0.037011   Top1 98.757324   Top5 100.000000   BatchTime 0.102904   LR 0.001000   
2022-11-03 22:24:30,771 - INFO  - Training [58][  340/  391]   Loss 0.036773   Top1 98.770680   Top5 100.000000   BatchTime 0.102699   LR 0.001000   
2022-11-03 22:24:32,740 - INFO  - Training [58][  360/  391]   Loss 0.037071   Top1 98.758681   Top5 100.000000   BatchTime 0.102463   LR 0.001000   
2022-11-03 22:24:34,724 - INFO  - Training [58][  380/  391]   Loss 0.037707   Top1 98.739720   Top5 100.000000   BatchTime 0.102291   LR 0.001000   
2022-11-03 22:24:36,044 - INFO  - ==> Top1: 98.740    Top5: 100.000    Loss: 0.038

2022-11-03 22:24:36,045 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:24:38,675 - INFO  - Validation [58][   20/   79]   Loss 0.404060   Top1 90.195312   Top5 99.570312   BatchTime 0.131404   
2022-11-03 22:24:39,572 - INFO  - Validation [58][   40/   79]   Loss 0.417742   Top1 90.039062   Top5 99.550781   BatchTime 0.088140   
2022-11-03 22:24:40,489 - INFO  - Validation [58][   60/   79]   Loss 0.403234   Top1 90.520833   Top5 99.609375   BatchTime 0.074046   
2022-11-03 22:24:41,607 - INFO  - ==> Top1: 90.460    Top5: 99.630    Loss: 0.398

2022-11-03 22:24:41,635 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:24:41,636 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:24:41,636 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:24:41,760 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:24:41,760 - INFO  - >>>>>>>> Epoch  59
2022-11-03 22:24:41,762 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:24:45,442 - INFO  - Training [59][   20/  391]   Loss 0.025169   Top1 99.218750   Top5 100.000000   BatchTime 0.184028   LR 0.001000   
2022-11-03 22:24:47,098 - INFO  - Training [59][   40/  391]   Loss 0.034452   Top1 98.945312   Top5 99.980469   BatchTime 0.133416   LR 0.001000   
2022-11-03 22:24:48,797 - INFO  - Training [59][   60/  391]   Loss 0.034431   Top1 98.867188   Top5 99.986979   BatchTime 0.117251   LR 0.001000   
2022-11-03 22:24:50,417 - INFO  - Training [59][   80/  391]   Loss 0.033672   Top1 98.886719   Top5 99.990234   BatchTime 0.108191   LR 0.001000   
2022-11-03 22:24:52,448 - INFO  - Training [59][  100/  391]   Loss 0.034194   Top1 98.851562   Top5 99.992188   BatchTime 0.106865   LR 0.001000   
2022-11-03 22:24:54,467 - INFO  - Training [59][  120/  391]   Loss 0.034280   Top1 98.860677   Top5 99.993490   BatchTime 0.105873   LR 0.001000   
2022-11-03 22:24:56,464 - INFO  - Training [59][  140/  391]   Loss 0.034450   Top1 98.844866   Top5 99.994420   BatchTime 0.105012   LR 0.001000   
2022-11-03 22:24:58,422 - INFO  - Training [59][  160/  391]   Loss 0.033757   Top1 98.876953   Top5 99.995117   BatchTime 0.104123   LR 0.001000   
2022-11-03 22:25:00,415 - INFO  - Training [59][  180/  391]   Loss 0.034333   Top1 98.854167   Top5 99.995660   BatchTime 0.103628   LR 0.001000   
2022-11-03 22:25:02,411 - INFO  - Training [59][  200/  391]   Loss 0.035410   Top1 98.820312   Top5 99.996094   BatchTime 0.103244   LR 0.001000   
2022-11-03 22:25:04,413 - INFO  - Training [59][  220/  391]   Loss 0.036000   Top1 98.799716   Top5 99.996449   BatchTime 0.102957   LR 0.001000   
2022-11-03 22:25:06,397 - INFO  - Training [59][  240/  391]   Loss 0.036047   Top1 98.779297   Top5 99.996745   BatchTime 0.102645   LR 0.001000   
2022-11-03 22:25:08,410 - INFO  - Training [59][  260/  391]   Loss 0.035790   Top1 98.786058   Top5 99.996995   BatchTime 0.102492   LR 0.001000   
2022-11-03 22:25:10,436 - INFO  - Training [59][  280/  391]   Loss 0.035730   Top1 98.789062   Top5 99.997210   BatchTime 0.102408   LR 0.001000   
2022-11-03 22:25:12,443 - INFO  - Training [59][  300/  391]   Loss 0.035350   Top1 98.804688   Top5 99.997396   BatchTime 0.102270   LR 0.001000   
2022-11-03 22:25:14,438 - INFO  - Training [59][  320/  391]   Loss 0.035960   Top1 98.767090   Top5 99.997559   BatchTime 0.102110   LR 0.001000   
2022-11-03 22:25:16,427 - INFO  - Training [59][  340/  391]   Loss 0.036083   Top1 98.756893   Top5 99.997702   BatchTime 0.101955   LR 0.001000   
2022-11-03 22:25:18,406 - INFO  - Training [59][  360/  391]   Loss 0.036797   Top1 98.728299   Top5 99.997830   BatchTime 0.101787   LR 0.001000   
2022-11-03 22:25:20,387 - INFO  - Training [59][  380/  391]   Loss 0.036732   Top1 98.741776   Top5 99.997944   BatchTime 0.101642   LR 0.001000   
2022-11-03 22:25:21,711 - INFO  - ==> Top1: 98.726    Top5: 99.998    Loss: 0.037

2022-11-03 22:25:21,712 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:25:24,360 - INFO  - Validation [59][   20/   79]   Loss 0.411427   Top1 90.351562   Top5 99.609375   BatchTime 0.132313   
2022-11-03 22:25:25,271 - INFO  - Validation [59][   40/   79]   Loss 0.419404   Top1 90.234375   Top5 99.531250   BatchTime 0.088946   
2022-11-03 22:25:26,172 - INFO  - Validation [59][   60/   79]   Loss 0.408006   Top1 90.572917   Top5 99.596354   BatchTime 0.074318   
2022-11-03 22:25:27,295 - INFO  - ==> Top1: 90.550    Top5: 99.630    Loss: 0.403

2022-11-03 22:25:27,325 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:25:27,326 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:25:27,326 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:25:27,412 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:25:27,413 - INFO  - >>>>>>>> Epoch  60
2022-11-03 22:25:27,414 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:25:31,063 - INFO  - Training [60][   20/  391]   Loss 0.032474   Top1 98.828125   Top5 100.000000   BatchTime 0.182468   LR 0.000100   
2022-11-03 22:25:32,732 - INFO  - Training [60][   40/  391]   Loss 0.032508   Top1 98.789062   Top5 100.000000   BatchTime 0.132957   LR 0.000100   
2022-11-03 22:25:34,482 - INFO  - Training [60][   60/  391]   Loss 0.031586   Top1 98.893229   Top5 100.000000   BatchTime 0.117804   LR 0.000100   
2022-11-03 22:25:36,171 - INFO  - Training [60][   80/  391]   Loss 0.031766   Top1 98.925781   Top5 100.000000   BatchTime 0.109458   LR 0.000100   
2022-11-03 22:25:38,177 - INFO  - Training [60][  100/  391]   Loss 0.034305   Top1 98.867188   Top5 100.000000   BatchTime 0.107633   LR 0.000100   
2022-11-03 22:25:40,178 - INFO  - Training [60][  120/  391]   Loss 0.035099   Top1 98.828125   Top5 100.000000   BatchTime 0.106363   LR 0.000100   
2022-11-03 22:25:42,201 - INFO  - Training [60][  140/  391]   Loss 0.034685   Top1 98.828125   Top5 100.000000   BatchTime 0.105618   LR 0.000100   
2022-11-03 22:25:44,231 - INFO  - Training [60][  160/  391]   Loss 0.035225   Top1 98.793945   Top5 100.000000   BatchTime 0.105107   LR 0.000100   
2022-11-03 22:25:46,229 - INFO  - Training [60][  180/  391]   Loss 0.036075   Top1 98.771701   Top5 100.000000   BatchTime 0.104528   LR 0.000100   
2022-11-03 22:25:48,249 - INFO  - Training [60][  200/  391]   Loss 0.035605   Top1 98.785156   Top5 100.000000   BatchTime 0.104176   LR 0.000100   
2022-11-03 22:25:50,254 - INFO  - Training [60][  220/  391]   Loss 0.036376   Top1 98.735795   Top5 100.000000   BatchTime 0.103816   LR 0.000100   
2022-11-03 22:25:52,247 - INFO  - Training [60][  240/  391]   Loss 0.035776   Top1 98.746745   Top5 100.000000   BatchTime 0.103468   LR 0.000100   
2022-11-03 22:25:54,268 - INFO  - Training [60][  260/  391]   Loss 0.036274   Top1 98.737981   Top5 100.000000   BatchTime 0.103282   LR 0.000100   
2022-11-03 22:25:56,311 - INFO  - Training [60][  280/  391]   Loss 0.036055   Top1 98.736049   Top5 100.000000   BatchTime 0.103201   LR 0.000100   
2022-11-03 22:25:58,320 - INFO  - Training [60][  300/  391]   Loss 0.035939   Top1 98.744792   Top5 100.000000   BatchTime 0.103019   LR 0.000100   
2022-11-03 22:26:00,319 - INFO  - Training [60][  320/  391]   Loss 0.036095   Top1 98.735352   Top5 100.000000   BatchTime 0.102827   LR 0.000100   
2022-11-03 22:26:02,428 - INFO  - Training [60][  340/  391]   Loss 0.036058   Top1 98.740809   Top5 100.000000   BatchTime 0.102982   LR 0.000100   
2022-11-03 22:26:04,392 - INFO  - Training [60][  360/  391]   Loss 0.035913   Top1 98.745660   Top5 100.000000   BatchTime 0.102715   LR 0.000100   
2022-11-03 22:26:06,363 - INFO  - Training [60][  380/  391]   Loss 0.035924   Top1 98.750000   Top5 100.000000   BatchTime 0.102495   LR 0.000100   
2022-11-03 22:26:07,694 - INFO  - ==> Top1: 98.746    Top5: 100.000    Loss: 0.036

2022-11-03 22:26:07,694 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:26:10,329 - INFO  - Validation [60][   20/   79]   Loss 0.397507   Top1 90.351562   Top5 99.570312   BatchTime 0.131679   
2022-11-03 22:26:11,226 - INFO  - Validation [60][   40/   79]   Loss 0.411843   Top1 90.175781   Top5 99.531250   BatchTime 0.088276   
2022-11-03 22:26:12,139 - INFO  - Validation [60][   60/   79]   Loss 0.400381   Top1 90.677083   Top5 99.596354   BatchTime 0.074051   
2022-11-03 22:26:13,254 - INFO  - ==> Top1: 90.700    Top5: 99.620    Loss: 0.397

2022-11-03 22:26:13,296 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:26:13,297 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:26:13,297 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:26:13,396 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:26:13,396 - INFO  - >>>>>>>> Epoch  61
2022-11-03 22:26:13,397 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:26:17,097 - INFO  - Training [61][   20/  391]   Loss 0.033419   Top1 98.984375   Top5 100.000000   BatchTime 0.184988   LR 0.000100   
2022-11-03 22:26:18,754 - INFO  - Training [61][   40/  391]   Loss 0.035553   Top1 98.925781   Top5 100.000000   BatchTime 0.133907   LR 0.000100   
2022-11-03 22:26:20,478 - INFO  - Training [61][   60/  391]   Loss 0.033912   Top1 98.945312   Top5 100.000000   BatchTime 0.118009   LR 0.000100   
2022-11-03 22:26:22,317 - INFO  - Training [61][   80/  391]   Loss 0.033965   Top1 98.935547   Top5 100.000000   BatchTime 0.111490   LR 0.000100   
2022-11-03 22:26:24,309 - INFO  - Training [61][  100/  391]   Loss 0.033437   Top1 98.906250   Top5 100.000000   BatchTime 0.109111   LR 0.000100   
2022-11-03 22:26:26,319 - INFO  - Training [61][  120/  391]   Loss 0.033401   Top1 98.906250   Top5 100.000000   BatchTime 0.107679   LR 0.000100   
2022-11-03 22:26:28,343 - INFO  - Training [61][  140/  391]   Loss 0.033324   Top1 98.928571   Top5 100.000000   BatchTime 0.106752   LR 0.000100   
2022-11-03 22:26:30,350 - INFO  - Training [61][  160/  391]   Loss 0.034433   Top1 98.872070   Top5 100.000000   BatchTime 0.105952   LR 0.000100   
2022-11-03 22:26:32,366 - INFO  - Training [61][  180/  391]   Loss 0.034182   Top1 98.888889   Top5 100.000000   BatchTime 0.105380   LR 0.000100   
2022-11-03 22:26:34,373 - INFO  - Training [61][  200/  391]   Loss 0.035047   Top1 98.839844   Top5 100.000000   BatchTime 0.104874   LR 0.000100   
2022-11-03 22:26:36,414 - INFO  - Training [61][  220/  391]   Loss 0.034891   Top1 98.852983   Top5 100.000000   BatchTime 0.104617   LR 0.000100   
2022-11-03 22:26:38,424 - INFO  - Training [61][  240/  391]   Loss 0.034289   Top1 98.863932   Top5 100.000000   BatchTime 0.104275   LR 0.000100   
2022-11-03 22:26:40,444 - INFO  - Training [61][  260/  391]   Loss 0.034012   Top1 98.876202   Top5 100.000000   BatchTime 0.104022   LR 0.000100   
2022-11-03 22:26:42,460 - INFO  - Training [61][  280/  391]   Loss 0.033842   Top1 98.892299   Top5 100.000000   BatchTime 0.103792   LR 0.000100   
2022-11-03 22:26:44,466 - INFO  - Training [61][  300/  391]   Loss 0.033979   Top1 98.888021   Top5 99.997396   BatchTime 0.103559   LR 0.000100   
2022-11-03 22:26:46,450 - INFO  - Training [61][  320/  391]   Loss 0.034180   Top1 98.879395   Top5 99.997559   BatchTime 0.103288   LR 0.000100   
2022-11-03 22:26:48,439 - INFO  - Training [61][  340/  391]   Loss 0.034772   Top1 98.855699   Top5 99.997702   BatchTime 0.103061   LR 0.000100   
2022-11-03 22:26:50,403 - INFO  - Training [61][  360/  391]   Loss 0.034603   Top1 98.851997   Top5 99.997830   BatchTime 0.102789   LR 0.000100   
2022-11-03 22:26:52,376 - INFO  - Training [61][  380/  391]   Loss 0.034504   Top1 98.865132   Top5 99.997944   BatchTime 0.102572   LR 0.000100   
2022-11-03 22:26:53,711 - INFO  - ==> Top1: 98.858    Top5: 99.998    Loss: 0.035

2022-11-03 22:26:53,712 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:26:56,401 - INFO  - Validation [61][   20/   79]   Loss 0.406561   Top1 90.351562   Top5 99.609375   BatchTime 0.134360   
2022-11-03 22:26:57,291 - INFO  - Validation [61][   40/   79]   Loss 0.414107   Top1 90.312500   Top5 99.570312   BatchTime 0.089439   
2022-11-03 22:26:58,212 - INFO  - Validation [61][   60/   79]   Loss 0.401936   Top1 90.625000   Top5 99.609375   BatchTime 0.074972   
2022-11-03 22:26:59,300 - INFO  - ==> Top1: 90.650    Top5: 99.630    Loss: 0.396

2022-11-03 22:26:59,345 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:26:59,346 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:26:59,346 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:26:59,452 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:26:59,453 - INFO  - >>>>>>>> Epoch  62
2022-11-03 22:26:59,461 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:27:03,232 - INFO  - Training [62][   20/  391]   Loss 0.042557   Top1 98.437500   Top5 100.000000   BatchTime 0.188560   LR 0.000100   
2022-11-03 22:27:04,920 - INFO  - Training [62][   40/  391]   Loss 0.039467   Top1 98.554688   Top5 100.000000   BatchTime 0.136472   LR 0.000100   
2022-11-03 22:27:06,586 - INFO  - Training [62][   60/  391]   Loss 0.039761   Top1 98.593750   Top5 100.000000   BatchTime 0.118756   LR 0.000100   
2022-11-03 22:27:08,455 - INFO  - Training [62][   80/  391]   Loss 0.038638   Top1 98.681641   Top5 100.000000   BatchTime 0.112423   LR 0.000100   
2022-11-03 22:27:10,464 - INFO  - Training [62][  100/  391]   Loss 0.037871   Top1 98.671875   Top5 100.000000   BatchTime 0.110030   LR 0.000100   
2022-11-03 22:27:12,465 - INFO  - Training [62][  120/  391]   Loss 0.037242   Top1 98.684896   Top5 100.000000   BatchTime 0.108368   LR 0.000100   
2022-11-03 22:27:14,466 - INFO  - Training [62][  140/  391]   Loss 0.038028   Top1 98.643973   Top5 100.000000   BatchTime 0.107173   LR 0.000100   
2022-11-03 22:27:16,447 - INFO  - Training [62][  160/  391]   Loss 0.037468   Top1 98.686523   Top5 100.000000   BatchTime 0.106162   LR 0.000100   
2022-11-03 22:27:18,455 - INFO  - Training [62][  180/  391]   Loss 0.036992   Top1 98.706597   Top5 100.000000   BatchTime 0.105518   LR 0.000100   
2022-11-03 22:27:20,454 - INFO  - Training [62][  200/  391]   Loss 0.037405   Top1 98.718750   Top5 100.000000   BatchTime 0.104961   LR 0.000100   
2022-11-03 22:27:22,447 - INFO  - Training [62][  220/  391]   Loss 0.037522   Top1 98.686080   Top5 100.000000   BatchTime 0.104481   LR 0.000100   
2022-11-03 22:27:24,470 - INFO  - Training [62][  240/  391]   Loss 0.037545   Top1 98.688151   Top5 100.000000   BatchTime 0.104201   LR 0.000100   
2022-11-03 22:27:26,472 - INFO  - Training [62][  260/  391]   Loss 0.037485   Top1 98.695913   Top5 100.000000   BatchTime 0.103886   LR 0.000100   
2022-11-03 22:27:28,454 - INFO  - Training [62][  280/  391]   Loss 0.036933   Top1 98.733259   Top5 100.000000   BatchTime 0.103543   LR 0.000100   
2022-11-03 22:27:30,453 - INFO  - Training [62][  300/  391]   Loss 0.036863   Top1 98.718750   Top5 100.000000   BatchTime 0.103304   LR 0.000100   
2022-11-03 22:27:32,447 - INFO  - Training [62][  320/  391]   Loss 0.036374   Top1 98.745117   Top5 100.000000   BatchTime 0.103080   LR 0.000100   
2022-11-03 22:27:34,559 - INFO  - Training [62][  340/  391]   Loss 0.036207   Top1 98.747702   Top5 100.000000   BatchTime 0.103228   LR 0.000100   
2022-11-03 22:27:36,550 - INFO  - Training [62][  360/  391]   Loss 0.036044   Top1 98.756510   Top5 100.000000   BatchTime 0.103022   LR 0.000100   
2022-11-03 22:27:38,527 - INFO  - Training [62][  380/  391]   Loss 0.035829   Top1 98.760280   Top5 100.000000   BatchTime 0.102804   LR 0.000100   
2022-11-03 22:27:39,879 - INFO  - ==> Top1: 98.752    Top5: 100.000    Loss: 0.036

2022-11-03 22:27:39,880 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:27:42,571 - INFO  - Validation [62][   20/   79]   Loss 0.395417   Top1 90.351562   Top5 99.492188   BatchTime 0.134431   
2022-11-03 22:27:43,460 - INFO  - Validation [62][   40/   79]   Loss 0.410929   Top1 90.253906   Top5 99.453125   BatchTime 0.089449   
2022-11-03 22:27:44,360 - INFO  - Validation [62][   60/   79]   Loss 0.398077   Top1 90.611979   Top5 99.557292   BatchTime 0.074634   
2022-11-03 22:27:45,526 - INFO  - ==> Top1: 90.540    Top5: 99.600    Loss: 0.396

2022-11-03 22:27:45,552 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:27:45,553 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:27:45,553 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:27:45,668 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:27:45,668 - INFO  - >>>>>>>> Epoch  63
2022-11-03 22:27:45,670 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:27:49,222 - INFO  - Training [63][   20/  391]   Loss 0.033373   Top1 98.945312   Top5 100.000000   BatchTime 0.177601   LR 0.000100   
2022-11-03 22:27:50,841 - INFO  - Training [63][   40/  391]   Loss 0.031636   Top1 98.945312   Top5 100.000000   BatchTime 0.129275   LR 0.000100   
2022-11-03 22:27:52,531 - INFO  - Training [63][   60/  391]   Loss 0.034844   Top1 98.906250   Top5 100.000000   BatchTime 0.114350   LR 0.000100   
2022-11-03 22:27:54,478 - INFO  - Training [63][   80/  391]   Loss 0.034124   Top1 98.906250   Top5 100.000000   BatchTime 0.109626   LR 0.000100   
2022-11-03 22:27:56,474 - INFO  - Training [63][  100/  391]   Loss 0.033644   Top1 98.921875   Top5 100.000000   BatchTime 0.107653   LR 0.000100   
2022-11-03 22:27:58,513 - INFO  - Training [63][  120/  391]   Loss 0.033627   Top1 98.906250   Top5 100.000000   BatchTime 0.106710   LR 0.000100   
2022-11-03 22:28:00,531 - INFO  - Training [63][  140/  391]   Loss 0.034189   Top1 98.895089   Top5 100.000000   BatchTime 0.105873   LR 0.000100   
2022-11-03 22:28:02,566 - INFO  - Training [63][  160/  391]   Loss 0.034153   Top1 98.891602   Top5 100.000000   BatchTime 0.105361   LR 0.000100   
2022-11-03 22:28:04,578 - INFO  - Training [63][  180/  391]   Loss 0.034524   Top1 98.893229   Top5 100.000000   BatchTime 0.104829   LR 0.000100   
2022-11-03 22:28:06,586 - INFO  - Training [63][  200/  391]   Loss 0.035442   Top1 98.863281   Top5 100.000000   BatchTime 0.104389   LR 0.000100   
2022-11-03 22:28:08,589 - INFO  - Training [63][  220/  391]   Loss 0.035857   Top1 98.849432   Top5 100.000000   BatchTime 0.104001   LR 0.000100   
2022-11-03 22:28:10,586 - INFO  - Training [63][  240/  391]   Loss 0.035773   Top1 98.841146   Top5 100.000000   BatchTime 0.103656   LR 0.000100   
2022-11-03 22:28:12,601 - INFO  - Training [63][  260/  391]   Loss 0.035802   Top1 98.843149   Top5 100.000000   BatchTime 0.103431   LR 0.000100   
2022-11-03 22:28:14,613 - INFO  - Training [63][  280/  391]   Loss 0.036007   Top1 98.828125   Top5 100.000000   BatchTime 0.103229   LR 0.000100   
2022-11-03 22:28:16,619 - INFO  - Training [63][  300/  391]   Loss 0.035347   Top1 98.861979   Top5 100.000000   BatchTime 0.103035   LR 0.000100   
2022-11-03 22:28:18,656 - INFO  - Training [63][  320/  391]   Loss 0.035579   Top1 98.842773   Top5 100.000000   BatchTime 0.102961   LR 0.000100   
2022-11-03 22:28:20,638 - INFO  - Training [63][  340/  391]   Loss 0.035688   Top1 98.830423   Top5 100.000000   BatchTime 0.102732   LR 0.000100   
2022-11-03 22:28:22,631 - INFO  - Training [63][  360/  391]   Loss 0.035901   Top1 98.825955   Top5 100.000000   BatchTime 0.102562   LR 0.000100   
2022-11-03 22:28:24,616 - INFO  - Training [63][  380/  391]   Loss 0.035923   Top1 98.830181   Top5 100.000000   BatchTime 0.102387   LR 0.000100   
2022-11-03 22:28:25,992 - INFO  - ==> Top1: 98.834    Top5: 100.000    Loss: 0.036

2022-11-03 22:28:25,993 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:28:28,658 - INFO  - Validation [63][   20/   79]   Loss 0.409337   Top1 90.351562   Top5 99.609375   BatchTime 0.133167   
2022-11-03 22:28:29,563 - INFO  - Validation [63][   40/   79]   Loss 0.415954   Top1 90.234375   Top5 99.550781   BatchTime 0.089192   
2022-11-03 22:28:30,480 - INFO  - Validation [63][   60/   79]   Loss 0.398982   Top1 90.625000   Top5 99.609375   BatchTime 0.074749   
2022-11-03 22:28:31,586 - INFO  - ==> Top1: 90.610    Top5: 99.640    Loss: 0.392

2022-11-03 22:28:31,610 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:28:31,610 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:28:31,611 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 90.720   Top5: 99.610] Sparsity : 0.821
2022-11-03 22:28:31,699 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:28:31,699 - INFO  - >>>>>>>> Epoch  64
2022-11-03 22:28:31,700 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:28:35,376 - INFO  - Training [64][   20/  391]   Loss 0.032078   Top1 98.867188   Top5 100.000000   BatchTime 0.183777   LR 0.000100   
2022-11-03 22:28:37,118 - INFO  - Training [64][   40/  391]   Loss 0.031323   Top1 98.964844   Top5 100.000000   BatchTime 0.135438   LR 0.000100   
2022-11-03 22:28:38,658 - INFO  - Training [64][   60/  391]   Loss 0.033105   Top1 98.854167   Top5 100.000000   BatchTime 0.115947   LR 0.000100   
2022-11-03 22:28:40,696 - INFO  - Training [64][   80/  391]   Loss 0.035939   Top1 98.779297   Top5 100.000000   BatchTime 0.112436   LR 0.000100   
2022-11-03 22:28:42,736 - INFO  - Training [64][  100/  391]   Loss 0.036245   Top1 98.773438   Top5 100.000000   BatchTime 0.110356   LR 0.000100   
2022-11-03 22:28:44,767 - INFO  - Training [64][  120/  391]   Loss 0.035689   Top1 98.802083   Top5 100.000000   BatchTime 0.108887   LR 0.000100   
2022-11-03 22:28:46,794 - INFO  - Training [64][  140/  391]   Loss 0.035726   Top1 98.783482   Top5 100.000000   BatchTime 0.107809   LR 0.000100   
2022-11-03 22:28:48,830 - INFO  - Training [64][  160/  391]   Loss 0.035736   Top1 98.784180   Top5 100.000000   BatchTime 0.107054   LR 0.000100   
2022-11-03 22:28:50,829 - INFO  - Training [64][  180/  391]   Loss 0.035424   Top1 98.810764   Top5 100.000000   BatchTime 0.106267   LR 0.000100   
2022-11-03 22:28:52,847 - INFO  - Training [64][  200/  391]   Loss 0.035521   Top1 98.808594   Top5 100.000000   BatchTime 0.105730   LR 0.000100   
2022-11-03 22:28:54,849 - INFO  - Training [64][  220/  391]   Loss 0.036157   Top1 98.774858   Top5 100.000000   BatchTime 0.105219   LR 0.000100   
2022-11-03 22:28:56,854 - INFO  - Training [64][  240/  391]   Loss 0.036849   Top1 98.743490   Top5 100.000000   BatchTime 0.104804   LR 0.000100   
2022-11-03 22:28:58,874 - INFO  - Training [64][  260/  391]   Loss 0.036166   Top1 98.774038   Top5 100.000000   BatchTime 0.104510   LR 0.000100   
2022-11-03 22:29:00,873 - INFO  - Training [64][  280/  391]   Loss 0.035967   Top1 98.780692   Top5 100.000000   BatchTime 0.104184   LR 0.000100   
2022-11-03 22:29:02,885 - INFO  - Training [64][  300/  391]   Loss 0.035809   Top1 98.789062   Top5 100.000000   BatchTime 0.103944   LR 0.000100   
2022-11-03 22:29:04,924 - INFO  - Training [64][  320/  391]   Loss 0.035463   Top1 98.796387   Top5 100.000000   BatchTime 0.103822   LR 0.000100   
2022-11-03 22:29:06,920 - INFO  - Training [64][  340/  391]   Loss 0.035755   Top1 98.791360   Top5 100.000000   BatchTime 0.103583   LR 0.000100   
2022-11-03 22:29:08,895 - INFO  - Training [64][  360/  391]   Loss 0.035408   Top1 98.802083   Top5 100.000000   BatchTime 0.103314   LR 0.000100   
2022-11-03 22:29:10,862 - INFO  - Training [64][  380/  391]   Loss 0.035539   Top1 98.793174   Top5 100.000000   BatchTime 0.103055   LR 0.000100   
2022-11-03 22:29:12,274 - INFO  - ==> Top1: 98.790    Top5: 100.000    Loss: 0.036

2022-11-03 22:29:12,275 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:29:14,914 - INFO  - Validation [64][   20/   79]   Loss 0.407530   Top1 90.390625   Top5 99.531250   BatchTime 0.131867   
2022-11-03 22:29:15,785 - INFO  - Validation [64][   40/   79]   Loss 0.416011   Top1 90.390625   Top5 99.550781   BatchTime 0.087710   
2022-11-03 22:29:16,674 - INFO  - Validation [64][   60/   79]   Loss 0.402634   Top1 90.729167   Top5 99.596354   BatchTime 0.073296   
2022-11-03 22:29:17,759 - INFO  - ==> Top1: 90.730    Top5: 99.630    Loss: 0.398

2022-11-03 22:29:17,786 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:29:17,787 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:29:17,787 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 90.730   Top5: 99.630] Sparsity : 0.823
2022-11-03 22:29:17,896 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:29:17,896 - INFO  - >>>>>>>> Epoch  65
2022-11-03 22:29:17,898 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:29:21,554 - INFO  - Training [65][   20/  391]   Loss 0.032986   Top1 98.945312   Top5 100.000000   BatchTime 0.182825   LR 0.000100   
2022-11-03 22:29:23,351 - INFO  - Training [65][   40/  391]   Loss 0.034124   Top1 98.789062   Top5 100.000000   BatchTime 0.136321   LR 0.000100   
2022-11-03 22:29:24,969 - INFO  - Training [65][   60/  391]   Loss 0.033717   Top1 98.854167   Top5 100.000000   BatchTime 0.117842   LR 0.000100   
2022-11-03 22:29:27,065 - INFO  - Training [65][   80/  391]   Loss 0.035419   Top1 98.808594   Top5 100.000000   BatchTime 0.114589   LR 0.000100   
2022-11-03 22:29:29,080 - INFO  - Training [65][  100/  391]   Loss 0.034976   Top1 98.835938   Top5 100.000000   BatchTime 0.111820   LR 0.000100   
2022-11-03 22:29:31,113 - INFO  - Training [65][  120/  391]   Loss 0.034259   Top1 98.854167   Top5 100.000000   BatchTime 0.110120   LR 0.000100   
2022-11-03 22:29:33,116 - INFO  - Training [65][  140/  391]   Loss 0.034510   Top1 98.811384   Top5 100.000000   BatchTime 0.108698   LR 0.000100   
2022-11-03 22:29:35,144 - INFO  - Training [65][  160/  391]   Loss 0.034786   Top1 98.818359   Top5 100.000000   BatchTime 0.107784   LR 0.000100   
2022-11-03 22:29:37,172 - INFO  - Training [65][  180/  391]   Loss 0.035465   Top1 98.789062   Top5 100.000000   BatchTime 0.107075   LR 0.000100   
2022-11-03 22:29:39,175 - INFO  - Training [65][  200/  391]   Loss 0.035423   Top1 98.812500   Top5 100.000000   BatchTime 0.106384   LR 0.000100   
2022-11-03 22:29:41,175 - INFO  - Training [65][  220/  391]   Loss 0.035761   Top1 98.810369   Top5 100.000000   BatchTime 0.105804   LR 0.000100   
2022-11-03 22:29:43,174 - INFO  - Training [65][  240/  391]   Loss 0.035070   Top1 98.841146   Top5 100.000000   BatchTime 0.105316   LR 0.000100   
2022-11-03 22:29:45,184 - INFO  - Training [65][  260/  391]   Loss 0.035056   Top1 98.837139   Top5 100.000000   BatchTime 0.104944   LR 0.000100   
2022-11-03 22:29:47,202 - INFO  - Training [65][  280/  391]   Loss 0.035064   Top1 98.830915   Top5 100.000000   BatchTime 0.104655   LR 0.000100   
2022-11-03 22:29:49,227 - INFO  - Training [65][  300/  391]   Loss 0.034842   Top1 98.833333   Top5 100.000000   BatchTime 0.104427   LR 0.000100   
2022-11-03 22:29:51,238 - INFO  - Training [65][  320/  391]   Loss 0.034534   Top1 98.837891   Top5 100.000000   BatchTime 0.104187   LR 0.000100   
2022-11-03 22:29:53,230 - INFO  - Training [65][  340/  391]   Loss 0.034717   Top1 98.837316   Top5 100.000000   BatchTime 0.103916   LR 0.000100   
2022-11-03 22:29:55,132 - INFO  - Training [65][  360/  391]   Loss 0.035085   Top1 98.819444   Top5 100.000000   BatchTime 0.103426   LR 0.000100   
2022-11-03 22:29:57,124 - INFO  - Training [65][  380/  391]   Loss 0.035337   Top1 98.801398   Top5 100.000000   BatchTime 0.103225   LR 0.000100   
2022-11-03 22:29:58,458 - INFO  - ==> Top1: 98.808    Top5: 100.000    Loss: 0.035

2022-11-03 22:29:58,459 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:30:01,152 - INFO  - Validation [65][   20/   79]   Loss 0.400550   Top1 90.351562   Top5 99.492188   BatchTime 0.134544   
2022-11-03 22:30:02,055 - INFO  - Validation [65][   40/   79]   Loss 0.411445   Top1 90.253906   Top5 99.531250   BatchTime 0.089846   
2022-11-03 22:30:02,968 - INFO  - Validation [65][   60/   79]   Loss 0.397553   Top1 90.716146   Top5 99.583333   BatchTime 0.075122   
2022-11-03 22:30:03,878 - INFO  - ==> Top1: 90.810    Top5: 99.610    Loss: 0.392

2022-11-03 22:30:03,905 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:30:03,906 - INFO  - Scoreboard best 2 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:30:03,906 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:30:04,019 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:30:04,019 - INFO  - >>>>>>>> Epoch  66
2022-11-03 22:30:04,020 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:30:07,631 - INFO  - Training [66][   20/  391]   Loss 0.039422   Top1 98.671875   Top5 100.000000   BatchTime 0.180518   LR 0.000100   
2022-11-03 22:30:09,381 - INFO  - Training [66][   40/  391]   Loss 0.036623   Top1 98.847656   Top5 100.000000   BatchTime 0.133998   LR 0.000100   
2022-11-03 22:30:10,881 - INFO  - Training [66][   60/  391]   Loss 0.036684   Top1 98.815104   Top5 100.000000   BatchTime 0.114334   LR 0.000100   
2022-11-03 22:30:13,024 - INFO  - Training [66][   80/  391]   Loss 0.037708   Top1 98.837891   Top5 100.000000   BatchTime 0.112538   LR 0.000100   
2022-11-03 22:30:15,035 - INFO  - Training [66][  100/  391]   Loss 0.036877   Top1 98.828125   Top5 100.000000   BatchTime 0.110146   LR 0.000100   
2022-11-03 22:30:17,042 - INFO  - Training [66][  120/  391]   Loss 0.036237   Top1 98.860677   Top5 100.000000   BatchTime 0.108510   LR 0.000100   
2022-11-03 22:30:19,068 - INFO  - Training [66][  140/  391]   Loss 0.037474   Top1 98.777902   Top5 100.000000   BatchTime 0.107476   LR 0.000100   
2022-11-03 22:30:21,061 - INFO  - Training [66][  160/  391]   Loss 0.036602   Top1 98.798828   Top5 100.000000   BatchTime 0.106502   LR 0.000100   
2022-11-03 22:30:23,071 - INFO  - Training [66][  180/  391]   Loss 0.036341   Top1 98.802083   Top5 100.000000   BatchTime 0.105832   LR 0.000100   
2022-11-03 22:30:25,092 - INFO  - Training [66][  200/  391]   Loss 0.035844   Top1 98.824219   Top5 100.000000   BatchTime 0.105355   LR 0.000100   
2022-11-03 22:30:27,095 - INFO  - Training [66][  220/  391]   Loss 0.036493   Top1 98.792614   Top5 100.000000   BatchTime 0.104882   LR 0.000100   
2022-11-03 22:30:29,092 - INFO  - Training [66][  240/  391]   Loss 0.036047   Top1 98.818359   Top5 100.000000   BatchTime 0.104462   LR 0.000100   
2022-11-03 22:30:31,127 - INFO  - Training [66][  260/  391]   Loss 0.036134   Top1 98.810096   Top5 100.000000   BatchTime 0.104253   LR 0.000100   
2022-11-03 22:30:33,142 - INFO  - Training [66][  280/  391]   Loss 0.036087   Top1 98.794643   Top5 100.000000   BatchTime 0.104002   LR 0.000100   
2022-11-03 22:30:35,161 - INFO  - Training [66][  300/  391]   Loss 0.035982   Top1 98.791667   Top5 100.000000   BatchTime 0.103800   LR 0.000100   
2022-11-03 22:30:37,152 - INFO  - Training [66][  320/  391]   Loss 0.035894   Top1 98.798828   Top5 100.000000   BatchTime 0.103534   LR 0.000100   
2022-11-03 22:30:39,137 - INFO  - Training [66][  340/  391]   Loss 0.035929   Top1 98.812040   Top5 100.000000   BatchTime 0.103280   LR 0.000100   
2022-11-03 22:30:41,118 - INFO  - Training [66][  360/  391]   Loss 0.035938   Top1 98.802083   Top5 100.000000   BatchTime 0.103047   LR 0.000100   
2022-11-03 22:30:43,095 - INFO  - Training [66][  380/  391]   Loss 0.035652   Top1 98.807566   Top5 100.000000   BatchTime 0.102825   LR 0.000100   
2022-11-03 22:30:44,454 - INFO  - ==> Top1: 98.800    Top5: 100.000    Loss: 0.036

2022-11-03 22:30:44,455 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:30:47,107 - INFO  - Validation [66][   20/   79]   Loss 0.408527   Top1 90.078125   Top5 99.648438   BatchTime 0.132493   
2022-11-03 22:30:48,004 - INFO  - Validation [66][   40/   79]   Loss 0.417205   Top1 90.097656   Top5 99.550781   BatchTime 0.088683   
2022-11-03 22:30:48,890 - INFO  - Validation [66][   60/   79]   Loss 0.400713   Top1 90.598958   Top5 99.622396   BatchTime 0.073889   
2022-11-03 22:30:49,861 - INFO  - ==> Top1: 90.620    Top5: 99.640    Loss: 0.396

2022-11-03 22:30:49,884 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:30:49,885 - INFO  - Scoreboard best 2 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:30:49,885 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:30:49,977 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:30:49,978 - INFO  - >>>>>>>> Epoch  67
2022-11-03 22:30:49,979 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:30:53,644 - INFO  - Training [67][   20/  391]   Loss 0.028312   Top1 99.023438   Top5 100.000000   BatchTime 0.183241   LR 0.000100   
2022-11-03 22:30:55,343 - INFO  - Training [67][   40/  391]   Loss 0.027631   Top1 99.042969   Top5 100.000000   BatchTime 0.134090   LR 0.000100   
2022-11-03 22:30:56,814 - INFO  - Training [67][   60/  391]   Loss 0.029050   Top1 98.997396   Top5 100.000000   BatchTime 0.113906   LR 0.000100   
2022-11-03 22:30:58,852 - INFO  - Training [67][   80/  391]   Loss 0.031323   Top1 98.886719   Top5 100.000000   BatchTime 0.110905   LR 0.000100   
2022-11-03 22:31:00,873 - INFO  - Training [67][  100/  391]   Loss 0.032236   Top1 98.851562   Top5 100.000000   BatchTime 0.108936   LR 0.000100   
2022-11-03 22:31:02,887 - INFO  - Training [67][  120/  391]   Loss 0.032410   Top1 98.860677   Top5 100.000000   BatchTime 0.107561   LR 0.000100   
2022-11-03 22:31:04,895 - INFO  - Training [67][  140/  391]   Loss 0.032768   Top1 98.856027   Top5 100.000000   BatchTime 0.106537   LR 0.000100   
2022-11-03 22:31:06,924 - INFO  - Training [67][  160/  391]   Loss 0.033562   Top1 98.857422   Top5 100.000000   BatchTime 0.105903   LR 0.000100   
2022-11-03 22:31:08,952 - INFO  - Training [67][  180/  391]   Loss 0.034831   Top1 98.828125   Top5 99.995660   BatchTime 0.105398   LR 0.000100   
2022-11-03 22:31:10,972 - INFO  - Training [67][  200/  391]   Loss 0.034915   Top1 98.777344   Top5 99.996094   BatchTime 0.104958   LR 0.000100   
2022-11-03 22:31:12,978 - INFO  - Training [67][  220/  391]   Loss 0.034518   Top1 98.796165   Top5 99.996449   BatchTime 0.104536   LR 0.000100   
2022-11-03 22:31:15,001 - INFO  - Training [67][  240/  391]   Loss 0.034204   Top1 98.811849   Top5 99.996745   BatchTime 0.104253   LR 0.000100   
2022-11-03 22:31:17,000 - INFO  - Training [67][  260/  391]   Loss 0.034046   Top1 98.816106   Top5 99.996995   BatchTime 0.103923   LR 0.000100   
2022-11-03 22:31:19,020 - INFO  - Training [67][  280/  391]   Loss 0.033673   Top1 98.822545   Top5 99.997210   BatchTime 0.103712   LR 0.000100   
2022-11-03 22:31:21,025 - INFO  - Training [67][  300/  391]   Loss 0.033613   Top1 98.825521   Top5 99.997396   BatchTime 0.103481   LR 0.000100   
2022-11-03 22:31:23,017 - INFO  - Training [67][  320/  391]   Loss 0.033342   Top1 98.833008   Top5 99.997559   BatchTime 0.103239   LR 0.000100   
2022-11-03 22:31:25,011 - INFO  - Training [67][  340/  391]   Loss 0.033740   Top1 98.809743   Top5 99.997702   BatchTime 0.103032   LR 0.000100   
2022-11-03 22:31:26,997 - INFO  - Training [67][  360/  391]   Loss 0.033570   Top1 98.810764   Top5 99.997830   BatchTime 0.102823   LR 0.000100   
2022-11-03 22:31:28,988 - INFO  - Training [67][  380/  391]   Loss 0.033398   Top1 98.819901   Top5 99.997944   BatchTime 0.102652   LR 0.000100   
2022-11-03 22:31:30,326 - INFO  - ==> Top1: 98.822    Top5: 99.998    Loss: 0.034

2022-11-03 22:31:30,326 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:31:32,875 - INFO  - Validation [67][   20/   79]   Loss 0.399118   Top1 90.312500   Top5 99.531250   BatchTime 0.127370   
2022-11-03 22:31:33,763 - INFO  - Validation [67][   40/   79]   Loss 0.415004   Top1 90.078125   Top5 99.570312   BatchTime 0.085898   
2022-11-03 22:31:34,653 - INFO  - Validation [67][   60/   79]   Loss 0.402261   Top1 90.429688   Top5 99.622396   BatchTime 0.072090   
2022-11-03 22:31:35,845 - INFO  - ==> Top1: 90.560    Top5: 99.650    Loss: 0.394

2022-11-03 22:31:35,870 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:31:35,871 - INFO  - Scoreboard best 2 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:31:35,871 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.800   Top5: 99.690] Sparsity : 0.822
2022-11-03 22:31:35,969 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:31:35,970 - INFO  - >>>>>>>> Epoch  68
2022-11-03 22:31:35,971 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:31:39,555 - INFO  - Training [68][   20/  391]   Loss 0.034482   Top1 98.789062   Top5 100.000000   BatchTime 0.179177   LR 0.000100   
2022-11-03 22:31:41,172 - INFO  - Training [68][   40/  391]   Loss 0.031843   Top1 98.847656   Top5 100.000000   BatchTime 0.130015   LR 0.000100   
2022-11-03 22:31:42,836 - INFO  - Training [68][   60/  391]   Loss 0.032263   Top1 98.880208   Top5 100.000000   BatchTime 0.114416   LR 0.000100   
2022-11-03 22:31:44,725 - INFO  - Training [68][   80/  391]   Loss 0.034553   Top1 98.798828   Top5 100.000000   BatchTime 0.109416   LR 0.000100   
2022-11-03 22:31:46,740 - INFO  - Training [68][  100/  391]   Loss 0.034426   Top1 98.781250   Top5 100.000000   BatchTime 0.107685   LR 0.000100   
2022-11-03 22:31:48,739 - INFO  - Training [68][  120/  391]   Loss 0.034702   Top1 98.763021   Top5 100.000000   BatchTime 0.106393   LR 0.000100   
2022-11-03 22:31:50,730 - INFO  - Training [68][  140/  391]   Loss 0.034527   Top1 98.772321   Top5 100.000000   BatchTime 0.105417   LR 0.000100   
2022-11-03 22:31:52,742 - INFO  - Training [68][  160/  391]   Loss 0.034314   Top1 98.774414   Top5 100.000000   BatchTime 0.104815   LR 0.000100   
2022-11-03 22:31:54,751 - INFO  - Training [68][  180/  391]   Loss 0.034288   Top1 98.758681   Top5 100.000000   BatchTime 0.104333   LR 0.000100   
2022-11-03 22:31:56,766 - INFO  - Training [68][  200/  391]   Loss 0.034684   Top1 98.769531   Top5 100.000000   BatchTime 0.103974   LR 0.000100   
2022-11-03 22:31:58,781 - INFO  - Training [68][  220/  391]   Loss 0.035225   Top1 98.742898   Top5 100.000000   BatchTime 0.103678   LR 0.000100   
2022-11-03 22:32:00,778 - INFO  - Training [68][  240/  391]   Loss 0.034991   Top1 98.740234   Top5 100.000000   BatchTime 0.103360   LR 0.000100   
2022-11-03 22:32:02,800 - INFO  - Training [68][  260/  391]   Loss 0.035117   Top1 98.731971   Top5 100.000000   BatchTime 0.103186   LR 0.000100   
2022-11-03 22:32:04,835 - INFO  - Training [68][  280/  391]   Loss 0.035447   Top1 98.713728   Top5 100.000000   BatchTime 0.103083   LR 0.000100   
2022-11-03 22:32:06,870 - INFO  - Training [68][  300/  391]   Loss 0.035788   Top1 98.708333   Top5 99.997396   BatchTime 0.102996   LR 0.000100   
2022-11-03 22:32:08,892 - INFO  - Training [68][  320/  391]   Loss 0.035964   Top1 98.718262   Top5 99.997559   BatchTime 0.102875   LR 0.000100   
2022-11-03 22:32:10,908 - INFO  - Training [68][  340/  391]   Loss 0.036125   Top1 98.708640   Top5 99.997702   BatchTime 0.102754   LR 0.000100   
2022-11-03 22:32:12,912 - INFO  - Training [68][  360/  391]   Loss 0.036378   Top1 98.700087   Top5 99.995660   BatchTime 0.102611   LR 0.000100   
2022-11-03 22:32:14,896 - INFO  - Training [68][  380/  391]   Loss 0.036471   Top1 98.708882   Top5 99.995888   BatchTime 0.102433   LR 0.000100   
2022-11-03 22:32:16,208 - INFO  - ==> Top1: 98.722    Top5: 99.996    Loss: 0.036

2022-11-03 22:32:16,209 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:32:18,855 - INFO  - Validation [68][   20/   79]   Loss 0.400002   Top1 90.390625   Top5 99.492188   BatchTime 0.132248   
2022-11-03 22:32:19,739 - INFO  - Validation [68][   40/   79]   Loss 0.412376   Top1 90.429688   Top5 99.453125   BatchTime 0.088214   
2022-11-03 22:32:20,645 - INFO  - Validation [68][   60/   79]   Loss 0.398821   Top1 90.820312   Top5 99.544271   BatchTime 0.073918   
2022-11-03 22:32:21,955 - INFO  - ==> Top1: 90.820    Top5: 99.600    Loss: 0.393

2022-11-03 22:32:21,984 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:32:21,985 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:32:21,985 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:32:22,092 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:32:22,092 - INFO  - >>>>>>>> Epoch  69
2022-11-03 22:32:22,093 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:32:25,680 - INFO  - Training [69][   20/  391]   Loss 0.034915   Top1 98.710938   Top5 100.000000   BatchTime 0.179333   LR 0.000100   
2022-11-03 22:32:27,611 - INFO  - Training [69][   40/  391]   Loss 0.035961   Top1 98.671875   Top5 100.000000   BatchTime 0.137954   LR 0.000100   
2022-11-03 22:32:29,111 - INFO  - Training [69][   60/  391]   Loss 0.037444   Top1 98.671875   Top5 100.000000   BatchTime 0.116967   LR 0.000100   
2022-11-03 22:32:31,213 - INFO  - Training [69][   80/  391]   Loss 0.037191   Top1 98.740234   Top5 100.000000   BatchTime 0.113996   LR 0.000100   
2022-11-03 22:32:33,235 - INFO  - Training [69][  100/  391]   Loss 0.036393   Top1 98.804688   Top5 100.000000   BatchTime 0.111416   LR 0.000100   
2022-11-03 22:32:35,268 - INFO  - Training [69][  120/  391]   Loss 0.036626   Top1 98.782552   Top5 100.000000   BatchTime 0.109789   LR 0.000100   
2022-11-03 22:32:37,287 - INFO  - Training [69][  140/  391]   Loss 0.035907   Top1 98.800223   Top5 100.000000   BatchTime 0.108523   LR 0.000100   
2022-11-03 22:32:39,308 - INFO  - Training [69][  160/  391]   Loss 0.035458   Top1 98.828125   Top5 100.000000   BatchTime 0.107592   LR 0.000100   
2022-11-03 22:32:41,294 - INFO  - Training [69][  180/  391]   Loss 0.035513   Top1 98.797743   Top5 100.000000   BatchTime 0.106667   LR 0.000100   
2022-11-03 22:32:43,287 - INFO  - Training [69][  200/  391]   Loss 0.034472   Top1 98.835938   Top5 100.000000   BatchTime 0.105964   LR 0.000100   
2022-11-03 22:32:45,283 - INFO  - Training [69][  220/  391]   Loss 0.034357   Top1 98.852983   Top5 100.000000   BatchTime 0.105407   LR 0.000100   
2022-11-03 22:32:47,293 - INFO  - Training [69][  240/  391]   Loss 0.034406   Top1 98.847656   Top5 100.000000   BatchTime 0.104998   LR 0.000100   
2022-11-03 22:32:49,292 - INFO  - Training [69][  260/  391]   Loss 0.035150   Top1 98.789062   Top5 100.000000   BatchTime 0.104607   LR 0.000100   
2022-11-03 22:32:51,336 - INFO  - Training [69][  280/  391]   Loss 0.035206   Top1 98.780692   Top5 100.000000   BatchTime 0.104435   LR 0.000100   
2022-11-03 22:32:53,347 - INFO  - Training [69][  300/  391]   Loss 0.034911   Top1 98.794271   Top5 100.000000   BatchTime 0.104178   LR 0.000100   
2022-11-03 22:32:55,367 - INFO  - Training [69][  320/  391]   Loss 0.034931   Top1 98.789062   Top5 100.000000   BatchTime 0.103979   LR 0.000100   
2022-11-03 22:32:57,357 - INFO  - Training [69][  340/  391]   Loss 0.034939   Top1 98.795956   Top5 100.000000   BatchTime 0.103715   LR 0.000100   
2022-11-03 22:32:59,309 - INFO  - Training [69][  360/  391]   Loss 0.034763   Top1 98.806424   Top5 100.000000   BatchTime 0.103376   LR 0.000100   
2022-11-03 22:33:01,269 - INFO  - Training [69][  380/  391]   Loss 0.035183   Top1 98.801398   Top5 100.000000   BatchTime 0.103092   LR 0.000100   
2022-11-03 22:33:02,593 - INFO  - ==> Top1: 98.792    Top5: 100.000    Loss: 0.035

2022-11-03 22:33:02,594 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:33:05,213 - INFO  - Validation [69][   20/   79]   Loss 0.404413   Top1 90.429688   Top5 99.531250   BatchTime 0.130884   
2022-11-03 22:33:06,109 - INFO  - Validation [69][   40/   79]   Loss 0.415481   Top1 90.429688   Top5 99.550781   BatchTime 0.087843   
2022-11-03 22:33:07,006 - INFO  - Validation [69][   60/   79]   Loss 0.401275   Top1 90.729167   Top5 99.609375   BatchTime 0.073507   
2022-11-03 22:33:08,086 - INFO  - ==> Top1: 90.660    Top5: 99.640    Loss: 0.394

2022-11-03 22:33:08,113 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:33:08,114 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:33:08,114 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:33:08,206 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:33:08,206 - INFO  - >>>>>>>> Epoch  70
2022-11-03 22:33:08,207 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:33:11,733 - INFO  - Training [70][   20/  391]   Loss 0.037813   Top1 98.789062   Top5 100.000000   BatchTime 0.176290   LR 0.000010   
2022-11-03 22:33:13,458 - INFO  - Training [70][   40/  391]   Loss 0.036670   Top1 98.808594   Top5 100.000000   BatchTime 0.131273   LR 0.000010   
2022-11-03 22:33:14,992 - INFO  - Training [70][   60/  391]   Loss 0.036848   Top1 98.815104   Top5 100.000000   BatchTime 0.113074   LR 0.000010   
2022-11-03 22:33:16,944 - INFO  - Training [70][   80/  391]   Loss 0.037687   Top1 98.730469   Top5 100.000000   BatchTime 0.109207   LR 0.000010   
2022-11-03 22:33:18,956 - INFO  - Training [70][  100/  391]   Loss 0.037441   Top1 98.742188   Top5 100.000000   BatchTime 0.107484   LR 0.000010   
2022-11-03 22:33:20,953 - INFO  - Training [70][  120/  391]   Loss 0.035409   Top1 98.834635   Top5 100.000000   BatchTime 0.106215   LR 0.000010   
2022-11-03 22:33:22,990 - INFO  - Training [70][  140/  391]   Loss 0.036095   Top1 98.794643   Top5 100.000000   BatchTime 0.105592   LR 0.000010   
2022-11-03 22:33:25,015 - INFO  - Training [70][  160/  391]   Loss 0.035465   Top1 98.837891   Top5 100.000000   BatchTime 0.105046   LR 0.000010   
2022-11-03 22:33:27,043 - INFO  - Training [70][  180/  391]   Loss 0.035067   Top1 98.858507   Top5 99.995660   BatchTime 0.104642   LR 0.000010   
2022-11-03 22:33:29,085 - INFO  - Training [70][  200/  391]   Loss 0.035499   Top1 98.847656   Top5 99.996094   BatchTime 0.104386   LR 0.000010   
2022-11-03 22:33:31,111 - INFO  - Training [70][  220/  391]   Loss 0.034985   Top1 98.877841   Top5 99.992898   BatchTime 0.104107   LR 0.000010   
2022-11-03 22:33:33,133 - INFO  - Training [70][  240/  391]   Loss 0.034921   Top1 98.880208   Top5 99.993490   BatchTime 0.103854   LR 0.000010   
2022-11-03 22:33:35,141 - INFO  - Training [70][  260/  391]   Loss 0.035098   Top1 98.855168   Top5 99.993990   BatchTime 0.103590   LR 0.000010   
2022-11-03 22:33:37,147 - INFO  - Training [70][  280/  391]   Loss 0.034979   Top1 98.853237   Top5 99.994420   BatchTime 0.103356   LR 0.000010   
2022-11-03 22:33:39,142 - INFO  - Training [70][  300/  391]   Loss 0.034995   Top1 98.846354   Top5 99.994792   BatchTime 0.103113   LR 0.000010   
2022-11-03 22:33:41,152 - INFO  - Training [70][  320/  391]   Loss 0.034884   Top1 98.840332   Top5 99.995117   BatchTime 0.102951   LR 0.000010   
2022-11-03 22:33:43,148 - INFO  - Training [70][  340/  391]   Loss 0.034505   Top1 98.851103   Top5 99.993107   BatchTime 0.102766   LR 0.000010   
2022-11-03 22:33:45,137 - INFO  - Training [70][  360/  391]   Loss 0.034716   Top1 98.838976   Top5 99.993490   BatchTime 0.102580   LR 0.000010   
2022-11-03 22:33:47,121 - INFO  - Training [70][  380/  391]   Loss 0.034713   Top1 98.844572   Top5 99.993832   BatchTime 0.102403   LR 0.000010   
2022-11-03 22:33:48,442 - INFO  - ==> Top1: 98.842    Top5: 99.994    Loss: 0.035

2022-11-03 22:33:48,443 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:33:51,098 - INFO  - Validation [70][   20/   79]   Loss 0.397702   Top1 90.234375   Top5 99.570312   BatchTime 0.132642   
2022-11-03 22:33:52,024 - INFO  - Validation [70][   40/   79]   Loss 0.409555   Top1 90.175781   Top5 99.550781   BatchTime 0.089494   
2022-11-03 22:33:52,933 - INFO  - Validation [70][   60/   79]   Loss 0.396318   Top1 90.585938   Top5 99.609375   BatchTime 0.074807   
2022-11-03 22:33:54,047 - INFO  - ==> Top1: 90.540    Top5: 99.650    Loss: 0.390

2022-11-03 22:33:54,074 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:33:54,075 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:33:54,075 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:33:54,175 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:33:54,176 - INFO  - >>>>>>>> Epoch  71
2022-11-03 22:33:54,177 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:33:57,771 - INFO  - Training [71][   20/  391]   Loss 0.034843   Top1 98.867188   Top5 100.000000   BatchTime 0.179734   LR 0.000010   
2022-11-03 22:33:59,487 - INFO  - Training [71][   40/  391]   Loss 0.034827   Top1 98.730469   Top5 100.000000   BatchTime 0.132753   LR 0.000010   
2022-11-03 22:34:01,014 - INFO  - Training [71][   60/  391]   Loss 0.034515   Top1 98.854167   Top5 100.000000   BatchTime 0.113955   LR 0.000010   
2022-11-03 22:34:03,016 - INFO  - Training [71][   80/  391]   Loss 0.034968   Top1 98.847656   Top5 100.000000   BatchTime 0.110483   LR 0.000010   
2022-11-03 22:34:05,128 - INFO  - Training [71][  100/  391]   Loss 0.034735   Top1 98.843750   Top5 100.000000   BatchTime 0.109511   LR 0.000010   
2022-11-03 22:34:07,126 - INFO  - Training [71][  120/  391]   Loss 0.035226   Top1 98.782552   Top5 100.000000   BatchTime 0.107907   LR 0.000010   
2022-11-03 22:34:09,167 - INFO  - Training [71][  140/  391]   Loss 0.035974   Top1 98.794643   Top5 100.000000   BatchTime 0.107070   LR 0.000010   
2022-11-03 22:34:11,198 - INFO  - Training [71][  160/  391]   Loss 0.035279   Top1 98.828125   Top5 100.000000   BatchTime 0.106381   LR 0.000010   
2022-11-03 22:34:13,220 - INFO  - Training [71][  180/  391]   Loss 0.036072   Top1 98.828125   Top5 100.000000   BatchTime 0.105796   LR 0.000010   
2022-11-03 22:34:15,234 - INFO  - Training [71][  200/  391]   Loss 0.036067   Top1 98.824219   Top5 100.000000   BatchTime 0.105287   LR 0.000010   
2022-11-03 22:34:17,247 - INFO  - Training [71][  220/  391]   Loss 0.035963   Top1 98.835227   Top5 100.000000   BatchTime 0.104862   LR 0.000010   
2022-11-03 22:34:19,270 - INFO  - Training [71][  240/  391]   Loss 0.035969   Top1 98.828125   Top5 100.000000   BatchTime 0.104553   LR 0.000010   
2022-11-03 22:34:21,278 - INFO  - Training [71][  260/  391]   Loss 0.035839   Top1 98.846154   Top5 100.000000   BatchTime 0.104233   LR 0.000010   
2022-11-03 22:34:23,277 - INFO  - Training [71][  280/  391]   Loss 0.035809   Top1 98.853237   Top5 100.000000   BatchTime 0.103927   LR 0.000010   
2022-11-03 22:34:25,298 - INFO  - Training [71][  300/  391]   Loss 0.035795   Top1 98.851562   Top5 100.000000   BatchTime 0.103734   LR 0.000010   
2022-11-03 22:34:27,302 - INFO  - Training [71][  320/  391]   Loss 0.035473   Top1 98.869629   Top5 100.000000   BatchTime 0.103514   LR 0.000010   
2022-11-03 22:34:29,278 - INFO  - Training [71][  340/  391]   Loss 0.034998   Top1 98.883272   Top5 100.000000   BatchTime 0.103236   LR 0.000010   
2022-11-03 22:34:31,252 - INFO  - Training [71][  360/  391]   Loss 0.035081   Top1 98.871528   Top5 100.000000   BatchTime 0.102986   LR 0.000010   
2022-11-03 22:34:33,218 - INFO  - Training [71][  380/  391]   Loss 0.035056   Top1 98.869243   Top5 100.000000   BatchTime 0.102738   LR 0.000010   
2022-11-03 22:34:34,538 - INFO  - ==> Top1: 98.858    Top5: 100.000    Loss: 0.035

2022-11-03 22:34:34,539 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:34:37,162 - INFO  - Validation [71][   20/   79]   Loss 0.404528   Top1 90.742188   Top5 99.531250   BatchTime 0.131070   
2022-11-03 22:34:38,063 - INFO  - Validation [71][   40/   79]   Loss 0.413870   Top1 90.507812   Top5 99.531250   BatchTime 0.088083   
2022-11-03 22:34:38,939 - INFO  - Validation [71][   60/   79]   Loss 0.402948   Top1 90.859375   Top5 99.596354   BatchTime 0.073318   
2022-11-03 22:34:40,040 - INFO  - ==> Top1: 90.770    Top5: 99.630    Loss: 0.396

2022-11-03 22:34:40,063 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:34:40,064 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:34:40,064 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:34:40,176 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:34:40,177 - INFO  - >>>>>>>> Epoch  72
2022-11-03 22:34:40,178 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:34:43,766 - INFO  - Training [72][   20/  391]   Loss 0.031930   Top1 98.984375   Top5 100.000000   BatchTime 0.179395   LR 0.000010   
2022-11-03 22:34:45,577 - INFO  - Training [72][   40/  391]   Loss 0.034593   Top1 98.886719   Top5 100.000000   BatchTime 0.134967   LR 0.000010   
2022-11-03 22:34:47,084 - INFO  - Training [72][   60/  391]   Loss 0.035437   Top1 98.841146   Top5 100.000000   BatchTime 0.115099   LR 0.000010   
2022-11-03 22:34:49,083 - INFO  - Training [72][   80/  391]   Loss 0.036734   Top1 98.750000   Top5 100.000000   BatchTime 0.111312   LR 0.000010   
2022-11-03 22:34:51,102 - INFO  - Training [72][  100/  391]   Loss 0.035911   Top1 98.796875   Top5 100.000000   BatchTime 0.109234   LR 0.000010   
2022-11-03 22:34:53,131 - INFO  - Training [72][  120/  391]   Loss 0.033934   Top1 98.880208   Top5 100.000000   BatchTime 0.107936   LR 0.000010   
2022-11-03 22:34:55,135 - INFO  - Training [72][  140/  391]   Loss 0.033333   Top1 98.900670   Top5 100.000000   BatchTime 0.106834   LR 0.000010   
2022-11-03 22:34:57,100 - INFO  - Training [72][  160/  391]   Loss 0.033733   Top1 98.891602   Top5 100.000000   BatchTime 0.105757   LR 0.000010   
2022-11-03 22:34:59,121 - INFO  - Training [72][  180/  391]   Loss 0.035176   Top1 98.854167   Top5 100.000000   BatchTime 0.105235   LR 0.000010   
2022-11-03 22:35:01,127 - INFO  - Training [72][  200/  391]   Loss 0.035366   Top1 98.863281   Top5 99.996094   BatchTime 0.104743   LR 0.000010   
2022-11-03 22:35:03,138 - INFO  - Training [72][  220/  391]   Loss 0.035451   Top1 98.842330   Top5 99.996449   BatchTime 0.104361   LR 0.000010   
2022-11-03 22:35:05,155 - INFO  - Training [72][  240/  391]   Loss 0.035091   Top1 98.850911   Top5 99.996745   BatchTime 0.104066   LR 0.000010   
2022-11-03 22:35:07,167 - INFO  - Training [72][  260/  391]   Loss 0.035080   Top1 98.855168   Top5 99.996995   BatchTime 0.103800   LR 0.000010   
2022-11-03 22:35:09,171 - INFO  - Training [72][  280/  391]   Loss 0.035469   Top1 98.839286   Top5 99.994420   BatchTime 0.103542   LR 0.000010   
2022-11-03 22:35:11,177 - INFO  - Training [72][  300/  391]   Loss 0.035632   Top1 98.828125   Top5 99.994792   BatchTime 0.103327   LR 0.000010   
2022-11-03 22:35:13,151 - INFO  - Training [72][  320/  391]   Loss 0.035680   Top1 98.825684   Top5 99.995117   BatchTime 0.103036   LR 0.000010   
2022-11-03 22:35:15,143 - INFO  - Training [72][  340/  391]   Loss 0.035210   Top1 98.846507   Top5 99.995404   BatchTime 0.102836   LR 0.000010   
2022-11-03 22:35:17,115 - INFO  - Training [72][  360/  391]   Loss 0.035510   Top1 98.821615   Top5 99.995660   BatchTime 0.102599   LR 0.000010   
2022-11-03 22:35:19,094 - INFO  - Training [72][  380/  391]   Loss 0.035554   Top1 98.821957   Top5 99.995888   BatchTime 0.102408   LR 0.000010   
2022-11-03 22:35:20,437 - INFO  - ==> Top1: 98.810    Top5: 99.996    Loss: 0.036

2022-11-03 22:35:20,438 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:35:23,106 - INFO  - Validation [72][   20/   79]   Loss 0.404116   Top1 90.429688   Top5 99.531250   BatchTime 0.133283   
2022-11-03 22:35:23,995 - INFO  - Validation [72][   40/   79]   Loss 0.413694   Top1 90.234375   Top5 99.492188   BatchTime 0.088879   
2022-11-03 22:35:24,898 - INFO  - Validation [72][   60/   79]   Loss 0.401221   Top1 90.520833   Top5 99.583333   BatchTime 0.074296   
2022-11-03 22:35:26,002 - INFO  - ==> Top1: 90.550    Top5: 99.600    Loss: 0.397

2022-11-03 22:35:26,028 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:35:26,029 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:35:26,029 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:35:26,142 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:35:26,142 - INFO  - >>>>>>>> Epoch  73
2022-11-03 22:35:26,144 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:35:29,726 - INFO  - Training [73][   20/  391]   Loss 0.039071   Top1 98.671875   Top5 100.000000   BatchTime 0.179121   LR 0.000010   
2022-11-03 22:35:31,459 - INFO  - Training [73][   40/  391]   Loss 0.038251   Top1 98.691406   Top5 100.000000   BatchTime 0.132892   LR 0.000010   
2022-11-03 22:35:32,964 - INFO  - Training [73][   60/  391]   Loss 0.038993   Top1 98.580729   Top5 100.000000   BatchTime 0.113670   LR 0.000010   
2022-11-03 22:35:34,956 - INFO  - Training [73][   80/  391]   Loss 0.037459   Top1 98.642578   Top5 100.000000   BatchTime 0.110153   LR 0.000010   
2022-11-03 22:35:36,977 - INFO  - Training [73][  100/  391]   Loss 0.035840   Top1 98.718750   Top5 100.000000   BatchTime 0.108334   LR 0.000010   
2022-11-03 22:35:39,000 - INFO  - Training [73][  120/  391]   Loss 0.036283   Top1 98.769531   Top5 100.000000   BatchTime 0.107134   LR 0.000010   
2022-11-03 22:35:41,037 - INFO  - Training [73][  140/  391]   Loss 0.036834   Top1 98.744420   Top5 100.000000   BatchTime 0.106377   LR 0.000010   
2022-11-03 22:35:43,181 - INFO  - Training [73][  160/  391]   Loss 0.036423   Top1 98.769531   Top5 100.000000   BatchTime 0.106478   LR 0.000010   
2022-11-03 22:35:45,185 - INFO  - Training [73][  180/  391]   Loss 0.037043   Top1 98.741319   Top5 100.000000   BatchTime 0.105783   LR 0.000010   
2022-11-03 22:35:47,191 - INFO  - Training [73][  200/  391]   Loss 0.036561   Top1 98.757812   Top5 100.000000   BatchTime 0.105235   LR 0.000010   
2022-11-03 22:35:49,207 - INFO  - Training [73][  220/  391]   Loss 0.036849   Top1 98.735795   Top5 100.000000   BatchTime 0.104832   LR 0.000010   
2022-11-03 22:35:51,211 - INFO  - Training [73][  240/  391]   Loss 0.036267   Top1 98.772786   Top5 100.000000   BatchTime 0.104444   LR 0.000010   
2022-11-03 22:35:53,224 - INFO  - Training [73][  260/  391]   Loss 0.036261   Top1 98.783053   Top5 100.000000   BatchTime 0.104151   LR 0.000010   
2022-11-03 22:35:55,226 - INFO  - Training [73][  280/  391]   Loss 0.035745   Top1 98.803013   Top5 100.000000   BatchTime 0.103864   LR 0.000010   
2022-11-03 22:35:57,223 - INFO  - Training [73][  300/  391]   Loss 0.035482   Top1 98.809896   Top5 100.000000   BatchTime 0.103595   LR 0.000010   
2022-11-03 22:35:59,210 - INFO  - Training [73][  320/  391]   Loss 0.035302   Top1 98.808594   Top5 100.000000   BatchTime 0.103330   LR 0.000010   
2022-11-03 22:36:01,183 - INFO  - Training [73][  340/  391]   Loss 0.035163   Top1 98.821232   Top5 100.000000   BatchTime 0.103055   LR 0.000010   
2022-11-03 22:36:03,167 - INFO  - Training [73][  360/  391]   Loss 0.035348   Top1 98.815104   Top5 100.000000   BatchTime 0.102841   LR 0.000010   
2022-11-03 22:36:05,143 - INFO  - Training [73][  380/  391]   Loss 0.035527   Top1 98.807566   Top5 100.000000   BatchTime 0.102627   LR 0.000010   
2022-11-03 22:36:06,468 - INFO  - ==> Top1: 98.800    Top5: 99.998    Loss: 0.036

2022-11-03 22:36:06,469 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:36:09,123 - INFO  - Validation [73][   20/   79]   Loss 0.397123   Top1 90.546875   Top5 99.570312   BatchTime 0.132639   
2022-11-03 22:36:10,022 - INFO  - Validation [73][   40/   79]   Loss 0.415732   Top1 90.156250   Top5 99.531250   BatchTime 0.088786   
2022-11-03 22:36:10,920 - INFO  - Validation [73][   60/   79]   Loss 0.400584   Top1 90.611979   Top5 99.622396   BatchTime 0.074152   
2022-11-03 22:36:11,940 - INFO  - ==> Top1: 90.590    Top5: 99.640    Loss: 0.395

2022-11-03 22:36:11,962 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:36:11,963 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:36:11,963 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:36:12,068 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:36:12,068 - INFO  - >>>>>>>> Epoch  74
2022-11-03 22:36:12,070 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:36:15,603 - INFO  - Training [74][   20/  391]   Loss 0.034354   Top1 99.023438   Top5 100.000000   BatchTime 0.176628   LR 0.000010   
2022-11-03 22:36:17,320 - INFO  - Training [74][   40/  391]   Loss 0.032416   Top1 99.042969   Top5 99.980469   BatchTime 0.131245   LR 0.000010   
2022-11-03 22:36:18,899 - INFO  - Training [74][   60/  391]   Loss 0.033607   Top1 98.932292   Top5 99.986979   BatchTime 0.113809   LR 0.000010   
2022-11-03 22:36:20,972 - INFO  - Training [74][   80/  391]   Loss 0.035825   Top1 98.847656   Top5 99.980469   BatchTime 0.111278   LR 0.000010   
2022-11-03 22:36:22,970 - INFO  - Training [74][  100/  391]   Loss 0.036287   Top1 98.828125   Top5 99.984375   BatchTime 0.109000   LR 0.000010   
2022-11-03 22:36:25,006 - INFO  - Training [74][  120/  391]   Loss 0.035830   Top1 98.847656   Top5 99.986979   BatchTime 0.107797   LR 0.000010   
2022-11-03 22:36:27,033 - INFO  - Training [74][  140/  391]   Loss 0.035207   Top1 98.856027   Top5 99.988839   BatchTime 0.106873   LR 0.000010   
2022-11-03 22:36:29,057 - INFO  - Training [74][  160/  391]   Loss 0.035237   Top1 98.833008   Top5 99.990234   BatchTime 0.106165   LR 0.000010   
2022-11-03 22:36:31,042 - INFO  - Training [74][  180/  391]   Loss 0.035440   Top1 98.819444   Top5 99.991319   BatchTime 0.105396   LR 0.000010   
2022-11-03 22:36:33,037 - INFO  - Training [74][  200/  391]   Loss 0.036458   Top1 98.796875   Top5 99.992188   BatchTime 0.104835   LR 0.000010   
2022-11-03 22:36:34,972 - INFO  - Training [74][  220/  391]   Loss 0.036920   Top1 98.771307   Top5 99.992898   BatchTime 0.104100   LR 0.000010   
2022-11-03 22:36:36,961 - INFO  - Training [74][  240/  391]   Loss 0.036489   Top1 98.808594   Top5 99.993490   BatchTime 0.103709   LR 0.000010   
2022-11-03 22:36:38,969 - INFO  - Training [74][  260/  391]   Loss 0.036473   Top1 98.795072   Top5 99.993990   BatchTime 0.103457   LR 0.000010   
2022-11-03 22:36:40,959 - INFO  - Training [74][  280/  391]   Loss 0.036592   Top1 98.794643   Top5 99.994420   BatchTime 0.103172   LR 0.000010   
2022-11-03 22:36:42,955 - INFO  - Training [74][  300/  391]   Loss 0.036115   Top1 98.815104   Top5 99.994792   BatchTime 0.102948   LR 0.000010   
2022-11-03 22:36:44,955 - INFO  - Training [74][  320/  391]   Loss 0.035852   Top1 98.823242   Top5 99.995117   BatchTime 0.102763   LR 0.000010   
2022-11-03 22:36:46,937 - INFO  - Training [74][  340/  391]   Loss 0.036167   Top1 98.816636   Top5 99.995404   BatchTime 0.102548   LR 0.000010   
2022-11-03 22:36:48,903 - INFO  - Training [74][  360/  391]   Loss 0.035925   Top1 98.828125   Top5 99.995660   BatchTime 0.102313   LR 0.000010   
2022-11-03 22:36:50,851 - INFO  - Training [74][  380/  391]   Loss 0.035991   Top1 98.832237   Top5 99.995888   BatchTime 0.102054   LR 0.000010   
2022-11-03 22:36:52,166 - INFO  - ==> Top1: 98.830    Top5: 99.996    Loss: 0.036

2022-11-03 22:36:52,167 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:36:54,787 - INFO  - Validation [74][   20/   79]   Loss 0.401360   Top1 90.273438   Top5 99.609375   BatchTime 0.130934   
2022-11-03 22:36:55,676 - INFO  - Validation [74][   40/   79]   Loss 0.417490   Top1 90.195312   Top5 99.589844   BatchTime 0.087675   
2022-11-03 22:36:56,550 - INFO  - Validation [74][   60/   79]   Loss 0.404591   Top1 90.442708   Top5 99.635417   BatchTime 0.073025   
2022-11-03 22:36:57,541 - INFO  - ==> Top1: 90.520    Top5: 99.650    Loss: 0.397

2022-11-03 22:36:57,566 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:36:57,567 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:36:57,567 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:36:57,645 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:36:57,645 - INFO  - >>>>>>>> Epoch  75
2022-11-03 22:36:57,646 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:37:01,227 - INFO  - Training [75][   20/  391]   Loss 0.039677   Top1 98.710938   Top5 100.000000   BatchTime 0.179059   LR 0.000010   
2022-11-03 22:37:02,888 - INFO  - Training [75][   40/  391]   Loss 0.037639   Top1 98.769531   Top5 100.000000   BatchTime 0.131059   LR 0.000010   
2022-11-03 22:37:04,522 - INFO  - Training [75][   60/  391]   Loss 0.036206   Top1 98.750000   Top5 100.000000   BatchTime 0.114599   LR 0.000010   
2022-11-03 22:37:06,485 - INFO  - Training [75][   80/  391]   Loss 0.034629   Top1 98.837891   Top5 100.000000   BatchTime 0.110485   LR 0.000010   
2022-11-03 22:37:08,489 - INFO  - Training [75][  100/  391]   Loss 0.035319   Top1 98.828125   Top5 100.000000   BatchTime 0.108433   LR 0.000010   
2022-11-03 22:37:10,489 - INFO  - Training [75][  120/  391]   Loss 0.034772   Top1 98.828125   Top5 100.000000   BatchTime 0.107023   LR 0.000010   
2022-11-03 22:37:12,484 - INFO  - Training [75][  140/  391]   Loss 0.035254   Top1 98.772321   Top5 100.000000   BatchTime 0.105987   LR 0.000010   
2022-11-03 22:37:14,487 - INFO  - Training [75][  160/  391]   Loss 0.036094   Top1 98.740234   Top5 100.000000   BatchTime 0.105255   LR 0.000010   
2022-11-03 22:37:16,478 - INFO  - Training [75][  180/  391]   Loss 0.035466   Top1 98.780382   Top5 100.000000   BatchTime 0.104619   LR 0.000010   
2022-11-03 22:37:18,486 - INFO  - Training [75][  200/  391]   Loss 0.035317   Top1 98.792969   Top5 100.000000   BatchTime 0.104197   LR 0.000010   
2022-11-03 22:37:20,493 - INFO  - Training [75][  220/  391]   Loss 0.035520   Top1 98.771307   Top5 100.000000   BatchTime 0.103848   LR 0.000010   
2022-11-03 22:37:22,638 - INFO  - Training [75][  240/  391]   Loss 0.035514   Top1 98.763021   Top5 99.996745   BatchTime 0.104133   LR 0.000010   
2022-11-03 22:37:24,643 - INFO  - Training [75][  260/  391]   Loss 0.035868   Top1 98.768029   Top5 99.993990   BatchTime 0.103832   LR 0.000010   
2022-11-03 22:37:26,653 - INFO  - Training [75][  280/  391]   Loss 0.035990   Top1 98.761161   Top5 99.994420   BatchTime 0.103593   LR 0.000010   
2022-11-03 22:37:28,672 - INFO  - Training [75][  300/  391]   Loss 0.035870   Top1 98.757812   Top5 99.994792   BatchTime 0.103417   LR 0.000010   
2022-11-03 22:37:30,672 - INFO  - Training [75][  320/  391]   Loss 0.035764   Top1 98.759766   Top5 99.995117   BatchTime 0.103203   LR 0.000010   
2022-11-03 22:37:32,664 - INFO  - Training [75][  340/  391]   Loss 0.036098   Top1 98.747702   Top5 99.995404   BatchTime 0.102993   LR 0.000010   
2022-11-03 22:37:34,663 - INFO  - Training [75][  360/  391]   Loss 0.036349   Top1 98.739149   Top5 99.995660   BatchTime 0.102823   LR 0.000010   
2022-11-03 22:37:36,652 - INFO  - Training [75][  380/  391]   Loss 0.036430   Top1 98.735609   Top5 99.995888   BatchTime 0.102644   LR 0.000010   
2022-11-03 22:37:37,997 - INFO  - ==> Top1: 98.724    Top5: 99.996    Loss: 0.037

2022-11-03 22:37:37,998 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:37:40,656 - INFO  - Validation [75][   20/   79]   Loss 0.398727   Top1 90.742188   Top5 99.492188   BatchTime 0.132832   
2022-11-03 22:37:41,552 - INFO  - Validation [75][   40/   79]   Loss 0.412616   Top1 90.371094   Top5 99.492188   BatchTime 0.088815   
2022-11-03 22:37:42,438 - INFO  - Validation [75][   60/   79]   Loss 0.397566   Top1 90.625000   Top5 99.570312   BatchTime 0.073967   
2022-11-03 22:37:43,575 - INFO  - ==> Top1: 90.770    Top5: 99.600    Loss: 0.393

2022-11-03 22:37:43,599 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:37:43,600 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:37:43,600 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:37:43,703 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:37:43,703 - INFO  - >>>>>>>> Epoch  76
2022-11-03 22:37:43,705 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:37:47,272 - INFO  - Training [76][   20/  391]   Loss 0.051808   Top1 98.242188   Top5 100.000000   BatchTime 0.178352   LR 0.000010   
2022-11-03 22:37:49,035 - INFO  - Training [76][   40/  391]   Loss 0.048764   Top1 98.339844   Top5 100.000000   BatchTime 0.133244   LR 0.000010   
2022-11-03 22:37:50,516 - INFO  - Training [76][   60/  391]   Loss 0.045096   Top1 98.463542   Top5 100.000000   BatchTime 0.113516   LR 0.000010   
2022-11-03 22:37:52,482 - INFO  - Training [76][   80/  391]   Loss 0.040754   Top1 98.613281   Top5 100.000000   BatchTime 0.109708   LR 0.000010   
2022-11-03 22:37:54,515 - INFO  - Training [76][  100/  391]   Loss 0.038978   Top1 98.679688   Top5 100.000000   BatchTime 0.108100   LR 0.000010   
2022-11-03 22:37:56,535 - INFO  - Training [76][  120/  391]   Loss 0.037992   Top1 98.691406   Top5 100.000000   BatchTime 0.106912   LR 0.000010   
2022-11-03 22:37:58,559 - INFO  - Training [76][  140/  391]   Loss 0.036966   Top1 98.705357   Top5 100.000000   BatchTime 0.106096   LR 0.000010   
2022-11-03 22:38:00,563 - INFO  - Training [76][  160/  391]   Loss 0.037103   Top1 98.710938   Top5 100.000000   BatchTime 0.105359   LR 0.000010   
2022-11-03 22:38:02,593 - INFO  - Training [76][  180/  391]   Loss 0.036869   Top1 98.719618   Top5 100.000000   BatchTime 0.104932   LR 0.000010   
2022-11-03 22:38:04,596 - INFO  - Training [76][  200/  391]   Loss 0.037050   Top1 98.714844   Top5 100.000000   BatchTime 0.104451   LR 0.000010   
2022-11-03 22:38:06,582 - INFO  - Training [76][  220/  391]   Loss 0.036874   Top1 98.725142   Top5 100.000000   BatchTime 0.103985   LR 0.000010   
2022-11-03 22:38:08,584 - INFO  - Training [76][  240/  391]   Loss 0.036661   Top1 98.723958   Top5 100.000000   BatchTime 0.103661   LR 0.000010   
2022-11-03 22:38:10,593 - INFO  - Training [76][  260/  391]   Loss 0.037298   Top1 98.713942   Top5 100.000000   BatchTime 0.103413   LR 0.000010   
2022-11-03 22:38:12,597 - INFO  - Training [76][  280/  391]   Loss 0.036645   Top1 98.750000   Top5 100.000000   BatchTime 0.103185   LR 0.000010   
2022-11-03 22:38:14,612 - INFO  - Training [76][  300/  391]   Loss 0.036544   Top1 98.747396   Top5 100.000000   BatchTime 0.103021   LR 0.000010   
2022-11-03 22:38:16,607 - INFO  - Training [76][  320/  391]   Loss 0.036489   Top1 98.740234   Top5 100.000000   BatchTime 0.102818   LR 0.000010   
2022-11-03 22:38:18,608 - INFO  - Training [76][  340/  391]   Loss 0.035961   Top1 98.752298   Top5 100.000000   BatchTime 0.102655   LR 0.000010   
2022-11-03 22:38:20,596 - INFO  - Training [76][  360/  391]   Loss 0.035762   Top1 98.760851   Top5 100.000000   BatchTime 0.102473   LR 0.000010   
2022-11-03 22:38:22,583 - INFO  - Training [76][  380/  391]   Loss 0.035494   Top1 98.776727   Top5 100.000000   BatchTime 0.102310   LR 0.000010   
2022-11-03 22:38:23,901 - INFO  - ==> Top1: 98.776    Top5: 100.000    Loss: 0.035

2022-11-03 22:38:23,902 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:38:26,535 - INFO  - Validation [76][   20/   79]   Loss 0.405266   Top1 90.234375   Top5 99.648438   BatchTime 0.131590   
2022-11-03 22:38:27,419 - INFO  - Validation [76][   40/   79]   Loss 0.414621   Top1 90.117188   Top5 99.550781   BatchTime 0.087918   
2022-11-03 22:38:28,295 - INFO  - Validation [76][   60/   79]   Loss 0.398234   Top1 90.533854   Top5 99.622396   BatchTime 0.073198   
2022-11-03 22:38:29,556 - INFO  - ==> Top1: 90.540    Top5: 99.640    Loss: 0.394

2022-11-03 22:38:29,583 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:38:29,584 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:38:29,584 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.810   Top5: 99.610] Sparsity : 0.823
2022-11-03 22:38:29,698 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:38:29,699 - INFO  - >>>>>>>> Epoch  77
2022-11-03 22:38:29,700 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:38:33,303 - INFO  - Training [77][   20/  391]   Loss 0.024989   Top1 99.375000   Top5 100.000000   BatchTime 0.180121   LR 0.000010   
2022-11-03 22:38:34,956 - INFO  - Training [77][   40/  391]   Loss 0.031530   Top1 98.847656   Top5 100.000000   BatchTime 0.131392   LR 0.000010   
2022-11-03 22:38:36,603 - INFO  - Training [77][   60/  391]   Loss 0.031598   Top1 98.841146   Top5 100.000000   BatchTime 0.115041   LR 0.000010   
2022-11-03 22:38:38,501 - INFO  - Training [77][   80/  391]   Loss 0.033476   Top1 98.730469   Top5 100.000000   BatchTime 0.110001   LR 0.000010   
2022-11-03 22:38:40,500 - INFO  - Training [77][  100/  391]   Loss 0.033577   Top1 98.765625   Top5 100.000000   BatchTime 0.107994   LR 0.000010   
2022-11-03 22:38:42,521 - INFO  - Training [77][  120/  391]   Loss 0.034435   Top1 98.743490   Top5 100.000000   BatchTime 0.106836   LR 0.000010   
2022-11-03 22:38:44,504 - INFO  - Training [77][  140/  391]   Loss 0.034994   Top1 98.738839   Top5 100.000000   BatchTime 0.105736   LR 0.000010   
2022-11-03 22:38:46,506 - INFO  - Training [77][  160/  391]   Loss 0.034591   Top1 98.725586   Top5 100.000000   BatchTime 0.105035   LR 0.000010   
2022-11-03 22:38:48,500 - INFO  - Training [77][  180/  391]   Loss 0.034329   Top1 98.750000   Top5 100.000000   BatchTime 0.104440   LR 0.000010   
2022-11-03 22:38:50,488 - INFO  - Training [77][  200/  391]   Loss 0.033944   Top1 98.773438   Top5 100.000000   BatchTime 0.103938   LR 0.000010   
2022-11-03 22:38:52,509 - INFO  - Training [77][  220/  391]   Loss 0.033864   Top1 98.778409   Top5 100.000000   BatchTime 0.103671   LR 0.000010   
2022-11-03 22:38:54,525 - INFO  - Training [77][  240/  391]   Loss 0.034610   Top1 98.763021   Top5 100.000000   BatchTime 0.103433   LR 0.000010   
2022-11-03 22:38:56,567 - INFO  - Training [77][  260/  391]   Loss 0.034906   Top1 98.746995   Top5 100.000000   BatchTime 0.103332   LR 0.000010   
2022-11-03 22:38:58,660 - INFO  - Training [77][  280/  391]   Loss 0.034545   Top1 98.769531   Top5 100.000000   BatchTime 0.103424   LR 0.000010   
2022-11-03 22:39:00,657 - INFO  - Training [77][  300/  391]   Loss 0.034481   Top1 98.770833   Top5 100.000000   BatchTime 0.103186   LR 0.000010   
2022-11-03 22:39:02,654 - INFO  - Training [77][  320/  391]   Loss 0.034619   Top1 98.776855   Top5 99.997559   BatchTime 0.102977   LR 0.000010   
2022-11-03 22:39:04,645 - INFO  - Training [77][  340/  391]   Loss 0.034748   Top1 98.777574   Top5 99.997702   BatchTime 0.102777   LR 0.000010   
2022-11-03 22:39:06,621 - INFO  - Training [77][  360/  391]   Loss 0.034645   Top1 98.789062   Top5 99.997830   BatchTime 0.102556   LR 0.000010   
2022-11-03 22:39:08,591 - INFO  - Training [77][  380/  391]   Loss 0.034776   Top1 98.791118   Top5 99.997944   BatchTime 0.102343   LR 0.000010   
2022-11-03 22:39:09,910 - INFO  - ==> Top1: 98.796    Top5: 99.998    Loss: 0.035

2022-11-03 22:39:09,911 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:39:12,569 - INFO  - Validation [77][   20/   79]   Loss 0.398634   Top1 90.703125   Top5 99.453125   BatchTime 0.132829   
2022-11-03 22:39:13,494 - INFO  - Validation [77][   40/   79]   Loss 0.412667   Top1 90.507812   Top5 99.453125   BatchTime 0.089557   
2022-11-03 22:39:14,398 - INFO  - Validation [77][   60/   79]   Loss 0.401743   Top1 90.911458   Top5 99.557292   BatchTime 0.074762   
2022-11-03 22:39:15,494 - INFO  - ==> Top1: 90.960    Top5: 99.590    Loss: 0.396

2022-11-03 22:39:15,521 - INFO  - Scoreboard best 1 ==> Epoch [77][Top1: 90.960   Top5: 99.590] Sparsity : 0.823
2022-11-03 22:39:15,521 - INFO  - Scoreboard best 2 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:39:15,521 - INFO  - Scoreboard best 3 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:39:15,700 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar
                Best: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_best.pth.tar

2022-11-03 22:39:15,700 - INFO  - >>>>>>>> Epoch  78
2022-11-03 22:39:15,701 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:39:19,320 - INFO  - Training [78][   20/  391]   Loss 0.029446   Top1 99.023438   Top5 100.000000   BatchTime 0.180920   LR 0.000010   
2022-11-03 22:39:21,088 - INFO  - Training [78][   40/  391]   Loss 0.033198   Top1 98.828125   Top5 100.000000   BatchTime 0.134673   LR 0.000010   
2022-11-03 22:39:22,627 - INFO  - Training [78][   60/  391]   Loss 0.035616   Top1 98.723958   Top5 100.000000   BatchTime 0.115424   LR 0.000010   
2022-11-03 22:39:24,701 - INFO  - Training [78][   80/  391]   Loss 0.035649   Top1 98.720703   Top5 100.000000   BatchTime 0.112497   LR 0.000010   
2022-11-03 22:39:26,684 - INFO  - Training [78][  100/  391]   Loss 0.035227   Top1 98.750000   Top5 100.000000   BatchTime 0.109828   LR 0.000010   
2022-11-03 22:39:28,678 - INFO  - Training [78][  120/  391]   Loss 0.035692   Top1 98.743490   Top5 100.000000   BatchTime 0.108137   LR 0.000010   
2022-11-03 22:39:30,687 - INFO  - Training [78][  140/  391]   Loss 0.036262   Top1 98.722098   Top5 100.000000   BatchTime 0.107042   LR 0.000010   
2022-11-03 22:39:32,689 - INFO  - Training [78][  160/  391]   Loss 0.036430   Top1 98.706055   Top5 100.000000   BatchTime 0.106169   LR 0.000010   
2022-11-03 22:39:34,689 - INFO  - Training [78][  180/  391]   Loss 0.035934   Top1 98.741319   Top5 100.000000   BatchTime 0.105485   LR 0.000010   
2022-11-03 22:39:36,689 - INFO  - Training [78][  200/  391]   Loss 0.035305   Top1 98.769531   Top5 100.000000   BatchTime 0.104937   LR 0.000010   
2022-11-03 22:39:38,681 - INFO  - Training [78][  220/  391]   Loss 0.035624   Top1 98.767756   Top5 100.000000   BatchTime 0.104452   LR 0.000010   
2022-11-03 22:39:40,689 - INFO  - Training [78][  240/  391]   Loss 0.035577   Top1 98.779297   Top5 100.000000   BatchTime 0.104114   LR 0.000010   
2022-11-03 22:39:42,725 - INFO  - Training [78][  260/  391]   Loss 0.035445   Top1 98.792067   Top5 100.000000   BatchTime 0.103937   LR 0.000010   
2022-11-03 22:39:44,726 - INFO  - Training [78][  280/  391]   Loss 0.035542   Top1 98.789062   Top5 100.000000   BatchTime 0.103659   LR 0.000010   
2022-11-03 22:39:46,736 - INFO  - Training [78][  300/  391]   Loss 0.035978   Top1 98.770833   Top5 100.000000   BatchTime 0.103447   LR 0.000010   
2022-11-03 22:39:48,735 - INFO  - Training [78][  320/  391]   Loss 0.036399   Top1 98.759766   Top5 100.000000   BatchTime 0.103230   LR 0.000010   
2022-11-03 22:39:50,721 - INFO  - Training [78][  340/  391]   Loss 0.036656   Top1 98.747702   Top5 100.000000   BatchTime 0.102997   LR 0.000010   
2022-11-03 22:39:52,650 - INFO  - Training [78][  360/  391]   Loss 0.036601   Top1 98.750000   Top5 100.000000   BatchTime 0.102633   LR 0.000010   
2022-11-03 22:39:54,634 - INFO  - Training [78][  380/  391]   Loss 0.036688   Top1 98.741776   Top5 100.000000   BatchTime 0.102454   LR 0.000010   
2022-11-03 22:39:55,973 - INFO  - ==> Top1: 98.742    Top5: 100.000    Loss: 0.037

2022-11-03 22:39:55,974 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:39:58,629 - INFO  - Validation [78][   20/   79]   Loss 0.403055   Top1 90.234375   Top5 99.453125   BatchTime 0.132664   
2022-11-03 22:39:59,521 - INFO  - Validation [78][   40/   79]   Loss 0.415556   Top1 90.156250   Top5 99.453125   BatchTime 0.088628   
2022-11-03 22:40:00,429 - INFO  - Validation [78][   60/   79]   Loss 0.402983   Top1 90.494792   Top5 99.557292   BatchTime 0.074229   
2022-11-03 22:40:01,407 - INFO  - ==> Top1: 90.430    Top5: 99.610    Loss: 0.400

2022-11-03 22:40:01,433 - INFO  - Scoreboard best 1 ==> Epoch [77][Top1: 90.960   Top5: 99.590] Sparsity : 0.823
2022-11-03 22:40:01,434 - INFO  - Scoreboard best 2 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:40:01,434 - INFO  - Scoreboard best 3 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:40:01,518 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:40:01,519 - INFO  - >>>>>>>> Epoch  79
2022-11-03 22:40:01,519 - INFO  - Training: 50000 samples (128 per mini-batch)
2022-11-03 22:40:05,100 - INFO  - Training [79][   20/  391]   Loss 0.032726   Top1 98.867188   Top5 100.000000   BatchTime 0.179042   LR 0.000010   
2022-11-03 22:40:06,849 - INFO  - Training [79][   40/  391]   Loss 0.032804   Top1 98.984375   Top5 100.000000   BatchTime 0.133242   LR 0.000010   
2022-11-03 22:40:08,364 - INFO  - Training [79][   60/  391]   Loss 0.033840   Top1 98.880208   Top5 100.000000   BatchTime 0.114067   LR 0.000010   
2022-11-03 22:40:10,371 - INFO  - Training [79][   80/  391]   Loss 0.032434   Top1 98.964844   Top5 100.000000   BatchTime 0.110636   LR 0.000010   
2022-11-03 22:40:12,391 - INFO  - Training [79][  100/  391]   Loss 0.033622   Top1 98.914062   Top5 100.000000   BatchTime 0.108712   LR 0.000010   
2022-11-03 22:40:14,396 - INFO  - Training [79][  120/  391]   Loss 0.034579   Top1 98.867188   Top5 100.000000   BatchTime 0.107304   LR 0.000010   
2022-11-03 22:40:16,419 - INFO  - Training [79][  140/  391]   Loss 0.034784   Top1 98.889509   Top5 100.000000   BatchTime 0.106423   LR 0.000010   
2022-11-03 22:40:18,417 - INFO  - Training [79][  160/  391]   Loss 0.035307   Top1 98.852539   Top5 100.000000   BatchTime 0.105609   LR 0.000010   
2022-11-03 22:40:20,423 - INFO  - Training [79][  180/  391]   Loss 0.035629   Top1 98.841146   Top5 100.000000   BatchTime 0.105018   LR 0.000010   
2022-11-03 22:40:22,449 - INFO  - Training [79][  200/  391]   Loss 0.034660   Top1 98.886719   Top5 100.000000   BatchTime 0.104647   LR 0.000010   
2022-11-03 22:40:24,468 - INFO  - Training [79][  220/  391]   Loss 0.035591   Top1 98.856534   Top5 100.000000   BatchTime 0.104307   LR 0.000010   
2022-11-03 22:40:26,475 - INFO  - Training [79][  240/  391]   Loss 0.035788   Top1 98.841146   Top5 100.000000   BatchTime 0.103977   LR 0.000010   
2022-11-03 22:40:28,511 - INFO  - Training [79][  260/  391]   Loss 0.035945   Top1 98.843149   Top5 99.996995   BatchTime 0.103810   LR 0.000010   
2022-11-03 22:40:30,503 - INFO  - Training [79][  280/  391]   Loss 0.035973   Top1 98.847656   Top5 99.994420   BatchTime 0.103509   LR 0.000010   
2022-11-03 22:40:32,517 - INFO  - Training [79][  300/  391]   Loss 0.035541   Top1 98.861979   Top5 99.994792   BatchTime 0.103321   LR 0.000010   
2022-11-03 22:40:34,515 - INFO  - Training [79][  320/  391]   Loss 0.035168   Top1 98.874512   Top5 99.995117   BatchTime 0.103109   LR 0.000010   
2022-11-03 22:40:36,646 - INFO  - Training [79][  340/  391]   Loss 0.035083   Top1 98.880974   Top5 99.995404   BatchTime 0.103311   LR 0.000010   
2022-11-03 22:40:38,611 - INFO  - Training [79][  360/  391]   Loss 0.035027   Top1 98.884549   Top5 99.995660   BatchTime 0.103029   LR 0.000010   
2022-11-03 22:40:40,587 - INFO  - Training [79][  380/  391]   Loss 0.034955   Top1 98.879523   Top5 99.995888   BatchTime 0.102806   LR 0.000010   
2022-11-03 22:40:41,912 - INFO  - ==> Top1: 98.882    Top5: 99.996    Loss: 0.035

2022-11-03 22:40:41,913 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:40:44,575 - INFO  - Validation [79][   20/   79]   Loss 0.406838   Top1 90.312500   Top5 99.570312   BatchTime 0.132976   
2022-11-03 22:40:45,476 - INFO  - Validation [79][   40/   79]   Loss 0.418093   Top1 90.214844   Top5 99.531250   BatchTime 0.089034   
2022-11-03 22:40:46,388 - INFO  - Validation [79][   60/   79]   Loss 0.402546   Top1 90.729167   Top5 99.635417   BatchTime 0.074554   
2022-11-03 22:40:47,263 - INFO  - ==> Top1: 90.740    Top5: 99.650    Loss: 0.397

2022-11-03 22:40:47,290 - INFO  - Scoreboard best 1 ==> Epoch [77][Top1: 90.960   Top5: 99.590] Sparsity : 0.823
2022-11-03 22:40:47,291 - INFO  - Scoreboard best 2 ==> Epoch [43][Top1: 90.830   Top5: 99.650] Sparsity : 0.822
2022-11-03 22:40:47,291 - INFO  - Scoreboard best 3 ==> Epoch [68][Top1: 90.820   Top5: 99.600] Sparsity : 0.823
2022-11-03 22:40:47,386 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/out/MobileNetv2_cifar10_a8w8_10_epoch80_20221103-213952/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:40:47,387 - INFO  - >>>>>>>> Epoch -1 (final model evaluation)
2022-11-03 22:40:47,387 - INFO  - Validation: 10000 samples (128 per mini-batch)
2022-11-03 22:40:49,958 - INFO  - Validation [   20/   79]   Loss 0.406838   Top1 90.312500   Top5 99.570312   BatchTime 0.128503   
2022-11-03 22:40:50,644 - INFO  - Validation [   40/   79]   Loss 0.418093   Top1 90.214844   Top5 99.531250   BatchTime 0.081410   
2022-11-03 22:40:51,335 - INFO  - Validation [   60/   79]   Loss 0.402546   Top1 90.729167   Top5 99.635417   BatchTime 0.065795   
2022-11-03 22:40:52,187 - INFO  - ==> Top1: 90.740    Top5: 99.650    Loss: 0.397

2022-11-03 22:40:52,244 - INFO  - Saving checkpoint to:
             Current: /home/ilena7440/slsq/LSQ/pruned_model/MobileNetv2_cifar10_a8w8_10_epoch80_checkpoint.pth.tar

2022-11-03 22:40:52,244 - INFO  - Program completed successfully ... exiting ...
2022-11-03 22:40:52,245 - INFO  - If you have any questions or suggestions, please visit: github.com/zhutmost/lsq-net
